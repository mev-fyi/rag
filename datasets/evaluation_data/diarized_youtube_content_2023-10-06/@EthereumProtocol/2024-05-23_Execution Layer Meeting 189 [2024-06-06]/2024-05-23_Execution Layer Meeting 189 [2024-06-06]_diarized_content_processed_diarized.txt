00:02:59.954 - 00:03:37.758, Speaker A: Good morning everyone. We are live for all core devs number 189. Main thing on the agenda today, or at least most important thing, is finalizing the petroscope. The biggest question there seems to be around what to do with EOF and then potentially how we'd approach a blob count increase. Thank you to all the teams who've laid out their positions and views. Before the call I had some time to read through all of them. They're all on the agenda then.
00:03:37.758 - 00:04:22.048, Speaker A: Mikael had a lot of spec issues around picture that he wanted us to look into, so go through those. We also had another breakout room on 7702 and yeah, spent most of it discussing some concerns around revocability. So it's worth getting this group's opinion on those. Then. Last picture thing. There's a proposal by Guillaume about deactivating EIP 158 as it has some implications with portal, sorry, with Verkle after that is portal. After that I had some potential improvements for awkward evs, how we run network upgrades and how eth magicians plays into that.
00:04:22.048 - 00:05:28.984, Speaker A: And then testing teams has some comms stuff they want to talk about. And lastly, shout out to the first peer das breakout next week. Hopefully we get through all this. So first on the list, so the picture scope discussion so on the agenda, as I said, we have updated views from Bayesu, Ethereum, J's Nethermind ref had shared their views before, and then the EF DevOps team had shared their view of like all the potential forks we could do and what it would mean from like a testing perspective. So I think the only two teams we didn't hear from in writing were Geth and Aragon, but we have heard a bit from them on the last call. Reading through all of them this morning, it seems like pretty much like everyone across basically Ethereum, JS, Nethermine and ref would like to ship EOf relatively soon. So before the vertical fork.
00:05:28.984 - 00:06:15.994, Speaker A: And then the question is whether or not we want to combine it into like whether or not you want to combine it with Petra. Some teams raise concern around the scope of that. Other teams would rather have everything together in one fork. And there seems to be also like a pretty common, or like a broadly shared view that even if we do split the forks out, like if EOf is a separate fork, we should keep this minimal. Like, people don't want to do a fork with like many other features in addition to EOF before Virk. So I guess I'll pause here. Anyone from any of the client teams want to add more color or nuance that's what I just said.
00:06:15.994 - 00:07:25.280, Speaker A: And if anyone from Geth or Aragon specifically want to share their perspective, yeah, that'd be great. Yeah. So from my perspective, I personally would like to ship fork that is more or less implemented at the moment, with some minor changes might still go in, but without any major changes, I would consider UOF actually implemented. So it more depends if testing would delay the fork, but I would like it to ship in 2024 and then I'm open to anything else important comes up that is more urgent than vertical trees. And for that, for example, peer desk might be, or something else that will be ready later, maybe epbs for example, with inclusion list. If that's have a different iteration, then I'm fine. If we decide if it's more urgent than Verkle, for example, and will be ready earlier than verkle to be shipped to ship it earlier.
00:07:25.280 - 00:08:12.164, Speaker A: So I'm kind of. My reasoning is also because Prague is already quite big, I wouldn't call it small. Making it even larger would increase the risks of shipping it in time, whatever the timeframe is, as well as bugs, and just increase the complexity. And I think we should ship in small forks probably are a lie, in my opinion. But we shouldn't also aim for extremely big forks because they increase complexity of testing and shipping, etcetera, and they cause delays. So that's my stance. Thank you, Guillaume.
00:08:12.164 - 00:08:49.930, Speaker A: Yeah, so you were asking for perspective? I've got some perspective, some new perspective. I have tried to run a transition on a more recent database, which I hadn't done in a few years, and with ten k, which was the upper bound. Sorry, 10,000 leaves being translated per block. We already are over the two weeks limit, which means the state has grown way faster than the 2022 estimates. That was on the database that is about a year old. The state is growing. Now the question comes about the usability.
00:08:49.930 - 00:09:25.878, Speaker A: Sorry, the feature like shipping features, just because we can ship them now, including AOF. But not only. I don't think this is what we should be doing, we should be figuring out what we really need to do right now. In my understanding, or at least my fear, is that the more we wait, the bigger the vertical translation will take. The longer the vertical translation will take. Is if really that urgent? I don't think so. I've read several arguments for shipping it in Prague.
00:09:25.878 - 00:10:08.142, Speaker A: The more I read those arguments, the more I realize, no, they're actually, there's nothing that really justifies the of to begin with, like, Dragon has published something. I read it with interest I asked a couple questions. My understanding is that everything can be done without a UF. I think UF still doesn't have a very strong case and we are delaying verkle. Just because it's been coded doesn't mean it's been tested. Yeah, I heard about the two test, but from what I have understood, asking Pari and other people, it has not run on a test net. So you are not ready? Like EOF is not ready.
00:10:08.142 - 00:10:32.484, Speaker A: We don't know. So that's one thing. As when it comes to shipping EOF and other features in yet another forum between Pectra and Virkow. Well, once again the state is growing. Time to wake up. Time to start taking the problem seriously. Thanks, Andrew.
00:10:32.484 - 00:11:11.124, Speaker A: Yeah. From my point of view, if we can see if we agree that both Virko and EOF are good things, and we should deliver them both, then my thinking is that if we input Uif into a vector and then deliver Verkle, that will be the fastest way to deliver both. That's my intuition. So that would be my preference. Uf infectra and then verkle. If we are not happy with that, then I am fine. If EOF is excluded from backtrack and then we deliver.
00:11:11.124 - 00:11:57.044, Speaker A: Welcome. In the next fork, that is Osaka, my least preferable option is to have a fork between Pectra and Berko to ship Eoi. Because here I agree with Guillaume, the state is growing and Virko is. I think Virko is more important than UAF. So yeah, that would be, I think to my mind that's the worst outcome. Thanks, Jugan. Just to address the statement of growing urgency for the vehicle, we are talking about 1020 percent of the longer transition time.
00:11:57.044 - 00:12:37.964, Speaker A: EOF is not going to increase the state and three additional months that we will need to ship additional fork are not going to delay work for a lot. If you are talking about 1030 percentages, not even that. It's not like two X. So framing that inclusion of the EOF is going to damage the Ethereum is really bad, to be honest. That's it for me. Thank you, Matt. Sorry, can I just respond to this? Sure.
00:12:37.964 - 00:13:05.754, Speaker A: And then that's you, Matt. Arthur. Yeah. I'm not saying EOF per se is going to like the size of EOF contract, I'm aware are smaller. Well, at least that's the claim and the hope. But I'm talking about the time it takes to deliver. Yes, the state is growing, maybe by 20% per year, but my data is from last year, so it's already grown much more since then.
00:13:05.754 - 00:13:52.874, Speaker A: And then once again, the state the claim that it can be implemented in three months doesn't mean it's going to be delivered in three months, just some precision. But I'm not blaming Eof for everything. It's EOf and other features that do not as a whole, delay. Delay. Got it. Matt? Yeah, no, I mean, I agree with Andrew here that this is essentially an opportunity cost and that if we kind of delay EOf beyond the vertical transition that it might be hard to deliver to any reasonable timeline. And the two fork approach also seems dubious from a scope perspective.
00:13:52.874 - 00:14:48.754, Speaker A: And you know, there's also the, during our testing, are more efficient than what we have right now. And I know there's a few ideas kicking around on how we can improve the performance of the transition. So I kind of echoed the point of ref and other folks at the transition time might not be the end of the world here, especially considering the l two's position of posting stayed in bobs and these other kind of reductions that we're taking. But yeah, I mostly see this as an opportunity cost from our perspective, if we don't ship EOF prior to Verkle, it's going to be a long time before we see anything meaningful in the EVM like that. Thanks Gijinder. You're muted. Kushinder.
00:14:48.754 - 00:15:43.740, Speaker A: Sorry, it was mute. So as you, as you know what, as you know from our blog post what the perspective of Ethereum J's team is, and we see that EOF, if it has to make the window, it has to make the window by Q one for that. You know, the devnets for UF needs to start as soon as Pector is shipped out and maybe if we can ship it out by October. And so that is our team perspective. But in terms of, in my opinion, refactoring worker on top of EOF will delay workal at least by three months to six months. So I think we can, we may, we can try to do it in a quarter. So it will delay it at least by a quarter.
00:15:43.740 - 00:16:29.764, Speaker A: And that, that is something that should be taken care of that, you know, it might ship worker on to 2026 rather than 2025. Thanks. Let's do Lucas again and then jugan. So from my understanding. So while understand this can be very frustrating, especially for the people working on it, but even if we go from two week transition to four week transition, those additional two weeks are so small in grand scheme of things to everything else that I just, I don't know why we are over stressing on it, right? In my opinion, it's okay. It takes two weeks more. That's not a big deal.
00:16:29.764 - 00:17:20.722, Speaker A: Well, what I'm telling you is that it's not two weeks, it's already two weeks a year ago. So that means it's about, well, okay, if we ship next year, which we won't because of all the extra two forks apparently, or at least if that realizes we're already at three weeks, potentially four, is it going to stay linear? Probably not, because my estimates were linear, and clearly just from data a year ago, the growth is not linear at all. It depends. It depends on what events happen on the chain. There's no guarantee it's going to be one month if we ship by 2026. Thanks, Dragab. I want to say that TOF is one main job.
00:17:20.722 - 00:18:11.608, Speaker A: Basically it's localized to EVM and one or maybe two people to implement. Additionally, there is a big group effort on the testing that's already started, so we are not just starting EOf now. The implementation is back and everything around it, all the in finalized basically state. Thanks Camille. I just wanted to quickly add the perspective from the solid compiler. I mean like for us, like I know, like it's like on the client side it's a different matter. But like for the compiler, UF is like a huge improvement in terms of like implementation.
00:18:11.608 - 00:18:50.284, Speaker A: Time for futurefluegram to deliver, for example, will be. We already have like a lot of workarounds we have like for things we didn't like we had to do before we had like features of the UF. But we'll probably be rewriting those parts of the compiler soon. So in terms of that, like having to write it once on UF would be like a huge boon to us. And also some of the eips that are included, like access to the bigger area of stack would help. Like also in terms of like movements like those stack to the servers that are plaguing users. So overall we're very strongly in favor of having this improv as soon as possible.
00:18:50.284 - 00:20:32.454, Speaker A: Thank you. So I guess from all this discussion with the caveat that I think, yeah, geth obviously on the vertical side is kind of against including it, and it seems like like client is at least more in favor of keeping the pectoral scope as is, it seems like pretty much everyone else thinks that we should do eof before verkle. And then the question is how this relates to the current scope. With some people saying it's better to breaking out in two forks than others saying it's better to have it all in one fork. One thing, I guess one of the risks I see of having everything together in like a single fork now is that it lowers the speed at which we can test stuff across all the client teams because, you know, Nethermind is working on some EIP and then ret is working on another and basically is working like on a third. And it's really hard to get a new Devnet up where we're testing all three against each other because they don't have the same subset of eips ready. I guess my suggestion based on this discussion would be to include eof in the same fork scope as Spectra to signal that we don't want to open up a whole other fork, which would have a bunch of different things in, but then to use Devnets as a way to sequence when should teams have stuff ready implemented.
00:20:32.454 - 00:21:41.926, Speaker A: And this kind of allows us to make sure that we're testing cross client stuff in a gradual way and that we don't end up in a spot where we're waiting three months for everyone to have implemented everything and there's not any cross trial testing going on. And this would probably look like Devnet one is all the stuff we had in Devnet zero with the spec fixes. I'm not sure what, like a definite two would look like if there's like some first set of eof eips that makes sense to bring in and test. And I feel like if we, if we go with it that way, we can also potentially make the decision to like break EOf into a separate, like, activation. Yeah, break eof into like a second activation, like they've decided to potentially do on the El side with peer Das. But we sort of don't have to make this decision now. We can keep moving on the devnet, try to coordinate cross client testing that way.
00:21:41.926 - 00:22:30.604, Speaker A: And then if we see that everything else is literally ready to ship and then EOf still needs a couple months of testing, maybe we decide to. Yeah, maybe we decide to like separate them at that point. And like, yeah, there's two comments in the chat right now that like multiple forks have more risk and have, you know, more overhead. So I agree with that. And this is also why I wouldn't want to like, make that commitment today, but rather like say that it's all part of the same fork by default, use devnets as a way to sequence, like, what we prioritize in terms of testing on the multi client front. And then if we see that, if we see that, you know, like for some reason EOF is going to delay stuff, like for a very long time. We can then make the call to split it out.
00:22:30.604 - 00:22:42.524, Speaker A: I don't know. Yeah. What do people think about something like that? I know there's a couple hands up, but they were up before, so this.
00:22:43.514 - 00:23:29.884, Speaker B: I'm sorry, because the conversation veered while my hand was up. And in the chat I still see discussion of whether we should do this at all. And so I'd like to say just a little, we've been trying to get in what amounts to EOf functions for about seven years now. I showed up seven years now and said, geez, I can pick up my research and within a year or so we could actually have a compiler from EVM bytecode to machine code. And that should help with everyone complaining that the EVM is too slow. EVM is too slow. I kept hearing that when I got here it was known the EVM is broken.
00:23:29.884 - 00:24:22.742, Speaker B: And for seven years we've been trying to do what we needed to do to be able to compile EVM code to machine code in linear time so that we could do it on the blockchain with it not being a denial of service attack surface. And that has been impossible for seven years now. Attempt after attempt to get it in every single time. People come, people go, we explain again why it's necessary. We're told again, it's less important than anything else and it just keeps rolling. And I had wanted to write this thing like before I retired, and at this point I just turned 70. I'd really like to write that compiler before I die.
00:24:22.742 - 00:24:23.794, Speaker B: Okay.
00:24:27.154 - 00:25:31.680, Speaker A: This is Georgios from rest for Redsworth. We have written a JIT compiler for EVM without having EOF, so it's not necessary per se to use the EOF for that. We do know that it makes the code produced more efficient. And two, we do know that EOF removes the need for live jump destination, which is a very expensive operation, which is part of the reason why JIt could not be safe to do. Near the tip would like to echo some of the earlier points that the Ethereum platform also serves its users, which are smart contract developers. The rest team also maintains the foundry project, and we have a very good understanding of what do smart contract developers want and need. And I think somebody wrote in the chat, Ben Adams, that yes, large contract sizes and no out of stack errors are actually indeed one of the most common solid errors, and we really strongly believe that these should be fixed ASAP.
00:25:31.680 - 00:26:00.354, Speaker A: Yes, there might be other ways for fixing them. For example, there was a swap and pen opcode proposal a while ago that didn't come with EOF. Sure. Yes, you could do it. Maybe in other ways, given there is a set of features that you can get, do it at once. I personally think that's a huge benefit. And also Dragon from our team who spoke earlier, he shared the whole document with like ten bullet points for application developers benefiting.
00:26:00.354 - 00:26:38.130, Speaker A: So I guess I'm kind of confused at this point around why we're discussing this. I think most teams have said they like it solidly, has said they liked it. Viper has said there is some, also some extra small things that they need to do. They prefer to do some of the reentry things, but also supportive. Let's just do it. Why are we, it is a bit confusing where we are, where the conversation is that right now, because the chat has been saying we don't mind extending the virtual transition by a couple days. The data says state growth is going down.
00:26:38.130 - 00:27:27.450, Speaker A: So that is the confusing argument in the first place. And you have a bunch of application that's telling you this is a good feature. So yeah, it's just confusing why we're considering not doing it, given that most people have voiced support. Yeah, I think the question is around the pectoral scoping and not around the, you know, what to do about virtual. It's literally, do we do pectoral now? One fork, two forex 24, 25. So should we scope the conversation to that, Tim? Yeah, I guess that's kind of what I was proposing. And I think it's really hard to predict how much work EOF is going to be, how much it will delay things and all of that.
00:27:27.450 - 00:28:45.668, Speaker A: So I think what it seems like everyone wants is to not extend the extra scope significantly beyond potentially adding EOF. Opening up another fork would do that kind of by default. So putting everything in one fork, but then again, using Devnet as a way to coordinate on what we prioritize in terms of implementation work, what are we doing cross client testing on? And then if we find out later in the development process that for some reason EOF is a few months delay that we'd rather not have, and we'd rather ship the rest of Petra, we can make that decision to split it. At that point, I think the biggest risk I see of increasing the fork is just again, one client team is working on a subset of EOF eips while the other one is working on Petra core. And then we literally cannot ship anything before everyone has done everything and we can't even test everything before everyone has done everything and that slows us down. So I think if we have like relatively, like strong prioritization across what we test on Devnet, that would be like a way to manage this team. Is there a world.
00:28:45.668 - 00:29:13.314, Speaker A: Yeah, go ahead. Sorry for interrupting. Is there a world where we do Devnet one stat with either AAP 7702 and all of the stuff that we agreed on the last time? And, you know, maybe we do Devnet two, three the same way, and then around Devnet four, say around whenever it is, we also add eof on it. That. That would be my proposal. Like, I would do Devnet one for sure. Almost like.
00:29:13.314 - 00:29:53.564, Speaker A: Almost like a stretch goal. Yeah, yeah, but yeah, and I think people should start working on it and like we'll keep, you know, adding some static tests for EOF in the meantime. But like, yes, I would not add, I think, like for Devnet one, we have a bunch of stuff that came out of interrupt that we need to test in a multi client setting. I would isolate those changes, get them tested on Devnet one ship that have it be stable, then layer more stuff on top. Yeah. So it seems like CFI in terms of people working on it doesn't mean anything. Yes.
00:29:53.564 - 00:30:23.004, Speaker A: Right now if we did this, so I would propose like, we basically include the whole suite of EOf VIP's if this is. And then if in the future we decide that we need to split it out. Let's do that. But I think by default we'll assume it's all shipping together and. Yeah, again, just think we need to be mindful of how we approach devnets. But the devnet specs are kind of independent from the fork specs. So we already have a way to manage this separately.
00:30:23.004 - 00:30:53.700, Speaker A: So I guess we'd be supportive of that. Yeah. Okay. Any, I guess from the other client teams, basically including it in the fork and then adding it into the Devnets once we've tested everything else. Okay. They sue support. Oh, sorry, merus.
00:30:53.700 - 00:31:23.366, Speaker A: Yeah. As I kind of wrote in the chat, I don't think that's a good argument that no one will start working on it because people have already started working on it and everyone has started working on it. Everyone who needs to work on it has started working on it. Sure. But I think. I don't really care about, but I don't think it's a great argument to say people will only start working on it once it's included because they need to work on. Already working on it.
00:31:23.366 - 00:32:16.050, Speaker A: That's fair. But I do think it's stronger people are saying we want to ship this around Prague. And I think that's what it meant to highlight changing the stuff, whereas there's other stuff in the CFI that we probably won't do or even try to do in Prague. So I think moving it makes it like a bit clearer, if not for us, like, at least for like I think the rest of the community. Yeah. So I guess. But so just to make sure I understand, don't most client teams have yours implemented? And at the risk of being too provocative, are we not discussing whether get should allocate more resources to do it? I thought it was all you needed was one person to spend two months on it.
00:32:16.050 - 00:32:25.434, Speaker A: That's the claim your team is making. Right. So we have one person working on it for over a month now. That should be enough, right? Okay, great. Great. Yeah, sure. That's okay with us.
00:32:25.434 - 00:32:50.004, Speaker A: I think. I also think that's not the productive way to approach the conversation you own, with all due respect. And so I guess I wonder is what that what we're discussing because they implementation matrix that showed which teams have implemented it. I think, you know, testing and DevOps also like making it like a focus on their end. Like, so, yeah, I think, you know, clearly. Exactly. Exactly, exactly.
00:32:50.004 - 00:33:34.784, Speaker A: Okay. Yeah, but like, yes, I think on every client team there's someone who's been working on it and like, I don't suspect this would change, you know, if we include it, like. But like, yeah, it makes it clear, like, what's the full scope? Okay, so to summarize, yeah. What I propose is we include all the EOF, Eips in Prektra, basically the whole list. I'll post the link, but there's like twelve of them. And then we do Devnet one. Like, we don't include them in Devnet one, we do Devnet one, which is just like an iteration on what we had in Devnet zero with like the 7702, which we probably need to discuss after because it's not formally included.
00:33:34.784 - 00:34:02.764, Speaker A: But assuming 7702 is included, we do that. We do the changes that we made to 29, 35. Basically all the fixes coming out of interop. We use that for Devnet one. I think when we're ready to do Devnet two, we decide what else we want to include. But I think having teams all coordinate on. Having teams all coordinate on like, okay, this is the next Devnet that we're targeting.
00:34:02.764 - 00:35:11.240, Speaker A: And this is where we should make sure that things are production ready is probably the most productive way to move forward rather than having these, like. Yeah, 20 ips that people are sort of working on in different capacities. Does that make sense, Barry? And then, yeah, Merris has a comment saying like, yeah, want to make it clear that we can still remove EOF even if it's included. And yeah, I think that's always sort of been true, but so far it seems like people want to actually do it and try it. And then, yeah, once we know how well it's going, we can decide if we want to split it or postpone it or something like that. But yeah, having that be the default path that it would ship altogether in Pektra and it would be minimal delay to confirm. Tim, does this mean that a teams are expected to implement and test the OAuth? B.
00:35:11.240 - 00:35:59.744, Speaker A: The EF testing team will be expected to start shipping or allocating actively resources on the EOF testing and we should be able to start pinging them and maybe even help them shoot this more because we've been doing that already. And I wonder like if now that's considered priority and we should go ham on it. Yes. And then the one caveat is like, yeah, for cross client testing stuff. Yeah, we probably don't want to do. Yeah, for cross client testing stuff, we probably don't want to prioritize the of right now until we have like just implementations that are further along for both EOF in single clients and then the rest of spectra in a multi client context. Just rebelling on this.
00:35:59.744 - 00:37:04.264, Speaker A: Isn't that what the testing team is doing right now, working on the oauth? That was my understanding, yeah. I'm just confirming the case for everybody's context and I guess, yeah. Mario, from testing, you want to give your thoughts? Yeah, so yeah, we've been working on including UF tests into the execution spec tests for the past month. And in the last couple of weeks we have really good progress. I think if we keep up this way, I think we should be able to fully cover, I wouldn't say in less than a month, but I would say like maybe two months we will have full and confident coverage in execution spec tests. The great thing about how we have been working now is that we have this isolation between UF and the rest of the Prague Eips. But it is really easy to just join uf into the full Prague test set when time comes.
00:37:04.264 - 00:38:12.972, Speaker A: So now we have this releasing pre release schedule. We have not done a pre release for Uf now, but we will do in the, maybe this week or early next week we'll have the first EOF only pre release and it's really easy for us to do so. So we have been working really hard on the framework to make these things easier to have features, and in this case, you have feature release only for tests. So we will try to make these announcements a little bit more clear in the future, and we will have the test sets ready for you guys to consume. Okay. POTUS. Yeah, I don't have any take on EOf at all, but I just wanted to mention that I haven't seen any studies when people propose to include this or include that in a fork.
00:38:12.972 - 00:39:09.544, Speaker A: I haven't seen any report on how are these features testable in an independent fashion from the other ones that are already being tested and are already being considered for inclusion. The issue being that adding a feature, even if it's being already worked out, the testing is not linear with the number of features, it's quadratic. Every feature that you add, if it cannot be tested independently, it needs to be tested against every of the other features in an independent function from the remaining ones. And I think this has to be taken into account. It doesn't seem to me that people are considering the amount of testing and the complexity of testing and how it increases with any feature that is added to a portion, not against. I'm just asking whether or not this has been worked out, if there's a report of this can be tested independent of that and so forth. Yeah, I guess.
00:39:09.544 - 00:39:55.524, Speaker A: Do any of the EOF for testing people have a perspective on that? Yeah, that's also been the point that I brought up in the Ethpanda ops document as one of our concerns. Even just looking at all the CL eips, there's a lot of them that have interactions between eips that we don't even know what parts to exactly test. And yeah, I think adding more and more is just going to make it even more complicated. But, yeah, I do agree that at least the benefit of EOF is that you can test it quite a lot in isolation. While that won't be true for most of the Cleips. Thanks. And Charles, your hand has been up for quite a while.
00:39:55.524 - 00:40:43.594, Speaker A: Yeah. Just wanted to reiterate Viper's position, which is that I don't think that UF is that urgent. I mean, like to see it, and obviously I've been contributing, but eips for preventing reentrancy are more important for users. I think, from a prioritization perspective, because users are trained. Sorry, smart contract developers are trained not to have non reentrancy protection. Sorry, reentrancy protection because of the gas cost and if it's cheaper then people will use it more. Whereas Uf, you know, has some performance improvements and quality of life improvements.
00:40:43.594 - 00:41:27.426, Speaker A: It would be great to. So as far as I feel from solidity, they like EOF, but they also not been very pushy about it. So I don't know. If compiler teams are not really pushing for it because they need it and they need it done yesterday, then I don't really see the urgency to it. For compiler teams, EOF has a lot of quality of life features. I don't think you need EOF to prevent stack two deep. Vapor doesn't have stack two deep.
00:41:27.426 - 00:42:26.964, Speaker A: Like I said, it does have quality of life improvements. It improves performance. But from my perspective, preventing reenginecy is like a huge massive security hole or whatever you want to call it, foot gun for users. And EIP 7609 is small, you know, and it would let us prevent it at the application level a lot more cheaply and easily, I guess. Yeah, from my perspective just it seems like on the client side like everyone or there's like pretty broad consensus around EOF and yeah, it's not clear to me how much support there would be for something like that. And I think what's also pretty clear is if we do move forward with EOF, there's very little benefits to do anything else. It would already be the largest support by far.
00:42:26.964 - 00:42:47.404, Speaker A: Yeah, I don't know. Lucas Trigan, is this what you want to. Yeah. So this is about EAP 7609 a bit. So we would be also. For the CIP, though I think it needs a bit more analysis. From El developer perspective.
00:42:47.404 - 00:43:32.508, Speaker A: We want to run some benchmarks on it, basically. We also provided some feedback about decreasing the cost a bit less. So increasing the cost that was initially offered. And we also think potentially warmed s loads could also be decreased in price. But yeah, I think it needs a bit more analysis and like benchmarks being run actual numbers before we can fully commit to it. But it is a very small because this is gas repricing basically, so could also be. I don't think it's exclusive to UOF.
00:43:32.508 - 00:44:17.194, Speaker A: We can also think about including it either in Pectra or the next fork after Pektra. Yeah, that's basically my comment on the cipher. Yeah, I'm happy to like incorporate feedback, like fiddle with the pricing schedule a little bit. There's some more benchmarks that I want to run. Unfortunately, I've been very busy with other things and any help with benchmarks is actually really appreciated. But yeah, I mean, I'm happy to fiddle with it more, but I think the thing I want to see is whether it gets in the large. Can we talk about the details later? Thanks Jogan.
00:44:17.194 - 00:45:22.904, Speaker A: Yeah, I would like to say that I think this meeting is really good example why asset communication is very important. Because when I joined this meeting, I was assuming that we are talking about if we're going to have one fork or two forks, to be honest. And now basically from few people from the call, they are shifting discussion if the solidity doesn't matter or not, if the UF needs to come before workload, we've kind of hitting diminishing returns with this conversation and there's a bunch of other stuff on the agenda we're probably going to have to kick out. So yeah, unless there's any strong objection now, I would move forward with including EOF and Pectra. Again, this is the entire list of vip's. They're all listed in 7692. And then yeah, scoping Devnet one, which we can do, we can finalize async to not include EOF to include the other picture eips to make sure we get cross client testing on that.
00:45:22.904 - 00:46:22.196, Speaker A: I think this will help everyone prioritize multi client testing for everything non EOF. Keep working on static testing for EOF and then we can see what the best scope for future Devnets after Devnet one is. So yeah, I guess, yeah. Does this make sense? Okay then next up, I think the, probably the second most important Petra decision to make on this call is 7702. So we talked about replacing 3074 with that EIP. It seems like there's broad support to do that and then there's still some spec issues around 7702. So we discussed them on a breakout call yesterday, but didn't quite get to like a final conclusion on them.
00:46:22.196 - 00:47:07.684, Speaker A: But in short, there's some concerns around just how we handle revocability. I know Andrew, you posted about them on the agenda for today. Do you want to take a minute to just walk through this? Hopefully Andrew's here. Otherwise I take Sudeep from Aragon. You were on the call yesterday. Yeah. So I think it's about we feel strongly that we should have in protocol revocation and that it should not be optional, which is what is there in the current version of 7702.
00:47:07.684 - 00:48:18.384, Speaker A: It should be a mandatory feature and we are sort of exploring ways to have that revocability, mandatory revocability while also providing the work providers of enough breathing room to innovate and it not being too constraining. So I think maybe this week and over the next week we will be coming up with solutions to that. We also decided that if there are no good solutions that we can agree on, then we sort of moved ahead with the version of 7702 which is pointed out in light clients pr. Thank you. We can't hear you if you're talking. Can you hear me? Lightly? But yes. Okay.
00:48:18.384 - 00:48:52.814, Speaker A: Okay. Now it's good. It's okay. Yeah, yeah, yeah, yeah. I was just curious to do if you had a perspective on what the difference with the 7702 proposal on revocability is versus what is specced for 3074 and was accepted in Petra right now. 3074. I think it had the same problems and the problem of revocability was solved there.
00:48:52.814 - 00:49:33.012, Speaker A: Right. But we accepted 3074 into pectra with this property. And Andrew even came out and said that he was very supportive of 3074 now that we have a way of having in protocol revocation, even if it was sort of optional, depending on what nonce you chose. So it just doesn't really quite see what is different about the 7702 proposal versus what we seem to agree on with 3074. This is kind of why this was put into 7702 because we were under the impression that this already addressed the concerns from client teams. Right. I think.
00:49:33.012 - 00:50:30.138, Speaker A: I think the scenario is about changing the. Changing the smart wallet and like their existing previous authorizations, which can still be used. I think that's the major scenario that I'm concerned about. And so, yeah, I think we should have a way to. For the user to kind of revoke that which is baked in protocol and does not rely on trust on wallet providers. Is that not what is in 7702 right now? Like we have an in protocol revocation mechanism in 7702 for this exact purpose, but it is optional binance that is optional. And it was also optional in 3074.
00:50:30.138 - 00:51:14.174, Speaker A: And we have to rely on wallets to use some of these optional things. Like we rely on them to use the optional chain id that exists in transaction types to avoid cross chain availability. Yeah, but yeah, that's the scenario that I'm concerned about. And, you know, if that, that gets answered sufficiently, if we trust, like the. If there's a good mechanism to do that in the proxy contract, like, I think that was just by you. So I think, yeah, I'm willing to change my mind on that. So yeah, maybe I do need a few days on that.
00:51:14.174 - 00:52:03.940, Speaker A: Thanks. Yep. So I'm adding, you mentioned proxy contract, but like lite client said, the revocation is in protocol if the nonce is like specified. So like, why in the proxy contract do we need to look into it? It's like in protocol, like how you were asking. I think lifelines just had a way to kind of revoke things in the proxy contract level. So that's what I'm referring to. Yeah, it's.
00:52:03.940 - 00:52:41.764, Speaker A: Yeah, it's. But no, like that. That was how it was in 3074, but how it is in 7702 is that it's in protocol level. Not even on proxy level. So even better. Yeah, that's what I'm willing to kind of change my mind. Like, I was coming from a position where, you know, it should be mandatory and it should be at a protocol level and maybe I was not okay with having it in, you know, kind of trust these smart wallet providers for that.
00:52:41.764 - 00:53:34.092, Speaker A: But I think, yeah, like, like I said, I'm open to kind of the change in perspective, especially after like reading like, clients just so, yeah, I think I need a bit more time on that. Yeah, I just wanted to say that kind of the 7702 authors have also kind of brainstormed a little bit on potential kind of solutions for this. And it does seem in general that indeed, I mean, many people have been unhappy with this general property of 7.702 that you kind of have these signatures that are floating around and can be used in unexpected moments at any time, basically. And. Well, I think the Aragon team right now is the only team that actually would have this be a blocker for them. I think a lot of people share that general uneasiness.
00:53:34.092 - 00:54:36.446, Speaker A: And so in principle it would be preferable to find a mechanism where you basically have a more permanent way to store the currently active delegation target for an account on chain and then basically have specific operations that ideally also signed over the count nonce, that basically bump that delegation target to a different delegation target. There are actually several ideas how to do this. So for example, you could basically either do it, I think the most elegant way, at least in my opinion, would be to just basically use some sort of special UF version, just temporarily until we get to work. And we could have it more natively stored as an extra account field or something and basically slightly change the way 7720 interest work. So that basically have two different versions. One of them changes the delegation target and assigned over specific nons, and then you just have a flag of like, hey, this account is supposed to have delegation active for this, bring this transaction that would not have to come with the signature at all. So the only problem is that in terms of Prague, we are already like relatively late in the pork process.
00:54:36.446 - 00:56:03.354, Speaker A: Of course, this will take a little bit more time to figure out. And so, yeah, I already said that earlier and chat, like, if we end up kind of having some sort of smaller scope of packtra that is registered early and we're thinking about what to split out. To me, basically, it would be worth taking like two extra months, two, three extra months, making sure we have the best possible version of 7702, because it does seem like there is a scope here that would basically make everyone happy. So I guess given that, and I think, yeah, people generally want 7702 and we had included 3074 in the past, I'd kind of do something similar to what we did with EOF. So I would include it in the fork and maybe not have it part of Devnet one or even Devnet two. Like, we're not quite happy with where the spec is and then spend the next month or two, like two months feels like it's probably too long, but say, like the next month, actually ironing out the spec so that we have like, a revocation mechanism that's potentially better than what's proposed now, it doesn't seem like a huge EIp to add a bit later in the process. Like, you know, let's say Devnet three or whatever, if even if we change nothing, but then this saves client having to implement different versions of it if we feel there's a high likelihood it's going to change.
00:56:03.354 - 00:56:41.786, Speaker A: So would that make sense, people? George Ross, quick question. So if Devnet Zero spec was what we did in Kenya, and if we don't do 7702, then Devnet one spec diff from Devnet Zero would be just the eap to nine through five changes. Yeah. Removing 3074, 29, 35 changes. I feel like there was something else. And I know Mikael has a bunch of small changes he wanted to cover as well, so maybe some of those. Ah, right.
00:56:41.786 - 00:57:24.816, Speaker A: But, but, yeah, so, like, high level. Yeah, high level. We would remove 3074 from the Devnet and potentially not have 7702 and then basically spec changes on, like, everything that's already there. Yeah. So does this make sense to people, including 37? And so I think, like, Richard asks a good question, was it already format and decided to place sort of. So, yes, based on what you just said, maybe worse. So, like, last call, we basically removed 3074 because we knew we would not do that given that 7702 was still being like.
00:57:24.816 - 00:57:51.104, Speaker A: Was like a better alternative. So I think there was broad consensus that, like, we'd rather do 7702 than 3074. The reason we didn't include it on. The last call was because we saw there were still some spec issues. I think there still are today. But like, if we are kind of trying to finalize the scope in terms of what eips will be worked and iterated on, I think it makes sense to include it, but then, yeah. Not have it as part of the debt in the same way we're holding off on EOF.
00:57:51.104 - 00:58:37.104, Speaker A: So that, yeah, so that we don't get clients like, re implementing different versions of the EIP if we can avoid it. I think this does mean, though, like, I guess this does mean that the 7702 people and, like, account attraction people like, need to make this a priority in the next month or so to. Yeah, and I guess, yeah, look, like client said, you know, we can consider putting it in the next. In the next Devnet too. Like, if we feel we learn more by implementing it as is than we do by like, than like, the time we save by not implementing it. Like, I don't have a strong opinion there, but we should just be mindful that we're likely gonna put something in and tweak it. So.
00:58:37.104 - 00:59:16.192, Speaker A: So I guess to start, like, anyone against having it in the fork, regardless of which Devnet it lands in, if not. Yeah. Anyone against having it in the Devnet one spec, even though. Even though it'll likely change based on iterations. Okay. And then Ansgar said that, like, you know, any final version would probably share most of the logic, so probably minimal changes. So.
00:59:16.192 - 01:00:11.304, Speaker A: Okay, let's move forward with 7702 in the fork added to the Devnet one scope. So Devnet one would basically be effectively everything that was already included, plus 7702 -3074 which are already removed. And then EOF is not included in Devnet one. And then. Yeah, I think probably the next most important thing is to go over these spec issues that Mikael brought up, unless there's anything else left on 7702 people wanted to discuss. Okay, in that case, yeah, Mikael, hopefully you're still on, I guess, in the order that you've put them. But the first one was the execution API PR.
01:00:11.304 - 01:00:57.178, Speaker A: Yeah, thanks, Tim. I'll just briefly go through all of them. If anyone has any comments, raise your hand or just drop me. So the first one was the Yale triggered request as a sidecar. So during the last week we've been exploring the idea of processing the el triggered requests like withdrawals, deposits and consolidations, potentially as a sidecar to the execution payload. So basically it means that they're not a part of the execution payload. But the execution layer returns them in the get payload method call.
01:00:57.178 - 01:02:08.604, Speaker A: So Cl can take them and incorporate them into the beacon block body and keep them in a beacon block body and then can send them to Yale via new payload method to validate them. This idea was. This idea is appealing because the consumer of those requests is Cl. So let's just keep this data on the Cl side and you will not have to do all this work related to storing them in the block. And, yeah, and some validation can be omitted. So it's kind of like an alternative to 7685 EIP, which is general purpose Yale request EIP. And yeah, after a few iterations on that, we conclude that the original design kind of breaking the optimistic sync in one of the edge cases, and to avoid breaking the optimistic sync, we would have to keep at least requests root in the execution payload header, in the execution block header.
01:02:08.604 - 01:03:11.264, Speaker A: So the commitment to those requests needs to be kept on the Yale side. And it creates a cross layer complexity where you have data on one on Cl side, you have the commitment on the El side, and you have to verify that the data actually matches the commitment. And yeah, there is a discussion thread in this, in this pr. So the conclusion, the final conclusion is that with, after iterating on this, it seems to be really quite marginal benefit that this proposal brings. And the engineering complexity kind of, in my opinion, personal opinion, outweighs the benefits. So I tend to, personally, I tend to leave everything as is with 7685 and move forward. Just wanted to bring this up because we brought this up during the previous call.
01:03:11.264 - 01:04:10.240, Speaker A: And yeah, this is kind of an update on this stuff. Next is El Consolidations back. Can I quickly comment Misha on that? Yep, sure. In particular, I mean, it's not that it's a killer, but I would be against and strongly against any commitment for get payload to return something that needs to be included in the beacon block. Because I would want to have, I mean, it's public that I'm strongly advocating for epbs, and I want to have that separation of concerns being kept so that the beacon block should not be contingent to the payload already being present anything. So withdrawals, deposits, whatever it is. I do not want to have the beacon block depending on something that the payload needs to have.
01:04:10.240 - 01:04:36.116, Speaker A: Because this breaks the flow of epbs. Right. And it does not break. It doesn't break with the blobs and KCG commitments as of today. Well, it is more or less the same situation. It requires that then the builder needs to send the block KCG commitments in the bid. So that's why it's not a killer.
01:04:36.116 - 01:04:57.246, Speaker A: But whatever. Whenever you break this separation of concerns that the payload needs to include something so that the beacon bloat includes. It includes it, then that thing will have to go on the bid and it makes the bidding process more complicated. So. Yeah, yeah. Thanks for sharing this. Yeah.
01:04:57.246 - 01:05:20.794, Speaker A: Okay, well, okay, so closing this pr. Yeah. Okay. Okay, cool. Next one is like the El consolidation. Yeah, El consolidation spec. We had been working on the El triggered smart contract, the system smart contract during the interop.
01:05:20.794 - 01:06:07.604, Speaker A: We have this smart contract finished. Need to write some tests. As a follow up to this smart contract. There is a pr to the EIP 7251 which is the max effective balance increase which introduces the ultra grade consolidations. And it has the spec now it has the smart contract code. There is the transaction to deploy the smart contract and also there is the corresponding change to the engine API which introduces consolidations. It would be great to get some early feedback on these two prs before basically we merge them.
01:06:07.604 - 01:07:19.588, Speaker A: Also, ideally we have this in Devnet one, but it would be great if someone can check the, that this transaction actually deploys the code. And yeah, I'm kind of, I did not do this check and yeah, I need some help here. Many thanks to lightclient who, who has worked on these, on the similar stuff for 7002. And yeah, the spec and the smart contract basically leverage on his work pretty much. Okay, so the next one is the align withdrawal request with one with the IP and consensus pack. There is the, this, this PR is about renaming it renames the validator public key to the validator pub key as it is in the, as it is, yeah, this changed to the engine API. So the engine API uses this long validator public key name while the EIP and consensus spec uses validator pubkey.
01:07:19.588 - 01:07:59.958, Speaker A: And I think that this, as far as I can see in the comment dazzle has implemented it as well there pub key and engine API. So I think that this discrepancy will bite us here and there. And it is better to do the renaming and align the names everywhere in all the spec documents. The problem is that basically the El and CL has to do adjustment on their sides. So it would be great to have this PR merged soon. So please take a look, raise your concerns. But I think we just merge it and have it for Devnet one.
01:07:59.958 - 01:09:03.963, Speaker A: Probably also it needs to be taken into account for hive tests that, yeah, that needs to incorporate these changes. Okay. And the last thing is the slight discussion around engine get payload bodies requests. We are extending payload bodies by deposits, withdrawals and consolidations now. And the question is, actually we already have these methods, version two of this, of the payload by this method in the engine API spec. And Sean actually came with an idea that we could extend the v one data structure and extend, actually we want methods, and in this particular case it can work because it's backwards and forwards compatible. But I don't know if you want to do this.
01:09:03.963 - 01:09:49.554, Speaker A: From the spec perspective and probably from testing perspective, it is cleaner to introduce v two, but from the execution layer, client perspective, it's probably easier to keep one and just extend it instead of introducing a couple of new methods and do some plumbing. So it would be just great to have more, to see more comments in these, in this pr that introduces v two. And yeah, so we can make the right decision. And ideally, also if we, if we want to change, if we want to switch back to v one and just extend them. So ideally we can do it before net one. Yeah, that's pretty much all I had for today. Thank you.
01:09:49.554 - 01:10:29.894, Speaker A: Thank you. I guess my proposal for all of these. So like the first priority, the one that had issues with epbs, we closed that one, but then for the three other ones, one of them, I guess has already merged. So by default, I guess we would include it. But then the El consolidation one I would lean towards. We include it in Devnet one tentatively, and over the next week or so people can review. And then ideally we merge it before ACDC next week so that it's clear by then that, you know, this merged pr is included.
01:10:29.894 - 01:10:55.754, Speaker A: Does this make sense for everyone? Okay, no objections. Um. Oh, sorry, there's a message. I was just saying we didn't really test consolidations in Devnet zero, so be prepared for this to bring up some more bugs. But generally, yeah, I think this is the plan to move to Yale consolidations. So I think what you said makes sense. Sweet.
01:10:55.754 - 01:12:01.056, Speaker A: Okay, last agenda. Ilham around potentially pectora, but potentially another fork. So, Guillaume, you had posted around deactivating EIP 158 because of some potential interactions with Verkle. Yeah, if you want to give some context on that. Yeah, I mean, the general idea is that from what I gather, AIP 158 was a temporary measure that was meant to avoid some use case that has to do with the Schengen attack. To date, this turn off event cannot really happen. And now with 7702, we have the problem that you can again find some contracts that would be with an empty non, with an empty code hash.
01:12:01.056 - 01:12:37.578, Speaker A: Sorry, not contracts. Precisely. Eoas. You would find eoas that have an empty nons that have zero balance, that would have an empty code hash and they would therefore have to be deleted. With Eip 158, the problem is that these eras, because of 7702 would have state would have storage and that storage would have to be deleted. Except with verkle you can't. This is one of the reasons why we disable self destruct.
01:12:37.578 - 01:13:51.744, Speaker A: And I would argue we should treat EIP 158 exactly like we treat self destruct, namely that if you start creating an account and immediately delete it, or gets that, then gets deleted by EIP 158 in the same transaction, then it should be removed or not make it to the state. But once it's made it to the state, it should remain there. Yeah, otherwise we will find ourselves with dangling, well, potentially dangling storage storage slots in the tree, which might have some negative impact at a later stage, which is, I'm trying to remember there was an EIP push by Gary that was about deleting. It was not about deleting the storage, but we resolved it by saying during the vertical conversion we will delete those storage slots. 7610. Thank you. And yeah, we would find a new, with 7702 we open up a new way to produce, to produce this kind of situation.
01:13:51.744 - 01:15:00.274, Speaker A: So if we disable, if we disable s store in 7702, we could somehow avoid this problem. But I still think from a purely correctness point of view, EIP 158 should have the exact same behavior as self destruct. And yeah, that's the gist of the argument. I'm just wondering if there are counters to that. I guess one question, or the comment by Ansgar is depending on how we change 7702, these accounts might not have a nonce of zero. Would that be like assuming that 7702 incremented the nonce? Would this make this change obsolete, or would we still need it for some other reason? I would argue we still need it, but at least from a coherence between the behavior of self destruct and the current 158. But yes, we discussed that was actually the first idea, to increase the nons.
01:15:00.274 - 01:15:44.654, Speaker A: We had the conversation with several people in the guest team, and it appeared that was going to be fairly tricky to do when there's no reason to keep 158 around. So that was the argument. It's the simpler approach. But yes, we could potentially, if we managed to increase the nonce exactly when we need it, that would be a possible way to circumvent this problem as well. Got it. I guess there's a comment on Dragon saying it would be nice to have this discussion async so we can, like, understand the issue better. So I guess my proposal would be if we can have like an EIP or proto EIP for this.
01:15:44.654 - 01:16:16.708, Speaker A: Yeah, that's probably like a better way to anchor the discussion. Yeah, I mean, that would be the point. But I'm also trying to get some early feedback before I spend time writing the AIT, the VIP. I saw a comment. I'm on mobile, so I don't really have all the comments, but I saw a quick comment by Luke Wukash. No, it cannot be activated at the same time as Roko. It has to be activated at the same time as EIP 7702.
01:16:16.708 - 01:16:35.040, Speaker A: Otherwise we would have. Well, or we decide to delete all the storage slots during the conversion as well. But the problem is that more accounts, more empty accounts will find themselves with storage. And that's. Yeah, that's, that's the risk, actually. Wait. No, because then you could be.
01:16:35.040 - 01:17:10.364, Speaker A: You would be able to delete them. Okay. Yeah, I guess it can be deleted, activated at the same time, but, yeah, so I guess it seems like there's like, you know, no objection or like, no. Like, it generally seems like a good idea at this point. Back out. Any other comments or thoughts? Okay, thanks, yom. Next up, I believe we had Piper to talk about four fours and portal.
01:17:10.364 - 01:17:45.046, Speaker A: Are you still on, Piper? I am. Hello, everybody. All right, so we had our summit. We've discussed what El client integration looks like. We looked at our last client to join the network. I'm curious if we hear from EL teams, possibly individually, on what y'all's stances on four four s on this. Our last client that entered the network took six months to implement our spec.
01:17:45.046 - 01:18:53.114, Speaker A: They did that without really asking us for any support. They read our implementations, they read our specs, they implemented our cross client tests, and it took them about six months to implement history network. I think that that timeline can be sped up, especially with support and help and guidance. So we think that if this is a priority for EL teams, that if EL teams are able to get started on four four's integration in the next roughly two months, that it is very reasonable to have some of those teams be done by DeFCOn and those that aren't done to have really significant, meaningful progress done and delivery, ideally, probably by the end of the year. This is an effort that the portal teams are absolutely here to support. And if El teams are interested in running with this, we're here for it. So I'd be curious to hear from any El teams that have opinions on this, whether this is something that you'd like to do.
01:18:53.114 - 01:19:25.054, Speaker A: Yeah, that's the gist of it. Thank you. There's a question by Perry. Yeah. If the security has had time to look at portal, is the implementation audited or reviewed or just like. Yeah. What's the general security status? To the best of my knowledge, no, I'm not aware of any security teams that have looked at or audited portal.
01:19:25.054 - 01:20:30.050, Speaker A: And then. Yeah. Comment by Anskar around seems like every client team can decide whether they want to bundle it with their main client. Yes, I think that the recommendation would be that clients implement their own client to the network, but bundling an existing one is absolutely an option. And I don't know, this is a conversation I'd be happy to have with any client team who's trying to decide which path they want to take. I don't think it's a decision that we can, you know, it's not a decision that I can make for them or anything like that. Any other questions, comments? And I guess, is the history expiry channel on the R and D discord still the best place to chat about this stuff? Yes, the history expiry channel.
01:20:30.050 - 01:21:36.824, Speaker A: We're monitoring it actively. If people have questions, we will be there for it. I think the timeline for delivering this this year runs out in about a month and a half to two months. That's about the timeline where if we were going to ship this by the end of the year, it would be good for client teams to get started in that timeline. And similarly, we'll all be together in person for Devcon later this year. And if client teams get started and get working on this, that sets us up to have a very impactful and kind of like meaningful in person event around portal at Devcon within that timeline. Anything else on the portal can El teams report on where they're at with this? I've gotten a lot of silence in these questions, and I'm curious to hear back from El teams whether this is a priority for them, because if it's not, I can anyways, I'm curious to hear the answer to that question.
01:21:36.824 - 01:22:22.060, Speaker A: Overall, it is a priority. We had a meeting yesterday with portal team. The problem is that there are so many priorities, it's sometimes hard to juggle everything correctly. So it's the less urgent priority compared to, for example, the hard fork. Right? But yeah, never mind. We'll be working on it and we will prioritize it. It's a similar answer from the Bezer team with Geith, I don't think we discussed it yet.
01:22:22.060 - 01:22:58.804, Speaker A: So currently it's not a priority. If it makes sense, we're happy to revise that, but, yeah, we haven't really looked into this yet. Cool. Any teams who are interested in scheduling a meeting or talking about this more asking questions? We're here for that. Thanks, guys. Thank you. Okay, well, I think we made it through all the technical stuff on the agenda.
01:22:58.804 - 01:24:27.334, Speaker A: So I had, I had a doc that I shared on the agenda as well. So we had some conversations at interop, and I've been having these similar conversations with many of you for much longer time around. Ways we can, like, tweak the core dev process and use Ethereum magicians better to make things more efficient. I think, yeah, there was a bunch of proposals in there, but, like, I think maybe the two that are most important or like that. Yeah, would be good to have live feedback on are one, this idea of having EIP review requests. So I think it's come up a lot that when people present eips on awkwardevs, most folks don't have, like, context on them, and then it can be kind of a like, yeah, low value discussion because people have not gotten up to speed. So one tweak that came up was the idea that when people put eips on the agenda for the first time, instead of having a long live conversation about them, we just bring up the concept, does anyone want to review these async before the next call? So people basically get two weeks to look into it, and then we sort of default to only discussing something live on the call.
01:24:27.334 - 01:25:45.406, Speaker A: If there's been a review request made before, I guess I'll pause here. Does anyone have an objection to that? Okay, if there are no objections. Yeah, if there are no objections to like this, I think we can give it a try and see how it goes. It's a pretty easy thing to switch back. The second one's probably the most impactful, and you might not make a decision on this today. So people, when I asked people whether they thought the CFI status was useful, people said generally yes, but it's hard to figure out what it means, and it's hard to see what's all the eips that are proposed, what are the CFI ones, and then which ones are actually confirmed for the fork? As we were discussing just earlier around EOF, even when we include something in the fork, there's always a chance that we take it out. Um, so one proposal I had to make this all kind of more legible.
01:25:45.406 - 01:26:36.966, Speaker A: Is, um, adding uh, a status before CFI that's proposed for inclusion. And this would be like the canonical way someone could propose an Eip for a hard fork. And what they do is just, uh, open a Pr against a meta eIp and add their eIp in the list under like a PFI section. Right now it's kind of weird where like on eth magicians, people sort of propose them, to propose them on the Alcor devs agendas. And there's like the EtH magicians thread and some GitHub issue in the CL specs report that like tracks the proposed eips. And it's just kind of a weird, you know, hard to find resource that, like, is effectively like, yeah, like, not like lives kind of separately from all of the other information around, around the fork. So yeah, this would just add a section to the hard fork.
01:26:36.966 - 01:27:30.930, Speaker A: If you want to propose an EIP for the next hard fork, you open a printer, this gets merged in CFI basically remains as it is today. If we want to formalize it some more, like, there were some ideas around, there were some ideas around. As soon as a single client team would like this to maybe be in the fork, we CFI it. Or as soon as two client teams bring it up, we cfi it. So, and to Ansgar's comment, cfiing earlier in the process to like, give the signal to people like, okay, this is the subset we're actually considering. And then what I would also suggest is we rename included to scheduled for inclusion, which kind of conveys a bit more that, you know, the default path is we're gonna ship this. But as always, if we find some security issues or some blocker, we, you know, we reserve the right to take it out.
01:27:30.930 - 01:28:04.458, Speaker A: And then once the EI, once the hard fork ships and we move the Eip to final, we currently clear all the CFI stuff from the meta Eip. So what we would do is clear the proposed, clear the CFI, and maybe rename scheduled for inclusion to included, which kind of denotes that it's actually live and on the network. So now we only have three minutes. I'll pause here. Any thoughts, comments? And I guess, yeah, one last thing. I would not do this for Pektra. Like, I think it's pretty far in the process to change things.
01:28:04.458 - 01:28:48.556, Speaker A: So this would be for the next fork and onwards. Okay. If there's no objections on the call, then what I'll do, I'll open a pr to formalize all of this and get some feedback on that, and we can discuss it later. It's not a super time critical thing. And yes, I guess, yeah. Before we wrap up, there is a breakout on peer Das and a breakout on epbs next week or, sorry, the epbs one is tomorrow and the peer das one is next week. I'll post both issues in the chat.
01:28:48.556 - 01:29:18.834, Speaker A: And then lastly with like two minutes, there was something by the testing team around comms channels with client teams. I don't know if someone from the. Yeah, yeah. So yeah, basically the proposal is to. We have as it is right now, the R and D discord server. It has like testing channels all over the place. There are several places where one has to go to obtain different information for testing.
01:29:18.834 - 01:30:10.234, Speaker A: So we are proposing now that we create a new subgroup channel, just the way that we have like Pectra, sharding cross layer and so on. We will have a new subgroup called testing, which could be the new way, should be the new way that one gets their testing release information and all the testing related discussion happens. So this will be like the one stop for the client apps to go and to check testing information. We have a link in the agenda that you can go into and take a look. If you have concerns about this change, please just raise your voice and we will try to make it better. But yeah, if no one opposes, I think we could go live with this soon. But yeah, thanks.
01:30:10.234 - 01:30:42.954, Speaker A: I know we're at time. Any quick comments otherwise? Yeah, otherwise. Mario, do you want to maybe post this link in the Alcor dev chat so people can comment on there? But if there's no objection and some support, then we can make this change in the next week or so. Yeah, absolutely. I will send the link right now. Awesome. Thank you.
01:30:42.954 - 01:31:05.394, Speaker A: Anything else before we wrap up? Okay, well, yeah, thanks, everyone. I can't believe we got through the entire agenda. Yeah. See you all tomorrow on the epvs breakout. And please check the PM repo for all the other breakouts in the next week or so. Yeah. Talk to you all soon.
01:31:05.394 - 01:31:10.914, Speaker A: Thank you. Thanks. Thank you. Thank you.

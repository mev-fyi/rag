00:00:40.340 - 00:00:43.800, Speaker A: You okay?
00:00:43.870 - 00:01:03.210, Speaker B: I think we can get started. Welcome to virtual implementers, call number ten. This is issue nine 30 in the pm repo, starting off with client team updates. Would anyone like to start?
00:01:05.300 - 00:01:06.050, Speaker A: You?
00:01:07.300 - 00:01:42.568, Speaker C: I can start. This will be the first update from the tech team here. So the good news is that the work is in progress finally. It's been a while now. I was expecting to have a faster update on our branch, but seems like it's getting a little bit slower than expected. But the work is ongoing and hopefully soon we will join a devnet. Don't currently know when.
00:01:42.568 - 00:01:56.450, Speaker C: At the moment I'm not directly involved in it. I'm reaching Dimitri who is working on it. Once I got some kind of feeling from him, I will share with you. That's us.
00:02:12.220 - 00:02:14.090, Speaker B: Thank you. Anyone else?
00:02:17.020 - 00:03:04.308, Speaker A: I guess I can go next, right? So there was the holidays, so not as much progress as hoped, but nonetheless, Perry and I worked on the shadow fork. There's a lot of issues that got fixed and yeah, I'm currently fighting with one. I hope it's the last one. And otherwise. Yeah, we're going to prepare an update to relaunch Kelstinen. So we'll talk about this as part of the main agenda. I guess there's been some work on the tooling to help the test team, but I need to sync up with them and otherwise there were some updates needed to the EIP, to two EIPs.
00:03:04.308 - 00:03:25.070, Speaker A: The one with the state verification contract and the other one is the gas cost, the thing we discussed last time. So both of them need to be updated and yeah, that's all for me. Inesio, do you have anything to.
00:03:26.980 - 00:03:27.730, Speaker D: No.
00:03:34.180 - 00:04:17.516, Speaker E: Yeah, I think I can go next. So I majorly focus since a lot of people are on holidays and we are not relaunching the testnet. So we majorly focus on correcting small issues that were there with another client implementation. So now Netherland client can basically produce blocks with proofs on the vocal testnet. And the stateless node is also working properly. And the major thing is that I was also able to test vocal sync and the ranges sync part works quite okay. Like I created multiple testnet using katosis and tried on multiple locations and it works every time.
00:04:17.516 - 00:04:32.150, Speaker E: I was not able to test the healing part because the testnet was not big enough to actually reach the healing phase. I'm just trying out different tricks to test the healing part. But yeah, the range of sync part is working perfectly. So yeah, that's it from my side.
00:04:39.920 - 00:05:34.460, Speaker F: Okay, I can go next for Arigon I've been able to sync up to a certain block 7196. I think after that there are some self destruct opcodes that it's not really matching up with the worker route so I have been stuck on it. It seems like there may have been a code misconfiguration compared to get so I would probably try to replicate that misconfiguration in Aragon to try to sync to the tip or I'll just wait for the next set of changes to disable self destruct following from a short conversation on the Testnet group on element with Guillaume.
00:05:41.530 - 00:06:32.070, Speaker G: Okay, I think I can go next. So as far for the Nimbus client, we were working on the Virkil tree repository. All of the workal cryptography is finished and thanks to Ignacio he gave us the new test vectors. We identified few of the issues which we were facing in the primitives library that we wrote in Constantine. We fixed those and now the try is pretty much ready for computing the root commitment. But we are facing some issues in the internal node due to copy and write. We were following the get like the coworkal implementation so we are currently debugging that and we are aiming like in two weeks we can look for the correct root commitment computment and yeah, that's all the update after the holidays.
00:06:47.720 - 00:08:01.580, Speaker B: Anyone else? Not sure if Besu is here, I can give an update for Ethereum JS so I was out last week on leave, so I'm not up to date with the latest developments, but since Kishinder is not here, I can give an overview of what we've been working on. So we're progressing on Kowston and syncing. We've made it past block 13, which presented some hurdles for us, so we got that working. We've enabled a pre and post state verification so we can make sure that we execute the blocks properly. We initially ran into some issues related to gas costs, but now that seems to be fixed. However, we also have an issue at the moment where sometimes there's going to be instances where balance is going to be accessed, but it's not part of the witness. For example, contract creation, I think so, yeah, we're just debating if we want to handle undefined balances or always set them to zero in the constructor.
00:08:01.580 - 00:08:18.450, Speaker B: But yeah, we're making progress and I think this week should unblock us as well. Since I'm back, that's it for us. I'm not sure if someone else from Ethereum JS is here and would like to make an additional update. But that's it for me.
00:08:26.490 - 00:08:31.482, Speaker A: And for Basu. Latest thing that happened is we were.
00:08:31.536 - 00:08:36.710, Speaker D: Able to compute the state route and to follow the chain.
00:08:36.790 - 00:08:39.450, Speaker A: But only first twelve blocks.
00:08:39.810 - 00:08:50.240, Speaker D: Then we had some issues. Kareem will try to give more information about that.
00:08:50.610 - 00:08:51.360, Speaker A: But.
00:08:51.890 - 00:08:54.254, Speaker D: Yeah, that's it. We were able to compute the route.
00:08:54.302 - 00:08:54.900, Speaker C: And.
00:08:56.790 - 00:09:32.540, Speaker B: That'S it for now. No problem. Kareem, I just saw your message in chat. Did you want to give any other update for Beisu Dragon already gave a brief update. No worries. If not. Okay, we can move on.
00:09:32.540 - 00:09:54.436, Speaker B: So next up, an update on Snapsync is Tenish here. Yes, sorry.
00:09:54.618 - 00:10:09.692, Speaker E: So I think I already covered it during the client update. It's just that we tested the vocal sync, the ranges phase. It seems to be working fine. Now I'll start testing the healing phase. The second phase of the snapsync. Yeah, that's it.
00:10:09.826 - 00:10:24.720, Speaker B: Okay, great. Thank you. Didn't realize we have already covered it. Perfect. Okay, we can keep going then. Vertical testing. I think we have a few folks here from the testing team that wanted to potentially share a few thoughts.
00:10:26.020 - 00:10:27.650, Speaker F: Sorry, could you hear me?
00:10:28.260 - 00:10:36.870, Speaker B: Oh no, we could not. But now we can. I think we got you now.
00:10:42.440 - 00:10:43.284, Speaker D: Did you hear me?
00:10:43.322 - 00:10:47.080, Speaker B: Sorry, I can hear you, but very quietly.
00:10:49.020 - 00:10:49.770, Speaker F: Okay.
00:10:51.740 - 00:10:53.288, Speaker B: It's a bit better now. Yes.
00:10:53.374 - 00:10:55.450, Speaker F: Sorry. Yeah, I want to share.
00:10:58.880 - 00:10:59.790, Speaker B: No problem.
00:11:00.800 - 00:11:01.870, Speaker F: Can I.
00:11:05.920 - 00:11:08.300, Speaker B: Okay. Sorry, no other update.
00:11:09.460 - 00:11:47.244, Speaker F: I just wanted to share quickly. Regarding Bezu. Thanks to Dragon, we have a valid state route for the Genesis block. So we started to sync Bezu node in order to check the other block. And we have a problem on the block twelve. For the moment we think that it's related to gas cost because we are not implementing something related to gas cost modification in Bezo yet. So it can be a problem with that.
00:11:47.244 - 00:12:15.124, Speaker F: Because block twelve, it's the first block with a transaction. So it can be related to that. So we found an EAp regarding the gas cost modification for vehicle. So I shared that to Guillaume. Geode said that it was a good version. Maybe he needs some updates, I don't know. And so the idea is to try to implement this gas code modification in Bezu in the next week.
00:12:15.124 - 00:12:52.610, Speaker F: Or maybe this week, I'm not sure. And also with Thomas, we decided that the next modification regarding the vertical tree library in Bezu will be to optimize performance. Because for the moment, in order to commit the root ash of the Genesis block, it takes 15 seconds. So it's really slow. But we have some ideas in order to fix that. Yes, we are still moving forward. Thank you.
00:12:55.220 - 00:13:09.220, Speaker B: Awesome. Okay, so yeah, testing team, I think we have Spencer here and maybe Mario as well. Yes. Do either of you want to share a few thoughts?
00:13:11.320 - 00:13:13.844, Speaker H: Yeah, I can go. Can you hear me?
00:13:13.962 - 00:13:14.968, Speaker B: Yes. Perfect.
00:13:15.134 - 00:14:06.890, Speaker H: Yeah, basically just. Well, this is the first time I've joined this call, so hello to everyone. I guess we don't have anything concrete to share, but what I would like to know is just how we can improve the current testing framework that we have to include, for example, specific test fixtures formats for Berkele. So at the moment we only have two. So we have the blockchain test and the test. This is good enough for most of the cases, but we can create more basic formats to test specific things about Berkele. But at the moment I really don't have a complete idea of what could that be.
00:14:06.890 - 00:14:23.820, Speaker H: But yeah, that was basically my goal in this call to gather some insights of what the current state. If you guys already have test pictures for that, can we include them in our framework? And so on and so forth.
00:14:32.610 - 00:14:33.950, Speaker B: Yeah. Kyo.
00:14:35.670 - 00:15:23.520, Speaker A: Yeah, so my first question to you would be Dan and I had a quick exchange about modifying t eight n tool that is part of geth or the geth executable suite. Is that something that you had in mind or do you need another kind of tooling for us to support you? So I know you're asking the other question, what we need, and I have some comments about this, but my first question would be that thing that we discussed with Dan. Is it still current? Basically, do I need to keep working on that?
00:15:23.970 - 00:15:57.580, Speaker H: Yeah, of course. To my opinion, I think the transition tool already does a lot of things, maybe too many. But we can easily generate the blockchain test and set test for Berkele using the transition tool as is right now, maybe just outputting more fields. But if you have in your mind something that would be better as a separate tool, I think that we should go for it. It doesn't matter for us. We can use another tool. That's perfect.
00:15:57.580 - 00:16:07.662, Speaker H: So do you have something in the transition tool that could be better put as separate tool?
00:16:07.716 - 00:16:08.030, Speaker D: Okay.
00:16:08.100 - 00:16:40.860, Speaker A: I think we would just need to expand the tool to produce proofs and. Yeah, what I was getting to, the reason why I also asked that, yes. Is precisely if we start producing proofs as well, would you be able to in your framework, would you be able to compare? Imagine the block having some extra fields, although there won't be a block. There would be something on the side. But sorry, there won't be a block field. There will be something on the side. Could you also match the results based on.
00:16:40.860 - 00:16:48.300, Speaker A: So we would be exporting the witness. Could you also match some values in the witness as well?
00:16:48.910 - 00:17:36.378, Speaker H: Yeah, maybe I can explain a little bit how we use the transition tool right now. So we use it to produce both of the formats, and we can use it to produce a third format, if that's okay. We simply call it with the prealog and the transactions that it needs to execute. And then, for example, when we are producing the blockchain test, we use some of the fields to produce the blockchain test. And then for the state test we do a different approach, but this is basically just the same input, same output, and we take whatever we need to form whatever fixture we need. So I guess it could be very similar to this. So I'm guessing that we need to produce a pre alog and then maybe some other extra info to the transition tool.
00:17:36.378 - 00:18:20.454, Speaker H: And with this we can take another field, maybe the witness, and then we could produce a third test picture format, which would be the witness test fixture format, for example. Yeah, it's definitely dual. And I don't think it's too hard for us to just get another source of information. If it's another file or maybe it's another field somewhere, it's just fine. We can just parse it and then just produce a JSON test fixture format. Because ideally this third test fixture format would be another JSON file. And then the clients could consume this just as they consume the blockchain test and the state test, they would need to implement another consumer.
00:18:20.454 - 00:18:24.460, Speaker H: That's true, but I think that's good.
00:18:25.150 - 00:18:57.910, Speaker A: Okay, well that sounds good. Yeah. The other use case that would like to test. And in fact it's a fairly important one, but it's also more difficult. It's the transition like you start with a vertical root, right? Or, sorry, you start with an MPT tree and then you convert it to vertical. So that would be a bit like your state route, except you would be testing two states at the same time. Basically.
00:18:57.910 - 00:19:02.440, Speaker A: What could you use to test this? Yeah.
00:19:05.610 - 00:19:26.794, Speaker H: We already have something like this. So these are the transition for transition tests. So the transition tool is not aware of this. But the blockchain test format does contain the network. And. Well, normally it contains like Berlin, London, whatever. But sometimes it contains the London to merge.
00:19:26.794 - 00:19:59.994, Speaker H: For example, at some point I was thinking that maybe this could be good enough. So for example, if we do Shanghai to Berkele in block whatever, we can produce a blockchain test format that contains a lot of, or many at least blocks in the previous fork in Shanghai. And then we can just get to the Berkele fork block and then keep producing blocks and just keep testing for the transition to Berkele in that same test.
00:20:00.112 - 00:20:12.000, Speaker A: Because just to make sure you're like unlike any fork before that, this fork will take more than one block to happen.
00:20:13.170 - 00:20:41.078, Speaker H: Yeah, definitely. We can have as many as necessary. The blockchain test doesn't have a limit on how many blocks we can produce. And we already have many tests that produce a lot of blocks after the fork. Unless you're talking about thousands of blocks or more than thousands, I think it should be double still. But if that's something that we have to have in our minds or how many blocks are we talking about after?
00:20:41.164 - 00:20:57.980, Speaker A: It depends how much the start state is, how big it is. But yeah, if it's 100 megabytes, it might take, I don't know, maybe 1000 blocks, something like this.
00:20:59.090 - 00:21:54.590, Speaker H: Yeah, I think at least for this format we should have in mind that we are testing like specific parts of the transition. For example, for example, one test could be, okay, we are testing this account that has balance but has no code and then go through the transition. And then for this other test format, sorry, test vector, we go with an account that has code but no balance or something very specific like that. Instead of intensive test cases just to test scenarios. I mean, we can produce very big blockchain tests if it's needed. Maybe it's necessary anyway. But in my mind that's more like the idea we have to have on the transition tests that we produce.
00:21:55.010 - 00:22:39.850, Speaker A: Okay. Yeah, indeed. What we'd be interested is when we identify corner cases, try to make sure they happen and then produce them. So it's true, we don't need a lot of state to transition in one go, but some stuff happens because the state is pretty large. So yeah, it would make sense to also be able to handle larger states, but we're not shooting for something that is as big as main net, of course, or even a testnet. What's interesting is to see if the iterator huts halfway through a blog. Sorry, halfway through contract storage or this kind of use cases.
00:22:39.850 - 00:22:47.840, Speaker A: But yeah, no, I don't think it needs to be very large. So that shouldn't be a problem. If you can handle 1000 blocks. I think it's more than we need.
00:22:49.010 - 00:23:13.480, Speaker H: Yeah, we can try it. I mean, we can try some tests with a very big state at the beginning, before the transition to see if it's sustainable, if we can have such a big test in a repo we can try it anyway and give it a go and see if this is the right place where to have this test, or we have to move it somewhere else. It's okay.
00:23:14.810 - 00:23:23.530, Speaker A: One question I have is when you create those tests, is the data like hard coded in some file, or is it generated randomly?
00:23:24.270 - 00:23:42.880, Speaker H: We can do both. If you need some random information, we basically use python, so you can have a generator of any kind you wish, can be random, can be something hard coded or whatever is needed.
00:23:43.250 - 00:23:58.280, Speaker A: Okay, cool. Yeah, so I guess I will continue working on that with Dan or anybody else if they have questions or want to join. But yeah, for me that's all the questions I had.
00:23:58.810 - 00:24:30.640, Speaker H: So I wanted to share just a link to some of the test formats, definitions specs that we are working on. So this folder contains a branch. This is not merged yet, but it contains the two examples of the state test and the blockchain test. I think we can take this as starting point if you want to generate, for example, the witness format or something similar, and we can just begin to write out a new format in this fashion if we need it.
00:24:39.230 - 00:24:40.570, Speaker B: Yes, Spencer.
00:24:41.870 - 00:25:46.910, Speaker I: Hi guys. Yeah, I just wanted to ask, the vertical test vectors that Ignacio has, I think there's three different types. Would there be any benefit of us having that within our repo from your end? Like a tree test where you're adding the key value pairs into an empty vertical tree and then verifying the root hash. Similar for adding just accounts into an empty tree and verifying the root hash, because we could definitely add that into our repo as well, if it's of value. But I'm not sure how far along a lot of people are yet. Just from the perspective that the blockchain tests, it's amazing that we can use them already somewhat to test verkel, but the only real thing we have is this isn't working because the state route is mismatched and it makes it kind of difficult to find specific corner cases in that sense. So if there's these types of formats that we can add in the repo that are more low level, I think we'd be happy to add that.
00:25:46.910 - 00:25:56.290, Speaker I: And the only kind of precursor would be that clients might have to have an additional tool that we use within the repo as opposed to using ta ten exclusively.
00:26:00.870 - 00:26:59.510, Speaker D: Yeah, I think it will make sense to use those. So I have these cryptography test vectors, which I don't think are related to this testing infrastructure. So other libraries are using them in the format that I created them, but for these other test vectors about the tree inserts and expected state roots and things like that. I think it will be useful to import the test case itself, not necessarily the format. We can probably adjust the format to whatever exists now so we don't have to create any new custom thing. Because I'm not sure most Berkele library have been using these tests. But yeah, I would just simply leverage whatever thing I created for testing and not really respect much the format.
00:26:59.510 - 00:27:01.640, Speaker D: That's not really that important.
00:27:17.880 - 00:27:21.720, Speaker B: Okay, anything else on the testing subject?
00:27:25.980 - 00:27:58.870, Speaker H: I guess one last question could be is there any openpr for the transition tool for Berkele or is there anything we can take a look? Maybe the main thing is because there is no formal definition yet for the transition tool, so it can be sometimes tricky to really know what the testing framework is expecting from it. But it will be great. If you guys have any progress on that, I can take a look and submit some feedback if possible.
00:28:00.360 - 00:28:05.028, Speaker A: So you want a pr that goes through the transition basically. Is that what you're asking for?
00:28:05.114 - 00:28:10.360, Speaker H: No, for the transition tool, is there any pr or is it already merged?
00:28:12.860 - 00:28:17.370, Speaker A: There's a pr, yeah. At least against guests that I can send to you.
00:28:18.540 - 00:28:22.250, Speaker H: Okay, great. Yeah, that's exactly what I need.
00:28:28.730 - 00:28:45.580, Speaker B: Okay, next up, the new testnet and reviewing things to make sure that we include what we want to include, for example, the recent fix to the main storage offset bug. Guillaume, did you have anything that you wanted to start with here?
00:28:47.390 - 00:29:10.900, Speaker A: Yeah, so there's been several issues on the testnet that we identified. I'm trying to currently collect them. Yeah. So indeed there's the storage offset issue. There's the fact that self destruct is activated. So that was a rebase problem on my end. So yeah, currently self destruct works on the testnet and it should not.
00:29:10.900 - 00:30:28.314, Speaker A: There was what we discussed last time, not charging the gas from the transaction origin and the transaction like destination, the to and from fields of the transaction so that the gas remains 21,000, like the gas for a simple transaction remains 21,000. And then I had an extra fix. I'm trying to remember what it was. Yeah, so it was something that Gertzinder pointed out that when an account does not exist, it seems that the two address is not being part of the witness. So there's a bug that needs to be fixed. So I will fix that on the guest side, I assume most that's only a problem that affects guests. But yeah, I was wondering if there was something else you were aware of that I should also add to the scope of this relaunch yet?
00:30:28.352 - 00:30:44.270, Speaker E: Danish, if you remember, there was some problem with one transaction that there was an out of guess error, but the code still keeps on executing in the current constant.
00:30:44.630 - 00:30:57.620, Speaker A: I remember that. And yes, the fix is already in there, so that's why I didn't write it down. But yes, it should be added to the list. Thank you.
00:30:58.150 - 00:31:13.370, Speaker E: And one more thing. I'm not sure if we finalized the decision in this, but I think there was a discussion around, like, when there is an empty block, do we add the guest beneficiary witness or not? Did we have a decision on that?
00:31:13.440 - 00:31:26.320, Speaker A: I'm not sure about that. So when there is an empty block, and when it's an empty block. Sorry, help me here.
00:31:30.530 - 00:31:48.866, Speaker E: For example, we produce a block, or we produce an empty block, so there are no transactions. So in the execution witness, should we add the guest beneficiary to the execution witness? Because right now it's being added in the current testnet. So should we keep the same behavior or should we modify this behavior?
00:31:48.978 - 00:32:16.602, Speaker A: Right. So the fear recipient. So that's when there are no withdrawals and there's no transaction. So basically no reward gets given. So the point was, should we add the witness? Yeah, I'm not sure what we decided. My hunch is that we should not really bother about removing it when it's just null. Null.
00:32:16.602 - 00:32:23.150, Speaker A: But I'm trying to remember, was there any other point in that discussion that I'm forgetting?
00:32:30.670 - 00:32:56.798, Speaker D: I think it was just mainly that. And maybe if there were no tips, like any case that will cause the balance of the coinbase not to change. I think in the spec, the Coinbase state is only touched if the balance changes. And now we have simply pretach the coinbase. So it's always in the witness.
00:32:56.974 - 00:32:57.554, Speaker A: Yeah.
00:32:57.672 - 00:33:00.370, Speaker D: Like any case that won't change the balance.
00:33:01.990 - 00:33:02.740, Speaker A: Sorry.
00:33:06.090 - 00:33:07.080, Speaker D: That's it.
00:33:07.770 - 00:33:36.702, Speaker A: Okay. Yeah. What I was just wondering is how a stateless client that doesn't have anything in the tree would react. Are we going to create annoying bugs for no good reason? I mean, I don't mind removing it. It wouldn't be a big problem, I think. I'm just saying. Yeah, it might cause some annoying corner cases, but I don't mind removing it if that's all it takes.
00:33:36.702 - 00:33:57.320, Speaker A: Yeah, nothing comes to mind. I'm just wondering what happens if you get an empty witness. But I guess it's also an excellent test. So. Okay, let's try to do this. And if it causes a problem, we'll figure it out and we'll return to the old version. Cool, thanks.
00:33:57.320 - 00:33:59.080, Speaker A: Anything else?
00:34:07.130 - 00:34:11.450, Speaker B: Ignacio, did you have something you wanted to share? Block hash.
00:34:13.710 - 00:34:55.110, Speaker D: Oh, yeah, sorry. I created. Since there are a lot of new people here now showing the call, I did a small slide presentation to share now to explain this block hash situation that we haven't resolved yet. So it's kind of a hole in the spec. We discussed this about two months ago in a single big call, just like, exploring a bit the situation. So I will share my screen and give a refresher on all these topics so we can maybe get closer to making a decision. So, give me a minute.
00:34:59.290 - 00:35:00.040, Speaker F: Um.
00:35:04.270 - 00:35:05.740, Speaker D: Can you see my screen?
00:35:08.190 - 00:35:09.274, Speaker B: Not yet.
00:35:09.392 - 00:35:11.580, Speaker A: No, not yet.
00:35:12.190 - 00:35:12.940, Speaker B: Okay.
00:35:13.550 - 00:35:14.540, Speaker A: It's happening.
00:35:15.330 - 00:35:16.880, Speaker B: I can see it now.
00:35:17.650 - 00:36:09.360, Speaker D: Okay. So, yeah, I will try to go somewhat fast because I don't want to take a lot of time here. What is block hash? Just like, as a quick refresher, is opcode that allows a contract to retrieve any block hash within the last 256 blocks. So, as an example, if we are in block number 1000 and you ask block hash of nine nine eight, you will get the corresponding block hash. And if you ask for something that is not within this range, it will return zero. So why is this a problem for virtual trees? And the problem is that these block hashes aren't part of state.
00:36:10.930 - 00:36:11.680, Speaker A: And.
00:36:13.490 - 00:37:11.890, Speaker D: This means is that this data can't be in the execution witness. So a stateless client that receives an execution witness, which in theory, has all the data that it needs to execute the block, won't find these block hashes in case this block contains a block hash opcode. So, yeah, that's kind of the main question, or the main problem that we have to solve. Now, some minutes ago, when I was doing this presentation, I realized that there was already some attempts on targeting this problem in eips, which is interesting. So, one of them is EIp 210 from Vitalik from a long ago. So I have it here. So, his goal here was mainly to solve this problem.
00:37:11.890 - 00:38:03.940, Speaker D: So, store block hashes in the state, which obviously will solve the problem, to reduce process complexity and all that. But it also tries to extend the range of how many block hashes you can resolve. So I think that the original intention was to store all the block hashes in the state, so later nodes can prune some history but still have the blow hash reference. So if this data was stored somewhere else, you can still validate it. There's also this. So I think it contains some simplifications. Had some.
00:38:03.940 - 00:39:20.970, Speaker D: Mostly that there's also an research post from 2020, which is basically making the point. It's pretty short. So it's basically making the point that the way that block hash works will be a problem for stakeless Ethereum, which is obviously the case because we are here. Just to give you some context, this is not like the first time we discover this problem, but it is just that now it's important because we have to solve it to move forward. So in the previous call, we kind of jumped directly into some potential production solutions. But I wanted to go a bit slower here and maybe do some thought experiments about other potential solutions and why they work or wouldn't work or which are the trade offs. So if you think about this problem from scratch and you say, okay, so if these block hashes are in the state, maybe we can simply attach them as extra data in the witness.
00:39:20.970 - 00:41:13.470, Speaker D: And whenever a stateless client executes the block, it will find an opcode that is like a block hash, and it will say, oh, okay, I need block hash of this ask block, and I will find it in the witness in this extra data field, or something like that. So the good part is that this sounds simple because it's in the witness, but it's not part of the tree, but it's like an appendix of data. And the bad part is that it isn't verifiable because someone simply put some data in the witness that you cannot really verify. And this won't be verified as part of the Berkeley proof, because the vertical proof verifies data in the state, and this is like an appendix of data. So you have to trust whatever is put there. So maybe if you think further, you might say, okay, so if I'm verifying a block, and this block has unexpected gas usage and unexpected state routes that I want to verify, what is the chance that I can really put some fake block hash and still have the gas usage and state route validate anyway? Because if I kind of fake the block hash, probably something in the contract execution might execute differently and shouldn't match. And the reason at least that I found is that just like an easy example is to say that maybe the contract only uses the last eight bits of the block hash because it's using the block hash as some kind of random source, which actually would be a bad idea.
00:41:13.470 - 00:42:11.730, Speaker D: But maybe it's doing that. So if it is using the block hash result of the occal, in that way, you can simply fake the other 256 minus eight bits of the block hash, and everything would work correctly, and the gas usage and state route would still match. So this isn't really like such a crazy use case. Despite you might say that you were given enough data so the state transition could be validated, which is true. I would say that the data that you had in the witness wasn't 100% correct. So where you expected to receive the block hash for some block number, you got something else which is completely wrong. Despite that was enough to validate the state.
00:42:11.730 - 00:43:24.202, Speaker D: So I think it's a bit messy and not really that nice. So I don't think this is like a good argument, or I think it's like an unfortunate situation of the solution. So let's to move forward. The other potential is to say, okay, so instead of having this data from crossing this data from an untrusted source, why not use the CL to get these block hashes? So the good part is that our assumption is that the CL is trusted because you are using it for deciding which is the right chain to follow. And that will never change in a way, because the stateless client is only validating state transition and not really following the right chain. Since you will ask this party for this data, you don't have to add anything extra to execution witness, which maybe sounds nice. And we don't have this situation, as I mentioned before, of partially correct values or something like that.
00:43:24.202 - 00:44:16.940, Speaker D: Like whatever value we get from the CL, we will assume it is correct. The bad part is that, at least from my perspective, is that we are adding an extra expectation to the party that is resolving us the consensus problem. So in this case, the CL. So until now, the CL was mostly only used for deciding which is the right next block to validate. And that's fine. And that won't change because it's kind of the minimal thing, the minimal expectation. But I believe that if in the future we can have stateless clients that won't be using cls because they are trying to use some other solution to follow the right chain, whatever that is.
00:44:16.940 - 00:44:42.782, Speaker D: We would be like adding this extra expectation that this other solution should also provide a history of block hashes, which may or may not be a problem. But I think it's just better to not put more expectations to external APIs on providing us more data. I think that would be ideal.
00:44:42.846 - 00:44:50.040, Speaker C: I mean, in the long run, if we want to go stateless, we would also want to make the CL stateless, right?
00:44:51.690 - 00:44:52.440, Speaker D: Yeah.
00:44:53.530 - 00:45:47.366, Speaker C: So that kind of makes it not the ideal solution if we just solve this by putting it on the Cl. On the other hand, we could say right now, well, we can't go full stateless anyway because currently, we don't have a way to make the beacon chain stateless realistically. So it could be okay to box this away and say, well, block hashes is something that the Cl can take care of. And for now, it's always the traditional way, which is just, it isn't stateless. And once it becomes stateless, it's also realistic to mean the Cl does have a database of block hashes already. Like, we do have this history, right? This is stored in the CL. As far as I know, the beacon state has it.
00:45:47.366 - 00:45:54.090, Speaker C: So maybe this is okay. And we can simply say when the Cl goes stateless, it is required.
00:45:57.230 - 00:45:57.594, Speaker B: To.
00:45:57.632 - 00:46:00.090, Speaker C: Make this data available as part of its witness.
00:46:02.530 - 00:46:04.400, Speaker D: Yeah, that's a good point.
00:46:05.090 - 00:46:05.406, Speaker A: Yeah.
00:46:05.428 - 00:46:08.590, Speaker D: I think it's more mainly about short term.
00:46:09.810 - 00:47:10.850, Speaker C: Yeah, I agree. This might be something worth checking. Because also, in a way, I think it's a good point to point to the CL and say the CL isn't completely stateless anyway, which is not such a big deal. Right? Like the CL state is like hundreds of megabytes rather than tens to hundreds of gigabytes, like for the El. So it is a much smaller state overall. And maybe it's better in this case to say, since we can't solve that right now anyway, it doesn't make sense to over engineer this part. The question is, how much complexity does it add to ask the CL for it? So basically it would mean that the execution layer request would come with an extra field providing the last 256 beacon routes, execution routes.
00:47:10.850 - 00:47:13.780, Speaker C: Is that correct? Or how would it work?
00:47:14.710 - 00:48:25.222, Speaker D: Yeah, I mean, something like that can work and also can keep going to the next solution, which might allow to mix. Okay, I will move forward and I think I will indirectly answer this question, maybe so the next solution is a bit going that direction. And I call this stateful tracking, or keep your own history. It's like inventing names here. So another idea is simply to say, let's not trust or expect an external party to give us valid block hashes. And simply, when the stateless client boots get the last 256 block headers from anybody. And since a stateless client has as an starting axiom, the parent block, because it needs that for the state route to validate the execution witness, you will be in a situation in which you are trying to validate the current block, which you don't trust, because that's the reason why you are trying to execute this statelessly.
00:48:25.222 - 00:49:39.970, Speaker D: You have the parent block which is trusted, because that's your starting assumption as a stateless client, because you kind of trust the state roots and things like that. And you have all these block headers that you fetch from somewhere untrusted. And what you can do is you kind of simply check the ketchup chain from the parent block for the rest of the history that you fetch so you can verify this history. And that means that you have all these now verified 256 block hashes so you can execute this current block. And if any block hash op call appears, you can simply fetch it from memory. That's why I call it this keep your own history because the status client is simply creating this history from downloading these block headers from somewhere. And after your blog verifies you simply delete the last one and append the one that shows you have just verified and you kind of update this history and you kind of keep moving forward.
00:49:39.970 - 00:51:10.080, Speaker D: So the good part is that you don't have to trust or expect anyone to provide you the correct data so it doesn't force the ancient API or something like that to give you this data. Again, there's no extra data adding to execution witnesses. Of course, the most obvious bad part is that you have to download 236 block headers when you boot, which it isn't really that bad, but it's like, I know, some reasonably amount of data, but you have to only do that once you would. So it's not like on every block, it's just like once. Despite we are not forcing on a specific party to provide this data, like stateless clients still have to decide from where they will pull this. So it's kind of making the stateless clients just deal with this problem, which might not be obvious, this might be somewhat annoying for what I call short term stateless clients. So let's say that metamask wants to embed a stateless client and only verify the chain for a couple of blocks because it wants to check if a transaction was added or some side effect happened.
00:51:10.080 - 00:53:04.500, Speaker D: Downloading these 256 block headers might be like a big pain, considering that it's only trying to verify the chain for a couple of blocks. So this onload won't be a big deal for validators of the chain that are like long term, but for short term ones might be a big pain. And some point that we discussed on the weekend with Guillaume that he mentioned, which is interesting, which is if there's a reorg, that means that the state of the sky should also manage the situation, because it has to do the reorg on this history that is keeping itself. So it's nice in the sense that it's like not trusting anybody else, but it has these other side effects that might not be ideal. And of course, regarding Dangra's last question, you can also ask like in this solution, ask for the last 256 block hashes instead of headers and keep your own history and just ask once and just the stateless client can simply keep this history on every next block, so shouldn't be needed for being in every block. Ask for the history and the last solution, which is the one that we actually discussed like two months ago in the call, is this state ring buffer, which is okay, let's bite the bullet and simply put the last 256 block hashes in the state tree. Because if it is part of a state tree, that means that it will be automatically in the execution witness and the status kind will be happy because there's no magic or extra work that should be done by them.
00:53:04.500 - 00:53:45.502, Speaker D: So there are many ways to implement this. The most obvious one is to simply reserve 256 address in the tree. This should say ff, I guess. So just reserve some addresses. Before any transaction is executed in a block, you simply update the parent block hash in the corresponding address, which you interpret as a ring buffer. So nothing crazy here. So after you do that, before executing anything, you have the updated ring buffer.
00:53:45.502 - 00:55:00.410, Speaker D: So whenever you see a block hash or some block number, if it is not within the range, return zero, and if it is within the range, just simply take the block number modulo 256. That will give you the address and simply read that from the state. Another example is to instead of fixing these addresses, just create a system contract. This is something that I got to know because Kajinder mentioned that this is the kind of solution that was done for putting in the CL state routes. I think he can mention that later, but yeah, that might be a cleaner solution to make some kind of system contracts. So for the long, long term, I would say this is like the cleanest solution, because the block hash data is part of the execution witness, it's only added when it's needed. Like if a block doesn't have a block hash opcode, there's no extra data put in the witness.
00:55:00.410 - 00:56:08.234, Speaker D: And for stateless client there's like zero extra work or complexity. They don't have to deal with calling external data or dealing with reorgs or whatever. Yeah, the bad part is that the implementation that has the highest complexity, because we have to change with the tree design and reserve these addresses or create this contract. And something that was mentioned by Dankrad in this call from two months ago had this potential DOS vector because for example, in this example, all these keys are in the same branch, so people can have a lot of time to really kind of brute force keys rights. So this branch is longer than average. If this is like a problem or not, I guess this requires a more formal analysis. But it's just to point out that this attack vector wouldn't be a huge deal for the block hash execution, because probably clients will have their own in memory ring buffer, so they won't be reading from the tree.
00:56:08.234 - 00:56:35.000, Speaker D: But for execution witness size, this branch might be longer, and for updating the tree you might have to do some extra commitment updates in that branch. But if that's a problem or not, I don't know, maybe we have to think more about that. So yeah, that's all the presentation. So hopefully this will give a high level view of the situation.
00:56:42.670 - 00:57:01.920, Speaker A: Yes Lucas, so just my quick comment from the chat that EAP 4788 already pushed hashes though beacon block hashes in the state. So if we implement it in the state as EAP 2935, we will have feature parity here.
00:57:12.400 - 00:57:16.450, Speaker D: Yes, this was like the ip that ginder told me. Yeah, exactly.
00:57:18.020 - 00:58:00.664, Speaker A: Yeah, I have some questions about this EIP. First of all, the address. Clearly I don't think we can use this one because it's the system address. Yeah, I wouldn't want to use that one. But what I understand is that when you're storing something, you actually need to execute some bytecode instead of writing directly in the tree. Is that correct? No, it's not correct though, in the rational. Okay, so for example, with EIP 4788, most clients went with executing a bytecode, a transaction.
00:58:00.664 - 00:58:12.130, Speaker A: But for example in nevermind it's implemented currently by directly writing to the state slot. We are thinking about changing it. But.
00:58:14.900 - 00:58:21.044, Speaker D: Even in ethereum js, we directly write into storage slots and someone else.
00:58:21.082 - 00:58:24.500, Speaker C: Can access it with the contract.
00:58:25.000 - 00:59:35.308, Speaker A: So it's implementation details. Yeah, but it's an implementation details that actually matters because if one client executes code, you will find it will have to end up in the witness, and then another client will not execute that code, and so will find that the witness is larger than it needs to be. Yeah, I'd be happy because. Okay, I'd like to relaunch the testnet. I could implement this EIP, but I need some more clarity on. Yeah, can we decide? Ukash so will system transactions end up in the witness then? Or do you mean witness by loading stuff from the state? My understanding is that unless the contract is somehow available in the stateless client it needs to be in the witness. Yeah, I mean we could also not put it in the witness, but yeah, stateless client won't update the state.
00:59:35.308 - 01:00:22.252, Speaker A: Right. So it's like transparent to them. They need to update the tree though. Okay, but I mean, okay, it's true that they don't need. Okay, it's just that we were discussing an extra check to verify that the witness, in order to avoid some special kind of attack, or at least preventing people from sending bloated witnesses, you would check that every leap in the tree that you've been sent has been that you've been sent and then ended up in the reconstructed stateless tree would have been accessed. Otherwise you would declare the witness invalid. That's what we were thinking about.
01:00:22.252 - 01:00:44.160, Speaker A: It might be too extreme, but yeah, okay. There's a potential consensus problem here, but I guess it could be circumvented by saying, well, the witness doesn't include the system contracts, but there's always the risk that if for whatever reason you upgrade the system contract, you might find yourself with some complexity.
01:00:44.580 - 01:01:02.970, Speaker C: The system contract is like this is to record the state routes. Yes, but is it part itself of the state route? Does its state affect the ethereum state?
01:01:04.060 - 01:01:06.436, Speaker A: Yes, the system contract is part of the state route.
01:01:06.468 - 01:01:12.056, Speaker C: Yes, but then it's clearly part of consensus, right. Then everyone has to agree on it.
01:01:12.158 - 01:01:13.660, Speaker A: Exactly, that's the question.
01:01:13.730 - 01:01:30.880, Speaker C: Yeah, but I mean, that is clear. And then if it does affect the state route, then we also have to include the witness, because otherwise the status client will not be able to compute verify that the state rules have been updated correctly.
01:01:33.540 - 01:01:49.184, Speaker A: Unless they package the contract by, they package it themselves and they don't actually put it in the tree. But yeah, no, I think it should be in the list. It should be in the witness.
01:01:49.232 - 01:02:32.980, Speaker D: All right, nessio, there's some interesting case here in which whenever we add the parent block hash in the ring buffer, this parent block hash actually, it's like data that status kind already has because it already needed the parent block. So in theory this write in the execution width shouldn't be needed, but it's just like a single key. So maybe it doesn't make any big difference, but this is data for a right that the stateless clients already have, even if it isn't part of the execution witness.
01:02:38.860 - 01:03:15.170, Speaker A: All right, we're a bit overboard, I don't know if. I guess we have to push the rest of the discussion to next time. Okay, so what I suggest is that I will try to implement 29 35 in Geth for this purpose, because I don't think we have it. And if we find any problems, I can bring them up at the next vic. But from what I can see, we should relaunch Calston with this method because it's already defined. So let's give it a try.
01:03:21.680 - 01:03:40.620, Speaker B: Okay, cool. Yep. Sorry for going a few minutes over. Thank you, everyone. There were two topics we didn't get to. One is Prague Electra planning, which obviously is still ongoing and is a big topic. I would just encourage and remind folks to join the next ACD AcDE.
01:03:40.620 - 01:03:54.850, Speaker B: And then there's also agenda item today for migration strategy, which we can get to next time or continue async. Okay, awesome. Thank you, everyone. Talk to you next time.
01:03:55.220 - 01:03:55.970, Speaker A: Thanks.
01:03:56.300 - 01:03:57.160, Speaker H: Bye.
01:03:58.060 - 01:03:58.900, Speaker B: Thanks. Bye.

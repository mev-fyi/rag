00:00:02.030 - 00:00:02.580, Speaker A: You.
00:00:04.630 - 00:00:05.378, Speaker B: Okay?
00:00:05.544 - 00:00:56.802, Speaker A: Welcome everyone to now the 10th of these 4844 implementers calls, couple spec things to cover today, then some devnet discussions around where we want to rebase different, what we want to rebase different devnets on. And then I think is worth talking about some testing stuff that was mentioned last time to make sure we're all on the same page, and then we can cover anything else people might want to discuss. But to. Oh, to start, Roberto, you have this update to the EIP on the El side. Do you want to take a minute or two and walk us through that?
00:00:56.936 - 00:01:35.870, Speaker C: Yeah, absolutely. So this is something I encountered when I was doing the implementation of Aragon. I noticed in the implementation of Geth we are using the same hash for the transaction id as we are for signing, which I believe is a bug. So I wanted to clarify that in the EIP, what is actually the correct behavior there. And I guess that just sort of opened up a little more of a discussion on what is the right way of handling this. Anyway. So right now, when we compute the signing hash, we're using the hash tree root, which I guess is a standard way of doing things of the SSE encoding, which I guess is a standard way of doing things in the consensus layer.
00:01:35.870 - 00:02:39.982, Speaker C: So the question is, what do you do then for the id hash? Typically what goes on in the execution layer, and please, people who know more about this, correct me if I'm wrong, is you basically take the raw serialized encoding that appears in the block and you just hash that. So I decided to implement that and submit a PR that clarified that in the spec. So that's one potential solution. We can move forward with that. But it also just made me wonder, why are we using hash tree root at all in the execution layer? Perhaps we should change that to also just use hash, the raw serialized encoding proto commented on the PR is like, well, maybe we should just use RLP, or should we use hash tree root for the both. So these are kind of all the options and they're sort of laid out in that issue. And I sort of put out my favorite approach, which is just to use the raw serialized encoding, stick with SSV, and then continue to hash those raw bytes.
00:02:39.982 - 00:03:03.500, Speaker C: That will make things easier to implement in things like Aragon, where otherwise I'd have to have a much more involved SSV understanding in the transaction pool, for example. So I don't know if I'm summarizing this well enough. There's a lot of details balled up there, but I don't have a strong opinion on either way but that was just my feeling on how we should go with that.
00:03:04.110 - 00:03:28.418, Speaker D: Roberto, I kind of lost you in the beginning. I think I dropped out. But my understanding is that we're using SSD in the execution layer, which is not a standard way to do things. But is there a problem with. What is the problem with this? Again, can you just describe. I think I dropped when you explained the problem.
00:03:28.584 - 00:03:52.860, Speaker C: Yeah, there's not a problem per se. The only thing is we have not specified how to compute the transaction id hash in EIP. Should we use hash tree root for that? But that deviates a little bit from how we do it in the execution layer, typically, which is where we just hash the raw bytes that appear in the block of the serialized form. So we can do that too, right? Just to sort of open up.
00:03:53.390 - 00:04:01.218, Speaker D: And that's the only instance where we're using SSD in the execution layer in DCIP. Or is this the only problematic instance?
00:04:01.334 - 00:04:08.350, Speaker C: This is the only instance where we're using it. Proto probably has more context too. He can probably describe this better than I can. He's got his hand raised.
00:04:11.410 - 00:05:26.630, Speaker E: I want to add to this that there's a related problem about which contents exactly. We do include in the signing hash and which we do include in the fill transaction hash right now that's the message for both cases, which breaks some assumptions in the exclusion layer where otherwise the senior would be included in the hash. And all in all combines these type of problems of do we do the mercuryization or not? And which contents we include. I think we should just try to be create less surprises for developers and stick to things that have been tried and that most software relies on. Now with the EAP 2718, I think the one with the transaction typing in envlop, I do think we have the freedom to use a different serialization format, but we should probably stick to just making the transaction hashing predictable by just hashing the serialized format.
00:05:27.390 - 00:05:30.780, Speaker C: Yeah, and that's my same position as well.
00:05:38.240 - 00:06:13.050, Speaker B: Yes, it indeed will simplify things a lot on execution client side. Well, and for RLP, I saw that this encoding was removed for hashing of transactions. Right. Could you guys tell about that, where it was discussed and or defined? I missed that. Actually.
00:06:16.940 - 00:07:07.400, Speaker E: To give some context, the transaction was always signed over the transaction route and then the transaction in implementation was being, the transaction hash was being computed based on the serialized message in the transaction without a sensor. And so this was already inconsistent and SSD was there since the very start. And does clear up some trouble when the contents of the transaction are being read in the consensus layer, specifically the data hashes. So I would stick to SSZ, but there's no need for all the hash tree root complexity in the excretion layer.
00:07:12.660 - 00:07:27.848, Speaker C: Yeah, and to clarify, proto actually the geth implementation was never hashing the serialized form, even in the id hash. It was using hash tree root of just the message, which again really, I think is a bug, which is sort of what opened all this up.
00:07:28.014 - 00:07:41.310, Speaker E: Interesting. I was in the impression it was the serialized form for the full id, but not for the signing one. But yeah, I think there are inconsistencies. Convinced me there.
00:07:43.520 - 00:07:51.200, Speaker F: We at Ethereum js don't have any strong opinion, but we are also using hash tree root for generating the transaction hash.
00:07:56.090 - 00:07:56.840, Speaker A: Cool.
00:07:57.210 - 00:08:47.220, Speaker G: Sounds good to me. I'm curious, do we have an option just like covering our bases here, do we have an option to even change the hash how we like hash the transaction in the first place? I'm thinking of a theoretical future where all new transactions are SSE encoded and we deprecate using kekhak for the Hashing and just use the hash tree root instead, if that would make sense. I'm guessing no one knows.
00:08:49.900 - 00:08:50.804, Speaker C: Mophie.
00:08:50.932 - 00:09:16.800, Speaker E: Yeah, I took a quick peek at the EIP about the transaction envelop thing. It does not state anything about the transaction hashing. So there is the typing of the prefix for both receipts and the transaction itself. But correct me if I'm wrong, I cannot find anything about the specific transaction hash.
00:09:17.460 - 00:09:22.448, Speaker G: Yeah, I didn't see it in the IP either. Go ahead.
00:09:22.614 - 00:09:23.488, Speaker A: Yeah, I just going to say it.
00:09:23.494 - 00:09:36.570, Speaker C: Doesn'T say it specifically, but it's kind of implied. At least my reading of it is kind of implied in the part about computing the transaction hash root. Transaction hash root in there. Maybe I'm reading too much in between the lines though.
00:09:37.580 - 00:10:06.578, Speaker E: So something else about the transaction hashing is that it does produce the same hash as the hash that takes the value and converts it to 32 bytes when you put it into the miracle patricia try of the execution layer block. Take the hash, write the encoder transaction.
00:10:06.754 - 00:10:09.080, Speaker C: Yeah, that's the part I was referring to.
00:10:14.750 - 00:10:18.970, Speaker G: Yeah, but it doesn't really define what the hash should be, right?
00:10:19.120 - 00:10:19.820, Speaker C: Correct.
00:10:20.590 - 00:10:34.094, Speaker G: Okay. Either way, I think everyone here has made good points. We could just keep things simple and normalize the way hashing works. We'll cross that bridge if we have to.
00:10:34.212 - 00:10:45.060, Speaker C: So if everyone who has an opinion on this can click on that issue and just either act or disagree, and we can take it from there. Sounds like we're all in agreement though.
00:10:47.830 - 00:10:48.980, Speaker E: You go ahead.
00:10:49.830 - 00:11:07.820, Speaker D: No, just trying to understand. So you guys want to remove the mercurialization thing that hash three root does, but you still want to use the SSZ hashing logic or whatever it is, right? Because we don't use any merkle properties anywhere, so it's useless. Is that what you want to do?
00:11:08.190 - 00:11:14.380, Speaker E: You want to use the serialization properties of SSE but not the hash, right?
00:11:15.950 - 00:11:24.110, Speaker C: Yeah, I was going to say not just because it's not useful, but also just because that's the way the execution layer is hashing existing transactions.
00:11:24.450 - 00:11:27.854, Speaker D: Right, okay, that makes sense to me.
00:11:27.892 - 00:12:10.000, Speaker E: Thanks for the clarification and combined into the same discussion, we have this part where we include the sinchure values in the commitment to the filled transaction, which is important for some assumptions that may have been made in transaction pools, in the exclusion layer where you want to attribute the signature foundation to one transaction by hash. Roberto, does your issue capture this as well or should we combine?
00:12:10.580 - 00:12:18.260, Speaker C: Yeah, yeah, the signature details are in there as well. Let me know. Pretty sure that's addressed.
00:12:21.800 - 00:12:29.388, Speaker H: So just to confirm the decision we're making here, it's to move forward with using the SSC. Serialize the kacak.
00:12:29.584 - 00:12:35.930, Speaker C: Yeah, for both transaction types and including the signature values in the transaction id version of it.
00:12:42.720 - 00:12:56.698, Speaker A: Last chance. If anyone disagrees with this, do you think, Roberto, it's possible to have a pr for this before all core devs, just so we can.
00:12:56.864 - 00:12:58.262, Speaker C: Already done. Already done.
00:12:58.336 - 00:12:59.210, Speaker A: Oh, the prs.
00:12:59.290 - 00:13:13.060, Speaker C: Okay, there's prs for the eips in that issue and then I have one for gath. I mean, it's like a two line change. I was just waiting till we agreed on the EIP before I submitted a code change.
00:13:13.510 - 00:13:54.800, Speaker A: Okay, yeah, sounds good. Anything else on this? Okay, next up was Cl spec issue 31 70. Yeah, it seemed like everyone wanted to move forward with this on the last Yale call, but Mophie, you just had a comment like less than an hour ago on this. Maybe take it.
00:13:55.410 - 00:14:57.922, Speaker G: Yeah, I just recently became aware of the CIP. Sorry for the leak comments. Basically, I'm trying to understand how this decision avoids the case of peers, like sending the entire reason why we coupled like beacon blocks in the first. Well, one of the big reasons was so that we can easily decide on the spot if a blob site car is invalid and vice versa. If we move is data available to fork choice rather than during block processing, then that validation is deferred. And I guess it generates some sort of like an incentive for peers to provide coupled beacon blocks with valid blocks, but invalid like blob sitecar or the other way. Not quite.
00:14:57.922 - 00:15:15.660, Speaker G: I don't quite understand how this proposal resolves that, or if that is even a concern. I know, like Terrence already mentioned that that's quite okay, but could you explain why that's not a concern here?
00:15:16.990 - 00:15:29.134, Speaker H: Right, so I think we have similar issue here with attestation as well, because some peers can send you an attestations, but the block is never available.
00:15:29.252 - 00:15:29.678, Speaker A: Right.
00:15:29.764 - 00:16:09.114, Speaker H: So the design is really there basically to enable you to query block. Basically we have painting queue set up like you said. But in terms of deferred execution, that is a concern. For that, I need to probably think of it a little bit more, to be honest with you. But on top of my head, I think there's concerns to be both sides. It could be on the implementation side or it could be on the spec side.
00:16:09.232 - 00:16:09.900, Speaker A: Right?
00:16:11.070 - 00:16:16.380, Speaker H: Yeah, that I also need to think of it more. So I have to get back to you on that.
00:16:16.990 - 00:16:55.770, Speaker G: Yeah, I do agree that it is possible to resolve this in the implementation side. It will be quite gnarly to do so, which is why I was hoping what we have right now makes things super simple for implementers to attribute fault to any invalid messages. And with regards to attestation, I think that case is a bit different, because you can attribute the messages that are being propagated, the attestations themselves, to I guess their origin. But you can't quite do the same thing here with blob sidecar. We don't sign the blob sidecar, for example.
00:16:55.840 - 00:16:56.460, Speaker A: Right.
00:16:59.230 - 00:17:16.430, Speaker G: I think there's a concern here that some peers may be able to degrade the network, particularly giving how large these blobs are in some fashion if you defer their processing to fork choice.
00:17:23.560 - 00:17:28.950, Speaker H: Yeah, I think we can perhaps continue on the pr or the issue here.
00:17:35.320 - 00:17:54.750, Speaker A: Okay. And I know Danny had a comment about wanting to get this into the spec release on Friday either way. So yeah, if we can just try to continue this in the next couple of days so it gets resolved pretty quickly, that begin.
00:17:59.200 - 00:18:53.410, Speaker B: So I just say about this, for the implementation, we're treating the blob validation check similar to how we treat signature checks. So we're sort of using them as these are conditions for validity for inputs into block processing and like valid outputs of block processing or inputs to fork choice. So this wouldn't really change the implementation for us. And I think the only reason would be to make it so that the state transition function doesn't have a different I guess output based on a time component, which would be when the data availability check expires. That's why I think keeping it just in fork choice, it's meant to.
00:18:57.780 - 00:18:58.096, Speaker A: Have.
00:18:58.118 - 00:19:04.530, Speaker B: The time component bottled to fork choice. But yeah, it's my two.
00:19:07.700 - 00:19:27.210, Speaker G: Think. Yeah. Just for that point and this point that Danny already mentioned, it is worth it to move it to fork choice. I'm just not quite 100% sure if we may need to make some tweaks to the messaging itself to accommodate that. Yeah, we'll discuss more.
00:19:35.050 - 00:20:14.982, Speaker A: Okay, let's keep that conversation on the issue there and then. Last spec change was 31 74. Yeah. How do we deal with sidecar when there's no blobs or range requests? Terrence, you open that in some conversation with Mophie on this. And again, Mophie, you're the last. Yeah, Terrence, give a quick recap. And then Mophie, I thought you're also the last commenter on this.
00:20:14.982 - 00:20:15.990, Speaker A: Yeah, for sure.
00:20:16.060 - 00:20:50.354, Speaker H: Yeah, I can give a quick intro on this. So the issues around how do we treat blob, that's not missing, but zero. Right? Because when you have zero blob sidecar, it's about 100 bytes. So we define what the respond behavior should be. So currently it's that if you're up here, you must respond to it. So this pr updated to, okay, you basically may respond to it based on the issue. There's few points that's brought up.
00:20:50.354 - 00:21:04.098, Speaker H: The first one is the implementation complexity. I don't think there's much implementation complexity between the must and the may, just because you can always check if there's a KCG commitment on the block itself.
00:21:04.184 - 00:21:04.674, Speaker A: Right.
00:21:04.792 - 00:21:50.498, Speaker H: And then the second point that brought up is that how do we treat the rate limiter? Because, okay, if there's 100 bytes of the blobside card, I don't think we should incur much cost to it. And I know every client treat the rate dimeter differently as well, so that's definitely something to discuss. And then the third point is brought up. It's just that it is simpler from the spec perspective because this blobsack card does use the data gas as one. And then it also does exist at the gossip type. So it does make it nicer from the specs perspective. Just basically treat them as must.
00:21:50.498 - 00:21:57.480, Speaker H: Yeah, that's a quick intro, mostly. Feel free to add on or anyone else to add on if I missed something.
00:22:00.890 - 00:22:03.270, Speaker G: I think you got it. Thanks, Terrence.
00:22:04.810 - 00:22:19.520, Speaker H: So, yeah, so moving forward, I don't think we can come to a conclusion here, just because Danny is not here, but Danny has a few group points and Mophie has a few group points. So I think we'll just keep continue on the issue itself.
00:22:20.930 - 00:22:28.320, Speaker A: Okay, sounds good. And is this something we need to resolve for this spec release on Friday as well?
00:22:28.690 - 00:22:46.900, Speaker H: No, because, no, I don't think so. This is not like a consensus breaking change, just you can always adjust the behavior on the fly and it turns out this has become the default behavior for deafnet three. But for the follow up deaf net, we can just keep an eye on it.
00:22:47.350 - 00:23:15.854, Speaker A: Okay, sounds good. Okay. And there was actually one more sort of spec issue that I missed from Xiaoi. She left actually the issues originally from Yasek. But Xiawei, you had a comment on the agenda today that if we disable this, there's something else in the spec that we need to revert. Do you want to give a quick summary there?
00:23:16.052 - 00:24:14.210, Speaker I: Yes. So in this new capella change, we will update the process epoch function by we will replace the process historical roots update function with another new function called process historical summaries update. So if void four implementers want to disable this change, then we have to rewrite the process EPA function in voice as well. If you can see the pr that this function is actually just a lines of simple code in my opinion. And so I would like to check.
00:24:14.280 - 00:24:14.900, Speaker A: If.
00:24:17.670 - 00:24:28.200, Speaker I: Really want to disable it, or we can just include it to the definite fold as well.
00:24:29.210 - 00:24:56.414, Speaker H: So I think there's two parts to it. I think the first part is the beacon state itself. So the beacon state has to change, meaning that if today we stub it out, it's still consensus breaking, because we need to figure out whether to include this object in the bishop state or not. The second part is okay, at the process epoch, do we stop it out, just return now, or do we actually process it?
00:24:56.452 - 00:24:56.846, Speaker A: Right?
00:24:56.948 - 00:25:30.060, Speaker H: I think for the first part, yeah, I think it would be nice to follow whatever the behavior withdraws, for example, withdraw, we actually have it in the beach and state. So if withdrawals in the beach state, then yes, my hope is to have this in the beach and state. And the second part is that whatever withdrawal is doing just currently withdraw is getting stuff out. So we can also stuff this out as well. But if we were to include withdrawal, we also should include this as well. So that's my $0.02. Not sure if people agree with me.
00:25:33.230 - 00:25:55.090, Speaker G: Yeah, makes sense. Particularly the last part. What I don't quite understand is this is regarding withdrawals with capella, shouldn't this only come into effect the historical summaries update. If and only if there's a non zero amount of withdrawals to be processed.
00:25:59.190 - 00:26:08.150, Speaker I: The historical batch or summary update will happen in every EPAC processing automatically.
00:26:09.130 - 00:26:18.570, Speaker G: I see. Okay, so it does seem unrelated ish to withdrawals even though it's occurring in Capella.
00:26:19.950 - 00:26:20.700, Speaker I: Yes.
00:26:21.150 - 00:26:39.400, Speaker G: Okay. It seems simple enough, like the function change. So I'm fine with not stubbing this and just including this for the next Devnet testing.
00:26:41.260 - 00:27:14.310, Speaker H: I guess my concern is just like we need better tracking, otherwise it becomes pretty confusing on just what is enabled and what is disabled. So my preference is just either enable everything in capella or disable everything in capella. But if we have a better tracking then it's fine with me as well. But yeah, my main concern is just that there's like six other clients and then the less variable the better.
00:27:15.480 - 00:27:28.216, Speaker G: Yeah, that makes sense. I think this is probably also a segue into there's like another issue you might have opened, Terrence, in enabling withdrawals in IP four for four.
00:27:28.398 - 00:27:29.176, Speaker A: Yeah.
00:27:29.358 - 00:27:33.948, Speaker G: Perhaps we can discuss both what to do based on both of them.
00:27:34.114 - 00:27:42.190, Speaker H: Right. So I open the issue right now, the issues that I'm seeing, or I see we're seeing is just like.
00:27:44.020 - 00:27:44.336, Speaker A: For.
00:27:44.358 - 00:27:51.968, Speaker H: The last month withdrawal has been making great progress and some of the progress happened after some consensus breaking changes.
00:27:52.054 - 00:27:52.690, Speaker A: Right.
00:27:54.100 - 00:28:36.160, Speaker H: Currently for definite three, we are using the withdrawal spec that's a few weeks old and since then there has been few capella changes. They are consistently breaking. For example, they added a culis approach and they added bonded validators count as well. So it becomes harder for us to rebase code on top of capella because ideally I want to use the latest code. And so right now withdraw from my point of view. It's in a pretty good state. I think if we look at a discord conversation there has been few successful interrupt testnet and I think they're getting pretty serious right now.
00:28:36.160 - 00:29:21.070, Speaker H: So given the withdrawal spec is in a pretty good state, I added a proposal to rebase 4844 on the latest capella and Danny added a few viewpoints in the PM discussion as well. Basically they are releasing a release on Friday and then the Friday release will be used on the subsequent testnet test team and then. So therefore for the next 44 testnet we can perhaps target that as well or we can target that for the capella functionality. Yeah, so that's basically it.
00:29:26.260 - 00:30:04.430, Speaker B: Yeah. I think we might be getting to the point where enabling the functionality entirely is just simpler than whatever difficulty we might have withdrawals change, which there might not even be any. I don't know. But yeah, especially with what Xiaoi brought up. I think Terrence is right that we should either enable everything, including that component, or disable that component as well. So I think generally I'd be in favor of just enabling everything.
00:30:09.170 - 00:30:11.630, Speaker G: All right, the implementers have spoken.
00:30:12.290 - 00:30:13.280, Speaker A: Let's do.
00:30:16.530 - 00:30:27.540, Speaker B: Oh, should we also talk about the block value that Terrence brought up? I think whether we want to include that in the next death note as well.
00:30:28.950 - 00:30:40.630, Speaker H: Yeah, I think my vote is yes for that. Just because that makes no sense to basically rebase the latest capella but doesn't have block value. I'm curious if there's more thoughts.
00:30:42.250 - 00:30:44.040, Speaker B: I'm on the same page.
00:30:50.110 - 00:31:26.858, Speaker A: Great. And again, I think there's like two different conversations also happening in the chat just for the rebeising capella. Obviously this is like on the CL side on the EL. This would mean we're Beijing on Shanghai where we want to have all of Shanghai. Basically I don't think there's as much interactions beyond withdrawals but yeah, I think that would be the equivalent rate. Yeah. From the execution point of so on.
00:31:26.864 - 00:31:40.880, Speaker F: The yield, I believe there isn't really much change because if withdrawals are not provided, then nothing is basically added to the state. So it's very simple as legal site.
00:31:43.970 - 00:32:24.490, Speaker B: Withdrawals seem important for eap. Three, four four because it introduces timestamp based working and everything else is not so connected to this eap. Right. So if we could include just withdrawals as a base layer for eight four four, it could be enough. Probably EOF and other stuff looks like okay with that, but it doesn't look like very needed for CCIP.
00:32:30.290 - 00:32:46.070, Speaker E: Tim, should we wait for the awkwardfs call to get UF stability information? Yeah, we can also not include any of the UF eips for now, but only stick to the withdrawals functionality.
00:32:47.610 - 00:33:25.060, Speaker A: Yeah. And I think it'd be good to see from all the client teams like devs where EOF is at before making a call on that. But on the CL side, it seems like doing your full rebase on Capella and having that for basically the next Devnet is what we're going for. And the next Devnet I guess being the one at interrupt in about three weeks now. Okay.
00:33:27.190 - 00:33:32.450, Speaker F: Just to clarify, is the next Devnet going to have block summaries?
00:33:36.090 - 00:33:44.910, Speaker A: Yeah, that sounds about right. Cool.
00:33:44.980 - 00:33:50.910, Speaker I: So full capella on Friday release.
00:33:58.940 - 00:34:01.210, Speaker A: Did you say four or full? Sorry.
00:34:04.380 - 00:34:12.540, Speaker I: Everything in Capella will be included to the four for four in the next release.
00:34:13.540 - 00:34:20.530, Speaker A: And do we think we can do that change on Friday? Because I know on Terrence's pr you and.
00:34:23.380 - 00:34:28.404, Speaker I: Mean it will need some updates in the test so I can make.
00:34:28.442 - 00:35:02.560, Speaker A: It before Friday, I think. Okay, awesome. That would be great. And we should tell Danny about this. I'll send him a message after anything else on the specs. Okay. And then the next point was like about Devnet three.
00:35:02.560 - 00:35:44.390, Speaker A: I think it's sort of getting an update from the client teams. But the other point I wanted to talk about was like, how to rebase on Capella and Terence, your table that you have there. But I think based on this conversation, basically all of those features that are not in devnet three would be for devnet four. And we aim to have devnet four kind of on the master capella. Is that everyone's understanding? Yes. Okay. And then, yeah, I guess for Devnet three occurs to hear about the different client teams where we're at, and if there's any issues that we've run into.
00:35:48.130 - 00:36:20.186, Speaker H: I can give a quick summary. So on the prism side, overall, I'm very pleased with the net because of its successful. I mean, it's mostly because we have been finding many issues. We've been fixing it mostly on the PPP side. So I want to give a special shout out to mofi for setting it up and then keeping it alive. So we fixed a few issues regarding just like how do we handle p.
00:36:20.208 - 00:36:20.940, Speaker A: Two, p.
00:36:23.310 - 00:36:49.234, Speaker H: Trimming and stuff like that. And then we're currently fixing the rate limiter. So currently, even for blobs, they are zero. We don't really score the peer correctly, I think just because a lot of them are getting dropped during syncing. So we're fixing that. But overall I'm very happy because I'm happy we did it before New Year's just because we actually get to spend.
00:36:49.272 - 00:36:50.420, Speaker A: More time on it.
00:36:55.260 - 00:37:02.548, Speaker B: So for Lighthouse, we were able to sync to wherever the testnet was stalled.
00:37:02.724 - 00:37:03.336, Speaker E: Sounds good.
00:37:03.358 - 00:37:36.980, Speaker B: That means we're validating the blocks, whoever prism is producing them, but still be interested in if we could, I guess we can on this testnet because I don't think deposits are enabled, but I'd be interested in testing out like lighthouse proposals if other clients validate them or validate lighthouse blocks. And then also just like, yeah, I don't know, I guess that's the main component.
00:37:41.760 - 00:38:03.940, Speaker F: As an update, Lodestar has been able to successfully swing the definite tree. But what remains untested, as Lighthouse has mentioned, is proposals and the gossip. So I think that is something we need to address in next devnet so that we can do multi client devnet, hopefully.
00:38:15.120 - 00:38:59.130, Speaker B: As for Nethermind, we tested mostly with prism, tried to synchronize and got quite high numbers of blocks. We placed some forks, looks like on Devnet 3.2. Yeah, but it looks like it's usual state for now and we are trying to integrate with cluster to run with them and we'll try with Lighthouse this week. So that's the state.
00:39:05.150 - 00:39:16.190, Speaker C: I'm continuing to hack on. Aragon got a little blocked by that hashing issue that we discussed earlier, but now that that's resolved I can continue making progress.
00:39:23.690 - 00:39:28.950, Speaker F: Also to update for Ethereum. JS also has been able to successfully sync the devnet.
00:39:41.140 - 00:40:07.120, Speaker A: I think that's everyone. Anyone we missed. Okay. And yeah, I guess it probably makes sense to just keep working on Devnet three for the next couple of weeks and then start moving to Devnet four as we get closer to interop. Does that make sense for two people?
00:40:09.810 - 00:40:11.120, Speaker G: Yeah, makes sense.
00:40:12.210 - 00:40:39.240, Speaker A: Cool. Sweet. Last thing I had on the agenda, there were a couple of testing prs that were discussed on the last call. I was just wondering if people had any updates on those. So I know Mario Vega had a pr to hive. Frodo, you also had a pr to hive. Actually Mario and Proto basically had some pr with the testing front.
00:40:39.240 - 00:40:42.460, Speaker A: Any updates there? Anything to share?
00:40:44.830 - 00:41:14.530, Speaker E: Well, not directly for it for four, but for Capella. The tooling that's used in Hive and outside of Hive as well as the e two testnet Genesis tool have been updated with Capella support. Not with the change that's coming Friday. However, I will update that as well. And then this week I'm working on the four eight for four support so we can start four for four testnets at the four eight for four state rather than going through the forks.
00:41:19.590 - 00:41:35.350, Speaker G: Related to that, maybe. Terrence, you can answer this. Is prism able to start directly from Capella? Use a capella like state as its genesis?
00:41:36.250 - 00:41:47.420, Speaker H: Yeah, sorry it took so long, but I think we got it working before the holiday and I think that's what they have been using for the withdrawal test net as of today.
00:41:48.830 - 00:41:52.730, Speaker B: Yeah, that's what we're using for the withdrawal test net on all clients.
00:41:54.110 - 00:41:56.094, Speaker G: That is good news. Awesome.
00:41:56.292 - 00:43:06.580, Speaker A: Thank you. Anything else on testing? Okay, I don't know that there's been any other updates on the large block spam tests either. I know Giorgio posted in the chat wondering if we wanted to do another round of these. Any updates there? Okay, if not, I'll follow up async and see what the best next step is there. On the pre compiled benchmarking. I know on the last call there were some updates saying that it seemed like Nethermind, I believe, was also sort of converging around the 50k gas cost as being reasonable. Any other changes on that front since the last call?
00:43:13.340 - 00:43:34.370, Speaker B: Another man tested on some different machines and. Well, it is different, but is near 50,000. Guess probably we need more like five or 10,000 more of this.
00:43:37.300 - 00:43:50.420, Speaker A: Okay, yeah. In that case, let's wait a bit more like. Let's continue. The benchmark. Is there still work happening on the libraries themselves, or are they pretty stable?
00:43:56.230 - 00:44:05.330, Speaker D: Looks stable, sort of stable. I think there is like one or two prs that need to be done, but I think they're stabilized.
00:44:06.070 - 00:44:41.220, Speaker A: Okay, so stable enough that we don't expect some big optimization? Because I know when we talked about this a month or two, or maybe like more like six weeks now with the holidays, we talked about this like six weeks ago. There's a lot of talk about, like, we might want to optimize the libraries before doing too much benchmarking. And so does it feel like we're in a good spot now with regards to the library? And it actually makes sense to maybe get like the four El clients benchmarked and make sure we have a rough target for the gas price.
00:44:43.910 - 00:44:57.190, Speaker D: Yeah, I don't know of any pre compile optimization efforts going on right now. I mean, there are potentially avenues to doing that, but I don't think there is anything shorter.
00:45:00.970 - 00:45:40.302, Speaker A: And I guess I assume Aragon will be pretty similar to geth in terms of the implementation. Beisu, where are things at with you guys with regards to the pre compile? Are you in a spot where having some folks benchmarking it would be helpful or. Not quite. Not quite. The pr is open. We're waiting on it to be merged, but that should be done shortly. And then after that we would be able to maybe, yeah, in the next week or two, as these get kind of finalized and merged, we can then run some benchmarks, I think comparing at least get based to Nethermind if possible, Aragon.
00:45:40.302 - 00:46:22.372, Speaker A: And then we'll have a good idea of what the target for the gas price. But at least it seems like it shouldn't be like a massive change. So if we go from 50 to 60k, that's not the end of the world. Anything else anyone wanted to chat about? Okay, well, yeah, I guess it. So, yeah. Thanks everyone. See you all on lockware devs.
00:46:22.372 - 00:46:29.510, Speaker A: And we'll have another one of these calls next week. Bye. Thanks.

00:00:00.120 - 00:00:39.204, Speaker A: Now welcome to EOF call number 46. I think our agenda is client updates, compiler updates, spec updates, testing updates, and any other items. If there's any other items, put them in the chat. I guess we'll go ahead and start. As far as client updates, same status as last week, nothing too exciting. That's changed. Mostly writing tests.
00:00:39.204 - 00:00:49.264, Speaker A: So let's see who else we have on the call. Never mind. Do you have any status updates you'd like to share? Not really.
00:00:49.304 - 00:00:50.644, Speaker B: Same as last week.
00:00:52.384 - 00:01:11.114, Speaker A: Okay, Diego's, I think he's Basu is who he's calling for. Hi Diego. That's all of the clients we have online and EvM one. Any updates?
00:01:12.334 - 00:01:36.646, Speaker C: Yeah, we still have three prs in progress. One is init container validation. This is. It works. Basically we are writing more tests, like covering it with tests is kind of an effort. There are like many combinations of opcodes and opcodes that reference subcontainers. So this is in progress.
00:01:36.646 - 00:01:51.374, Speaker C: Another thing is creation transaction. This also progressed somewhat, I think maybe close to completion and the removal of TX crate. This is easy, but also requires test updating. So yeah, almost finished.
00:01:51.714 - 00:01:54.574, Speaker A: Okay. Rev ref.
00:01:55.194 - 00:02:18.674, Speaker D: Yeah, hello. From my side I removed ts create and added missing validation for call f and jump f. What's missing is like new creator section but this needs to be specced out and I need to check while what test I'm running. I run a validation but like state tests.
00:02:19.534 - 00:02:22.194, Speaker A: Yeah, yeah, good testing.
00:02:22.534 - 00:02:24.034, Speaker D: Yeah, that should be it.
00:02:24.694 - 00:02:28.550, Speaker E: I think that the spec for the create transaction is there, right?
00:02:28.662 - 00:02:31.718, Speaker D: Yeah, I need to implement it and look at it.
00:02:31.846 - 00:02:37.398, Speaker E: Okay, yeah, but just to make sure I also understand where we are.
00:02:37.526 - 00:03:05.914, Speaker A: Okay. I don't see Geth or Ethereum J s. Is there any other clients we're missing? I think that's it. Or eels. Okay, so compiler updates, solidity is not on the call. Charles, any updates for Viper? Go ahead, Charles.
00:03:07.134 - 00:03:17.354, Speaker B: No updates. But if uf is like kind of getting finalized, then we'll schedule it. I think we can schedule a proof of concept for like the next month or something.
00:03:18.494 - 00:03:20.470, Speaker A: Excellent, excellent, that's good.
00:03:20.582 - 00:03:44.374, Speaker F: Yeah. And regarding solidity, I hope I finished the implementation of the prototype in based on the, on the, on the Shanghai version implemented by solidity team today I contact also Daniel regarding this. He also had a couple of, couple of hints for me.
00:03:45.274 - 00:03:45.674, Speaker E: Yeah.
00:03:45.714 - 00:04:20.284, Speaker F: So basically it's going well. I implemented new creation, new calls, x calls and a couple of new things like jump f returning functions. It looks quite well regarding the process. How is it going? But we'll see. I will try to finally also generate some matrix for the cold size and gas consumption and comparison between.
00:04:27.764 - 00:04:28.356, Speaker G: Hello.
00:04:28.460 - 00:04:35.064, Speaker A: For solidity and for Viper. This gives us a good opportunity to see actual hard production numbers.
00:04:36.124 - 00:04:39.144, Speaker F: Yeah, I think we have some broad connection problems.
00:04:39.444 - 00:04:43.984, Speaker G: Did you hear you cut off for a second, like 10 seconds?
00:04:44.364 - 00:04:50.572, Speaker A: Sorry. East african stability, it's quite good, but.
00:04:50.588 - 00:04:54.994, Speaker G: It'S just, well, like the last bit of Radek sentence. What cut off?
00:04:55.894 - 00:05:03.006, Speaker F: We had to get rid of two zebras coming here. Sorry.
00:05:03.150 - 00:05:07.366, Speaker A: Okay. Um. So, yeah, that, that's good news.
00:05:07.430 - 00:05:40.244, Speaker B: We can point out the production numbers are like. I mean, it is a proof of concept and like, it's kind of a new architecture, so we're not. So, like, there's a kind of long tail of optimizations that probably need to be taken. So proof of concept numbers are, I'd say indicative, but it's also like when, when we're learning to work with a new architecture, it's also like there's a kind of learning or adaptation curve.
00:05:41.144 - 00:05:42.568, Speaker E: Yeah, that's for sure.
00:05:42.616 - 00:06:00.344, Speaker F: And I hope this more advanced optimization using the new opcodes for EOF, for EVM will be applied by solidity team, not by me, but they are much more, they have much more expertise in this matter.
00:06:01.684 - 00:06:06.544, Speaker G: And I guess we're not reaching the benefits of the relaxed stack validation yet, right?
00:06:07.844 - 00:06:11.884, Speaker B: No, those are pretty soon, actually.
00:06:11.964 - 00:06:32.884, Speaker F: I implemented the non returning function already, and it probably will help a little with a little bit with the stack validation also. And an unnecessary duplication, but not sure yet, actually. So I will let you know till the end of this week.
00:06:37.504 - 00:06:38.284, Speaker A: Cool.
00:06:40.384 - 00:07:14.374, Speaker B: Kind of at the intersection of testing and compiler updates, like, is there. I was wondering if there's any way to jerry rig execution tests, not just to, because the output gas numbers. Right, like those have to be correct. But is there any way to like, turn execution tests into benchmarks so we can see how much time is spent in each opcode or each stage, for instance.
00:07:16.474 - 00:07:27.922, Speaker A: Yeah. So hold that thought for just a tiny moment. We'll come to that with testing updates, and I think we'll be there quick because do we have any spec updates, anything? Should we. Let's go inside.
00:07:28.018 - 00:07:28.694, Speaker E: Yeah.
00:07:31.874 - 00:07:45.134, Speaker A: This is a good idea. Five minutes ago. There's a door right here. Yeah, maybe Illinois. This poor person here.
00:07:45.214 - 00:07:49.554, Speaker G: But let us know when you're back and safe inside.
00:07:52.214 - 00:07:53.434, Speaker A: I think we're safe.
00:07:55.214 - 00:07:59.518, Speaker G: Okay. In specific topic.
00:07:59.566 - 00:08:04.458, Speaker A: Right, so spec updates, there are still.
00:08:04.506 - 00:08:07.010, Speaker E: Some, some items to finish out, right?
00:08:07.122 - 00:08:12.466, Speaker A: Oh yeah. So return data, load, copy, get resolution on that?
00:08:12.570 - 00:08:13.254, Speaker E: Yes.
00:08:14.994 - 00:08:18.134, Speaker A: We don't have any resolution on that, no.
00:08:20.674 - 00:08:30.550, Speaker E: That was one thing. Init code validation, I think it's not merged yet, but we agree we want it.
00:08:30.622 - 00:08:35.566, Speaker C: Yeah. I would appreciate review on the implementation.
00:08:35.630 - 00:08:45.954, Speaker E: Yeah, sure. Okay. And there's one item that popped out, which is this block hash instruction.
00:08:46.254 - 00:08:47.194, Speaker A: Oh yeah.
00:08:47.574 - 00:09:00.812, Speaker E: And I actually started writing the spec update, which is like one word addition. But I think I want to have pull requests for both eaps and mega specs so at least we have, can have discussions there.
00:09:00.868 - 00:09:08.676, Speaker D: The last change on that AIP is like, will contain same behavior. Yeah.
00:09:08.860 - 00:09:09.436, Speaker E: Okay.
00:09:09.500 - 00:09:26.604, Speaker D: And we just like flush the block hashes to the state, and the next fork after the probe will enable block hash opcode that patches those states. So it's like two steps.
00:09:28.304 - 00:09:36.632, Speaker A: Yeah. So that gets tricky. If we ban it, then solidity might need to put in the address of the contract to do the reading and set that up.
00:09:36.688 - 00:09:37.444, Speaker E: Okay.
00:09:38.584 - 00:09:42.320, Speaker A: So yeah, let's think. Huh.
00:09:42.512 - 00:09:44.124, Speaker B: Why is block hash banned?
00:09:44.724 - 00:10:34.884, Speaker A: So we were having discussions about EIP 29 35. This is something being done for Verkl because they need to have the block witnesses of the hashes available in an easy format. So we're putting them in a new contract like we did with the beacon chain routes. But then there are some design discussions going back and forth, like do we expand block hash to 8000k, do we preload everything at the transition and do we alter the gas? So one of the things that came to mind is if we're trying to motivate people to use the contract instead of the opcode, we could just ban the opcode in Evm one and make everyone use the contract. Since you can get back in with the current setup, the contract only gets, the contract gets you a full day's worth of hashes, whereas the opcode gets you like an hour or so.
00:10:36.844 - 00:10:55.424, Speaker B: For what it's worth, I think banning the opcode is not a problem from the compiler point of view, because precompiles are really easy to access from user code. So it's like the compiler doesn't even need to implement it anymore.
00:10:57.364 - 00:11:07.600, Speaker E: I mean user, we need to maintain this because it might not be available on every chain and it might have different address on chain.
00:11:07.712 - 00:11:09.604, Speaker A: Oh yes.
00:11:10.264 - 00:11:16.208, Speaker E: If some like project really needs that, it's doable, definitely. So you will still get that because.
00:11:16.296 - 00:11:17.984, Speaker D: Yeah, I do have it for the.
00:11:18.104 - 00:11:31.472, Speaker E: But. Yeah, but like this portable option then like to use the block hash if you only need like previous block hash. Right. So like the instruction is more portable. Yeah, in this sense, because already, it's already everywhere.
00:11:31.648 - 00:11:46.848, Speaker A: So I'm leaning towards don't ban it. Then what? I'm leaning towards don't ban it. I mean we can discuss it fully next week, but I was thinking of l two s. If they deploy EOF, but they don't deploy the beacon contract, the system contracts, then we take away any block hash opportunity.
00:11:46.976 - 00:11:48.496, Speaker E: Yeah, yeah.
00:11:48.680 - 00:11:52.844, Speaker A: So I'm leaning towards not banning, but. Well, these mosquitoes are crazy.
00:11:54.964 - 00:11:57.024, Speaker B: Maybe everything should be a precompile.
00:11:58.044 - 00:12:22.544, Speaker A: I actually think it should be for anything going to. Going to the blockchain system, but. Yeah, but we'll add that to the spec and we'll talk about it online and more thoroughly next week and finalize the decision, hopefully. So testing updates, you had mentioned benchmarking some of these items, right?
00:12:24.004 - 00:12:45.584, Speaker B: Yes. And that will also help with like any other time that we want to update, you know, the pricing tables. Like it's always like, oh, do you have data for this? And well, if they were just like part of the execution test, they would be like free data.
00:12:46.534 - 00:13:09.394, Speaker A: Right. So basically at least can use the state tests to get some benchmarking. That's what I've been using to gauge performance. And any state test in theory could be used on any of the clients. If you can get the timing output, you can get the overhead removed from the performance.
00:13:09.974 - 00:13:32.584, Speaker B: Yeah, exactly. Like if there is some like standardized way we can output or even like, doesn't even need to be that standard, but like just like get total time spent in a test. Test without, you know, set up overhead and then test spent time spent in each opcode would be really nice.
00:13:34.604 - 00:13:53.894, Speaker A: Yeah, that's a big question to address, but that was actually something that was brought up not for repricing the gas table, but just to make sure that we don't have any major performance regressions in the meeting we had yesterday.
00:13:54.994 - 00:13:56.814, Speaker B: I mean it's the same thing, right?
00:13:57.434 - 00:14:01.154, Speaker A: It is the same ballpark. Yeah, it's the same kind of like.
00:14:01.234 - 00:14:07.464, Speaker B: Testing regression is like the same thing. Same question as is gas priced accurately.
00:14:09.204 - 00:14:09.944, Speaker A: Right.
00:14:11.044 - 00:14:20.452, Speaker E: So yeah, I don't think we can. We can go into instruction level because I don't think we have any infrastructure even for legacy VM for that.
00:14:20.628 - 00:14:21.344, Speaker A: No.
00:14:22.004 - 00:14:55.738, Speaker E: So I think what would be probably easier and more, more meaningful is to have example of the same code done for UF and for legacy. So maybe solidity can help here. If we can. I have some benchmarks that I are generated by. By solidity. We can pick something else. But yeah, I think that's more doable than trying to benchmark individual instructions because they actually change.
00:14:55.738 - 00:15:19.174, Speaker E: So much. And I think EDM's actually don't really also exploit this EOF feature so much right now. At least we don't, we don't, we don't skip the stack validation, I believe, runtime yet because it's like there wasn't really points to doing so.
00:15:21.234 - 00:15:22.866, Speaker A: Right, so.
00:15:22.890 - 00:15:23.418, Speaker E: Yeah, definitely.
00:15:23.466 - 00:15:31.964, Speaker B: Yeah. And that's actually a good point because like if UF code gets jetted or something then like you can't even measure time spent in each other.
00:15:32.384 - 00:15:44.920, Speaker E: I think I did benchmarks before by just removing these checks and then you can. But it's like you get like 510 percent performance. I can repeat that. But yeah, it's kind of, I mean.
00:15:45.072 - 00:15:55.352, Speaker B: I think it would be super useful to have that level of tracing. But also if we have the time for each test, like we can actually use like statistics to like.
00:15:55.528 - 00:16:18.564, Speaker E: Yeah, but the test, the problem with the test is like we have tests for legacy and tests for UF and they are different tests. So you don't compare the same workload. You would need to have a test that is kind of doing the same semantic for legacy, for UF. And I think we don't have it. Although we have some idea how to do it maybe, but it's like probably kind of longer term.
00:16:19.304 - 00:16:31.364, Speaker B: Yeah, but what I'm saying is like you can actually use like statistics. Like if you have, you know, a set of tests, like 10,000 tests and you know what opcodes are in them and you know how long they take, you can like use regression to find.
00:16:33.704 - 00:16:36.208, Speaker E: What kind of instructions were executed and.
00:16:36.336 - 00:16:43.088, Speaker A: Okay, like if you have just 10,000 pushes and then the next one, that's 10,000 ads. Yeah.
00:16:43.136 - 00:16:45.604, Speaker B: You just need the trace. The PC trace.
00:16:47.144 - 00:16:49.644, Speaker A: Yeah. Because you could count how many of each are in there.
00:16:50.164 - 00:17:04.956, Speaker E: Yeah, I know what you mean. Yeah. Still not sure that actually the state tests are good. Good thing for that. But we can try because they mostly execute calls because that's the biggest.
00:17:05.020 - 00:17:08.064, Speaker A: You have the transaction overhead. That would be in every transaction.
00:17:09.404 - 00:17:11.824, Speaker G: Could the gas cost estimator approach help?
00:17:13.204 - 00:17:14.144, Speaker A: The what?
00:17:14.924 - 00:17:17.224, Speaker G: The one that we've done with IMap.
00:17:18.713 - 00:17:27.173, Speaker E: Yeah, I'm not sure because it's also like focus on single instruction and they doesn't change actually so much.
00:17:27.553 - 00:17:41.013, Speaker G: So you could compare, I don't know, jump to our jump and so forth. That would be a, that would be a like how do you say, a valid comparison.
00:17:42.153 - 00:17:49.644, Speaker E: Yeah, I mean if you can produce like the full report out of it, I think. Yes, but I'm sure how much work it is.
00:17:50.064 - 00:17:54.764, Speaker B: But yeah, I mean, we just need some industrialized way of doing benchmarking.
00:17:55.984 - 00:18:07.256, Speaker G: That's kind of like. That's kind of like it, but. But it's. I don't know what's the status of how easy would be to reproduce this, these calculations? It's been a couple of years.
00:18:07.440 - 00:18:13.204, Speaker E: Well, I think they're actually working on the, like, fourth report right now.
00:18:14.504 - 00:18:15.120, Speaker A: Fourth?
00:18:15.192 - 00:18:16.136, Speaker G: Oh, Jason.
00:18:16.320 - 00:18:20.124, Speaker E: All right, somewhat like next it. I think it's in progress.
00:18:22.184 - 00:18:26.444, Speaker G: I lost touch of what's changing Nash anymore.
00:18:27.504 - 00:18:33.360, Speaker E: They want to just add more. More clients. And I'm not sure what the scope is, but we can check with.
00:18:33.512 - 00:18:47.434, Speaker G: I mean, for this context, even one client would probably be. Makes sense because you don't want to compare it across clients, but you want to compare uf versus legacy, so it's kind of easier.
00:18:49.414 - 00:19:03.314, Speaker B: Yeah. I think even if you can run like a client in benchmark mode and it just gives you timings for all the state tests, I think that is already, like, super useful.
00:19:05.054 - 00:19:09.034, Speaker A: Because at the end of the day, that's the timing that matters is what's run in production.
00:19:09.454 - 00:19:10.234, Speaker B: Yeah.
00:19:13.094 - 00:19:13.662, Speaker A: Okay.
00:19:13.718 - 00:19:33.894, Speaker B: And that also gives you, like, really, like Pavel pointed out, like, I think it's Pablo, but I think, like, that's like, the cases in the state test are like really weird, but that's like, also good because you want to benchmark the kind of weird cases.
00:19:39.194 - 00:20:23.744, Speaker A: Yeah. On the subject of state tests, we've been aggregating some of the execution spec tests together. So as mentioned last week, the future of tests is execution spec tests, not ethereum tests. So we've been writing them all in, what you call it in python. We've aggregated them here in this Ipsalon execution spec test repository and includes all of the prs that are in process. Because it takes a while for the testing team to review it, they have some very strong opinions about how their python should look. So this is just an aggregate of what we have so far.
00:20:23.744 - 00:20:26.004, Speaker A: Where's Prague?
00:20:27.864 - 00:20:33.120, Speaker E: Oh, you need to change the branch. So the main branch is Uf main.
00:20:33.192 - 00:20:33.960, Speaker A: Got it.
00:20:34.072 - 00:20:39.524, Speaker E: I guess I can make it the main one on the repo. What? I didn't notice this.
00:20:40.704 - 00:20:52.472, Speaker A: Okay. It's probably, I don't know, we could just change the default, but here we've got the aggregate of the test we have. This isn't all of them, is it? Oh, yes.
00:20:52.528 - 00:20:54.804, Speaker E: Now it's under this, by the way.
00:20:55.224 - 00:21:11.444, Speaker A: So I need to do some of my changes to get these in. So there's also going to be a layout change in the test directory. But I think the more exciting part, rather than having to run the python, is we're also publishing how far back filled.
00:21:15.264 - 00:21:17.602, Speaker E: It's just the artifact of the release.
00:21:17.768 - 00:21:57.624, Speaker A: Other artifacts. Okay. They're publishing the fixtures that include all the state tests. So you can just throw these into your clients implementation and make sure you can see where things differ. One thing that we're going to see out of this, I know Bayesu's got some differences in gas costs that only show up when you run the fixtures and compare against other clients. Because we haven't written any of the gas cost tests to gauge the gas because there's no gas op code. So the one feature that we put in there is biting us and testing.
00:21:57.624 - 00:22:26.424, Speaker A: But I think we can figure out how to make it work. We can just hard code the values. I mean, we know how much it's going to cost, hold execution wise in the test. We can just test it afterwards. It's not going to be too variable. Okay. Any other questions about tests? Any updates? Going once, going twice.
00:22:26.424 - 00:23:00.314, Speaker A: So other items. This is probably worth the discussion. We want to talk about the breakout room. So things are looking much more positive for getting EOF in a Prague. We were in a room with all of the other clients. It wasn't unanimous, but the majority of clients want to see EOf much sooner rather than later. And if it depends on some of the scheduling with Prague, there's a discussion needs to be had about how big Prague is.
00:23:00.314 - 00:24:25.812, Speaker A: And depending upon what's in electra or not, some people think that we could just cut what we have now and ship Prague and start scheduling test nets in a month. If that's the case, EOF can't make Prague, and in that case there is support for then doing another fork after that. That includes EOF before Verkle, which was contentious. But if Prague goes longer, and there's some concern that the consensus layer teams aren't as ready to start scheduling test nets next month, we get more time, then there's room for EOf to come in. So the Mo that the client teams are working on is just implement EOF and we'll figure out which work it goes in when we decide to close the doors on Prague, and whether it goes into Prague or into a fork after Prague, whether we call it Osaka and move stuff to Amsterdam, or whether we create a new fork name in between them, is the discussions we had. But there's also the distinct possibility that Prague might ship Q four this year, which means we totally got room to get EOF in, and there's some pretty broad support amongst all of the clients in the meeting. Yeah, and that's, I think, probably what we could say about the meeting, for the most part.
00:24:25.812 - 00:24:41.964, Speaker A: There'll be more on the call next week on the AC de, so that's, you know, tune in, bring some popcorn. The question is, will it be more or less contentious than 7702?
00:24:44.344 - 00:24:54.806, Speaker E: Yeah, I actually noticed that this new update to 7702 fireworks, which it's less compatible with that we've hoped for.
00:24:54.990 - 00:24:55.558, Speaker A: Yeah.
00:24:55.646 - 00:24:58.854, Speaker E: But. Yeah, that's kind of outside of that.
00:24:58.974 - 00:25:27.034, Speaker A: That's not the issue I have, but I'm willing to get run over it if I can just have my say on, you know, make my statement, so when things go bad, I can say, I told you so, but we'll see. Okay. Um, yeah, we're running this meeting kind of quick today. Um, is there anything that. Do I have the chat window open? Nobody's been chatting me, have they? Um. Gas cost estimator.
00:25:29.894 - 00:25:37.874, Speaker G: This is the one I. We talked about briefly right now with Pablo and Radek to estimate. Uh, yeah.
00:25:40.014 - 00:26:14.022, Speaker A: Okay. Take a look at this. I'm sure I'll be awake at four in the morning, so I can look at that. Any other things people want to discuss, or should we give people 30 minutes of their life back? Going once, going twice, and you have to figure out what to do with the next 30 minutes yourself. Thanks for coming, everyone. Thanks for all the hard work we've been doing.
00:26:14.158 - 00:26:15.118, Speaker E: Yeah, thank you.
00:26:15.206 - 00:26:17.486, Speaker G: Thank you all. Bye.

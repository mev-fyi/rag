00:00:50.868 - 00:01:37.340, Speaker A: And we are live. Welcome everyone to Acde one six eight. So some updates on Denkun today on Devnet eight. Like I mentioned in the chat, it'd be good to have a conversation around the deployment of the 4780 contract. And then we have some more updates on Hol sky and the testing that's been done there there some updates on the whole EIP Erc repo split and then two other things to discuss, one just around naming the fork specs so that they're easier to reason about. And then we have someone to discuss, new EIP EIP 7212, I guess. To start.
00:01:37.340 - 00:02:29.260, Speaker A: Perry, do you want to give an update on Devnet eight? You posted about it on the agenda. Yeah, I can give you a brief update on Devnet eight. So we had the Genesis yesterday and since then the chain has been mostly fine. We did hit a couple of issues overnight where Prism got stuck, as well as Lighthouse and Ethereum Js. Lighthouse and Ethereum Js have been fixed in the meantime, and I think Prism already has a pr, but are waiting for it to be checked and merged. In the meantime, we've just reallocated a couple of validators and we're finalizing and people can use the chain as expected, you can expect the blob scan and some other additional tooling to come up shortly. But the beacon chain Explorer is already live.
00:02:29.260 - 00:03:30.030, Speaker A: What was the domain of the problem? I actually haven't looked into either of to maybe the client teams can talk about. Yeah, yeah, there's a new one from Prism, Lighthouse, Ethereum Js or any of the other team want to give a quick update. So for Lighthouse, I think the issue is because we removed mplex support in a recent update and that caused us to not be able to connect to some clients. So we just added it back in. It's more impactful on small networks, which is why we saw it here. For Ethereum Js, the issue with Lighthouse pairing was that on every slot, Lighthouse sends around two fcus, one with the old head and one with the new head. And when we were generating payload id, we were basically not doing uniqueness by the parent beacon block route.
00:03:30.030 - 00:04:09.980, Speaker A: So basically the payload id that was finally being provided was belonging to the old head and that was causing the block hash mismatch. And once it's fixed, now the correct payload, the new fresh payload id is generated and new fresh payload is built for the latest FCU. Got it. And this is the first time that this was triggered. It feels like something that would have showed up previously. No, we didn't have version three before, I think. Okay, got it.
00:04:09.980 - 00:05:03.040, Speaker A: Basically, I think these tests are not in the hive, where basically two kind of FCU, two, an old FCU and new FCU's are being sent and checked whether the payload is generated of the new FCU. But yes, for this particular new parameter, it was the first time. Got it. Yeah, we ran through a couple of the V three related errors earlier this week. We just used a couple of local testing tools, echotosis, and we were able to get them patched relatively quite a bit faster than we usually would have. And I think we also caught an issue where Nethermind and Geth would have been forked, and that was also fixed with some local testing. I know the Nethermind team had a few stuff they wanted to bring up and have potentially fixed by now.
00:05:03.040 - 00:05:53.902, Speaker A: I would also highlight that kurtosis has been working very well for us. So it would be pretty good if different client teams could also begin into looking into it and possibly giving it a try to check basic interrupt, not like a full matrix of all client combos, but just some basic big ones. I think it would be very nice. Yeah. To give you guys an idea on how we used it, once we had an El ready, we just made a list of the CLS that are ready and just did that combination. And then once the second El was ready, we just separated that combination so we knew that all the CLS work with one particular EL, and then we just combined the El networks together to get complete interruptor. Yeah.
00:05:53.902 - 00:06:35.660, Speaker A: And I've listened to document there in case anyone wants to try it out. And so this has been valuable, just literally just running local nets. Like, you're not even doing network partitions or anything? Nothing at all. We're kind of just running these tests, and when we find something, we can just send a Json config along with the command to the client team, and they're able to reproduce it almost immediately, saving us a bunch of debug time there. Very nice. And one thing I want to also mention in the end, I'll be bringing up in the next call, which is Mev related. But we also have the entire mev workflow now, so we should be able to do a lot of mev testing there as well.
00:06:35.660 - 00:07:05.202, Speaker A: Nice. Mev doesn't support the fork yet, though. Yeah, it's kind of the chicken and egg problem. We need the network to support it before the relays can support it, and we need. Yeah, you get it. But I guess, does this mean we're now ready to get relays to support this. Yes.
00:07:05.202 - 00:07:23.420, Speaker A: Okay, so this is what we're blocked on, is relay support for the fork. Yes. Okay. And they can test on kurtosis also, so that's going to be very useful. Nice. Andrew, I saw you had your hand up briefly and then it went down. But did you want to add.
00:07:23.420 - 00:08:09.592, Speaker A: I was curious about some doc about ketosis, but now Parentosh has sent one. Be planning to write a very proper documentation about how to get started, but the small doc that Pari put together, it's really enough to get started, but there's like a bunch of new features that we have recently added that can even do high scale testing with multiple nodes on kubernetes. So it's even good for bigger tests also. Yeah. When ready, if you could share that one, that will be great. Yeah, sure. Nice.
00:08:09.592 - 00:08:45.110, Speaker A: Did any of the other client teams want to share thoughts about the Devnet or how it's been going? Yeah, I would like to give an update on everyone. So we haven't joined Devnet eight yet. We've been mostly looking at fixing the hive test for Dan kun. So literally five minutes ago, I've checked in a patch to our devil branch. Bring down the number of hive test failures. Does two failures out of 38 tests. So there is progress there.
00:08:45.110 - 00:09:29.158, Speaker A: We need to improve the security of our transaction pool for blob transactions. We need to implement IP 4788 version two. So it would be nice if that one gets finalized and then join Devnet eight. But we are getting there slowly but steadily. Got it. Thanks. Anyone else want to share? Update? So from our site, everything is working as expected.
00:09:29.158 - 00:10:20.834, Speaker A: We never might pass this hive test. We had a couple of issue, but we managed to fix them before the Devnet started. One maybe interesting one was that Nethermind doesn't have implementation of parade for for based on system transaction. We have still direct rights to statedB, but it turns out that we had some edge case three encoding issue, but now it's fixed and we plan to move to system transaction. Got it. Thanks. Yeah.
00:10:20.834 - 00:11:01.840, Speaker A: Justin, you want to give an update from baseview? Yeah. So we're still working on being ready for Devnet. 84788 is still in flight. The hive tests are not passing yet, and we do need to break apart our 4788 branch so that we can include the beacon route in Genesis. Right now we're experiencing a lot of failures because those are, like I said, the 4788 branch is not merged in yet, so we need to separate those and we'll move forward from there. We're still working on passing all of the high tests. Got it.
00:11:01.840 - 00:12:25.760, Speaker A: Any other team want to share updates or where they're at? Okay. If not, I guess the last big spec question we had was figuring out how we approach deploying the smart contract that's part of EIP 4788. We discussed this on last call, but I don't think we had strong consensus either way. At this point, it's probably the main just blocker to finalizing the Cancun spec. So yeah, I'm curious if anyone has strong opinion on how we should approach this, or if anyone has changed their thoughts on this since the last call. Danny? Yeah, I will make my case once more, but also acknowledge that either method work, it's a bit of an aesthetic decision, and I'd rather this be unblocked than push this kick the can down the curb again. But essentially I think that this is a system contract.
00:12:25.760 - 00:13:31.632, Speaker A: This can be elevated as such and live at a particular address. And given that we have the opportunity for the EIP just to be entirely self contained, it deploys its own code and then utilizes and exposes it via just on the fork, conditionally placing code at what becomes kind of a system contract address. I think this makes downstream tooling easier, I think this makes testnets easier. I think this makes all sorts of things simpler. It's a matter of just turning the EIP on for a given network rather than also considering if the contract is actually deployed. It's likely that this will be precedent setting in other things where we might want to have some sort of system type contract. For example, EIP, I think it's 7002, is something that I think is pretty important, which is execution layer, triggerable exits to enable certain types of validator activity.
00:13:31.632 - 00:14:22.244, Speaker A: But I think it's likely that once we kind of experiment with this type of system contract, that we do see more of them. And so instead of having n of these, where we're making sure that for a given testnet, a given side net or given main net have the contract deployed, we just have them be able to deploy them themselves again, I think that that's the simpler, more elegant, more self contained solution. But I both work and I am ready to unblock however you all please. Okay, thank you. I guess I can argue the other side. Yes, please. Yeah, I really don't think that we should just enshrine code onto mainnet.
00:14:22.244 - 00:16:00.304, Speaker A: And I think it's maybe simpler for some other networks to utilize this beacon root contract concept because they can just turn it on, but it doesn't make mainnet simpler. It actually makes the code a little more complicated because now we have to write something that says, if we're at this fork, then we need to enshrine this code into this address and it needs to be hashed into the state route. And so there's just like another branch of logic that needs to exist there. Then we set the precedent that if we need to do more of these, we possibly end up with some file that has a bunch of different functions that says, if this fork, then deploy this code, if that fork, deploy that code, et cetera. And it just doesn't seem necessary because we have a good system for deploying contracts, and this is an EVM contract, and I think we should use the system that exists for deploying those things, and we should be kind of a normal citizen on there. And it almost feels like that's a little bit more of a generic approach for other networks who want to use different types of system contracts, because then it's more of a configuration thing where in their genesis file they can say, this is the address I want to call my system, I want to do my system calls to, and they can decide what code actually ends up going there and possibly do something different than what 4788 specifies. And if it's really a problem for people on new networks to deploy this thing, we can have some automatic set up with the genesis allocation where if you say this four, seven, eight eip is turned on, then it just automatically adds it to the genesis allocation.
00:16:00.304 - 00:16:41.264, Speaker A: A lot of this stuff can be done behind the scenes. I think that putting the code and trying the code is a little bit more complicated. And this is a simpler thing. And it utilizes the contract appointment after structure that already exists. Yeah, I guess my one pushback is like, this isn't just code that gets to be a good citizen. This is code that has very special system logic around it with an exceptional color. And so I think we end up mixing two things to enable a system activity.
00:16:41.264 - 00:17:15.900, Speaker A: We have to have some user perform an action, otherwise it's not there. And I think you do end up with conditional logic the other way as well, because now I have to handle what is a reality where this EIP is turned on, but the code is not actually there. And then we have to test. That's very easy to handle. The call already needs to handle EVM failures because it's just a normal EVM call. So you kind of just discard whatever error comes back. So there'd be no additional tests in hive.
00:17:15.900 - 00:17:45.180, Speaker A: I mean, we can have an additional test in Hive. That's probably good. Okay. But I would rather have an additional test in hive than more code in the clients. Yes. I don't know. I see the thought in the chat saying what if we forget to deploy it? We'll just deploy it.
00:17:45.180 - 00:18:23.434, Speaker A: We can deploy it. Yeah. So I guess possible. I meant more like if you're on some other network and you forget to deploy on testnet or some roll up, it just seems so like one of us here is not going to go and make sure this contract is deployed for every other network that's going to exist ever. So it's easier just to have it as part of the fork logic, I think. I feel like a lot of networks don't need 4788 or they need a specialized version of 4788 and they need to think about how it's going to look. So I'm not really worried about it being a little bit more complicated for them.
00:18:23.434 - 00:19:35.560, Speaker A: I also don't think we should complicate main net to make it slightly easier for l two s to have a feature. Okay. I'm curious to hear from more of the client teams, I guess. Is there another client team aside from yet who is like in favor of the pre deploy through a regular transaction? Okay, so does this mean all the other teams are in favor of having it combined as part of the fork logic? I don't have a strong position. Okay. Same as Andrew. To the point of future compatibility.
00:19:35.560 - 00:20:15.270, Speaker A: Oh, sorry. Yeah, Anzgar, you can go before. Yeah, I wanted to just bear with you mention that in case we basically want to do this for all future contracts of the sort, it could be that in the future there might be an instance where as part of the initial deployment we want to set, maybe exceptionally set some initial storage slot or something. And we can't do that out of a normal transaction. In that case, we would have to have basically deployment as some sort of special operation. So if we wanted to have a standard, the standard could only be that we do it in a special transaction. Of course, if we just do one off solutions for every such type, then this would be fine.
00:20:15.270 - 00:21:50.756, Speaker A: Yeah, that's an interesting argument. Meaning if you had to initialize the memory to non zero, you'd have to do something additionally exceptional. Right. Although of course the argument could be that you just deploy a normal contract and then as part of the fork only set a few storage slots that would still be a smaller at the point of Hok change. Um, so I guess clearly there's still some diverging opinions. Do people feel like it's better to debate this and discuss this for another week or that we're sort of blocked on this and we should make a decision now in order to move forward with the whole fork as quickly as possible. It doesn't feel like it's blocking right now, but I would rather decide sooner than later because all of the test networks, we just enshrined them in Genesis it.
00:21:50.756 - 00:22:36.562, Speaker A: Yeah. Okay, so does it matter if public testnets have different addresses? Yeah, we can use create two, right? Well, we can use a generated create address. Martin in the PR has a transaction that deploys it to any network that supports pre one five, five transactions at the same address. Okay. Yeah. I don't know. It feels like it's pretty split still, like, and I guess, yeah.
00:22:36.562 - 00:23:50.334, Speaker A: So. Okay, so never mind. Is also against any approach besides the system transaction, or at least part of the team. Does anyone else have strong opinions? So in terms of just the code paths, how big is it a significant change to do in fork deployment? If not, I don't know. I would lean towards the infork deployment because it seems like there's slightly more support there and we can always revert it, even though that's not ideal if people feel strongly the other way later. But I think we probably. Okay, so there's more people who prefer the transaction process not there.
00:23:50.334 - 00:24:58.374, Speaker A: Yeah, I don't know. I feel like we'd probably better off to agree to a direction and start working on that for Devnet nine. Or I guess maybe we defer it to one week, but I don't know, it doesn't feel like we're going to get new information in a week, I guess. Yeah, maybe this is the right question. Does anyone feel like an extra week of debating this will be valuable or we have to actually debate it? Because I don't think that a lot was discussed between now and the last call that we discussed on. Okay, I would like to see when is the system deployment, like, the deployment via fork, really going to be useful on other networks? Because I think a lot of networks won't use 4788, or if they do, they'll do it slightly differently. And any new network for a new network, it doesn't really matter which approach we take because it can just be enshrined in Genesis.
00:24:58.374 - 00:26:18.490, Speaker A: That's very simple. So it's really a matter of networks that want to use 4788 that exist today. Ahmad? Yeah, I just wanted to say that regardless of the approach that we follow here, I would like to emphasize the importance of finalizing the spec in general before going into trying to deploy another devnet. So before going to at least two weeks before Devnet nine, we should have a spec finalized with tests, ready to have enough time to run our tasks and be ready for the next devnet. Yeah, I totally agree. I'd rather make a call on this now and be able to move forward. And I guess so if we do the bundled transaction approach, it doesn't necessarily preclude us from not doing that in the future, like just deploying a contract naturally.
00:26:18.490 - 00:26:56.216, Speaker A: Whereas I guess what we're saying is if we don't bundle them together, then it starts to become awkward because we then have a list of contracts that we need to consider each. Yeah. Okay. So Dan was saying also that there may not be that many. This contract is only a main net focused contract with the ELCL pairing. Not many l two s do that. I'm not aware of any.
00:26:56.216 - 00:27:41.884, Speaker A: They might, maybe they'll repurpose it for l one root, which means they'll do their own thing. I don't think we need to make much space for this other than just for how mainet is going to use it. Yeah, exactly. I mean, there is nosis. Also, I think this is precedent setting for this type of deployment, which the fact that we're talking about uniquely something that is ClEl is interesting here, but do you maybe want to give context on the appointments, like a generic way? Yeah. Do you maybe want to give a bit of context on the el triggered exits and roughly why that would use a similar design that's also probably exceptional, although. No, yeah, I know, but I related to these two things.
00:27:41.884 - 00:28:28.284, Speaker A: Yeah. If we're just thinking about Mainnet, right. It's not clear to me how much context everyone has around how El triggered exits would work. And it might be helpful to just understand that a bit better to make sense of this. I mean, similarly, right now, 7002 is specified as a stateful pre compile, which we kind of got into the zone on this one that maybe stateful pre compiles don't make sense, and instead we should be deploying code. So in that if this is precedent setting, then if we did something like 7002, then similarly we would have a contract or some bytecode living somewhere that users can hit. And then the system does something with respect to that.
00:28:28.284 - 00:29:33.276, Speaker A: So on this case, instead of preloading the state with something like 4788 for users to use, users are triggering actions inside of this contract. And then the system is picking up stuff. So like, users trigger exits that are valid upon some logic, then the system picks these up and pulls them into the consensus layer. So kind of similar concepts going on there. But other things you could think about were like the example of removing the 256 historical routes that are implicitly part of the state transition function right now and put it writing them into state. That's not cross layer, that ends up being useful kind of in any EVM deployment, and is definitely a nice to have, especially in the context of statelessness, to make things much more contained on that front. But there's a lot of examples you can think of that we might end up going down that path.
00:29:33.276 - 00:30:19.830, Speaker A: Some are cross layers and we're not. One of the other reasons that I also support system transactions is that I feel like I don't want to have a change in the state that is not justified by a certain transaction. Usually in ethereum, when there is a change in the state, there is a transaction that made that change. That's most of the cases that I know of, so I would like to keep that up. Even if it's deploying a system contract, it should be like done by a transaction changing the state. So I can think of many examples where that's not the case. Withdrawals are those transactions.
00:30:19.830 - 00:31:17.950, Speaker A: I don't know. The other component of 4788 is actually that the system updates the state. Every slot, every block and coinbase, and there's all sorts of system operations that update the state. If we're going to be bound to that, then we can't do a lot of things. And just because this is, I don't know, to compare this to an irregular state change I think is a bit dishonest with respect to the other things that we do to the system. But I'm going to stop debating this because we're at half an hour already and I don't want to be the only person that's holding this up because at the end of the day both methods work and I don't really want to block this anymore. Yeah, it does seem like it's pretty split.
00:31:17.950 - 00:32:43.394, Speaker A: I. So in terms of just the code implementations, if we go with just the pre, is it easier to go from we've pre like just the regular transaction flow to then adding the special deployment flow, or is it easier to go the other way around? I assume it's easier if we go with the normal transaction that gets deployed, that deploys a contract, and then decide to make that into like a special transaction during the fork. That's probably simpler for clients, is that correct? Yeah, I think right now we're kind of compatible with the just deployed in a transaction. And if we want to support the deploy via fork, we would have to add that code and then have some tests. So I would lean towards deploying it in a separate transaction for now. If people want to keep discussing it and feel strongly about it, we can bring it up in two weeks. And if people implement it and feel like it's actually a terrible approach and the other way is better, we can revisit that and then add the extra code path in two weeks.
00:32:43.394 - 00:33:14.158, Speaker A: But I think for now, given it's pretty split, I would just go for the simplest option. And so we can have a tentatively finalized spec move forward with this and, yeah, revisit it if we feel a strong need to. Does anyone object to. Oh, okay. Yeah. So there's a last question about the regular transaction is like, it requires a transaction. Oh, it doesn't require a transaction key.
00:33:14.158 - 00:34:02.620, Speaker A: Matt, do you want to explain how that would work? Yeah, I mean, I kind of want to keep this debate mostly focused on whether we deploy with a transaction or whether we enshrine it. Because I think once we get into, let's deploy with a transaction, there's a couple of ways that it's possible to do it. There's a way that you can just arbitrarily pick a signature which kind of creates a synthetic signature. You recover the address, and then that address is like a one time use address for a specific operation. So if we wanted to deploy the same address at any EVM network that supports pre one five, five transactions, we could do something like that. I think that's the best approach. But if people are not as enthusiastic about that, then we can't just have someone deploy it with a key.
00:34:02.620 - 00:34:41.314, Speaker A: There's really nothing wrong with that either. You fund that address once you pick it, right? Yeah, exactly. This was used extensively in Shanghai attack recovery. There's a lot of transactions with that online. You're going to fund it like client? Is that what it takes? Yeah, I guess, yeah. Just because I do want to make sure we all agree on the spec. Like, this is probably the most important thing.
00:34:41.314 - 00:35:27.080, Speaker A: So does anyone disagree with clients approach to deploy the transaction? Okay, so let's do that. Like client, do you want to open a pr to the EIP? I don't know if your pr already had this. It has it. Okay, perfect. So we should go ahead and merge this. If it's not already done, then. Okay.
00:35:27.080 - 00:36:01.806, Speaker A: Anything else on 4788? Okay, sweet. Next up. Sorry, was there okay? No, that was a little happy emoji. Next up, testnet updates. So there's been some more testing on the whole sky. Perry, do you want to give an update on this as well? Yeah, so we had the last tests last week, and I think I also brought it up in the last call. But we tested essentially 1.4
00:36:01.806 - 00:36:45.614, Speaker A: million validators and we're able to get finalizing that network. So we went with recommending that as the starting size for Holskey. There's an onboarding document and telegram group for some entities to share their pub keys, and then we'll be generating the Genesis state using those pub keys. The info is also available on the GitHub repository. The only thing that's still kind of open and that we also wanted to test was in the earlier calls. We had agreed to limit the overall issuance of Holsky to roughly the same order of magnitude as Mainnet. But the commitments we've received total up to something like 1.6
00:36:45.614 - 00:37:13.974, Speaker A: billion. We initially thought, okay, maybe that's too much. But while looking at the testnet code, we've kind of been starting every testnet for the past year with like 10 billion, and that's been fine. So we also tried a couple of transactions moving around like 9 billion ether or something, and nothing broke on Devnet eight. So the question to the room is, do we just take the allocation as is, I. E. Holsky would have roughly 1.6
00:37:13.974 - 00:37:51.780, Speaker A: billion ether, or do we just slash it down until we hit roughly main net size? So it's going from 1.6. I thought you said 36 billion. No, 1.6. Okay, that's what we have committed. But if we were to slash it down to main net levels, that would be like ten times lower at least. Is there a reason to not do 1.6 billion if we've seen it work on the Devnets? I think the earlier fear was just that we thought we hadn't tested that, but apparently we have been this whole time.
00:37:51.780 - 00:38:18.310, Speaker A: Got it. Yeah. Does any client team feel like 1.6 is not doable or would cause a risk? Okay, let's do 1.6 then. Sounds good. Then we should have a genesis date ready around Monday, and we'll put it up on the GitHub repo.
00:38:18.310 - 00:38:57.134, Speaker A: And hopefully client teams have a chance to make releases before September 15. That's the date we're aiming for Genesis, so. Merge day. Nice. Anything else on Hosky? Okay, thanks, Barry. Next up, Sam, I believe, had an update on the Erperc repo split. Sam, are you on the call? I am oh yes.
00:38:57.134 - 00:38:57.422, Speaker A: Nice.
00:38:57.476 - 00:39:24.802, Speaker B: Hopefully my audio is so very, very brief. Update three points. So one, we're going ahead with the split. We'll be removing Ercs from all the other types of eips first, and then we may be dividing it up further. We'll see. Second, we're working on making our governance process more transparent and actually writing it down into a document. Reach out to me on discord if you're curious.
00:39:24.802 - 00:39:42.720, Speaker B: Otherwise it doesn't really affect you guys directly. So just mentioning it here for fun. And third, Greg wants me to make it explicit that we're staying like one group or one organization. Yeah, so that's pretty much it for the updates on the EIP and governance side of things.
00:39:43.410 - 00:40:26.210, Speaker A: Thanks. Thank you. Does anyone have thoughts, questions, comments? I'd like to add that the governance will be such that the editors should never be in the way of making an upgrade. Never. Got it. Thanks. Anything else on that specifically? There'll be documents soon enough.
00:40:26.210 - 00:41:05.422, Speaker A: We're working on that. Yeah. Sam, I know you had a pr up with some of your proposed change. Do you mind just sharing either the pr or the doc in the chat? If people want to review, they're really not ready for review. It'll probably take a few days to a week. Then the next meeting, we should come to consensus on that, and then we'll bring them back to this meeting and we need to open up some communication with the consensus layer and see if we can find a way to serve them. Okay, cool.
00:41:05.422 - 00:41:58.926, Speaker A: Then we'll wait till the docs are in a better state. Anything else on this? Okay then, Andrew, you had just a quick ask. So we have all these fork specs on the El side and their name just using their fork name. So Cancun, MD, London, Md. And you were mentioning that it's a bit awkward to navigate if you don't know the actual ordering of the fork. So should we just rename everything to use numbers? So one, the first fork, two the second fork. That seems reasonable, I guess.
00:41:58.926 - 00:42:40.100, Speaker A: Do you want to add more context around that? Well, yeah, it's a minor thing, but it might be a slight usability improvement. And I think with the clocks they are named alphabetically, so with those it's easier to navigate. Cool. Oh, it's. Yeah. Okay, so I can make that change in the spec if there's no objection or concerns. Okay, so week and then last thing we had someone wanting to present EIP 7212.
00:42:40.100 - 00:43:21.630, Speaker A: Are you. I hope I got your name right. I'm uloy. Please. Yeah, go ahead. I'm ulaish I'm one of the authors of the IP 7212 and I'm here to present the proposal to request some reviews and feedback from the core developer community. The proposal creates a new pre compiled contract similar to EC recover, which allows the signature verifications for Sec P 2656 r one elliptic curve which is one of the most mass adapted curves in the Internet ecosystem.
00:43:21.630 - 00:45:02.210, Speaker A: Allowing an efficient use of this curve in the EVM provides utilization of the products using this curve in the application, such as signature abstraction by secure elements of the mobile device and DNS sec operation for web two domains in DNS, et cetera. And I think that this pre compiled contract can onboard lots of new users and solutions which connect web two to web three, especially in the account abstraction wallets and we would love to hear any comments and recommendations for the EIP and I also have a few questions and I will ask them here. The first is the EIP specifies the curve operation for the verification, but it's a bit different from the common use case that we are familiar in EC recover, which is recovery. My design choice are coming from in the EC recovery, the recovered address is the account's public address, so it makes sense. But in the r one curve it's not a meaningful data for the account and the products implementing this curve is not giving the v signature values. So it's not possible to make recovery directly without trying different values to recover. So my question is, does it make sense to keep verification process going as the verification so that the implementation is also becoming more adopted in the applications or I had some feedback to change the proposal to recovery from the verification.
00:45:02.210 - 00:46:19.014, Speaker A: These are my questions and again, I would love to hear any comments and recommendations. Thank you. Anyone have thoughts? Comments? Daniel so one trend that's happening, it's not ready yet, is the ipsilon team. I'm watching them build this thing called EVM Max, which is modular mass extension to the EVM with the intent that a lot of these things that might be pre compiled could be done in EVM for reasonable costs. Is the r one curve something that might be usable for that? Because judging by some of the experiences I've had in the past couple of years with performance, and not just performance, but corner case issues with pre compiles, they're kind of high risk to put in. It seems simple, but the corner cases and the tax service they exposed tend to be problematic and it'd be a lot better if we could. I used to be in the camp that yeah, let's do all these pre compiled let's bring all twelve b lessons.
00:46:19.014 - 00:47:20.538, Speaker A: But now I'm more of the camp that we should try and do as much on chain as possible. And would this EVM max be able to support the r one curves? I guess is a big question. I can actually answer that because I did a bit of investigation on that. So the answer is yes. And based on the cost model that I had originally proposed in EIP 58 43, it would cost around 70,000 gas to do EC recover with Sec P. With this curve, it's quite a bit more expensive than the pre compile. But I think the best implementation we have in EVM right now is around, or I was told is around 600,000 gas.
00:47:20.538 - 00:48:13.998, Speaker A: So yeah, I think something like EVM X would bring us closer to pre compile like costs, but it's still quite a ways off. But yeah, 70,000 gas versus, I think, what is it, 2000? From a union perspective, that's a lot less relevant than 600,000 versus 70,000. Right, right. But then there's also some design issues, like it doesn't have the recovery key and a lot of the signatures. The initial signature said, here's a public key, here's a signature, try and match it out, which might result in one or two typically tests to see if it works. So it would allow the end user to customize their use of the r. One is one advantage, but I don't know if that overcomes the 20 x.
00:48:13.998 - 00:48:43.190, Speaker A: So that's a good measure that you have the number that we know that is like 20 x. That's very useful. Yeah, it was a back of hand. Well, I don't have a benchmark, but I think it should be around there conservatively. I mean, I think it could be potentially better, but. Yeah. Thanks, Ansgar.
00:48:43.190 - 00:49:55.914, Speaker A: Yeah. Well, on that point, first I just wanted to briefly mention that I think even if we end up at a 60 70k gas cost point, that's not ideal. Just because if we expect that a big portion of future, the kind of extraction contracts use this curve, then this would immediately still be the dominant portion of the overall overhead of sending a transaction, which just not ideal, given that we would expect high usage of this precompiled slash Evmax curve. But my original comment was going to be a bit more abstract. So just to give context for people who haven't paid attention to the ERP yet, why it's an interesting ERP is that there's a lot of interest by layer twos to also add this functionality. So we're basically in the process talking with layer two, it might be that they are interested in adopting this EF relatively soon, whereas of course if this ever reaches mainnet it will take a little bit. So it might be just an interesting first.
00:49:55.914 - 00:51:08.690, Speaker A: Canada in basically just seeing in that standardization process and kind of like basically interacting between layer ones, layer twos. And so basically us paying attention relatively early on in the process would still be valuable so that we don't end up in a world where we bring a version of this to layer twos and then six months later bring a slightly different version of this to layer one. So I wanted to basically just mention that this is like the ERP here is in an interesting place. Thanks for the comments. Also, I heard that ZK and Aztec are implementing the precompile contract in some way. And also I have another recommendation that implements this precompile as a progressive precompile idea which creates future precompiles as smart contracts implementing the same precompile interface in a deterministic address in every chain by create two so that different chains can implement the EIP independently in the same address. I think it matches with Anscar's comments and usable.
00:51:08.690 - 00:52:00.810, Speaker A: Okay, does anyone else have thoughts comments on this? If not, then yeah, so there's a discussion link that was shared in the chat here, we can continue the conversation there. And yeah, it's definitely interesting to explore the angle of l two s potentially adopting this. Prior to l one, that was the last thing we had on the agenda. Anything else anyone wanted to share before we wrap up? Okay, well thanks everyone. Talk to you all soon. And yeah, have a good day. Thanks everyone.
00:52:00.810 - 00:53:10.290, Speaker A: Thanks Tony sa o.

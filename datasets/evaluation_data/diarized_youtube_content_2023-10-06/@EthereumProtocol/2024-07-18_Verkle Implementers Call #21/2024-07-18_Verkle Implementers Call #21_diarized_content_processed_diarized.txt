00:00:03.040 - 00:00:27.260, Speaker A: All right, welcome to vertical implementers. Call 21, issue 1092 in the pm repo. Cool. So yeah, we have a somewhat lighter agenda this week, starting off as usual with updates from any client teams if anyone would like to share anything small or large.
00:00:28.320 - 00:01:16.390, Speaker B: Yeah, I can start. I've been working on polishing a document that I will share more later in this call regarding the cold access gas overhead for barcode in mainnet transactions. And I've been working on some more focus test vectors for the state conversion from the Merkle Patricia tree to the Merkle tree. Maybe I will mention a bit more in the testing part of the call. And I've been working on a first draft of the state conversion EIP, which we didn't have that yet, and hopefully this will help other people implement the state conversion and also have a source of truth for test vectors.
00:01:20.540 - 00:01:48.870, Speaker C: Yeah, adding to this, I've been working on collecting witness size data and implementing the missing prs for the testnet relaunch. And also really, really busy trying to merge more cool stuff into geth so that we can have a testnet on top of Cancun, hopefully before the end of the summer. Yeah, that's pretty much it.
00:02:04.490 - 00:02:42.540, Speaker D: Okay, I can say something from bazu side. We are currently mostly working on optimization concerning storage in the database and trying to do some of the work in background trends in terms of floating from the database. So that's what we are. And I think some of the people from the zoo are on vacation, but they were discussing finishing gas cost stuff.
00:02:50.320 - 00:03:04.870, Speaker A: Cool. Thanks Thomas. Anyone else? Anything on the testing side of things? Spencer, anybody else? It's okay if nothing.
00:03:07.200 - 00:03:31.520, Speaker E: Hey. Yeah, so, not much from my side. I've taken some expected time off the past couple weeks, but the same focus will be placed on getting the genesis test vectors that Ignacio has been writing fillable. So that's, that's a priority.
00:03:36.180 - 00:04:32.180, Speaker C: I have a question because I have a couple branches to test that I would like to test. So I know you did the release, but I've never managed to get the release to work on my machine. This is something we already had as an issue back in Kenya. Could you do me a favor and update the machine that you created for me back in Kenya so that I can just try my new branches that would really be useful and maybe make it accessible for more people? The reason why I'm asking is because we would like to do a testnet relaunch, which is going to be the next topic, I think. And this time, instead of going the very inefficient way of starting the testnet and hoping that everybody will be able to join. I would like to be able to fill the test, make sure we all agree on the topic, and then do the relaunch instead of hoping for the best, like being sure.
00:04:34.560 - 00:05:37.872, Speaker E: Yeah, that sounds like a great idea. I can write a document on how to consume these tests. I think currently at least the way we've been consuming them is kind of using a weird hive workaround on something which is unfinished on the, I guess the testing framework side from us. But ideally, ideally clients should have a way to just consume the test fixtures very easily. I think so on Geth there's the evm block test command and other clients I believe have similar commands to consume the blockchain fixtures. So that might be, it might be a good idea to focus on that after getting the. Yeah, okay.
00:05:37.872 - 00:06:00.330, Speaker E: Okay. So it'll be good for us to just have a generic way for all clients to run tests very easily. I can set that up and then afterwards, I guess after the testnet relaunch, we can maybe look into making sure all clients have an easier way to consume the tests, just like the EVM block test.
00:06:01.110 - 00:06:29.870, Speaker C: But isn't there some issues? Isn't that already the case? Because you have Hive. So I understand you've got some special setup for Hive, which maybe I can help you normalize. But because you have Hive, hive is supposed to run every client. I think they support every client out there. Could you just not, or could we not get guests to fill the test and check that every client can import that in turn? Is it not already an option?
00:06:31.450 - 00:06:34.510, Speaker E: Yeah, definitely, definitely, definitely with guests.
00:06:38.900 - 00:07:09.500, Speaker F: So maybe I can shine in. So that's the end goal. The way that we work right now is that Hive, the Hive simulator, it goes into the release page and tries to fetch the latest release for us. It's a little bit not, it's a little bit finicky because it tries to get the latest release. And since the Berker release is not an actual release, it's just a pre release. That's what we're trying to sort out right now. To get this process a little bit smoother.
00:07:09.500 - 00:07:48.930, Speaker F: We are working on the consume the engine consume. What it will do is basically just, it's calling the interface that get that sorry. That Hive provides for us to immediately consume the test with all the clients. This is about to be merged in the next couple of weeks, I would assume. So with this we can ourselves run, luckily tasks. But right now what you guys can do is I don't know if you guys are familiar with the releases that we're putting out. If not, I can just quickly just share my screen and just show you where you can find these files, if that's okay.
00:07:49.310 - 00:07:50.410, Speaker C: Oh yes please.
00:07:50.710 - 00:07:51.182, Speaker E: Yeah.
00:07:51.246 - 00:07:56.570, Speaker F: All right. I'm not allowed to share my screen. I'm going to do that.
00:08:00.080 - 00:08:01.780, Speaker C: Josh, are you the.
00:08:02.320 - 00:08:06.700, Speaker A: Yeah, yeah, sorry. Give me 1 second. Let me enable that. Okay, should be good now.
00:08:08.440 - 00:08:08.960, Speaker F: Excellent.
00:08:09.000 - 00:08:09.620, Speaker C: Yeah.
00:08:16.360 - 00:08:16.928, Speaker B: Yeah.
00:08:17.024 - 00:09:00.836, Speaker F: Okay, so, all right, so this is the page I review guys from. You let me share the link which is the execution spec test. Just one? All right, so when you get here, you will see down here you will get the releases page. So when you go here you will see a lot of different releases. Right now we are working on three different ones, which is the devnet one which contains all the eips for proc and the Eof one which contains only eofemen plus plus spread if necessary. And then here we got the release that Spencer prepared. So this is the one that you guys are interested in.
00:09:00.836 - 00:09:50.982, Speaker F: So inside of here you will see the pictures, you will see the tarbell file. So inside of this you will see the status and you will see the blockchain tests. So this you should already be able to consume using any of the clients because this is basically the same format as Ethereum does. So every single client that is now available should have a consumer that consumes this picture. So if you don't download this file, you go inside it and you will have state tests and you have blockchain tests and then you should be able to consume them with your plant. And maybe there will be some modifications that are required because this, the fixtures inside will point to a specific vertical fork. And maybe you will have to modify something in your client.
00:09:50.982 - 00:10:05.370, Speaker F: But I don't think it should be that complex. This is what you guys should do. In the meantime, before we prepare the consume command which will interface with Hive and will make it easier for us to run tests. But I think right now this is everything that you need.
00:10:07.390 - 00:10:33.020, Speaker C: Because that's my question. Currently everything, all the fixtures have been generated, or at least the test has been filled with a branch that was for calcinen six and we want to test Calstinen seven. So if we want to regenerate everything, can we do this tarball or is it just the output of something that we need like the field?
00:10:33.800 - 00:10:57.510, Speaker F: No, no, it has to be regenerated. If you are using another fork as base, you need to change it. This is just a small configuration file that we have to probably change, but it's pretty easy. Yeah, that will probably require another release. I don't know, what's the base of this? Do you remember Spencer, if it's.
00:11:00.410 - 00:11:02.544, Speaker C: I know, go ahead.
00:11:02.682 - 00:11:45.950, Speaker E: No, you're probably going to say the same. It's the base route last Merkel root merge branch that we're filling with on Geth. It's worth mentioning as well. It's only blockchain tests and here no state tests and says it in the release. But just make sure you have the Shanghai to Pragate time 32 enabled on your fork configuration. But I guess that's for this release, maybe for the next testnet. Will it be the same fork configuration? And also when do you plan to launch the next testnet? Just so we can prioritize a bit.
00:11:46.570 - 00:12:06.024, Speaker C: I mean, ideally in two weeks. I don't know if we'll be ready. That's the next topic. But yeah, the goal of was, was to be end of July. I mean if it's middle of August it's okay. But we also want to relaunch one after that. So yeah, the sooner the better.
00:12:06.024 - 00:12:24.100, Speaker C: But there's going to be a lot of back and forth. So this is kind of blocking us. I mean we can still go the old way, like start guess and wait. We don't, it's not blocking us in a way, but it would really, it would really help speed things up for us.
00:12:28.960 - 00:12:56.844, Speaker E: Sure. Yeah. I think you messaged about testing the branches that you had merged and so yeah, we can focus on that and getting this new release launched and then also assisting with clients being able to consume the tests over the rest of the week. If that works for you guys, that would be awesome.
00:12:56.892 - 00:12:57.520, Speaker C: Yes.
00:13:06.060 - 00:13:08.800, Speaker A: Awesome. Thanks Mario and Spencer.
00:13:09.940 - 00:13:10.276, Speaker B: Cool.
00:13:10.308 - 00:13:26.560, Speaker A: Next up, testnet readiness. I think we wanted to do a quick check from any of the client teams around desktop readiness and see if we think the next few weeks might be practical. Guillaume, did you have any other, I guess, specific thoughts or questions around this?
00:13:27.260 - 00:13:56.878, Speaker C: I had a list of tasks to be. Wait, I'm looking for the, for the window with my listen, as always, every time I want to show something. Okay, share. I don't know if you guys can see my screen. Yeah. So yeah, I guess I can start with Geth fill. Cost is not currently implemented.
00:13:56.878 - 00:14:25.670, Speaker C: We're struggling with it. The Nyota costs also have a weird bug that I'm currently debugging. The 164th gas subtraction. We have the mainnet version of 29 35. We. So the 29 35 version that was on calt six is an older version. So now we need to bring it up to speed.
00:14:25.670 - 00:14:44.092, Speaker C: We have the code. It's not integrated, but we can integrate it and state routine witness. Kejinder and I worked on it last week, so we are ready for this one. And the self destruct warm costs. Yeah, I don't. Do we have. I don't remember.
00:14:44.092 - 00:15:13.058, Speaker C: Do we have that? No, it's okay. We haven't implemented it. I'm not sure we should, but yes, we have implemented it. Sorry, we have not implemented. I've been told by tennis while I'm at it, that everything, like he says, everything that was discussed in Kenya is implemented. So he needs to do some checks. But this is exactly why we would be using the test framework.
00:15:13.058 - 00:15:23.670, Speaker C: But according to him, everything is implemented. Yeah, that's all for me and guests, and neither mine.
00:15:30.980 - 00:15:44.720, Speaker A: Cool. I guess since maybe most of the teams aren't here, unless more people have joined, we can either go through it right now or maybe continue the call or continue this topic async in chat.
00:15:45.420 - 00:15:48.004, Speaker C: Oh, I think it's. Yeah, sorry, go ahead.
00:15:48.132 - 00:16:23.140, Speaker G: I was gonna say I think Thomas might have some more detailed perspective, but I think Bixiou is similarly not ready for a testnet that has fill cost and iota costs. Yeah, I think we are probably. We're still waiting on some of the database work that we are refactoring before we get the fill cost and iota costs and so forth in. So, yeah, we would probably be joining the testnet after it started if it started with these criteria.
00:16:26.040 - 00:16:36.340, Speaker A: Gotcha. Anyone else want to give their status? That's not wise.
00:16:45.690 - 00:16:47.866, Speaker B: Is part of our muscle.
00:16:48.058 - 00:16:53.350, Speaker E: And for the gas cost of.
00:17:04.970 - 00:17:09.110, Speaker A: Couldn't hear you super well, but maybe someone else was able to get that.
00:17:11.300 - 00:17:17.520, Speaker C: Uh, it was also quite garbled for me, but it's okay. I'll check. I'll check offline with Gajinder. Okay.
00:17:19.540 - 00:17:41.650, Speaker A: Cool. All right, well, I guess that was everyone that's on the call at least. No worries, Cassandra. Okay, cool. Anything else on this topic? Guillaume or anyone else? Maybe we can. Yeah, just make sure that we get updates from everybody at least. Offline.
00:17:41.650 - 00:17:56.050, Speaker A: All righty. Next up, witness size measurements from Guillaume.
00:17:56.510 - 00:18:11.846, Speaker C: Yep. So I. Wait, I need to move a window. Yeah, right. So I wanted to talk about some experiments I've been doing. They're not complete. They take a lot of time to run.
00:18:11.846 - 00:18:49.950, Speaker C: But I was just curious how large the witnesses are for an actual payload. So I'm still replaying at the beginning of Chappelle. So that's data. That's like a year old. Nonetheless, it's more representative than what we used to do before. So this is, and yeah, that brought to my attention some possible or potential optimization. This is currently how we store the state diff in the current version of the spec.
00:18:49.950 - 00:19:49.130, Speaker C: So for each stem you have a list of state diffs, and each state diff has once suffix, and then the old value, which is an optional, and a new value that is also an optional. So yeah, just as a reminder, if current value was null or not present, that means that the tree was empty before then. And if the value was, if new value is null, that means whatever was there before was not updated. If current value was not null, that means there was a value that we read and potentially overwrote. And if new value is not null, that's the value that we overwrote the current value with. So there's a couple issues with this approach. One of them is optional.
00:19:49.130 - 00:20:36.270, Speaker C: No, very very few. I know of a single library that supports optional SSD library. I mean, and it's not used in any client. And yeah, like there's push to replace optional with stable containers, I think. So the semantics of optionals are switching a bit. But the most important consequence of this, of the lack of support currently, is that the Gosse libraries that I used will just write zeros instead of using of really implementing optional. And that makes for very, very large witnesses.
00:20:36.270 - 00:21:36.610, Speaker C: So one thing that was proposed by Peter actually is to actually right the name is wrong, it should not be suffix state diffs. Well, okay, I guess it could be suffix state diffs, but the idea is to get rid of optionals by using like collating all the suffixes together, grouping them in an array of bytes, and also doing the same thing like collating all the current values and all the new values in their own lists. And if the semantics are the same, if a value in the list is null for current value, that means it was not present in the tree. If it's null in the new values list, that means it's not been updated. And if it's not null, that means that there was something present and or that it was overwritten. So I've done some tests with this. It took quite some time to collect the data.
00:21:36.610 - 00:22:40.910, Speaker C: But if you compare the current version of the library, so using the spec version with the first proposal by Peter, you can see that this is a box plot. So the red line here represents the median. That means half the points are below this and half the points are above. So we have an average median that is about at 700 kb for the witness, and it's mostly zeros. If we use that new method, which is not perfect, you still have nulls and things like this in the encoding you already get a huge benefit. Your median is now around 400, little bit under that. So as a quick approach, as a quick optimization, it's already quite useful.
00:22:40.910 - 00:23:33.360, Speaker C: One thing to understand or to notice is that this is actually almost double from what was initially promised as the witness size, because that was around 150 kb. But those estimates with the witness size were actually without the new value. If we remove the new value, we would on average get half. Not exactly, that's an estimate, of course, but that's a general idea. And because we get half, we go to about 200. So that's more or less what we expect. So this is a preliminary analysis of this stuff, preparing another document to be a bit more thorough.
00:23:33.360 - 00:24:26.516, Speaker C: But I wanted to share this. There's another proposal that I haven't had the time to implement yet, because like I said, there's a huge turnaround time for running those tests, but the idea is to remove nulls altogether. So there you have one list for everything. It gets updated. So something that had a previous value and a new value, you have something like, you have a list of suffixes, a list of paleo values, of leaves for everything that was inserted. So something that did not exist before and was inserted, and then the opposite, something that existed and was read. And actually the name is terrible, untouched suffixes, it should be missing suffixes.
00:24:26.516 - 00:25:20.594, Speaker C: So this is the list of all the suffixes that were not present in the tree and were not updated. So because you do not really store any nulls or any empty values, you should be able to amortize the list header quite quickly. And so I expect this to be a bit even smaller, but I don't have the numbers for that yet. But yeah, just FYI, this is a new proposal I wanted to suggest to use the better one. So the one that has been implemented. So this one for the new testnet that would require CL's to implement it. But yeah, we don't have a lot of client devs today, so let's push the decision to a different time, I guess.
00:25:20.594 - 00:25:22.910, Speaker C: But yeah, that's the idea.
00:25:32.700 - 00:25:45.960, Speaker A: Cool. If nothing else on this topic, we can keep going. Up next we have a agenda item for fill cost updates.
00:25:48.550 - 00:26:01.130, Speaker C: Yep, we can actually skip this one, because the only person that I, from what I understand, the only person who implemented it is Tanisk and is currently not here. So let's move it to the, let's discuss it next time.
00:26:02.070 - 00:26:10.330, Speaker A: All right, then the next one is also, you had a few updates on some eips or prs that you recently, you wanted to go through.
00:26:11.150 - 00:27:06.648, Speaker C: I don't necessarily go through, but make people aware that they existed. There's a proposal for EOF. So I actually just saw that Dino answered. Sorry, I just realized. So I did not get back to you on that. But yeah, the idea here is to change the format a bit in the case of EOF, to get a version marker or any byte that would tell you that you are looking at an EOF contract so that you don't need to go and read the EOF header because otherwise that's a bit more expensive for EOF contracts because you have. Or actually for every contract because you have to go and read the first byte of the code for many operations, including the code hash, which is.
00:27:06.648 - 00:27:40.400, Speaker C: Yeah, which is bit wasteful in terms of gas. So, yeah, like I'm not trying to discuss. Unless of course Dano or Ignacio have a comment on this. But yeah, if you could go and have a look just to give your opinion, that would be appreciated. So same thing with the next one. That's more like something that was proposed or asked for by both Gary and Karim from Bisu and also the. The rest team.
00:27:40.400 - 00:28:04.636, Speaker C: This is actually a fairly perfect proposal. It's quite. It's quite flawed. But the idea is to just add per. Per stem state diff. Add a bit list of all the transactions that access this number. I don't think this is the best way to do it, actually.
00:28:04.636 - 00:28:32.118, Speaker C: So I want to make another proposal, which would be to have a byte list at the beginning of the. Of the proof that says this transaction. Like breaking already breaking the transactions into groups that can be executed in parallel. But yeah, that hasn't been really updated. I'm still thinking about it and I'm just saying this thing exists. So have. Have a look at it.
00:28:32.118 - 00:29:05.576, Speaker C: Ignacio doesn't like it for the record, so that's completely fine. Yeah, just please have a look. And. Right, so this one would be nice to have for Cal student, but it was already in the list of eips and the idea is just to. At the top of the execution witness. So that also requires a Cl update. Add the state root of the parenthood so that stateless clients don't have to go back and get two blocks to execute.
00:29:05.576 - 00:30:00.390, Speaker C: One block. You just put this information straight into the execution witness and you see if that works. This was something that we decided on during the interrupt in Kenya. So, yeah, also have some feedback on it, implement it if you're okay with it, so that we can include it in Kelstinian seven. And the last two eips, it's actually, they should be merged, sorry, not eips, PR, but this is just an EIP, an update to 29 35. So there's been some back and forth between the proponents of the 4788 method, people who say, no, you should call system contracts, and me and a couple other people say, no, you should not because that's going to make, you're going to have to do some complex filtering. But we agreed to split the issue in two parts.
00:30:00.390 - 00:31:06.290, Speaker C: So we make 29 35 exactly like the 47 eight eight people want it. So we just say, okay, just use the 4788 mechanism and then just be aware that in the future this is going to come back and bite you because you're going to have to implement some complex filtering. And there is another update to AIP 7709, which is the vertical enabled 29 35, where the wording is also changed to say the same thing. Your system contract execution is no longer favored over direct state updates. So once again, just please have a look, give some feedback if you're not, if you disagree, so that we can, we can actually merge those, those eips and be done with this, with this question. Yep, that was pretty much it.
00:31:09.670 - 00:31:13.970, Speaker A: You mind sharing the link to the hack MD and I guess opening it up?
00:31:14.350 - 00:31:18.334, Speaker C: Yes, I should do that. Absolutely. I will do that in a minute.
00:31:18.462 - 00:31:19.170, Speaker A: Cool.
00:31:19.550 - 00:31:20.846, Speaker B: I think you have to update the.
00:31:20.878 - 00:31:36.170, Speaker A: Permissions to it as well. Cool, thank you. And last up, we have a gas overhead analysis from Ignacio.
00:31:39.830 - 00:33:00.276, Speaker B: I will share my screen. So earlier I forgot to mention that I also work on this document regarding testing. This is in the chat so everyone can look at it if interested, but it's basically trying to go through all the border cases that might happen for the state conversion. So today we have some states conversion tests that are more like generate some big states, run the conversion and check if, like if, if things go well, let's say. But actually during the conversion there are a lot of things that can happen, are quite hairy, let's say. So I basically went through all, everything that I thought could happen and I explained like, which are like more focused test vectors that are worth creating. So we have like simple test cases, we have cases to test state conversion where like between blocks you have partial account migration.
00:33:00.276 - 00:34:01.040, Speaker B: We have to account for special accounts. So for example, accounts from EAP 161 are accounts that we won't migrate during the conversion. So we have to test that this works correctly in our implementations. There are some border cases that can happen on the last block of the conversion. We have also to test for what will happen whenever you will move key values from the Merkle tree to the workload tree that are stale because another transaction before has written things directly to the workload tree, so those things shouldn't be moved. You also have test cases for what will happen if the keys that you will move in a block also are going to be written by transactions in that same block. And yeah, so there are like a lot of these kind of things.
00:34:01.040 - 00:35:21.199, Speaker B: So if anyone is interested in understanding a bit more what could happen in the conversion, this might be an interesting read. As I mentioned earlier, I was, I am working on, I have already like a draft of the EIP for the state conversion. So we have a source of truth of what is really the conversion. So that will be helpful for knowing what should happen and also for clients to implement it. So probably in this week or the next week I will share the CIP so everybody can understand what the conversion is really. So yeah, I just wanted to make a quick mention about this. So regarding this other topic of the cold access gas overhead for Berkel, so as everybody knows in this call, because this is like a really technical audience that knows about Berkel, in the vertical change we have to, whenever you do a transaction, apart from paying gas for computation or state access, you will have also to pay for including the cold chunks needed for executing transactions.
00:35:21.199 - 00:36:54.840, Speaker B: So this is a kind of gas dimension that doesn't exist today. And I think that probably everyone might be wondering, okay, how much of this new gas payment might be expected in a real transaction, right? So this is one of the questions that this document tries to answer. So what is the expected code access has overhead on the current mainnet transaction access patterns. So I mean, you can try to answer this question by thinking theoretically or using testnet transactions. But the best way to really try to answer this is to use mainnet access patterns because this might be different from testnets once. And the other question I wanted to answer is today we have this 31 byte called chunker that we use for chunking, but we also have these other proposals like the 32 byte cold chunker proposed by the Ipsalon team. And despite it's really, it's not that hard to compare them theoretically, as usual, if one is better than the other, whatever that means, can only be answered by real access patterns, not really like theoretical ones, because there will be always cases in which one will be better or worse than the other.
00:36:54.840 - 00:38:11.230, Speaker B: So the real question is what is the average case or something like that. So yeah, I want to thank Pavel, because when I was implementing the 32 byte called Chunker in go, he had like a slight sidecar comment that really inspired all this work. So yeah, just wanted to mention that, so I won't go into full detail on this document. It might seem pretty long, but it's full of charts, things like that. So if you like looking at charts, maybe that's interesting, but I just want to mention which was the method to really do all this analysis. And it's quite simple considering that most people here are core devs. So basically what I did is I created a geth livetracer that for each mania transaction records what I call the PC trace, which is basically saying, let's say that you have a transaction that only executes code from one contract.
00:38:11.230 - 00:39:29.636, Speaker B: The PC trace is basically the program counter that executes instructions in this, in this transaction. So like a sample PC trace might be something like this, like one 2310 15 or whatever. So you are executing instructions, then maybe you have a jump and you keep doing stuff. Okay, so of course in the transaction you have more than one contract, you will have a PC trace per contract in the transaction. So basically what you can do with these numbers is you can exactly calculate which go chunks you will access in a vertical world for this transaction execution. So basically what you do is you take these PC numbers, you map them to the corresponding call chunk number, and this depends on which kind of chunker you use. So that's the idea of this method allowing you to compare different cold chunkers.
00:39:29.636 - 00:40:38.500, Speaker B: And after you have the cold chunk number, you can map that to the tricky and calculate the gas costs. So you can see if a particular cold chunk access is cold, it's warm, has been charged before or whatever. So you can have like an exact calculation of how much gas you will pay for the accessing code. I basically export these PC traces for a million transactions. And I wrote some other programs to analyze this data and use a Jupyter notebook to generate some analysis and charts. So all of this thing is pretty much automated, so we can run it again in the future, or if you have some other code chunker proposal, we can also run it and compare stuff again. So all this data is based on 1 million transactions between days 24 and 25 from June this year.
00:40:38.500 - 00:41:54.780, Speaker B: And basically there are two main conclusions. The first one is basically if you simulate how much gas a transaction would pay for accessing coal, how much that would be compared to current mainnet gas consumption for that transaction. And the answer to that is that on average that will be around 30%. So basically if you take a random maintenance transaction and is consuming 100 gas, the amount that it will consume regarding code accessing will be 30. Okay, that's kind of the super simplified TRDR. You have here a histogram that really shows like how many of them will have like a 20% overhead. There are others that will have 80% overhead, but it's not really that many things like that.
00:41:54.780 - 00:43:16.710, Speaker B: I also show here like worst case scenarios that I found like there is a transaction that has 130% overhead. These are like outliers. So these kind of things might be useful to maybe better understand these weird cases. So yeah, like TLDR is basically that number. Of course there is much more detail that you can find in the document then regarding this comparison between the 31 byte codec and 32 byte codechanker, if you don't know how this 32 bytecode chunker works, you can read the original proposal from the epsilon team or you give a TLDR if you are interested in a shorter description. So basically we can compare these code chunkers in two dimensions. The first one is if using one code chunker or the other makes any difference on the gas usage for a transaction.
00:43:16.710 - 00:44:19.000, Speaker B: And the conclusion here is that the third two byte code chunker uses around 1.5% less gas than the 31 bytecodechanker. So it has an improvement. It isn't like super crazy improvement, but it's at least 1.5%. And the other dimension that you can compare them is the chunked contract size. So basically you take the original code, you chunk it on each chunker and you compare the final size of both. And on that dimension, the third two byte code chunker is using on average 3% less space, which is I guess nice.
00:44:19.000 - 00:46:04.474, Speaker B: Again, it isn't like a super crazy saving, but it is saving space. Of course, like to make any kind of decision, you have to take these numbers, compare that to any kind of complexity analysis of the implementation of each, and maybe come up with a conclusion. But I wanted to leave any kind of discussion out of the document and only show like data or results. And finally I said, okay, well maybe apart from like showing average cases or even if I show histograms of everything, let's take a look at like more concrete contracts. So I said, okay, maybe looking at top burners, like if you go to ultrasound money website, that you see which, which contracts are the most used of course you will see the Uniswap universal router being one of the most used ones, or like the one that burns more gas, burns more east regarding gas. So in the case of Uniswap, we see that coal access overhead is greater than the average is around 54%. And we see also like there, which is below average, is around 21%.
00:46:04.474 - 00:47:45.250, Speaker B: Remember that the average was around 30. And after some digging of. Okay, so why Uniswap might be higher than the average? The reason for that after some digging can be found in something that I show here, which is basically something that makes a lot of sense in hindsight, which is the more your transaction calls, the more calls your transaction has. So the more contracts you interact with, usually the more overhead you will have. Because calling a contract usually means forcing you to pay at least one call branch access, which is pretty obvious because for the contract, for the contract that initiates the transaction, you have to always pay for the contract header because you have to touch the notes, the balance and everything. But in uniswap it's pretty common to call a lot of contracts, because obviously the idea of Uniswap is if you want to swap two tokens, there is usually no direct liquidity pool between both. And you have to switch token a with token b and b with c and c with d to really achieve what you originally wanted of swapping a and d.
00:47:45.250 - 00:48:43.750, Speaker B: So in uniswap, it's really common to do a lot of calls to access liquidity in different contracts. And accessing too many contracts basically means you will have to probably pay for a lot of gold branches. And this accounts for like high gas costs compared to the average case, which usually maybe interacts with one or two contracts. So, yeah, if you are more interested in details about all this, I will just invite you to read this document, which I will share in the chat. Well, I see a lot of comments here and yeah, if you have any other further question, just let me know. Thank you.
00:48:52.850 - 00:48:57.790, Speaker A: Awesome. Any questions or comments before we wrap things up?
00:49:01.260 - 00:49:20.960, Speaker C: I just have a quick answer to Gary. I copy pasted the list, like my presentation, and if you go back, this is page five of my presentation. If you go before, you have all the described proposals. Cool, thanks.
00:49:33.430 - 00:49:39.130, Speaker A: Cool. All right, well then we can end things there. Thanks everybody for joining.
00:49:40.550 - 00:49:42.718, Speaker C: Thanks. Bye. See you.
00:49:42.894 - 00:49:43.486, Speaker A: See ya.
00:49:43.518 - 00:49:44.206, Speaker F: Thanks.
00:49:44.398 - 00:49:44.830, Speaker E: Thank you.

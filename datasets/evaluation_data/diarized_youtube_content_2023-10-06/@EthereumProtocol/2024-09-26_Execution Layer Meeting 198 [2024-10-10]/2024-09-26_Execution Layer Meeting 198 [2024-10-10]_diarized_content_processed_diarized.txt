00:01:01.055 - 00:01:41.495, Speaker A: And we are live. Welcome everyone to ACDE number 198. Bunch of picture related things today, then some EIP Updates and new EIPs to talk about and then if we have time, there's a couple more CL related topics that were also put on the agenda. So we'll see if we can, if we can get to those. And before we get started, we had this request out for audits for the PETRA system contract. So the proposals are closing tomorrow. If there's anyone who still wants to submit their proposal.
00:01:41.495 - 00:02:18.359, Speaker A: Yeah, this is your last day today and tomorrow to do so. I posted the link in the chat here, but it's also on the agenda. Yeah, on picture itself I Believe there's a CL spec release for DevNet 4. Any other updates on overall readiness and where we're at there? Yeah. Hi everyone. So I'm taking over from Ari while he's on holiday. So for Devnet 4 we have a.
00:02:18.359 - 00:03:38.085, Speaker A: This backlist right here, I just linked it in. We have a couple of more open issues that we should probably discuss during the call today, but it looks like we managed to close quite some issues throughout the or quite some PRs throughout the past week, so I think we should be good to go. We also had Alpha 8 release just yesterday I think. Yeah, let's go over the issues now. I know maybe BLS was already on the agenda, but yeah, do you, do you want to go over the ones you think are most relevant right now? We had the update, the submit pool attestation v2 endpoint 4.7.2. Okay, we haven't got an update on this in a while, so I would just like to make sure that we want to include this and if we do then maybe we can merge that in. Does anyone.
00:03:38.085 - 00:04:19.675, Speaker A: Alex, are you saying that we do not want to merge this in? Basically, yeah. For 472. So I think for this it's for a different CL PR that we at least said we put into a later DevNet. Okay, so we can omit this one from DevNet. Yeah, perfect. I'm pretty sure that's what's going on. Okay, so we can omit this and then if we scroll down future hard Fork, future DevNet.
00:04:19.675 - 00:05:27.783, Speaker A: So on the CL spec, okay, we have this one. So I think we're good then on the CL spec and beacon APIs, unless I'm missing something. And then on the Execution API we had like Client already put this one on the agenda. But the pull request 575 on the execution API. Yeah, don't like Client do you want to give some context on that one? I think Paul has been working on this. I don't know if you wanted to just quickly mention the changes. Yeah, I can screen share too if you need, but it's essentially the same as 4844 minus the blobs and plus the authentic authorization lists, the links in the agenda as well.
00:05:27.783 - 00:06:48.695, Speaker A: So, and I guess given this is like an execution API scheme, do we want to block launching the DevNet on this or. Yeah, I can say that we need to get the 7702 changes upstream to a few places before we can merge this. So I would not block on it, but clients should be aware of the scheme and this is a good time to raise any concerns with the formatting right now. Okay, anyone have comments now? Otherwise we can point people there to review asynchronously. Okay. If not, it seems like there's a CL PR that was marked as merged, but that isn't 3900 separate type for an aggregated network at a station. I don't know if we have the right people here to make a call about this one, but any updates or things people wanted to flag.
00:06:48.695 - 00:07:34.165, Speaker A: Is this something we want for Devnet 4? No. So yeah, this is the one that was paired with 472. So yeah, this is a change to the attestations along with I always forget this number. I think it's 7, 495. Is that paradise? Anyway, the attestation EIP and Pectora, this would go with that but when we discussed this might have more code change than it appears and then we want to evaluate that against timelines for petra. So what we said was we'd give another AC DC cycle for client teams to take a look. Point being, it would at least be DEVNET 5, definitely not DEVNET 4.
00:07:34.165 - 00:08:58.035, Speaker A: Okay, sounds good. Okay, and then on the EL side there is one last open PR which is 8949 that changes a bunch of VIPS based on how we adapted the request format. Yeah, like any more context you want to share on this, I don't think there's any thing that people care about here other than just making the request. EAPs match the new formatting for 7685 because before request data referred to a single request, and now we're using request data to refer to the output of the system contract. So that's just updating that. But the other changes have already been made to all the EIPs for the DevNet. So this is kind of this is not really changing any behavior.
00:08:58.035 - 00:09:56.963, Speaker A: Okay, so I guess can we just get this merge in the next day or so if there's no comments on it? I think that's everything that was open or under consideration for DevNet4. Anything else I'm missing? Barnabas? Andrew. Andrew has a question. Yeah, I have a question. I'm slightly confused. I think there was a proposal to remove a request from Blog Body, but I see that the Corresponding change to IP7685 was closed by light client. Oh, it's okay.
00:09:56.963 - 00:10:28.201, Speaker A: It's superseded. Yeah. That's the PR we just talked about. Yeah. Ah, all right, so. But like, does it mean that requests like that blog bodies are no longer contain requests? I just want to clarify. So are requests removed from.
00:10:28.201 - 00:10:45.159, Speaker A: They're removed. Okay. Okay, good. Okay. Sorry, Barnabas, you're. Can you say something? Yeah. So I think that that's it for Devnet4.
00:10:45.159 - 00:11:13.957, Speaker A: I'm curious about client implementation readiness. Possibly we could talk about timelines for launch of this DevNet. I think there's one last thing. The art filters. Yeah. Since DEFNET 3 is not finalized right now, we should maybe talk about this first. Okay.
00:11:13.957 - 00:11:37.999, Speaker A: So yeah, let's finish the spec discussion, then talk about Devnet 3 and then we'll talk about Devnet 4 launch. One other thing. So let's. Client has a comment and then it's also worth talking about the BLS precompiles and you know, whatever you'd want those changes that I'm in DevNet for. But yeah. Yep. So there were some changes to 7,702 in the last couple days.
00:11:37.999 - 00:12:29.595, Speaker A: One of those was fixing up the serialization for 772 authorization tuple elements. So we restricted the sizes to the values that we had previously discussed. But one thing that sort of fell out of that was we had a serialization requirement previously that the forget. I think it's the S value has this EAP2 restriction where it's half. It has to be on the lower half of the valid range. And this exists in transactions today to avoid this transaction hash malleability. And we sort of just pushed it into the authorization tuple list because that's how we typically do signatures.
00:12:29.595 - 00:13:15.395, Speaker A: And there is now a question. I didn't necessarily intend to remove it. Whenever I updated the spec, my intention was to keep that check, but it sort of opened the question. And Kim mentioned that it doesn't seem it's necessary to have this check for the signature in 7702 for the authorization Tuples because you don't have the same transaction malleability issue. If you were to have another, if you were to change it to be the same valid signature just on the other end of the range, then it would actually change the entire transaction hash, which would require the outer EoA to resign, etc. All this to say I'm indifferent to what we do here. I think if people have any feeling one way or another, I'm happy to go with it.
00:13:15.395 - 00:14:36.805, Speaker A: I just had kept. I had the intention to keep the bound check on it just because that's how transactions are typically signed and verified against. But if they're there, the reason that it exists for transactions is not necessary for here. So it's just a question. Do people want to be consistent with transactions or is it okay to have it slightly different and closer to EC recover as it normally is in the pre confile? Anyone have thoughts comments about this? If not, should we move this conversation to the R D discord and yeah, maybe give people a bit more time to think through it. Yeah, I mean I think barring any comments here, I'm just going to add the check back in since that's how tests are and if someone has a feeling that we should Change it for Devnet 5, let's do it. But I don't really see a reason to block anything else related to DEVNET 4 on this.
00:14:36.805 - 00:15:24.933, Speaker A: Okay, so you're going to add the change back in and we assume that PR is part of DevNet 4, correct? Yeah. Okay, sweet. Yeah, so yeah, just I guess send Barnabas a ping when you have that PR up so we can track it. But sounds good. And okay, so while we're talking about spec changes. Yeah there was some updates around the BLS precompiled pricing saying that the mole pre compiles still are like underpriced and then a PR open to potentially remove them. Do we have author on the call? Yes, yes, I'm here.
00:15:24.933 - 00:16:14.175, Speaker A: Yes, Hi. Okay. Yeah, hi Pablo. Yeah, do you want to give a bit of context? Yes, so I think this, these pull requests are not actually related. The biggest issue we have is that the gas price for multiscalar multiplication. So one of the precompiles in BLS don't fully match the reality of how the implementation works. And to my understanding this is because this discount to the multiscaler multiplication some like table which says how cheaper this is supposed to be based on the number of points you get in the input.
00:16:14.175 - 00:17:49.685, Speaker A: It kind of makes the general cost trend sublinear but at Some point which to my understanding is that was done after this initial gas cost were proposed. We also added a subgroup checks for the inputs which is kind of linear factor because you need to do the check on every point and this linear factor actually quickly, relatively quickly dominates the total costs. So to my implementation which is based on plst library, around 100, 120 points, like half of the time is spent on the subgroup checks of the input and the other half is actually spent on actually doing computation. So that's more how it looks like. And I think there was number discussion number places if do we need these subgroup checks? And yeah, there's number of opinions. I don't have strict opinions about it, but I think that's like the most pending issue we should resolve. I can speak for nevermind on this.
00:17:49.685 - 00:19:27.127, Speaker A: So we ran some native C benchmarks and these had much lower variance than the state tests. And they also agreed that with the results that the MSM precompiles steam underpriced, but without the subgroup checks they seem. So I think one possibility is to have to increase the cost of the normal MSM check and then have an alternative version without the subgroup checks because I think in a lot of cases you might already be confident that the points are in the correct subgroup, so you don't need this overhead. So we can have a cheaper version of the precompiles without the subgroup checks? Yeah, so I mean this would be sort of like an unsafe version, as if you did call it with points from outside of the subgroup, it wouldn't be guaranteed to have the same result. So you'd have to be careful about when you use this version. And also I saw that EVM one team made another proposal to remove the multiplication precompile and generally we would also support this as it's just redundant as the same functionality is covered by msm. And if we were to add a non subgroup check version, then this would just simplify things a bit and we wouldn't have to add even more precompiles.
00:19:27.127 - 00:20:59.981, Speaker A: We only have to add two for MSM and the pairing. Yeah, from a basic perspective, we did a lot of benchmarking specifically with the proposed discount table bump and with subgroup checks obviously. And we found that when we're using pippingers, the discount table gives us a pretty flat price distribution across different pair accounts. But we did find that G1 MSM was still underpriced and G2 MSM is overpriced, at least in comparison to EC recover. So in order to kind of bring those into parity with EC recover. We found that bumping the multiplication cost from 12 to 19 on G1 MSM brought that in line with EC recover and dropping the G2 MSM multiplication cost from 45 to 33 kind of just gave us almost flat kind of parity with the cost of EC recover. One other thing about the removing mul One of the kind of idiosyncrasies of our implementation is that we initially started with a non pippinger's version of MSM and found that for single pair counts or low low count pairs that we it actually performed better than Pippingers.
00:20:59.981 - 00:22:02.995, Speaker A: So if we removed mole, I think at least in basically what we probably would do is just kind of intercept the single pair count MSM and not use Pippenger specifically for that. But it seems like we could remove Molly and the notion of having a non subgroup check version seems like maybe we could reuse those precompile addresses for a non subgroup check version. Thanks Potus. Podus disappeared. Sorry. An advantage of having the separation of the subgroup check and the linear combination is that there's different safety thresholds that you might have in an application. Some applications may not need at all.
00:22:02.995 - 00:22:38.749, Speaker A: And even those that do need, there's two scenarios. You either need to check for every one of the points that you're summing up, or you need to check only one that you're adding. So it means that you can check on the total sum and be fine, or check independently each one of them and be fine. And I'm sure that there's application for all of these things, I don't see any reason not to include them separately. That's an interesting notion. You're saying like have a G1 and a G2 subgroup check precompiler. Yeah, just have them separately.
00:22:38.749 - 00:23:29.915, Speaker A: And then anyone that actually needs to call this linear combination with a separate check, just check it. And there's some that might want to check it before doing the linear combination and some that might want to do the check only after and just check the sum. And this is something that we are, I mean this of course work contracts, but this is something that is actually happening on the cl. There's a lot of times that we have a linear combination that we don't do the subgroup checks at all. Okay. And then there's yes, some comments in the chat about, you know, maybe we could do this as an input to the precompile so either it has the subgroup checks or not. And then.
00:23:29.915 - 00:25:07.693, Speaker A: And then, yeah, whether or not we want the same Number of pre compiles. I guess my sense here is overall there are still things to figure out on this, so I would lean towards potentially not making These changes for DevNet 4 unless someone feels it's urgent to do so. But yeah, like I think if we can try to work out the spec on this in the next couple of weeks, yeah, we should block dev on that and just. Yeah, I guess one question I have is like, what's the right, what's the right next step here? Do people just need more time to review this? I think. Should we have a call specifically focused on this and trying to go more into the details? Yeah. Any strong opinions there, Radek? Yeah, so there is one additional thing to add here because this subgroup check now guarantees that you can use, you can use the additional optimization in the algorithms, which is the using of the endomorphism. But so if we remove this subgroup check, not sure what will be the results for this kind of algorithm when the points are not guaranteed to be in the proper group.
00:25:07.693 - 00:26:07.051, Speaker A: But yeah, this is something which should also be considered here. And I think the issue there is that different libraries might implement different algorithms for this. And so if the behavior is undefined, if it's not in subgroup, then that might lead to some consensus issue on some points because they behave differently. Yeah, we might not know. Yeah, exactly. But on the other hand, on the other hand, from the benchmark it looks that basically these precompiles are kind of useless for many points because the cost of the subgroup check and exactly the case which POTUS already mentioned about algorithms which by design guarantee that the input is in the proper subgroup, don't need the check. So in these cases these three compiles won't be useful.
00:26:07.051 - 00:27:07.705, Speaker A: But absolutely. I don't know how exactly these precompiles are going to be used. Yes, Kev. So I think the subgroup check is mostly useful for the G1 mul for MSMS. Most implementations I've seen don't use the this optimization that we're talking about just because it's not that useful for after a certain threshold. So Gnarc, for example just doesn't use it. But G1 mile they do use this optimization that we're talking about and I guess if we don't do the subgroup check then G1 mul would probably increase by a 2x.
00:27:07.705 - 00:28:33.537, Speaker A: So yeah, I guess there was a comment chat by Alex about potentially having a breakout. If we can get all relevant people on the same call, would it be realistic to try and do a breakout on Monday either before or after the testing call, if not potentially making that the focus of the testing call. I'm sure there's other stuff as well, but people seem to be available at 15 UTC. Let's do 15 UTC Monday breakout on this. I'll put up an agenda, put up an agenda for it right after this call. Is there anything else I guess before we, before we close off here that people feel we should discuss on the BLS pricings or additions or removals of contracts? Okay. So yeah, let's try to iron this out on Monday and then we'll see.
00:28:33.537 - 00:29:10.623, Speaker A: Yeah. How big or large of a change it is that we need to do. And yeah, thanks everyone for spending time looking into this over the past couple weeks. I think this was the last DevNet4 spec issue and then yeah, we'll see whether or not we add this based on complexity. But is there anything else around DevNet4 specs that people want to chat about? Okay. If not DEVNET 3 we're not finalizing right now. Yeah.
00:29:10.623 - 00:29:35.425, Speaker A: Anyone had context or things they want to bring up around this? We're running an older version of Geth deploying the new version on saying if it were recovered. So Geth was the only one that had an issue. Yes. Okay. And it was like a super majority of the development. Is that why it let it. Oh, it's barely over 30%.
00:29:35.425 - 00:30:10.737, Speaker A: Okay. Yeah, I see. Okay, nice. And we have some other validators that also not testing and that's why we just went under finalization gaff on its own shouldn't have breaking the network. Okay. And so the other validators I guess we need to figure out what the issue is with there with them. So Ethereum JS is the other one that is not able to flow the head of the chain but that is known.
00:30:10.737 - 00:30:59.233, Speaker A: We're going to exit those validators and we have some big deposits that we had made in the beginning of the DevNet and we're going to exit those validators also. So we should be able to reach very close to 100% participation. Nice. And I guess is there anything else we want to be testing on DevNet 3 aside from this get bug fix or assuming that works, are we happy with things we're at and ready to shift our focus to Devnet4? I think we should be good to go to proceed to DevNet 4. Okay. And in terms of implementation. Yeah, you know BLS aside because that's the an open question but I'm curious how.
00:30:59.233 - 00:31:20.041, Speaker A: Yeah. How much work the teams feel they have to do to get the readiness for DevNet 4. Oh, and yeah Mario, maybe if you want to start with a testing update. Yeah, of course. So I think all the spec changes are that we needed to update. Tests are raised. So it's just a matter that we finalize the changes to the test.
00:31:20.041 - 00:32:23.769, Speaker A: So that should be done today or tomorrow. And I think at the moment Ethereum JS is working on an updated version of the transition tool interface which will help us to fill the test. So I think a release for the fixture should be possible for tomorrow. Amazing. And then Geth is saying a couple days for them in the chat. So is it. Again, take BLS aside for a second, but assuming we made no changes to BLS, would it be possible to try and launch DevNet 4 before next ACDC? Or does anyone think that's unrealistic? Okay, so yeah, let's try and aim for a pre ACDC launch date and then see Monday if there's any big BLS changes that we consider urgent.
00:32:23.769 - 00:33:02.035, Speaker A: But otherwise it might be worth just trying to ship Devnet 4 next week and then dealing with BLS and Devnet 5. Yeah, could we actually just freeze this back in this call maybe and agree that we're not going to do anything with bls and if we do something with BLS then that would be in Devnet 5. That way client team can actually. Yeah, I'm happy with this by next week. Anyone have an objection here? Okay, are we talking about removing BLS from. No, no changes. Okay, no changes.
00:33:02.035 - 00:34:03.621, Speaker A: We leave it as. Yeah, yeah, yeah. So this way like any engineering work towards bls goes towards Devnet 5 basically. Okay, so let's consider Devnet 4 spec frozen, try to get it live before AC DC next week and then we can deal with BLS in the next DevNet. And actually yeah, maybe as we start talking about DevNet 5 there was this idea brought up a couple weeks ago that yeah, we'd want to do like a live or a longer lived testnet. Sorry, I don't know if we want this to be Devnet 5 or maybe it'll be what would be Devnet 6. Yeah, we can see how this evolves, but there is a thread on ETH Magicians to try and set a name for it.
00:34:03.621 - 00:35:31.531, Speaker A: So I think in the next couple of weeks, once we. In the next couple of weeks, once we finalize the spec for Devnet 5 and decide whether or not we want to make this the long live testnet, we should find a name for it. So please visit this thread. Yeah, I don't know if there's any other thoughts comments on that. Ideally we also want client teams to make a release for this so the public can also easily sync up this chain. I'm not sure if this is reasonable, but I think it would be nice to have okay, yeah so comment by saying devnet4 should be moodyng? Yeah, I guess let's see how devnet4 goes and then if there's any issues we can address that. I guess my argument for maybe the BLS changes being in the public devnet is if we do something like change the precompiles, like remove some or split the subgroup checks out as separate precompiles and stuff like that, there might be value in having that in the public devnet if people want to test applications against it.
00:35:31.531 - 00:36:28.735, Speaker A: So if there is something that is going to change how you'd interact with the BLS precompile and we think that's important for the community to test, then we should probably try and include it. If it's just gas pricing I agree it's probably not the end of the world but yeah, we don't have to make this decision right now. Yeah, I agree but I'm also just thinking, I think it would be best if Mudang, whatever we call this test net is stable for the community. So like I wouldn't want to like launch five a few days before devcon and then you know, find issues and then now it's chaotic. So I think time wise we'll have a better chance of having four be nice and stable. Yeah, sure, yeah, yeah. And I think actually yeah I do agree that having it for defcon would be nice because we'll probably cancel a couple awkward dev calls during DEF CON and like all of us or majority of us will be traveling and stuff.
00:36:28.735 - 00:37:26.590, Speaker A: Being able to ship off something that's relatively stable either right before or right at the start of defcon means that for the couple weeks while there might not be as much new devnets going live and stuff like that, at least there's something for the community to test. I think that might be the right approach working backwards from what can we ship before devcon and then if the BLS changes make it in, great. Otherwise yeah, otherwise then we just don't include them there and have something stable. Okay, sweet. I think that's everything on pctra. Anything else that people wanted to discuss that we didn't get? 2. Okay then EIPS.
00:37:26.590 - 00:38:12.555, Speaker A: So Tony had an update to 7623. Tony, do you want to give a quick overview of that. Yeah, sure, yeah. EAP763 increased call data cost so based on the feedback I got from Tanish we changed that. We don't deduct the intrinsic gas cost before execution. Now we instead just check if the transaction sender is theoretically be able to pay the floor cost. Thanks for posting the link Tim.
00:38:12.555 - 00:38:59.471, Speaker A: You can find all the changes in the execution specs PR so far. I heard that Ref and netamind have already implemented it. I think Marios was also implementing it and also curious how is it going at Aragon. Thanks. Yeah. Any comments about this from implementers? I've not implemented the latest our suit PM okay. Okay.
00:38:59.471 - 00:40:20.495, Speaker A: Anything else on this? Yeah, thanks Tony for sharing the changes. Okay, so next up there were two new EIPs proposed in the past couple weeks that tried to address similar issues around resource consumptions. First there was one proposed to reduce the slot time and then one that was proposed as a non core EIP to adjust the gas limit based on to adjust the gas limit programmatically slot time 1 although it was like the first proposal is like kind of a CL thing so it probably makes sense to discuss the gas limit one first even though it came after. But yeah, I think let's just open this up and then be mindful that there's like these two proposals that are somewhat related. But yeah Julio, do you want to start with yours and can take it from there? Yeah, yeah. So first just to give an introduction to what this IP does, it's basically just another strategy to adjust the gas limiting client so it doesn't add any hard fork. It just basically makes it so that with certain parameters you can set your proposed gas limit to increase over time without cap at some point.
00:40:20.495 - 00:41:32.875, Speaker A: So the re so the reason why I wrote this was first of all there are some of the problems that were with the slot time reduction and also because one of the main issues that were that most people have with increasing the gas limit is the uncertainty of potential bugs coming up due to the increase. And an example of this is kind of the 413 status code incident which if we increase the gas limit to 40 million we would probably have issued the chain because then the blocks would have probably been too big on for mainnet and this and this type of issue is kind of something that you cannot really predict either. So this IP mostly tries to decrease the risk related to the actions of increasing the gas limit. It doesn't really of course have to scale anything but it does reduce the risk significantly compared to a fixed gas limit strategy which is now employed by clients. And yeah, I mean it also addresses the prob. And some problems that. That the slot time reduction have.
00:41:32.875 - 00:41:59.545, Speaker A: For example, the fact that it has to go to the cl, this one doesn't even need an out fork and it's also quite much. It's also simpler. But maybe I think that the drawbacks can be discussed when the other AP will be discussed probably. Thanks. And yeah, actually let's maybe do that. Let's have Ben share his eips and then we can take. Yeah, you can take questions and conversations about kind of the set of them.
00:41:59.545 - 00:42:24.735, Speaker A: Yeah, yes, sure. The. So the idea is. No, sorry. So I just want to say that of course another thing I would like to say about this is that this of course is to increase the gas limit in the short term. So maybe it's better to also get a kind of a vibe check from that too. Yeah.
00:42:24.735 - 00:43:46.925, Speaker A: So mine was in response to Vitalik suggesting that we increase the without peer das, we increase the blob counts and the idea was if we speed up the slot time, we increase the blob counts and we increase the gas limit also, but without increasing the block size that any individual validate, block producer or validator has to deal with. And for both the PRs, one of the concerns. Sorry, for both the EIPs, one of the concerns is like what about history growth? What about state growth? State growth isn't pressing immediately but for history growth we obviously have four. Four fours or four fours. But due to blobs the amount of call data that's being posted has decreased significantly. So the history growth has also decreased significantly. So we do have some safety margin that wasn't previously expected.
00:43:46.925 - 00:44:13.247, Speaker A: There you go. That's a summary mostly. Thank you. Yeah, there's a comment saying that, you know, the state size does matter if we. If we do something like Verkal or. And we transition to a new type of structure for the try. But yeah.
00:44:13.247 - 00:45:02.783, Speaker A: Any other thoughts? Comments on these two EIPs? Sorry, just to comment about Verkal. I mean that's very comment about Verkal. The state size matters before we do the transition. Right. After that not as much, but before it does. So I guess, yeah, maybe let's start with the gas limit. One, like how do people feel about one, the overall idea of a potential increase and two, that if we were to do an increase to have the increase be kind of programmatic rather than like a one time number that we propose.
00:45:02.783 - 00:45:50.965, Speaker A: And obviously this isn't something that like this is something that every validator sort of decides. But like there's a difference if the default, you know, in all of the client software moves from, you know, 30 to 40 to 40 million. Yeah. Well, after like four days of the discord being completely flooded with this. Yeah. Not much interest on the call. Bigger problems right now than raising the gas limit.
00:45:50.965 - 00:46:27.483, Speaker A: Yeah. I mean, I. If no one has thoughts on this, we can continue discussion Async, but. Okay. Iraq thinks a gradual increase would be better and then, I mean, I feel like we've committed to increasing the scalability of Ethereum through blobs. So we need to focus on getting higher blob throughput out there. Yeah, but blobs and gas limit kind of works on two different axis.
00:46:27.483 - 00:47:05.615, Speaker A: Blob is Blobs are capped by bandwidth while gas limit is capped by storage. They are two different dimensions. If you increase the gas limit, you're not going to increase the bandwidth requirement by that much because most of the bandwidth right now is from blobs. Yeah. I'm not saying that they're addressing the same thing, but we have sort of made a commitment as an ecosystem that we want activity on L2s and that means that we need to increase the throughput for activity on L2s, not necessarily on the L1. Well, but it's nice to have on L1, isn't it? As well. Yeah.
00:47:05.615 - 00:47:39.635, Speaker A: And we should address it after we finish the things that are the priority right now. My point is that it can be done in parallel because if it doesn't get in the way of the priority, why not making it in parallel? Because we don't have the ability to do things in parallel. We can barely ship this fork that we're working on right now. Well, but I mean, this is kind of a trivial change. It doesn't even require an art fork. Right. It does require testing and analysis and like.
00:47:39.635 - 00:48:05.125, Speaker A: Yes, it does, but it's not something big like blobbing, because blob increase does require a lot of time. Right. And also seconds first lot required time to test. It's just make. You need to just make sure that every client, that this small function returns the same number on every client during a DevNet. Yeah. Which can be done in parallel with DevNet 4, for example.
00:48:05.125 - 00:49:00.127, Speaker A: I think one thing about this proposal as well is a lot of the concerns around blob increases is we have to wait for another hard fork which will take six months or something like that, or more. You could imagine doing something like this right after Vectra where if we actually think that we are bandwidth constrained in the next couple of months. And we want to maintain our focus on shipping PETRA or even when we put out the mainnet client releases. @ this point, we expect clients to be effectively done with the PETRA work. This is something we can literally ship the week after that or something like that. And another thing. And another thing is.
00:49:00.127 - 00:49:37.267, Speaker A: Yeah, that. And another thing is that, yeah, again, this is not really that big of a change, but I also saw that Alex Talks said that it's actually riskier. I don't know what he means by that, though. Yeah, I mean, the concern is like, I mean, again, I haven't looked at this exact VIP yet, so maybe I'm missing something. But the concern is just like, if we have some automatic increase schedule, it could be very hard to stop the automatic increase. And then the concern is then that, you know, like, no, there is a cap. The network falls over.
00:49:37.267 - 00:49:57.305, Speaker A: No, you can set a cap. Like, it's not infinite. Like in the app, it's written that there is a cap and after you reach to, say, 40 million, it stops. It increases. Of course, if you change the defaults yourself, it's going to still increase. But the same can be said by the current fixed strategy. Yeah, so, actually, so, yeah, a way to frame this can be.
00:49:57.305 - 00:50:10.141, Speaker A: It's. We're. We're like expanding the bound. Right? Like, we're. And again, no. Yeah, yeah, yeah. But I think that overall this is just an improvement upon the current strategy.
00:50:10.141 - 00:50:58.495, Speaker A: So if anything, it should be treated as just a nice improvement to have and eventually to bump up the gas limits. Right. And. Yeah, so, yeah, got it. And Potis. Yeah, I just wanted to echo what Juliet just said, that I'm not advocating for increasing or decreasing or anything on the gas limit, but DCIP seems to make it safer actually than the way that we currently have of increasing the gas limit. If we decided as a community to go and we get people that are ramped up and we get validators to like, say, move to 45 million for the gas target or for the gas limit, then it would start immediately increasing at the maximum level.
00:50:58.495 - 00:51:28.877, Speaker A: We may find out that it's hard to do. And getting back from that is much harder than if we do this at a slow pace as the CIP is showing. So I actually think it's safer than the current mechanism, not more dangerous. Yeah. And I also would like actually to have a more like, strong response from. Because for now I just heard from Gaff and Nethermine. Nethermine seems to be okay with raising the gas limit.
00:51:28.877 - 00:52:30.255, Speaker A: Gaff seems to say what like clients had but other clients like Bezu I would like for the European too. Of course. Yeah. As I shared on Discord, so we have like these two EIPs decrease in slot time and increasing block size. So as I said on Discord, decreasing block time it seems more CL concerns because currently from the metrics I gathered we have 5% of the blocks that arrive after three seconds. So we could have attestation misses, maybe blocks reorgs. Yeah, so this is like more on the CL side and basically if we're going to keep the 4 seconds window on the EL side or we're going to review it like related to this 8 second on the block size.
00:52:30.255 - 00:53:07.105, Speaker A: So increasing the block size. So there are different areas we need to, we need to check here. In terms of block processing I think there is no issue On PAISU side we have like few, like we have few EVM or precompiles that are slower than other clients that we are currently addressing. But this is on the per second basis. I mean on like there's still window. Right. But while addressing those differences.
00:53:07.105 - 00:54:14.745, Speaker A: So in terms of slot time, I mean in terms of block processing there is no issue. So in terms of bandwidth, solar staker requirements, storage. So I believe this is more. We need like more testing to know how it's going to behave. But my first feeling is to say yeah, well for increasing block like block size because we already, this is something we already have on L2s. Not exactly on the block size, but yeah, but I mean we have like similar configuration on R2s that work very fine even if there is, you know, it's less decentralized. But maybe yes, but for more testing and yeah, and as I said also on the discussions in a gradual way it seems to be the right way to do it.
00:54:14.745 - 00:55:09.279, Speaker A: Yeah, and also, and also yeah, so if you increase it gradually you also don't have most of these problems because the moment you see that sort of stickers cannot stay. They're computational. You can just alt it right. You can just make a release and even set it lower because in the APS state that you can still use the fixed guest limit option and it will overwrite the option. Right? Yeah, right. Ben, one of the advantages with increasing the block size versus the increasing slot time is increasing slot time does increase the number of consensus votes that happen because whereas block size has no effect on the consensus in that way. Oh right, yeah.
00:55:09.279 - 00:55:57.277, Speaker A: And and also I did this, I mean I did some research about around how them block size increase actually affect Computationally and the bigger the blocks, the faster actually transactions execute amortizedly because of the state route and also because of the caches. So actually if you execute a big block, it will actually take on average less time per transaction than for a small block. And I think ERICO is not the only one that is like this by the way. So actually. Yeah, yeah. Useful to consider. Okay.
00:55:57.277 - 00:56:20.465, Speaker A: So I guess yeah this is. Yeah clearly something people have opinions on. Yeah, please. No, sorry. I was reading the chat that there was somebody said that there is more bandwidth but in reality, I mean the block bandwidth is very low. Like it's like 70 kilobytes per block and the blob is like 128 kilobytes. So if you increase block size by 50% you have like a quarter of a blob.
00:56:20.465 - 00:57:12.849, Speaker A: It's really not, it's really not like a bottleneck on the yell the bandwidth. It's not going to be significant. I think Amputation. Yeah. So it's true that the decrease of the slot time is better discussed in the CL meeting. I mean there's a lot of problems on the CL if we were to adopt something like this. It's not trivial at all but there's one component that is on the EL which is does it probably break contracts or not? There's currently you can you have a linear relation between block height and timestamp and we would break that and this is a breakage at the EVM level.
00:57:12.849 - 00:57:51.485, Speaker A: So this is something that probably you guys should discuss. Yeah, that's actually didn't have that relationship before the merge anyway. So people may have deployed contracts. Right. But there's contracts that can be right now using this. There was never the stated thing that we are never going to change the block time. I think like this is not an assumption that we ever made and so developers that relied on this assumption kind of make that assumption on their own.
00:57:51.485 - 00:58:40.277, Speaker A: So it's not our fault if we break it in my opinion. And there is a time parameter for the blocks so they should be using that rather than the block number. Yeah. And I guess if we were to do this change we should definitely look at it on chain. I'm not saying that we should pause it based on this but there's a difference between a handful of random contracts have a hard coded divided by 12 somewhere or you know, some large and well used contracts have this bad pattern. I think that's unlikely but it's definitely something we'd want to be sure about if we, if we were to change the slot time. So there are.
00:58:40.277 - 00:59:39.935, Speaker A: So since I have some experience on the CL side, I can kind of give some feedback very quickly on the slot time. And my concerns about it is. So my main point, my main stance is that it's probably a good improvement overall and it's probably going to happen eventually, but it probably should not happen now because first of all, first of all, the biggest problem with solo staking is bandwidth and this will not only increase the gas limit, but also the blobs and it will increase the bandwidth requirement. And after talking to some sort of taker and the guys from dvt, they told, yeah, from DVT they told me that it's very, it will be very punitive to have an increase in bandwidth, a significant increase in bandwidth. And another issue with this is that if you. Is that it will get in the way of research on single cell finality because the times there actually matters and currently there are. There are being taught to approach.
00:59:39.935 - 01:00:16.637, Speaker A: One approach is. And one approach actually does is kind of reliant on time of the slot time. So I wouldn't really do this upgrade before single slot finality, if anything. And also you need to also consider that maybe you need to readjust some economic incentives with the CL because now validators will earn more money per year and more ETHs will be issued. So you need to also think about that. Yeah, so yes, that's just my main concerns. Thanks.
01:00:16.637 - 01:01:29.571, Speaker A: And yeah, I think we can follow this conversation on this Yale call next week, but agreed we should consider not just can the protocol support this today, but are there future changes or things that would be complicated by changing the slot plan? Anything else on either of these topics? It doesn't seem like there's an urgent decision to be made here and there's clearly like more conversations to be had. But yeah, is there anything people feel we should address on this call? Oh, and nice. Devnet 3 is close to finalize again, but there may be some Lighthouse issues. So yeah, someone wants to look into that. But okay, moving on from this. Alex, you had the PR on the builder spec that was also kind of CL related but you wanted to bring up if we had time. So yeah, thanks.
01:01:29.571 - 01:02:43.511, Speaker A: This is back to the request structuring that we've been talking about. Where we landed for Devnet4 was that the engine API would send essentially the serialized list of bytes. We have the same question to answer in the builder API. I guess I was just looking for feedback on any preferences people would have the most natural thing to do just based on how the builder specs work is to use what the beacon APIs do. And then in the beacon APIs we have this full JSON structure of the request rather than this more compressed serialization. It was a bit of an open question, do we want to mirror the engine APIs or do this other way? I was curious if anyone had any thoughts on how to handle it here. If there's no feedback, I'll go with what I had right now, which is essentially to have again.
01:02:43.511 - 01:03:32.431, Speaker A: Yeah, following the Beacon APIs, which has the full JSON structure. So the sort of downside to this is that as a MEV builder, you'll need to get your transactions which in some way will sort of emit the request data. Then that request data will need to be put in the right format. It will require a little sort of deserialization, but that's how we have. That's how it works now, probably for the cl, but this is bandwidth dependent. Right? So this is adding latency on the builder path. I wonder if we cannot just blind it.
01:03:32.431 - 01:04:00.789, Speaker A: The builders can themselves compute the HDR that we're going to put in the beacon block body and sign over. And then we just trust them that they include the right requests since anyways we're trusting them on the transactions. Yeah, the issue is that the co, like the proposer, will need the request to actually execute the state transition, which they need to sign over. The blinded block. Yeah, you need the. You need. You basically need.
01:04:00.789 - 01:04:20.095, Speaker A: Yeah, you need the state. Yeah, we need the. Otherwise we can compute the state route that we're signing over. That's right. I had it that way originally because I was concerned more about MEV and maybe some more niche case. But yeah, Terrence raised this point, which is correct. EPVS makes this much nicer.
01:04:20.095 - 01:05:34.929, Speaker A: Okay, any other comments? Okay, and then the last thing we had on the agenda. So Ryan had an ETH research trend, again more of a CL related topic, trying to nudge people towards getting better numbers around what we believe home staker bandwidth requirements should be. And this way we can make better decisions around things like blob counts. Yeah, again, more of a CL topic, but I don't know if anyone has thoughts, comments or things they want to discuss about this. Okay. If not. Yeah, this is clearly a topic that will come up over and over as we start discussing blob counts on the CL side.
01:05:34.929 - 01:06:40.355, Speaker A: So we can leave it at that. That's everything we had on the agenda for today. Anything else people wanted to bring up that we didn't get to? Yes, Ben, just on the staking bandwidth considerations. That should hopefully be helped a lot from the eth get blobs if the most ELS are implementing that so that the validators can pull the blob from their own transaction pool if the C has used that rather than waiting for it to be propagated. Nice. And then yeah, there's a comment in the chat by Alex about four fours. Any updates on this? Any progress made? Yes, so never mind.
01:06:40.355 - 01:08:14.193, Speaker A: We are working on both basically Portal network and era files as well. I mean right now we are kind of finalizing pectoral so we should have more power to push force. Nice. Anyone else? Do any client teams have thoughts on how Portal is coming, their implementations or is it still too early? Okay, yeah. Anyone from Portal here, Snapshot sync, if that counts. We don't plan on reusing Portal, but we can get every blocks without the FPTO P and all blobs too. So I think there's three people from Portals in the call Me, Piper and Jason Carver.
01:08:14.193 - 01:09:04.541, Speaker A: But yeah, yeah. Any update you want to share or where people can go for updates if not? Yeah, I mean for our project. Not exactly. I know that two people picked up making a Portal client for Bezos in the EPF and that's coming along fairly good. They're just about to integrate with Hive tests, which is cool and yeah, sweet. Okay. Anything else people wanted to bring up? There's a question in the chat how people are integrating Portal into their infrastructure.
01:09:04.541 - 01:09:55.464, Speaker A: Does anyone have thoughts on this? I guess I could give some ideas. So some of my ideas are I guess running it as an alternative like history provider instead of devp2p. Especially because with E44 you'll no longer be able to retrieve that data over dev P2P. It could also be used to like seamlessly. Once 4.4S is activated, no JSON RPC functionality would be lost, which is nice. So if somebody tries to fetch something before the EAP 4.4S
01:09:55.464 - 01:11:17.435, Speaker A: window, you can actually give like a valid message if that data actually existed, instead of just saying I have no idea what this data is. But I'm sure there's other things I missed. Yeah, I was mainly interested in how it's being done now. Like is it being integrated? Are the current EL clients calling the Portal network or is there like some network that's being created that doesn't integrate well with Portal? So for us, for Nethermind implementation, I think we're connecting directly to the P2P portal and trying to get the data from P2P directly and also trying to serve. So not only getting data but also serving. But yeah, other clients could choose to do it differently. Yeah, I'm not sure I see benefit in like half of the clients having a separate P2P network for serving a history like Portal and then half connecting to Portal seems like unneeded redundancy.
01:11:17.435 - 01:12:41.595, Speaker A: I'm a little confused with how that was phrased, but I think every implementation would probably be like succinct in that. Like, I'm a little confused by your two examples, but I think they would all be done the way Ahmed, I think that's his name, a smart programmer, said I think that'd be the most sensible implementation. Okay, anything else on Porto? If not. Yeah, I think we can wrap up here. Thanks everyone. So I'll put up the issue for the BLS breakout on Monday, but we have that and then the interrupt testing call, and then hopefully we can finalize specs for Devnet 5 and get Devnet 4 up before next awkward devs. And yeah, in case you missed it in the chat, Pectra DevNet 3 finalized as we speak.
01:12:41.595 - 01:12:47.065, Speaker A: So yeah, thanks everyone and talk to you all soon. Thanks, Tom.

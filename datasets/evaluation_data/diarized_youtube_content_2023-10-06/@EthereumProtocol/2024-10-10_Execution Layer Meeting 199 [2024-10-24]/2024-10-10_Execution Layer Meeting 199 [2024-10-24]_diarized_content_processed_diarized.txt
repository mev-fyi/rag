00:00:49.435 - 00:02:10.381, Speaker A: We are live. Welcome everyone to ACDE number 199. A bunch of minor but important PECTRA updates today. So we'll catch up on devz4 but then also on a bunch of different changes to EIPs so hopefully can close out the subgroup check conversation for EIP 2537. Felix had two PRs to he wanted to discuss. There was a minor change proposed to 7702 and then I wanted to do a last Check on including 7742 as per the last ACDC and Kujinder has a small modification for this as well so we can chat about all that, figure out how that would look first DevNet 5 specific and then aside from that there was this conversation around validator bandwidth that we never quite got to on the last acd, some stuff around the gas limit and then the ETH APIs. Oh and yes, the 200 celebration would happen right before DEFCON.
00:02:10.381 - 00:03:05.445, Speaker A: So yeah, we can celebrate that at DEF CON to kick us off. I don't know, do we have Barnabas or Perry to talk about how DevNet 4 is looking? Yep, I'm here. So last week, Friday, we have started Devnet 4 and we have shut down Devnet 3. Since then we have had a pretty good participation rate. We have a few clients that are still having some issues. Hopefully we can get some. So clients that are known not to be working are currently Aragon and Ethereum JS on the execution layer side and Grandin seems to be the one that is still struggling with a few clients, but they are now also proposing some blocks so it seems to be a bit more intermittent.
00:03:05.445 - 00:04:15.807, Speaker A: Sweet. Anyone from any of those teams want to chime in with some more context? Ethereum JS looking into it. Okay, any other updates on DevNet 4 that anyone wanted to bring up? I have started the bed block production again this afternoon. Only we do a single node for now, but we'll grow that into like three or four different nodes later on. Anything else on Devnet 4? Grandin solved some of the issues yet? The other one should be solved soon. Nice. Anything else on Devnet 4? Not for me.
00:04:15.807 - 00:05:08.845, Speaker A: Okay, next up then, BLS. So there's been a lot of conversation around potentially removing the subgroup checks, filling out the subgroup checks. Over the past week a couple people have reached out to different L2s and other potential users of BLS, as well as investigated the libraries themselves. I don't know if we have. Yeah, does anyone want to get an update on that either? On the side of the community outreach or the actual libraries I can give them. It's working. Yeah.
00:05:08.845 - 00:05:45.461, Speaker A: So on the decision, it seems that we're moving towards just having the subgroup checks in. One reason was that one of the dependencies. It's pretty hard to see what. It's pretty hard to get good confidence on what will happen if it's removed. And it's. Yes, it's pretty hard to read. It seems like from our outreach that the ZK Snark folks, at least the ones we reached out to, aren't sort of like saying we want.
00:05:45.461 - 00:06:35.803, Speaker A: This is the best way to say it. Some of them have infrastructure and that makes it pretty hard to switch away from BN254 to BLS12381. So I'm not sure what the use cases for this precompile are. I mean, there are possible use cases, but it doesn't seem to be like the ZK Snark folks at the moment. Thanks. Anyone else have context on that? Yeah, I could add a little bit, essentially. Yeah, I think the investigation Kev was talking about was really helpful because it does sound like with this dependency blst, it's not clear what happens if we don't have them the subgroup checks.
00:06:35.803 - 00:07:21.931, Speaker A: So we'll go ahead and keep them in. That gives us a pretty stable interface now to proceed with final GAS benchmarking. And then separately we can keep thinking about different use cases and reach out to different community members to try to get a sense of, yeah, the expected use of this thing once it's live. And yeah, that's a thread that can keep running even over the next month or two. But yeah, I think we're unblocked at the moment, which is good. Awesome. And on the benchmarking, I know it's been a couple of weeks since I followed up there, but my sense is we still didn't have quite consensus on what the right price for a subset of the calls should be.
00:07:21.931 - 00:07:45.515, Speaker A: Is that still correct? I think we do now with the subgroup checks in. Okay. I think it was just a 2x the current costs. Okay. So the original proposal of. Yeah. Change adding a factor of two on the discount table after those calls.
00:07:45.515 - 00:08:37.869, Speaker A: Yeah, I believe everyone was on board with that. Yeah, I'm not sure I fully agree with this one because since this original gascos doesn't fit like the shape of the curve we're seeing, and we just try to use something that wasn't a good fit in the beginning and like multiple. But I think we can like spend next week to like, figure it out exactly how it's supposed to work. And if the other people will be in favor of the original proposal, I'm also. Okay. Yeah, I think there's probably value if you want to spend a week or so looking at a better, better proposal. Yeah.
00:08:37.869 - 00:09:27.395, Speaker A: And we should, I guess. Yeah. We should ideally have a final merged gas cost scheme in the next week or two so that we're not blocked on that to launch future devnets. Sorry, what was the issue of the 2X? Is it just that it's like not exact enough power? No, it feels to me that we start with some like, I don't know, like lookup table. That wasn't good in the beginning. And we just keep the lookup table by just multiplying everything by two in the same sense. We can just create a new lookup table that actually fits the hour timings more closely.
00:09:27.395 - 00:09:58.368, Speaker A: I mean, it's the kind of the same amount of benchmarking quirk. It's not like so clear that you multiply by two, but it just puts new numbers and maybe it's not even needed lookup table anymore. And so that's what I mean. Exactly. Okay, that makes sense. When we were benchmarking In Basu against Narc, we found that we were using the 150% proposal, not the 2X. And we found that even with 150%, the G2 was way overpriced G2 MSM.
00:09:58.368 - 00:10:48.045, Speaker A: So if we 2X that, I think that's going to get even more overpriced. Oh, that makes sense. Sorry, I thought everyone was sort of in agreement, but yeah, it seems like we need to redo the numbers from scratch then if we were to do that. Yeah. Powell, what's like the timeline that you'd expect here? Is this something that you can benchmark in a week? Do you need client teams assistance? Yeah, I don't know, but it feels to me that it's kind of the same amount of work. We just put different numbers in the end. Well, I guess, yeah.
00:10:48.045 - 00:11:35.087, Speaker A: One part I want to be sure on is like, what's the, what's the flow here? Where my sense is, when we did the 2x proposal, every individual client team ran those benchmarks on their, on their end. So is. So I assume here there's like some work of proposing a curve or like a, you know, like a lookup table for prices and then having clients confirm that. Is that correct? Yes, I think what, what happened is that with 2x, like everyone is within the safety margin. Right. So the worst case out of all These lookup table numbers, it's. It's fitting like the expectation, but there may be some outliers in the.
00:11:35.087 - 00:12:14.865, Speaker A: In the other side like in the other places that makes them like maybe too expensive. I don't know. To my understanding, GNARC implementation is hit by the subgroup checks more than plst. At least what I get from data I received. So it's more on the GNARC side. Unless they can fix the performance in the implementation, I think it's a bit more on their side to propose the numbers. If they think like 2x it's like great, I will accept that.
00:12:14.865 - 00:13:08.713, Speaker A: So I don't think we need to take the pre assumption from four years ago when trying to find the good girls prices. It doesn't save you any work if you just take this. This? Yeah, this like original work in gas prices from four years ago. We can just put new numbers and it doesn't make all this process take longer. The longest part is just to do the benchmarks and collect data. Okay. Is that something you have the bandwidth to take on and that other teams can assist with? I don't know.
00:13:08.713 - 00:13:36.511, Speaker A: I need to. I mean I can plot the data if I get one, but I don't think I will be able to benchmark every client. So yeah, I think we need to figure out how to exactly do this. Right. I'm not that great at this actually. What if there's no one else? I can actually do like similar spreadsheet I did some time ago. I think maybe what we can do then is we have the testing call on Monday.
00:13:36.511 - 00:14:07.345, Speaker A: If all of the client teams can make sure to send someone there who could help with the BLS benchmarks. And Pavel, if you're able to attend that too, that would be great. And we can zoom into that discussion on Monday and make sure that we. Yeah, we have a plan for benchmarking this. Okay, I'll try but I think Monday is quite busy for me actually. Kev. Yeah.
00:14:07.345 - 00:14:45.297, Speaker A: So what exactly is needed here in order for us to reach a decision? Is it just some set of inputs and then we just show what the timings are? Because I think a bunch of clients have already done that. Correct. Yeah. So we had the clients do this with the 2x proposal. So what we need is what's arguably a better proposal than the 2x and something that I guess is more like a granular. Like a granular repricing per call and then having the clients rerun the benchmarks on that hardware. Sorry.
00:14:45.297 - 00:15:17.951, Speaker A: On those numbers. Okay, I see. And Paolo, you're saying that the benchmarking process is the hardest part? Because I think we don't need you to actually do that since you've already done it for Eve 1. We just need the clients to do that. Okay. Yeah, I think if Powell could propose a set of numbers, like a lookup table, and then the client teams can benchmark that, we should be good. And so we get.
00:15:17.951 - 00:16:04.155, Speaker A: Yeah, so I would suggest like sorting out the details of this. We can use the R and D discord, but then on Monday if we can. Yeah, check that we have everything sorted, that would be great. And if you can't make the call directly on Monday, Powell, if there's a way for you to share like async, either a proposal or like what's needed for a proposal, that would be. That would be quite helpful. Okay, cool. Anything else on bls? Okay, thanks everyone.
00:16:04.155 - 00:16:33.875, Speaker A: So, yeah, we'll move forward with that and again we'll keep the subgroup checks as part of the EIP. Next up, Felix had two PRs he wanted to discuss for EIP 7685. Is Felix on the call? Yes, I am. Can you hear me? Yes, we can. Yeah. I just posted your first PR in the chat. Excluding the empty requests data in the commitments.
00:16:33.875 - 00:17:43.935, Speaker A: Let me just quickly explain. So basically I am proposing this because we noticed during the implementation of the DevNet 4 changes that it's very inconvenient for the ELS to have empty value of the. The empty value of the request hash depend on which fork is currently active. So for example, this is if you initialize new chain and at the Genesis block the fork, like the pectoral fork is active, then we need to compute the empty request hash in the Genesis block. And with the current DevNet 4 definition, this is basically a request hash with re empty requests lists and. But in the future fork this might change. So basically every time now it's just going to add a whole bunch of code to the Genesis book initialization where we have to figure out like the like empty request.
00:17:43.935 - 00:18:18.475, Speaker A: And then more generally there are certain cases where you want to produce blocks just for testing purposes, but there's not going to be any kind of cl. So it doesn't really. It's not really necessary to bother with the request at all. And then it's like, it's just nicer if you just hard code this empty value there. Like that's the main motivation, honestly. And yeah, that's only possible if it is not dependent on the fork. So this is where the proposal comes from.
00:18:18.475 - 00:18:59.411, Speaker A: And I mean the corresponding change in the Engine API. I only propose it just because we feel like it's much easier if there's a canonical sort of request list that is shared both on the Engine API and it's also used for the commitment. Right now we already have this bifurcation of the commitment and the Engine API. I personally think it's quite bad. So basically we have to. What happens is when we compute the commitment, we have to add these type bytes for the request. But then in the very last minute on the Engine API, the type bytes were removed.
00:18:59.411 - 00:20:16.595, Speaker A: And so this already means right now that we have two different representations of the request list, one which is only for commitment and only which is one which is only for the Engine API. And so I'm just proposing to make these two the same again by also removing the empty request from the list which is shared on the Engine API and adding back the typebyte. Thank you. Anyone have comments? Thoughts on this? Okay, Breath is in favor. I know Tiku, I think, approved the changes as well on the PR directly. Ethereum JS is in favor. Does anyone, I guess disagree with this change or have like significant concerns? I'm pretty sure if I had proposed it on the AC DC next week, there would have been some backlash because it does mean that the CLS have to add one more check, which is that they have to now validate that the request items are given in strictly increasing order just to ensure that, for example, because with the typebyte it again introduces an ambiguity that wasn't there before.
00:20:16.595 - 00:20:50.019, Speaker A: However, I do think it's a minimal. It has minimal impact, but it does have some impact on the cls. So maybe someone from the CL side should speak up. And I mean, I mean, I think it's a minimal impact, but it definitely has an impact on the CLS as well. Any CL dev on the call have strong opinions. Okay, so Lodestar should be okay. Lucas from Teku had already plus one edit.
00:20:50.019 - 00:21:19.595, Speaker A: So my sense is we can probably go ahead and include these two PRs as part of the DevNet 5 specific and aim to get them. Oh, they're already part of the Devnet Fire stack. Awesome. Yeah. And aim to get them merged by next week's acdc. And if there's any CL level issue that comes up, we can address that on next week's call. Okay, thank you.
00:21:19.595 - 00:22:16.505, Speaker A: Yeah, thanks Felix. Anything else on this topic or not from me? Okay, moving on then. Next up, we had a proposed change for 7702, so I haven't quite followed the conversation on this, but supposedly it was due to some back and forth on each magicians. Yeah, I don't know. Does anyone have context on this PR to remove the delegation behavior of ext code opcodes? Yeah, just quick context. So 7702 currently introduces a new type of account that can change its code hash. This is currently somewhat possible if the contract has delegate call and since the delegate call changes only if it uses in the same transaction as creation.
00:22:16.505 - 00:23:04.111, Speaker A: But this is a strictly new kind of way of changing the code hash because it can happen even if the code doesn't include self destruct. Even if the code doesn't include delegate call, it weakens the guarantees that one gets from looking at the code hash of an account. If a contract relies on that to trust the way that the account is going to behave, it could be vulnerable because it's able to sort of temporarily masquerade as a different kind of contract. So it does seem like something that we should look into. We've looked. We found a couple of code samples that appear to be affected, but nothing really too serious. But we haven't really done a thorough search.
00:23:04.111 - 00:23:38.775, Speaker A: So the proposal here is to only delegate code execution. So ext code hash would. An ext copy would just act on the delegation designator instead of following the delegation pointer. That seems just sort of more normal in line with what an EVM proxy is. And so it just seems like it would be less surprising in terms of the effects on applications. Should be noted that the code hash will still change. All right.
00:23:38.775 - 00:24:13.721, Speaker A: Like if you change the delegation, you will have a different code hash anyways. Or is the code hash going to be reported as the hash of delegation? Or do you mean after this proposed change? Yeah, so. Yeah. So I mean, you were saying. Sorry, go ahead. So you were saying that basically the point of this is to ensure that account cannot change its code hash unexpectedly. But I think if we don't do the delegation, we still have to take the hash of the delegation code.
00:24:13.721 - 00:24:47.375, Speaker A: Yeah. So that basically means we still have. You can still change the code hash of the account with 772. Yes, that's right. So there's a stricter version of this proposal, more conservative, which is to do kind of like EOF contracts and just look at the prefix. So it wouldn't change, as you say. Although in this case, if it does change, it would at least not correspond to different code because the delegation designator is not valid.
00:24:47.375 - 00:25:11.317, Speaker A: Valid code. Right. But it is another option that I would also be open to considering. Yeah, I thought we actually have a proposal in UF that says any code that starts with 0xef is immediately forbidden for looking at. Isn't that the case from executing. Yeah, yeah. But also like from being introspective.
00:25:11.317 - 00:25:24.093, Speaker A: Yeah. Oh, interesting. You cannot. You cannot look it up. It will just behave as like some sentinel value. So. So it only returns 0xef.
00:25:24.093 - 00:25:38.235, Speaker A: Basically. Yeah. So maybe that's what we should do for the delegation as well. Just. But then it's actually worse because you don't even know it's a delegated account. Basically you don't know anything about the account. And maybe that actually makes the problem worse.
00:25:38.235 - 00:26:11.085, Speaker A: Well, if. Yeah, so Ansgar is saying it's EF00 and in the case of delegated accounts it could be EF01, which is the prefix. So that would allow to distinguish. But I don't know that well. I mean the contract could kind of know that it's a delegated account and then like reject interacting with it, for example. So that would be the main advantage here, just being able to detect within the EVM that the delegation is active for this account. And then you could be like, you know, I'm not talking to that account because it's a delegated one.
00:26:11.085 - 00:26:46.545, Speaker A: That's certainly something. But the contract would have to be aware of this concept anyway. So it doesn't apply to the old contracts because they don't know anything about this. That would be a new security pattern that you have to introduce into your very important protocol. Like basically ensure that this is just fallout from 7702 adding so much new attack services. Yeah, Daniel. Yeah.
00:26:46.545 - 00:27:45.259, Speaker A: So just one problem I have with this proposal is that right now all the opcodes that interchange that interact with code like the call or XCODE has, are completely oblivious of code delegation. They just get the code of the target. If we do this change, the code delegation is not transparent anymore to the avm because we need like two ways to retrieve code. One that follows the delegation for cords and another one like in the proposal XCODE hash and the others that don't. So this breaks a bit. The assumption of 7702, that EVM in the end does not have to be aware of it. Also in the future when we introduce new opcodes, that interactive code, it might be a bit error prone because we have to be careful which of the two ways in case of 77.2
00:27:45.259 - 00:28:54.195, Speaker A: we use to retrieve the code. So that's like my one doubt about this change. Got it. And yeah, onsgrad you want to talk about the EOS style behavior you brought up in the chat? No, I'm actually not 100% sure. It could be that you have extremely returns the kind of 0xef hash as the magic kind of hash if you try to code inspect it. I think if that's the case, we should probably revisit this now that we actually reuse the 0xef domain basically for other things other than Ulf. But what I'm saying is there would probably be value in having if we want to just return a magic byte which made a hash of a magic prefix or something as the response now in the 7702 case as well, which I personally think would be just another principal step towards getting rid of code introspection.
00:28:54.195 - 00:30:10.995, Speaker A: And then I think we should make sure that it's not the same magic hash that we use for uf, because I do think there's value in being able to distinguish those two cases and they're also conceptually not the same. Right. Yeah, I guess it still feels like there's some discussion to be had on this to actually understand this sort of second order impacts and like, yeah, what it would look like implementing the evm. What's the right way to like move this conversation forward? Is the ETH Magician thread sufficient now? Do we want to have a breakout on this in the next week or two? I would love to just hear from some more DAPP developers. I am weekly in favor of this change. I guess, you know, it's to me it's pretty much okay how it is, but it's also okay to change it. I don't think that this is.
00:30:10.995 - 00:31:11.715, Speaker A: This is not something I'm super worried about. But if there are more examples that could motivate changing the behavior like I'm open to hearing them. The ones that I've seen are pretty contrived examples. Thanks, Guillaume. Yeah, if you're looking for an example, it's not a dev developer example, at least not directly. But when it comes to any stateless gas cost model, if you have to do a jump to a different location, you're going to potentially incur a significant price for opening a new group. And what happens in that case is that some operation that you think is pretty cheap because it's just checking the code hash is going to have a jump to a location, open it and pay maybe like 1900 gas, like 21,000 extra gas.
00:31:11.715 - 00:32:00.925, Speaker A: That could be surprising. That could be breaking some contracts that expect xcode hash to be fairly cheap. So yeah, just for your information, that's going like doing it the current way is going to have an impact. Returning a default hash lets us just go to the current header that we already know about and that's pretty cheap. So yeah, in terms of gas, this could introduce a very surprising significant cost in the future. So I'm in favor of this proposal because it would keep the fairly cheap price that we expect. But why is it that cheap though? You don't know if it's going to be warm or cold.
00:32:00.925 - 00:33:00.223, Speaker A: Right? The account that you're sizing, you're going to call. Right? That's true, but I mean instead of being warm once or cold once, it's going to be warm and cold twice. Yeah, I mean the same order of magnitude and people need to be writing contracts to deal with changes in gas costs. Like we could easily just say in the future that this needs to be twice as expensive. So I don't really see that as that compelling either. Yeah, Frangio, I guess do you have a sense of whether there would be concerns of using the sort of hard coded return value like Onsgar was proposing or. Yeah.
00:33:00.223 - 00:33:46.817, Speaker A: Do you not have a good. I don't have a super strong opinion, but do you mean like if there was a way to tell apart that an account has been delegated so more that like. Yeah, instead of returning the delegated account we just return like a magic byte like 0xef01 for any attack. Oh yeah, I think that's fine. Okay. Yeah, because yeah, I think I do agree that in the past we would like we've said we want to move towards less introspection and that feels like a clean way to move a bit further direction. But yeah, I don't know.
00:33:46.817 - 00:34:31.257, Speaker A: Was there a use case to actually return the delegated. There are certainly use cases one could come up with, but I think not a critical. Yeah, yeah, nothing that exists already. So I think if that's the direction that like this group feels weakly in favor of, then maybe we should modify this pr, have a hard coded value returned and then try to get a last round of feedback from application developers on that before Devnet 5. Cool, that sounds good. I can make the change. Awesome.
00:34:31.257 - 00:35:17.365, Speaker A: Thank you very much. Let's do that then once you have the PR open, just send us a pane so we can tentatively add it to the Devnet 5 spec as well. Sweet. Anything else on this topic? Okay, and then next up. So EIP 7742 on the CL call last week we seem to want to move this to the fork to separate the blob count from. To have the CL drive the blob count there. So I guess.
00:35:17.365 - 00:36:13.815, Speaker A: And then. Sorry, there was a proposal by Gajinder to change this. He opened the draft PR for it. So I don't know. Gajinder, do you want to maybe give a bit of context on your draft pr? Yep. So basically what will happen is that CL will send the target and which can basically change theoretically block to block. And so the way this impact the fees, the fee double this impact, how fees calculated on EL is that we have basically an access gas accumulator and where we can play where we accumulate on each block how much it's below the target or above the target and then use it to calculate the fee with the.
00:36:13.815 - 00:37:08.517, Speaker A: So we have an update fraction which basically makes sure that the factor by which the fees goes up and down by which basically this delta delta affects the fuses less than 1.115 because excess gas by this update fraction is exponentiated. So the problem with a dynamic target is that this you can't basically you can't. You don't have a constant update fraction. So what this UIP does is it normalizes the delta against some target and then accommodates it. And then there's a normalized absorb fraction that is used to exponentiate and get the gas cost. So everything else stays the same.
00:37:08.517 - 00:37:55.473, Speaker A: But now when you are calculating the excess gas, you are basically calculating excess gas. And so which is basically target, which is target minus gas used by that other times some constant factor and that factor you have chosen arbitrarily. So that factor could be chosen up or down depending upon how large or small. Gajendra, your MIC is a little hard to understand. Maybe move a little bit further back or I don't know if you could switch to another micro if possible. If not, just some feedback. It's not great.
00:37:55.473 - 00:38:22.105, Speaker A: But yeah, maybe that describes the change. I was almost done. Thanks. Yeah, I think that's. Yeah, we can somewhat hear you now. Anyone have feedback or thoughts on this change? I know it's been. I think the PR was opened.
00:38:22.105 - 00:39:08.645, Speaker A: Yeah, just yesterday. So. Any comments, thoughts? Yeah, so I mean I think the main thing to do today is just to move this to SFI so that you know we have it. There is this question. I think the issue that Gajendra is pointing at is that the like base fee adjustment constant doesn't like it's hard coded essentially for the fact that we have six blobs and so we'd have to change it eventually anyway. And then this is just now figuring out the right way to make it flexible enough under 7742 so everything works nicely. Yeah, so I mean I think we can iterate on that.
00:39:08.645 - 00:40:13.595, Speaker A: But then separately we do want some blob increase in picture it sounds like. And this is required, right? Okay, maybe yes. To flip the conversation around, does anyone on the EL side have a concern with moving 7702 to Petra as it exists today? And then maybe we can take some more time to review Kuchindra's proposal in the next week or so? Last call. Okay, so let's move 7742 to Vectra. I'll make the change right after the call. We can, yeah, have an async conversation on the PR that Jinder pull up and then hopefully resolve this by next week's AC dc. And yeah, Barnabas is asking if there's any client implementation started for 7742.
00:40:13.595 - 00:40:42.005, Speaker A: I guess not much. Oh, Ethereum, JS and Lodestar have PRs in the works. Basie should be ready by the end of next week. Okay. Prism is in the work, so. Okay, some clients have started. Sweet.
00:40:42.005 - 00:41:22.305, Speaker A: Anything else on 7742? Okay, and then lastly DEVNET 5. So we had a couple PRs today that we decided we're going to add. It seems there's still issues with DevNet 4. Yeah. Do we want to spend at least another week working on Devnet 4 and revisit a final Devnet 5 spec in the next week or two? Okay. I have a plus one from Barnabas. I think we'll move forward with that.
00:41:22.305 - 00:42:14.409, Speaker A: I think the only PR we mentioned today that is not tracked there doesn't exist yet is the change to 7702. So as soon as we have that we can include it to the Devnet 5 spec. Anything else on Petra before we move on? OK then. Next up wanted to touch on the validator bandwidth point that was brought up on the last call and we didn't quite get to. I don't know, is Ryan on this call? If not, I can just share his questions. I'll just post the agenda link in the chat as well. But yeah, quickly.
00:42:14.409 - 00:43:17.833, Speaker A: So the first one was giving the emergent. Giving the emerging importance of validator bandwidth in driving real world disaster contingency planning for the validator set. How do we feel about the existing scope and rigor of bandwidth research? Are we doing a great job? Can we close the gap? Occurs to him. There's at least two different research area Research into internal bandwidth, dynamics of the protocols and client implementations, and research into the external bandwidth supply available across the world and how that's expected to grow, expand, how it changes in different parts of the world and whatnot. And he links E Research posts with some more like tactical versions of this. Yeah. Anyone have thoughts, comments on this? Okay, if not, yeah, I will point people to the ETH research thread and we can continue there.
00:43:17.833 - 00:43:51.155, Speaker A: I know there's already some responses by, I believe some Lighthouse folks around what's happening on the client side. Yeah. So we can continue the conversation on ETH research. And next up, Julio had a proposal for the gas limit EIP that we discussed a couple weeks ago. Yeah. Giulia, do you want to talk about EIP 7790? Yeah. So first of all, if possible, I would like to give a little update on 7783 just from an implementation point of view.
00:43:51.155 - 00:44:48.983, Speaker A: So right now I was able to implement into Ref, Aragon and gaf and that works. I know nethermine also planned to do an implementation, but I don't know if they actually did it, but I think they did. So this is just an Update then. Regarding 7790, I did some asynchronous coordination amongst clients and it seems that I was able to kind of come to. I think I was able to kind of come to an agreement for agreement across the clients, across most people, at least on the actual guidelines. So the guidelines I came up with that came up was basically a target of 60 million gas over two years. And I talked this with Nethermind and they were fine with it.
00:44:48.983 - 00:45:13.695, Speaker A: Aragon is fine with it. I went to Gaff and Peter told me that there is no reason not to increase it. At least that's what Peter told me yesterday. There were some concerns from Bezu. I haven't heard nothing from Raf yet, but I think. Well, I think. But really I didn't really.
00:45:13.695 - 00:45:49.805, Speaker A: But like, at least from a technical point of view, it seems that there is really no reason not to increase it. I think at least, at least after discussing it, most people agreed at the end of the day. Right. So yeah, there are some questions from Bezel yesterday, but I hope they are cleared. So I mean, I think we're kind of also ready to kind of at least take a decision here because I mean, seems that at least the majority agrees. Maybe the. Maybe neither mind can confirm or if Peter Zilak is on the call, he can also just confirm.
00:45:49.805 - 00:46:23.901, Speaker A: I don't know if he is, but yeah, he's Not. He's presumably not on the call because he's on holiday. But I can like him. We discussed that in a standup and I confirmed that he agreed. Okay, so what about nethermind? Just so that we are sure that you're also on board. Is there something from Net. There's a comment in the chat from Ben that said nevermind is good.
00:46:23.901 - 00:46:35.757, Speaker A: Okay. And. Okay. And basically they had some concerns yesterday. I hope they're cleared. And yeah. And what about Raf? Because I heard nothing from Ref.
00:46:35.757 - 00:46:53.521, Speaker A: If they have an opinion or not an opinion. Are we talking about including Disinfector? No, it's not an art fork. It's like it's actually. You can include it also a bit afterwards. So it's not an artwork like the AP is not an artwork. So you don't need to do it. Right.
00:46:53.521 - 00:47:25.075, Speaker A: It's like the default behavior that you'd ship with the client. Which also doesn't have to be the same across clients. Right. Yeah. I don't currently have an opinion on this. I don't know who you reach out to, but I haven't heard anything. Okay.
00:47:25.075 - 00:47:57.465, Speaker A: And yeah. So regarding the biz. Okay, so there are some hands. So who wants to start? Yeah, maybe let's do like client and then we'll do Enrico. Yeah. Yeah. I think my general feeling on this is that we have some work that we need to do around history and we haven't completed that work and it feels very weird to sort of skip over the thing that's kind of necessary to just do a very easy change to the protocol and increase the footprint of clients.
00:47:57.465 - 00:48:20.229, Speaker A: I would really like to see some progress on four 4s made before we talk about increasing gas limit. I mean. Yeah. But at the same time regarding history and already kind of talked about it a lot is that even if you don't commit to it. So first of all, this is a very easy change. Yes. And it came into the testing is really trivial to do.
00:48:20.229 - 00:48:38.409, Speaker A: Like it's just tracking a number. So I'm just going to say that out of their way. And the second. But the other thing is that regarding history growth, if you choose not to do it, you're going to end up with eating the 4 terabyte mark for comfortable study data running in the same amount of time. Pretty much. Right. It doesn't make a difference.
00:48:38.409 - 00:48:56.405, Speaker A: So I mean, I mean if. If it's just. I mean, I don't know you. I know that it's for you. It's just kind of a preference because you feel it's lazy but from a practical point of view there is I think objectively no difference whether you do the gas limit increase or not. So. Yeah, so okay.
00:48:56.405 - 00:49:53.609, Speaker A: Anyway and let's maybe do Enrico and then Ben, if I'm not mistaken we send gas limit as a configuration for the proposer through the MEV boost when we do proposal registration of the builder network. So it's just a comment that if this happens then this, this interaction must be changed and is kind of static and it works. No, well not really. Well not really. I mean after all you can still suggest it and if you don't specify the builder is going to use whatever they have which is. Yeah, yeah that must be true. Honestly it was just a comment that says there is an interaction.
00:49:53.609 - 00:50:54.115, Speaker A: It's not pure EL thing. There is an interaction with the way CL talked to them builder and we have to do some consideration there. Yeah but yeah, it's minimal but it's something that we need to care about. Thanks Ben. With regards to history, history growth has slowed from blobs because a lot of the data is now going into blobs rather than into call data. Also the way it increases linearly over two years means the average increase over the entire period would be only 15 million. So that's the impact you got to think about rather than the end impact.
00:50:54.115 - 00:52:04.735, Speaker A: And I hope progress has been made on four for us by then and also that we've included the call data increase. So I mean if call data goes into Fusaka, Fusaka maybe takes 6 months say then it's only gone up to 37 million gas by that time for instance it's not, you know, it's not a straight shot to 60 million and we can also halt it at any time. Can I also add something really quickly because I see some people here in the chat says that says that basically that basically the impact after shipping it is not strong. Well the thing is that actually the beginning I heard way higher numbers from people not 60 million in the beginning it was more close to 90. Reason why it's 60 is because we would like first to merge kips before actually making it more significant. But since 60 million is a start, why not. And also it's just a better way to increase the gas limits.
00:52:04.735 - 00:52:24.765, Speaker A: Yeah, like objectively it's a better way to increase the gas limit. So I don't really. So sexy meal comes actually from. So 60 million is just. It just comes from basically it's something that clients think they can handle. I mean the ones I talk to, that's what you think they can handle quite well. That's where the 60 million comes from.
00:52:24.765 - 00:52:48.831, Speaker A: And but if it weren't for some things, it could also be 90. So in reality in the future it's probably going to go up with the QIPs being merged. So. Yeah, yeah. Anyway, yeah, let's do Stokes and then Marius. Yeah. I mean I think you might have just touched on my question, but I do wonder where the 60 million number is coming from.
00:52:48.831 - 00:53:22.055, Speaker A: Like, did we just decide to double where we're at now and then go from there? Yeah, basically. So basically kind of, yes. And we basically first of all we kind of tried to go for multipliers. I mean I worked with nethermind and we first it was. We went for multipliers. So the first multiplier was like 90 million because there was some consensus between Aragon and nethermine that 100 gigabytes of state curve was the max they would allow. Then they basically.
00:53:22.055 - 00:53:41.491, Speaker A: Then we basically said no, okay, wait, but maybe there are some other things that might get in the way. Maybe we should actually wait for some hippies to be merged. So we actually just say 60 million. And 60 million is actually very conservative. It's very slow increase. It's a low impact immediately. But it's.
00:53:41.491 - 00:54:04.667, Speaker A: Yeah. And just one thing actually. And actually one other thing I want to just also say add some more things so that I seeing. So the testing. I saw somebody talking about testing why testing is for this AP trivial. Like it's just tracking a number. Like you basically set a bunch of flags on a devnet and you just see if the number goes up.
00:54:04.667 - 00:54:17.255, Speaker A: It's really. And it's very. And it's deterministic. So it's not. There is almost no unknowns there. It's just like it's easy to implement, it's easy to test, it's low effort and it says. And it's okay.
00:54:17.255 - 00:54:47.691, Speaker A: Yeah, so yeah, so yeah, yeah. I'm not opposed to raising the gas limit, but I would want to see like a more rigorous analysis around all of the various considerations before picking a particular number. Yeah, 6 million is just what I mean we are. I mean I can tell you that arrogant can definitely do 60 million. I mean the number seems to indicate actually quite, potentially quite. I mean there are numbers. This is actually based on numbers.
00:54:47.691 - 00:55:21.745, Speaker A: Like it's not like just taken at random just out of multipliers. It's actually based on number. So then the main reasons is kind of that we put 60 mil was because we're doubts about the cold Data and some OPACOs who don't scale very well. That's the TLDR from that perspective. But yes, it is of course not just taken out of my head and just put it there perform. Right. Anyway, yeah, and I think just communicating again with more data and your analysis and thinking would have helped people get more comfortable with it.
00:55:21.745 - 00:55:44.475, Speaker A: I mean I wrote some blog post. I also wrote like an entire nice verkle and yeah, you can go check it out. I posted on Discord. So yeah, I can share it with you later. Marius. Yeah. So I think we are again having two debates at the same time.
00:55:44.475 - 00:56:49.235, Speaker A: One debate is whether we should increase the gas limit and whether we should. Or maybe we even have three debates whether we should increase the gas limit, whether or what the good gas limit should be. And the other debate is about the mechanism of increasing the gas limit. And while I agree that we should increase the gas limit, I. I'm not knowledgeable enough about whether 60 million is a good number to land on. I think there needs to be more research and we made some numbers. But the problem is a lot of the worst cases grow exponentially with the amount of gas you have in a block or at least quadratically with the amount of gas that you have in a block.
00:56:49.235 - 00:57:39.291, Speaker A: So we need to have a lot of like we need to really make sure that it works. And the other thing, the mechanism for it I just don't agree with. I don't think we should do these gradually increases. I think we should do steps, steps of 1 million or 5 million gas or something. Do a step, decide everyone decides that we should do a step and we will ship the next client version with this step as the default and most people will update. So the gas limit will be raised gradually to that next step. We will see how it works and then we will make a decision on the next step.
00:57:39.291 - 00:58:22.605, Speaker A: I think this automatically like this automatic gradually increase is just. It's not great. It would in the case that something happens and this is 60 million is not the. Just doesn't work and we see it breaking. Then we would need to do basically an emergency release of all the times to vote on the gas limit again. And I don't think that's good. So in my opinion we should do bigger steps and have time to evaluate the impact of these steps.
00:58:22.605 - 00:58:36.657, Speaker A: Yeah, I mean the gradual increase is just better because you don't need to coordinate. Right. Like what you're saying. Yes, we do it in steps, but then you need everyone to upgrade and it's hard to measure. It's objective. Just hard to measure. Right.
00:58:36.657 - 00:58:54.489, Speaker A: Doing in little steps also takes time. It takes duration, time. It's inefficient from a management point of view. And also that's. And also like. And also the 60 million is kind of researched. Like, it's not like, as I said before, it is kind of research.
00:58:54.489 - 00:59:17.085, Speaker A: Not like I just took it out of my head. I discussed it for like an entire week with another mind. So it's not like something we just came up with in our sleep. Right. There are actual numbers behind it. And also, 60 million is just. Also 60 million over two years is just really small.
00:59:17.085 - 00:59:47.359, Speaker A: Like it's just kind of just to start something. Right. And it's easy change. But anyway, anyway, okay, let's do Guillaume and Ben and then ideally wrap up. Like, again, I think there's clearly different opinions on this. This is not something we also need like full consensus on. We want it be good to have like rough alignment.
00:59:47.359 - 01:00:11.911, Speaker A: We can have different teams. We can have different teams, like test different things on their clients. Yeah. Guillaume. Yes. It's just a remark on the Verkal documents and it's entirely my fault that this got published with this mistake. Like, Julio, you asked me, does the proof size increase logarithmically? Which is what your document says.
01:00:11.911 - 01:00:31.525, Speaker A: And the proof does increase logarithmically, but the weakness increase linearly. So I think we should actually do some more, you know, dimensioning or whatever. Checking. Checking. That's doubling the gas doesn't make the witness larger. Yeah, I. Sorry for the miscommunication.
01:00:31.525 - 01:01:21.149, Speaker A: Okay. Anything else that hasn't been brought up yet? Okay. I think we can continue these conversations, I think. Yeah. And again, like, while it would be ideal to get some consensus on this, it's also not something that like requires a hard fork or that core devs effectively control at the end of the day. Yeah. Okay.
01:01:21.149 - 01:01:45.917, Speaker A: Last thing we had on the agenda for today, again from Felix. So adding official revert error codes for all of the APIs in I believe, the engine API. Felix. No, it's a different one. Okay. Yeah. So I put up the PR in the chat.
01:01:45.917 - 01:02:22.775, Speaker A: Yeah. Do you want to give some context? Yeah. So this came up pretty suddenly. So we have received this issue multiple times over the years that people have complained that there is no standard way to get access to the revert data when accessing contracts using the eth call east estimate gas or access list operation. And so, yeah, we would like to basically introduce our way. The way we've been handling it in get as sort of like the official one. So in get we have this like error code 3 that we use for this purpose.
01:02:22.775 - 01:03:46.851, Speaker A: And yeah, I mean it's. I don't know, for us it's the most important thing just to have a defined error code and just basically ensure that all the clients behave the same way. Because right now in a lot of the client libraries for the RPC you have this huge kind of function with different, like matching different behaviors of the APIs, matching on error messages and so on, just to figure out if it's this error and then somehow trying to extract this data from the error in some way. So yeah, I don't know. I mean, I'm also open to having a different solution, but I mean for us it's the easiest to propose the one that we use already. And yeah, I'm just open to hear like what other people think. Yeah, I think from beso side it makes totally sense because this is something I wanted to do recently, basically comparing the results, the outputs from Geth and Baisu on ethcol and I had this issue because we have different return codes and basically payload and yeah, it was very hard actually to do the comparison.
01:03:46.851 - 01:04:41.175, Speaker A: So yeah, I am totally in favor of it. Just I was once wondering why we would not have a code that is similar to what we have currently in the engine API, something, you know, around minus 32,000. Currently in Baizu we return minus 32,000, which is basically a server error when we have this kind of error. Yeah, so I can answer it. I think it's kind of a common misunderstanding that JSON RPC error codes must be negative. So basically there's absolutely no need for the error codes to be negative. It's just that the JSON RPC specification, you've predefined certain errors and these predefined errors are not taken to like, they don't have to be used for everything.
01:04:41.175 - 01:05:29.565, Speaker A: But in. For some reason in Ethereum we have always only used the arrows which are predefined by the JSON RPC specification. But in fact they made these negatives so that you have the full positive error code range available to your application, which Ethereum is like Ethereum is an application of JSON rpc. So we have all the positive numbers available for our use. It's just that we for some reason only use the error codes that are in that spec and the error codes that are in the JSON RPC spec are only. Most of them are for internal use by the JSON RPC subsystem itself. So basically the most error codes that are defined by the JSON RPC spec are just used to notify the client that their request is malformed in some basic way or something.
01:05:29.565 - 01:06:09.649, Speaker A: And then the server error that we used for most things, it's just. It's like the generic error code. Like the generic server error in HTTP. You know, like can use it, but it's not descriptive of the actual error. Okay. Any other comments on the proposal? Okay, maybe. Yeah, we can have another couple teams have a look, and if there's no objections, we can move forward with it.
01:06:09.649 - 01:06:54.765, Speaker A: But, yeah, we can probably continue this, I think. Yeah. Thanks, Felix. Last thing I had on the agenda. So, on last week's acdc, we agreed to cancel the awkward devs call during defcon. I would suggest probably canceling the one after as well, as a lot of people tend to travel back or take time after the week and we'll have a whole week of people being together. Any objections to canceling the call on the 21st or any strong preference? Instead, cancel the one like before Defcon, but right after feels like it's probably the right timing.
01:06:54.765 - 01:07:28.575, Speaker A: Okay, no objections. So we'll have ACDE number 200 right before DEFCON. Oh, actually, Barnabas is opposed. Anyone else in Barnabas? Yeah, we need to ship, man. Yeah, so, exactly. So I'm keeping the call before defcon. So we ship before and then we ship at defcon.
01:07:28.575 - 01:07:53.444, Speaker A: I think this is the right call. And we get the 200 before DEFCON. Yes. So we have the call on November 7th. Yeah, of course. So we have ACDE on November 7th, ACDE on November 7th, acdc on November 14th. Or no, sorry, ACDE on November 7th.
01:07:53.444 - 01:08:28.343, Speaker A: No ACDC on 14th, no ACDE on 21st, and then back on the 28th. And Marius will be here at 14 UTC. Okay, Maris and Barnabas, does everyone want to call on the 21st? We can keep the 21st if people feel strongly about that. Okay. My. Oh, more 21st. Okay, a bunch of people want to keep the 21st.
01:08:28.343 - 01:08:58.885, Speaker A: My proposal then is we should probably merge the testing call so we usually have the Monday testing call. That would be on like the 20th. Or, sorry, on the 18th. So keep that together and have like, maybe an informal call for whoever's there on the 21st, but cancel fully the 14th. Okay. And Barnabas might also do the testing call. Great.
01:08:58.885 - 01:11:49.005, Speaker A: Anything else people want to discuss before we wrap up? Okay, then I think we can leave it at that. Thanks, everyone. I'll post the summary shortly on the discord and talk to you all soon. Take care, everyone. Thanks everyone. Bye bye, everyone. Ra.

00:01:26.900 - 00:02:14.796, Speaker A: And we are live. Welcome everyone to do EO call number 171. So today, obviously discussing Denkoon, we can talk about devnets to start. And then we have the different audits that have come in for 4788. We have some of the auditors on the call. I'm not sure if all three firms are on the call, but I think we have either a copy of the report or someone from every one of the auditing firms so we can go over the results there. Then I understand Holski relaunched today and so we can get a status update on that.
00:02:14.796 - 00:02:46.840, Speaker A: And after that there were two other topics people want to discuss. So one is the new EIP seven five three. And then Guillaume and Dano had some discussion points around self destruct behavior after vertical tries are implemented. Yeah, so I guess maybe to kick it off. Barnabas, you posted the spec for Devnet nine. Do you want to maybe give us a high level overview of where things are at with regards to Devnet?
00:02:47.820 - 00:03:29.300, Speaker B: Yeah, sure. So I have prepared all the different images already for Devnet nine based on the feedback that the different client teams have given us and we should be pretty much good to go hopefully tomorrow. But we are still hoping that we can get some more years to pass some more hive tests. So the general idea is to have about 1300 validators for this test with a split of 75% for gas and undermined, 18.8% for Bezel and Ergon, 3.7% for Ethereum js and 1.8% for rest mate.
00:03:32.280 - 00:03:35.830, Speaker A: Yeah, do any of the specific client teams want to comment on where they're at.
00:03:38.540 - 00:03:41.976, Speaker C: So I can start? I think we are ready.
00:03:42.078 - 00:03:45.450, Speaker A: And a few failing tests on the.
00:03:46.060 - 00:03:49.304, Speaker C: Hive Cancun page is mostly testing setup.
00:03:49.352 - 00:04:13.952, Speaker A: Issue and we are talking with Mario just to fix it. And that's it. We don't see serious issue. Got it. Nice. Just one other point for Devnet band, we're doing the updated address, 4780. So that's the one that we'd be using on main net as well.
00:04:13.952 - 00:04:48.060, Speaker A: And we'd be doing the manual deployment, which is also the approach we'd use for main net. The only open question is what do we do about the trusted setup file? Do we continue using the one we've used in the past or is there an updated trusted setup file? So the setup file is not updated yet. Okay, then we'll continue using the previous one and then we do devnet nine and possibly a future devnet can use the new trusted setup file. Sounds good.
00:04:50.190 - 00:05:16.610, Speaker B: One more quick note. We probably will need to have a devnet ten. Also to test out the churn limit change, where we can actually spin up 350 to 400,000 liters and then see if the churn limit change is actually working for all the different cs. But that is expected to be a much shorter lived Devnet.
00:05:21.180 - 00:05:50.710, Speaker A: Got. And one more point following that one. The mev workflow works with the mock builder. Now, we've tested four of the five cls and it works fine, which means we would like to start pushing for everyone to have mev workflows. And ideally in devnet nine. Devnet ten also test mav builders and relays. So if you have a builder or relay, please reach out and we'd like to get you set up.
00:05:52.840 - 00:06:09.240, Speaker B: And one more quick note that we're going to be deprecating the bell tricks genesis. So from now on, Devnet nine and any future Debnet and Testnet will probably use capala Genesis.
00:06:15.420 - 00:06:45.180, Speaker A: Got it. One quick question before Mario. So you mentioned the validator churn limit. So that and the blob base fee, are they implemented in clients for Devnet nine? I recall that was what we had agreed on. Yeah, it's just that the noticeability of that churn limit cap is not going to be hit until certain validator thresholds. Yeah, got it. There's logic there, but you're not going to hit that code path.
00:06:45.180 - 00:07:02.820, Speaker A: Got it. Yeah. This is a configuration variable, so we could change it to be lower. But I'm also fine with doing a big test that uses mainet configuration.
00:07:03.400 - 00:07:19.690, Speaker B: Yeah, I would not do anything lower than four. So that's why I said we would need at least 360,000 validators for bigger tests. We also don't want to run a 400,000 validator test for multiple weeks that Devnet Nine is supposed to live.
00:07:21.900 - 00:07:33.870, Speaker A: Got it. So because the number of validators hired and just having a short run once devnet nine is stable, to make sure we hit those code paths and everything works is the plan.
00:07:34.800 - 00:07:36.590, Speaker B: Yes, that sounds about right.
00:07:37.440 - 00:07:55.474, Speaker A: And we'll be testing it with holes key anyway. So eventually we'll be testing it with a bigger set. Right. Got it. Sweet. Mario Vega, you had your hand up a couple of minutes ago. I don't know.
00:07:55.672 - 00:08:32.560, Speaker D: Yeah, just a couple comments. So on the side of the test running on the hype cancun, some of the errors might be that we bumped up the parallelism on the test execution. So we are lowering it down. So probably we'll see more passing tests from the clients later today. And another comment is that I think at least one of the clients has not updated the address for the beacon route, so I'm passing it over the chat. So make sure that you have this address for all the tests and for Devin 92.
00:08:35.330 - 00:09:44.070, Speaker A: Got it. And did any of the other time teams want to share progress updates or blockers or anything? With regards to the devnets, I can say that we're passing a lot of the hive test now. I think we've gotten it down to about ten or eleven of the hype cancun ones that we're not passing, and most of them are pretty small edge case things like what happens if you try and send some of the cancun data objects in an old method, like for choice v two or new payload v two. And just trying to find the best way to implement these changes. I think the only notable thing is that we still haven't added the code path to actually propagate blob transactions on the PTP. So we have the blob pool to keep track of the blob txs if they're submitted directly to us via an RPC. But right now we're not sharing them on the p to P with our peers.
00:09:44.070 - 00:10:07.260, Speaker A: Got it. I'm curious, do other clients have peer to peer networking for blob transactions? Okay, so nevermind and rest have it.
00:10:08.590 - 00:10:32.834, Speaker E: But sorry, I'm a bit confused. I think in the epit says that gossip is not allowed. There should be no gossip for blob transactions. But it should be in a hash announcement. But not in gossip. But maybe I'm missing.
00:10:32.882 - 00:10:48.410, Speaker A: We're not announcing them at all. Yeah, we have a different code path for transaction fetching and that just hasn't been connected with the blob pool. So it's not really aware when transactions are submitted to the blob pool to share with its peers.
00:10:52.140 - 00:10:57.870, Speaker E: I think ETH 69 should have the gossip announcements, right?
00:11:09.650 - 00:11:23.970, Speaker A: Yeah, I'm not sure if this specific number, but. Okay, so get doesn't have that, but yeah. Andrew, does Aragon have the announcement?
00:11:25.590 - 00:11:31.160, Speaker E: Yeah, I think we have them. You can double check. But we should.
00:11:33.930 - 00:12:18.230, Speaker A: And I guess on the El side, besides some. One moment, Matt, you said that gap doesn't have it. Are you sure? I don't really see a reason why we wouldn't announce. Yeah, there's a channel that's not hooked between the blob pool and the transaction fetcher. So we don't really push anywhere that we've received a new transaction in the blob pool. But the transaction fetcher is not relevant when announcing transactions or the ease handler. Sorry.
00:12:18.230 - 00:12:39.070, Speaker A: Yeah. Anyway, I have to look into this. It's a bit weird. Yeah. If it is connected, then it's failing the hive test for propagating the transaction. So we could look more into that. But when I looked at it, there's the transaction announcement channel, and it's just not hooked into the blob pool right now.
00:12:47.050 - 00:12:56.170, Speaker B: Are we not working the other way around that you're subscribing to the transaction announcements?
00:13:06.140 - 00:13:59.896, Speaker A: Okay, I guess maybe you all can figure this out off slide, but I just want to check broadly. So blob gossiping. And then there's a few failing hive tests for it seems like most of the El clients. Are there any other sort of big blockers or big chunk of work left on any of the El clients? Yes. One week ago I did an experiment with sending a high amount of blob transactions with only six blob in transaction. And like Devnet eight were not healthy under such high load. And in nethermind we had a bug.
00:13:59.896 - 00:15:01.088, Speaker A: In broadcaster, we're sometimes requesting transactions which we already have in blob pool. So after fixing it, the condition of our nodes were way better. But there is still some work to be done on building blocks when there is a high amount of block transactions in the pool. But it's definitely not a blocker, it's optimization. Got it, thanks. Any other team have blockers or just optimizations or things that they're working on they want to share. So for Bezo, regarding the blob transaction, we still have to apply some optimization.
00:15:01.088 - 00:15:55.510, Speaker A: Now it's possible to crash the node if you send too many blob transactions because the limits are not yet in place for that kind of transaction. On the other way, I was following some oleski nodes, so I'm not sure if before you were talking about transaction broadcast, but Bezu is broadcasting also block transaction. Got it. Thanks. I think that's most El team. Sorry. If anyone else has anything they want to share, and if folks on the Cl side have updates they want to share as well, feel free to.
00:15:59.240 - 00:16:02.100, Speaker E: Also gossips the block transactions.
00:16:02.920 - 00:17:16.190, Speaker A: Got it. Okay, so I guess then, yeah, if we have Devnet nine going live, hopefully tomorrow or maybe early next week, we can see how the different clients work on it. And then it probably makes sense to test the blob transaction gossip code, pass on it, and hopefully have things stable, then run another one on another devnet with a high validator count for the churn limit, and then start moving to testnets. Once things are stabilized. Does that seem reasonable to people? Cool. And yeah, we can follow up either next week or the week after once we have a bit more data on how the Devnet mine tests went to figure out next steps. But yeah, it seems like we're in the final stages of just polishing everything and getting it ready.
00:17:16.190 - 00:17:55.860, Speaker A: Anything else on the devnets? Okay, next up then. So we had three audits done for the smart contract that's part of 4788. So I linked two of them in the chat, sorry, in the agenda here. And then the third report we expect to have tomorrow. But I believe we have folks from most of these teams on the call. So is anyone from chain security on?
00:17:57.030 - 00:17:59.206, Speaker F: Yeah, hi, this is Hubert here from chain security.
00:17:59.308 - 00:18:06.730, Speaker A: Hi, yeah, do you want to give a quick, just overview of your report, the audits in general, and sort of any thoughts you have on the contract?
00:18:07.390 - 00:19:25.234, Speaker F: Yeah, sure, I guess. Super quick recap, but most are aware. So EIP 4788 will introduce this smart contract that will store the beacon routes where only the system address is allowed to set beacon routes and anyone can otherwise query. So the primary finding of our report was that you could query the zero timestamp and would get back a zero hash as long as the slot for the zero hash was still uninitialized, which in the original version of the code would have taken a long time to initialize because of how it was set up. But that directly brings me to the secondary finding in our report where we suggested that the size of the two ring buffers, so we have ring buffers for the timestamps of the corresponding beacon routes and the beacons roots themselves. So we suggested that the ring buffer sizes become prime numbers so that the storage size of the contract is more predictable, even when the block interval might change in the future. Yeah.
00:19:25.234 - 00:20:18.002, Speaker F: That being said, I'm happy to talk more about what we did. We did a bunch of tests and even some formal verification, but I guess to conclude, the most interesting insight that we had towards the end, now, based on the updated review where we reviewed what prime buffer ring size means, is that really the property? Because the original EIP said that beacon routes should be held for 24 hours. So the real property that the contract has at the moment is that beacon routes will be held for 8191 seconds at least. So as long as the block interval doesn't change, then everything is fine.
00:20:18.056 - 00:20:18.660, Speaker A: And.
00:20:20.870 - 00:21:11.742, Speaker F: Every beacon route will only be overwritten after, let's say, 8000 blocks. But the moment the block interval changes for this time period, like where the change happens, this property doesn't hold anymore. So we just want to point out that in this somehow very tight transition time, you only have, let's say 2 hours guaranteed history of block of beacon routes. So yeah, I would say these are our primary findings, but. Sorry, I hope this wasn't too quick. But yeah, Tim linked our report in the chat, so obviously feel free to read the whole thing or ask questions now or directly.
00:21:11.886 - 00:21:39.100, Speaker A: Thanks. Thanks. Yeah, we'll see if there's other auditors on the call and sort of get everyone to go through their findings and then we can do questions to everyone after that. I don't know if there's anyone from trail of bets on the call. I don't think there is. So I link the reports at pDF. It's not published on their website yet, but I linked it in the agenda if people want to check it out.
00:21:39.100 - 00:22:30.890, Speaker A: And then last we had DDOB also do an audit and I believe they have someone on the call and we expect the report to be out tomorrow. Yes, hello. So essentially our findings were similar to the previous one. So the only, let's say real finding was that the zero timestamp can be quit successfully. And according to our analysis, with the block time, it could never be overwritten. But that was a migration and it was solved. And then the other thing we did is we had, as an exercise, what would happen if the block times were to change and we resulted into advisory items.
00:22:30.890 - 00:23:31.742, Speaker A: Basically that the storage footprint would change for different parameters, for even possible block time parameters, and that some stale values would remain stored. But again with the changes, this is resolved as well. Now we have reviewed the changes but we just haven't updated the report. So it will be up in the same link again and we'll update it tomorrow. Now in terms of methodology, what we mostly did is we inspected the code in different representations using from disassemblers to our own decompiler and binary lifter to see how it works here. So that's all. If there are any questions, I'm happy to answer.
00:23:31.742 - 00:23:48.070, Speaker A: Also, Michael de Bonne is on the call here with me. He also worked on the audit. So Maris has a question in the chat about push three. Do you want to give more context on that? Maris?
00:23:49.210 - 00:24:12.720, Speaker B: Yeah, in the updated code we use push three to push a constant that is only four bytes long. Sorry, two bytes long. Yeah, but it's not a big deal. I was wondering if someone else caught this as well.
00:24:14.050 - 00:24:27.460, Speaker F: Yeah, we noted this in our updated report. Yes, but I'm not sure if it's relevant enough for change. But, yeah, we noted this in our report.
00:24:29.910 - 00:24:35.240, Speaker B: It's not relevant enough, I think I would say, for changing it now.
00:24:39.530 - 00:25:15.370, Speaker A: Yeah, we didn't see that. Are there any other questions? Okay, yeah, so we'll have obviously all three reports. People can review them and bring up questions if there's any in subsequent calls. But I think at this point, we're pretty confident in the changes and the final version of the bytecode. Does anyone have anything to add or questions, concerns?
00:25:17.090 - 00:25:50.600, Speaker F: Yeah, just maybe one quick addition. I know this is not necessarily the target audience here, but indirectly it might be. So it might be useful to push to smart contract developers the info that when you're querying for a timestamp x, you're not getting the beacon route from time x. You're getting the beacon route that was inserted at time X, but originates from an earlier timestamp. I think that will otherwise lead to likely implementation issues.
00:25:52.730 - 00:25:54.570, Speaker A: Right, good point.
00:25:54.720 - 00:25:55.420, Speaker C: Yeah.
00:26:01.150 - 00:26:52.490, Speaker A: Okay. Anything else on the 4788 contract? Just wanted to say thanks a lot for all the auditors who took time to look through this, and all of the people who we didn't engage directly who took a chance to look through it, and all the client teams who updated the address four or five times. Yeah. And also special thank you to the auditors who looked. We were a bit late in sending the updated commits around, so appreciate the quick turnaround for the additional review. Okay, then, next up, we had Holski relaunch this morning. I'm not sure Barnabas Perry who's the right person to give a high level update.
00:26:53.150 - 00:27:19.700, Speaker B: Yes, we had the launch this morning. We had the first ten epochs a bit struggling, but since then quite some validators came online and now we are finalizing with about 78% to 80% participation. We are still trying to get as many validator groups online as possible, and hopefully we are going to be closer to 90% by the end of today.
00:27:20.150 - 00:27:31.160, Speaker A: And is there like 20, 30% missing validators that are struggling to keep up, or is it just people who forgot about the launch and are not online at all?
00:27:32.170 - 00:27:35.078, Speaker B: There was a bug with vouch and prism.
00:27:35.174 - 00:27:35.546, Speaker A: Got it.
00:27:35.568 - 00:27:40.646, Speaker B: And because of that we saw a bigger group being offline.
00:27:40.838 - 00:27:41.900, Speaker A: Got it.
00:27:42.750 - 00:27:56.318, Speaker B: And also some people just run a lot more validators on a smaller machine, which caused some performance issues and missed proposals, but it's slowly getting there.
00:27:56.484 - 00:28:35.004, Speaker A: Okay, nice. Anyone else have thoughts, comments, questions about the launch? Awesome. Well, congrats on getting it live. Okay, you have some nice graphs that we can all retweet. Nice. Okay, then moving on. We had two eips, or at least one EIP and one sort of modification to discuss.
00:28:35.004 - 00:28:59.188, Speaker A: So first up, we have some folks on the call who want to introduce Eip seven five three, which called zero knowledge wormholes and enables minting secretly burned Eth directly on l one. Yeah, I forget who is the author, but if you want to speak up now, it's time.
00:28:59.274 - 00:29:00.884, Speaker E: Yeah, we are here and.
00:29:01.002 - 00:29:01.764, Speaker A: Hi. Hi.
00:29:01.882 - 00:29:11.530, Speaker E: Timber. And my friend now trying to share him a slide and introduce the whole idea and the whole EIP. Kavan, are you online?
00:29:12.940 - 00:29:14.888, Speaker C: Yeah, can you guys hear me?
00:29:14.974 - 00:29:16.490, Speaker A: Yes, we can hear you both.
00:29:17.520 - 00:29:26.636, Speaker C: Sounds good. So let me share my screen. Okay. Do you have my.
00:29:26.738 - 00:29:28.110, Speaker A: Yeah, we see the.
00:29:29.280 - 00:30:22.080, Speaker C: Okay, perfect. Okay, thanks guys for having me here. I'm Kayvon, a member of Novatex Labs, and we have been researching on privacy solutions that are based on zero knowledge proofs in the past few months. And recently we have found a new privacy solution that we found interesting and it's the topic of this presentation. We have named it zero knowledge wormholes and we have made an EIP for it, which is EIP seven five three. It's currently in the draft stage, but you can check it out if you want. So, yeah, let's get deeper.
00:30:22.080 - 00:31:33.620, Speaker C: So, if I want to describe it in a single sentence, it's a proposal that is proposing Ethereum l one clients to enable reminting of eaters that are secretly burnt. Before going further, we first have to define what is a burnt eater. Eaters are burnt if they are in addresses that are not expendable. As you know, there are two kinds of addresses in Ethereum blockchain. There are externally owned deck cons and there are smart contracts. And both of them, they are derived from getting the kchak hash of something. So in case of externally owned accounts, you get the kcheck of a public key and you just cut the first 20 bytes of it.
00:31:33.620 - 00:33:04.420, Speaker C: And in case of a smart contract, you get the kcheck of the combination of the deployer address and its accounts nons. And then you just get the first 20 bytes. And we define unexpendable addresses. So an address is unexpendable if there exists no private key such that the catch of its public key is equal with the Akons address, or there exists no address and non spare which is kchak is equal with the. So if we send Ethereum to an address that is definitely random and not a result of getting a kchak of a public key or something like that, the fonts in that address are burned because you can't suspend them anymore. And the reason this happens comes back to the fact that hash functions are pre image resistant, which means it is invisible to find an x such that the catch of x is equal with some arbitrary value. And yeah, so if you know that some phone has been sent to an address that is definitely random, you know that the funds are burnt.
00:33:07.000 - 00:33:07.748, Speaker G: The question.
00:33:07.834 - 00:34:13.956, Speaker C: Is, how can one confidently know that someone else has burned his eaters? We can have an interactive protocol. We let someone else to choose the random bytes for us, and he gives the random bytes to us and we send our iters to that address, and then we can be sure that those funds are not spendable. So this is kind of an interactive protocol. And yeah, this was a meme I found a bit ago on Twitter, which I found funny. It says like cryptographers use this fiat Shami heuristic trick in order to turn interactive protocols into non interactive versions of them. And yeah, we can use an idea like that here too. We can use hash functions as sources of randomness.
00:34:13.956 - 00:35:49.450, Speaker C: So in case of a non interactive protocol, one can choose a pre image r and send his iters to hash of r, like the 21st bytes of hash of R. And yeah, the hash function use should be something other than ketch. It could be like, I don't know, sha two or some zk friendly hash function like Mimc or Poseidon or something like that. So yeah, I will generate this pre image r and I give it to you as a proof that the address I have sent my iters to is indeed random, because it is very hard to find a private key that its public key is equal with hash of something. And yeah, the next trick is that using the help of zksnarks, we can hide the value of this pre image r. And imagine that in our Ethereum clients we are recording all of the Ethereum transfers that are happening in a giant Merkel tree, a sparse Merkel tree to be specific. And using the help of Zksnarks, I can prove that an Ethereum transfer has happened which has burned some amount of ethereum, but I won't show which transfer was it.
00:35:49.450 - 00:37:16.400, Speaker C: The whole idea behind EIP 75 three is that let's build a new kind of transaction in Ethereum that allows us to mint Ethereum when someone actually provides such a proof that some amount of ethers have been burned. And the beauty of this method, and the reason it is better than other cryptocurrency mixers, is that it gives you a bigger anonymity set. We can somehow say that all of the accounts that have not transferred anything yet are included in the anonymity set. And as the sender, you can always deny that you have ever used this protocol, which is very good for you as a sender. And yeah, here I have an implementation proposal of how something like this can be implemented on ethereum clients. So we can have something like an event handler in our code that is called whenever an it transfer happens. It could be transfer that is happening as a result of a function calling a smart contract.
00:37:16.400 - 00:38:52.464, Speaker C: So we gather all of its transfers in a single function and we put the hash of the destination address and the value that is being transferred in a zk friendly sparse Merkel tree. And then we should have a new transaction type, which we call it the mint transaction, which means some amount of iter in case someone proves that he knows a pre image r where h of r combined with amount exists in the miracle root of the Merkel tree we were maintaining. And we can also have a nullifier to prevent double spendings, very similar to tornado cache style mixers. Yeah, so that was the basic idea. And this could have some extra features, like we can allow people to merge and split their nullifiers to bring some private utxo model on Ethereum whenever someone migrates his funds into this private anonymity pool. And yeah, in case we are able to split our coins, we will be able to spend only a portion of our money. Like we can burn ten eaters and only spend one eater, something like that.
00:38:52.464 - 00:39:58.360, Speaker C: And instead of using hash functions, we can do elliptic curve multiplications. And this will allow us to have steels burn addresses. Like someone will give me a burn address and people can, someone can publicly provide burn address and we can drive other burn addresses which are spendable by the master burn address holder. And we can have steels addresses and we can also obfuscate the amounts in case people transfer their ethereum in the pool. And as an extra feature, we can also have proof of innocency. And there is also implication if we implement such a thing in Ethereum. And it's about scalability.
00:39:58.360 - 00:41:31.204, Speaker C: The thing is that centralized exchange usually gather the user's funds into their hot or cold ballots from time to time by making a lot of transactions. So they will give different users different addresses and after some time they will move all of these funds into a single address, which is like a huge source of transaction traffic on Ethereum blockchain. And imagine we are able to pre mint multiple burns in a single proof. Imagine there is an exchange that gives burn addresses to its users and it's able to generate a proof like proving that 1000 burns have happened and the sum of those burns is like 100 eaters and remains them in a single transaction. This will save a lot of space. And using this solution, we will only store a single nullifier value instead of a whole transaction with a giant signature on our database. Yeah, that's it.
00:41:31.204 - 00:41:36.010, Speaker C: Thank you. If you have any questions, you're happy to answer.
00:41:37.740 - 00:41:51.180, Speaker A: Thanks for sharing. Yeah. So there was one question in the chat asking about how would you track the ETh supply under this scheme? Would it still be possible to just track the total supply?
00:41:52.880 - 00:42:10.560, Speaker C: Yes, absolutely. Each supply. In this case, you can get the total supply by subtracting the amount that has been minted from the total ethereums in all of the Ethereum accounts.
00:42:15.940 - 00:42:31.530, Speaker A: So you're able to track how much has been reminted. And so if you look at the balance of every account, which includes the burns account, and you remove, however, was minted in a new mint transaction, that gives you the circulating supply. Is that right?
00:42:32.380 - 00:42:33.480, Speaker C: Yeah, exactly.
00:42:33.630 - 00:42:45.420, Speaker A: Got it. Any other questions? Thoughts? Oh, Guillaume.
00:42:48.720 - 00:43:27.290, Speaker G: Yeah, quick question. So you're putting everything in a miracle tree. Why do you bother doing this? Because if you can make a snark proof that a ZK snark proof that you sent funds to a burnt address, why would you incur the extra issue that is plaguing tornado cash, for example, that you're pooled with potentially other criminal transactions and therefore you would become immediately suspicious by using this system?
00:43:29.520 - 00:43:56.880, Speaker C: Yeah. The point is, as the sender, as the sender, you can always deny that you have been in this protocol, so you are safe, but as the receiver, your phones may be flagged or something like that. And the reason we are using a miracle tree is because we want to hide the addresses that are actually like burn addresses.
00:44:01.780 - 00:44:08.090, Speaker A: There's another question in the chats that's asking, can't you deploy a contract to an unspendable address with create two?
00:44:11.700 - 00:44:20.770, Speaker E: Not yet, but we are working on it and we can't find any solution for doing that. But we're working on it.
00:44:22.180 - 00:44:46.670, Speaker D: No, sorry. The question is the opposite, is that this should not be possible, because if you can deploy a contract on the unspendable address or the burn address would be a problem. So if you use create two, create two does not depend on the deployer's address and announce. It depends on other factors like the contracts code.
00:44:48.000 - 00:45:37.672, Speaker E: I got it. Let's say in this way we can prevent this event with using the random number and providing the proof in our circuit. And we can prevent this event using and deploying a contract on the same address with using the create two, because the create two using some sort of parameter. And I can put these parameters in my circuit to prevent this event. But what if we can do some sort of thing? If we can find a way to doing this way, we don't need the protocol change and we can do our mixer in the contract level. But I don't think so. There is an easy way to find this approach.
00:45:37.672 - 00:45:42.350, Speaker E: If we find it, we can do it on the contract level, not to protocol level.
00:45:44.720 - 00:45:52.770, Speaker G: But how do you guarantee that your circuit is going to have a random number?
00:45:54.580 - 00:46:48.450, Speaker C: Yes, the thing is, it is almost impossible to find appropriate parameters for generating a contract address that is equal with like for example, the MiMc of some random number. I don't think this is possible. I mean, a hash function that is not Kcheck is a source of randomness in our case. And you can just easily find the parameters that are used for generating contract addresses that will result in an address that is exactly equal with the output of our other hash function. If you know what.
00:46:56.140 - 00:46:59.340, Speaker E: We'Re using the hash function as a source of randomness.
00:47:00.960 - 00:47:06.350, Speaker A: And the input to the hash function is given by the protocol, like randao or the state route or something.
00:47:07.700 - 00:47:11.010, Speaker C: No, the user can actually pick anything.
00:47:13.380 - 00:47:17.010, Speaker G: Right? So they could pick something that they like.
00:47:18.420 - 00:47:19.170, Speaker C: Exactly.
00:47:22.570 - 00:47:25.990, Speaker G: Therefore, you cannot prove that this address has been burnt.
00:47:30.240 - 00:47:52.432, Speaker C: Yeah, you will need your pre image value in order to prove that this address is a burn address. Because if you lose your pre image, then no one can be convinced that this address is really a burn address and not the result of hashing public key.
00:47:52.486 - 00:48:07.800, Speaker G: For example, if your pre image is not shared, because you said it's part of your private witness, right? So it's not shared. How do I prove to you that my number was indeed random?
00:48:09.340 - 00:49:20.530, Speaker C: Yes, so you do the hash function, you do the hashing in the circuit. And your argument is that there is a transaction that has happened in the previous blocks that have sent some iters to an address that is actually the output of ZK friendly hash function and not a k check. If you prove that the address is the output of a Zk friendly hash function, then people can be convinced that this address is indeed random. And by that they can be sure that there is a very low probability that people can spend the money in that address. But the transaction itself and the address itself is hidden. No one can know that which address is the burn address, but they will definitely know that one of the addresses is a burn address. Something like that.
00:49:20.980 - 00:50:06.350, Speaker E: Exactly. In the whole network view, no one can see or understand what is address is a burnt address or a normal address. But let's see. We just need to find a point on the elliptic curve that we don't know the private key, and we should provide the proof we don't know the private key. And for doing that, we can do it simply get a random number on the curve and multiply it with the hash of our pyramid hash of our private key. And we can provide a proof with our circuit for doing this and finding no random point on the curve. We don't know the private key.
00:50:12.540 - 00:50:21.890, Speaker D: So what you need is to prove that this address can never be produced from a kitchen hash. Can you prove that?
00:50:22.580 - 00:50:23.330, Speaker C: Yeah.
00:50:25.540 - 00:50:33.540, Speaker D: From any kitchen hash. Not only from deployer plus nons kitchen hash. From any kitchen hash.
00:50:34.600 - 00:50:42.310, Speaker C: Yeah, exactly. Actually, let me write something in the chat. So it is very fine.
00:50:43.240 - 00:50:45.400, Speaker E: You are talking about the collision.
00:50:50.140 - 00:51:04.430, Speaker C: The argument is that you can find a pre image x for a ketchup hash that is equal with a pre image y applied on another hash function. This is impossible to do.
00:51:07.920 - 00:51:42.920, Speaker G: Right? That's actually my other question. So you want to build a transaction that would mint token that is based on the premise that Poseidon is trustworthy? My understanding is that currently it's not, or at least it's not been used enough in the field that we trust it. So we should consider it as non trustworthy for the time being. And assuming we're right to consider it not trustworthy, that means it would be possible to find a pre image and therefore to mint tokens.
00:51:44.300 - 00:51:58.830, Speaker A: But the construction is sound. If you use Shaw 256 or something. Yes, we can debate the hash function and which hash functions are safe versus optimal, but the construction is safe if you have a safe hash function.
00:52:00.080 - 00:52:12.960, Speaker C: Yeah, you can use any hash function. Like, you can shot 256 folks too. But it will make the circuit bigger and it will take more time to generate such a zero knowledge proof.
00:52:14.520 - 00:52:56.316, Speaker H: The ZK friendly hash functions, basically, there's like MIMC, Poseidon, a few others, and even these that are the most used are very relatively well unknown. Their properties, they're kind of new. And this technology is being experimented with with multiple l, two s and other privacy pools. But we've seen inflation bugs in aztec privacy pools, different versions of tornado cache. We saw one in Zcash that we don't actually know if it was used or not. And so the issues with introducing relatively untested versions of privacy pools, whether it's this construction or others have inherently huge risk. And I would argue that we don't gain much by putting it in the base layer.
00:52:56.316 - 00:53:41.570, Speaker H: Now we stand to potentially lose the credibility of all ethereum and the ability to say how much ethereum actually there actually is, which would be detrimental. I'm a huge advocate for privacy. I think there's a lot of reasons for it. But to be honest, we still have solutions, whether it be an l two s or other mixing contracts where people can get these sort of functions when they need them, that don't bring the same inherent risk to the base layer. And I guess what I would like to know is, like all constructions and technical details aside, what is the argument for bringing this into the base layer now versus leaving it in L two s and other things?
00:53:45.940 - 00:54:12.570, Speaker C: Yes. So the whole advantage of such a thing compared to other privacy solutions is that there are no smart contract interactions at the sender. So that is some kind of a new thing we were considering. Yeah, it's a very large anonymity set.
00:54:15.700 - 00:55:27.092, Speaker H: I think that we have sufficient anonymity sets for this purpose. We have to kind of give up some things, like we have to have fixed size pools right now, otherwise we have to trust newer technology like Nova. But for what it's worth, from the security side, and I'm not an expert, but I spent the last eight months kind of collecting ZK bugs and looking at various bugs, and we've seen inflation and double spin bugs in almost some version of almost every single major mixing technology. And so I would argue that long term, maybe this is something like, this is where we do want to go for various reasons, especially like a pre compile, making this cheap. That would be really great. But short term, I would advise against using these hash functions that are not relatively tested to the other hash functions have 20 years of testing, and we're starting to see collisions in them, and we have a better understanding of where we're at there. But like circuits themselves, I would advocate in being cautious of adding these directly into the base layer.
00:55:27.092 - 00:55:54.770, Speaker H: And I think the only other eips that we've even considered using ZK proofs for are still relatively simple versions of things, and we're hesitant to even go there. That's just my two cent. I think it's about like a when, maybe not so much an if. And I think that testing the technology significantly more and finding the right construction and stuff, it sounds like there's still some dispute about the construction itself.
00:55:57.540 - 00:56:41.810, Speaker A: Yeah. And I think just also to be super clear, I didn't want to bring this up today in the context of, like, do we do this in the next hard fork? But more like, is this something we can start to get people thinking about? And obviously, the first path, the easiest way to get something like this used is you could imagine it being deployed on an EVM equivalent, l two. Right. And running that for a couple of years and having significant funds use it, building confidence over time, because, yeah, obviously there's been many cases of ZK bugs, and it's all still quite new.
00:56:42.740 - 00:57:43.648, Speaker H: Yeah, I definitely think that's a good path forward. The one thing I will say is that if you look at Ethereum and you trust the way it works right now, and you say, like, okay, Ethereum works, if ketchak works, if BLS signatures work, we're saying there's not, like, some serious bug in the base layer. And if we did add this, we would be adding circuits, we would be adding dependencies on a ZK friendly hash function and other things that we don't have yet. And that is a big leap. And in Bogota, there was some discussion about when would you be okay zking the entire EVM in the base layer? And there's benefits for that. And I think the general answer, at least, that I was like, the school of mine that I was in was almost never. There's some benefits to having transparency at the base layer, because you can count the total supply if there's full privacy in an l two and there is a serious bug, or there is some issue with circuits.
00:57:43.648 - 00:58:26.256, Speaker H: ZK technology has been around, in theory, since the years at a larger scale, and maybe eight beyond that. And we would be basically opening ourselves up to that. Like, right now, if there is an inflation bug or if a privacy pool goes insolvent or something, an entire l two, we wouldn't even know. But if the base layer has transparency, we always know. At least the base layer can sever that limb and survive. And I don't think that this is, like, a perfect analogy, because these pools would be slightly smaller than, like, a huge l two, and you're using them to mix. So it's not like one address has $100 billion in it.
00:58:26.256 - 00:59:12.128, Speaker H: But we do open ourselves up to a question and fud about the actual total amount of ethereum. And I also do think Lucas kind of mentioned something about the regulatory perspective here. I'm not saying ethereum should bow to the ideologies of governments or anything like that, but there is a happy medium before there where you can still get things like privacy and you can still get things like provable total inflation. Right. Anyways, I've said my part. I do think this is a very exciting construction. Let me just say that I don't want to complain about that.
00:59:12.128 - 00:59:26.260, Speaker H: I think it's exciting. I think we should just use a lot of caution. And it's not just for legal reasons, it's not just for security reasons. I think there's like an ideological aspect to this. I think we should discuss all of them. And I'm happy to put my thoughts into the IP directly.
00:59:28.120 - 00:59:56.830, Speaker A: Yeah, I agree. Both from a technical soundness analysis and also from do we eventually want to do this on l two, s on l one and whatnot. There's a lot of discussions to be had, and maybe this is a good place to wrap up. What would be the best place for people to discuss this dip? I assume it's like an ETh magicians thread, but is there somewhere else? The authors think it's better.
01:00:01.220 - 01:00:06.850, Speaker C: We haven't built a discussion group for that, unfortunately, yet.
01:00:08.740 - 01:00:21.030, Speaker A: Got it. So let's maybe just use the discussion link on EtH magicians for now, and then if you have a new and better place, we can move to that in the future.
01:00:22.920 - 01:00:23.876, Speaker C: Sounds good.
01:00:23.978 - 01:00:34.170, Speaker A: Yeah. But yeah. Thank you so much for presenting, and if you can share the slides either here on the discord or on ETh magicians, that would be great for people to be able to review them.
01:00:37.610 - 01:00:40.440, Speaker C: Sure thing. I will put it in the chat too.
01:00:40.890 - 01:00:57.610, Speaker A: Awesome. Thank you. Sweet. Then last up. So, Guillaume, you wanted to discuss some self destruct behavior changes with regards to virtual?
01:01:00.190 - 01:01:21.540, Speaker G: Yeah, yeah. Something very simple, in fact. I don't know if I can share my screen. Yeah, I'm always at the loss to find my window. Okay, well, it doesn't really matter. So what's happening is that.
01:01:23.270 - 01:01:23.666, Speaker A: If you.
01:01:23.688 - 01:02:58.686, Speaker G: Look at the text of the EIP 67 80, it says when self destruct is executed in the same transaction as the one the contract was created in, you retain the old behavior. But there's one thing where the old behavior is not retained, and that's in the case of vertical trees, in which case it says the clear storage will be marked as having been written before, but empty. That's something I would like to change, but it's a request that also came from dragon, from wrath, because if you look at the code, when you do the deletion, basically nothing hits the tree layer. So we would have to create a special case to write a zero, and it's a departure from the current behavior, and that's something that indeed has no observable difference from the EVM point of view, but from the client code base point of view does have an impact. So I would like to remove this and just keep the current behavior, which is the tree doesn't get updated in that case. So yeah, I would like to know if someone is against that. I know Dano has countered, but I don't think it's really a counter.
01:02:58.686 - 01:03:44.500, Speaker G: It's still compatible with this approach. Dano has suggested we simply deactivate self destruct with vertical trees, period. That's going to spark a lot of debate, and we don't necessarily need to have this debate now. But yeah, I would like to just focusing on the EIP proper, leaving open the possibility to deactivate self destruct altogether at a later stage. I would like to know if there's some disagreement with this approach of keeping the old behavior in the vertical tree world.
01:03:51.740 - 01:03:53.560, Speaker A: Any thoughts, comments?
01:04:00.150 - 01:04:31.182, Speaker G: I mean, there's a comment by Ahmed. Yeah, that's exactly what the effect would be, except you don't even delete what's in the tree because that account has been created and self destructed before the cleanup code. The cleanup process at the end of the block writes it to the tree. So it would be an in memory EIP 158.
01:04:31.236 - 01:04:31.790, Speaker A: Basically.
01:04:31.940 - 01:04:37.790, Speaker G: I mean, this is how it works already. I would like to retain this behavior in invertible.
01:04:39.010 - 01:04:41.120, Speaker E: That sounds reasonable to me.
01:04:45.910 - 01:04:53.300, Speaker A: And when you say this is how it works already, you mean width 67 av.
01:04:56.490 - 01:05:15.450, Speaker G: Yeah. Even if you create a contract and you self destruct it in the same transaction, all of a sudden I'm being unsure, but I'm still pretty sure that it never hits the disk, basically. So it's as if nothing was created.
01:05:16.350 - 01:05:32.480, Speaker D: My understanding is the same. It's as if nothing is created. So my question to gallium again is, what exactly is the proposed changed? Because if nothing hits the disk, what's the problem?
01:05:33.010 - 01:05:58.790, Speaker G: The problem is that this is not what the EIP says. Currently the EIP says in the vertical tree world, when a contract is created and self destructed in the same transaction, we should overwrite all the for example, the balance should be set to zero and the tree should be updated with a zero, instead of the account being nonexistent.
01:06:01.310 - 01:06:07.740, Speaker A: Okay, so this is the last bullet. I'm looking at the EIP now. This is like the last bullet of the second.
01:06:10.030 - 01:06:11.262, Speaker G: Exactly the bullet two.
01:06:11.316 - 01:06:11.920, Speaker A: Okay.
01:06:13.090 - 01:06:13.902, Speaker G: Removing that.
01:06:13.956 - 01:06:22.430, Speaker A: Yeah. And I assume this would not change anything about current implementations because it's all based on when vertical trees are implemented.
01:06:23.990 - 01:06:24.740, Speaker G: Exactly.
01:06:27.030 - 01:06:37.134, Speaker D: Okay, now it's clearer. Let's check who added this point and why. Because there must be a reason for adding this.
01:06:37.192 - 01:06:55.160, Speaker G: So it's Dankrad. And I asked him and he said he thought that would be. I mean, I don't know. I saw him earlier, maybe he can confirm directly. I don't see him right now. Oh, yes, he's here. But yeah, basically he said he thought that was simpler, but turns out it's not.
01:06:55.160 - 01:06:59.560, Speaker G: Unless Dankrad wants to add something.
01:07:00.090 - 01:07:00.430, Speaker A: That.
01:07:00.460 - 01:07:02.160, Speaker G: That's my answer.
01:07:07.540 - 01:07:14.944, Speaker A: Yeah, no, I don't have a strong opinion on what the state of those.
01:07:14.982 - 01:07:16.084, Speaker B: Such addresses should be.
01:07:16.122 - 01:07:22.948, Speaker A: Yes, it was simply seemed like that would be the straightforward to implement it.
01:07:22.954 - 01:07:23.844, Speaker B: But if it's the other way around.
01:07:23.882 - 01:08:06.936, Speaker A: Then we can just re specify it. Like in practice, it shouldn't matter in practice. From the EVM point of view, both of them look completely empty. So it's only about the state commitment where we need one unique definition. So in that case. Yeah, Guillaume, if you want to open the pr to just remove it, maybe give people a couple of days to comment if they weren't on this call or whatever. But then I would push for us to make that change now, because when the EIP is deployed on main net and it's set to final, it'll be harder to change.
01:08:06.936 - 01:08:21.440, Speaker A: So, yeah, now feels like the right time to just remove that. And it won't change anything in terms of client implementations, but at least the spec will be future proof. Yes.
01:08:21.510 - 01:08:22.850, Speaker G: Okay, I'll do that. Thanks.
01:08:23.540 - 01:08:26.130, Speaker A: Cool. Any other thoughts? Questions?
01:08:29.380 - 01:08:39.716, Speaker D: Why are we defining behavior about Verkel in an AIP for 6780 when Verkel did not hit main net yet, so.
01:08:39.738 - 01:08:47.370, Speaker A: We should have EIP standards. Yeah, I agree. It's kind of weird. Yeah.
01:08:48.780 - 01:09:03.580, Speaker D: My understanding is that if you want to add such specification, it should go into how vertical is implemented, not how the 6780 is implemented. That's just how I think about it.
01:09:03.730 - 01:09:26.230, Speaker G: Yeah, that makes sense. At the same time, the vertical EIP is already pretty long. I assume there's a risk that people might forget stuff, but yeah, if everybody wants it, I don't mind removing the entire paragraph because it makes no difference to me.
01:09:32.350 - 01:09:58.510, Speaker A: Okay, anything else on the cipher? Okay. And that was the last thing on the agenda. Anything else anyone wants to add before we hop off? Okay, well, thanks everyone. Talk to you all on the calls next week. Thanks.
01:09:58.960 - 01:09:59.576, Speaker G: Bye.
01:09:59.688 - 01:10:00.872, Speaker A: Thank you. Bye.
01:10:00.936 - 01:10:01.710, Speaker B: Thank you.
01:10:02.560 - 01:10:03.630, Speaker E: Thanks, guys.
01:10:06.920 - 01:16:12.800, Speaker A: Sa ra.

00:02:34.284 - 00:03:23.970, Speaker A: You okay? Welcome everyone to Acde number 81. Bunch of things on the call today. So first just going to go through Dencoon updates. I know some of the El clients already have releases, so yeah, chat about that and see where everyone's at. Then Martin had an EIP he wanted to discuss that should be retroactively applied from then so we can discuss that. There was another one by Peter who can't make it, but left a big comment in the discord that also is a retroactive EIP. So finalizing those two discussions after that, moving to Prague Electra.
00:03:23.970 - 00:04:28.160, Speaker A: There's three eips that people wanted to present. And then tomorrow we have an inclusion list breakout room. So go over those things and then hear from client teams how they're thinking about filling up the rest of Prague given what we've decided around Vercol and Osaka and one thing there as well. So we had sort of committed to 25 37 but yeah, just confirming that we're still good with that. Yeah, hopefully we get through all of that to kick it off. Anyone have any specific Denkoon topics they wanted to discuss otherwise, any clients want to share where they're at with regards to client releases for the main shadow should probably take next week. The main nodes that have not synced yet are Ern and rest, which are expected.
00:04:28.160 - 00:04:59.590, Speaker A: You're breaking up a bit, but I think I understood 90% of what you said. So you're syncing main net nodes. You're missing rest in another client. Yeah, it's just the archive notes take a bit longer to sync, but we should be hopefully ready sometime next week. And that should be in time for when client teams have releases. Got it. Sweet.
00:04:59.590 - 00:05:25.402, Speaker A: Yeah. I think Geth and Besu have releases out Nethermind Aragon rest? Yeah. How are things looking there? Yes, we are testing our release. We plan to release tomorrow. On Monday. Nice. Yeah, the same with Aragon.
00:05:25.402 - 00:06:11.312, Speaker A: We'll publish a release tomorrow or on Monday. Sweet. Ret is out. So one alpha 18 is the main net release for Dankoon and then Besu get. What was the release number for your clients? Besu is 24 one two. Got it. Released yesterday and guess anyone and okay, I don't have the number quick, but I think guest release came like right after the call last week.
00:06:11.312 - 00:06:58.384, Speaker A: So it's been out for a few days now. Any CL folks have updates on their release? I know that on the call last week teams on the CL side needed a bit more time, but any updates people want to share? Prism is going to release by next Thursday, but just two, heads up. We're still blocked by the CL release because we have this unit test that basically set a mannequin for epoch, but it puts the manned upstream release. So until the CL spec does a release for the manned for Epoch, we are currently blocked. Yeah, just wanted to flag that. Okay. I was a bit afk the past couple of days.
00:06:58.384 - 00:07:22.450, Speaker A: I know we did approvals on the little prs that needed to be done. I'll check in with Xiaoi and we'll get it out by tomorrow morning. Thank you so much. Can you hear me? Sorry. Yeah, we can. Cool. Yeah, Teku is already releasing, so we are in the final stage of releasing.
00:07:22.450 - 00:08:27.600, Speaker A: Nice. Loadstraw is also ready to release, so we are just doing some final things so we most probably can release early next week. Anyone from Limbus or Lighthouse? I think those are the two we didn't hear from yet. Okay. And then yeah, there's a comment in the chat Abo Barnabas saying we should wait until we have all the ELCL pairs for the release. I think that's reasonable. So probably means that we have all the releases out by say like late next week and then maybe we schedule the main net shadow fork for the Monday after that or something so that we can put out the blog post one day after once we're sure everything's all right.
00:08:27.600 - 00:09:22.310, Speaker A: Does that seem reasonable? Having the last magnet shadow fork on say Monday the 26th? If we can have all these by Thursday, then we can do it on Friday. Nodes to run. So we wouldn't necessarily want to wait over weekend. If next week Thursday releases are out and we can do it next week Friday. Yeah, I like that. Okay, so let's aim for Friday the 23rd and then we'll have the blog post out early the week after, assuming there's no issues that we find on the shadow fork. You even try to do the shadow from the 20th.
00:09:22.310 - 00:10:21.410, Speaker A: Okay, sweet, I guess. Anything else on Denkun? Yeah, Carl, yeah, I know there was previously some mention from l two s about not quite being ready or what might be a while after that. We had a local yesterday as lots of discussion around this. It seems like we're at least going to have one of the l two s ready being polygon, but many others are still trying to have some kind of main net release ready very soon after or even on the 13th. Nice. So it's looking nice. Sweet.
00:10:21.410 - 00:11:16.758, Speaker A: Anything else on Denkun? Okay then next up. Yeah, these two retroactive eips 1st 17610. I don't know if Martin is on the call if not, does someone else, he's not here today, unfortunately. Yeah. Can you give the context on this Maris for someone else? I could probably try, but I think someone else might be more equipped to do it. I'll take a stab. Yeah.
00:11:16.758 - 00:11:48.606, Speaker A: So this is looking to amend the contract creation rules. Right now, if a contract is being created in address and it has a non zero notes, it fails. This rule would extend it to say if that address has any storage, it also fails. And there are a few contracts that existed before the Shanghai attacks that have a zero notes but have storage but also have no code. So I think, yeah, the two things need to have no code and the zero notes for it to succeed. So if there's code, it'll fail. If there's a notes of one, it'll fail and they change.
00:11:48.606 - 00:12:14.914, Speaker A: The rules in the Shanghai text require notes of one on all creation attempts. Success or failure. We're going not success or failure, but if they leave code or not. So there are a few addresses prior to Shanghai that have zero notes, no code, and storage because of failed creates. And these are all coming from create one attempts. Now, because it's a create one, it depends on the notes. The notes has been incremented by rule.
00:12:14.914 - 00:13:00.854, Speaker A: It is impossible to recreate the situations to create that already. So this can't be created unless there is a hashing accident of one of those impossibly large hashing numbers where the collisions are basically impossible. To change this rule, we make it so that we don't care if there's a hashing accident or not. If there's any storage or any nodes or any code, the create will fail. Now what's not mentioned in the EIP that we realized on the basic team this week is this have positive impacts for vertical trees, because when you do a create, you're supposed to delete all the storage. And that's why we got rid of self destruct is because enumerating through all of the storage and deleting it is prohibitively expensive. In Verkel, we'd have to either change the rules for create or prohibit creates like this.
00:13:00.854 - 00:13:42.658, Speaker A: So I think we should just retroactively activate this. There's going to be highly unlikely ten or impossible for it to happen on main net. And formalizing this rule will make a lot of client code simpler when it comes to the create process, especially in vertical, if I may add some dissent in the vertical part, it's not that self destructing is impossible, is proactively expensive. It's just impossible. We just don't know which storage slots belong to what? And that was going to be my question, actually. You also can't figure out if a slot belongs to an account. So how do you.
00:13:42.658 - 00:14:16.014, Speaker A: I don't think that will work for vertical. Gary, who proposed the EIP, is aware of that. So all I'm saying is if this EIP makes it, which I'm fine with, it solves a lot of problems on the way to vertical. It will not be able to work in vertical. So what would we have to do when we switch to vertical? Yeah, that's the question. And that's the thing that's missing with the CIP. Cool.
00:14:16.014 - 00:14:37.830, Speaker A: So there's no state route kept in vertical anymore. That field is taken out of the account tuple. Sorry, I didn't hear what you said. There's a state root hash that is kept in the current account tuple. It's taken out of oracle. Yeah. The problem is that you would be potentially able to access older.
00:14:37.830 - 00:15:07.450, Speaker A: I mean, you can no longer delete accounts anyway, so it's not really a problem. But if you were able to recreate accounts, you would potentially have. There's no rehash. So you would automatically access the old storage. Like the storage of the contract that has just been deleted. So there's no way to tell if address has storage. Exactly.
00:15:07.450 - 00:16:09.076, Speaker A: That's one of the reasons why self destruct is deactivated. Yes. Also you can't do a trioc of storage slots, which the dows are really going to love, let me tell you that. So maybe when we do the transfer, the translations, we put a flag that it's had storage in the past. We need to adjust this for vertical. When we do the transition, if we see that it has a root hash that does not signify empty state, we put some sort of a flag on there that says you can't created this address. Why don't we just remove storages? When we transition to the workload, we good opportunity where we transition from one tree to another tree and the hashing is going to be like state change that we are doing in some way.
00:16:09.076 - 00:16:51.620, Speaker A: Because that opens Pandora's box of an irregular state transition, which is a larger discussion. But we already doing that with the virtual transition. We're not deleting any. Yeah, but this storage is not accessible because you don't have code for it. It's not something that can be used, seen or like fetched from the state. It's just that data. Yeah, I think that's a good idea.
00:16:51.620 - 00:17:29.106, Speaker A: I'm not sure I understand. Danos reason not to like that it would be possible for sure. Although I'm just wondering. But we're going to talk about this later if 580 six would not cause a problem with that. Yeah. Just because we have a lot of vips to cover today. I think it's not obvious that we should just go ahead and include this as is.
00:17:29.106 - 00:17:53.930, Speaker A: It seems like there's more conversations to be had on it in the final design. So does it make sense to just continue those conversations over the next couple of weeks and discuss this on the next call? Yes, it does. Peter will be back and be able to answer more. The deeper issues on Peter Martin. Just say I don't have any. Like, I'm fine for this. Happy to be included.
00:17:53.930 - 00:18:21.014, Speaker A: My statements were mostly how to remove it fully with vertization that we have. Well, I think without the vertical issue it would have been easy for us to just go ahead and do it. But because there's vertical implications, I think you need two more weeks to mull over what it means. Okay. Makes sense. Sweet. And the next step.
00:18:21.014 - 00:19:17.130, Speaker A: So Peter David is not here for 7523. But this one seemed pretty uncontentious last time. There's some tests that have been updated. And then he mentioned on the discord. The only thing we should potentially discuss is if we want to do an independent verification of the deletion of the empty accounts he checked. But it would be nice to have somebody's sanity check that there actually are no more of these accounts. Before we sort of finalize this, any thoughts, any volunteers to run another sanity check? Okay.
00:19:17.130 - 00:19:37.620, Speaker A: If there's no comments, I'll follow up offline then with Peter. And we'll try to find somebody else to run another check on the chain and publish those results. And ideally the script that they use and whatnot. And. Yeah. Assuming that's all good, we can finalize that. Okay.
00:19:37.620 - 00:20:12.126, Speaker A: Moving on to Prague. So there were a couple of eips that I added last minute to the agenda. Because we said we would cover them last time and we didn't. So. Yeah, I think it probably makes sense to briefly go over the five or six that we had for discussion today. Then hear from client teams how they're thinking about all of this and see if we can make any decisions about what we want to include. Yeah.
00:20:12.126 - 00:20:51.530, Speaker A: So the first one we had on the list was 5806, which I believe Adrian is here to chat about. Yes. Hello. So thank you for allowing me to discuss it here. I think you have wanted me to present it. The context being that 30 74 is actively being suggested as a candidate in inclusion. Prague and 58 six is a potential alternative, or at least an EIP that would somehow implement the same functionality for a user's point of view.
00:20:51.530 - 00:22:01.022, Speaker A: The point of DCIP is to enable eoas to be more expressive in what they can do, in particular allowing the multiple pattern. It's been discussed at length, so I'm not going to go over why multiple is good to have, but 58 six allows that in a different way than 30 74. So there are big differences between these two eips, and I think 58 six, which is my proposal, has some strength that should be considered. One of them, in my opinion, is the fact that unlike in 30 74, where you sign a hash and you rely on a smart contract to tightly associate that hash with an intention like bugs can happen at the contract level. In 58 six, the transaction that is being signed is very explicit about its entire context. There is no external factors that should tamper with it. I can go into more detail if you want, but I think it's more secure in that regard.
00:22:01.022 - 00:23:15.642, Speaker A: Also about the counseling, since it's a normal transaction done by an EOA, it can be replaced by a dubbin transaction with higher fees and tips so that it's being canceled. So I think the model is better here in the predictability of how it's going to be executed. Then 58 six also has a lot of things that it enables in terms of what a use and UA can do, in the sense that it may allow it to access opcodes like log to emit an event, or create two, to create a smart contract in a very predictable way. The question then is about long lasting changes like storage. For a long time I was an advocate of storage being useful in that context. Like you could store something under your account that would stay there and be provable. I understand that this can create challenges and security issues if an EIP proposed to put code at an UA address, because using this 58 six, you have the ability to put code before creating the contract, and that might hide things.
00:23:15.642 - 00:24:06.310, Speaker A: So I'm completely open to the idea of preventing s store to being executed in the context of an EOA through 58 or six. I'm not exactly sure what I should say. More. Yeah, this is a good overview, definitely. If there are questions, we're going over them now. There's a comment in the chat by light client, but okay, Andrew has his hand up, so let's start with that. Yeah, I think if we disable s store, then this sounds like a good simple improvement, and it will be reasonably simple to implement, and it will bring a nontrivial UX improvement.
00:24:06.310 - 00:24:33.780, Speaker A: During one of our previous calls, we discussed batch transactions. So allow batch transactions. I think we should have it in Prague, but with the s store disabled. So, meaning you disable transaction types, those transaction types to use s store. Exactly. Yes. Okay.
00:24:33.780 - 00:25:33.484, Speaker A: Yeah, I'm having a look at the comment from my client on the chat, and I completely agree with .2 and 358 six doesn't try to do social recovery. And I think that's partly because the signatures, it's like a transaction, it's supposed to be mined straight away. And if you keep assigned transaction for a while and you do other stuff with the same nonsense, it's become invalid. So it's not something you can store for social recovery. Also, it doesn't allow bundling transaction from different users, and basically impersonating multiple eoas in the same transaction. So that's something that 30 74 does, that 58 six doesn't do, because the signature pattern is different, and because signature of 58 six are way shorter lifts, and 30 74, which I believe goes in the sense of security here.
00:25:33.484 - 00:26:43.090, Speaker A: But yes, it's different approaches. Okay, any other comments, questions of Guillaume? Yes, that's in the light of the discussion we had about the retroactive vip. So I understand that you would be very unlikely to call it if your nonsense and balance are zero, but assume you just have the key to an account that does not exist yet. So you generate your private key, the account, the associated account does not exist yet on the chain, and you sign a transaction that sends, that calls a contract, that delegate calls to a contract. My question is, have you thought how it would fail? Because clearly it doesn't have any funds, so it would very quickly go out of gas. I mean, it would immediately go out of gas. But my question is more like what state should be touched in that case.
00:26:43.090 - 00:27:45.736, Speaker A: And yeah, the question is for Verco trees, and how do you make it work in the context of vertical trees and also in the EIP that Gary was working on? I'm not sure I really understand the question. I mean, if the sender has no gas, the type of the transaction here is, in my opinion, irrelevant. Part of the verification of a transaction is that the account has enough funds to pay for the amount of gas required, multiplied by however it costs you for each unit of gas. And if you don't have enough, like type two transaction, and type zero transaction will fail. And this type of transaction will fail the same. It's not about the type of transaction, it's how it fails. But would it be a revert or would it be an out of gas? It would be not thought of that.
00:27:45.736 - 00:28:20.850, Speaker A: I think it would be the same as what happened with older type of transaction. Yeah. Okay. Yeah, no, just asking if you had thought of that. I would have to consider that, but it's probably fine. What I was thinking was that everything that is part of the verification of the transaction, including the signature and the encoding, except for the value part, would be handled similarly. So any revert condition that exists for type two transaction would just be dealt similarly here.
00:28:20.850 - 00:29:10.992, Speaker A: Just maybe because my question wasn't very clear, but if you try to access a contract that should be deleted under those new rules, what should happen and should it be different than what we do? But. Okay, it's just me thinking out loud here. Yeah, I'll come back to it if it turns out to be problematic. Okay. Any more questions, comments on this one? Otherwise we can move on to the next vip. Okay, thank you for having me and feel free to ping me if you have any questions. Sounds great.
00:29:10.992 - 00:29:47.230, Speaker A: And thank you for coming on. Okay, so next one is 7557, which Joav was also asking to discuss. So this is for block level warming. I don't think Joav is on the call, but I don't know if there's no. I am here, but Alex is also here and going to present it. Alex, please. Yeah, hello everybody, can you hear me? Yes.
00:29:47.230 - 00:31:48.320, Speaker A: Great. So I'll try to give a brief overview of what we are proposing here. So in EAP 29 29 and 29 30 theorem edited concept of warm and cold storage and accessing a cold storage was made obviously way more expensive than the cold of the warm one. However, this distinction is only made on a transaction level, and if you look at the terms of the block, the same storage may be accessed by each transaction in a block and it becomes cold access for every transaction, which is not exactly the case because the block builder only needs to look up this data once and can reuse this data. So while we have a concept of access list, which is an information about which slots might be used in a transaction that is available outside of transaction execution, just as part of a transaction payload. So what we are proposing here is after the finalizing the block, when dealing it basically to iterate over the access list and build a table of how to redistribute the cost of accessing the cold storage between the transactions that actually access the same storage or the same addresses, and to issue a refund in a way that is similar to maybe beacon chain withdrawal. Like a system operation, it just injects value to the code after the block, not in the scope of a transaction, mostly because otherwise doing it as a refund is not really feasible because then there is a retroactive effect of the last transaction can has an effect on the first transaction.
00:31:48.320 - 00:32:58.760, Speaker A: So that's a high level view. It's quite simple with base fee because it's just the same across all transactions. It gets a little more tricky with priority fee because each transaction can pay different priority fee. So what we are proposing here is a proportional distribution of the priority fee back according to the marginal contribution of each transaction to the amount that is being refunded. It's similar but not same to Chefley values that are used to define such things. And yeah, that's it. Not especially, but more important in the context of ERC four three seven and maybe like an AP seven five six that we are working on, that will make it native account abstraction where many transactions are very likely to access the same slots within the block.
00:32:58.760 - 00:34:24.260, Speaker A: And also reference to there is a vertical tree eap that is suggesting that accessing contract code will also be priced in. And in this case such an EAP would also be useful because we expect that many transactions will use the same wallet implementation in the same entry point, and it would be beneficial to just share this cost among the transactions instead of like each one paying full unjust price. Jov, would you like to add anything? So basically the idea is to make it first of all to make the pricing fair. To make the pricing fair, because the validator only pays once for reading from the database and then it's already warm. So it makes sense from fair's perspective, but also for any commonly used contract. Account of suction is one example, but there are many examples of contracts that are used many times during the same block. So including them, including the excess list of multiple transactions and sharing the cost, I think makes a lot of sense.
00:34:24.260 - 00:35:15.190, Speaker A: As for concerns that I've seen in the chat about parallelization, this EIP does not affect EVM execution in any way because it's not visible. The change of pricing is not even visible to the individual transaction. Instead, since we calculate it at the end of the block, we calculate and do a refund at the end of the block. Similarly to how consensus layer withdrawals show up in accounts it should not affect. I don't see how it should affect things like EV and parallelization. Thanks Andrew. I haven't looked into this EIP in detail, but on the surface of it it sounds like a bad idea.
00:35:15.190 - 00:36:12.500, Speaker A: We will be spending time a lot on tweaking the gas instead of making fundamental improvements to either UX, EVM or whatnot. And as to batch transactions, we should address it properly with a mechanism to allow batch transactions rather than trying to tweak multiple transactions in the block to work as a batched transaction. I didn't quite understand the part about batch. It's not about batch transaction in this case, but I think one of the motivation that you mentioned is that. Exactly batch transactions. Or maybe I misunderstood. Now, batch transaction, we talked about it about the previous eap, about 58 six.
00:36:12.500 - 00:36:58.610, Speaker A: This was the batching transaction. For this one, we're talking about sharing the cost of cold access to accounts and storage slots across multiple transactions that use them. But essentially those multiple transactions because there is a need for multiple transactions because you cannot batch them. That's what will be one of the use cases. If you could batch them, you don't need this tweak that much if you could batch them. I mean, there are transactions for multiple users. They just happen.
00:36:58.610 - 00:37:38.270, Speaker A: Let's say the most common use case would be proxies. You have many proxies that use the same implementation. So it doesn't make sense that in each transaction, accessing the implementation is called access because it was already loaded once. These are not going to be in a batch because they are unrelated. They just happen to use to be accessing the same contract at some point. Well, okay, maybe that's right. But another thing is that now transaction pricing depends on the other transactions.
00:37:38.270 - 00:38:53.106, Speaker A: It depends even more on the other transaction included into the block. And it complicates guest estimations, it complicates transaction pricing, complicates a lot of calculations, but it doesn't help us to scale the EVM, it doesn't help us to scale the throughput. One question I had is, do you have a feeling for how much gas is wasted here? Assuming we went ahead and did this, what's the amount of transaction fees that you imagine we could distribute back to users? So yeah, we didn't run a simulation to see how much it happens per block, but I did look at some blocks and see some contracts are accessed dozens or sometimes even hundreds of times. Take for example, uniswap. In the Uniswap case, it's probably going to save users a lot of gas. And I agree that during estimation you will not be able to know it. So you're going to overestimate.
00:38:53.106 - 00:39:35.366, Speaker A: You're going to assume that it's called excess. But at the end of the block there's a refund. So I assume that in blocks that have a lot of uniswap trades, there's going to be significant gas saving for users. Yeah, I guess it would be useful to see numbers, because first, there's the breakdown between the base fee and the tip. Second, there's how much overlap is there in the median block versus, say, the max block. And I can imagine you would save more in cases, say, there's some new NFT that drops or some new pool on Uniswap. It's like in the cases where the priority fees surge, you'd probably save more.
00:39:35.366 - 00:40:34.022, Speaker A: But is that if you put this relative to all the transaction fees paid, what percentage or amount does it represent? I think would be useful to know, is this worth the complexity basically, right? Yeah, I think it's a good idea to run some simulations, but also I think that some use cases will become more possible once we do it. So we may actually see patterns, like usage patterns changing a bit, but we can't know that for sure. So for now, we should only measure what we can on the current blocks. And I think that another thing that we need to keep in mind is what happens after vertical. Because in Verco there's going to be an increase in the cost of running contracts. When you load contract, you're going to pay for the code loading per chunk. I know it's not finalized yet.
00:40:34.022 - 00:41:32.410, Speaker A: We don't know exactly how the cost is going to be calculated, but it will become more expensive to load contracts. And then if you can split the cost of loading the contract, it could be significant saving. Got it? Yeah. That might be also an interesting analysis to run, like if it's a smaller part of transaction fees now, but then it grows a ton after vertical. That's really useful to know. Guillaume, you have your hand up then, Lucas. Yeah, speaking of mean, I don't really have any comments on the merit, on the intrinsic merits of this EIP, but what I can say, this is the typical thing I would like to see after vertical, not before, precisely because the gas model is already quite complex as it is, and this is going to make things even more complex.
00:41:32.410 - 00:42:28.222, Speaker A: It might be nice to have, although we have a very specific model where every transaction precisely pays the cost of warming their state up. So that would go against what has been specified and what we're used to, we've been working with for three years now. I don't think we should even consider that for Prague or Osaka, it should really come afterwards. And yeah, it would make Verco way more complicated than it needs to be already. If it makes Verkel more complicated, then again, I didn't think it's going to affect the calculation for vehicle itself. If it does, then it takes second priority. Of course I'm also happy to change my mind, but this is exactly what I said for EOF last time.
00:42:28.222 - 00:43:19.442, Speaker A: I would like to see a demo of this happening on the vertical testnet first. Lucas so first let me ask one question to summarize it up so it works. The transaction execution works as usual, and then at the end you look at the access list and potentially just add some post back to some sender addresses. Is that correct? That how it works? Yes. You can see in the EIP there is a pseudocode of how it is handled, so you can see exactly how we propose to do it. Now, of course we don't know, maybe there could even be a better calculation. But the general idea is that yes, you collect.
00:43:19.442 - 00:44:14.894, Speaker A: First of all, you only split the cost. You don't look at actual EVM execution because that would complicate things. So instead, only transactions that have the slot or the contract in their access list get to share the costs. If a transaction doesn't have it in the access list, it's going to pay full price for warming. And then you split the cost across all of if you had ten transactions accessing the same, having the same slot in their access list, then you split the cost proportionally across these transactions proportional to the priority fee. And this happens at the end of the block only once. And second question, would that complicate things for block builders because they kind of continuously can improve the block? For example, revert one transaction at another right at the end or something like that.
00:44:14.894 - 00:45:32.950, Speaker A: Would that complicate this kind of strategy for block building, or generally block building code, since the calculation only happens at the end of the block, after you're finished with the block, you can keep changing transactions and applying any strategy before you do this calculation. And also in order to keep it fair for the builder, for the block proposer, we also didn't want to create a situation where if you add another transaction, you actually end up making less money because of the split cost. The cost to everyone is actually derived from the cost of the highest priority fee, so the builder is going to get paid according to the highest priority fee. So hopefully it's not going to break the strategy for any block builders. But of course we need some input from block builders for this. Okay, let's do one last comment and then we'll move on. Dankrad.
00:45:32.950 - 00:46:26.300, Speaker A: Yeah, okay. I'm not sure how it works, but it feels like it could actually break stuff if you have to run something at the end of the block to know how much gas exactly was paid and how much fees you get. But I haven't looked at the details. But more generally, I was wondering why not? It seems to be over engineered in terms of trying to refund it to everyone. Why not just do it so that the first transaction does pay the full warming fee and then the other transactions just get it cheaper and get the warmed up slots. Yes, it doesn't seem as fair as a bit of a lottery, but it feels much more predictable and much less complex to implement. And it's still like on average, you pay the same amount.
00:46:26.300 - 00:47:10.962, Speaker A: So first of all, since the refund is not a transaction, it's more like consensus layer withdrawal. There is no execution at the end of the. There's no execution at the end of the block. You just collect the numbers and then you divide it in the end and do the refund. But as for. What was your other comment? Well, I was wondering why? Okay, here's an alternative about fairness. Simply just like considering all the slots that have been used by previous transaction as warmed up, so then it's exactly predictable what happens at the start of each transaction execution.
00:47:10.962 - 00:48:03.234, Speaker A: And you don't have to do anything complicated at the end of the block. It's less fair, but on average it gives you the same result, right? Yeah, it gives the same result. Except that, like you said, it's a lottery. It's a lottery where the first one, it's not a lottery, because in practice, if there's contentious access or in demand access, for some part it's maybe because there's some arbitrage or some profitability. So I think it would be interesting to look at that. But I feel like for a lot of those, you would just see it's like you're taking away from the MEV profits if you're taking it from the first section of the block, which might be fine. Yeah, of course, in these cases, in the cases of when there is MEV contention around some slot, it makes perfect sense that the first one that also pays the highest priority is also going to pay for the warming.
00:48:03.234 - 00:48:45.640, Speaker A: That's fine. But in the case of proxy implementations, for example, let's say in the account obstruction case where you have many users using a wallet with the same implementation, it may be less fair that one user pays for warming for all the other users. So we could do it this way, it does simplify things. It also makes things a bit less predictable for users. Right. And I think that makes a big difference, whether that's like 200% variation, then I see your point. But if it's like, say a 20, 30% extra cost per transaction, then it feels over engineered to me.
00:48:45.640 - 00:49:44.400, Speaker A: Okay, Lucas. So I think this is actually, the current proposition is simpler to implement and simpler to parallelize because it doesn't depend on the full block order. It just, at the end, returns some funds to the transactions based on the access list, if I understood correctly. Yeah, I see that it is actually a complicating parallelization, for example, a lot. And you have to track the access patterns across the whole block in order, which you don't have to with this proposal. So it's actually, in my opinion, easier to implement and easier to parallelize in the future. All right, thanks.
00:49:44.400 - 00:50:25.246, Speaker A: Sweet. Thank you, Joav. Okay, next up, Danny, you had your hand up, but then took it down. Is there still anything on this? Oh, I just was going to mention that the asymmetric strategy, where the first one pays for it, like a builder could pick a user transaction to warm something up and have somebody pay for it and then insert their transactions to use the worm. But again, if we're talking about marginal differences, I don't think that strategy matters too much. But I think the parallelization and asymmetry comment previously is important. Got it.
00:50:25.246 - 00:51:23.520, Speaker A: Thanks. Okay, next. Sorry. One very quick note that if we introduce anything where basically execution of the cost of a transaction depends on a transaction before it, another issue that you might introduce is gas estimation issues. Because all of a sudden, if your gas estimation runs in a certain context, and during a block execution, you change the context, you might end up with basically failed transactions. That couldn't happen if you only do the refund at the end of the block, because you have to assume that you're going to pay the full warming price, and then if you are not alone and others also share the cost at the end of the block, you get something back. But it cannot cause the execution to fail, because during execution, you are not even exposed to this information.
00:51:23.520 - 00:52:07.486, Speaker A: Yeah, I think that was an argument against the asymmetric version that Dunkard proposed. Oh, yeah, I understand. Okay. I'm not necessarily saying it as an argument against either version. Rather, what I'm kind of saying is that this kind of means that during gas estimation. So currently what the gas estimators do is that basically you have this previous state, which is either the latest block or the currently pending block, which, whatever it means for a client, and then people just run estimate gas transactions on top, and that might get wonky. So basically just.
00:52:07.486 - 00:52:43.158, Speaker A: The only thing I'm saying is that gas estimation needs to take care that it's estimating on top of a clean slate and not this partial warm duck thing. Yeah, during estimation. You should not assume anything about this. It's like, maybe you'll get something back, maybe you won't, but you have to assume that you're going to pay full price during estimation. Otherwise stuff is going to break. Yeah, of course. But the point is that the gas estimator is just a dumb thing which takes a transaction, runs it against a pending block or a pending state, and just spits out a gas value.
00:52:43.158 - 00:53:27.160, Speaker A: It doesn't know anything about anything. Currently, the gas estimator is kind of dumb, and such a feature would require the gas estimation to be a tiny bit smarter so as to basically know about this refund mechanism and make sure that it doesn't interfere. Actually, I wouldn't want to know about it. I'm sorry. Yeah, I think there's clearly more discussion to be had on this if we went forward with it, but we do have a bunch of other eips, so I would table this for now, move to the rest. Yeah, sorry to cut you off, but I want to make sure we can cover most of the stuff. Yeah, thanks, Jov, for sharing this.
00:53:27.160 - 00:53:55.520, Speaker A: Next up, we had 29, 35. Sorry, I had a typo in the agenda. So this is the vertical related one. I don't know. Guillaume, do you want to give background on this? Yeah, I even have a tiny presentation. I promise I'll keep it short. Can you guys see my screen? Yes.
00:53:55.520 - 00:54:23.900, Speaker A: Okay, cool. Yeah, so we have this EIP that was initially created by Tomash and Vitalik, which is about storing the historical block hashes into a contract. Or contract storage, more. Exactly. And it's been stagnant for a while. Looks like I can't change. Yeah, it's been stagnant or stalled for a while.
00:54:23.900 - 00:55:19.786, Speaker A: And we discovered while working on the vertical testnet that we actually needed this for stateless clients to execute. And the reason for this is because you would need to somehow pass the historical block hashes, and either you pass it on a side channel, but they definitely need to be part of the proof. And we do have a way to provide, we know how to do proofs. So it looks like the perfect EIP just needs to be updated. So we created this revival pr to like 81 66, which is just meant to update it because it's quite old. It used to be block number based. Now it's a timestamp based.
00:55:19.786 - 00:56:51.030, Speaker A: And there were some fairly complicated things, I mean, things that were not necessarily complicated at the time, but now that forks are timestamp based, it got very complicated. So the gist of the update is really to say, once the EIP is activated, you just take the 256 ancestors and you insert them right off the bat into this contract, which is really simpler than the proposed version until now. I mean, once again, it was meant for a different fork model and you no longer like the other major change is that in the initial description, you had to wait 256 blocks after the fork to be able to use the contract. Now with this new approach, because we insert all the historical block hashes that we need, we don't need to wait, so you can start using them right off the bat, what doesn't change? And this is something that is going to probably create some pushback, but let me explain why it doesn't change. Unlike the beacon hash contract, the 4788 contract, we don't want to use a ring buffer. And in fact, the argument is that we might actually also have to give up on the ring buffer for 4788. We are still gathering information.
00:56:51.030 - 00:57:53.610, Speaker A: But the reason behind this is because, well, okay, first, this whole EIP was created to be able to access historical block hashes. And so that would be really hijacking this EIP if we did not provide that. And the other reason is because hashing in a vertical context is way more expensive and takes way more time than it does in KCAC or kshak context. And so we feel that an attacker could potentially increase the depth of that ring buffer in the tree, and therefore for relatively cheap, make block production slower in the future. So this still needs to be confirmed. We're working on getting data to confirm if this is a problem or not, but until we have not confirmed, this is not a problem. I think not using a rig buffer is actually the best approach because then it will move in the tree and so it will make the attack more expensive.
00:57:53.610 - 00:58:47.658, Speaker A: We also considered putting all of the data during the vertical transition, but we decided so, I mean, all the historical hashes during the vertical transition, but I think it's not really useful unless there's a clear use case for that. And we also didn't want to do any solidity implementation. So it's just at the beginning of the block writing the contract, that's what's specified in the initial version of the EIP. And we want to keep it this way? Yeah. There's a couple of discussion points. What address should we use? Because, for example, we don't want necessarily to use the one that's currently specified in the AIP. EIP one five eight currently deletes every contract that has a zero nonsense and zero balance.
00:58:47.658 - 00:59:17.430, Speaker A: So in our implementation, we had to create an exception. And yes, currently it's deployed the first time it's being accessed. But we could change that if people disagree. Just want to point out that it has actually been tested. It's currently tested. The bar prevents me from showing the other tab. Here we are.
00:59:17.430 - 00:59:47.954, Speaker A: So if you look at Kelstinin. So this is the block explorer for Kelstinen, and you have a stateless tab that tells you what gets touched. And if you look at the first slot, if you're not really familiar with vertical, most of those numbers will not talk to you. But basically, this is the location of the first slot in the contract. The suffix is 64. That's normal. Once again, if you don't know vertical, you don't care about this number.
00:59:47.954 - 01:00:12.954, Speaker A: And what you can see is the new value is some hash. And that happens to be the genesis hash, which is right here. Exactly. Just to point out that it's working and. Yeah. Why would you consider that in Prague? Well, okay. The first argument is that it's easy to do.
01:00:12.954 - 01:00:46.660, Speaker A: It's already implemented, it's being tested, it's necessary for vertical. And because I was explaining the trick of inserting 256 ancestors at the fork block, it's not conceptually very hard, but this is something I would like to avoid doing when the transition starts. So that would be the reason why we would be pushing for this in Prague. And. Yeah, that's pretty much it. Thank you. Danny has his hand up.
01:00:46.660 - 01:01:20.350, Speaker A: Yeah, I definitely support this. I would be curious to hear a bit more about the ring buffer argument. Maybe later, after you do some analysis. But I just want to point out on the consensus layer. We've had the design principle since day zero, that the state transition should be a function of free state and block and no other explicit or hidden inputs. And so I'm a major fan of the execution layer moving in that direction for the statelessness reasons. But I also want to just elevate it as a design principle in general.
01:01:20.350 - 01:02:01.754, Speaker A: And when people are designing eips to think in that mode, because I've seen EIP drafts where they'll assume access to some movie, the parent block or something like that. But anytime that we want to do that kind of thing, we should be writing it in the state to elevate it into this kind of stateless mode. So just a comment and definitely support it. Thanks. Any other questions? Comments? Daniel? Yeah, I'm still wondering how using a ring buffer introduces new attacks scenarios that storing everything in history supports. 4788 works. It's out there.
01:02:01.754 - 01:02:25.666, Speaker A: You can't change the numbers. It's not going to get any larger than storing all of the history. And it has a process that is already established to work. We just change it with a different contract address and a different value we put in. So I'm wondering why that simpler solution is not preferable. So, yeah, right now it's working. That's precisely the thing.
01:02:25.666 - 01:03:10.346, Speaker A: Because the hashing you use is sha three based, and currently you don't see the problem. But as soon as you switch to vertical, like I said, we need to get more data. We're working on it. We'll get them as soon as possible. But if it's confirmed that greatly increasing the tree depths is going to be a potential attack, your ring buffer, and I'm talking about the one in 4788, will be attacked. Now, what do you need to do if you want to change it? You have to define attack. If you manipulate the beacon block roots, then you can change the depth of the ring.
01:03:10.346 - 01:04:04.210, Speaker A: Piper. Yeah, no, you just need to create a contract, because everything ends up in the same tree. All you need to do is to find an account to slot whatever that will hash to the same prefix as the stem or the path to the ring buffer in the tree. And as soon as you get that, you can artificially increase the depth of the string buffer, which means you will need to compute more levels of commitments. And that means it might potentially make things really much longer to compute. And how is this different than targeting a high use contract? Obviously, this is system level, and it's going to be updated every time in hash. But why is that different than something that just has very high usage? Exactly.
01:04:04.210 - 01:04:45.294, Speaker A: It's not very different from any high usage contract. In fact, Peter pointed out that you could do the same thing on a gateway contract, for example. But the system contract is indeed like this system contract is executed on every single block. So you could do this and attack, for example, a competing DaP, and they would have to redeploy and everything Daniel talked about. So that's a pain. But if you start attacking the system contract, you will have to do a new fork to fix it, and that's a bit more involved. So that's why we would like to avoid that.
01:04:45.294 - 01:05:27.054, Speaker A: And as it turns out, if uniswap is attacked like this, does the cost of executing uniswap become more expensive or cost in terms of gas or just cost, so they have no incentive to move it? Similar. Right. It's just in terms that's true. Uniswap itself has no incentive to move it. But people that, client developers that see the time frame getting closer and closer to the limit, the block production time getting closer and closer to the limit will have an incentive to change that. But they have no control over that. They have no control over that.
01:05:27.054 - 01:05:46.926, Speaker A: No. So they have more control over the system level contract probably, than attacking the application layer. Okay. I'm still wrapping my head around it. Thank you. Sure. But what I was getting at is if you get rid of the ring buffer, you will automatically move this target all over the tree.
01:05:46.926 - 01:06:26.426, Speaker A: So it makes it very expensive to attack because you really have 256 blocks to find a collision and then it's only effective for 256 blocks, and then you move to another part of the tree where you have to start over. So it's way more expensive. That's the cost of linear state growth on the system contract, right? Yes, absolutely. Got it. Thank you, Lightline. I mean, I'm just kind of echoing what the Andy said. I don't really see why this is a specific problem for the system contracts.
01:06:26.426 - 01:07:06.106, Speaker A: I think this is also a huge problem if it significantly is affecting block production time for any kind of DAP. I don't think it's reasonable to expect daps to go into some PvP battle where they're expanding state branches around the contract and then forcing others to redeploy. Sure. Especially if the gas cost doesn't escalate. But also some apps just like can't and shouldn't redeploy. Right? Yeah, I'm not saying they should, but they don't even have an incentive to because it's not going to even show up in their gas. We have the deposit contract as.
01:07:06.106 - 01:07:34.386, Speaker A: Yeah, there's plenty of contracts that get used, Andrew. Yeah, well, of course we have to figure out whether to include the ring buffer or not. But in general, I support inclusion of this vip into Prague. It makes sense to do it before local. I. Peter. Yeah.
01:07:34.386 - 01:08:36.354, Speaker A: So just circling slightly back to this attack vector. Basically, my concern was kind of the same, that whether we use a ring buffer here or non ring buffer, I kind of feel that if the attack is viable on the ring buffer, then we will have bigger problems because I can basically target any high profile proxy contract and make it super expensive. And if basically targeting uniswap is. So my point is that if the attack works, then both attacks will be very potent. And if it doesn't work, then it doesn't really matter, then we can just keep the ring buffer. That's why I was kind of suggesting that we should really have a number on how effective or unaffective this attack is. Because I kind of feel it that you cannot make an attack ineffective on Uniswap, but effective on the ring buffer.
01:08:36.354 - 01:09:11.762, Speaker A: So it's going to be both or none. And we should really keep this. I mean, I really like the ring buffer approach in that the step is kind of constant. I really like constant stuff. So changing it to a non ring buffer would really need some motivation. And I think the problem is that the motivation that would prompt the ring buffer to be swapped out would also be a huge problem for the DAP ecosystem in general. I think that issue is a bit deeper than just changing a debate structure here, just to be clear.
01:09:11.762 - 01:10:05.374, Speaker A: I mean, I agree with most of what you said, but we're not changing the ring. Switching from a ring buffer to something else should be completely transparent to daps because they would just ask for their block number and they don't care where it's stored, they just want their block number. So it's really how the storage is laid out that changes. Yeah, of course. But my point is that if the ring buffer needs a change, because otherwise it can be attacked, then so can uniswap proxies contract and any proxy contract. And you cannot really, I mean, with upgradable contracts, you can redeploy the implementation itself, but you still have one proxy which is kind of your entry pointer into the system. And that's the thing that you can attack and you can't deploy that unless you actually change the contract address of Uniswap.
01:10:05.374 - 01:10:34.650, Speaker A: And I mean, that's going to be a huge pain. Nobody's going to do that. So my point really is that if this attack is realistic, then we have to rethink big things. If it's not realistic, then the ring buffer is not relevant. Thanks, Peter. Danny? Yeah, I was going to say very much agreed with Peter. This is either fundamental and affects both or not either.
01:10:34.650 - 01:11:35.322, Speaker A: So I would say if there's a write up, if there's numbers on us being able to wrap our head around this attack in general, system contract aside, it seems like very important to the vertical conversation rather than it more in the abstract. I think Omsgar said potentially doing simulations where we're mining maximally adversarial depths might be important, but it seems we need to elevate it to a fundamental concern rather than like a system contract concern. But I think many of us are saying the same thing. Got it. Thanks. Yeah, I think this is probably a good place to wrap this one up, given we still have a couple more eips to cover, but yeah, thanks, Guillaume, for sharing, and I think it was a useful discussion. Okay, so next up, we have two eips, which we were going to discuss last call and didn't have time for, so Charles is on to discuss them.
01:11:35.322 - 01:12:19.138, Speaker A: First is the pay opcode, and then the second is a transient storage reduction. Yeah. Charles, are you on the call? Yes. Hey, I'm Charles. I work on Viper. I want to advocate for the payoff code, which was considered last time for Cancun, but it was deferred because of complexity. But basically, just to give quick gist of it, it's a way to transfer ether without transferring calling context.
01:12:19.138 - 01:13:30.050, Speaker A: And I think this is just generally important because sending ether shouldn't have to transfer the calling context because the called contract can do whatever it wants. One of these things that it can do is, of course, reentrancy attacks, and it's just a huge foot gun for users in general. And if we have a payoff code, then entire class of smart contract vulnerabilities can be mitigated. I think one issue kind of that's been brought up is that you can do the same thing by creating a contract and then self destructing it. But first of all, it's like kind of a hack. And second of all, we know that the semantics of self destruct are kind of always in flux. So I don't think that users should have to depend on the semantics of self destruct to do a specific thing.
01:13:30.050 - 01:14:20.180, Speaker A: And in fact, people relying on this behavior forces us to kind of make. It forces self destruct to actually be a little bit brittle in that it can't be changed as much. So, yeah, that's the overview and the motivation for it. I can go over my second EIP. Yeah, let's maybe just get the questions or comments on pay, and then we can do the other one just so we can keep them separate. So, yeah. Any thoughts? Comments on 59 20? Yeah, I think it's a simple EIP, and it's a nontrivial improvement to the UX, so we should include it.
01:14:20.180 - 01:15:04.240, Speaker A: Thanks. Any other? There's not. Yeah, I think we'll punt the discussions of what we actually include a bit later and maybe next call based on how it's going so far. But yeah, we can go over the second EIP. Okay, cool. The second EIP is still a draft, which I just threw up recently because I realized that we're discussing Prague already. And basically the core motivation is also kind of branch and structure related.
01:15:04.240 - 01:15:40.952, Speaker A: But basically transient storage, in my opinion, is overpriced. And the reason it was priced the way it was. And it's of course too late to change for Cancun, but the reason it was priced that way is, first of all, it's kind of conceptually the same as warm storage. Sorry, it's not the same. It's conceptually similar to warm storage, but there's important differences. And also there's some discussion of dos. So you don't want people to be able to allocate too much memory on a client.
01:15:40.952 - 01:16:35.010, Speaker A: And I think in EIP 1153 there was some discussion calculation, like how many slots you can allocate. Given that pricing, I think it's fundamentally overpriced because it just doesn't require as much resources as warm storage. And let's see my notes. Yeah, it doesn't interact with refunds, and it doesn't interact with the physical database. You don't need a new allocation every call. You only need an allocation when you touch a contract for the first time. I also did some benchmarking with Revin and it seems to be just compared to other.
01:16:35.010 - 01:17:57.050, Speaker A: Relatively speaking, it should be about ten times cheaper. To address the issue with allocating too many slots, I added this kind of super linear component so that every time you allocate a new transient storage slot, you pay an increasing amount. So if you want to allocate like 100 keys, then you need to pay three gas for the first key, six gas for the second, and so on, until you're paying 300 gas for the final key. And I think for most use cases, this decreases the cost of transient storage for users. Interestingly, it actually decreases the amount, the total amount of transient storage you can use, which I think is good for clients because they have stronger caps on how much memory you can allocate. And I have the calculations and all this stuff and benchmarks in the EIP and the east magician swim. So I think we can open for.
01:17:57.050 - 01:18:51.268, Speaker A: Thanks, Andrew. Well, you know, my position is against the gas schedule unless absolutely necessary, because my mind, we have much bigger fish to fry. We need to somehow tackle the scalability issues, because if we don't, we can have a super precise route and guess schedule cannot be super precise because you have different client implementations. But even if it's more accurate than what we have now, it still doesn't help us much because it doesn't help with total throughput unless. So yeah, we should focus on actually improving the total throughput rather than tweaking the gas schedule all the time. I don't think it's exactly a tweak. I mean, it kind of is like quote unquote micro optimization.
01:18:51.268 - 01:20:14.468, Speaker A: But I think it's a fairly easy to change to implement and it allows compilers and users to implement global reentrancy locks. So reentrancy can be mitigated by default instead of people having to opt into it. Depending on if it's cheap enough, and I think it's 2024, we have the capability to prevent it and make the EVM modern. I think it's easy and fairly inexpensive. Win. Okay, any other questions? Comments on this one? If not Mike, you wanted to talk about inclusion list, right. Can I just quickly add a very short comment? So whilst I kind of also agree that it's a micro optimization and we shouldn't really go very deeply on one end, on the other end, I think if these micro optimizations are simple enough, then if it takes 5 minutes to implement or 10 minutes, okay, I'm being deliberately very extreme here.
01:20:14.468 - 01:21:30.684, Speaker A: Then even if it's a micro optimization, I don't think we should necessarily say no because we have bigger fish to try. I mean sure, if it's a big enough effort then yes, but if it's very trivial then I think it could be a valid consideration. Now the catch on the other side is that basically the suggestion, I mean, making transient storage cheaper altogether, I mean that's super easy to implement. Now making the cost tiered as to how many slots you allocate, I think you enter into this territory where it gets a bit wonky because, okay, you say that the compiler could generate reentrancy locks super cheap. Yeah, but if I call a big enough stack of contracts then already I'm going into this, okay, every subsequent t store or slot gets a bit more expensive and then if I have a deep enough stack of contracts then this thing starts to get expensive and it's kind of harder to reason about. So I don't want to challenge this specific design because I haven't studied it. So please don't take it as a specific attack on this design.
01:21:30.684 - 01:22:37.076, Speaker A: Rather, I think basically if this EIP can keep the modifications needed and the mental model needed simple, then I think it's perfectly fine to include it in some form, but the more complex gas mechanisms it includes, the harder it is to rationalize the optimization. Yeah, and in the EIP I did do the calculation for how much memory you can allocate if you do t store on a single contract versus if you do this wonky nested thing and you try to optimize as an attacker, you try to optimize how much storage you can allocate. Another suggestion, and I'm quite open to feedback on the design, but I just would like to see it in some form be included. Something that decreases the base cost for transit storage. Another suggestion was to just keep the gas price flat and then just introduce a hard limit on how many slots can be allocated. And maybe I'm not a client developer, so maybe for clients that's easier to implement. I don't know.
01:22:37.076 - 01:23:31.100, Speaker A: Again, I'm open to feedback, so I would probably say that introducing a hard cap would be very problematic. It's kind of like with the hard cap on the stack limit that it's just very annoying when solidity tells you that, okay, some stack limit exceeded or something. Ideally you want to avoid these hard limits. So I think raising the price is infinitely more preferable than just throwing or basically aborting execution because you reach some arbitrary limit. Thanks, Peter. Yeah, thanks Charles for presenting the two eips. I'll move us on to inclusion list because I want to make sure we can cover it.
01:23:31.100 - 01:24:14.630, Speaker A: Mike, do you want to give some context and then share the info on the breakout tomorrow? Yeah. Thanks, Tim. And hey, everyone. Yeah, I guess I probably only need like a minute here and all I wanted to call out was two documents, I guess the first being this ieltspec overview. This is kind of taking some of these unconditional design properties that I mentioned two weeks ago and trying to put it into the spec for the consensus execution APIs and the Eels spec. The eel spec. So yeah, I guess the only other thing to mention is the call that Tim brought.
01:24:14.630 - 01:24:56.310, Speaker A: You know, this is scheduled for tomorrow at the same time as the beginning of the all core devs. I think there'll be kind of both consensus teams and some execution layer teams there. So if you're curious and kind of like want to know more, I'll probably start by just running through the spec doc and then happy to kind of take questions and brainstorm and think through what might make sense. So, yeah, I think that's all I'd like to share. Thanks, Tim, for the floor. Thank you. Any questions, comments in advance of the inclusion risk.
01:24:56.310 - 01:25:59.580, Speaker A: Okay, so we can chat about this tomorrow. We only have 5 minutes left and we've discussed a ton of eips today. So I think what might make sense in terms of next steps is to not try and figure out what we include in Prague today, but give teams like the next two weeks to think through this. And then maybe two specific things are one, we had CFI 25 37 last time and we moved all the other eips to included once the Cl devs plus one them. But 25 37 is the only one that didn't require any Cl help. So anybody object moving it to inclusion so that we can clearly have it part of the fork I think it should be in. I think we just need to revisit gas costing on it.
01:25:59.580 - 01:27:07.190, Speaker A: But other than that, I think it's a good ad. Okay, last call for objections. Okay. And then the other thing I would propose. So we discussed 5806 today and then 30 74. And I know that in the past we talked about wanting to do something around just like better account ux, but not really being aligned on the strategy. Or if we do a single ep, how does it fit in the broader account abstraction roadmap? So would it make sense to have a sort of account abstraction EOA upgrade management breakout room in the next two weeks before the next acde so that we can discuss that in more depth? Maybe have some wallet devs and some application devs join so that if we do want to do something, whether it's like 30 74 or 580 six or whatever, at least we've sort of gone down that rabbit hole a bit more.
01:27:07.190 - 01:27:57.930, Speaker A: Yeah. Any interest for that? Sometime in the next two weeks. Okay, so there's some plus ones? Yeah. Okay. I'll propose a time after this call because I want to make sure we can at least ping a couple of wallet devs and other folks to see when they can attend. But we should have this before the next acde and ideally probably sometime next week so that there's basically a week between when we have this AA breakout and when we have to make the final decisions. Yeah.
01:27:57.930 - 01:29:07.454, Speaker A: Anything else people would like to discuss before we wrap up? Yes, basically just a very short note. I'm not sure whether Guillaume already mentioned this or not, that he was kind of a bit concerned that what we're kind of targeting for this hard fork, to be very short, so that the next big thing being vertical and maybe something I wanted to voice his concern too, is that we usually suck at estimating when artworks should ship and what we should cram in and not cram in. Because obviously everybody wants to cram in as lot as possible. And basically just to try to keep things on track. Perhaps it would be helpful to try to at least guesstimate when we want the next artwork to ship in point of date. And then based on that, try to cram in as much as possible, but try to enforce that date so that it doesn't really overflow by one more year. Yeah.
01:29:07.454 - 01:29:43.130, Speaker A: And I think people definitely agreed with that. I think the rough sentiment I've gathered is people want something to ship. This means, and we haven't started working on it. So assume that Denkun goes live in a month. It means there's only, like nine months left of the year at that point. So if we want a bit of buffer, it should be something we think we can probably get done in like, six months or less. And then maybe we'll get it done by the end of the year.
01:29:43.130 - 01:30:17.326, Speaker A: So I agree. Yeah. That's something that we should consider when planning the scope for Prague. Yeah. Anything else before we wrap up? Okay, well, thanks, everyone. I'll coordinate the breakouts for the AA stuff on the discord and talk to you all next week. Thanks, Tim.
01:30:17.326 - 02:32:04.850, Speaker A: Hi, Tim. Thank you, Tim. Thank you. Record sa it because it's.

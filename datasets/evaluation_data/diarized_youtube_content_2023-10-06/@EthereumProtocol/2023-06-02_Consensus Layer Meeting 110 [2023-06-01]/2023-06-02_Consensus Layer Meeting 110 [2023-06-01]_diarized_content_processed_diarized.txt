00:04:02.440 - 00:04:24.580, Speaker A: Hello. Welcome to consensus layer. Call ACDC 110. This is issue seven, nine, six in the pm repo. Here's the link. Looks relatively light, but we shall see. Got a couple of Danab things.
00:04:24.580 - 00:04:45.228, Speaker A: Research spec thing. Actually, something's not on the agenda. Doncrad has some big data tests that we're going to go over as well. Okay, cool. So there are a couple of pending Deneb changes that came out of the 4844 call on Monday. And this has parallels to the execution layer. So it's primarily updating the data structure.
00:04:45.228 - 00:05:25.070, Speaker A: So adding data gas use field, the execution payload and changing the excess data gas type from unit 256 to 64. These are both very simple. They're approved and will be merged today. The intention, barring anything unexpected happening probably on this call, is to have a release out tomorrow for the updated test nets. Is the EIP the related prs for the EIP, have those been reviewed and merged or are they still pending? Because that's kind of. We're just waiting on that to push these through.
00:05:26.880 - 00:05:42.516, Speaker B: So adding the data gas used to the header is getting merged momentarily. There's a couple of white space things, but Onstar just approved it and we talked about on the call on Monday. So everybody was okay with it.
00:05:42.698 - 00:05:42.996, Speaker A: Yeah.
00:05:43.018 - 00:05:47.830, Speaker B: That'll be merged before the end of this call. Probably the others.
00:05:48.520 - 00:05:49.270, Speaker A: Yeah.
00:05:49.880 - 00:06:02.120, Speaker B: Changing the size. Yeah, we haven't discussed that at all. That kind of came after the call on Monday. So I would like to just discuss it briefly here before moving that into the eap.
00:06:04.220 - 00:06:27.650, Speaker A: Right. So again, that's the excess data gas going from a unit 256 to unit 64. I think if we look at the execution layer payload, there's most fields that can fit within the 64 bit type. Do utilize the space savings. There's no concern that this would go in excess of 64 bits, right?
00:06:31.080 - 00:06:41.460, Speaker B: Yeah, in the pr, I had some numbers and I think the biggest it would get is like 28 nine bytes, 30 bytes, sorry, bits.
00:06:43.000 - 00:06:54.260, Speaker A: Got you. And this is bound generally by the supply on main net. If you had some crazy amount of supply, you could break that invariant.
00:06:54.920 - 00:07:18.960, Speaker B: I. I would need to see where it breaks, but I don't even know if with 64 bits that allows. I think that would be more than the representable amount of way in a UN 256. In general, I guess that every account has a UN 250 max balance.
00:07:22.120 - 00:07:43.610, Speaker A: Is anybody opposed to this? I think we're pretty fine on the execution, on the consensus layer, not the post. I just have a quick question on the proper ordering. Is data guess used before accessive data guess because the consensus spec PR is different than the EIP here.
00:07:47.740 - 00:07:48.490, Speaker C: Yeah.
00:07:50.220 - 00:07:56.060, Speaker B: In the EIP it's data gas used and then excess data gas.
00:07:57.040 - 00:09:12.660, Speaker A: Okay, so the consensus spec needs to fix that. Yeah, it's not broken if we don't follow that ordering, but we very much might as well follow that ordering. Okay, I can make a note of that's. Okay, cool. Is there enough execution layer representation here that we feel comfortable with changing the bit size on the payload or do we need to have. Okay, is anyone opposed? Because if not, why don't we drop it into discord and get this merged quickly and we can get the release out on the layer? Can someone do a quick blurb on discord to ask if any opposition? It's ceremonial. I don't think there will be any or could be any.
00:09:13.350 - 00:09:14.754, Speaker B: I'll post it.
00:09:14.952 - 00:09:40.446, Speaker A: All right, cool, thank you. Anything else on these couple of minor changes? Great. Alex, do you have an update to 4788 which is still intended to be included? Alex, can you give us that update? Sure.
00:09:40.548 - 00:10:29.710, Speaker D: So there's pr with the change to the EIP, no changes at the consensus layer. So basically from the Cl all you're doing at this point is sending over the root itself, say, in the engine API. We had discussed maybe sending the slot over and using that to change some of the UX from the pre compile that we'll get to in a second. But yeah, that seemed a little clunky and basically we've kind of moved away from that. So now the question is, what can we do without, say, that slot information? So the Cl will send over the route. And the now question is like, how are these routes organized? And the EIP is here, 4788. This PR is seven one seven.
00:10:29.710 - 00:11:25.360, Speaker D: And what this does is basically change this so that we basically have the timestamp and the root inside the evm that's written to this pre compile. So the state of this contract does a pre compile which you can call and. Yeah, really the last question here was how we key these things, how they're organized within the state of this pre compile. And there's a little bit of optionality here. Ultimately, the simplest thing we get from the els perspective is we have the timestamp from the header and then now this root. And that's kind of what the CIP proposes, is just adding the root to the header as well. So you have these two pieces of data and now the question is like, how do you write them to the pre compile? What this PR does that I just posted basically writes the root and then sort of the value to that key is the timestamp, just itself.
00:11:25.360 - 00:11:54.194, Speaker D: And then the question is basically, okay, is this useful to anyone? And basically what this does is say there's now a set of all the valid beacon routes. And if you know it's in the set because you get back an actual timestamp rather than say zero or something. And yeah, generally all of the staking pools and different people in that space I've talked to are okay with this change. Yeah, there's one maybe question around bounding.
00:11:54.242 - 00:11:55.506, Speaker E: The size of these things.
00:11:55.628 - 00:12:23.220, Speaker D: So right now the way it works is you would just, for every block you would write parent beacon route timestamp and just keep going. An earlier version basically bounded this with a ring buffer. So we might want to add that back in. Otherwise it's looking like 80 megabytes of state growth per year, which is not nothing. So yeah. Has anyone had time to look at this PR or think about these changes?
00:12:25.190 - 00:12:41.800, Speaker A: Yeah, I mean, my gut is to not have some unbounded state growth here, especially given like on the since layer we have these double back merkel accumulators and try to keep anything unbound pretty small. I know this is relatively small.
00:12:43.610 - 00:12:54.860, Speaker D: Yeah. So another option is rather than do root to timestamp, do timestamp to root, and then it becomes much easier to handle bounding them in time.
00:12:57.710 - 00:13:03.754, Speaker A: Right. And then the emphasis is on the caller to juggle.
00:13:03.802 - 00:13:12.130, Speaker D: Like, okay, if I'm going to approve something at this slot, then I need to figure out which timestamp that was. But that's not a huge ask.
00:13:12.280 - 00:13:36.280, Speaker A: And the people constructing transactions have access to APIs. Yeah, I guess the other thing, you could have some weird like map where you have time a and time b, and you always alternate between which one you're writing to. Or I guess you don't want to clear out memory like that. Never mind.
00:13:37.690 - 00:13:52.160, Speaker D: Yeah, I mean, there's like different more complicated constructions you can think of, but it's simpler to say, for example, you could say, okay, if we want this many seconds worth of data, then basically just take the timestamp, mod that and.
00:14:01.410 - 00:14:25.720, Speaker A: Yeah, I know we keep kicking this one back and forth a bit. I would imagine the execution layer. People have a bit more opinion here. I'm definitely of the, it seems like kind of just lazy is not the right word. But if we can avoid having unbounded growth with a simple change, I would lean towards that.
00:14:28.570 - 00:14:29.270, Speaker D: Yeah.
00:14:29.420 - 00:14:30.120, Speaker A: Okay.
00:14:31.470 - 00:14:46.400, Speaker D: I tend to agree. There's no reason just to have this extra thing for fun in terms of state growth. So I'll make a pass on trying to do that and have it ready for the next all core devs next week.
00:14:55.380 - 00:14:55.984, Speaker A: Right.
00:14:56.102 - 00:14:58.690, Speaker D: In the meantime, if you're listening, take a look.
00:14:59.640 - 00:15:42.470, Speaker A: Are there any other comments or questions for Alec? Great. And then Mikhail and I were discussing some stuff that comes out of 6988, which is that proposal shuffling mod that proposers can't be slashed, and it looks like it might break kind of at least a property that we have today. Mikael, can you give us the update on that one?
00:15:43.800 - 00:16:46.010, Speaker C: Yeah, sure. So there is the 69 eightyp, which makes the slash provider not eligible to become a proposer. And if slashing happens like within an epoch, it may change the proposal set for this epoch. But currently we have this invariant that the proposal shuffling remains unchanged throughout the so these fix may break any cache in the beacon node or in the validator client that we have that the clients may use on the proposal shuffling for the current tipbook or for the current tipbook, and also it can break some tooling. So that's question that I think it's very important to discuss before we decide to have this change.
00:16:53.460 - 00:16:58.000, Speaker F: I'll just say right there that computing and you shuffling is very expensive.
00:17:01.140 - 00:17:09.870, Speaker A: Even on the. Sorry about that, Mikhail.
00:17:10.610 - 00:17:57.870, Speaker C: I was just going to say that it's not like probably in this case you don't have to compute to recompute shuffling. It's just about if a proposer that you have in this cache, one of the proposals becomes slashed. So you have to swap this proposer for a particular slot with a new one. Yeah, probably. It's also computationally intensive. What worries me more is that there is a cache on, for instance, while they're a client side, and whether client will have to do some additional requests every time or otherwise will have to track slashings, which sounds like quite an overhead for every client.
00:18:00.370 - 00:18:59.970, Speaker A: It definitely brings more complexity. For presum you break our current safety in terms of using proposal cache, I mean, it's not doable. I mean, we can definitely fix that. I think that's our sense. Yeah, I mean, my perspective, it's definitely realizing this like a higher complexity change than we expected a few weeks ago when we greenlit this one. So I guess where I'm at is, do we have the confidence to move forward on this, or do we want to put this on the back burner to do a deeper analysis and slots than some other time? I guess it's not really analysis of the spec. We understand the spec, it's just how much complexity it brings into clients.
00:19:03.130 - 00:19:14.490, Speaker F: I mean, the validator client, it has to assume that the proposal shuffling can change anytime anyway, because of reorgs.
00:19:15.070 - 00:19:29.960, Speaker A: So I don't know if that's a big deal. Right. So it's constantly reassessing.
00:19:34.720 - 00:19:44.050, Speaker C: Yeah. A question to Terrence. So there is some cache that you use for that is attached to a fork, right?
00:19:45.780 - 00:19:48.290, Speaker A: Yeah. Okay.
00:19:58.870 - 00:20:07.060, Speaker C: Because I assume that probably whether a client can have this type of cache, I don't know.
00:20:10.710 - 00:21:19.872, Speaker A: Anyway, Kitan brings up another interesting point. You can still propose, just not on the parent or the ancestor that had slashed you, which in the normal case, you then would be reorg. But it does bring out, bring in kind of like a weird side dynamic here. So, zooming out, there are 4788, there's 6988, there's 70, 45, and there's this fixed voluntary exit domain, which might have an EIP as well, that we intend to build down into the Danev spec over the next couple of weeks to introduce these, what are relatively small features in relation to four. Eight. Eight into the spec. So given that timeline, I guess we could focus on building the other three into the spec.
00:21:19.872 - 00:22:11.590, Speaker A: I meant 4488. I said it out loud, and Marius and I realized it was totally wrong. But we could focus on building these other three into the spec to keep the discussion open for 6988, because this just came to light in the past 24 hours and readdress it in a call in plus two weeks. So likely before that call, we'd have these other features built in for a release and then can make the final call in 6988. At that point, does anybody pose that gives a little bit of time to talk about this one and think about the engineering implications? Okay, I see one thumbs up and hear no opposition. Okay. And that was a point I wanted to make as well.
00:22:11.590 - 00:22:46.710, Speaker A: I meant to make an issue before this call, tracking the features that we tend to build into Daneb from here. I did not, but I believe that list of four is correct. Did I miss anything? Four. 7886-988-7045 DAP lion voluntary exit domain, which maybe has a number or not. I'm not certain. I'll make a tracking issue for that. And note in there that the intention is to build those down into the NEB spec over the next couple of weeks, and we will bring up 6988 in plus two weeks.
00:22:46.710 - 00:23:50.324, Speaker A: Please take a look at this. This is moderate wrench in the intention here, or what we thought was simple here. So let's have that conversation and surface this back in two weeks. Any closing comments on 6988? Great. Next up is doncred, which you're very welcome to share your screen, if that's helpful. Doncred ran some big data experiments and has some stuff to show us. Hello, can you hear me? Yes, it.
00:23:50.442 - 00:23:51.270, Speaker F: All right.
00:23:51.720 - 00:24:18.902, Speaker A: Can you see my screen as well? Yeah, that's pretty small, but I imagine maybe you can zoom in. It seems like the aspect ratio is kind of crazy. That's better. Yeah. Any additional amount of Zoom would be useful, but this is beginning to be readable. I don't know what you're on.
00:24:19.056 - 00:24:21.230, Speaker C: Zoom in the browser?
00:24:21.970 - 00:24:30.160, Speaker A: Yeah, like command. That's looking good. Good. Great.
00:24:31.910 - 00:24:42.020, Speaker E: So, over the weekend, I did some tests on Mainnet. Basically, I wanted to figure out.
00:24:43.910 - 00:24:44.226, Speaker A: If.
00:24:44.248 - 00:24:55.910, Speaker E: We could support those blocks and how many we could do on each block. I'm going to share these as well, so that you can all have a look at it. So, basically.
00:24:56.060 - 00:25:06.060, Speaker A: Hey, Donkra, your mic sounds not great. Are you going through your headphones? Yes, I hope so. Wait.
00:25:27.470 - 00:25:28.620, Speaker E: Is this better?
00:25:30.110 - 00:25:33.102, Speaker A: Quieter, but clearer? Yes, that's good.
00:25:33.236 - 00:25:34.750, Speaker E: Hello, is this better?
00:25:34.900 - 00:25:35.662, Speaker A: Yes. Great.
00:25:35.716 - 00:26:27.070, Speaker E: Okay, great. Okay, so, over the weekend, I did some tests where I basically created large blocks on mainnet in order to see how much data we could support. I shared the dashboards that Sam created for this, just in the chat, so that you can all have a look at it as well. So basically we created blocks. Well, I mean, this is not the actual size of those blocks, but that's how much, basically extra data I try to integrate into each block. I started at 128 kb, went to turn 56. 512, 768, and 1 corresponds to between one and eight blobs per block in terms of amounts of data we added.
00:26:27.070 - 00:27:34.770, Speaker E: And what we saw was that for pretty much the whole range, the network itself was stable. There weren't any crazy things happening, although I will come to that. On the second test, at 1 mb, we did see one reorg, due to the late block reorg that some clients have implemented. So, one, to start with here, is like a dashboard that Sam has created that shows how the bandwidth was on different clients. And, yeah, you can clearly see that on those blob tests, the bandwidth consumed went up quite a lot, and I won't go through all. So, basically, up to 512, even 768, you'll see everything looked very normal and stable. So this is the first 768 kilobyte tests.
00:27:34.770 - 00:28:42.758, Speaker E: The red markers, they are the annotations for when the blocks were sent, the big blocks. And these are block arrival times at different centuries on mainnet and on this first test, actually, for most of them, it's like even well within the ratio when those blocks arrive, you can see that even under normal network conditions, you get blocks arriving up to 3 seconds past the slot time. And that's also what we saw during the test. So that looks pretty good. And most of this is just completely normal. We can see almost a very small decrease in the attestation scene distance. And there's one decrease in attestation agreement here on the first of those blocks.
00:28:42.774 - 00:28:44.700, Speaker A: And that's head agreement, correct?
00:28:45.390 - 00:29:23.110, Speaker E: Yes, I think so. Although, yes, in this case it is, but that's unfortunately not what this dashboard always shows. Like, when nobody agrees to the head, then the zero apparently indicates the block before. Yeah, so that is the first 768 kilobyte tests. Second one is here. On this one, I think it looks like a bit more like there was a little bit, like maybe the blocks were a bit larger. I haven't looked at exactly detail, but, yeah, you see a little bit more of spiking, but it's still within the range.
00:29:23.110 - 00:30:15.222, Speaker E: And, yeah, and we also see a little bit more people missing the head on some of these. Overall, I would say, like, 768 KB looks very stable to me. Like, there's nothing I would be worried about in these metrics. So I think we can relatively safely go to up to six blobs per block. And then I also ran tests at megabyte, which would correspond to eight blobs. This is the first test, which, again, looks fairly okay in terms of block propagation, while we're sometimes spiking to 3.5 seconds here.
00:30:15.222 - 00:30:29.340, Speaker E: But when you look at the other dashboards, that's even, again, something that you sometimes see for not even very big blocks, but definitely some spikes in block propagation here.
00:30:30.670 - 00:30:37.360, Speaker A: And, yeah, you see, I think you're on the 756.
00:30:37.970 - 00:30:40.030, Speaker E: No, this is 1 mb.
00:30:41.170 - 00:30:41.920, Speaker A: Wait.
00:30:43.010 - 00:30:44.062, Speaker E: Yes, this is.
00:30:44.116 - 00:30:45.220, Speaker A: Okay, got it.
00:30:46.870 - 00:31:22.406, Speaker E: This is the first test. And, yeah, you see a little bit more people not voting for the head here on some of these blocks. And then on the second test, we saw for the first time, something's going wrong. So, like, can actually see it here so very nicely. Like, one of the blocks actually arrived more than 4 seconds into the slot time. And so what actually happened is that it was orphaned. And that's like we checked.
00:31:22.406 - 00:31:30.714, Speaker E: The next proposal was prison. So I assumed that what happened was that they decided it didn't have enough attestations and intentionally built on the previous block.
00:31:30.842 - 00:31:34.302, Speaker A: And it was something like they had 8% or correct head.
00:31:34.356 - 00:31:37.140, Speaker E: Right. I do not know that number.
00:31:38.070 - 00:31:41.602, Speaker A: I thought it was in that chat under discussion. I'd have to look it up.
00:31:41.736 - 00:32:01.226, Speaker E: Okay. I don't remember that. Okay, maybe so. Yeah, it looks like this is what happened. I would say the network was still stable, but we just didn't manage to get it before that deadline. But nothing crazy happened due to that.
00:32:01.328 - 00:32:08.540, Speaker A: Yeah, pop said you can also 92% attested to the parent of that block and 8% attested to that.
00:32:09.150 - 00:32:09.610, Speaker E: Okay.
00:32:09.680 - 00:32:14.110, Speaker A: It shows you something about the kind of delivery boundary.
00:32:14.930 - 00:32:15.680, Speaker C: Yeah.
00:32:18.530 - 00:32:40.614, Speaker E: Actually, if someone is able to get. I haven't got. This is the slot for that. This is the often block. If someone is able to get the block for the slot and could tell me how big it actually was, because, unfortunately, I don't have that number. I suspect that we created a block that, like, some of the later blocks, were actually much bigger. They were even up to 1.7
00:32:40.614 - 00:32:52.380, Speaker E: megabytes, and those made it in. So I suspect that this block as well might have been larger than we were intending because, yeah, we can't perfectly control how big the blocks are going to be that way.
00:32:55.470 - 00:33:08.160, Speaker A: So given the note stock, especially the first one, does that give other people that want to dig into this data enough note about which slots these tests are happening on?
00:33:09.090 - 00:33:15.490, Speaker E: Yes. Here in the second, in the stock here, it has all the block and slot ranges.
00:33:15.990 - 00:33:24.306, Speaker A: Cool. So I guess some of the potential orphan blocks become harder to do historical analysis on. But if somebody.
00:33:24.408 - 00:33:38.120, Speaker E: Only a single block that was orphaned, there was another. Actually, in the second range, there's another missing block. But that validator was just offline, so that wasn't us. It was already offline before that.
00:33:38.730 - 00:34:05.140, Speaker A: So I do think it would be valuable for if somebody wants to or multiple people want to do more data analysis on this rather than just looking at these dashboards, like, better understand kind of the variance. Better understand. I guess some of this is going to be hard to do if you don't have sentry nodes that we're already looking at this. I guess primarily we just have chain data nonetheless. Cool.
00:34:07.110 - 00:35:17.910, Speaker E: Yeah. I would say basically based on this, that since this is actually quite pessimistic, like, we are actually creating those huge blocks, but we decided a while ago that we're going to separate block and block propagation. And also we should consider that we were actually going through the mem pool with 64 kilobyte transactions, so that added additional load. That's not going to exist with the blobs, which have used the more, like, the less bandwidth intense mempool where people do a pull rather than push. So given that, I think going to a limit of six blocks and a target of three blocks, blobs would actually still be safe. So that would be my recommendation based on these. And the second thing that I would maybe want to think or recommend we start thinking about is whether the four second deadline for blocks is still appropriate.
00:35:17.910 - 00:36:07.970, Speaker E: Because what we have done is that now we're adding more and more things that need to happen in this first third of the slot. Like we had this four second deadline originally already when we launched the beacon chain. And back then, the only thing that needed to happen is the beacon block itself. And we also didn't have for a second deadline because we didn't reorglate blocks. And since then we have added the execution block, which now needs to be propagated and verified. We're going to add the blobs and we have now added those kind of block slots. Poor man's block choice kind of through this reorg if it doesn't have enough attestations.
00:36:07.970 - 00:36:53.480, Speaker E: So I think we are much, much harsher on what needs to happen in this first third. And I would think it might maybe be a good idea to think if we want to move the deadlines around a bit in the slot at least it would be interesting to see what we know about when attestations happen, when aggregations happen. And maybe it makes more sense to prolong this first phase where we wait for the block and have a little bit less time for the second and third phase, because that would give us a lot more. Yeah, first, it would make the chain probably more stable. And second, it would also make it much easier to increase the number of blobs a little bit at least.
00:36:59.010 - 00:37:50.670, Speaker F: This is really nice. Two points. If we're moving back times, which I'm generally positive about, what happens today, is that there is like a big bandwidth spike around the time when attestations are published, and then the aggregation publishing is actually not that bad anymore because we remove duplicates much better. That would be interesting to see, like look at when the bandwidth spikes happen. And also in clients implement this rule that we're allowed to test as soon as we've seen the block. This kind of evens out the bandwidth profile of attestations, but I think not all clients implement it. In fact, maybe only nimbus.
00:37:52.390 - 00:37:57.490, Speaker A: Sorry, what was the second thing you said? Maybe Nimbus is only implementing.
00:37:59.830 - 00:38:09.334, Speaker F: So the rule for when you're supposed to publish the attestation is currently when you've seen the block or when 4.
00:38:09.372 - 00:38:14.040, Speaker A: Seconds have happened, which kind of causes potential weird race conditions, right.
00:38:14.410 - 00:39:11.706, Speaker F: Well, it causes a big burst at the four second mark if you don't implement the first rule, because everybody then at the four second mark sends an attestation like literally the whole. Well, it's a second of the validator set, which is quite a lot of validators today, and they all just spam the network at the exact same moment. So that's bad. So if clients were to implement send data station when you see the block or a little bit after that would even out that flow. The second good news is that thanks to the split, we've also opened the pr on the lippy to PSPEC, which introduces a new message that's called I don't want instead of I want. And it's basically great. Enrico, thank you.
00:39:11.706 - 00:39:15.450, Speaker F: Teco also does this even sending.
00:39:17.550 - 00:39:17.914, Speaker A: It.
00:39:17.952 - 00:39:50.360, Speaker F: Basically says that I don't want my neighbors to send me a particular piece of data because I already have it. So this is really good for big blocks and big blobs. So if anybody's interested in that kind of network optimizations, check out the lib p to p spec repo where there is a Pr app about this which I forgot the number of, but I'll post it later in the consensus dev rnd channel.
00:39:52.810 - 00:40:16.160, Speaker A: Yeah, I'm definitely eager to see some of those types of optimizations make it through. I think they certainly complement the type of data analysis we're currently doing. Was there not a race condition problem with the releasing the attestation right when you got the block? Is that why there's some sort of like short time delay after.
00:40:18.770 - 00:40:41.880, Speaker F: There is? If you send the attestation to a client that hasn't yet processed the block, it might ignore that attestation unless it has a queue which queues unknown attestations for the current slot. Yeah, that race is solvable, let's put it this way.
00:40:50.200 - 00:42:01.470, Speaker A: So Donker does have a concrete recommendation, which is to change this from two four to three six. Is that in the cards? Is this data convincing? Is there more analysis or additional longer experiments that should be done? Temperature gauge on that? We have some time to tune this value, if there is an intention to tune the value, but we need to begin to have that conversation now. It is nice. I think one of my goals in this experiment was to see that two four was safe. And I believe that we have that data now, which is good. But there's also then the question of and what else Donkrad for the data that's behind those dashboards which came from this entries that the DevOps team is running. Is there a raw version of that or an API version of that that people could do more analysis other than just look at the dashboards or are we pretty much have the dashboards and that's what we got?
00:42:02.000 - 00:42:07.410, Speaker E: I don't know. I haven't looked at the raw data, but I'm sure they can provide that.
00:42:09.620 - 00:42:32.966, Speaker A: Okay, I can ask them. Cool. This is awesome. I really appreciate you taking the chance.
00:42:32.988 - 00:42:58.320, Speaker E: I would like to also, because I see a lot of messages in the chat being very, oh, we should start slowly and not. I have a lot of people asking me when blobs are finally coming and there are like several teams which are building products at the moment really needing this. I think people underestimate how much this is going to be used and how big this is going to be.
00:43:01.490 - 00:43:03.790, Speaker F: That's an argument to start slow.
00:43:04.770 - 00:43:05.614, Speaker E: Why?
00:43:05.812 - 00:43:16.738, Speaker F: For the simple reason that the data, like this experiment, it shows behavior under unsustained load. Right. And it's already.
00:43:16.824 - 00:43:22.550, Speaker E: It is sustained bit of effects. It's sustained ten blocks in a row.
00:43:23.690 - 00:43:27.542, Speaker F: Okay. Ten slots actually a lot better than I thought.
00:43:27.676 - 00:43:28.422, Speaker E: Oh, yeah.
00:43:28.556 - 00:44:44.690, Speaker A: Nice. Consider trying to do a longer one, although it just becomes very expensive. If there's value in attempting to do more repeated experiments or longer experiments, we can attempt to do so. Okay. I do believe there's also kind of a side conversation going on on the ever pending honest block reorgs specification, and if there should be additional changes about the percentage of attestation scene and potentially stronger circuit breaking mechanisms. So that in the event that every block is taking more than 4 seconds, for whatever reason, you get more than 50% of the blocks. Hotels on the call? No, I believe on prism there's some sort of justification circuit breaker that was said in the chat.
00:44:44.690 - 00:45:07.680, Speaker A: Does that mean like if there's not sufficient blocks to justify, they would actually circuit break and stop doing the reworks. So there is a circuit breaker. So there is a circuit breaker. So there's actually a bunch of circuit breaker that's defined in the spec. Right. So we look at whether the parent block is missed and we don't reorg the first slot of the epoch. And we also look at the participation as well.
00:45:07.680 - 00:45:24.360, Speaker A: Got you. Okay, well, let's continue that conversation. And yes, a longer test on sky would cost multiple hundreds of thousands of dollars.
00:45:28.810 - 00:45:53.326, Speaker E: That's not necessarily that much. We could do a longer test. I wonder what would we get out of this? What would happen? I mean, ten slots is already a lot. Realistically, most things that could happen due to sustained load should happen after three slots already, right? Like what would we learn from a 2030 or 40 slot tests? Someone can yeah, I guess completely a.
00:45:53.348 - 00:46:10.546, Speaker A: Full epoch and then through an epoch transition might that's the only kind of milestone thing that's happening is like, does sustained full epoch into that epoch transition do something other than okay, but the.
00:46:10.568 - 00:46:19.240, Speaker E: Load doesn't make the epoch transition more difficult. I can see having it in an epoch transition would be interesting, but I still don't see why the full epoch would change anything.
00:46:23.310 - 00:46:51.960, Speaker A: Yeah, I guess my intuition is that it likely would not, but that there might be small things that compound, like for example, if you're having trouble processing everything due to delays and your queues are getting more full random stuff like that. But I agree that the actual network component side of it should be if you're in more than three slots, that's the same load. You're probably seeing a lot of what you expect to see.
00:46:52.330 - 00:46:56.678, Speaker E: And we can check we might have already hit an epoch boundary. I mean, it's pretty likely since we.
00:46:56.684 - 00:46:59.240, Speaker C: Have quite a few tests, right?
00:47:12.750 - 00:48:12.190, Speaker A: Okay, do we have any other questions for docred or the data as it currently stands? We can see to the extent the data can be opened up for more analysis. Okay, let's continue the conversation in the consensus chat or awkward chat and discord. Thank you very much tanko. Okay, anything else on Deneb for today? Great, thank you. There is an engine API versioning RFC from Mikael Mikael.
00:48:13.910 - 00:49:36.490, Speaker C: Thanks. So there is an intention to start starting from Dan Kuhn to allow for every engine API method only one version of a structure that it can accept, because having multiple structures accepted by the same method brings an ever growing checks and complexity to yale side. And we were discussing this in more details for a call this week. But the question is basically some of CL clients already used relies on this feature that the most recent version of each method in engine API supports all the previous data structures, so they can use the same method, for instance for sending a payload for Paris, for Shanghai, and for Cancun. And the question is how hard it would be to break this reliance and to get back to one to one relation on Cl site between the method version and data structure version. So that's basically the main question for that discussion.
00:49:44.080 - 00:50:16.520, Speaker G: I think the main reason that we had them decoupled was so that we could decouple or so we could deprecate old methods as well as update to newer methods outside of forks. I could see how we could still deprecate old methods if we linked up the versions, but decoupling them from forks, I think, would be difficult if we enforce a one to one mapping.
00:50:20.130 - 00:50:45.926, Speaker C: So you mean that if any change happens between the forks, it will be difficult to switch to a new method version, right? Yeah, the same forex support has two method versions. Like one is v three for instance, the other one is v four. And when v four is available, it will be difficult to switch to v four. Is that what you mean?
00:50:46.108 - 00:50:46.840, Speaker F: Yeah.
00:50:50.980 - 00:51:23.470, Speaker C: See, you're talking about when the same method has the same actual data. So you cannot switch based on the data yet you're passing, but just using the latest available method, whatever version is it is, and no matter the data you're passing. So if it is data driven, you cannot switch easily to the next version of it if the data is the same. That's the problem.
00:51:24.320 - 00:52:01.770, Speaker G: Well, we'll take the adding in of the value of the payload as an example. That was a change we wanted. So if we wanted something like that to change it, we would, I guess, presumably have a new method, but yeah. The proposal is to have a one to one mapping, like execution payload v two, new payload v two, execution payload v three. New payload v three. That's the proposal. Whereas right now we can have.
00:52:04.300 - 00:52:04.664, Speaker A: Any.
00:52:04.702 - 00:52:11.020, Speaker G: Of the underlying data types go with the versions. Basically the versions have supported all previous data types.
00:52:14.200 - 00:53:11.432, Speaker C: Yeah. In order to make this kind of switch, you will have to request the available capabilities and then see that some new capabilities available and start using it with the old data structure. I mean like with the data structure of the previous version. And this is basically what you would probably do anyway, because if a new capabilities added between the forks, it means that some new data has been surfaced to Cl or some new data are requested from Cl. So you'll have to anyway handle this somehow. It's not just you're switching to v four and sending basically the same data. That's actually how I see it, yeah.
00:53:11.566 - 00:53:36.160, Speaker G: Presumably you could create a version like a new method for the interim before the next fork, but then we would have to add a new method. Like if we have new behavior, we can't just use it right away with the method that we will use in the next fork. We would have to have a method for the interim.
00:53:36.820 - 00:54:08.400, Speaker C: Yeah, and probably will. Yeah. So I mean, like, it, this does not, I mean, like having a method handling all previous data structure types. Data types doesn't seem to help much here. That's just my intuition.
00:54:09.860 - 00:54:14.768, Speaker G: What if we didn't make this kind.
00:54:14.774 - 00:54:16.080, Speaker D: Of a hard rule.
00:54:20.180 - 00:54:36.490, Speaker G: In the case where we still, where we wanted to do something between forks, we could support two different types, but in cases where we only need to do it at the fork, then we can keep this one to one mapping, just kind of a hybrid. I don't know if that makes it too complex, but.
00:54:38.300 - 00:55:26.478, Speaker C: I would say that we have a precedent that we're really eager to introduce something in between the forks, and that would be the case that we will really need these two versions supported in it. I'd say that let's discuss it by that time, but by default use one to one. I mean like not making any commitments for the future, but if it will be reasonable to do this way, probably why not? And the question for Lighthouse, do you think it will be really difficult to get back to this one to one thing?
00:55:26.644 - 00:55:27.360, Speaker G: No.
00:55:28.610 - 00:55:29.760, Speaker C: Okay, cool.
00:55:32.290 - 00:55:43.250, Speaker G: Yeah, it's just mostly not losing the ability to deprecate old methods and not losing the ability to upgrade independent of forks, which is the point of exchange capabilities.
00:55:44.950 - 00:56:35.220, Speaker C: I see. And yeah, about deprecation of fault methods, I was thinking about it. So we can currently deprecate v one or v two and say that we three handles all of those data types, but basically we're just deprecating methods. But this last method version has all the complexity that those method has. So in one to one there will be just this complexity. Yeah, this logic of validation of data types will be just lay across different methods, while with this approach they currently have just in one method. So I don't see big advantage of having those deprecated while you have all this stuff checked anyway.
00:56:35.220 - 00:57:39.760, Speaker C: And deprecating the data structures is really difficult thing because we want to allow for lock step sync since bilaterix, since Paris. So that would be another question. Does any other ECL clients than techwind? Lighthouse relies on this feature that Cl can pass whatever data structure to new payload, for instance to the most recent version of. So I think that I can make a pr if we are agreed on that. So I can make a pr to make the blob extension file specification just with one version.
00:57:43.220 - 00:57:53.270, Speaker G: An additional complication here comes in how we actually switch over, because now we're changing the behavior unless we enforce it at NEB fork or something.
00:57:56.040 - 00:58:47.070, Speaker C: Yeah, this should be agreed that since, I don't know, first I guess that this one to one should be implemented in every Cl that is not yet supported and then we can plan it for some Devnet for it for Devnet because you have all those methods, all those previous methods, and you can just start using this logic that you send with one to v one and v two to v two and so forth, and then El can just drop all these things from v three. Yeah. What's proposed is you start to do since V three, but V two will remain unchanged.
00:58:51.360 - 00:58:51.724, Speaker A: Yeah.
00:58:51.762 - 00:59:01.760, Speaker G: So the clients can switch over to this new version and then once we're confident that all the cls have done that, then the els can migrate.
00:59:19.980 - 00:59:34.640, Speaker A: Anything else on this one? Okay, so you do have that open RFC if anyone else has.
00:59:36.930 - 00:59:37.582, Speaker C: Sure.
00:59:37.716 - 00:59:38.110, Speaker A: So.
00:59:38.180 - 00:59:45.410, Speaker C: And I'm going to open APR and can discuss it more if any concerns will arise.
00:59:47.830 - 01:00:31.410, Speaker A: Got it. Thank you, Mikhail. Okay, anything else under discussion today? Great. I will put together we're going to have a release in the next day with these minor changes to the types in the additional field. We'll put together an issue that's tracking the handful of eips that we're going to build into Dnab over the couple of weeks, and we will talk about 6988 in two weeks. Please take a look. This is the change to the proposal with respect to slashing.
01:00:31.410 - 01:00:38.402, Speaker A: Okay, thanks everyone. Take care. Talk to you soon. Thanks, bye. Thanks.
01:00:38.456 - 01:00:40.158, Speaker C: Bye everyone. Bye.
01:00:40.334 - 01:00:40.946, Speaker D: Thank you.
01:00:40.968 - 01:00:41.680, Speaker C: Bye bye everyone.

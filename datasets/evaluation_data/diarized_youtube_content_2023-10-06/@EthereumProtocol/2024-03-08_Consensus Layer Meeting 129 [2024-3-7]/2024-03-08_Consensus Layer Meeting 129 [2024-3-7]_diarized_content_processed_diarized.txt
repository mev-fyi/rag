00:03:09.680 - 00:03:52.850, Speaker A: It. All right. Welcome to all core devs consensus layer. Call one two nine. This is issue nine seven three in the pm repo. First off, we're going to discuss anything related to the Nab cancun dancun, which is happening doing within the week from now. Then a few things up on Electra, a number of things related to looks like APIs and testing, and then a quick discussion of women ethereum protocol.
00:03:52.850 - 00:04:13.186, Speaker A: Let's get started. This is happening on the 13th. That is Wednesday. Today is Thursday. So six days I believe. Morning us. Actually, I had a reminder.
00:04:13.186 - 00:04:42.100, Speaker A: Thank you Tim, for bringing that up. I believe Saturday night, Sunday morning in the US. At least we're doing the daylight saving time thing. Be aware, almost all of these types of calls, the ACD and the breakouts are usually denominated in UTC, which does not change. So it's 07:00 a.m. For me right now. The next version of this call next week will be at 08:00 a.m.
00:04:42.100 - 00:05:39.050, Speaker A: For me. The rest of the world changes at slightly different times, so just be aware that we're kind of going through that phase. Okay? Yeah. So may night launch on 13th. We'll have a call the next day. Obviously if anything goes wrong we'll have calls before then, but we can debrief that on the next ECD. Is there anything we need to discuss before them? Anything related to testing, any unexpected releases, any further stable things we've seen on Devnets, anything people want to bring up? I do see Terrence will have a release today, tomorrow, a recommended upgrade related to improvements.
00:05:39.050 - 00:06:18.940, Speaker A: Lighthouse also has a release being cut for Monday I believe, so. Gotcha. Onscar I did see a zoom link in the discord from that, so I didn't drop it, but if it's not there, please somebody add it. Chris yeah hey Chris here from Flashpods. Just wanted to say that our stack is so far stable there have been no changes in the last week or so. Mafboost v one seven was checked last week. Relabel is v 29 one from three weeks ago.
00:06:18.940 - 00:07:05.080, Speaker A: The builder is still an active branch that we are merging this week. I just wanted to note that on our Mainnet relay we are only seeing about 20% of validators using the latest web boost version and about 60 or 70% sticking on the v one six version that is not Ben app compatible. So it probably would be good to give a shout out to proposers who upgrade to the latest webboost version because otherwise things won't work. Got it. At least you wouldn't get access to the external builder network on that one. Yeah, absolutely. And that could be just a function of people not having upgraded yet.
00:07:05.080 - 00:07:15.690, Speaker A: Tim, or anyone aware of some monitoring tools. Do we have any perspective on the amount of nodes that have upgraded?
00:07:17.710 - 00:07:57.702, Speaker B: I checked yesterday for nodes, so the best place for the CL seems to be metrica. I'm pulling up the link, I'll post it in the dashboard. And since I checked on Monday, Monday we were at 26%. It seems we're at 51% now. So lots of last minute folks upgrading and then the best place for El node was ethernets. But you have to update three different filters. So I'll find the number and put it in the chat once I've gone through the filter.
00:07:57.766 - 00:07:58.746, Speaker A: Ether nodes, right?
00:07:58.768 - 00:08:31.138, Speaker B: Not Ethernet, ethernets. Ether nodes is basically deprecated. It has stats about who's supporting the merge. And then the one thing we do not have that I'll give a shout out to is I didn't find a great validator weighted dashboard for updates. So somebody listening to this wants to build this something. Tracking the actual validator nodes rather than only all the nodes on the network. That'd be great.
00:08:31.304 - 00:08:38.374, Speaker A: It's nontrivial to do that. It's not probably impossible. Yeah.
00:08:38.572 - 00:08:43.160, Speaker B: Consider we're starting from nothing, so anything is probably an improvement on that.
00:08:43.850 - 00:08:52.140, Speaker C: I think relays can tell us at least about all validators that are not locally building, which is already quite a bit.
00:08:54.270 - 00:09:23.538, Speaker A: Right. Okay. Those numbers aren't shocking to me. A week out and seeing kind of that movement from 20% to 50%. If you're out there, update your node, assuming that you want to go through this. Yeah. Anything else on Dankun? Just to wrap up from my side at Lashbox, we are going to be on standby, of course, and available and around.
00:09:23.538 - 00:10:07.138, Speaker A: And we are trying to work with all the other relays as well, that they have people on deck and that everything is going smoothly. And if not that there is countermeasures that are deployable quickly. And just to echo the chat, it does look like there's. It seemed like most of the client seems to not all have a recommended update on stability. Nothing critical. And that's only critical. Updates on the EF blog post are going to be added to avoid any sort of confusion.
00:10:07.138 - 00:11:09.760, Speaker A: But obviously keep an eye out on discord and mailing lists and things of your favorite client. Anything else related to the upgrade next week? Cool. Here we go onto Electra EIP 7549 on chain aggregation. This is an iteration on top of something that has been greenlit for Electra to further allow change the data structure to allow for on chain aggregation. I think this is really nice to have. I believe we've touched on this in the call. Mikhail, is this just kind of sanity checking that we do want to do the spec update or what?
00:11:11.170 - 00:12:48.000, Speaker B: Actually, I've shared a document which reasons about the parameters for max attestations and max attestor sessions. And also this document does some complexity analysis and reasons about potential edge cases where this kind of on chain aggregation, which is more tight on chain aggregation than we had before, can have some adverse effects. Where we have like network aggregates with overlap and indices, we could easily include them. We can easily include them now, but it will be more tough to include them after this change. And also there is like one small proposal at the end of this document that I've shared. So I don't know if we want to go over this document or just keep it there for people to read it offline, but Dapline already incorporated the first part of this doc that we have passed through during the last call incorporated into the EIP PR. Yeah, and I think for this pr we should leave it for a few days, just keep it there.
00:12:48.000 - 00:12:52.030, Speaker B: And if there are no opposition merger.
00:12:53.490 - 00:13:00.930, Speaker A: Do you have a concrete recommendation that comes out of your analysis that you'd like to point out just in terms of the parameterization?
00:13:01.510 - 00:13:51.586, Speaker B: Yeah, parameterization is like for max at the stations. With this tide on chain aggregation, we should have eight max attestations, eight attestations at maxim block. It increases the capacity of the block. In terms of how many different views that Valerie is attested to, we can incorporate. So currently we can incorporate two views into a block. Assuming that committees are voting for more or less the same views. This parameter increases the capacity, but it does not increase the block size.
00:13:51.586 - 00:14:54.150, Speaker B: So we can leverage on a tight aggregation. It can save us more space to incorporate more views on chain into one block. And yeah, was a fair comment that we'll have to include more. So on chain aggregate case will potentially include more bits, aggregation bits. It means that if we generate a slashing event out of these quite dense on chain aggregate, the number of validator indices in the tester will increase significantly, increasing the complexity of adester slashing. What we can do is set just max tester slashing to one, the only option we have. And yeah, there is a section in this doc about tester session.
00:14:54.810 - 00:15:15.520, Speaker A: Right. Did you do analysis on whether with one in these types of actual network fault cases that a high enough number could be included before the exit queue is run out because that was kind of the analysis on two in the past.
00:15:16.770 - 00:16:10.400, Speaker B: Yeah, so there is like imperfect aggregation section in the doc. Indeed there are two cases where there are many different folks views, which is kind of like this proposal improves the status quo. The other one is that where we can get many network aggregates with overlapping indices, but they are quite overlapping in two or three bits or whatever, a small number of beats. And yeah, there is a proposal which allows aggregate those overlapped indices. So yeah, a bit of analysis is done on that as well.
00:16:12.450 - 00:16:34.854, Speaker A: Okay great. This is awesome. This is very needed. How about we leave this at this point with your stated recommendation, people can dig into the analysis and we can surface this in the spec. And anyone else to chime in on if they disagree can do.
00:16:34.892 - 00:16:35.480, Speaker D: So.
00:16:36.650 - 00:16:57.646, Speaker B: I have a few comments. Yeah, so I guess I read through it. I am a huge fan of Mikhail's changes and I'm not speaking for my team. I think the team seems to review it, but I can say a few things. So from the state transition side I think it's fairly low risk. Those should be fairly covered by the spat test. So I have high confidence on those.
00:16:57.646 - 00:17:59.890, Speaker B: And on the honest validator side there are two sides of changes, right? So the first of change is the proposal side that you're redesigning your attestation packing algorithm. And given the validator doesn't have a spare test today, this will require more testing and monitoring. And then the second change is on the aggregator side and this is where the document hasn't mentioned much today. And I think we need to add that to the documentation that say today if you have ten aggregators with the same slot before you need to send ten message, and then with this change you only need to send one message. And because of this you probably need some beacon API changes and such that today I think beacon node has this kind of like the dais design. So I think that part will probably need more thinking on how to change the beacon API and validator interaction to solve that. So yeah, just some feedback.
00:17:59.890 - 00:19:25.180, Speaker B: Thanks Terrence. By the way, one question if I may. I don't know how slasher software is implemented in terms of database schema, but if slasher in general has access to network aggregates so it stores the network kind of like an aggregate of single committees, then in general case, in most of the cases where we are slashing, one or two validators will not have this huge complexity. Because if a tester slashing is created from two network aggregates, the attessor complexity, data complexity will be the same as today. The complexity only increases if we use the on chain aggregate and we use it to just one wire because we'll have to include all widers attested in a slot into the message.
00:19:38.140 - 00:20:30.110, Speaker A: Got it. Any other comments on this before this surfaces as a pr to parameter changes and I guess further work on some of these other components. Again, take a look at the analysis and when there's a pr up, chime in if you disagree with the prioritization. Thank you, Mikhail. Okay, Anskar, you wanted to give some update on the feedback and discussion around the proposal for issuance change that you brought up.
00:20:31.760 - 00:20:35.790, Speaker E: Yeah. Everyone, I hope you can understand me. It's a little bit noisy here.
00:20:36.640 - 00:20:38.220, Speaker A: Yeah, it sounds reasonable.
00:20:38.640 - 00:21:16.324, Speaker E: Okay, sure. Yeah, I just wanted to give a quick update. So basically we published the post, the one kind of general post about where we think the stake economics should go in the long term, and then a specific proposal, kind of intermediary proposal two weeks ago and briefly announced it on the SCDC last time already just to the captive. Basically we had some kind of community feedback. It's basically been mixed feedback. Some people kind of followed the reasoning and agreed that that would be a good idea. There were some people who were skeptical.
00:21:16.324 - 00:22:22.748, Speaker E: We are facing in the process of addressing that kind of, hopefully also in the future have to have some extra, more like boiled down crisp to the point kind of explainers, explain us on this. So this is going to be an ongoing process. Just one concern that was raised, and I just wanted to briefly address, is that the kind of the timing for electra and that of course an exchange change would be a significant kind of change to ethereum. We were very much thinking that because it was such a small change last time I linked the proto eap, that would be like literally a two lane change, the post adjustment for electra, that we could add this basically very late into the fog process. So say, assuming we are targeting something like an October fog, then we were thinking that we can make like a final decision on this specific EFP in say June, July just to maximize kind of the time for community conversation around this. So yeah, I just wanted to basically stress that point that this is not a decision that we're trying to force through here on a one or three months timeline. Yeah.
00:22:22.748 - 00:22:39.250, Speaker E: Other than that, I think again, it's more going to be an ongoing conversation. If people have had a look at the write ups and have questions that we could now, or like a conversation we could have now on this call, then we'd be happy to, but otherwise, again, just want to give quick thumbs up.
00:22:42.520 - 00:23:44.900, Speaker A: Yeah, thank you. I was going to take issue with the claim of very late and say how about not so late, but the summer notion that you then clarified with is not unreasonable. Thanks for the update. Any questions for OnScar? Okay, thank you. One of the lingering discussion points in electra that I do, I think there's an eagerness to make a no go decision soon is around inclusionless, and there was a breakout room and there's definitely a group working on some R d to better understand complexity. Mike, give an update. Yeah, hey everyone.
00:23:45.910 - 00:24:43.974, Speaker B: So yeah, just kind of catching up on everything post eth Denver and I think it could make sense to have another breakout room to just kind of continue circling in on the exact features of the design. There's been a lot of back and forth in the Discord channel and that's bridged into telegram, so definitely take a look there if you're curious. I thought it would make sense maybe to do the breakout room after the hard fork, and I thought maybe next Friday during this slot could potentially make sense because it's after the next all core dev execution layer call. So yeah, that's kind of it. Happy to continue helping answer questions if people have them. And I guess the Discord channel is probably the right place to engage with the discussion. I can give a general update on where the specification is at.
00:24:43.974 - 00:25:10.990, Speaker B: Right, so today I think the spec is at the Xiaoi's option repo. So I think moving forward is probably better to move it to the official ethereum repo because now I think spec is probably like 75% ready. And then in terms of all the components, I think right now validator on this validator and execution API are the ones that's under specified. Rest of them are in pretty good shape.
00:25:17.040 - 00:25:56.360, Speaker A: Thank you. Any other comments on inclusion list? Normally I think breakout rooms are often on days that are not Thursday and 02:00 p.m.. UTC, but that's not a rule. It's totally fine to do it after the execution. I call if people want.
00:25:57.130 - 00:26:00.946, Speaker B: Sorry, I meant Friday during that slot.
00:26:00.978 - 00:26:26.760, Speaker A: Yeah. All right, cool, let's go for that. I don't see an issue with that. All right, anything else on Electro?
00:26:32.470 - 00:26:33.874, Speaker B: I've talked to a number of people.
00:26:33.912 - 00:26:34.740, Speaker A: That are.
00:26:36.810 - 00:27:29.110, Speaker B: I guess more willing to check Max EB than has been sort of indicated in previous calls. Like we've pretty much prototyped it in Lighthouse. There's still work that needs to be done on the spec, but it doesn't actually seem like a significant amount of work. And given that validator set size is a bit of a ticking time bomb, and we have this proposed issuance adjustment. And issuance changes are always contentious, so it's no guarantee that the community would accept such a thing, especially like I'm pretty sure that would have significant ramifications on say the rocket pool token, for example. So you could expect they would push back. We already had Lido kind of indicating, but we just have no idea how the community is going to accept issuance changes.
00:27:29.110 - 00:28:01.040, Speaker B: So if they don't like it, then really the only thing we can do is Max Eb. And while the spec needs work, just writing so far from what we've seen, trying to implement a proof of concept in Lighthouse, it hasn't been a significant amount of work. So I'm wondering if anyone. I haven't heard yet, people push back on this.
00:28:01.970 - 00:28:17.990, Speaker A: So the major pushback has come from Prism's claim of complexity in their code base, which is potentially related to design decisions. But I couldn't speak to it too much more. Okay.
00:28:24.140 - 00:28:32.536, Speaker B: I suppose we can continue. I mean if anyone on the call wants to offer any from the prison team wants to push back, but I.
00:28:32.558 - 00:29:10.680, Speaker A: Could also just get in touch with them later. Yeah, and I surface that information not as Neil McCauffin, just as that I believe has been the primary rebuttal of. Okay, well, yeah, and I will note that at least a couple of members from a couple of different client teams that are not prison do echo their supporting chat.
00:29:16.460 - 00:29:42.748, Speaker B: And just to put it out there, I don't anticipate a lot of pushback from the execution side either. It would require partial withdrawals from the execution side. But if they've already agreed to do 7002, then partial withdrawals are not a lot of additional complexity as far as I can tell. So just saying, I wouldn't anticipate a lot of pushback.
00:29:42.924 - 00:30:05.110, Speaker A: Yeah, I believe on the 7002 component the complexity would likely almost entirely surface in the smart contract, which gets to be written once. So it's kind of mask complexity. Potoz, I just have a technical question.
00:30:05.880 - 00:30:27.980, Speaker C: I don't want to repeat this thing of the complexity, but I had one comment on the pr, which is this issue that we choose a random byte to decide the shuffling. And I wonder if this is just not as small enough when we increase the effective balance. Perhaps we need to change in the shuffling from one byte to a larger integer.
00:30:36.530 - 00:31:56.950, Speaker D: Yeah, we had someone looking into this and we didn't got a conclusion if it was super necessary or not. In my view, the detail. We can run the numbers later and see if we have to bump it or not, if that satisfies it. I would just like to general raise a voice against the idea of using client complexity today to determine the future of a useful feature. I think all of our clients are now at the stage where we have a well working test set up with well working spec tests and so on. So a broadly useful feature I believe should lead to architectural changes in clients that are fairly safe to implement. Regardless, it might be a bit of work, but it's a lot less work than it used to be, and changes tend to be almost mechanical for many features.
00:32:07.750 - 00:32:52.060, Speaker A: Thank you. Okay. Given the proximity to interop in May and from these outstanding things in discussion, electra, I would encourage us to attempt to make pretty firm decisions on both these proposals in two weeks. I know that's not an easy thing to do given competing views here, but let's surface both of these in two weeks and do what we can.
00:32:55.870 - 00:33:02.640, Speaker D: Sorry, I want to add, I understand the complexity pushbacks, but I see.
00:33:04.370 - 00:33:04.686, Speaker A: With.
00:33:04.708 - 00:33:35.750, Speaker D: What we mentioned last time, with leading pocs to, I guess, prism and anyone else that's concerned about complexity, please let us know exactly what's concerning to you, and I will be willing to do a talk or basically help you guys figure out if we have found this complexity or how that differs to you. So yeah, let's chat async, but we can translate our findings to you guys and see if we can alleviate the concerns.
00:33:47.830 - 00:34:55.522, Speaker A: Thank you. Other electra items further comments further discussion points okay, yeah, those that are in favor of either of these proposals, inclusionless and maxv, certainly the onus is on you to do the work. Have the communications dig into details to try to push things one way or the other. General research spec discussion Barnabas has a couple of points. Key a manager API standardization barnabas yeah, hi guys.
00:34:55.576 - 00:35:43.640, Speaker F: So this past weeks I've been looking into enabling key manager API on the validator nodes on kurtosis so we can start testing basic API calls using this. And I realized that every client had a different implementation for authentication for these endpoints, which makes it a bit problematic to add it to kurtosis nicely. So it would be good if this could be specked out properly, same way as we specked out the JWT secret for communication between the El and Cl. I'm not sure what the different CL teams think of this.
00:35:43.790 - 00:35:46.090, Speaker A: Where does the JWT spec live again?
00:35:49.980 - 00:35:53.150, Speaker F: I thought it was execution spec.
00:35:53.600 - 00:35:59.656, Speaker B: Maybe it's in the execution APIs, in the engine spec folder.
00:35:59.848 - 00:36:10.560, Speaker A: This would likely live in the Beacon APIs spec repo. I think it should live in the key manager APIs repo.
00:36:11.300 - 00:36:15.990, Speaker F: Yeah, most likely in the key manager APIs repo would be the best place for this.
00:36:19.840 - 00:36:23.020, Speaker D: I guess the most problematic thing is.
00:36:23.090 - 00:36:26.380, Speaker B: That every client is maybe handling.
00:36:28.480 - 00:36:32.672, Speaker D: Certificate in different ways because at least for.
00:36:32.726 - 00:36:37.356, Speaker B: Tech we want to have HTTPs by default enabled.
00:36:37.388 - 00:36:41.904, Speaker D: So you need to specify key store, then you have to create a key.
00:36:41.942 - 00:36:55.012, Speaker B: Store and then to spin up HTTPs and then you can have the authentication on top of it. So maybe every clients have different way.
00:36:55.066 - 00:36:59.050, Speaker D: Of creating those key storage certificates, stuff like that.
00:37:06.660 - 00:37:32.890, Speaker F: I'm not necessarily pushing towards one or the other, I would just like to see a standard implementation across the board and I think HTTPs certification creation is a pretty standard thing to do. So it's not Java specific or go specific or anything. Authentication should be able to be a standard thing.
00:37:35.940 - 00:37:50.230, Speaker A: So do you want to flesh out a doc or a pr there to make the design space conversation a bit more concrete? You probably have a better view of the different design decisions across clients than anyone else here.
00:37:54.430 - 00:37:55.420, Speaker F: Yes, sure.
00:37:58.760 - 00:38:37.030, Speaker A: Any other comments to Barnabas before we move on? Next up, also from Barnabas mixed validator client beacon node testing. As we all know, there is a standard API that is utilized, but I think more often than not people have a single validator client connected to its partner with the same client. But Barnabas wants to know is it expected that these should work cross and should they put effort into testing?
00:38:41.250 - 00:38:59.410, Speaker D: We fix any bugs that people report above all, because we've seen a lot of people that run two beacon nodes and then some of them run different clients in the beacon node.
00:39:02.390 - 00:39:08.130, Speaker F: So it's an expected behavior that this should just work with every client combination.
00:39:10.650 - 00:39:12.550, Speaker A: I think it's a desired behavior.
00:39:12.890 - 00:39:14.130, Speaker F: It's desired behavior.
00:39:14.210 - 00:39:52.780, Speaker A: Okay. I would say the prism's validator client is still not ready on the standard API. Yeah, validator client on the standard API because it's still using GRPC behind the scenes. There is a rest option, but it's still being cleaned up. We're making steps forward on.
00:39:56.030 - 00:41:06.518, Speaker G: So I would say that in general it should be working. I know some teams are already using the rest option and there have some issues, but more or less it works. So I would say that feel free to test the present value client with the rest flag with other beacon nodes and I would be happy to hear any feedback. So actually I would be really interested if this becomes a reality that we have a good test harness with different clients. It would be a good way to check cross client compatibility and everything. It's not 100%, let's say, as we would like it to be, the rest one, but it is working. And as you mentioned, the expected outcome is that it should just work out of the box.
00:41:06.518 - 00:41:14.920, Speaker G: If any combination doesn't work, I would say there's a box somewhere. So the expectation is that every combination should work.
00:41:23.480 - 00:41:33.140, Speaker A: Okay. Yeah. So any testing you can do here, I think would be really valuable. Any other comments for Barnabas?
00:41:34.360 - 00:42:15.792, Speaker D: Yeah, if you're writing anything that tries to do something about this, there are a few gaps in testing. One is the rewards API, and the other one is the consensus block value. And the third is doppelganger. Now, liveness, it's called in the API. All those three are kind of under specified, in my view. And all of them are also kind of intricate. If, if some beacon node does them slightly differently, we'll, we'll get a very bad outcome if we mix and match clients.
00:42:15.792 - 00:42:32.170, Speaker D: So it would be nice, for example, that there are comparisons of these API between clients and the values that they actually return for a given, say, head.
00:42:34.460 - 00:42:49.710, Speaker A: That's a great lead into Dustin's next issue, which is generally the treatment and specification of where block rewards do surface in the beacon APIs. Dustin, do you want to.
00:42:55.140 - 00:44:03.670, Speaker H: Are. And I linked here actually, so people don't have to go back to the GitHub issue for the meeting. I'll link the gist here as well. Okay, so there are relatively new last several months to a year, and not necessarily universally implemented yet APIs that involve either a new option in the case of produce block v three, or the rewards, which is not universally implemented. The idea of a consensus block value or the value of constituent parts of a consensus block in the case of the block rewards API. And this is what Yosek was, I think, explicitly, partly getting at is this is, I would say, under specified. Now, I may have simply failed to find specification or documentation which exists, but yeah, and in particular, we've had discussions in the nimbus team about how to interpret this, and we're not sure.
00:44:03.670 - 00:44:56.468, Speaker H: And we think that if we're not sure, perhaps that there's not enough explicit guidance to ensure interoperability. So this ties into and is a little bit, it overlaps with the idea of testing for it and interoperability testing in an empirical way. But even if Barnabas, say, goes and tests things and turns out everybody magically agrees on how to interpret this, that's sort of coincidental. The specs do not specify enough to say this. Now that's sort of the broad thing. And I sort of try to keep this relatively brief. But to say the specific, there's two basic categories and people can read in details of what I linked, but one of them is the proposer index changes.
00:44:56.468 - 00:45:37.540, Speaker H: I mean, there's various places in the beacon chain spec where it says you do this. During block transition, the proposer index's balance changes. That's at least, I think by my reading, unambiguously part of this reward value, a consensus reward value both for block reward and for produced block v three. That's, I think, probably uncontroversial. I don't see how you can interpret it in any other way. I think what's less clear is there's one view. I think the high level view of this perspective is the block value is the amount by which the block changes the proposer's balance period.
00:45:37.540 - 00:46:37.476, Speaker H: And it's easy to state, but it turns out to have a lot of sort of, let's say complications or nuances, because you can imagine epoch blocks or I described some of the self slashings, or if you're part of the sync committee, et cetera, et cetera. A lot of edge cases come up. And there's another perspective which says, no, the block value is better viewed as even though it says it's confesses block value, in the header of block b three response, it says it's something like the proposer rewards value, which is to say, even if there happens to be accidental integer aliasing on the validator index is equal, or the whistleblower index for slashing is equal to the proposer index. Well, is that part of the block? It consists of the blockbard. So that's the question. Again, people can read the document. I put up a little some more examples.
00:46:37.476 - 00:47:09.600, Speaker H: But the point is that, as Yasak is saying, I think all the clients need to agree, especially for produced block b three, because this is how validator clients are going to select their blocks. Now, it ultimately doesn't matter enormously. I mean, I have my preferences. I'm trying to present this neutrally, but it doesn't matter enormously which one is chosen. But people have to agree, otherwise there's going to be a skew, artificially invalidated client choices.
00:47:13.270 - 00:47:33.018, Speaker A: Yeah, it makes sense. I know that you're trying to present it neutrally, but do you have a perspective on the correct way to specify this? Because ultimately we need to kind of surface an opinion here. I think there's probably broad agreement that there is an ambiguity because that is clear.
00:47:33.104 - 00:49:10.200, Speaker H: I think the proposer index, only one is the only, and here I want to be fair, I'm speaking for me, I think it's the only reasonable one. And I'll say that without reservation, you can find other people who disagree with me on this one. But in particular, I think the basic argument for me is along the lines of, well, if you swap out that proposer, so you can run a couple of different sort of thought experiment, again, a few sentences, you can run this thought expert experiment in a couple of directions. One, you swap out the proposer, but it's otherwise the same block and with the same sync aggregations, the same slashings. It's a little weird, I think, and unexpected that somehow, because that slashing would have happened anyway, that sync aggregate penalty would have happened anyway, it's a little accidental that it happens to be part of a block proposed by that validator. So that's one direction you can also keep, that's keeping the proposer constant, keeping the non proposer validator constant, if you keep the proposer constant, but then allow the non proposer validator to change, and you could say, well, there's two non valid proposer validators which missed their sync aggregate or sync committee contributions at some point. And it's a little strange to treat them differently in some sense in terms of accounting purposes, because one of them happens to be the proposer completely accidentally and one not.
00:49:10.200 - 00:49:30.542, Speaker H: And indeed, if you have a small enough validator set, as some of the tests do in the consensus spec test, you can be in the validator set, the sick committee rather two or three or four times. And again, it's just kind of strange to me. Yeah, go ahead.
00:49:30.596 - 00:50:17.840, Speaker A: And I see that. I guess my counterargument be like, what is this used for? This is used for a validator client maximizing their reward and, and so, and or penalty, or minimizing their penalty. So like seeing two blocks and actually seeing that one gives you two more g way than the other, due to some of these happenstance things, which could be node specific because one might have certain messages that it include or pack in a certain way, the others do not. From a use case perspective, it seems like I want to know that.
00:50:20.530 - 00:51:52.830, Speaker H: Sure. And in general, validator clients are free to choose other information if they want. And there, I would argue that it's still, I think, in favor of a cleaner split, even for what you're describing, between the proposal reward proper and having that be readily accessible, and then having these other bits of information which are also accessible, the validator client when it sees even the sort of blinded blocks which is tied to transactions and such, they can make that decision already can see, oh well, this sync aggregate includes my contribution, or doesn't include my contribution. And this is another reason I think, that it's to allow a certain flexibility to say if you have a node, or let's say you have a validator on a node that has 100 validators on it, and at any given time one validator happens to get that block, but the other 99, they may or may not have that node, probably should care, let's say, about its validators as a whole, not just about the one validator which happens to be proposing, and a validator client, whether it's a beacon node or validator client. And splitting this out allows that kind of flexibility on the part of large or not even large, even several validator nodes.
00:51:53.650 - 00:52:02.720, Speaker A: Okay, so the optimization function isn't always just directly towards synchronous proposer in many cases, right?
00:52:03.330 - 00:52:50.862, Speaker H: The other thing that I would point out with regard to the optimization function is that it can be, at least my suspicion is, and I haven't rigorously looked at the math on this, but I did write this in the note linked as well, is that for sync aggregates, it is probably the case that it makes sense to, yes, optimize the way if you have a block being offered which doesn't have your sync contribution, then that should in fact be weighted. There's no real advantage in letting that in if you have a slashing, if you can be your own whistleblower on being slashed, that's still to your advantage. And my suspicion is that it's better.
00:52:50.996 - 00:52:58.402, Speaker A: Sorry, to your advantage, meaning, assuming someone else is going to include the slashing, so you might as well include it yourself. Is that the assumption? Yes.
00:52:58.536 - 00:53:50.386, Speaker H: So if you can include the slashing in your block and be the whistleblower, well, the splashing has already happened. It will come in the next few blocks anyway, even if there's a lot of slashings and mass flashing. While I can't sort of vigorously defend that right now, again, I will say that that kind of consideration certainly is something that can come up whistleblower for sure. The others, I don't know. So it can be a little distorting to say, well, this block hurts me a lot, I really don't want this block. Yes, but you would get the penalty next block anyway. So I would argue for optimization purposes, it's still useful to be able to split this out.
00:53:50.386 - 00:54:13.290, Speaker H: And of course, ultimately it's a symmetric argument, you could say if validator clients can add this back in, well, validator requirements can take it out. You can have the aggregate, as it were. You can have the combined version of this and then subtract as easily as add. So it's kind of a version of at that point, I guess, conceptual clarity or true. I mean, there's other arguments.
00:54:15.790 - 00:54:37.022, Speaker A: Okay. Are there other opinions on the direction this should go in before someone makes a pr to clarify the specification, or do we need to kind of put this up in an issue for discussion? But yeah. Any opinions and perspectives?
00:54:37.086 - 00:55:52.620, Speaker G: Yeah, so I have an opinion, not a strong one, but still. So, question is, how much of a discrepancy would there be in different client implementations if this is not specified that tightly? And there might be some discrepancies between clients, because if we're talking about a few guay, for example, then my question is, does it really matter? Wouldn't it be okay if different client implement different clients just return the block value within some delta of each other, instead of trying to specify every single small thing so that we make sure that the results are exactly the same up to one way even. I'm just thinking how much work it is to make sure everyone aligns and how much discussion it will take versus. We are just okay with having these values a little bit different maybe. And we're just fine with that, I guess.
00:55:52.990 - 00:56:01.310, Speaker A: Meaning the common practice is if I see in blocks within some delta, I pick randomly.
00:56:04.800 - 00:56:08.270, Speaker G: Well, maybe you pick the one that you see that is the highest, right.
00:56:10.000 - 00:56:33.360, Speaker A: Right. But at that point, then the interpretation of the spec becomes a heavy bias on which one would be the block producer. Correct. Like if client a does it a slightly different way, then 90 something percent of the cases, client a might just look more profitable when actually they might be the same.
00:56:35.330 - 00:56:35.694, Speaker B: Right?
00:56:35.732 - 00:56:36.254, Speaker G: That's true.
00:56:36.292 - 00:56:36.494, Speaker B: Okay.
00:56:36.532 - 00:56:38.080, Speaker G: Yeah, that's a good point.
00:56:46.400 - 00:57:57.620, Speaker H: The other point here is that related and potentially a little distinct, but I would say, but why it's worth kind of standardizing this, even though for fuse block b, three people might think, might have this argument that some amount of sloppiness is okay, is that ideally it should match get block rewards. This is kind of why I brought them up together. And my suspicion is that there are relatively few people, although I don't know maybe, who are willing to have both of those be just kind of randomly variable. And then, so I would suspect the one is going to, and people might have different views on which one they care more about being precise. But whichever that is, that should probably kind of constrain the precision of the other as well. Sure. POTUS or, I don't know, somebody raising their hand.
00:57:58.950 - 00:57:59.266, Speaker G: Yeah.
00:57:59.288 - 00:58:54.318, Speaker C: I want to make an argument that I don't strongly hold, but anyways, it's a half baked argument, which is the consumer of this presumably is a client like vouch who's choosing between different bitcoin nodes which block to sign. And I feel like this is so specialized that essentially there's not any other one using this. Or perhaps there's some other clients and some people that developing validator clients that are doing this. But this is sort of like pushing us like having six different clients, five different CL clients, discussing on API, getting to agreement what is what we need to specify. Getting, testing, getting to spec test and taking our bandwidth for something that perhaps can be done downstream. I don't even understand why we even agreed into supporting this. If the consumers are restricted.
00:58:54.318 - 00:59:06.440, Speaker C: I would try to study these markets and try to see if we can actually send this work to the people that are consuming these endpoints instead of ourselves coding them.
00:59:11.070 - 00:59:14.560, Speaker H: Without consistency between the BNS. I don't know.
00:59:18.290 - 00:59:22.958, Speaker C: For one, it's not just, well, you can get all the blocks and decide and compute this yourself.
00:59:23.124 - 00:59:23.502, Speaker A: Right?
00:59:23.556 - 00:59:36.740, Speaker C: So if I am a client that I'm faced with core devs don't want to implement this in the beacon, then I can just get all the blocks and do the software that computes what is what I'm going to be getting.
00:59:37.350 - 00:59:43.080, Speaker A: Yeah. And you can pass in indices and essentially do a diff on them.
00:59:44.410 - 00:59:44.822, Speaker D: Yeah.
00:59:44.876 - 00:59:55.850, Speaker C: I'm not confident coding this for just a few consumers. I mean, if RPC providers are using such an endpoint, then I'm happy, but otherwise it seems like far fetched.
00:59:58.750 - 01:00:23.826, Speaker D: Yeah, you need a state to compute this actually. And that's the first point. The second point is that the nimbus VC supports this, selecting between bns based on profitability of the block. And I believe Lighthouse does as well. I wouldn't be surprised if they didn't because I think they support multiple vns and at that point we do. To ask yourself. Yeah, exactly.
01:00:23.826 - 01:01:54.640, Speaker D: There's already two of us supporting selection of blocks. And users will be very confused if randomly because they're using some particular client, that client gets either more blocks or no blocks. I mean, this was the whole impetus behind produce blocks v three that you would unify block production value for both execution and consensus so that you could compare two blocks and potentially blinded blocks and see which one is best for you. And this is also a way of resolving the problem of MEV blocks. If ever you happen to get a bad MeV block that isn't profitable, obviously your locally constructed block should be preferred. But how much you gain is the sum actually of the consensus value and the MEV value and the transaction value or whatever it is, right? So I think this is just really basic functionality that just makes sense to have. If we envision a future in which there are multiple block sources and you need to compare them, it's that simple.
01:01:54.640 - 01:02:44.340, Speaker D: Sorry. And that's actually a comment against or it's a difficulty when you want to compute the block value from attestations or your participation in aggregates and in sync committees, because you don't get an eth value. You get like a random number, and then you can guess the ETH value, but you can't really determine it without the full state because it depends on a whole bunch of things, like the size of the active validator set. And the active validator set depends on who's been slashed. And it's a mess.
01:02:55.100 - 01:03:49.160, Speaker C: For the nimbus validator client and the lighthouse validator client, you're presumably running a bunch of beacon nodes, and hopefully you have access to one of those beacon nodes, which is a nimbus one or a lighthouse one. And in that case you can just code yourself an endpoint that says, here's a block, tell me, how much money does it give you? But this is, again, something that you can do. You have the state in this peacon node, and you don't need to have all peacon nodes that you're connecting to giving you this value. I'm not saying that this is something that I'm strongly against, it's just that it's something that you can solve yourself without requiring support and agreement, which is a hard part on all of these API discussions. There's always a lot of arguments, and even they discuss about names, if they should be capitalized or not. So you can avoid all of this by coding it yourself in your own endpoint.
01:03:52.060 - 01:04:46.060, Speaker D: Well, we have a produce block, v three endpoint. It's actually the only endpoint that we have right now for producing blocks because the other two were deprecated. So this is a discussion that should have been had when approving the v three endpoint into the beacon API. But that chip sailed, and that v three endpoint has this value. So if we want to roll back on that, we should release either a v four or undeprecate v two, which never really was in production. And I think v one, we can't even use it because it doesn't have the necessary functionality. So we're in a bit of a bind here if we go down that route.
01:04:58.060 - 01:05:27.810, Speaker A: Okay. I do think it makes sense for Dustin or someone to service a proposal on standardization, especially given that v three is the endpoint. And obviously we can always have a discussion of deprecation and movement onto something else if this is actually something people don't want to support. But it does seem like at least a few clients do. Dustin, can you move forward with the.
01:05:28.420 - 01:05:39.990, Speaker H: Yeah, yeah, I'll make a pr, I guess was a beacon API, because that's where both of these live, their beacon API endpoint. All right.
01:05:47.750 - 01:05:52.930, Speaker A: Okay, before we move on to open discussion, any other spec research related items?
01:06:02.250 - 01:06:05.046, Speaker D: Yes, protest just a quick one.
01:06:05.148 - 01:07:14.460, Speaker C: I asked this question on R-D-I was hoping that if there are eldevs that can confirm the question is about sending different fcus with attributes and whether or not the EL clients start building those blocks and continue updating those blocks. This is not really specified in the engine API, but it seems that geth and Nethermind are supposed to continue building both blocks if we send them both fcus with attributes. If this can get specified in the engine API. This would make our life much easier when reorgan late blocks. So currently we need to so it's a bunch of edge cases because we don't update our head when a block comes late. But if every client already implements this and allows for different fcus with different ids at the same time, then we could just simply import the block, do everything as we do normally, just update the head and just choose the right id at the time of proposing. It'll make our code much simpler, so take a look.
01:07:14.460 - 01:07:18.000, Speaker C: It's in the execution dev channel in R D.
01:07:22.520 - 01:07:35.610, Speaker A: Thank you. Any comments on that? Any other research or spec related items?
01:07:42.330 - 01:08:21.922, Speaker C: Podas anyways, I just also wanted to point so you asked the question a couple of calls ago about epbs whether or not there could be partial builder safety. I posted a short note on it. Research I'd love if someone can give feedback up to now, I think Francesco just replied something which is guaranteeing builder safety and reorg resistance up to a collusion between stakers having 20% of their stake. There's some arguments there, but I'd like to hear some more feedback.
01:08:22.066 - 01:08:24.710, Speaker A: This is payload boosts in epbs.
01:08:25.230 - 01:08:26.220, Speaker C: That's correct.
01:08:27.230 - 01:08:59.030, Speaker A: Got it. And I'll call out that that also links to another post from a few days prior, epbs design constraints, which is something that on the breakout call was pretty high value. So also please take a look at that.
01:09:07.970 - 01:09:08.720, Speaker D: Okay.
01:09:09.570 - 01:09:28.510, Speaker A: Anything else on spec research related discussion? Okay, Pooja, you have something to discuss?
01:09:30.800 - 01:10:23.310, Speaker I: Yeah. Thank you, Danny. Hello everyone, I'm Pooja Ranjan from the Ethereum cat herders. I'm excited to be sharing about an inspiring initiative that's really close to our heart, the Women in Ethereum protocol group, also known as WIEP. This is a new working group in collaboration with the Ethereum Foundation, Ethereum Protocol fellowship and the Ethereum Cat Herders. It's basically a movement towards inclusivity diversity in the Ethereum blockchain development, with the main goal to encourage and onboard more women developers for protocol development. I'd like to thank Piper, Mariam, Carrie Claus, Tim Becko, Josh and many others from the Ethereum space for their support during the launch event in etcity Denver last week.
01:10:23.310 - 01:11:23.250, Speaker I: And I'm also happy to announce the celebration of International Women's Day with WIEP. So we are organizing an hour long webinar on March eigth at noon Est with inspiring speakers from Ethereum ecosystem, including researcher, product manager and fellows from the earlier cohort of Ethereum protocol fellowship. The invite link can be found on Twitter handle at wiepdeen. Anyone listening to this announcement now or later in the recording, if you or someone you know may be an aspiring Ethereum protocol contributor, please reach out to Shive Wong, Ladonna, Higgins or me. It is a collective effort that we want to bring the real change. So let's collaborate, learn and grow together. Thank you.
01:11:25.060 - 01:12:00.220, Speaker A: Thanks Vidja. Any questions or comments related to this effort? Great. I have an announcement. Starting April 1, I'm going to take time off for three months. This is a well o machine. You won't even notice I'm on Stokes. Alex Stokes will chair the car.
01:12:00.220 - 01:12:47.408, Speaker A: Is this is not an April fool's joke. Alex is going to chair the call. Xiao Wei is going to be there providing some extra support and generally I think we should be in a good spot. So don't have I'm going to try to be totally unplugged for a few months, so if you have things that you want to talk about before then, please get in touch with me. If you have things that you think you would need help with me, from me during that time frame, I can help you now and I can make sure that you have the resources you need to get help when I'm gone. So just hit me up if you have anything cool. On that note, let's close the call.
01:12:47.408 - 01:12:52.908, Speaker A: Thanks everyone happy. Upgrade this coming week. Exciting.
01:12:53.004 - 01:12:53.890, Speaker D: See you, guys.
01:12:54.420 - 01:12:54.944, Speaker A: Thank you.
01:12:54.982 - 01:12:55.612, Speaker B: Bye.
01:12:55.756 - 01:12:58.780, Speaker A: Thanks. Bye. Thank you. Bye.

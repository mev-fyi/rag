00:00:19.210 - 00:00:33.320, Speaker A: We're going to be listening to a presentation about Swarm by Daniel and Victor. It swarm hasn't really had as much publicity as it probably should have. So please welcome these guys to the stage. They're doing awesome work.
00:00:40.750 - 00:01:48.378, Speaker B: Thanks, guys. I start the talk right now before we set up here, just so that I don't want to make the same mistake as Chris. Okay, so what is swarm after all? So swarm is supposed to be for content distribution and storage for web3. So basically it's the content distribution network for the Ethereum ecosystem. So if Ethereum VM is the word computer, then you can say that swarm could be the word hard drive or a word hard drive, because there might be alternatives to this solution. So on the other hand, what else is a swarm? I mean, you can just imagine an imaginary swarm where the happy beekeepers sit behind their hives and look at their fantastic product from the bees and just happy to have their honey harvested from the beehive. You can also look at the beehive as this lovely repository of honey where all these like drops of honey are stored.
00:01:48.378 - 00:03:01.446, Speaker B: And also you can look at that swarm and see the buzzing swarm of bees just communicating with each other. I don't know how you are, but for me it obviously reminds me of a network protocol and all the network messages are sent around. So let's concentrate on these three aspects. First of all, as a service, what swarm provides is basically it allows to store the Ethereum, dapps, the decentralized applications, and also kind of off chain data that's important, for example contract sources or like registry indexes, all kinds of things which people need to store and what they want for that. Like users want to keep this record safe and in general they want integrity protection. Always availabilities like basically zero downtime, fault tolerance, all these nice things that you want from a decentralized solution in general. And one important message to take away from this, and they are willing to pay for this in a way like incentives is there for you.
00:03:01.446 - 00:04:10.146, Speaker B: Like the user wants to have the contract, the content retrieved, and that's an incentive. So how we solve this problem is an interesting, you can reduce this problem of file storage and basically hosting to resolving the problem of storing fixed size chunks in a decentralized system. How is that working? Basically on the file level or document level, you can basically chop up the files into small little pieces, rearrange them in a nice Merkel try. This is not a swear word in this company of people. I mean, you all know, like the Ethereum works in the same way the Ethereum state for the Patricia try. And what you end up with this mercury try is that you can have like a random access partial read into a file with still preserving the integrity. And you can do this like one step further and say that you can not only handle documents, but also document collections.
00:04:10.146 - 00:05:29.126, Speaker B: So another level of indexing, which is kind of a similar structure, you call it a manifest, and this also allows to index, but as opposed to the previous mercury, the parts of the document collection are obviously of arbitrary length and the indexes are just paths. So this means that if you have a root of a manifest like this chunk, then basically they can represent entry points to the web. So basically they can be thought of as hosts, because the manifest basically constitutes the routing table for that host. So basically you can use these chunks as representing or mimicking a web server. So this is how you make like a decentralized server from Swan. Now basically the message is here that we reduce the problem to a chunk store, and we associate each chunk with a hash of the hash of the content, which means that we have to look up them based on these keys. So what do you actually store? Let's look at the other aspect of the hive, like the store.
00:05:29.126 - 00:06:25.570, Speaker B: So each node has a memory store and a disk storage. So basically these are the caching that the node can look up locally. But eventually there's going to be a situation where you can't store everything. So you have to look out to the network to find something, because the neighbor's honey is always sweeter anyway. So now you have to solve this problem of how you communicate your needs, how to find basically these chunks. So what you basically do is use a network protocol, and swarm relies heavily on the Ethereum network, which is basically Alex Labarent and Felix's wonderful genius product. It's basically the dev peer to peer multiprotocol suite.
00:06:25.570 - 00:07:25.206, Speaker B: I don't want to go into the details, just refer you to Alex's talk on I think it's Wednesday morning. The most important message here is that it comes with all the beautiful security and integrity properties of this network implementation. And also it gives you a semi permanent peer pool. Basically the peers that you actively connected to can be considered relatively stable. And also the network overlay topology is flexible. So all we needed to do for swarm is basically use academia routing table academia peer selection mechanism, and we immediately had like a key based routing system available. Now how you combine these two ideas, obviously if you establish that the way you find a particular chunk is to go through the cadamlia routing.
00:07:25.206 - 00:08:27.680, Speaker B: Sorry. For those of you who are not into this mambo jumbo, let me give you an example. So the cadamia routing basically would be that you organize your hive so that for each chunk you can find a bee that can take you to a hive that's closer to that target than you are by a factor of like a fixed factor. And basically this logarithmic distance that the keys space defines, makes sure that you can find a particular either node or information about that particular chunk in logarithmic time in a fixed constant number of hops. So this is basically the idea of DHT. There's nothing, not much new here. The interesting twist on the DHT that we have comes from several properties of this semistable peer base.
00:08:27.680 - 00:10:26.642, Speaker B: But more importantly, the other thing is that we don't only assume that the nodes that we reach contain like give you information about where the chunks are found, but they actually give you the chunks themselves. So it's a proper content addressed storage. What's the advantage of this view? This gives you the possibility to define a content push mechanism, basically how the distribution of content works, not only their retrieval, basically along the same kind of lines as the routing works, or even simultaneously to that. And one consequence of that is that eventually, as a result of continuous retrievals, and the scheme that we define basically through these forwarding requests and forwarding deliveries, the end result of that is that you end up with the swarm being a kind of elastic cloud, which means that all the content that is popular can end up relatively far from the node that's supposed to be close to it, that's supposed to store it. But that means that the content will be more readily available in less hops, because it's just more pervasively present in the network, and therefore you get auto scaling that popular content will be retrieved with less latency, or that's the idea. And also this means that swarm is basically a constantly maximum utilization system. So this forwarding and distribution scheme that we also call like smart synchronization, it also makes sure that the network adapts to when content becomes popular.
00:10:26.642 - 00:11:45.262, Speaker B: It basically replicates. And you can think also of it like a giant doughnut that grows when everybody bites to it, and the same way it can also shrink. So if document popularity is dwindles, then it's continually deleted from those nodes that are relatively far from it, for which the popularity doesn't justify anymore that they store it just because they are too far. You can think of it as the doughnut shrinking, and in the end, it can also happen that certain content is deleted. Now let's go to the incentives, that kind of force aspect of swarm. So each of the decisions that the swarm participant nodes take should be somehow legitimated by some sort of incentive, because as we all know, they are like rational actors and they are not shying away from maximizing their profits so they can abuse the system if we don't align the incentives properly. So what do you actually store? Let's go back to this question.
00:11:45.262 - 00:12:52.366, Speaker B: First, we can answer this question simply by like you store what you actually deem most profitable to store. It turns out that all you need is to consult like your database and see how much a particular chunk or content was accessed. Because actually on one hand, access is a very good predictor of future profitability of a chunk, to assume some sort of constantly of popularity over time at least. And on the other hand, it makes sure that the content synchronization results in a network which behaves like in elastic cloud way. So do the auto scaling. Now I realize that the incentives for retrieving certain content takes care of only those cases where we talk about depths like the typically popular content that you want to distribute and you want people to reach. This is not all the cases.
00:12:52.366 - 00:13:33.198, Speaker B: We also envision swan to be used for cases where you want to store and actually make sure that your content is stored, even if it's very seldomly accessed. For example, a birth certificate. And we realize that this incentive that we are talking about is not handling that properly, among other things. It's because it's a very different type of a reward mechanism. Because here you actually want to make sure that my birth certificate is available. I don't want to pull it all the time because it's anyway insecure and inefficient if I always receive it. So it's a different system it needs.
00:13:33.198 - 00:14:02.140, Speaker B: There's a lot of discussion about this. I'm not going to go into that. I just refer to the documentation and like the kind of orange paper that we are in the middle of writing for this discussion. The main point is that one type of incentive that we do talk about can appropriately handle the incentives for retrieval. And basically which also translates to.
00:14:04.030 - 00:14:04.298, Speaker C: The.
00:14:04.304 - 00:15:20.450, Speaker B: Pricing of bandwidth, basically because that's what it does, as opposed to like disk storage. Now for this we are using the swap system, which swaps just is a kind of fun that you basically swap payments and service. But on the other hand, it's also an abbreviation of swarm accounting protocol and some other things. And the way it works is that basically it allows you to account for in general kind of any commodity class that can be quantified and has certain other properties that you can use this for. In swarm it's used for the accounting of bandwidth. And in swarm you use a checkbook contract on the blockchain that allows you to do delayed payments that this system uses. So it's basically it's a micro payment system in which you use pairwise accounting for peers where they can exchange one unit of service from one unit of service.
00:15:20.450 - 00:16:41.454, Speaker B: So if they consume and provide the same amount of service, then their balance hovers around zero. Obviously there can be things that if I work at night and the other person download films in the day, there can be vast differences in the utilization over time. So for these cases, basically when the balance tiered towards one particular peer, then the peer is obligated to send the compensation, which is an off chain delayed payment. In this case it's a signed check, the signed check. This type of offline payments can be verified offline, but in order to redeem the amount that they are about, you need to transact with the blockchain and the transaction cost is burdened on the recipient, which means that they are incentivized to delay cashing it and thereby save blockchain time and blockchain cost. And also they are indirectly incentivized to watch all the kind of aspects of their peer which make them trust them more so that they can delay the payment even longer. So basically it incentivizes the emergence of a reputation system in a way.
00:16:41.454 - 00:17:52.206, Speaker B: And that's also possible because the checkbook contract is basically historical. It's a credit record that you have. So basically at the end of the day, this system can allow to trade reputation for some sort of upfront deposit and most importantly can incentivize the retrieval and correct working of the network. Now just a quick summary before I give it over to Daniel who will talk about the upper layers and some of the applications for Dapps. So just to summarize. So basically swarm is defined more formally as a protocol, the Visa Z protocol, which is kind of a mix of several different aspects of the system. So basically it's also a protocol for peer selection and peer, basically bootstrapping your node and connecting with others in the network.
00:17:52.206 - 00:18:28.800, Speaker B: It's also a protocol specifying the request forwarding and how the retrieval is and the routing works. It's a synchronization protocol and also it's a swap protocol. It's like the payment, there's maybe a fifth part which relates to the storage incentives that we don't talk about. That's also part of this protocol, the communication layer. And of course it's also defined by a set of APIs which are more related to what Daniel is going to talk about. So I give it over to him.
00:18:30.530 - 00:19:56.038, Speaker C: Thank you. So hello, I'm going to talk about what can you build upon the solid foundation of an incentivized chunk store. So once we have in place a reliable retrieval and storage infrastructure that stores fixed sized chunks, we can build web based distributed applications on top of those. And I'm going to talk about these possibilities and the APIs that we provide for application developers. So the most important I think is the HTTP based API which really acts like a locally running web server with the guarantee that the usual methods, the usual HTTP based methods are all efficient. So you can change single files, you can retrieve via range queries some portion of the file which allows for streaming, and you can change the content of your virtual web server, which of course raises the question that this whole thing is content addressed. So what actually happens when you change something? So here are a few URL examples.
00:19:56.038 - 00:20:53.022, Speaker C: In the first case you're accessing the raw API, which means that you're just downloading without any metadata, a large set of bits or bytes. And then the next one is a swarm site which is a root page of a web server. I actually have it here. Yep, so it's here. This is a photo album. So this is a photo album. And if you click around then you can see that there's a part of the URL which is just the fragment part, which is not a state that you want to share, it's just which picture are you looking at? So this is a state that only exists locally.
00:20:53.022 - 00:22:02.630, Speaker C: However, if you delete a certain picture, that means that as you can see, even the root has changes. And once you share this one, then the entire content changes. And if you rearrange the pictures or you upload the pictures, the exact same thing will happen, the root hash changes and therefore you can share that state with others. And you can do that through a name registry contract. So for example, this URL here, clipped wings, would be always the current state of this photo album. The nexus with Ethereum blockchain is first of all the swarm naming system, which is just a single contract where you can register root hashes for names. Then there's this content availability insurance where you can put up a deposit for making sure that a certain contract is certain content is available.
00:22:02.630 - 00:22:55.762, Speaker C: And if somebody challenges you by saying that this particular chunk that you promised is not there. Unless you upload that you will lose that deposit and possibly the person gets rewarded for the trouble. Then you can also store off blockchain states. So this refers a little bit back to the scalability talk. So one way of thinking about somewhat scalable distributed applications, given a traditional blockchain, is that you treat the blockchain as an arbiter of disputes. And as long as you don't have disputes, you don't consult the consensus, the byzantine consensus of the blockchain. But if there is a problem, a disagreement, then you resolve it through the blockchain.
00:22:55.762 - 00:23:59.354, Speaker C: And there are all these other things which kind of link swarm to Ethereum. So the distributed application, the photo album that I have shown, is basically the simplest distributed app because you have one producer, many consumers. So you kind of sidestep the difficult problems. There's no concurrent modification, changes don't happen frequently, and latency is acceptable. Like if others see your photo albums changes after a few minutes or even hours. That's not really a big issue. However, it's interesting to think about how would you go from web two to web3, like how do you build complex concurrent distributed applications? And we think, and we hope, that swarm as an infrastructure together with Ethereum, is actually suitable for this purpose.
00:23:59.354 - 00:25:35.722, Speaker C: So in case you want to do something like Facebook, where multiple users can comment on the same content, then of course you need to transact with the blockchain more often, and to query the blockchain more often to see what the actual status of a particular content is. And you also need something like whisper to distribute real time commenting information. Building an index of swarm, well, that's a really difficult task, and it's a topic for probably a separate talk or even a separate section. But the basic idea here is that you take the mapreduce paradigm with untrusted workers and you specify what they can and cannot do in a contract. And again, in case of a conflict, when they violate the contract, then you can punish them and otherwise you can reward them. Now, the other interesting cases, I think Wikipedia and OpenStreetMap, which are examples where the web two model doesn't really work very well and where we can actually substantially improve on the state of the web, because in these two cases, there's not a real world consensus about the content. So in Wikipedia you have anything related to recent history of conflicts, where there are editors and there are disagreements about what should be there.
00:25:35.722 - 00:26:43.730, Speaker C: And in open street map, it's a current question whether liberland is a country or not, and therefore forking these projects is not really feasible. So people try to do something like conservapedia, where they try to eliminate the supposed liberal bias from Wikipedia. But the problem is that they have so little content and it's so expensive to fork over content from the mainstream Wikipedia, that that project is simply unlivable. But with Swarm, what you can do is you can present different views to the same large body of content and simply mark up which point of view you would like to take. And it's really, really cheap to make slightly different versions of the same huge data set. So I think that in case of maps and encyclopedias, we're actually looking forward to something that is qualitatively superior to what currently exists in web two. So finally, I would like to tell you what of this exists and what's the status of this project.
00:26:43.730 - 00:27:57.286, Speaker C: So we have a reference implementation of. So this is an extension of the Go client get which has a HTTP, which has the HTTP API, it has the pairwise accounting. All of it works on small scale. We simply haven't been able to test it on a larger scale, and I'm sure that it would have some problems that need to be ironed out. So far it has been funded by Ethereum foundation and we have had a lot of community support as well. And here are the things that we are ready to demo. Well, not right now of course, but hopefully during this conference and in GitHub you can see the source repository, which is basically a fork of the Go Ethereum client with a separate branch BZ, where you can always find the current state of the BCC capable gas client.
00:27:57.286 - 00:28:16.140, Speaker C: And we are keeping it up to date with the upstream version of Go Ethereum. So that's where you find our source code and our documentation as well, maybe. Victor, do you want to say anything about the status? Okay, thanks.

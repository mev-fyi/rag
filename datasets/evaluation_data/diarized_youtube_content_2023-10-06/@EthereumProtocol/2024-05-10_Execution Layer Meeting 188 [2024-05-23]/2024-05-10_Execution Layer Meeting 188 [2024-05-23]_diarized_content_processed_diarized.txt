00:05:18.324 - 00:05:57.168, Speaker A: Welcome everyone. We're live for AcdE number 188. There was a ton of stuff on the agenda today. We'll do our best to get through all of it. I wanted to make sure there's a couple small technical things we cover at the very start so that if we get in the picture read for most of the calls we've at least gone through them. So Charles had a execution APIs PR that he wanted to get attention on. And then Peter had concern around the miner tip requirement as we can do the two of them.
00:05:57.168 - 00:06:42.818, Speaker A: And then last week all the l one client teams got together to work on Interop for Pektra, Pure, Das and Virko. So I've linked an update that we published on the agenda. I can give a couple minutes overview of what went down there and then most of the call. We have a bunch of petrol related things to discuss, so probably makes sense to start with where we're at on Devnet zero. There were some spec changes done to 29 35. I think everything's been merged now, but just want to make sure that we're all on the same page for this. And then a lot of the CFI then proposed Eips for the fork had some updates so we can cover all of those, specifically the account abstraction stuff around 7702.
00:06:42.818 - 00:07:20.386, Speaker A: I know there's like an in person event happening now that is discussing this too. So there's like a short window on the call where we can discuss this and then ref and the DevOps teams both shared what their preferences for the fork scope should be. So hopefully we can wrap up on that, see if we want to make any changes to Pictra scope. And then lastly portal network. So there were some discussions that interrupt about history expiry and if and how that would relate to portal. So Piper is on to give kind of a quick overview of where things are out there. Yes, to kick us off.
00:07:20.386 - 00:09:09.516, Speaker A: Charles, are you here? And if so, can you give a bit of context on the return data pr that you have? Excuse me? For context, my name is Charles, I'm the maintainer of the Viper language, and also I maintain Titanoboa, which is an interpreter for Viper and also a framework for deploying contracts and interacting with the network. So this I think is like a feature that every framework designer runs into, which is when you ask for ETh get transaction receipt, you don't get the return data. And so I made a pull request to the, what is this called? Execution API specs and to request that return data be optionally included in the receipt in the RPC call. I discussed this also with some people from ref, and they said that this can increase the base cost of the endpoint and it could. An alternative is to have a separate endpoint like ETH get return data, which gets you the return data, which is a new endpoint, gives you the return data for a transaction. And that also works. I'm not as big of a fan of it because there's some race conditions like you can get the transaction receipt and then there's a reorg.
00:09:09.516 - 00:10:09.786, Speaker A: So when you call ETh get return data, you get a different return data. Or there's other more practical issues like usually you're calling ETH transaction receipt in a retry loop, and then you finally get the receipt and then the server goes down, which is actually really common among RPC providers. So you get the receipt, but then you have no return data, and then you have to do another retry loop. And it's just a lot easier if you get everything back in one call. And yeah, I was wondering if I could get some feedback from client teams and figure out what is resembled improvement. Thanks. Anyone have some quick feedback on this? Dano Besu optionally stores the revert reason, which is basically the same data as returned data just on a failed call.
00:10:09.786 - 00:11:00.194, Speaker A: So it does have the wire to support it. But as is mentioned, it does take more storage data because you got to store all the return data for every single call. And so it is doable. But I'm wondering if the revert reason is a standard API, if that's just something basically did at a customer request years ago. Also, the way I specced it out is the client is allowed to return nil or null or whatever if it doesn't have the return data or it doesn't feel like recomputing it. So it's kind of a request to return it on a best efforts basis. And my hope is that eventually everybody would just start returning it, but there's an upgrade path.
00:11:00.194 - 00:11:56.082, Speaker A: Any other comments now or otherwise? People want to take this to the PR parody traces. These are non standard. I mean, right now what everybody does is like they either ask for the parity trace or debug trace transaction or ETH call resimulation doesn't work because you get the return data. I mean, the state could be different at the end of the block. So that's like a. Yeah, EtH call is like not correct actually, but yeah, the tracers don't work. They're not, or they do work, but every client supports a different version of it.
00:11:56.082 - 00:12:56.854, Speaker A: There's a lot of variation between clients in exactly how it returns it. And it again suffers from this race condition thing where you ask for the return data and then, sorry, you asked for the transaction receipt and then you ask for the trace and then honestly, God knows what you get back. And it's just not universally superior supported. Got it. Merrick? Yes. The problem is that clients do not store this data and clients have this data, but after a processing block and there is no networking, so we cannot simply add it as other fields, it would require consensus changes or our clients can store it after execution, but only your local client will have that when process the block. So I'm thinking about more effective way than debug trace transaction.
00:12:56.854 - 00:13:42.754, Speaker A: And what comes to my mind is as it was mentioned, if call or parity traces. So yeah, yeah, I understand that it's not, um, in the receipt database. Uh, so I guess clients would need to like store it in an auxiliary database or something. And it's like, yeah, right, not part of the consensus. Um, but as I already mentioned, there's like issues with the parity trace. Um, Sina says support adding TX level state for ETh call. That also works.
00:13:42.754 - 00:14:50.594, Speaker A: But my question is like why can ETH call return the return data but not eth get transaction receipt? Okay, I guess, yeah, we do have a lot of things to cover today. Does it make sense to continue this conversation on the PR? Because it doesn't seem like there's a clear consensus on like do we want to implement this and how? Lucas, you want to have a final, so why if call can return and get transactional receipt might have a problem. Because we are obliged to serve get transaction receipt, but we are not obliged to serve serve ETh call if we don't have the state. Right. So we might, if we prune those state already, we won't be able to serve ETh call. So that's, that's the reason, right, right, but, so that's why it's optional in the PR, the client doesn't can return nil if it doesn't happen. Yeah, we can take it offline.
00:14:50.594 - 00:15:56.904, Speaker A: Yeah, my question is like what can we do to like fix this? Because it's like a major thorn for like people who are using rpcs. So there's a good comment in the chat by my client around, just like trying to frame the motivation better in the PR because it didn't seem as big of an issue reading that on the call. So yeah, I think now that people are aware, if we can rework the PR a bit discuss this async there over the next couple of weeks and yeah, if we need to bring it up on the call again we can, but hopefully we can resolve this async. If I can have one last thing. Maybe we want ETF call but for traces that would only return this without doing the big tracing and returning bunch of data and just returning the result. Yeah, that was the alternative proposed by the rest team which is ethk return data and that also works. Although I put for the single call workflow, single RPC call workflow.
00:15:56.904 - 00:16:41.264, Speaker A: Ok yeah, thanks Charles for bringing this on. Next up, Peter, you had a thread around the minor tip behavior and I know there was a lot of back and forth in the chat or sorry in the agenda issue about this. Yeah. Do you want to give a bit of context on your original thread and then the conversation that happened? Hopefully Peter's. Yeah, Peter's here. We cannot hear you if you are speaking though. Oh I think now we can.
00:16:41.264 - 00:17:21.643, Speaker A: Can you hear me now? Yes we can. Okay. It's really weird. The microphone is using some other anyway hail. So I will be kind of short because I don't really think this deserves too much time. Basically the issue that was brought up is that Geth has pretty much since forever had this notion of controlling the minimum gas price that miners require transactions to have. And in the proof of work pre 1559 world that was basically all the transaction fees went to the miners.
00:17:21.643 - 00:18:24.564, Speaker A: And then miners just chose what they want as a minimum fee. Later, after 1559 was introduced, most of the fees were burned. But 1559 still has this notion of a minor tip or a priority fee which goes to the miner. And way back then the suggestion was that we should reduce the dip to something like one gigaway because that seemed fair. And basically everybody as far as ran with that and as time passed, merge came at some point, I'm not entirely sure when, maybe it was the merge, probably sooner or later there was some regression in get where this minimum tip enforcement was not passed from whatever subsystem to the miner. So basically this led to geth pretty much accepting arbitrary tips for transactions as long as they met the base fee, of course. And of course the tips were ordered by their magnitude.
00:18:24.564 - 00:19:23.940, Speaker A: So if whenever there was some big congestion, the higher tips always preferred. And probably because of that we kind of never really saw this bug, that smaller tips are also accepted. And a couple of months back when I was refactoring the transaction pool, I noticed that this tip wasn't really passed to the miner. So I fixed it and with the release, which all of a sudden again started enforcing the minimum 1 gw priority fees. Now the concern was raised that this one gigaway is inappropriate and it is causing problems for the network, which basically for this, my suggestion was that we should bring it up to at all core calls because, yeah, for me it was kind of a surprise. And the big question is that. So this is kind of a client specific configuration.
00:19:23.940 - 00:21:01.384, Speaker A: So any sign or validator can control this via CLI flag. And being just a client configuration, there's zero effect on consensus. However, given that there seems to be an effect on the network itself, I wanted to just bring it up as if the consensus is that this value is inappropriate for whatever reason, then we are more than happy to change it. And before I give the word to anybody else, just one more thing I wanted to bring up is that basically we can easily agree that enforcing one gigaway might be too big in the current climate where basically the base fee is around five gigaways, not proportional. So I don't really have any issues with lowering this fee. However, I kind of feel that having the local miners accept zero tips has a thorny other issue where basically MeV miners can take a zero tip transaction and they have a chance to actually get some money out of it. But naive local validators, or local miners do not have MEV extraction, so they can only really rely on the tips to have to mean it basically to have a meaningful reward for including a transaction.
00:21:01.384 - 00:21:50.654, Speaker A: So whilst I agree that we don't want to mess with market conditions, I think we also should take into account that local validators don't necessarily behave the same way as MEV extractors, and we should somehow pick something that makes sense for both the network's perspective, but also from a local block producer's perspective. Anyway, that's short thing, so thank you. I think Tomas has his head up first. I have two things, so I think it's totally fine for gap to set it one way. It's not unreasonable. I agree that it's clear. It was there, it was removed.
00:21:50.654 - 00:22:32.834, Speaker A: I remember that from the old times. And it's also reasonable for the local validators to have this set to one way and not accept zero g transactions, because then you can. Sure, I mean, we avoid spam because base fee is there anyway. But you don't justify the inclusion entirely from the perspective of whoever builds a block and they put some effort into building the block. Well, when they are validators, they are paid the reward for the block construction. So maybe they're justified for trying to include as many transactions as possible and clean the mempho. So those different views.
00:22:32.834 - 00:23:21.794, Speaker A: But I think still gaff can set the default, especially as this is just a default and you can change it to something else. I not necessarily agreed towards the negative sentiment toward the entire MEV construction in the context of this conversation, but this is broader topic and it might be that we just have slightly different definitions here. But yeah, I'm definitely on Peter's side, but not necessarily also would suggest other clients to apply exactly the same defaults. They may, it may make sense for another mind, but we shouldn't have this in the spec or protocol design. Thanks. Thank you, Peter. First, just one very, very quick reaction.
00:23:21.794 - 00:24:12.080, Speaker A: Basically, I'm not really looking to have a consensus on how all clients should behave. Rather, I would like guests not to do anything where it's obviously bad for the network. So it's like the consensus should only be on behavior that's kind of considered healthy for the network, not further specifications. Got it. Anzgar yeah, specifically on that point I wanted to say that I don't think that the arguments I saw them in the kind of discussion in the issue for today that the concerns around the network health I don't think are valid. I think basically Geth having a one way or whatever they want default is fine for network health. I just wanted to find out because Barnaby couldn't be on the call today.
00:24:12.080 - 00:25:03.784, Speaker A: He looked into this a while ago from an economic point of view, and I'll post his write up in the chat where he was basically arguing that the rational long term outcome would be for, even for solo builders, to set the minimum as low as possible. So like more one way than one way. But again, I think defaults are not hurtful in this case. If Geth wants to choose a higher default, I think that is reasonable. The only thing I would say in the past with proof of work, the tip was used to also basically account for the timing problems that would be caused. You would release the block, it would have more chance of being anchored like now with the slots, if you build at home, if you still build a block, they aren't really these timing concerns anymore. They're only really for me extracting builders.
00:25:03.784 - 00:26:09.274, Speaker A: So the cost for the builder are lower now. So basically you'd only have to account for that little bit of extra compute that you're spending on building the blockchain. There might be an argument to at least lower the default below one way, but I don't think there are any network health concerns. Thanks, Lucas. So from the network perspective, I don't see how if like, let's say 80% of network is building with MEV, how setting this in clients would help with the network, it will then cause even more of these small blocks followed by full gas blocks from the MEV builders. So unless we get MEV builders on board or we do something in protocol, then I don't see this as being helpful to the network in any way. Got it.
00:26:09.274 - 00:27:35.904, Speaker A: Fabio. Hi. So my point is that I would like to see some research on the effect of changing this, even if coordinated way, or just by the stakeholder that decide which is the value to set. Seeing that, because I see some possible side effect on this. For example, the impact on the burning of the base fee, since could be that there will be less burned fee as a result of users switching to some of the value of the base fee as priority fee. So there will be more inflation in this case, and also any case since you have also, if the transaction has zero priority fee, it will reduce the amount of the currencies. So like to see in case, if there are any study about which will be the provision about that.
00:27:35.904 - 00:28:42.246, Speaker A: Thanks. So I don't think it's related, like, I don't think addressing if and how the base fee gets burnt is kind of related to this. Because if we, if we send part of the base fee to the miner, it's just like saying, you know, the base fee was that amount lower. And just from like a conceptual perspective, thinking of the tip as this is what the miner gets is, you know, it's probably the best way to do it. And so, um, yeah, it does feel pretty unrelated to, like, how much we burn because. Yeah, yeah, if I can quickly explain better, I mean, if someone has a target spending three gigaway, if we set the priority fee to be one gigaway, they will, instead of using a bc of three gigaway, they will use a bc of two gigaway and a priority fee on one gigaway. And so there will be less burnt fee.
00:28:42.246 - 00:29:23.124, Speaker A: This is one of the possible outcome. I'm not sure of it for this. I would like to see some research about that. I think there's already a fair bit of research. I can maybe pull it off after the call, but when we were working on 1559, we did have a lot of research around, should we give the base feed to the miners and if so, how much and whatnot. So at this point, I'm pretty convinced that whatever we give to the miners is effectively, you can think of it as just having the base fee being that much lower and it just makes the base fee a less reliable oracle for like supply and demand. Yeah.
00:29:23.124 - 00:30:35.458, Speaker A: So, yeah, I think, I think it is valuable to like agree on what is the standard tip that we send? And do we want to standardize that regardless of whether that tip comes from the base fee or if it comes from like the priority fee? Yeah, Ben, I think you have your hand up. And Peter, the suggestion on the base fee is because then that's enshrined in the, you know, that's already the oracle price in terms of it's still going to be whatever it's going to be. And then you can have the priority fee be. That is a priority. Yeah, sorry, that's all. I mean, I don't mean giving all of the base feed, but just like 1% or something, which would encourage the miner to include transactions in the block because it's going to be hard otherwise. That's the whole reason we effectively have the priority fee is to separate those two concepts.
00:30:35.458 - 00:31:21.834, Speaker A: And the way it's exposed in the transactions is we say, what's your priority fee? What's your max fee? And the max fee is effectively what you're saying. The max fee is like how much is a user willing to pay for their transaction to be included? And then the priority fee is how much are they willing to send to the miner and to get back the difference. If the base fee is not high enough, but the max fee per gas is effectively this value already. Yeah, yeah, but the miner is getting what, 160 fourth of the block reward for building and the. Yeah, that's a different thing. Yeah, yeah. So you get more for testing than block building, but you do get the priority fees on top.
00:31:21.834 - 00:32:49.480, Speaker A: And if it's not an enshrined that it's higher than zero, then since most of the blocks is Mav, and Mav does get a value for it, most of the transactions will become zero fee transactions. No, because different builders compete through the relay to send the block. And I think so the question is, given that because we have external mev, builders can effectively create these zero tip blocks that pay the validator through some other way, do we want to enforce a minimum on the network even if it breaks with this mechanism? I think that's the point Peter was trying to figure out. Even if it is possible to still pay the miner a different way, should the clients have a minimum and if so, what that minimum should be? I don't know. Peter, does this represent your concern correctly? Yeah. So basically, if you want to push this issue to the very limit, then the worst case scenario that can happen is that let's say the base fee goes up and there aren't enough transactions to fill a full block, but there are multiple zero tip transactions. So basically transactions that pay the base fee, but transactions that give absolutely zero to the miner.
00:32:49.480 - 00:34:08.500, Speaker A: Now, is the miner expected to include those even though it gets absolutely nothing for it, or is the miner not expected to include those? And this is kind of a philosophical decision, because from our perspective, from the miners perspective, why would it include anything that pays exactly zero? And from a ethereum network perspective, I mean what's the harm in cramming them in if they fit in? And that's why it's not really a very, very clear cut scenario. And that's why personally I'm leaning towards having a default that's permissive enough to not cause any issues, but not too permissive to really go to this extreme. So I have a few comments, maybe Peter, for you directly. I think that I see some potential negative effects of that if you take some assumptions. So imagine that everybody runs gaff with this setting, such as default. One way they didn't change it and there's no mev. Then it means that practically moved one way of base feed to the priority tip, which simply redirects the burn to the validators.
00:34:08.500 - 00:35:08.024, Speaker A: It's not necessarily valuable problematic, but it also doesn't feel like it makes sense. Now assume that there is 80% running geth nodes with this setting and 20% running the other client as solo validators with zero set. Then it means that the get validators actually decreasing are decreasing the propagation of the transactions that the other validators consider as valid because the gaff notes will be discarding those below one k transactions from the network and other validators will have less chance of getting the valid transactions. That is not the case. So way way back that was the case that gas transaction pool was linked to the fee that the miner was doing, but currently it is not linked. So currently, basically our transaction pool is enforcing one way to avoid spam. Other than that, basically everything gets propagated independent of what you set your miners to.
00:35:08.024 - 00:36:20.114, Speaker A: But the problem is that I think that even if this is not happening, then imagine that all the gaps are running with one way default and 100% of the networks is gas. Then there is potentially attack attack on the network when you fill the transaction with the with the zero priority fee transactions that are not discarded by Gav but never included by the validator in the block. So you have practically, and you can set them in a way that they seem like the best paying transactions in the sense of max, I guess, because the best paying transaction is the priority fee. So GATT will get transaction pool always orders everything by the priority fee that it actually pays. So everything addressed. Thanks. Okay, so I guess it seems like people are generally fine with guests selling the amount that it wants, even though it's not zero.
00:36:20.114 - 00:37:13.320, Speaker A: And yeah, I think this one probably makes sense to move on to other topics. But is there any last. Yeah, last comments on this? I guess my takeaway is that if there's no, nobody sees really a very hard reason for setting it to zero, then we will probably think about this a bit and either set it to zero zero one or zero zero. Basically either 100 or 1000 of a gigaway. I'm not entirely sure which one the idea is to be. Basically want a good enough default and then clients can just go wild or node operators can go wild on top. Yeah, that makes sense.
00:37:13.320 - 00:37:57.460, Speaker A: Thank you for your time. I think. Yeah, maybe one last thing on that. There were these analyses done during 1559 about what the amount should be based on the unco rate and whatnot. So obviously it's probably much lower post merge. But I assume you can do a similar analysis where how much the incremental gas usage creates a risk of being basically uncooled and that might be a way that you can set the value. Yeah, well, personally I would pick a much simpler heuristic, basically saying that if below some number, basically it just doesn't make sense to have a transaction.
00:37:57.460 - 00:38:24.584, Speaker A: I mean, if a trend, if adding a transaction is going to pay you 0.00 $0.01, then yeah, it just doesn't make sense. So I think we'll try to pick a number where economically it's not a rounding error, it's something that's meaningful and then people can go from there. Got it. Perfect. Yeah.
00:38:24.584 - 00:39:08.594, Speaker A: Thanks for bringing this up, moving on, because we're already kind of late in the call. I won't spend too much time on this, but we did have an interop event with client teams last week. I posted a recap of it on the awkward dev on the Ethereum foundation blog and then link this on the awkward apps agenda. Yeah, there was a lot of product Chris made, non defnet, zero vertical, Pierre Das and a bunch of other things. We'll discuss those topics specifically throughout this call and others. Yeah, I think probably makes more sense to just dive into Petra directly than I discuss Interop. Unless there's anything else people want to bring up about it.
00:39:08.594 - 00:40:08.114, Speaker A: Okay, so next up, I guess on the picture front. So on Devnet Zero, we did launch a first version of it during Interop. Yeah, it's someone on the DevOps team here to give a quick update on this. Yeah, so we launched Devnet Zero during Interop and I linked the spec sheet for Devnet zero on the in chat in a minute. We have all the clients joined in, but there have been some changes that were already proposed for Devnet one. So we haven't done intensive testing on, for example, 3074. And we should discuss probably we will be doing that async as to all the change sets for that will be active from Devnet zero to Devnet one and then do a relaunch once clients are ready.
00:40:08.114 - 00:41:20.014, Speaker A: There's one active bug that still needs looking into and fixing, but otherwise the network has in general been stable. Awesome. Any other comments? Thoughts? Okay, so yeah, talking about Devnet one, it probably makes sense to discuss just what we want the scope of spectra to be, updates on the different eips, and then that will kind of lay the groundwork for Devnet one. One of the things that did get a bunch of changes during Interop was EIP 29 35, which, especially with regards to the block hash opcode, it seems like everything has been merged, but were there any outstanding questions or concern around 29 35? Okay. Okay, great. So then I think that was the only one with like significant spec changes that happened during interop. 3074 and 7702 is kind of a whole different EIP, so we can discuss that separately.
00:41:20.014 - 00:42:25.364, Speaker A: And so. Okay, on the topic of like stuff that's been CFI'd or proposed for the fork, one of the big ones is EOF. So there's been an update shared on that as well, basically by the solidity team that they would support it. And Ipsilon shared a proof of concept for solidity to support it. Does anyone on the call have any questions, comments, concerns about EOf or any specific updates? Do we have anyone from solidity here? They said that they had it ready or that they would be supportive rather of the, of Daniel. The solidity lead posted in the R and D discord earlier today that their team was very supportive, but I don't think that he can make it on the call. Yeah, I pasted the message in the agenda, but let me just paste it in the zoom chat here.
00:42:25.364 - 00:43:02.476, Speaker A: Yeah, this is Dan O'Faran. Sorry, my Internet literally just went down, so I missed some conversation. But the numbers that I, that the ypsilon team put up are better than the numbers I saw. With what solidity had for the big EOF, I was seeing three to 5%. We're seeing 6% code size reduction and call gas usage down by 9%, which is bigger numbers than I was hoping for. So I guess, you know, once again we're asking for be included in Prague. Bernie Sanders, thanks.
00:43:02.476 - 00:43:49.914, Speaker A: Came from the red side. I can speak on all progress from the cast side. Yep, we had an issue. Basically we, I implemented a non optimal algorithm for the stack verification and I started implementing the new algorithm. But that also means that basically most of my progress is moot. So I start in new. It's almost implemented, but it pays like basically like half of the test.
00:43:49.914 - 00:45:03.364, Speaker A: The spec still isn't in the place where I would say it would be easy to implement for someone that starts from nothing. I think at this point no other client starts from nothing. So basically everyone has at least something implemented. For us, it's still a pretty long way to go to be future complete. But even then I'm not super convinced that our implementation is actually correct or will be correct, because it's such a huge change and has a lot of edge cases. And as I said in the, during interrupt, I only implemented it like I just took the spec and tried to implement it. I have not really thought about what I'm actually implementing.
00:45:03.364 - 00:46:23.418, Speaker A: So from the breakout rooms I was in also the one yesterday, I believe it feels like the, the Epsilon team and Charles and I guess Dano have really thought about the implications of changing the opcodes in the way they are changed, so. But yeah, I don't at this point I cannot say if this is like if they missed something or not. At this point, I kind of have to believe them that they made the right decisions for all of the changes that they are proposing. It kind of depends on when we are trying to schedule a petra, but from my point of view, adding EOF would definitely delay the PCR, for which I don't like. But that's just my personal opinion. That's it. Thanks Charles.
00:46:23.418 - 00:47:35.624, Speaker A: Yeah, I assume this is right at the EOF. Yeah, I posted my kind of current position on EOF in the Ethereum magician thread. Basically I've been helping out, contributing to the spec for the last year or two, and I'm supportive of anything that improves EVM execution. There's a couple spots in the spec which I think could still be improved if we had more time. I think that the format would be improved if we use variable length quantities, which I've been going on about for the last few months because it's more future proof. And I guess the consensus currently is that, you know, we don't have enough time to change the format at all and kind of just want to, you know, make it known that I raised this as a concern so that when we can't or it's hard to like upgrade UF to allow larger code in the future. Yeah, it could be an issue.
00:47:35.624 - 00:48:37.134, Speaker A: The other thing is that UF by design, which is it's a bit deeper, Uf by design doesn't have the same global code section design as EIP 2315. So it necessarily forces the compiler to make some trade offs. And with some recent improvements to the. The validation and also spec, they're not that large, but they are trade offs. And I think ideally this could use some more thinking. I also think that EOF is nice, like quality of life things, a lot of really nice quality of life things. I think that solidity is seeing, you know, really good improvements, partially because Uf has things that are specifically or, you know, kind of targeted towards solidarity's cogent, actually.
00:48:37.134 - 00:49:36.924, Speaker A: And my position is I think it would be nice to have a dedicated Uf fork or something so that there's a little bit more time to finish some of these things. I also think. Dano, I see your hand up and I'm guessing you know that, you know, I can already hear Denno saying, you know, we don't, we can't get everything perfect and we need to ship it. But I think that user safety, and I've been pushing a lot on recent ACD calls for either non re entrant opcode or improvements to transient storage pricing. And these are user safety things that I think should also be in Petra. And if there's a conflict between these, I would prefer to see UF go in its own fork and we're able to get transit storage pricing improvements sooner. Thanks.
00:49:36.924 - 00:50:19.616, Speaker A: Yeah, I know you have your hand up, but I do want to make sure we get through the rest. And assuming we move forward with EOF, we'll discuss the specifics later. The other big one that's been heavily iterated on in the past couple of weeks is EAP 7702, which is meant as a replacement for 3074. So 3074 is still sort of what it's officially included in the fork. But it does seem like there's been growing consensus around 7702 from both the people who supported 3074 and the people who had issues with it. Yeah, I don't know. Ansgar Vitalik, Lightkind, the three of you have been working on this.
00:50:19.616 - 00:50:59.124, Speaker A: I don't know if either of you can give an update on where things are at. Yeah, can take it from there. Yeah, I mean I can give a quick update. Just so basically there have been some discussions over the last while it interopened in different other places on the Internet as well, and there's been some iteration on the EAP. I think right now Lightclient has a pr pending with updates to the eap. I can link that in chat in a sec. Here we go.
00:50:59.124 - 00:51:46.828, Speaker A: Basically, I can briefly go the cant variant of the IP. So basically you would specify the address of the limitation you want to use for your account in the transaction body, not the code itself. You would also sign over that address. It would not run any init code at the beginning of the transaction, just copy the code in that address. Over chain id would be possible to specify, but optional. Nonce would be possible to specify, but optional. There would be no opcode restrictions, including no restrictions on self destruct, and including no restrictions on storage rights, meaning that storage would also be persistent after the end of the transaction.
00:51:46.828 - 00:52:56.584, Speaker A: And for now there would be no initial permanent upgrade capability. So no flag or anything from the start, at least to have the code persist in the UA after the end of the transaction. Although of course the idea would be to add that at a later fog, there have been like, some of these are pretty uncontroversial, some other ones are still like this pretty active conversation on. I'm not sure to what extent it makes sense to have that conversation live here on all cordefs, but so basically, for example, to mention draw from the 437 team, I've seen be quite vocal about saying that we should have chain id commitments be mandatory instead of basically optional. And also I remember having some conversations with the Aragon team specifically around them, preferring to have a more explicit split of versions that are revocable or like basically are committing to nonsense. Id was the ones that are not. So we could basically have two completely separate signature types, one of them basically for a version that is with nonce and with train id mandatory, and one version that is basically completely without nonce and train id.
00:52:56.584 - 00:53:36.004, Speaker A: That way we could have a more clean split. So these are like still some of the questions that are a little bit in flux, but we are overall converging more and more into like a specific version of the CIP. Yeah, that's kind of my take. Thank you. Anyone else have thoughts? Oh, Andrew. Yeah, that's what we discussed at the interop. So there are several scenarios how this IPP can be used.
00:53:36.004 - 00:54:59.854, Speaker A: If it's a milestone towards permanently migrating to a smart contract, then it makes sense to have non revocable signatures. But also this heap can be used for more ephemeral things like batch transactions or sponsored transactions. And in that scenario you want to play safely and have revocability. So yes, we discussed with NSCAr, it would be good to have two types of signatures, like one very generic without nonsense chain India, and the other with chain id and nonce to separate those two use cases. And I think I would replace 3074 with this 7702 in pectra, but I would only certify it until we kind of we agree on the revocability design. Because to my mind that's very important and I don't want to commit to this eap like 100% until the revocability question is resolved. Thanks Ahmad.
00:54:59.854 - 00:56:07.494, Speaker A: Yeah, just to clarify, when he said version signature, because Marius asked on chat this means that there will be two magics for this type of message and message signature. One magic will mean that it has a nonce because nonce cannot start with zero, whereas the other magic will have no nonce. So one magic with nonce, non magic without nonce. So if someone wants to sign something without the nonce, they can do that. And if they want to specify the nonce, they can do that as well. With chain id, we decided to go with zero for not specifying a chain id and a number for specifying a chain id. This gives maximum flexibility to the developers to implement multiple patterns at the same time allowing the user to have all the security guarantees that he like the users that they would like to have on their accounts.
00:56:07.494 - 00:57:14.180, Speaker A: Yeah, thanks Daniel. Yeah, I just wanted to add something to what Andrew said regarding the revocability. So I initially was also very much against not having revocability in the EIP. But after some feedback from the metamask team, it seems they feel confident that they can still manage the security of the user funds without it. So they, for example, are talking with other wallet providers to implement some sort of like a permissioning system. I think they also want to do something like adding like modular permissions on the, I think similar to force 367. So before we are adding maybe more complexity, complexity to the EIP, but adding more functionality, we also should seek feedback from the wallet teams if they think that's a good idea or not, or if this is something that they will use.
00:57:14.180 - 00:58:15.084, Speaker A: Because the worst case would be that we are adding complexity to the protocol, and afterwards nobody is using it anyways. So I think we should do this first before we make decisions on our own. Got it. Thanks, du vitalik. And then Andrew again. Yeah, I mean, I think one important consideration to keep in mind is that a lot of the revocability and chain id considerations regarding 7702 are extremely similar to the ones for 374, which makes sense because the whole design rationale for 7702 is to basically be a something that provides the functionality that's very parallel to 3074, but in a more like smart, contract, forward compatible way. And so given that, I think it's just valuable to remember that, like, there has been existing discussion about trade offs that has very similar reasoning.
00:58:15.084 - 00:59:42.060, Speaker A: And like, the switch of EIP is that we're pushing is not a reason to, like, restart that discussion from zero. And there is value in revisiting things that have already been discussed over the last couple of years. Yes, Andrew, do you have another comment or is your hand still up? Yes, I do. So I totally agree that we should check with wallet providers feasible and for them, and they're happy with it. But I am a bit worried that if we decide to rely on exclusively on wallet providers for revocability or whitelisting or whatnot, my preference is to have something built in the protocol instead of relying on only relying on wallet providers. And can you, can someone please remind me what we did for 3074? Like, did we not have this trust assumption? All right, okay. They're not synchronous.
00:59:42.060 - 01:00:59.774, Speaker A: Got it. Thanks, Derek. Yeah, so I think in 3074, like the last finalized, the last finalized version says that every time you increment the nonce, you'll be revoking all outstanding auth messages. Right. But I do want to remind everyone that in our last call, and also just like in all the conversations that happened since the last call, I think all the stakeholders, all the relevant parties, whether it's the core devs or the 437 authors, or the wallet teams such as Metamask, as well as the four through seven account builders such as myself, I think we are all aligned, that it's very important to support the longstanding authorization use case. It's very important to make sure that it's not the case that every time the user makes a transaction, that all outstanding revocations, all outstanding authorizations will be revoked. I think everyone has already aligned on that, whether it's in the last call or in the subsequent online conversations, that it's very important because some of the most powerful use cases of account direction.
01:00:59.774 - 01:02:27.760, Speaker A: What is like, like adding new signers to your accounts or whether it's things like transaction delegation, permissions, session keys, those all depends on having a way to keep authorizations alive despite the user sending transactions. So I think the only thing that we are not aligned on right now is the mechanism that enables that. So I think there's proposals for things like introducing like a max nonce mechanism, or like there's the proposal that I think that mat made in the latest updates about introducing optional, basically just making nons optional. So personally I'm fine with whatever, but I just want to stress again that all the relevant stakeholders have already expressed that it's very important to enable the longstanding auth use cases. Thank you. Let's do Vitalik and then Eric. Yeah, I mean, I think this is starting to get a bit zoomed in, but one thing that's important to also think about is like there is a particular way of using 7702 that a lot, some people have in mind for some of these long standing things, which is basically that wallets only ever sign one message where the one section message is permitting a standardized proxy.
01:02:27.760 - 01:03:35.836, Speaker A: And then the intention is for like any use case that's not like literally ephemeral could just be built on top of that and the proxy would have its own upgrading mechanism. So I think one of the side questions that's worth discussing is basically like to what extent there is, there is alignment on that approach, right? Because, you know, if there is, then like, yes, like making unrevocable, like complete unrevocability becomes something that's much safer. But then like if not, then there's more discussion. But I mean, I think in general, right, this is definitely starting to get into some of the rabbit hole areas. And so I think as a meta point, like realistically it's, this stuff is going to get resolved through like one or two breakouts and not through like getting everyone to agree on things in the next five minutes of this ACD. Yeah, I think I would agree with that. I guess one thing.
01:03:35.836 - 01:04:14.216, Speaker A: So I think, yeah, one thing is we should schedule a breakout to like get this resolved. It is worth highlighting that if we can't get to a solution, then the status quo outcome is we don't ship anything. So I guess, yeah, maybe one thing to figure out is just when we want to have this breakout. I know there's some in person meetings happening in the next week or so on this stuff. So if someone who has context on the whole 7702 discussion can propose some appropriate times for a breakout on discord. That would be great. We should ideally have a final spec before the next awkward devs.
01:04:14.216 - 01:05:54.344, Speaker A: I think if we don't, then it becomes very hard to actually include this in the EIP and then. Yeah, there's two comments in the chat now about this. It seems like everyone would be in favor of swapping 3074 for 7702 assuming we have a final specific. I don't know if we're finalized enough to include 7702 in implementations now, but does anyone oppose removing 3074 CFI 7702 and then on the next call we can potentially include 7702 if we have a spec and yeah, I guess to Ansgar's point, we sh, okay, so people would rather not remove until we switch over. And I guess the, yeah, I think it was Aragon who raised the concerns with the revocation, like on your end, Aragon, would you prefer to like include this, include this and remove it at a future date if we don't find a final specific so that we can actually get started on the implementations? Yeah, from my point of view, it's fine to CFI it and start working on it and include it into the next Devnet, but yeah, I mean, if we fail to find a solution dramatically. Yeah. Then later we should exclude it.
01:05:54.344 - 01:06:58.140, Speaker A: Okay, so I think then what this would look like is we CFI 7702 included in Devnet one and then remove 3074 and assume that. Assume that, yeah, we can figure out the issues with 7702 for now. Yeah. Okay. Actually, there's a final proposal by Justin is like, keep both right now, is it simpler for client teams to keep both in the next Devnet, or is it simpler to just do 7702? Yeah, okay, well, I guess, yes, let's move forward with 7702. So, yeah, so just one small thing. We didn't actually test 3074 and definite zero because Perry forbid me to do it because we were so afraid that the definite will completely break.
01:06:58.140 - 01:07:51.020, Speaker A: So I would propose removing 3074 so we can just go wild with the puzzle and test. Okay, so let's do that. Let's remove 374. I had to nerf my, oh, sorry. Were you gonna say something else? Nope. Okay, remove 374, add 7702, have, yeah, have that part of the next Devnet, and then if, and create basically, basically have a breakout in the next two weeks to iron out the spec issues. And I think, Ansgar, to your last comment, and based on the Aragon stuff, it's probably similar to you, CFI 7702 and then include it once the spec issues are finished.
01:07:51.020 - 01:08:51.964, Speaker A: But we also have it as part of Devnet, one that feels like the best compromise to move forward, actually get the work done, and also make sure we have a final spec that people are happy with before we commit to it further. Anything else on this before we move forward? Okay, thanks everyone for all the thoughts and comments here. So please Ansgar, like clients, someone else figure out the time to schedule the a breakout or the 7702 breakout based on the burn in meetings. But we should aim to have all this wrapped up before the next all core devs. Yes. Okay, and then there's three other eips that had updates that are a bit shorter. So if we can get through those in like five minutes, hopefully we can then spend some time discussing the fork scoping.
01:08:51.964 - 01:09:35.608, Speaker A: So 7623 Tony, are you on the call? Yes, I will be very quick. So 7.623 the latest update included reducing the gas cost from 1248 to 1040. This would mean that even less users are impacted talking with people, it feels like there is some demand to ship that in Paktra. Maybe we can do that already in the next definite because it's a rather small change. There were some discussions on Eve magicians, so Martin from Geth also voiced that concern about this weird market that it might create. But yeah, we could resolve those those concerns.
01:09:35.608 - 01:10:10.134, Speaker A: And Martin is now also for the eap. Awesome. Thanks. Any question? Otherwise we'll move on to the next one. Okay, the other one is 7212 the rip eip with the r1 precompile. I forget who was supposed to give an update on this. Hello, I will give the updates and I will be very quick and I want to remind the current situation about the rip.
01:10:10.134 - 01:12:02.314, Speaker A: As you remember the first the IP has moved to an rip status and be implemented by some of the roll ups and it has been CFI'd to acds before and I will be talk about the current roll ups that implemented and also talk about the current client implementations. I'm also posting at the chat recently Polygon has gone to mainnet with this pre compiled contract and the casing is on Testnet and will be very soon on Mainnet and in optimism and op stack roll ups including base and Kakarot ZK EVM has merged to their repos and arbitram is on governance to implement the proposal in the next hard fork and in the client implementations get ergonom, Besso and jet client implementations are ready and polygon and the other optimistic prolapse are using this reference implementation. Ergonom is following his implementation and also used it on the polygon and I have just seen that as a draft pr about the issue and I think it's also ready. And great implementation has been worked on Ethereum fellowship and I guess it's also ready. And I have just seen that Naturalmind team is currently working on this EIPN. I am not aware of any implementation in Ethereum J's and that's all I want to mention for now. And if there are any questions about current status or CFI states, I would love to answer them.
01:12:02.314 - 01:12:46.278, Speaker A: Okay, thank you. Okay, and I guess last one was Ssiz. I don't think Etan is on the call, but he posted. Yeah, he posted an update on the agenda. I don't know if anyone has any questions, comments about it. Yeah, Kayman, I can just. Yeah, I think this makes sense to discuss more in the context of increasing the scope or not increasing the scope of the fork.
01:12:46.278 - 01:13:19.922, Speaker A: So I think we should delay that discussion until then. Okay, so I guess, yeah, that is the next thing on the agenda. And maybe to start this. So I know Rhett put together a document with a bunch of different options and then the DevOps team as well. So maybe, yeah, maybe. Brett, do you want to start? And then we'll hear from DevOps and go from there. So I'll share the doc and the zoom chat in case people haven't read it.
01:13:19.922 - 01:14:20.484, Speaker A: I would appreciate if people would have a chance to read it the next time we have such conversation. I'm trying to answer three simple questions, which is when do we ship prag? If we ship prag later on, should we extend the scope? And B and C, if we choose to extend the scope, what should we include? I think the first topic that I would like to discuss is should we ship it 2024 or should we ship it Q 120 25? In my experience, people haven't been shipping hard forks in November and December in particular, because in December people go on vacation, and this time because people, people will be in Devcon. And my understanding was that people don't want to be doing work while they're at Defcon. Now, I don't know. I'm just raising that into presence. I know that we ship when ready. That's how definitely we ship.
01:14:20.484 - 01:14:56.594, Speaker A: So if people are down for that, sure. But you know, like just bear that in mind. And my understanding is that indeed people don't want to be fixing a consensus issue at Defcon. So I'm just caveating that. And beyond that, my thinking is that if we were not to ship it in 2024, basically, if there is any kind of scope change allowed. There is room for one very, very important thing that is peer desk. I'm not an ACL developer and we don't run a Cl team.
01:14:56.594 - 01:16:07.988, Speaker A: We do know that demand is arriving, and we do know that the El and Cl updates are coupled as EIP 4844 is defined right now. What does this mean? It means that there's no room for a Cl, only hard fork from the El because the El has a constant that says a blob count. So if you want to do a blob count increase, you need to do it on the Cl and the El. And that's a problem. The final thing on why I think on why period is important here versus just increasing the blob count is that and somebody from CL should confirm that. Is that due to how 4844 works and how blobs and the block proposal or attestation are coupled, there's already high bandwidth requirements, so there's some blocking that happens during the Cl process. And even if you increase blobs, you wouldn't be able to have a solo staker or a low resources node operator to be able to not miss slots.
01:16:07.988 - 01:16:39.498, Speaker A: So it seems like a problem in any case to increase blobs. And it seems like it's worth including peer desk to get around that. And to the extent that we do that for Cl, it gives us plenty of time to also do it on Yale. And in that case, there's a question of, okay, what should go then? And then we would pitch the scope for EOF, which we think deserves a whole conversation for it. And we wish we had time. So that's where we're at. So the TLdr is let's ship Craig in Q one.
01:16:39.498 - 01:17:07.604, Speaker A: On the Cl side, let's do peer des. On the el side, let's do EOF, including whatever else we've talked about for 7702. And I would love to also hear the EF DevOps take on this. From our point of view, small fork is kind of a meme. I don't know that this has happened properly ever. So it seems worth being present to that and not saying it as something we could do. It seems worth being very explicit about what our expectations are here.
01:17:07.604 - 01:18:12.298, Speaker A: Thank you. And yeah, before we hear from the DevOps team, I will plus one, the small fork comment, there's a couple chat comments like we can do just a quick fork with peer dos and EOF before Osaka. Then we should just call that thing Osaka and assume that we've agreed to do more work and separate it into a separate fork. And if it ships quicker, great. But it's probably a bad process to assume we would only do this work if it's quick fork, Barnabas, or Perry from the DevOps side. Yeah, I can go. So we've also posted our thoughts on what the fork could look like, and I think one of the differences is that we just wanted to define all of the options that we thought were viable, and then towards the end, just specify which option we prefer, but also want to caveat that we as a team could not even come to consensus as to what option we prefer.
01:18:12.298 - 01:19:02.014, Speaker A: So, yeah, take that with what you will. I'll just start with a bit of thought and concerns that we had, as well as counterpoints to them. The first one is that right now we've been looking at most eips as just testing the single EIP. We haven't necessarily looked into testing the edge cases of one IP, with interactions with edge cases of another EIP. A simple example is where changing how deposits work, but we're also changing what a validator is with Max EB. So we're going to have to stress test both of those edge cases in combination and not just in isolation, so that, I imagine, would increase the scope of testing. But one of the points that Pawam made as a counterpoint to that is that irrespective if we ship it together or if we ship it separately, we're still going to be doing edge case testing.
01:19:02.014 - 01:19:47.694, Speaker A: So it doesn't make a difference if it's in one fork or over two forks. I think me personally, I would prefer it in two forks purely to reduce the risk, but I think that comes into the mega fork versus the smaller fork discussion. Again, another point that we wanted to bring up was that in all of the discussions so far, we haven't included Eip four four. I don't know what the status is of that, if it's happening fully out of protocol, if there's some sections in protocol and out of protocol. And I think we also should be aware of how many research efforts we have that we want to ship. So if there's a subset of the team working on four four, a subset working on work or subset working on pure Das, that's a lot of subsets for small teams. Yeah.
01:19:47.694 - 01:20:34.670, Speaker A: And like Anska said, we just wanted to put all the options out there and see what people thought and then use it as a starting point for a discussion. Yeah, thank you. This is really helpful. Yeah. Any other teams aside from DevOps? Rhett, has thoughts on how we should approach this from the Ret side, we generally defer to the DevOps team as the testers here. Yeah, I think we've said we've shared a view in writing. In general, I would say that EUF as it stands now, could be even shipped in 2024 because it took just two months to implement it.
01:20:34.670 - 01:21:32.174, Speaker A: I know there is a lot of testing needs to be done, some of the tests already written, but EVM as the component that's well defined, or they have testing suits and frameworks that we can reuse. So I think the framing that UF is the big change and will take like a year to implement is not correct, because I heard some discussions that relate to that. So I don't know if it's like a year, but there's some comments by guess about, like, it would not ship in 2024. And I think, yeah, like, obviously we have many clients, but like, yeah, we have many clients and we need kind of them all to ship the fork. So, yeah, so I think we should assume if we do eoF, then we are probably delaying pass 2024. And it's great if we are quicker than expected and we ship in 2024, but usually we're actually slower than we expect with these things. Andrew.
01:21:32.174 - 01:22:19.374, Speaker A: Yeah. So I think if we include EOF into pectra, it will realistically delay it by maybe three months and. Got it. But I'd like to say that it's better if we decided either on this call or the next one, because we need to plan our pack to work, so we shouldn't, like, prolong it indefinitely. The decision. Yeah, thanks. Just said for discussion, both the get and ergo, don't have implementation.
01:22:19.374 - 01:22:52.120, Speaker A: So it's just estimation that they're giving that's going. That UF is going to push Prague for 2025. It's like, it does increase the scope, but in my opinion, it's not that big. Got it. The Zoo Jasec and then Guillaume. Yeah. I just wanted to mention two things.
01:22:52.120 - 01:23:47.054, Speaker A: One is for a stable container, which basically, the way we were thinking about it in Kenya was that we could introduce it for the things that already change. This would be good for users because they, like, they only need to perform one smart contract upgrade and then in the future they can have their proofs and everything forwards compatible. So that's kind of like a stable container, light way of including it in Vectra for four. Four s. The way I think about it at least, is that a lot of it, we can ship without a hard fork, including experimental test nets and things like this. So I think it's worthwhile to start working on it now. Ship the parts that are shippable without a hard fork.
01:23:47.054 - 01:24:28.764, Speaker A: And then when it's stable, we can formally, like, include, you know, user documentation, basically that the network, all the nodes on the network will no longer be holding block history. Got it. Yeah. Guillaume. Yeah, that's actually not a bad eof. I mean, I do think, like the rest of the guest team, that is going to push stuff to 2025. Traditionally, we have done the testing, but I would say that's not a reason per se to stop eof.
01:24:28.764 - 01:25:30.494, Speaker A: The question I have is something you said, tim, did you just say that you were already considering moving Osaka? Yet another. Sorry, Roko. Yet another fork. That's something that was clear from what I said, is that if the decision is there should be a fork after Pektra that has peer Das and EOF, we shouldn't call it Pectra two and lie to ourselves that, like, it's a quick fork and we're going to be able to ship it in two months, we should assume that it's going to be another full fork and the consequence will be delaying verkle. Yes. I think this is like the failure mode we get in when there's more stuff we want to do than what we can actually do. So we try to squeeze things between two forks, but effectively they are two real forks, and the naming should reflect that rather than making us feel better that it's only Pectra two and it's not actually Osaka, in practice, it's another fork.
01:25:30.494 - 01:26:02.556, Speaker A: From what I understand from Perry's proposition, at least, proposal. Sorry, is that he's talking about a seal only fork, which could perfectly cohabit with Verkle. And so whatever doesn't make the cut in Prague should make the cut in Amsterdam instead. Sure. Like, yeah, yeah, whatever. I guess my point is much more, if we have something on the EL between now and the next fork, we should just call that the next fork. It doesn't matter, like, you know what it is.
01:26:02.556 - 01:26:35.382, Speaker A: We just shouldn't, like, assume that we can just sneak in, like, mini forks between forks, because that's just realistically not going to happen. Yeah. Andrew and Alex. Yeah. I think between Verkle and EOF, I think verkle is more important. And we already committed to shipping Verkle in Osaka. So if we don't include EOF into pectra, I don't think that we should have kind of a pectoral tool fork.
01:26:35.382 - 01:27:30.266, Speaker A: Then we should postpone eof to Amsterdam. Thanks Alex. Yeah, sorry if the mic is a bit noisy. It's kind of connected to what Andrew said. I kind of feel like this group on all codevs has maybe a tiny bit less visibility on the application layer and what kind of benefits people using the EVM could feel with something like UF. Obviously all the discussions here are extremely important and tackle different parts, but I kind of feel like maybe the visibility of developers experiences is less understood by this group. And I do have a question, because I kind of feel like what Andrew said.
01:27:30.266 - 01:28:16.424, Speaker A: If EOF right now wouldn't be included in Petra, then I don't really see that it would ever be included because then having another fork with EOF, there wouldn't be just like a one or two or three month delay to backtrack. That would be a full fork with, you know, however many months that takes. And that in that case that would extremely delay Varco. Because of that, I kind of feel like this is the only opportunity to really introduce UF, maybe at the cost of one or two or three months delays. I don't think it would be introduced otherwise. And we, and I do feel that we have really good momentum right now with all the implementations. So it feels like this is the correct time to do it.
01:28:16.424 - 01:28:38.244, Speaker A: I think that's my summary. Thanks. I do. Yeah. Okay. I do want to make sure we keep at least a couple minutes for Piper so we can do Guillaume and then Marius and then wrap this up and have you a few minutes to at least talk about the history expiry. Yeah, so I'll be quick.
01:28:38.244 - 01:29:07.830, Speaker A: I think doing like, it doesn't matter when you do eof either. EOf is important and adds value, which I think it does. The rest team, for example, in Kenya has made a fairly compelling point about what they want to do to achieve with it. So I don't think that if you don't schedule uf in Prague, it kills Eof. Because if that was the case, then Eof is pointless, which I'm convinced it's not. Thanks, Marius. I wanted to say exactly the same thing.
01:29:07.830 - 01:30:04.234, Speaker A: If we, if we think this is the only, this is the only time that EF can ever happen, then it's not a good feature and we should just drop it. Like, there's no point in shipping something if we don't, if we're not convinced that we can also ship it six months later and it's still important. So yeah, do with that whatever you want. But I think. I also think UF is a good feature and it should be shipped at some point, I do like the thesis of doing it on l two s. First they can do it right now because they have the code, because we are writing the code for them. So I don't really see the argument of tools cannot build this because we basically built this for them already so they could roll it out if they wanted to.
01:30:04.234 - 01:31:00.056, Speaker A: Okay. I guess it does, yeah. It doesn't seem like we're going to resolve all of this in the next two minutes. I think, as I said in the chat, like pure Das feels like the most significant bit here. And it'd be valuable to discuss on the CL call next week how we want to prioritize pure Das and or just like a normal blob increase and then kind of structure everything else based out of there. Assuming we do that, it would be really valuable for teams to think through the different options that the DevOps teams put out and other options, potentially, of what they want to prioritize, so that on next week's CL call we can make a decision about pure Das blob counts and whatnot, and then use this to inform what we do on the El side. It does feel like, you know, there's not a burning desire.
01:31:00.056 - 01:31:42.464, Speaker A: There's not like the same level of urgency, I guess, on anything El related than there is on potentially the blob count. And. Yeah, Georgios Dragon, if you can put your comments in the chat, just because I want to make sure we leave at least a couple minutes for the history expiry stuff. Yeah, sorry about that. But yeah, TLdr, I think teams thinking about this in the next week, discussing on the CL call next week specifically related to peer Das and what that implies. And then two weeks from now on Acde, we make a final call about the scope of pectra from the El side. And in the meantime, teams can obviously work on Devnet one, which would include.
01:31:42.464 - 01:32:45.276, Speaker A: Which would include the same Eips as we had modulo the 3074 7702 switch. Yeah. Piper, everybody. How's my mic? Great, thanks. Been playing catch up this last week since I wasn't there for the breakout on four fours and history expiry, been looking over all the notes and documents and trying to find out what happened there and what El teams are interested in. We're excited to collaborate with you guys on this. In the notes and things that I've seen, I've seen a lot of description of a minimal portal spec, and I'm curious if anybody has anything specific that they've identified in our spec that they are, you know, wanting to cut out, and I haven't gotten anything specific yet.
01:32:45.276 - 01:33:37.614, Speaker A: And if there isn't anything specific, I'm wondering if we can stop using that terminology. I'm pretty sure that our history specification does exactly what you guys want it to do. My questions, I guess, are kind of like, what do El teams need from us to move forward with this? We're definitely, like, here and ready to answer questions, ready to show El teams around that sort of thing. There's documents posted in the History XB channel on the R and D discord. I encourage you guys to take a look at those. If you're on an El team and you're going to be heading up implementation of this, I encourage you to come say hello to, you know, our client teams and things like that and introduce yourself. Let us know what team you're working on or what client you work on.
01:33:37.614 - 01:34:35.084, Speaker A: And we are having an in person event next week in Prague, May 28 through May 30. And if you are going to be diving into some of this stuff and you are able to make it to that, it would be a great way to onboard fast. If you'd like to come, please dm me on Telegram or wherever and I can get you guys added to that. And I know we're mostly out of time here, but if there's any questions or anything around this that anybody wants to raise, I'm here for that. Thank you. Yeah, we are already a minute past time, but, yeah, Jasek, and then, Andrew, we can do your comments and then wrap up. Yeah, so when we talked about minimal, we talked about the block history and not so much the other components like client and state.
01:34:35.084 - 01:35:24.944, Speaker A: So that's what minimal refers to, like block history. So we already do this in our specs, and so there's nothing that actually needs to be cut or changed for clients to be able to implement only history. So that is supported in the existing network and client designs. Yeah, and the discussion was mainly around the, like, client protocol as well, whether that is the dependency or not. And it's not really from an execution client's point of view. It's more if you're running a full portal node that doesn't have access to any other consensus mechanism. Thanks, Andrew.
01:35:24.944 - 01:36:16.932, Speaker A: Yeah, I just had the same comment as that we want some kind of mini portal spec for block history only because, as I understood, Vitalik's worries that we don't want to rely exclusively on archive nodes for block history. So as far as I understood, the idea is that non archive nodes commit to store a certain chunk of block history via the mini portal. Cine yeah, our specs are history data like the history network is history data only. There is no minification that needs to happen here. We don't do transaction hash lookups in that network. It is strictly block history. And to the best of my knowledge, it does exactly what you guys want it to be.
01:36:16.932 - 01:36:53.324, Speaker A: So we can keep talking about it. But the concept of like a minified version of the spec, I'm wondering if we can drop that language unless somebody has something specific in our specs that they've identified that is extra. Looking forward to answering more questions. We're here and ready for it. We got a network ready for you guys. So we already kind of have like a networking layer. And as far as I understand, portal is built on a different networking stack.
01:36:53.324 - 01:37:37.646, Speaker A: Do we need this different networking stack to be implemented in full nodes in order to join? Or would it make sense for portal to adopt the current networking stack that we have? Portal does not work on dev p two p. You need a DHT for this. And that is why we've built on the networking stack that we have built on. Building it on a fundamentally different network stack is going to require somebody to come in and solve a whole bunch of problems. So if somebody else really wants to do that work, they can, but that isn't portal. Thanks. Okay, I think this is a good spot to wrap up.
01:37:37.646 - 01:38:06.728, Speaker A: We're already a few minutes over time. Thank you, Piper, for coming on. Thanks everybody for all the conversation. And again, I'll emphasize like, please try to think through the scoping for the fork in the next week so that we can have a good discussion on pure Das and everything else on the Cl call and then finalize the scope on the El side on the next acde. Yeah, that's it for today. Thanks everybody. Thanks everyone.
01:38:06.728 - 01:38:09.024, Speaker A: Thank you, Tim. Thanks everyone. Bye. Thank you.

00:05:50.450 - 00:06:30.060, Speaker A: Okay. Hello everyone. Welcome to Acde one six seven. So a couple dencoon spec updates clarifications today. Then there are some questions around some engine API prs for the Devnet eight. And then we had two people with new ips they wanted to present. And to wrap up, Guillaume and Josh have a big vertical update to share sort of what they've been doing over the past couple of months.
00:06:30.060 - 00:07:23.400, Speaker A: But yeah, I guess to start, there were three PR comments for 4788 and I guess, yeah, Martin, you put up the first. So do you want to give some context on that? This is PR 7431. I think I saw Martin on the call. Hello, can you hear me? Yes, we can. Right. So about 47 81st of all, I made a suggestion. Let me see if I have the PM somewhere here, just so I remember what it was about.
00:07:23.400 - 00:08:19.260, Speaker A: So the first one was like the history storage address. It has mount zero. First of all, we discovered this problem that due to the definition of empty, the beacon root stateful precompile storage was wiped at the end of every block. Because emptiness does not require an empty storage route, the definition of emptiness does not care about what the storage looks like. So that's kind of wonky. And I proposed one fix for that, which would be to set the nons when we set the storage, check the nons, if the nons is zero, then set it to one. That's kind of a neat way to solve it.
00:08:19.260 - 00:09:22.480, Speaker A: Yeah. Then while we were kind of investigating that, some other people got their eyes on 47 80 and there was the question raised if we should turn it into not being a pre compiler at all. Is that something we want to discuss now or is it something we should postpone to a later point? Can I ask you a question about the first? Yeah, let's do the first. Yeah. And then we can discuss the precopal. Should this actually be conditional, and if so, should there be tests where it's already non zero before the fork, like it's nine on mainet, we will only ever have it be zero once, and then it will forever always have to be one on testnets that people might spin up. They can set it to whatever they want.
00:09:22.480 - 00:10:07.232, Speaker A: It's a very simple thing to get right. I'm not concerned about it. And if we get it wrong, it might screw someone up on some very strange private network. Okay, but there should be probably a test case where it's non zero and stays non zero. Yes, sure. Okay, I do think, yeah. So the question of do we want to even make this a pre compile is something we should discuss now, because if we want to make this decision, it feels already pretty late to make like a significant change.
00:10:07.232 - 00:11:25.988, Speaker A: So yeah. Martin, do you want to share rationale behind that? Give a little heads up, and then perhaps, I don't know if Pablo is on the call or someone else who can give it their thoughts about why they don't want stateful pick and price. But first of all then I think the question was raised a long time ago by Axic. At that point in time, the EEP looked very different and then the EEP evolved and now we're at the point where the whole of the pre compile could just be replaced with a regular contract. And the only magic that will be needed from the client consensus point of view would be that the system makes a call to it at starter block processing. The EEP already today contains pseudocode that says what this precompile is supposed to do, and now all of us client implementers have taken it and implemented that in our respective languages. Guess did it go? And other people will implement it in other languages.
00:11:25.988 - 00:12:24.392, Speaker A: I noticed yesterday when I was comparing them that our implementation was not according to spec. That would have been a consensus issue and we need to write tests about that. Yada yada. If we instead have taken the pseudo code and put it into solidity, it wouldn't have mattered. From a consensus point of view, it wouldn't have mattered if there was one such type of error, because from the client developer's point of view, it would all have been an opaque black box. We would just call it once on the block processing with a fixed amount for gas, hope that it does its thing correctly. And for a consumer's point of view, people who write contracts that actually want to use this beacon route, it does not matter much at all for them whether it's a pre compile or whether it's regular contract.
00:12:24.392 - 00:13:34.870, Speaker A: The tangible difference, I guess, is that if it's a pre compile, we can decide arbitrarily that hey, the gas should be 4200 or whatever. If it's a contract, it's going to be a little bit of change. It's going to be a few more opcodes for the logic, and it depends on a bit on there's going to be a bit less around number, but otherwise no difference. I think that going with the regular contract increases the security. I mean it decreases the complexity of implementation, so it lessens the risk of a consensus split. And in a separate it way, I think decoupling pre compiles from I'm not having stateful pre compiles makes easier for plugin architectures such as Aragon and EVM one, but I'm sure someone else can talk about that more than I can. So that's it for me.
00:13:34.870 - 00:14:11.570, Speaker A: Got it. Thanks. Lucas, do you have your hand up? So if I understood correctly, that would be at the end of the block, we will call this kind of special transaction that would update the contract as the EEP is currently specified. To do it in the beginning of each block. On the beginning of each block, we would call this special transaction that would update the contract. Yes. So it's more of a special call rather than an actual physical transaction in the block, right? Yes.
00:14:11.570 - 00:14:58.336, Speaker A: I mean, it's. Semantically it's a transaction. Yeah, it's a transaction, but it doesn't emit any receipt and things like that. Okay, give me a second. But I just wanted to mention that's already part of the currency, regardless of it becomes a pre compiled or it becomes not. And what about gas metering of this transaction? So I suggested, when I just suggested we could then change that, we would just set the gas to like 100,000. It's not going to be near that because you're going to do two.
00:14:58.336 - 00:15:31.380, Speaker A: Two storages. But this gas wouldn't be counted for blog gas in any way. No. Okay. And that's the same. I mean, there's no difference between the current way the EEP works and what I propose because this system calls goes outside of gas. Okay, so just FYi, this sounds very familiar to what aura consensus introduced as system transactions.
00:15:31.380 - 00:15:58.370, Speaker A: This is basically the same thing. It's implemented currently in Nevermind, Aragon. And I know that Gilam is working on GEF implementation of this thing to work similar to support this. Makes sense. So we have been using that for years now. So it makes sense from the decoupling perspective. I totally agree.
00:15:58.370 - 00:16:41.568, Speaker A: It has its own drawbacks, because now there's something like shadowy going on that updates the state, but it's not visible, but it's similar as it would be implemented in the code. So generally I don't disagree. Makes some sense. Just a bit funny that we are porting this potentially to the original Ethereum from my side. I think actually it's not that funny. Of course you can consider it funny, but I think the original source for this is e 210, which Vitalik proposed back in 2017 or 18 to use this exact mechanics for block hashes. So it's before my time.
00:16:41.568 - 00:17:22.648, Speaker A: Yeah, makes sense. And it's fairly easy to implement from our so and some clients have already similar mechanisms, so it's doable fairly easy. Powell, you have your hand up? Yes. Can you hear me? Yes. Okay, so one comment to what was said about the technicalities, how the system call works. So I think there's also like special address where the call comes from. That's a way to identify the system is calling a contract from inside the contract.
00:17:22.648 - 00:18:34.230, Speaker A: I'm not sure this aura thing is similar, but yeah, it's interesting that it kind of converged the similar design so common from my side as a kind of EVM maintainer. It's also simplifies stuff on the testing and implementation because otherwise you need some special data structure somehow to transfer this data, what the pre compiler would have to answer to users. So we need to have this data somewhere and either you need to get it from some API or whatever. Right. And the same for testing. If you consider like we have a JSON structured test, you need to extend this JSON format to also somehow encode this data. The precompile might be asked for if all goes to state, and if all of that goes to state by a regular call, then there's not really need to do anything.
00:18:34.230 - 00:19:51.590, Speaker A: And yeah, the second comment I will just repeat, we kind of translated the pseudocode from the spec into EVM bytecode. So I think that's much easier to consume by the implementers as well. When you say the pseudocode from the spec, you mean the current spec? Yeah, I mean the current spec, yeah, that would be kind of replaced with EVM, something we probably will need to use high level. But in the end, the bytecode only matters that has to be deployed. And I think it will be even less complex than the current pseudo code because pseudocode, for example, has to handle ndns and conversion between different types and whatever. And when you specify it with the EVM inputs and EVM opcodes, it's already kind of. Sorry, what did you say? Martin? So the pseudocode allowed a lot of you into big endeavor conversion, but when I moved it over to solidity, all of that just fell away.
00:19:51.590 - 00:20:41.362, Speaker A: There was no need to worry about it. It was a bit like end code turned out in my eyes, simpler than the pseudocode. Got it. Danny? Yeah, I think this is a very fine direction. I just want to understand at this point in the process what the security and kind of overhead of the process would be. Right. If this were written today and we have bytecode, how do we get comfortable with the bytecode? We need to have a test suite which runs independent of say, the hive et cetera.
00:20:41.362 - 00:21:27.950, Speaker A: And we probably want a handful of, probably EBM experts to be doing review. When we did something like this for the deposit contract, we also formally verified the thing. Granted, the deposit contract handles capital, whereas this would not. So I don't know if that's requisite, but the process of doing this is not the process of doing hive and tests and things. So we have to define what the process is and how long it's going to take and what the overhead. One thing on that is if we deploy it and it breaks, we'd have to wait till the next hard fork to redeploy something. So it's not like there's zero cost.
00:21:27.950 - 00:21:49.542, Speaker A: Yeah, it's like instead of a consensus split, you get a broken opcode. Sure. Yeah. You don't actually get a broken opcode because there is no opcode for it. Sorry. You get a broken system facility that people use like the feature breaks. Yeah, people want the feature.
00:21:49.542 - 00:22:14.660, Speaker A: And so if we deploy something and the bytecode has worked, then they lose a feature. Yes. And that's the difference between you're taking either a consensus split or you're taking a potential broken thing. Yeah. And me as a client, I know what I pick, but sure, I understand your concern. Arguably it should be easier to get it right once. Yeah.
00:22:14.660 - 00:23:03.794, Speaker A: This is also a very actually simple contract. It does not have a lot of state, it does not have a lot of paths, and as you point out, it does not handle huge amounts of money the way the deposit contract. Yeah. I don't know what process we need to follow with this. I'm open to suggestions, I guess. Alex, I know you've talked to a lot of the potential users of this. Do you think from their perspective it matters? No, I mean, I think some of them have started working against the current EIp, but this is a pretty small change.
00:23:03.794 - 00:24:06.134, Speaker A: And to be clear, I think this makes a lot of sense. The main thing is interface doesn't change. Well the address would change, but yeah, otherwise it's pretty much the same. And then my bigger thing with this is just if we want to keep this in EB, then we need to figure out the testing security or less informal verification story ASAP, I guess. Fortunately we could get a bytecode that works into testnets very quickly, but simultaneously we need to be doing kind of a rigorous testing and analysis and review of that bytecode. So we're not blocked on switching to this very quickly, but we simultaneously need to be doing a verification of it. Yeah, I don't think I mentioned it here today.
00:24:06.134 - 00:25:19.110, Speaker A: But what we could do then is we could deploy it with create two. We could deploy it across all networks. We could deploy it on Mainet long before Cancun, and anyone who wants to can audit it and test it and check it on Mainet. And then what happens in Cancun is just that we bless it, we start invoking it by the system. One more comment on system transactions from me that I remember when implementing them, all the gas related things like there are some gas checks, like subscribing the value for the gas, for example, or refunding it was a bit problematic to implement it correctly, that it wasn't that easy. It's easy to make a consensus error implementing that. And something real quick on what you said, martin, I had assumed incorrectly that you just intended at the fork for a bytecode that exists kind of written into the EIP to be deployed at a certain address.
00:25:19.110 - 00:26:16.702, Speaker A: You're saying instead to just manually deploy. Yes, and I'm saying that what happens in Cancun, the fork is just that we start invoking an address and hope that everything is in place. I mean, we don't really care if there's anything there listening, but we do invoke. Why not have the fork deploy the bytecode and not have a manual dependency? I guess obviously additional complexity. But then you know that it's like self contained and it works independent of human activity. I just think it would be nice to remove it from the EEP and not have it be part of the consensus. Right.
00:26:16.702 - 00:27:06.400, Speaker A: I guess the EEP just has like kind of a dependency on a human, and you have to write it under the EEP at that point. Yes. Before x human must deploy bytecode with interface. If you're on a network and no one has deployed it, then you won't have the feature. If you decide to deploy it, it will start functioning because the system will, if you do deploy it on the system, then the system calls will start functioning. Yeah, I understand that, but some of the, like what happens to the failed system call that isn't doing the right. So I might put someone must deploy before and then sidestep those questions.
00:27:06.400 - 00:28:01.428, Speaker A: Anyway. Anvar. Yeah, I was just wondering, because the only thing that would worry me in general, I think it's a good idea, the only thing that would worry me a little bit is kind of potential conclusion delays. So just be curious. In my mind, it's mostly the system transaction, not so much that the contract code itself, because we could basically have audits and everything running in parallel, as long as they finish by the time of the artwork we're basically good. But with the system call, obviously Netherlands has something implemented that could probably be adapted more or less as is. But it just maybe would be nice to get some sort of feeling for how confident the other clients would be that this would not add significant timeline delays in terms of testing over it and everything.
00:28:01.428 - 00:28:45.090, Speaker A: Because that's like the one big unknown for me in my mind. Yeah, I agree. Do any of the client teams want to share maybe how they think this would affect their cancun development? I talked a lot. Someone else want to go, but I guess just to confirm, do you feel like forget this won't meaningfully change the development timeline for Cancun? Yes, I do. Okay. It will remove some complexity. It will remove one of the pre compiles.
00:28:45.090 - 00:29:30.714, Speaker A: Yeah, I don't think it's going to be a problem time wise to implement this. Got it. Yeah. Did anyone from BSU say anything about perhaps no one is here? Yeah, I think when we talked about this earlier, we talked about this ahead of some of the. Certainly ahead of the contract option. So it's not something we really have any consensus on right now. Personally, I think that sticking with the pre compile option is going to be better self contained and easier to reason about in terms of delivery.
00:29:30.714 - 00:30:46.974, Speaker A: But it's not a strongly held opinion for us. We can definitely deliver it. There are some quirks around gas economics for this call and like AAP one five eight for the system address, things like that that other clients would have to accommodate too. I think Ericon also implemented that already, so they should be fine. Yes, we have an implementation for system transactions or system transactions used for gnosis chain, so we can implement this one especially. I think the bulk of the work will be informalizing system transactions and ideally we should get it. There should be no discrepancy between Ethereum mainnet and gnosis chain or like aura stuff.
00:30:46.974 - 00:31:32.590, Speaker A: That would be perfect. Okay. And so it seems like Danny and Alex would rather have the deploy of the contract part of the EIP. They sort of keep it all self contained. So part of the hard fork activation. If we went that route, does that significantly make things more complex? Because then the hard fork logic needs to include a contract deployment. I also just worry in testing, like in hive and testnets and stuff.
00:31:32.590 - 00:32:38.268, Speaker A: For example, even if we're doing like Deneb and post Dankoon testnets in the future. Now we have to figure out is that bytecode deployed at Genesis who's deploying it seems to bring like a whole thing to have to think about in any testnet in the future. So it adds one quirk, though, and it's the same quirk as with this nonsting. And that's why I maneuvered around that by doing it the check every time, however. So if we do the code, if we configure that cancloon happens at zero, block zero, and there is nothing there into Genesis, then we create block one. So it's just. Do we then deploy the thing before processing? Yeah, it becomes a bit of, we need to do it correctly when we do the deploy.
00:32:38.268 - 00:33:10.590, Speaker A: If it's at block zero. Right. But if it's part of the EIP specification, it can be at fork block, which is block zero before you're doing anything. You essentially deploy bytecode and then it's self contained and we never have to think about it. Once you get the logic right. Once, yeah. And what if there's code there? Well, you put it at an address that is essentially reserved, like a pre compile.
00:33:10.590 - 00:33:51.200, Speaker A: But it doesn't have to be a pre compile address, it could be any address. Would we be able to use the same logic we're using for the deposit contract on testnets? We currently just hard code what the storage encode needs to be at an address we decide. And this is in the Genesis JSon. Yeah. So if we do the manual kind of thing, then it's going to look like the deposit contract, and it's just going to be something that needs to be baked into tools rather than something that's baked into consensus logic. Got it. At least from a testing perspective, this is super easy because we've basically set it up such that everything inherits genesis from this one tool.
00:33:51.200 - 00:34:55.570, Speaker A: I know Hive is different and antithesis is different, but. Yeah, I'd let Mario speak for Hive, of course. But for testnets, it should be a super easy change. Yeah, I guess if the decline somehow makes it so that the code appears automatically at the allocation before starting the test, that will be very helpful for testing because otherwise we have to hard code it into every single test somehow before starting. For this, the main issue would be the theorem test type of testing, where we do some pre allocation. So we have to pre hard code the code before each test. But if the client itself does it at the hard fork and the code appears where it has to be, that will be very helpful indeed for testing.
00:34:55.570 - 00:35:55.140, Speaker A: Also, to Paulo's point, that kind of, if we deploy to the same address everywhere, it has a certain implication on tooling if it's deployed ad hoc. Depending on network, then it has a different implication on tooling. The tools that want to use this, the libraries that want to use this have to be configured per network, whereas the other, they're just kind of configured singularly. Yeah, I can go with either. I don't really have strong opinions about this, so I guess. Does anyone still feel strongly in favor of the pre compile, or. It seems like we've slowly shifted to how we do the normal contract rather than defending the pre compile.
00:35:55.140 - 00:37:08.810, Speaker A: But is there anyone that thinks that we should stick with the pre compile? I know Besu mentioned they have like a weak preference, but aside from Besu, did we agree on how to trigger the contract from the system standpoint? Yeah. Like does this account against block? Is this a transaction? Does it come from something? Does it have a terran transaction hash? It comes from a special system address, it does not count towards the block gas and it does not emit any receipt. I think that's okay. And so does that function have a conditional like assert must be from system address and otherwise it fails? Or is it. So in the implementation that I wrote, yes, one of the looks at system address and decides the path, and one which actually uses four bytes. It's easier, nicer for addressing better ux. We'll decide, I guess, in the coming days on which one we prefer.
00:37:08.810 - 00:38:58.720, Speaker A: Thanks for posting the yeah. In terms of getting to a final decision on this, it seems like it's probably worth discussing offline a bit to work through the details of the spec, but at the same time it'd be nice to not cause huge delays over like, do we think it's realistic to get to the call, the Cl call, I guess. Do we think it's realistic to either have a decision and people agree by Monday on the testing call or the Cl call next week? I think if we need longer than like a week to agree on this, it's probably a sign that it's too long. Okay, Alex says decide by Monday. Does anyone think that's unrealistic that by Monday we can't have a okay, yeah, please. I was going to say if we wanted to move on to Devnet eight without 4788, which is not the current discussion, we need to think about how that impacts the consensus layer, test and release and stuff. So I prefer to try to just get it sorted.
00:38:58.720 - 00:40:04.688, Speaker A: Okay. And so the things we need to figure out by Monday are, one, do we put this as part of the hard fork flow, or do we have a manual deploy? And two, what contract we want at the very least, to start with, this is a bit more of a reversible decision, but it would be good to align on the deployment flow and the deployment flow, our preferred contract. And I guess to also have at least a pr to the EIP with the proposed changes. Yep. Yeah. Okay, and what's the. Is there a channel that should we just use like awkward devs or interrupt to discuss this, just so everyone sort of goes to the same spot? I don't think we had a channel quite for this Eip here we've been talking in testing.
00:40:04.688 - 00:40:32.812, Speaker A: There's EVM testing, sorry, execution layer testing. Okay, so yeah, let's keep using that then. Testing channel. We have many testing channels, but. Okay, so under the execution layer category, the testing channel. Yeah. So maybe we can summarize a bit.
00:40:32.812 - 00:40:45.568, Speaker A: Yeah, so we're going to need the nonsting no matter what. Right. So we can go ahead and merge that EIP. So this is Martin source pr. Right. The one that. Sorry, exactly.
00:40:45.568 - 00:41:17.130, Speaker A: It becomes moot. Well, you could still deploy this and someone could delete it. Right, right. But then if there's non empty code, it's not considered empty. Right? Yeah, for Devnet eight. Because do we want to start with Devnet eight with the current version with the pre compile or do we want to wait until the new CSYS address is called? Yeah, I think we would try to wait. Okay.
00:41:17.130 - 00:41:53.240, Speaker A: So yeah, I mean, unless someone else wants to. I can make a pass and update in the IP like today and or tomorrow. So I think by Monday it'll at least look clear what to do. And then separately there's the testing nod being front, but I think we can have the actual functionality pretty quickly. But I just want to understand what we're all agreeing to. So if we're sure about the code thing, then we don't need 7431. And then, yeah, I can update the ip with this bytecode approach.
00:41:53.240 - 00:42:22.430, Speaker A: Sounds good. I can work with you on that. Okay, great. And one other thing. There was another pr to this EIP to handle the Genesis case, which I think most people saw, but I just wanted to call it out, the one that Tim put in chat. And then. Otherwise, I think that's it on 4788.
00:42:22.430 - 00:43:30.054, Speaker A: Okay. And then. Yeah, so for Devnet eight, it seems like we also agreed to wait until these changes are done to deploy to Devnet rather than deploy with the current version and change it. Does that make sense to everyone? Okay, anything else on 4788? Okay, next up. So last call we discussed the exceptions, edge cases to the self destruct EIP. And so after checking with the l two s, there's no l two that breaks based on the change. So I believe optimism is the only one that uses the burn.
00:43:30.054 - 00:44:05.570, Speaker A: But they call it inside of a contract creation transaction, so they're, like, unaffected. It still works under the new logic, yeah. And, Daniel, was there more that you wanted to cover beside this? No, I just want to do a last call. If anybody knows of any other change that we need to look at. I looked at the ones off of l two b. Like you said, optimism is the only one that uses the burn. The other ones either just use exactly what's in or they blow up on.
00:44:05.570 - 00:44:56.730, Speaker A: They don't implement self destruct or they revert on self destruct. Polygon ZKM, changed it to send all, but that brings them out of the EVM compliance. So I'm not too terribly worried about accommodating them based on the spec because they're already moved off the spec. Got it. Any other thoughts, comments on this? Okay, I guess we can merge your clarifications to the EIP. Dano? Yeah. Anything else on self destruct? I think that's it.
00:44:56.730 - 00:45:46.380, Speaker A: Cool. Okay. Yeah, and Mariel says that all the tests are implemented with the clarifications from PR already. Okay. Anything else on the eips themselves for Denkoon otherwise, there's some engine API stuff, but on the eips themselves, any other comments, thoughts, concerns? Okay, so, Andrew, there were three engine API prs that you mentioned were not merged, and we were not sure if we wanted them in Devnet eight or not. So they're in the agenda. But the first one is adding blob gas used and blob gas price to the receipts for 4844 transactions.
00:45:46.380 - 00:46:40.572, Speaker A: Second one is four two six, which clarifies the Cancun payload ahead billing. And then the third is just a rename of data gas to blob gas. They're currently all listed in the spec, but they're not merged. I guess given especially we have this extra delay or short delay due to the pre compile change. Does anyone see a reason to exclude any of those three from the Devnet? Because it would potentially delay things or introduce logics that we don't want to test quite yet. If not, then I think we should. Okay, so we should keep them on.
00:46:40.572 - 00:47:49.490, Speaker A: And I don't know if there's any specific blocker to merging any of them. It looks like there's been some approval on the first, there's some discussion on the second, and the third looks approved as well. So yeah, maybe if by Monday we can try to have a look at those, get them mostly merged and if there's any discussion left on either of those three prs, we can discuss it on the testing call Monday. Does that make sense? Maybe if we have time we can discuss the second one. I think it makes sense and I think we discussed it a few times, but I don't remember whether there is still opposition to it or not. We can postpone it, but if we can agree now to merge it, that would be great. I mean, four to six.
00:47:49.490 - 00:48:24.104, Speaker A: Yeah, to my mind it makes sense. Yeah, it doesn't seem like there's any opposition on the pr. Yeah, the only one that still seems to have discussion is like the receipts pr. But the two other ones seem. Yeah, the two other ones. We should just merge on the receipts. Yeah, on the receipts.
00:48:24.104 - 00:49:29.010, Speaker A: There was like a comment by Peter that's just I guess made obsolete by the previous naming change. But is there any other reason not to merge that or do people feel like we need more discussion? Okay, it's already implemented in Beisu. Okay, so yeah, let's merge the last two for sure. And then yeah, it seems like there's support for the first one as well, but maybe if some of the implementers just want to give it a thumbs up we can get it merged as well. So all three are merged by Monday? Yeah, I think all three makes sense. Cool. And then Maris says hive can be updated to reflect the changes from four two six today.
00:49:29.010 - 00:50:30.040, Speaker A: Awesome. Anything else then on Devnet eight or engine API specs? I think there is one small change that we still need to do regarding folk choice update. Basically in the engine API specs we haven't clearly mentioned that Cancun or birds you should only call folk choice update tree. I mean on new payload v three we already made a one to one correspondence of these versions with regard to the hard folks, but I think we haven't specified on folk choice update. So I think that we should also get in and close it out. And there's no pr for this yet. Correct.
00:50:30.040 - 00:51:31.008, Speaker A: But isn't it covered by four two six? I think it also has this. It says that. No, it has folk choice updated with two. Sorry, used. Do we need to use folk choice updated v two or v three for Cancun? V three only. I mean, we decided that Cancun overs will make sure that the hard fork and the versions will match because it makes for an easy validation on the side. And I think we updated for new payload v three but we didn't basically update the same for folk choice v three and there is no eIp add.
00:51:31.008 - 00:52:40.370, Speaker A: But I can drop in something. I mean it should be pretty easy to drop in the pr on the same, right? Are you going to do it on top of four to six or as part or are you going to update four to six? I think we can update four to six, no issues. Okay, cool. Okay, so then let's merge the receipts, PR and renaming basically as soon as we can. And we can make that change in four two six to require the call to v three. Does that make sense to people? Okay, anything else on the testnet or. Sorry, on Devnet eight or Denkun vips or specs in general? Yeah, Mario.
00:52:40.370 - 00:53:39.464, Speaker A: So yeah, I just wanted to comment that we have the hive branch that is ready to test all the changes up to now before the pre compile changes that we're going to make this weekend. But if clients want to test. I shared the branch in the interrupt channel and you should be able to run the execution clients with this and test up to this point in time. If you have any questions or help names around, do you have tested, just let me know. Awesome. Okay, moving on. So Perry, you wanted to share some updates based on the large validator testnets that you ran? Yeah, so over the last couple of days we've been running some big validator tests.
00:53:39.464 - 00:54:24.430, Speaker A: So we've been attempting to have a testnet up with 2.1 million validators and roughly 420 nodes. We tried once with machines that were using on other testnets, so those were four core 16 gig machines and that hit memory and cpu limits almost immediately. And in order to save some time we went really overkill. So we went to 16 core 32 gig machines and we've done a split such that each node has roughly 5000 keys and we're mostly mirroring what you see on main net. So Prism Lighthouse gets nethermind account for roughly 1 million validators. So about half, slightly over half.
00:54:24.430 - 00:55:10.524, Speaker A: And you can have a look at some initial impressions here. The last run had a regenesis about an hour ago and we're still not able to finalize. We're still noticing issues with late blocks or with duties not being performed in time. And we definitely appreciate help in triaging everything. And the whole purpose of this is we want to be able to launch the Holski testnet, which would be roughly one and a half million validators. But we don't know if the current paradigms support such a large network. So we wanted to go with a 2.1
00:55:10.524 - 00:56:01.350, Speaker A: million validator testnet and see if we need to make emergency changes or not. Got it. Thank you. Any comments, thoughts by client teams or others? Okay, we can touch on it again, this will not be online for a week, by the way. We don't plan to run this for a very long time because they are quite expensive tests. So we would like to get as many people as possible on them as soon as possible. Yeah, I don't mean to delay consideration, but even if the test net's down, this is a conversation we'll continue next week.
00:56:01.350 - 00:56:53.908, Speaker A: Okay, next up. So there were two eips that people wanted to briefly present today. So the first one was from Adrien 5806. I don't know if you are on the call. Yes, hello? Oh hey. Yes. Do you want me to present it? I guess maybe if you want to give like a minute or two background on it and if there's any questions that you'd like answered.
00:56:53.908 - 00:57:33.216, Speaker A: Yeah, this is a good time. So all of you know that account abstraction is a big topic right now. And this PR is not really about account abstraction. Sorry. This EIP is not really accountable, but it falls into the same scope of thinking of what eoas will become and what accounts per user will become. And my intuition and what I understand from all of the discussion I've seen, particularly in etc, is that eoas are here to stay because you will still need them to start transaction and operation like that. And currently eoas are very limited in what they can do because they can basically just send transactions.
00:57:33.216 - 00:58:11.608, Speaker A: There are new transaction types, they can produce blobs, that kind of thing, but it's pretty limited. There are a lot of ideas of what coals will become. I think they will stay here in the network and I think it's interesting to provide them with more capability while not starting to build something too complex and too difficult. And there is already a behavior in DevM that I think is really interesting. It's the delegate call behavior. And just this proposal is about, let's just allow eoas that are just accounts. They don't have code, but they are accounts like smart contracts to do a delegate call.
00:58:11.608 - 00:59:22.900, Speaker A: And that opens a lot of possibilities while reusing mechanisms that are already present in the EVM that are already pretty well understood. The possibilities include being able to do multiple to batch operations that would be helpful for DeFi. It also allows an EOA to execute a create to by delegate call, a contract that does create tOs, and it will also allow EOA to emit events which might be useful for. For social operations like advertising data under your accounts that can be easily recovered by observers. Got it? Yeah. Does anyone have any comments, questions, thoughts about this? Okay, let's start with Guillaume. Yeah, quick question, because you say that would be to call from eoa, and I get the point.
00:59:22.900 - 01:00:31.100, Speaker A: Would it be possible to get it, to send it from. Yeah, no, actually it's a dumb idea, but from a non EOA account, or at least to transfer it to a non EOA account. And what I'm thinking here is, could we somehow hijack this system to recover some funds that were locked in the contract that was locked, basically that was destroyed or incapacitated for some reason. So to emit such a transaction, you would need the private key that, when hashed, correspond to this address. So if it's a contract that was deployed using create or create two, that would not be possible. Also, there are current proposals that I think are going to be discussed later in this call about being able to create code in place of MUA to do a migration to account abstraction. Those transactions would not be able to happen because you cannot.
01:00:31.100 - 01:01:00.644, Speaker A: There is an EIP somewhere I can remember the name that enforces that you cannot emit a transaction if there is code at the address. The current ecosystem means that this could only be done for addresses that don't have code and that never had code. Basically. Yeah, no, I understand that. I'm just wondering if it would be possible to somehow extend it this way. But, yeah, I don't see it working either. Okay, never mind.
01:01:00.644 - 01:02:23.490, Speaker A: Thanks, Anzgar. Yeah, I just wanted to say that my just initial impression would be that while I'm generally sympathetic to the idea trying to make erase more powerful, it seems like in the past when this came up, like for example, as one of the people who port for ERP 30 74 quite a while two years ago on this call, without success. I think generally the skepticism was that executing code, basically that allows things like multiple transactions from one account and within one transaction just is a pretty high security risk because then one single transaction can empty out all your accounts and whatnot. So I think basically all the reasons that made us not go with 30 74 also apply here, unfortunately. Also specifically, I think in the context of delegate calls from an EUA, there were some additional concerns around basically just executing code in the context of an account. Basically what the implications are for storage usage and all these kind of things. So it seems like this would basically be a more contentious version of 30 74.
01:02:23.490 - 01:03:01.630, Speaker A: Yeah, for these reasons. Also specifically, because there are now some other proposals to completely migrate away from EOAS, even basically from the requirement of using them for entry points of transactions. It seems like this is probably not the way to go, but I could be convinced with basically. But I feel like this is not as simple of using existing logic of the EVM as it was presented. So I think it would be pretty extensive change and with a lot of implications and would require a lot of basically justification. Yeah. If I can just say two things here.
01:03:01.630 - 01:03:33.700, Speaker A: One is about, yes, we are preparing for paths towards migration. I still believe that the migration, while it's very useful, has also some downsides. Like you are committing to a specific code that you cannot change later. Some people, I believe will stay with UAS. So I think it's still valuable to accommodate that. And about 30 74, the very big difference here, and what makes this less powerful, but also, I believe, more secure than 30 74 is here. All the replay protection and the signature is built into the transaction by itself.
01:03:33.700 - 01:04:09.644, Speaker A: It's not an independent system. If you sign a transaction like this, it's only good for one transaction. It's not something that is going to be used in the future. If you sign in 30 74, there was a risk that if you sign for a contract that is malicious or buggy, it could exploit you here by reusing the replay protection currently built in the system. It's safer now for sure. If someone signed a transaction like this that is malicious, they can do a lot. But so is true of any other more normal kind of transactions.
01:04:09.644 - 01:04:49.870, Speaker A: Like if you have the private key, you have control over the account. That's basically it, Dano. So this is a bit more of a metacommentary. About five, eight, six and 7377. It seems like we're trying to get into accidental design of a good account abstraction system. And before we do that, I think we need to pause and consider, is this really the best way to get the account abstraction system that ethereum needs? I mean, these are interesting solutions. They open up interesting design space.
01:04:49.870 - 01:05:27.076, Speaker A: But I think we should step back and think if we serve better by deliberate design towards account abstraction. So that's my concern with these going forward, is we might be left with some albatrosses when we go to a real account abstraction system. These also might be the right solutions. I mean, I don't know. That's just my concern here. One point I made in the document that maybe I haven't made very clear in this call is I don't think this is a solution to account abstraction. I think it's just providing useful mechanism for eoas.
01:05:27.076 - 01:06:40.060, Speaker A: And this is definitely not an alternative to the other account abstraction proposals. My concern there is that it could cause design constraints on the other proposals if they now have to account for delegate calls into eoas and eoas having storage now, maybe it's the right solution. Maybe that's what they need in the end. I don't know. But I think we should make sure that we put the big rocks in first before we fill in small rocks. Martin yeah, just something that Oscar and now also Dano mentioned. I think this should be raised in the security considerations on this e, the fact that a user might invoke some moltasic or whatever contract, it stores some things into the storage area of the EOA, and then later on the user unwittingly might invoke some other delegate call thing which also interacts with the storage area on the EOA.
01:06:40.060 - 01:07:26.278, Speaker A: And users can invoke things in strange orders, and the slots may interfere in ways that are not intended. The same problem would exist in contracts, except that contracts are usually written more. I mean, not as haphazards as the way end users do things. So I think that just be raised at the point on the security considerations. That's just my feedback. Yes, I completely agree with that. Okay, thank you, the east magicians thread.
01:07:26.278 - 01:08:14.660, Speaker A: I think we can continue the conversation there and in the discord, just to be mindful of time, I think I have to move on to the next one. Thanks, Hadrian, for coming and presenting this. Thank you for having me. Of course. And next up, I believe like client had an EAP as well that you wanted to discuss. Yeah, I wanted to introduce the EAP 7377, which was kind of mentioned briefly in the discussion of the last one, but I wanted to explain the functionality very simply. What it allows is it allows for an externally owned account to submit a transaction which creates a one time code deployment to their account.
01:08:14.660 - 01:09:09.746, Speaker A: And the specifics are something that we can debate on the magicians for maybe on discord. There's some ideas here that I think are kind of interesting. Like instead of deploying code and running a NIC code, we actually have the user submit an address which the code will be copied from, kind of taking advantage of the fact that we usually store only the code hash in association with the account. These are just things to try and make it as cheap as possible for users to migrate their EOA to a smart contract wallet. And I wanted to mention that I think there's a lot of demand for things in the protocol layer to improve UX. I mean, here we're talking about two different UX improvement proposals. And over the last couple of years, Erc four three seven has taken a lot of growth and seen a lot of deployments on many chains outside of just Ethereum L one.
01:09:09.746 - 01:10:17.350, Speaker A: And this EIP is something that I think really helps four three seven and any other kind of account abstraction proposals that we might have, whether it's in protocol or some sort of application level one, because a drawback for users is if they want to use an account abstraction mechanism, whether it's in protocol or out of protocol, they have to deploy a new smart contract wallet and move all their assets over. So this EAP is really trying to address that issue by making it simple for users to just start using smart contract wallets by submitting a single transaction, upgrading their existing address to the smart contract wallet. Yeah, that's a general proposal. Happy to answer any questions, hear any feedback. Thanks. Thank you. Any thoughts? Questions, comments? Okay, yeah, please.
01:10:17.350 - 01:11:20.312, Speaker A: I just wanted to add that indeed, we are seeing a lot of demand. This is one of the most commonly asked question with four three seven users. And there's quite a big ecosystem for four three seven at this point. So very often people ask about migrating an existing account. So I'm not very opinionated on how we should do the migration, but we should have some form of migration. So the main thing I think about is whether the right way to do it is through a transaction type or through an opcode, but either way it would be good to have a migration path. Yeah, I just can, I just mentioned, because I read through this a couple of days ago, and I had to get clarification from live client on this specific point.
01:11:20.312 - 01:12:11.780, Speaker A: So after this migration, there is code on the account and the transaction where the sender has code is an invalid transaction. So I just wanted to point that out, that after you do this upgrade, there can never be a transaction from that account again unless substruct still exists and it's substruct. I guess that's actually a feature, not a bug, I think. Because if you migrated your account, one of the primary use cases for account abstraction is that you can rotate the keys. So if you change the key of the account, you don't want it to ever transact again with the old ECDSA key. Yeah, I just wanted to lift it up. Yes.
01:12:11.780 - 01:12:54.394, Speaker A: Everyone understand? Yeah. You're 100% right, Ansgar. Yeah, I just very briefly wanted to say that I think maybe similar to the comment on the last eIp that I think the direction is a fruitful one because similarity, we should probably migrate completely over to an AA world. But I think the CIP is mostly used for as like a concrete proposal. So we can start debating this and not something that we would just do in the very short term because it has very far reaching implications. So basically this is more of a set an ambitious goal and then start debating how we get there. Kind of, kind of thing not.
01:12:54.394 - 01:13:49.290, Speaker A: Let's schedule this for the next hard work, in my opinion. Got it? Yeah. I think with that we're probably good to wrap this up for now, unless there's any final urgent comments on either of the vips. Okay then, last up we have Guillaume and Josh to give an update on the work that's been done on Merkel trees. Hello. Let me share my screen. Okay.
01:13:49.290 - 01:14:19.170, Speaker A: Let me know if anyone cannot see my screen. I can see and hear you. Okay, perfect. Cool. Thank you. So, in the interest of time, I will go through some portions of this fairly quickly so we can get to what we believe to be the meat of it here. Most of this presentation will be kept fairly high level, but please feel free to flag anything, of course, that you would want to see more of a deep dive on.
01:14:19.170 - 01:15:31.450, Speaker A: And we would also love to encourage anyone to join the discussion on upcoming vertical implementers calls where we can dive deeper and we can also, of course, future acds as well. So quick overview or quick agenda in the past five or six months, we have hit a number of big milestones that we are excited about, so we will give an overview of that. But of course there are a number of milestones remaining and we would love to bring more people in who would like to contribute to any of these remaining milestones. Which brings us to questions answered and questions remaining. These are questions or general areas we think we have solved or have a very clear path to solving in the near future, as well as questions still remaining and will require a bit more exploration. The overlay method although most of this will be high level, we will do a very quick mini deep dive into the overlay method. Goal is to bring people up to speed here quickly.
01:15:31.450 - 01:16:16.822, Speaker A: The design and implementation of the migration has, perhaps unsurprisingly, downstream effects and will impact some of our remaining open questions here. And then finally next steps, how we will begin to answer some of these yet to be answered questions, hopefully by getting more people into the discussions as well. I will go through this again very quickly. Quick reminder on why we are doing all this in the first place. Won't spend much time here. I think most people on this call are likely familiar with this, but state is growing. This growth is unbounded, permanent.
01:16:16.822 - 01:17:13.850, Speaker A: Even today. You likely need a two terabyte SSD to run a node. But in a future where we have stateless, it is possible that this could be something like 1gb or less, and making it easy for anyone to run a full node is a very good thing. So the key to unlocking stateless is small proofs, which just happens to be something that Verkel gives us. So with Verkel, thanks to the much smaller proof size, no extra state is needed to validate a block. You can do it with what the block gives you. Also a note here we are going for weak statelessness, which means block builders will still need to store the full state.
01:17:13.850 - 01:18:19.460, Speaker A: We can share more at a later date or if we have time, on why we believe that to be the best path. Or you can read a write up that Dhakrad has created here that I've linked to my notes. So diving into what we have actually done over the past six months, as I mentioned, it's quite a lot. A number of notable milestones have been hit on the performance front. Thanks to Ignacio and others, the overhead of Verkel is much lower, current benchmarks at 20% compared to Merkel when we replaying blocks the overlay method. So this again is the solution for the Merkel to Verkel migration. We have gotten to a place on the trade off where there are no longer trade offs like two xing design disk space, which is a huge win.
01:18:19.460 - 01:19:20.990, Speaker A: And we have again validated the initial strategy and created a working proof of concept. Multiple clients have made great progress, likewise on the snapsync front. Lastly, we are currently targeting our first shadow fork for later this month. Client updates if you'd like to see a full list, please visit vertical info. Also, as a quick side note, vertical info is a resource where we point people to who are looking to get up to speed on vertical in general, find the latest documentation and just see the current status of things. But on the client updates front, again, just a very quick sampling here. Nethermind and Ethereum js both making progress on stateless, which is exciting.
01:19:20.990 - 01:20:22.330, Speaker A: Besu has a small group working on making sure that Verkel will play nice with bonsai and Lighthouse is deployed to mainnet and Lodestar will soon be joining. Okay, so with that I will hand it over to Yu Gi. Oh thank you. I need you to try to unshare your screen so that I can share. So we noticed that there was a lot of misunderstanding about our current state, like this current state of development of Veracle. And usually it comes with not being aware what the current state of the transition proposal is. So I'm going to present some slides actually presented at HCC.
01:20:22.330 - 01:20:56.426, Speaker A: In the interest of keeping it short, I will go over it fairly shortly. I'm trying to select the right window. There's too many of them. Let's see. Can you see my screen? Yes. Okay, excellent. If something is not clear, I'll direct you to this talk I did at etcc.
01:20:56.426 - 01:21:52.600, Speaker A: Otherwise, feel free to ping. So, the principle is pretty simple. The idea is that just before, at the last block before the fork, we have the MPT, and we have all the internal nodes that are represented by those things in red. All the blue squares are the values that were written to the state before the fork. And we have this green arrow that represents an iterator that is going to sweep over the state over a series of blocks. So at the beginning of the first block of the fork, you start with an empty vertical tree that is read and write, that is writable. And the MPT, like I said, becomes read only.
01:21:52.600 - 01:22:50.890, Speaker A: And so, as you execute the block values get written too. So they are represented by a purple square, which means purple squares are values that get written to the state after the fork. So here, first value got written into the tree, and at the end of the block, number of values. So in this case, two get moved from, well, actually don't get moved. They get copied from the miracle tree to the Veracle tree. And so if you're looking for data that is currently represented by a pink square, and that data is currently not present in the Veracle tree, but it is present in the MPT, you first go to the vertical tree, and if you don't find the value there you go search it through the merkel tree. So that's basically the principle.
01:22:50.890 - 01:23:50.330, Speaker A: Each block more values get copied into the Merkel tree. Some values that were there before get overwritten. And when the last block with the MPT gets finalized, you can delete all the internal nodes. So you already free up some space. And as things continue, once the whole state has been converted, you can delete the MPT, because all the values that were present then have either been overwritten or have been just copied. So, just to finish on this story, the reason why we're trying to get people to look at this a bit closer is because time is of the essence. If we decide to convert 1000 leaves per block.
01:23:50.330 - 01:24:31.900, Speaker A: And assuming that the payload, the total amount of data that needs to be transferred is 1 billion leaves, it will take six months. So 1 billion leaves, to be clear, is an estimate of what the size of the tree will be in a year. If it's 10,000 leaves, it's 15 days. So of course those numbers are an estimate of if we perform this fork in the next year. If we do it later, it will be more. So even with ten k, with 10,000 leaves, it can be more than 15 days. So, yeah, just to be clear, we have answered some questions, or at least we're pretty close to.
01:24:31.900 - 01:25:44.734, Speaker A: We have definitely answered the design. We are sometimes finalizing, what is it called, the details, but most of it is clear we have good performance, we understand how we're going to migrate. Nethermind has a prototype of snapsync with Oracle. Now the question is, how do we distribute the pre images? Because we need to rehash the whole tree, which is where the problem lies. We still have some questions about the gas schedule, how to update it during the transition, and yes, basically we need a lot of testing, RPC or not. So yeah, what we're going to work on in the next month is basically the shadow fork, validating the snapsync, relaunching a testnet, and hopefully we can get more clients to join us in that effort. So there's a call, the virtual implementer call, and the channel virtual migration, that you can join.
01:25:44.734 - 01:26:27.930, Speaker A: The next virtual implementers call, if I'm not mistaken, is next Tuesday. So 2 hours before ACD, like the time at which starts, I think. And so if you want to be invited, let us know, let Josh know. And otherwise, yes, we are always interested in deploying more application, more contracts to the testnet, to just trust it out. And there's also currently the two big discussions are how we are going to distribute the pre images and the gas cost during the transition. And yeah, I think that was the last slide. Yep.
01:26:27.930 - 01:28:01.956, Speaker A: So that's pretty much it. Thank you, Andrew, you have your heads up. And then Daniel has a question in the chat as well. Yeah, so for pre images, we can just introduce a new method to the east protocol, or like a new protocol, and Aragon can serve them, because as you know, Aragon nodes are all full archive nodes, and we have all the pre images. Guillaume, Josh, any thoughts? Sure, yeah, I was just thinking of something smart to say after that. But yeah, we'd love to. Basically, if we can experiment with arrogant distributing the pre images, like create a protocol, that would be a great start a great starting point, right? Yeah, so I think we'll try to find out a developer, but it makes our job easy if somebody just maybe pens the protocol, something like an extra capability like snap is or whatever.
01:28:01.956 - 01:28:37.380, Speaker A: But it's a minor point. Yeah, we can do it. Yeah. So I think that would be the topic of conversation on the next vic. And then we can do exactly that. Dano has a question. What will state proofs look like during the overday period? Verco only and all reads get moved over? Or is it writes only? Yeah, sorry, I missed some of that.
01:28:37.380 - 01:29:13.838, Speaker A: The comment is in the chat. There are no state proofs during the trend. I mean, state proofs are separate from introducing vocal trees anyway, right? Verco trees just change the commitment so that state proofs become possible. So while the changes in progress, state proofs would still be large, so it wouldn't make sense to introduce them. Well, there already exists an ETH get proof that will return a large proof from the Merkel tree. How would that transition, I guess is my question, would there just be. Nobody can do proofs until the transition is over.
01:29:13.838 - 01:29:49.930, Speaker A: I don't think that's a good solution. I thought you meant block witnesses by. I mean, my understanding so far was that there would be no proof with definitely no MPT proof. Okay. Except you would have to just, you could still get the MPT proof. It's just that the MPT doesn't get inserted anymore, so there would be a bit less value in this. We could just provide proofs for the vertical tree itself during the transition.
01:29:49.930 - 01:31:36.640, Speaker A: I mean, I think it depends on how much this is used at the moment, but there are definitely ways to have state proofs during that time. So basically the complete state proof would be a verkel proof, and if it does not exist in the verkel tree, then you would provide a proof for the MPT at the same place. I don't think we can design in this call, but that seems like something needs to be discussed in the tooling discussions and rollout, right? I'm simply saying it's possible to do it. Any other questions? Comments? There's a question about the JSON RPC from Mario in the chat. I'm having some issues with the chat, so if you could read it, should we introduce eth, get vertical proof that returns empty until the tree node makes it into the vertical tree? We could do that for sure. The question is, is it going to be useful? But yeah, that would be possible to do. Any final questions? Oh, how is the Chappella rebase coming.
01:31:36.640 - 01:32:15.860, Speaker A: It's painful. I just created a PR today. But yeah, I need some input from Gary because we have this new storage system or database system in guest that I need to integrate with. So yeah, I would say it's happening. Nice. Okay, any final questions before we wrap up? Sweet. Well, thank you everyone.
01:32:15.860 - 01:32:22.720, Speaker A: Talk to you all on the testing and Cl calls next week. Thank you. Thank you.

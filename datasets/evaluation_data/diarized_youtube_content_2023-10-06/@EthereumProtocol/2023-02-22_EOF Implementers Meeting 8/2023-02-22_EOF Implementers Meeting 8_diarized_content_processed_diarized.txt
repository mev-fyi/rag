00:00:00.730 - 00:00:26.920, Speaker A: Hi everyone, this is EOF implementers call number eight. And I think this will be a short one because a lot of people are often on holidays. I think usually we go through a round just to see what everyone did. So maybe let's do that. And yeah, I would suggest start with Dano because based SUS starts with the letter b.
00:00:32.170 - 00:01:14.910, Speaker B: We have EOF one implemented. We haven't done much movement on 1.1, waiting for some of the specs to settle for exactly what needs to be implemented. In the interim, we've got the TNN tool implemented, which should help getting reference tests. I know Dimitri was pretty excited when he saw the first pr come through. It's not quite ready yet, there's some packaging issues, but we've been focusing on getting working so that wherever things get implemented first, they can get tested first rather than having to wait for the geth implementation. And it seems like we're all settling on the TN tool for the interface rather than the retest at the interfaces, because the testing team has been pointing nethermind and EVM one at that tool instead of standing up the RPC server.
00:01:14.910 - 00:01:30.860, Speaker B: So that should improve the testing story when we get to final implementation to provide better vectors for us to do differential testing against, and also so that any client with the correct answers can fill the tests. So that's what we've been doing for the past couple of weeks.
00:01:36.590 - 00:01:43.542, Speaker A: Awesome. So you have the entire t eight n implemented and you merged the US fully as well, so you're able to.
00:01:43.616 - 00:02:03.460, Speaker B: Fill any test, right, right in Cancun. Well, it's targeted at Cancun, even though the reference test still target Shanghai, that needs to be fixed. So if you target cancun, EOf V one should be turned on, ready to test. I'm sure there's differences in there. We just haven't done a full differential run, so.
00:02:07.930 - 00:02:28.670, Speaker A: Sounds good. Should we move on to Nethermind, Ahmed or iman? Do you guys want to give an update?
00:02:30.770 - 00:03:01.020, Speaker C: Okay, well, at Nethermind we kind of finished the implementation of UF one. We didn't merge it yet since we are still doing some optimizations and trying some stuff out. When it comes to UFV one or UfV two, we still haven't started on that stuff, still waiting to see what happens and what we decide. And yeah, that's mostly it.
00:03:07.150 - 00:03:23.666, Speaker D: But I actually would like to ask you, Alex, one thing is that since we have EOf one and EOF 1.1, when we are going to the hard fork, it's going to be 1.1, it's not going to be one.
00:03:23.768 - 00:03:24.178, Speaker A: Correct.
00:03:24.264 - 00:03:30.610, Speaker D: So we're going to go right away with Uif 1.1 without the first version?
00:03:32.070 - 00:03:35.734, Speaker A: Yes, that's correct. I mean, that's the idea. Okay.
00:03:35.852 - 00:04:01.134, Speaker D: Just making sure because, yeah, then I would ask what is the status of the spec or finalization of the spec of UF 1.1? Is there anything to discuss about the spec of 1.1? Obviously we don't have probably enough attendance to discuss a lot of things, but.
00:04:01.172 - 00:05:09.250, Speaker A: Yeah, there's definitely a lot to discuss. Let me give just a brief update from Epsilon and then we can jump into the discussions. So from Epsilon, I mean, just starting with EVM one, the also fully merged t eight and support which. Yeah, I think it's not like 100% complete because things like supporting the logs bloom filter that is being implemented currently there's a pr for it. There's also work for the B eleven R, but the currently merged version is already capable of filling tests, UF tests. However, the complete, I mean the big UF support isn't merged into EVM one. It only has 35 40 and 36 70 in the master.
00:05:09.250 - 00:06:11.110, Speaker A: But we have a large pr with every single EIP implemented in it. That is the next goal to be merged. And then EVM one could also be used to field tests. But since Besu has it implemented, maybe Besu is the best client currently just to fill UF tests separately to this we have a pr on which Andre is working, which is basically UF 2.0. So it's APR for create tree and return contract. And the goal of this is just to have a working implementation to discover any issues we didn't really think about. And in fact we did find some cases like we need error handling when the auxiliary data is larger than what would fit into the data section.
00:06:11.110 - 00:07:42.210, Speaker A: So I think it is a useful way to prototype tests and get more data on it. And then separately, outside of EVM one, we did a complete review of the checklist and updated the status of every single client and also the testing suite. And regarding the testing suite from our side, it seems to be like mostly complete prs have been submitted for every single EIP, including 54 50. I think the last 247 50 and 54 50 tests haven't been merged yet, but pr success with the test cases we wanted to have for them. So from that perspective, we kind of consider like UF one almost complete, with the exception of at least one discussion, which is the type section flags. And for that I posted a document with a number of different proposals how to accomplish that? The main point for this type section flags is to support non returning functions. I mean, that is the immediate need we want to fill, because that feature has been requested from solidity.
00:07:42.210 - 00:08:37.830, Speaker A: But as part of this discussion, it opens up the door to support more flags and some ideas. We discussed that we could have purity level, so like pure or view functions. Beyond that, the other feature we thought about that maybe one could mark init code, but that seems to be even less useful. The point is that we are unsure whether anything like purity makes sense or anything else could make sense. And that's why we would like to discuss this document. And I think this is likely the last discussion needed to close down Uf one, and then we can move on to 1.1, for which no proper spec exists.
00:08:37.830 - 00:09:43.480, Speaker A: But my plan was to create a copy of the unified spec and modify it to include the changes. The alternative is to have one document which just describes the differences to EUF one. But we already have such documents, so I'm not sure what is the best option. Having like you know, a diff or having like this complete UF 1.1 unified spec. And I kind of bled into discussions apart from the updates. But yeah, should we discuss these to be your questions, or do you guys have any questions to the updates I gave? The non returning functions means that a given function wouldn't be returning to the caller.
00:09:43.480 - 00:10:42.540, Speaker A: And the significance is that right now we need to, if you are so by calling, you need to make sure that the Kohli has exact number of outputs because the outputs are validated. And the main use case solidity has, is have like an error handling function. And they want to share this error handling function across a number of other functions. And the callers likely have very different number of outputs. And in the current system they cannot really easily share the same error handling functions. So that's the main use case. When we mark a function on returning, then the number of outputs don't need to be validated.
00:10:44.640 - 00:10:54.880, Speaker D: Another question would be if a function is non returning, does that mean that I can use a non returning function call as a terminating instruction?
00:10:58.120 - 00:10:59.830, Speaker A: Yeah, I would say so.
00:11:02.600 - 00:11:07.690, Speaker C: So I guess effectively like try cats, but at the VM level.
00:11:10.060 - 00:11:14.590, Speaker D: But if we use the. Sorry to interrupt, you can go ahead.
00:11:17.820 - 00:11:22.490, Speaker A: No, I just didn't understood what offcode you referred to.
00:11:23.260 - 00:12:26.990, Speaker D: Yeah, for me the question is if we can use an unreturning function as terminating instruction, that would really complicate the code that we use for validation to validate that the code ends with a terminating instruction, because that means that if we have a call method instruction at the very end, we have to check that the call is calling an unreturning function. And if it's not, then we will say that it's not valid, which increases the complexity of the validation operation. Is that something that we would really would like to introduce or allow? Or do we just say, no, we're not going to allow a call function call to be a terminating instruction, and that means that after it we will have to do return or something.
00:12:28.880 - 00:13:25.680, Speaker A: No. So we have another instruction which was part of 47 50, but has been removed and moved into another EIP, which is the jump f jump to function. And that's the way you would use non returning functions, you would jump to them. The jump f is basically a terminating instruction. Got it. So as you can see, without having this non returning flag, let's say you call into a function and that jumps to another one, and where you jumped returns, this target function has to have the same number of outputs as the first one, right? That's the current case. And introducing this non returning flag removes this requirement.
00:13:27.060 - 00:13:49.640, Speaker B: But if it's non returning, it wouldn't have any return values anyway, would it? You could have multiple people jump into it then. I get it then now, so one question I have is if these flags are there, if you have a non returning function and you don't flag it, is that a validation error or is it an option to flag one that matches it, or do all functions that match the case have to have the flag?
00:13:54.270 - 00:13:57.660, Speaker A: No, I think it has to be done at validation time.
00:13:58.510 - 00:14:09.710, Speaker B: Well, yeah, validation time, but when you compile it and I compile a function in solidity and it happens to not return, if I don't set the non returning flag, will that then become a validation error?
00:14:12.050 - 00:14:26.002, Speaker A: Yeah, I'm kind of slow today because I haven't been that much part of the validation discussions. I cannot give like a clear answer right now.
00:14:26.056 - 00:14:58.240, Speaker B: Okay, so that's one thing I would want to clarify to the spec, that the flags, whether or not the flags have to be put on functions that match the standards, or if they may be put on the functions that match the standards. Because if it's may, that simplifies the issue for the compiler, and if it's a must, if it's all done ahead of time and we're not analyzing it, it could possibly be quadratic for the compiler. But who cares about quadratic for the compiler, because you can always cancel it as long as it's linear for validation. So.
00:15:02.530 - 00:15:10.530, Speaker A: Yeah, I mean, the specific case for solidity is that it already knows which are these functions.
00:15:12.310 - 00:15:16.690, Speaker B: What about Viper, a new language? Or what if solidity has a bug?
00:15:19.370 - 00:16:16.220, Speaker A: Yeah, I mean, that's fair that other languages may have different design, or compilers may have different design where they don't fully notice. But I'm not sure I can be of real value on this conversation on at least the arguments around the non returning. I think it has been the biggest debate has been between Daniel and Pavel, who I think have the most context on the different options they discussed. I think how the non returning should work probably has to be discussed in a call where both of them attend. What we could discuss is assuming we want to have this flag, how do we store, where do we store this indication.
00:16:19.040 - 00:16:43.990, Speaker D: And what the size of it should be like. Should it just be one bit returning, non returning, or should it be more? Is there other flags that people were suggesting? As you said, there is the pure thing, but what benefit would introducing this pure flag would do?
00:16:47.480 - 00:17:48.696, Speaker A: So share the document in the chat here. But I also shared it, I think last week sometime on discord. And the short answer is we don't know if anything. So we're like fairly certain, and the non returning flag makes sense somehow indicating it, but we are unsure if anything else really makes sense. This purity stuff is something we identified as potentially maybe useful, and I think the main discussion we have been going around is what to anticipate and how much effort do we need to put into forward compatibility. And we came up with a number of different options how to represent this if we want to support multiple flags. If we only want to support this non returning feature, we already kind of have an answer to that.
00:17:48.696 - 00:18:43.390, Speaker A: We can have a special value in the outputs because we already restrict the outputs to seven bits. So we have basically two options there. We just use like a reserve value, like zero ff for the outputs. Or we could treat the top bit as a signal and then use the bottom seven bits as like a bit set. And so one example is we could have the value 81 in hex, which is the top bit set, and the lowest bit set to signal that this is non returning. And then we still have options to have other flags in the outputs. If we want more than this non returning, then we definitely need to discuss the other options.
00:18:47.590 - 00:19:27.710, Speaker B: So a couple of uses I could see for these flags, but this is only in an eof world would be like eth call. When you set the static flag you could verify it along the way. You can do quicker proving that the call is going to be static when you could require the static flag for some of those. Similarly, for just in time compilation of the code, you can look at the flags and make assumptions about the compilations. My question is, is it worth imposing that analysis on everyone when only hypothetical implementations would be using these flags? Is this the return of the bloom bits in the receipt? So I think it's cool, but I'm concerned about the utility.
00:19:31.490 - 00:19:59.990, Speaker A: Also, just to make sure, even if we think that this purity makes sense, I don't think we would introduce this feature in 1.1 or 2.0 or anytime soon. We would just want to make sure that the header is forward compatible to support this. Aiman, you have your hands up.
00:20:03.640 - 00:20:43.090, Speaker C: I have a few questions. First, this thing and all the other flags, aren't they compiler specific? Like compiler needs them to emit specific code or optimized code, but should they be visible to the VM if we might not be needing them? And also the other question is what happens after running a non terminating function? Do we just stop interpretating the bytecode? If so, doesn't a function section ending with a stop up code do the same thing?
00:20:47.380 - 00:21:30.560, Speaker A: Cool. Yeah, I was just going to briefly answer if anybody else's other opinions, then go ahead after. So like the stop opcode, wherever the stop GOP code is, that just terminates execution successfully with not returning anything in the return buffer or return data buffer. The non returning functions, if they're marked non returning, it just means that they're not returning to the caller. They have to be terminating. They have to have like a terminating instruction at the end. So they still have to clearly stop execution.
00:21:30.560 - 00:22:12.690, Speaker A: And regarding the purity, if we would have purity flags in that type section, that would have to be enforced by validation. And what that means is that those given code sections couldn't use specific instructions. So if it would set to be like a view function, that would mean it couldn't use s store, couldn't use call, but could use s load and static call. And if it's pure, then it couldn't even use s load as an example. So it would need to be done at validation time.
00:22:29.200 - 00:22:47.200, Speaker D: I mean about the view and the pure, I understand the appeal, but again, what is the use case like? What benefit will they bring to the eVm?
00:23:02.610 - 00:23:43.814, Speaker A: I would say it's more like a security. I mean, two cases where it helps, it could help with security and it could also help with execution time because one could translate different functions. Yeah, I see, you said aot. Yeah, exactly. I mean, if you know that some of these don't really touch state. You may have more efficient options. To be honest, we haven't really explored the concrete usefulness.
00:23:43.814 - 00:24:22.500, Speaker A: It does seem to be useful, but just stating again that the main reason we discussed is whether we want to be future compatible and have a flex field, first of all. And if none of these make. If we don't want to be future compatible, then we should just choose the easy option, have a special value for the non returning functions. Greg, I think you had your mic on, maybe you wanted to add something.
00:24:24.950 - 00:24:52.300, Speaker E: It sounds like to some extent you're just asking what can we validate? That would be clearly an error at runtime, and anything we can validate that would be an error at runtime is probably worth validating, even if we can't easily think of a use case right now. There's a lot of users out there.
00:25:21.240 - 00:25:49.310, Speaker A: Dragon on the call, he bumped off. Yeah. So anybody has like any other hunch, if any other flag would be useful generally, apart from the ones we discussed, any other feature which could be enabled with flags, you.
00:25:51.440 - 00:25:55.420, Speaker C: I mean, we can flag functions that may fail.
00:26:04.320 - 00:27:11.700, Speaker A: You mean like use reverts or have unexpected failures, like out of gas or it. Can we maybe take like just a round in. Where are we leaning towards? One option is having flags, extensible flags, or not having them because we don't see too much value. Do you want to get everyone to say which direction they're leaning towards?
00:27:12.470 - 00:27:30.200, Speaker D: I would go with extensible flags, but only very limited. So I wouldn't go with eight bit with the full byte. I would go like something like four bit or something like this.
00:27:41.320 - 00:28:19.810, Speaker B: I'm weakly against because I'm concerned about the effort return ratio that we're going to get out of this. I'm not seeing what critical space that is opening up, that can only ever be opened up now, because if we needed to, we could get another format where we could put flags in a different section that we could add later, rather than having to put it into the type three section. Not type three, the client three data. So I'm hesitant to get fully on board with this without a concrete value of saying this is how it makes it better in the future when we do implement it. So that's kind of what I'm waiting for.
00:28:23.320 - 00:28:35.110, Speaker A: I'm just trying to write up a comment on the checklist just to record what we discussed. So Daniel, you're leaning towards not adding flags right now, only adding them when the need.
00:28:36.540 - 00:28:37.288, Speaker D: Yeah.
00:28:37.454 - 00:28:54.190, Speaker B: And creating space for things that we might have. I'm afraid we're going to wind up with something like the bloom bits again in the receipt. Something that sound like a good idea that no one ever actually implemented that are continuing to impose restrictions on us as we go forward.
00:29:02.910 - 00:30:11.220, Speaker D: Right now, after I heard his argument, I kind of agree. And the whole idea of EOF is that upgrades can be virgin and contracts can be virgin. And since everything is virgin, what preventing us from just introduce these new flags that are needed later on with the new version. And we can easily upgrade old contracts into new contracts with this version with these flags because we can probably introspect the code and see that this function does not return and we can flag it in that case if needed. But yeah, basically we can also check like if we are going to have a pure flag or have view flag, we can check what type of instructions are executed inside this function. And if these epcodes are not used, then we can mark it with these flags also. So the upgrade path is clear and.
00:30:12.070 - 00:30:21.750, Speaker A: There is no need to include it from nowhere.
00:30:31.390 - 00:30:37.120, Speaker B: So when I say weekly against, if it goes in anyway, I'm not going to block it. So that's what I mean by that.
00:30:47.070 - 00:31:44.160, Speaker A: I kind of agree that we have the flags for this exact reason that we can make upgrades, but at the same time, reflecting to the past couple of months, it seems to be a lot of pushback in terms of having multiple versions. So maybe that just means the version is really just the last resort. And for things like this, it would just mean that the feature wouldn't be worth the introducing because nobody wants a new version. And maybe that's correct, because if the feature is useful enough, maybe that's a forcing function. But then just judging based on how much pushback even uf itself got. Maybe the system isn't perfect yet.
00:31:48.230 - 00:32:08.810, Speaker D: But does that mean that in the case that we add this eight bit field that we would have a hard fork implementing this new pure view blah blah flags without a bump in the version of EOF.
00:32:16.110 - 00:32:17.500, Speaker A: That's a good point.
00:32:20.110 - 00:32:50.066, Speaker D: I'm pretty sure it goes against the whole idea of EOF. Like the whole idea is that we want to have things be clear as if it's this specific version, then it has these specific set of handling of instructions and validations, et cetera, et cetera, et cetera. And that anything that changes it needs a version bump. That was the premise as far as I knew.
00:32:50.168 - 00:32:51.060, Speaker A: I don't know.
00:32:51.670 - 00:33:53.000, Speaker B: So some of the pushback that I recall from the offsite interop is that they want a future world where clients only need to have one version of the EVM for a current fork. If they're not doing any historical validation, they can get rid of it and remove it. So we're going to be stuck with at least two because of legacy and EOF, but they don't want to have like five because it supports the four different versions of EOF. So that's the reason why they want the pushback, so that at a current fork there's only the EOF version and the legacy version. So if we were to do a breaking change, we would need to have some sort of a transpolation that we can point at the old contracts to bring them into new states. So that's some of the pushback against just adding a new version is they don't want out of control code growth like we've experienced with the current legacy version of the EVM. We've got basically nine versions that you need to tweak and configure EVM to be able to validate all stuff back in the previous history.
00:33:53.000 - 00:34:12.640, Speaker B: Once they solve the previous history version, then you don't need nine versions, but then they don't get rid of the thing where they still have to have two versions of the EVM. So they want to try and put a lid on that. That's where some of the desire to not have multiple versions at the same time. And I think the compromise they're willing to make is there's not multiple versions of EOF at the same time.
00:34:17.010 - 00:34:49.500, Speaker E: Adding a pure is compatible. We don't need to bump the version, because if something isn't marked pure, it doesn't matter that it is in fact pure. Adding a pure flag later just allows us to check that something that the author claimed to be pure was in fact pure, but it has no effect on what went before. So yeah, as much as possible we can add new features without breaking anything.
00:34:52.510 - 00:35:31.800, Speaker B: But the concern I have is if you care about peer, you're probably doing analysis anyway, and you could get the answer that it's peer without the flag. So why are we requiring everyone to calculate and validate peer when the utility cases for the pure flag, existing or not existing, are kind of small? I'm concerned that we're pushing work on everyone for something that only one implementation might benefit from. And then by might benefit, I mean they could actually calculate it themselves since they already care about that data. That's my concern with the current flags out there. Again, if they go in, I'm not going to push back or try and sabotage it, but I want us to think about, is this the right thing to do?
00:35:32.250 - 00:36:07.860, Speaker E: Yeah, I don't know, but it's more like stating the number of arguments to a function. You're just stating part of the interface that you can checking it at validation time. Otherwise you can do for optimization purposes, but not for checking the interface. I don't know how far we might want to go with that, but anything that you can specify about the interface to be checked the validation time increases the type safety of your program.
00:36:08.870 - 00:36:09.282, Speaker A: Right.
00:36:09.336 - 00:36:56.930, Speaker B: But in the case of function arguments we're actually matching up to make sure. Well, let's make sure that we have this many on the stack before we proceed. That count has an impact on the interpretation time, whereas the impact of a pure in theory has no impact on the interpretation time. I would need to be presented with how would this make the interpreter better? I definitely make an AoT compiled better because even in the AoT compiled because you still have to keep in the message frame the link to the state. Well, for pure you could get rid of the link to the state, but for like read only. Where is the advantage of this? Where does this speed up and provide value to the execution process? Would be my question rather than it's nice to be explicit about what you're adding. What is it actually changing?
00:36:57.990 - 00:37:51.070, Speaker E: I don't know that it adds anything, it's just type safety at validation time. You don't need the number of arguments. You can check at validation time that the stack is okay without stating up front what the number of arguments is. You can just check at validation time that you use the arguments consistently. So any of this is a matter of what do we want to state in the program itself to type check at validation time and peer sounds useful. I don't have a strong opinion on whether we should have peer. I'm just saying the point of it is, as I said, there might be other points, but that's the main one.
00:38:03.260 - 00:39:08.970, Speaker A: Yeah, I think, Daniel, your reasoning is correct that we push the burden on everyone even if nobody uses the feature. But I think this pure end view is actually a bad example for that, because we do need to do code validation of each of the code sections, and what this flag would do is just reduce the number of accepted instructions in the validation run. So in that sense it doesn't actually put like extra burden on the VM because the validation has to be done anyway. But yeah, otherwise I definitely agree that we shouldn't really add features which the VM wouldn't benefit from. Yeah, iman, please go ahead.
00:39:11.020 - 00:40:16.850, Speaker C: Yeah, I was just going to say that I kind of agree with you. Since these validations for pure and for view and other stuff can be done, they will be done once, they will not be done twice at runtime, or even if they are not included as flags. Like if the VM implementer needs to know if a function section is a pure function section, they don't need a flag to verify it, because the flag would be just a kind of indicator to validate whether the compiler is telling the truth. But when it comes to use case, we will validate it anyways, and based on the results for alt we will emit code or we will interpret code or whatever the need of that flag for us. But my point is, in either ways it will be validated, so we don't need it to be in the bicycle it.
00:40:29.820 - 00:40:59.250, Speaker A: I think the entire debate whether to have flags or not goes back to this one premise, whether we can have flags and then introduce features without bumping the UF version. Because if you cannot, then there's no point having like a forward compatible field. If you need a new version we're going to change, or we could change the format anyway.
00:41:01.380 - 00:41:47.120, Speaker C: To be honest, this feels like a very primitive effective system that we are trying to add to the bytecode here, pure, total or whatever other effects that can be added. But I don't think the VM will benefit from them since we can just verify them if our VM has some specific implementations that are intrinsic to it. So we don't need to impose them on everyone to have to validate these functions or these flags, while we know that only certain ones will need it because they have some specific technological stuff that goes underneath the hood.
00:41:52.020 - 00:42:26.200, Speaker D: So to clarify, what Ayman is saying is that if a client is seeing a benefit in having, in defining if this function is pure or if it's view, then they can simply, while validating the function, check the opcodes, and if it accesses memory in load it's a view, and if it doesn't then it's a pure, and in that case they can flag it, but without imposing this on everyone. Is that what you're trying to say?
00:42:26.270 - 00:42:27.080, Speaker A: Amen.
00:42:27.440 - 00:42:34.110, Speaker C: Yeah, exactly. So they can do it for themselves and use it themselves, not force it on everyone.
00:42:38.980 - 00:43:54.260, Speaker A: So there's one more use case we thought about is the init code marking a code section which is used as in it code. And there have been like a number of different designs on how even this contract creation like in UF two could work. And with these factory contracts you could definitely have multiple init codes in the same container, but it's unclear which direction we're going to go with this. And from that reason, just mandating there that the first code section is in a code is good enough. But there is one other side to this is how to actually finalize the creation within the init code. And in legacy we just use the return opcode to return the entire code we want to place into the state. But in euf two it's slightly more complicated because we don't want to have access to all the code and everything in memory.
00:43:54.260 - 00:44:39.990, Speaker A: So the current designs have a new instruction called return contract, which take a memory area for auxiliary data which gets appended to the container. And sorry that this was so long winded, but the one problem, or like not a big problem, but just one thing we need to do is check whether we are in an init code context, because outside of that, this return data return contract should not be valid. So if we would have this init code as a flag, then we could easily validate that this return contract opcode only is present in code sections which are meant to be in it code.
00:44:41.080 - 00:44:54.350, Speaker D: But again, this will be introduced in EOf two, which is a version bump. So if we really need it in the flag, we can just say okay, then we will introduce the flag in version two and not introduce it in version one.
00:44:54.720 - 00:45:56.814, Speaker B: We were also contemplating making Uf quote two a forward compatible that doesn't require a version bump. So that's part of the design space that we were trying to keep available, so that all the bytecodes are still the same. It's just suddenly you can now use these new opcodes that are introduced if you follow the rules. So there is also a path for keeping forward compatible changes that don't require a bump like we've been doing forever in the legacy EVM. So one of my concerns about this is one of the discussions we had about the space we wanted for create was we wanted zero ability to put opcodes in memory. Because I've been doing a little bit of ZK research that has a very positive impact. If the execution and the logic are entirely separate, maybe we need to keep it open just in case it has for a knit code and just do the bit packing and don't use any of the flags.
00:45:56.814 - 00:46:32.160, Speaker B: That might be the solution that we have here, but I'm skeptical of some of the flags. But the init code flag, we might need that space, we might not in that everyone's going to use init code, but I'm still in favor of solutions that involve bytecode never hitting operational memory. That would make things a lot better for the ZK world, I think may open up new possibilities, but that's a discussion we're going to have in a much future date. We just need to preserve space for us to do what we need to do. So that might be the argument. We need to keep the flag space open.
00:46:39.330 - 00:46:46.020, Speaker A: So if you would have this init code flag, then you would be in favor of having like a flex field.
00:46:48.550 - 00:47:12.060, Speaker B: So I think the possibility of the knit code flag I think is a stronger argument than the possibility of a pure and static flag. So that I think there's case where we need to keep the flags open but not specify any of them in the 1.1 version, but just outline. These are the things we're considering, but we're not committed to shipping any of them yet.
00:47:21.550 - 00:47:58.886, Speaker A: Yeah, exactly. I mean, we wouldn't define any of them. We only have five minutes left. I think maybe the best way forward because we didn't had a number of people who have been active previously on this call. Maybe we shouldn't do a final decision on this today anyway, so I would suggest that all of you just think about this. You can leave comments on the document as well, and then maybe on the next call we should be in a position to make a final decision on this. But there's one last topic I think we can fit into the three minutes.
00:47:58.886 - 00:48:32.900, Speaker A: What is the best way for the UF 1.1 spec? And the number of options I see is we just create a diff, just state high changes from UF one. Another option is that we take a copy of this unified spec and just modify it so it has everything clearly what 1.1 would look like, and then whether any of these should be any IP or not. What's the view? What direction should we go?
00:48:48.420 - 00:49:11.000, Speaker E: I'm not sure what document you're referring to at this point, but I'd really like to see a meta eip pulling this all together because we have a lot of hack MD sort of scattered around, it seems I can't always find them, and I can't always use them effectively because I'm not in the organization.
00:49:21.500 - 00:50:22.350, Speaker B: In addition to a meta EIP, I would kind of be in favor of going back and changing the eips. I mean, these never shipped in an approved fashion, so they're not finalized stuff like we would be increasing the scope of what operations are invalid, we would be adding entries to it. I think we just go back and edit that to add it to it. As far as the differential, and people who are curious about the history can just go back to the GitHub and look at the state of the spec at a certain time. So maybe in the comments stream we could point them to a static copy of the markdown to say here's what the meta ETH looked like at this point in time for those interested, but I don't think we need to keep this rejected version in the eips because it wasn't ever fully shipped and finalized. But if we want to do a new one that specifies the changes on top of those three eaps, that's a viable path too. Or five eaps, or however many eaps it is.
00:50:24.880 - 00:51:01.950, Speaker A: Yeah, I think the only reason we haven't just gone and changed it because we've seen value, and maybe this is wrong, but we've seen value that the clients who started work on EOF one, they can complete that work with the test suite as it is and the EIPs, and then maybe it's easier to, once everybody is on the same page, just to modify the EIPs and roll out the EUF 1.1 changes. But maybe this is a bad assumption and we don't need to wait for everyone to finish uf one.
00:51:05.070 - 00:51:05.578, Speaker B: What are.
00:51:05.584 - 00:51:16.420, Speaker E: We actually going to ship? That is what's actually going to go to final.
00:51:18.470 - 00:51:20.180, Speaker A: Hopefully 1.1.
00:51:22.810 - 00:51:25.960, Speaker E: Then that's what the EIP needs to describe, right?
00:51:33.670 - 00:52:00.700, Speaker A: Yeah, I think Beisu is not affected that much because Besu merged everything. But regarding nettermind, are you guys planning to merge the current set of PRS, which is Uf one, or if you do like this 1.1, then you would just keep them open and then do the changes there. What is the plan, the follow up?
00:52:03.010 - 00:52:45.370, Speaker D: Yeah, so the idea is that we don't really like to merge stuff if it is not tested on the ethereum tests, consensus tests, et cetera, et cetera. So we keep everything in a pr in a branch, we keep updating it. If EOfV 1.1, the spec is finalized, then we will implement the changes and then we can then test everything once the tests are finalized. For nethermind, the bottleneck is always ethereum tests, in my opinion. If these are finalized then we can move a lot quicker in my opinion.
00:52:49.630 - 00:53:36.300, Speaker A: Okay then since we are like on the top of the air, I think my suggestion is then that we're going to probably create a single pr on the EIP's repo and not merge it, which has all the changes and we can discuss the changes there. And hopefully all the consensus tests or execution tests are merged soon enough with 54 50. And at that point we can just record all the commit hashes of the final EOF one test suite and eips, and we can record it in the checklist. And so if people want to test for EOf one, they can still do that, and we can start merging the IPs at that point. Does that sound like a plan?
00:53:40.930 - 00:53:49.600, Speaker B: Sounds reasonable. The pr, I think, solves the meta EIP concern. And we could have one location for them and just merge the pr when we're ready to finalize it.
00:53:55.760 - 00:54:08.000, Speaker A: All right, I will write this summary down in the channel. Then we can take it there because Pooja has to leave. Thank you, Pooja, for recording and hosting us. And thank you everyone. Talk to you soon. Thank you. Bye.
00:54:08.000 - 00:54:08.532, Speaker A: Thank you.
00:54:08.586 - 00:54:09.360, Speaker B: Bye. Thanks. Bye.

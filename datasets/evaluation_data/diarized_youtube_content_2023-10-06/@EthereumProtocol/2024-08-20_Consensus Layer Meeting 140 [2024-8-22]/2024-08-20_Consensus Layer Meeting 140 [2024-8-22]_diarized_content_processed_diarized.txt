00:01:44.580 - 00:02:12.520, Speaker A: Okay. And we should be live. Hey, everybody, this is consensus layer call 140. I put the agenda in the chat there. And, yeah, there's quite a bit on the agenda today, so let's go ahead and dive in quickly just to kick things off. There was a specs release version 150. This is Alpha five.
00:02:12.520 - 00:02:46.598, Speaker A: I think it's exclusively things for peer to us. But yeah, just a heads up there. And I believe this is the target for Pyrados dev net two. So might be relevant later in the call, but just be aware and take a look if it's relevant to you. Cool. So then let's jump into Elektra. If we could start with updates on Devnet two, that would be super nice.
00:02:46.598 - 00:02:49.710, Speaker A: It looks like there might have been a bad block recently.
00:02:51.170 - 00:03:17.356, Speaker B: Yeah, I can give an update on that. So if we go to. If you guys are interested in more details, please have a look at the interop channel on eth R and D discord. There's a few bad blocks we've noticed on the network. They seem to have been produced by gats, but are also not importable by gats. So we need to look into why. I have a timeline there as to what I'm seeing, at least.
00:03:17.356 - 00:03:39.456, Speaker B: Please validate that. And there's two threads right now. One for debugging the get block, and two, Aragon has forked off. But each Aragon node seems to be on its own fork. So there's also something going on there that needs debugging. But, yeah, we don't really have more than just a few questions. A few open questions right now.
00:03:39.456 - 00:03:50.460, Speaker B: And there's a link to the trace of both the specific bad block that has been posted earlier, as well as in general, which bad blocks we've seen on the network over the last day or so.
00:03:54.200 - 00:04:01.656, Speaker A: Okay, awesome. Thanks, Perry. Yeah, so please take a look. We can work on debugging that and.
00:04:01.848 - 00:04:12.750, Speaker B: Otherwise, I think that's it for me. Yeah, mainly Marius looked in and he said it was likely 7702, even though we did not actively test that. But, yeah.
00:04:14.210 - 00:04:28.230, Speaker A: Okay, thanks. Yeah, sorry, I was actually muted, but, yeah, just saying thanks and. Yeah, we'll take a look at that. Otherwise, it seems like Devnet two is in a pretty good place. Yeah. Any other updates from anyone else on Devnet two?
00:04:33.730 - 00:05:24.436, Speaker B: Oh, yeah, there's one more thing we noticed that's a JSON RPC standardization issue. We tried making the ETH call that we spoke about at the test call, and then after some debugging, kind of found that the Nethermine team uses a different default from then the get team. So when you send like a raw RPC call, if you don't specify the from, then you don't really get an output. In Nethermind, it seems like an under specification of the JSON RPC right now. And there's a similar bug in Bezu where if you call debug trace call, it complains that the gas price is less than the base fee, but if you send a regular ETH call it works fine. So yeah, I guess the teams have already been notified. I think they're looking into it.
00:05:24.436 - 00:05:27.680, Speaker B: But if there's some update on that, then please bring it up.
00:05:41.670 - 00:06:06.370, Speaker A: Okay, good. Should we touch on Devnet three? I don't know if there's anything we really need to do. If 7702 is the issue with this Devnet two bad block, then yeah, maybe that will just resolve naturally in Devnet three. Any 7702 updates worth discussing right now?
00:06:11.340 - 00:06:35.020, Speaker B: Someone from the RET team brought up if this EIP 29 35 change should go into the next Devnet or if there's still like an open discussion. So I want to bring it up here. It's been merged as an update. I think I'm more in favor of having it ready for Devnet three, but yeah, up for discussion I guess. I posted it in chat.
00:06:36.000 - 00:07:04.700, Speaker A: Thanks. Yeah. Anyone working on that? Care to chime in as far as understood? Yeah, there was something around the semantics to clarify, so I agree it would make sense to put it in three. I don't think it's a huge change or departure from what we had before, so. Sounds good to me.
00:07:05.720 - 00:07:08.940, Speaker C: I mean, what does, what needs to be put into Devnet three?
00:07:09.800 - 00:07:11.624, Speaker A: This PR Perry put in this printer.
00:07:11.632 - 00:07:13.740, Speaker C: Yeah, but the PR couldn't change anything.
00:07:14.680 - 00:07:15.072, Speaker A: Okay.
00:07:15.096 - 00:07:33.870, Speaker C: There's like no semantic change. It's just saying like you have to call the system contract to do the update, but I think everyone is doing that. And you can still not call it if you want, but like you have to make sure it's right.
00:07:36.690 - 00:08:14.360, Speaker A: Right. Okay, so yeah, let's just go ahead and assume this goes in Devnet three, but it should be transparent with the behavior we had. Cool. Anything on Devnet three to talk about? I think we had said last week that we had aimed for two weeks, so next week would be Devnet three launch, but it sounds like it's going pretty well. I'm not sure if there are any implementation updates or anything else to discuss there.
00:08:22.790 - 00:08:41.050, Speaker B: Yeah, I think once client teams have branches, please just ping them on the interrupt chat or DM either Bundabas on me, and then we'll update configs and start sharing them around. And yeah, Mario's posted the spec release for Devnet three as well, so the El specs.
00:08:43.680 - 00:09:43.436, Speaker A: Okay, great, cool. Then next up we had, let's see, this was a Pr to update the Max Eb Eip. Let me grab a link here, I'll put it in the chat. So essentially, yeah, I believe this was only an issue, sort of like an edge case in XDB, where if there was a lot of eTH staked, say like more than 30 million, there was an issue with consolidated validators, essentially like validators with a lot of stake interacting with the calculation of the correlation penalty for slashing. And essentially there's an overflow with the way that we have the spec today, and this PR fixes that it looks like in a pretty nice way. So let's see. I don't know if anyone like, is Mikael on the call? I don't see him.
00:09:43.436 - 00:09:47.040, Speaker A: Oh hey, would you like to say anything else about this?
00:09:48.180 - 00:11:00.918, Speaker D: Yeah, just a quick overview of the problem and the fixes Alex mentioned. So this is about the correlation penalty computation, the penalty that is applied roughly 18 days after the weather gets slashed. And actually the cause of the bug is in the integer division. And the result, the outcome, the potential outcome of the problem is quite becomes much more severe with the max effect of balance increase. So to highlight the problem, we should consider two cases where the same balance, say 2048 etH, is distributed between. In the first case it is just one valir, which has all this eth on its effective balance. And the other case is like 64 weathers, that has, each of them has 32 eth, and under some condition, each of those 32 ethwater will get zero penalty.
00:11:00.918 - 00:11:57.620, Speaker D: So the total penalty, the total correlation penalty applied to this balance, this entire balance will be zero for 32 ethwaters, but for 120-48-2048 eth, while error will, it will be non zero. So this is where we get the discrepancy. And actually this PR proposes fix to this problem. Also, the other problem is the overflow in the same computation. But yeah, it's the detail of the overflow and this discrepancy and the amount of correlation penaltified can be found in the description. So the fix basically changes a bit the correlation penalty curve. It makes it linearly dependent on the effective balance, on the effective balance, on the number of effective balance increments.
00:11:57.620 - 00:13:00.370, Speaker D: So it's like 32 or 2048. And the side effect of the fix is that we'll get correlation penalty for even when the one value gets slashed, but this penalty is going to be negligible in this case. The detailed analysis is also in the post and you can take a look at this as well. So what else is here? Yeah, the correlation penalty becomes a bit higher on average, but the curve is much more smoother than when it was with the before Elektra combination. So you can see it as well. And the total session penalty will anyway go down and decrease with this in Electra because the initial penalties is significantly decreased. So for all these details you can just read the post.
00:13:00.370 - 00:13:08.790, Speaker D: Yeah, that's the that's what this PR is about. I know Francesco on the call and want to give more information. Information.
00:13:12.770 - 00:13:15.150, Speaker C: No, that's, that's for me.
00:13:17.930 - 00:13:55.120, Speaker D: Cool. So it would be great for more eyes to take a look to this PR because it changed the penalty that we used to have for all the time and yeah, but from our perspective the fix looks good and I think we just aim into merge it sometimes next week. Maybe if there is the desire, we can wait till the next call and make the last call the next time.
00:13:58.060 - 00:14:31.070, Speaker A: Cool, thanks. Yeah, nice catch. This is a very important computation for slashing penalties, so please take a look. I looked the other day and yeah, it seems equivalent to what we had say if we were working with the real numbers. The issue kind of comes in when we move to integer arithmetic that we use in the spec, and then you start hitting different overflows and things. So take a look at least. I'd probably wait for a few other client teams to chime in on the pr, but after that should be ready to merge.
00:14:31.070 - 00:15:23.730, Speaker A: Cool. If that's it on that one, we can go to the next agenda item. So this one I think has had a bit of work put into it, and essentially it's refactoring how the execution requests are put in the data type on the beacon chain. And the reason we want this is because the sort of natural thing to do is just mirror the EL here, where the execution request would be in the execution payload in the beacon chain type. Generally, I think all the clients pretty aggressively prune these because there's no reason to have them duplicated both on Cl and El. And so if you do this, then you don't have access to these execution requests which you now need for this El state transition. So there was another proposal by POTus.
00:15:23.730 - 00:16:10.260, Speaker A: I think there's some back and forth and people have landed on this new pr here. I just put in the chat and yeah, it looks generally pretty good to me. Yeah. Again, call to take a look. I think there is still one thing we'll need to do is pass the request to the El, say in the new payload call that was missing, but otherwise it looks pretty good. So I'm not sure if any other client teams or anyone else has had a chance to look at this or if there are any questions about it at the moment. Yeah, POTUS.
00:16:11.400 - 00:16:46.796, Speaker E: Yeah. So one of the reasons we. Well, I guess you can ask the author, but one of the reasons that this approach turns out to be much simpler to write in the python spec than having an extra envelope, than having an extra layer. But the problem is still that you need to have like tests for this and pass the python tests. Are we going to agree on like starting implement? That's going to take some time. So are we going to agree on like starting implementing this thing on clients before having tests on the python spec or. It's fine by me.
00:16:46.796 - 00:16:48.080, Speaker E: I actually want this change.
00:16:50.670 - 00:17:01.330, Speaker A: Yeah. I mean, they can go in parallel, but yeah, I guess the sooner other client teams can take a look, the better at the PR.
00:17:06.190 - 00:17:08.890, Speaker E: The PR looks good, it's just that it needs tests.
00:17:09.390 - 00:17:29.560, Speaker A: Right. So, yeah, I mean, it might be simpler to just move ahead with this PR just so people have like a target, say if it gets into a specs release, test can come along the way and. Yeah, I guess it would be nice to have a few other client teams take a look at this PR before merging. Mikael.
00:17:31.940 - 00:18:33.690, Speaker D: I just wanted to add that this PR is nice because it does not actually, does not introduce any changes to the execution pivot struct on the CL. And also I think that I've been putting this comment into the PR thread, but I think that we could remove the payload body's version two request from engine API because Cl's will not offload those requests from. From their databases. But yeah, that's, that's what I was going to look for. I mean, like the answers to this question, whether it is correct or nothing, ask scale desk about it. Like, yeah, does it make sense to just not have those getpaylord bodies method in the description definition? Sorry, would you not still need.
00:18:34.470 - 00:18:44.580, Speaker A: Yeah, would you not still need those? Say if, you know, someone asks their CL for a block and they need to go fetch the execution payload from the eldest, say for like a historical block.
00:18:46.960 - 00:19:05.100, Speaker D: Yes, but we already have so those we version one methods that can serve transactions and withdrawals. So if request will not be uploaded from the database. Yeah, we don't need to update those.
00:19:05.680 - 00:19:42.520, Speaker A: Gotcha I think you had a comment on the PR about that. So I can follow up there and yeah, I can also look at test in the next week or two. So then my ask for client teams is to take a look at the PR and we'll move ahead there. But yeah, generally this makes sense. Okay, anything else on that?
00:19:48.540 - 00:19:54.964, Speaker D: By the way, you mentioned tests. What kind of tests do we need to merge this VR?
00:19:55.092 - 00:20:25.880, Speaker E: Well, the problem is that this change is going to break essentially every test that we already have. So fixing those, until those tests are fixed, we're not going to have spec test vectors to pass. So we need to fix the existing tests, have a release with those tests that are going to be applicable for this PR, and then we can just run spec tests in our CI ourselves. So that's just the inconvenience of having this large change on the PI stack.
00:20:26.740 - 00:20:31.850, Speaker D: Got it. So you mean that it's not about it, PI spec tasks, right?
00:20:32.870 - 00:20:33.206, Speaker F: Right.
00:20:33.238 - 00:20:40.250, Speaker E: So whatever we have now currently on spectest is going to start failing once we merge this in our, in our developed branches.
00:20:40.710 - 00:20:43.090, Speaker D: Yep, I see. Thanks.
00:20:47.870 - 00:21:09.710, Speaker A: Okay, so we'll move to the next agenda item. This is related around the execution request and how they are written or represented in the engine API. So liteclient had this PR like client. Do you want to give us any more additional context here?
00:21:14.250 - 00:22:09.850, Speaker C: Sure. I think we talked about this a couple of weeks ago, but just bringing it back up for final call from CL devs. The idea is on the execution layer, we don't make the distinction between requests in the block body. And so what we do is we just have this sort of union like thing where we serialize the request with the type prefix. This is the same thing that we do with the transaction types. I'm trying to expose that same type of that same data type to the engine API instead of what we're doing right now, which is during the engine API call, we have to actually go in and parse out each individual request type from the list of requests. So really it's just trying to have better parity of the API versus the data that exists.
00:22:09.850 - 00:22:28.810, Speaker C: There are a couple issues with how it is formatted. I think if we were to add more request types in future forks, it won't be so easy for us to parse it out. It's still possible. And if this is a blocker for CL's, like we can do it, but I think that it's better for the API to match the data type that exists in the blog.
00:22:30.950 - 00:22:31.422, Speaker G: Yeah.
00:22:31.486 - 00:22:38.730, Speaker C: If anyone has thoughts on that like, happy to hear it. Otherwise, probably merge it later this week.
00:22:42.030 - 00:23:58.884, Speaker H: Yeah, I think some of the issues that have not been addressed in that GitHub issue and I would have personally say I agree with at least, at least one of them. So, for example, this SSE question, and I think it's, it is useful, it is going to be useful to be able to have an SSC representation of this in the hopefully not too distant future. I think there's been a, some consensus, although there's been a not on timing from the ELS, but there's been some consensus that SSE is probably a good direction to go with representing data in Ethereum in general, El and NCL. There's been, yeah, and some enthusiasm. Whatever's been brought up towards moving towards that direction again. Yes. Not everybody's ready with their SSE libraries and etcetera, but, and we have to time that for, in other ways, but this would actively make that more challenging and to just kind of toss in, well, maybe use an SSC union is, is not sufficient because SSC unions, I understand they're in the SSE spec, they are not used.
00:23:58.884 - 00:24:20.388, Speaker H: I need to emphasize this, they are not used. They effectively don't exist. They don't exist in our libraries, they should note, be relied upon. And as such, there is no corresponding representation of this in SSE currently. So that's, that's, I'll stop there for the moment, but that's one of, one of the issues that the, I mean.
00:24:20.404 - 00:24:48.320, Speaker C: This is just not an SSD API, though. Like we not only do we have one solution, which is the SSD spec that says either are unions, so if you want to go down the right path, we have that. And if people don't want to implement SSD unions, then we could just revert back to what exists today, which is separating them out and sending them over as individualists. Just because we're changing how the JSON RPC is representing this today does not really affect how people want to represent it with SSE.
00:24:53.900 - 00:25:03.782, Speaker H: Well, it does to an extent. So I mean, you can, you can.
00:25:03.966 - 00:25:23.370, Speaker C: Like when we, when we do this in SSD, like people, you're going to come up with your own SSE spec for how things are represented. So it's like up to the SSD designers at that point to decide how do they want to represent it, if they want to represent it as a union, like I think the best thing to do. But if they, that's not possible, then we could do exactly how it's represented today.
00:25:26.040 - 00:26:27.150, Speaker H: So generally speaking, the way these SSC transitions have been mapped out, not universally, and various other people here have been involved in some of them. So. And is that they are structurally isomorphic, maybe is how I'll put it, that not universally, but in general there's often a goal to have them be closely equivalent structurally. So there's, they are just the same kind of higher information hierarchy, but with a different encoding, rather than saying that they are just a completely reimagining of the API. And if you look for example at the Beacon API which has offers SSC, I know this is not el related, but this shows a model for how this has been worked out. The SSE representations are as close as possible. This is not a different API, it's the same API over Sse.
00:26:27.150 - 00:26:38.270, Speaker H: And this, so this does impinge therefore on how SSE would represent it. And again, union doesn't effectively exist right now.
00:26:40.010 - 00:27:01.110, Speaker C: I mean, I just don't agree. So this is why I don't think that this is an outstanding problem. I understand this, maybe you guys do, but I don't think that something that we might do in the next one year should impact like what we're doing right now, when it like can, can easily be changed in the future. For me too.
00:27:04.050 - 00:27:17.760, Speaker A: Have other CL teams had a chance to look at this printhead? Yeah, photos.
00:27:18.700 - 00:27:46.152, Speaker E: I looked at it, but personally I can't speak for prism. It sounds like something reasonable. I also think that it's easy to change if you want to change the SS representation later. So I agree with Matt, although Ethan left a comment in that pr that is also reasonable to me. Either way works for me. They both look like reasonable changes. So that's why I'm asking Matt and Chad what he thinks about that comment.
00:27:46.152 - 00:27:54.660, Speaker E: We just concatenate in the mercant Patricia tree roots of the three requests and then hash them and use that.
00:27:56.160 - 00:28:37.060, Speaker C: Yeah, I mean, it's not a bad idea in general. I just prefer to keep things the same when we have mechanisms that look the same. And the reason is that every time that we make a small deviation in an implementation, then that just creates a lot more complexity. Right now, the way that it's implemented is exactly how transactions are serialized and merkelized. So we get to reuse all of that tooling. If we change that, then we need to write more code around that, and then it kind of starts to defeat the purpose a bit. So I think the way that it's written is simplest, and I think it's the most maintainable for the long term.
00:28:37.060 - 00:28:45.480, Speaker C: Because if you have to understand the TX root, then you get to understand the request routes for free. You don't have to go and learn how this other mechanism works.
00:28:46.980 - 00:29:11.590, Speaker E: So my understanding of this is that it is actively simpler for you guys to implement your suggestion. And for us it's a very simple change because it's just extracting out that quantity that we don't care the type and just use the right serialization to match it into our internal object. So it's very simple change for us as well. I don't see why not to include this now.
00:29:14.450 - 00:29:28.190, Speaker A: Yeah, personally I lean towards merging just because it sounds like it simplifies implementation on the EL, and especially given the uncertainty around SSE and how it ultimately looks like, it just sounds like something to figure out down the line.
00:29:31.490 - 00:30:13.310, Speaker H: I'm not sure that the comparison to transactions is. I mean, I understand from a Yale perspective that they may well be represented similarly or a similar structure, let's say, of distinguishing types from each other. That is, relatively speaking, compared to most of the Cl data structures, kind of, let's say from a little bit, from the outside, an unmaintainable mess. It has problems. And the fact that, and so importing that into the Cl world, which has mostly avoided these problems, I'm not sure is a positive step.
00:30:15.850 - 00:30:41.730, Speaker C: Yeah, I wasn't really commenting on how it's represented on the CL. I'm talking about on EO. Like we have these roots that exist in the execution layer header, and I'm trying to keep those in sync with each other rather than having every single route mean something like slightly different. The way it's represented on the beacon chain is totally up to the consensus layer teams.
00:30:51.000 - 00:30:52.100, Speaker H: So what?
00:30:53.920 - 00:31:40.338, Speaker E: Yeah, this doesn't change how we represent these things. I mean, our internal structure doesn't change at all. This just changes how we deserialize over the engine API, which is grab this thing, grab the quantity, say this has to be decentralized as a request for withdrawals. And then this other thing needs to be decerialized as, as some deposits. But we don't change the SSL type of these things internally, we don't change the consensus layer python types, we don't change anything. So that's why it's very simple change for us. If it makes El happier, why not? And I do see your complaint about the future as a z.
00:31:40.338 - 00:31:51.230, Speaker E: But then in that case, we can just change the API. It's not a hard fork. So if it bugs us when we move to ss on both layers, then we could just change this again.
00:31:58.250 - 00:32:28.760, Speaker A: Right. So again, yeah, I think this makes sense. And it would simplify implementation. So I would say let's do it. Maybe we'll let it sit for another week and I'll try to get another client team or two to take a look and we can go from there. That's unreasonable to everyone. Okay, I'll assume that's yes.
00:32:28.760 - 00:33:04.150, Speaker A: Thanks. Okay, so that was all we had, I believe, for Electra. Any final comments on Electra? Otherwise we'll move to peerdos. Okay, cool. So first I was just curious if anyone wants to give any implementation updates. I know clients have been working in parallel on pure dos devnets. Anything worth discussing there? Any questions anyone has or anything like that?
00:33:08.290 - 00:33:53.286, Speaker I: Yeah, our goal to launch two peer does, two hopefully tomorrow if we will have enough clients to participate. So currently I've done some local tests with Prism, lighthouse and Nimbus. And Prism and Lighthouse seem to be working fine. Nimbus have some awesome block proposal issue, but it's being investigated right now. I'm interested to hear from Taku and Lotsar. Possibly they have not yet. I think it should be ready.
00:33:53.286 - 00:33:54.406, Speaker I: I'm not sure.
00:33:54.598 - 00:33:57.850, Speaker A: Are there any issues that you're saying one of us?
00:33:59.550 - 00:34:15.490, Speaker I: I haven't tested yet with loadstart. Just, uh, I haven't heard anything either that it would be ready to go or not. So basically with metadata, v three included, I think you can test it out.
00:34:24.880 - 00:34:29.260, Speaker A: Cool. Anyone from tecu on the call who can speak to Pyrdas?
00:34:32.560 - 00:34:36.820, Speaker D: Yeah, from tech side, we also have metadata with Ri.
00:34:39.080 - 00:34:39.940, Speaker F: Yeah.
00:34:41.760 - 00:34:45.820, Speaker D: I think we are ready to participate.
00:34:50.889 - 00:35:00.269, Speaker A: Cool, thanks. And there was a question, lodestar, is this the pure dos branch? Is that the right one to be targeting? And similar question for tecu.
00:35:01.809 - 00:35:03.709, Speaker G: Yep, that's the branch.
00:35:05.529 - 00:35:08.945, Speaker F: Yeah, we also have branch the same branches.
00:35:09.017 - 00:35:09.629, Speaker D: Before.
00:35:11.329 - 00:35:16.090, Speaker I: One more question. Can loser now be supernode or that's still not implemented?
00:35:17.670 - 00:35:21.454, Speaker F: Uh, you mean, uh, subscribed?
00:35:21.502 - 00:35:32.086, Speaker D: Uh, I mean even like custodian. Uh, there is all subnets, yes. Uh, yeah, yeah, I think yeah, for tech.
00:35:32.118 - 00:35:38.494, Speaker I: For tech who it is. But for Loadstar, we didn't have it for Loadstar last time. Yeah, Loadstar can also be the super.
00:35:38.542 - 00:35:42.352, Speaker A: Node and I think I posted the.
00:35:42.376 - 00:35:44.700, Speaker I: Param that you will need to supply.
00:35:45.000 - 00:35:47.900, Speaker A: To make it a supernovd. Okay.
00:35:54.200 - 00:35:54.704, Speaker I: Great.
00:35:54.792 - 00:36:36.532, Speaker A: Sounds good. So next up, I wanted to follow up with some questions around the blobs. So the first one is there is some work to think about uncoupling the blob counts between the El and Cl. So right now, basically there's like a target and max value. And the max at least is hard coded both on Cl and El. And you could imagine that it streamlines development and just generally ops around this stuff if we uncouple them to the extent possible. So I've been working on some stuff recently, and it has culminated in an eipde.
00:36:36.532 - 00:37:03.490, Speaker A: Just adjust this change. This is EIP 7742. I can google some links, but yeah, generally, I think Justin put this. Yeah, so Justin put the CLPR here. There's now this EIP 7742. And then just the other day I started on engine API changes. So that's all here.
00:37:03.490 - 00:37:19.530, Speaker A: And, yeah, I think there's generally pretty broad support to go ahead and include these. Yeah, I guess that's the question. Now, I'd suggest we put these into Vectra and. Curious what people think about that. Mikael.
00:37:21.430 - 00:37:37.270, Speaker D: I have a couple of questions, a couple of clarifications. So the first one is the, do we need to pass the max log count to payload attributes as well?
00:37:38.610 - 00:38:00.550, Speaker A: I think not. So the El, right. The El just needs the target for the fee accounting. And really how it is right now is the max is kind of redundant on the El. So this EIP, let's say these three prs, they kind of just take the max away from the eldest and all it does is pass the target.
00:38:02.410 - 00:38:10.450, Speaker D: But if El will include more than the max value on the Cl, then the block will not.
00:38:10.610 - 00:38:15.710, Speaker A: The Cl will validate. So, like, before the El sees it, the Cl handles that check.
00:38:19.450 - 00:38:29.370, Speaker D: Right. But then El should know that it should not include more than the Max value. More transactions, more block transactions than the max.
00:38:29.870 - 00:38:36.622, Speaker A: I see. Yeah. Okay. Okay. Yeah, that probably you either need the.
00:38:36.646 - 00:38:55.300, Speaker C: Max or you need the El to just like, have hard coded a percentage of the max. So you could say that we'll just like, quote unquote, always target the target being half of the max. If you want fancy stuff like Runabus is saying that, I do think you need to be passing at both targeting the max to the El.
00:38:58.720 - 00:39:13.620, Speaker I: I think in the future it would be better to have both of them passed because we might want to do something, like with higher blob numbers, we might want to change the target only, but keep the max at a higher level.
00:39:17.370 - 00:39:17.706, Speaker D: Right.
00:39:17.738 - 00:39:22.762, Speaker A: And I was kind of. The thinking of this as well is just to give us that flexibility. Yeah.
00:39:22.786 - 00:39:28.030, Speaker I: I mean, if you're already changing it, we might as well pass both of them. That's my take.
00:39:28.690 - 00:39:31.950, Speaker A: All right. Okay. So, yeah, I can update that.
00:39:32.890 - 00:39:58.470, Speaker D: It makes sense to me as well. And the other question is about target block count. So the target block count will pass through payload attributes to the payload build process. So the El will be able to compute the excess blob gas. Right. Or excess blob count.
00:39:59.850 - 00:40:00.282, Speaker F: Right.
00:40:00.346 - 00:40:00.990, Speaker A: Yeah.
00:40:02.450 - 00:40:18.320, Speaker D: But in this case, the kind of the target blob count is required to update the El block. So in order to not break the optimistic thing, the target blob count will need to be to become a part of the execution layer block.
00:40:19.460 - 00:40:22.520, Speaker A: Right. So does the IP puts that value into the header.
00:40:25.580 - 00:40:45.060, Speaker D: Okay, so there is the target block count in the yelp walk header. Right, I see. Okay, interesting. Okay, got it. I just probably missed, missed this. This part.
00:40:46.400 - 00:40:48.660, Speaker A: Sorry. Yeah, no worries.
00:40:50.400 - 00:40:51.040, Speaker H: Cool.
00:40:51.160 - 00:41:50.650, Speaker A: So, yeah, I guess then everyone take a look. Do we want to talk about packtra inclusion or should we wait until these changes are more in a final state? It would be good to get a temperature check. Now we have one thumbs up in the chat. Anyone against including this in pectrade? This should simplify development. And I think already the pure DOS implementers are moving to rebase peer Dos onto electra soon. So I think this makes a lot of sense. Yeah, we got another plus one.
00:41:54.360 - 00:42:21.980, Speaker D: Have a kind of follow up. Yeah, sorry, just a quick follow up question. Can we just pass the access block count from, from Cl or not? I mean, like, it's already in the block. Probably the target is not that meaningful for El if the access will be passed, which was computed by Cl. So we will not need probably to add one more field to the yelp block.
00:42:23.440 - 00:42:50.388, Speaker A: Right. And that could be a good compromise. It kind of gets. So tech had another proposal that basically hoist, like the entire computation into the Cl. And I think we kind of stayed away from that just because to the extent we can. It's nice to have the separation of concerns between Cl and EO, where the Cl more needs to think about just, you know, dos concerns and things like that around the max. And then the El primarily just needs to know.
00:42:50.388 - 00:43:31.310, Speaker A: Yeah. Excess in some sense for the fee accounting. So that's kind of why we settled on this. But it could be, yeah, I'll think about this some more. It could be an option to pass the excess around rather than pass both Max and target like we were just discussing. Okay, so yeah, there's an update then for me to make on that. And generally it sounds like people are on board with including.
00:43:31.310 - 00:44:06.390, Speaker A: So I'll bring this back to the next yell call and. Yeah, we'll go from there. Cool. So the next thing. Yeah, so I'll need some help from the client teams. But from what I've been hearing, it sounds like some implementations essentially have these blob parameters hard coded. So for example, if we wanted to iterate on a even very ephemeral devnet with changing these values, it would mean a recompile of the client.
00:44:06.390 - 00:44:32.070, Speaker A: So I'm not sure if anyone here has anything to add to that. Generally, we would like these to be configurable. So it's very simply just to change, very simple, just to change some configuration and not need to recompile the entire client if we change blob counts. Does anyone here? I don't know, Barnabas, I think you raised this point. I'm not sure if you know if there are particular clients that had this issue.
00:44:33.460 - 00:44:49.360, Speaker I: I think it was something to with the CKCG library, where some of the blob values were hard coded. But I'm not 100% sure anymore. We haven't been playing around with the verbal number of blobs yet.
00:44:52.700 - 00:45:06.280, Speaker C: So, yeah, I think we would have had issue in Lighthouse. Poan is working on going through and making it easier to runtime configure Bob count right now. So we're trying to fix that.
00:45:12.180 - 00:45:36.410, Speaker A: Okay, cool. So, yeah, I guess then just a general notice for everyone. To the extent that it is runtime configurable, that's much, much simpler than the alternative. So please be aware of that. And, yeah, I guess we can just follow up on that asynchronously. Perry was asking if Geth had this issue as well. Yeah, Barnabas?
00:45:37.950 - 00:45:56.650, Speaker I: Yeah, one more question. So right now we have the max blob limit in the config as a. As a value that you can set, but we don't have target on the Cl side, so maybe we can also add that so we can independently configure both of the values.
00:45:58.990 - 00:46:13.690, Speaker A: All right, yeah, that's a good point. Yeah, live client, or. I don't know if anyone else from Geth is here. Can we speak to this question?
00:46:16.150 - 00:46:17.810, Speaker C: Sorry, can you repeat the question?
00:46:18.580 - 00:46:24.668, Speaker A: Just how easy is it to change the blob parameters in Geth? Perry was asking. He thought there was an issue in.
00:46:24.684 - 00:46:32.840, Speaker C: Geth as well, to change the parameters for a hard fork, or to change the parameters like on demand via the engine API.
00:46:34.780 - 00:46:46.790, Speaker A: Well, just so, like, if you build Geth, those numbers are fixed, and then the question is, do I need to change the source code to change them in Gethse and rebuild the client, or can I just pass some configuration?
00:46:47.370 - 00:46:49.830, Speaker C: Yeah, you have to change the source code right now.
00:46:50.250 - 00:46:54.230, Speaker A: Okay. Are there plans to update that?
00:46:57.410 - 00:47:23.490, Speaker C: I mean, no, but we'll change it when it needs to be changed. If there needs to be plans, we can make them. I have a pr for the 7743. So that would make it configurable by the engine API. If we want it configurable by Genesis, that's something that we can also look into. But I think that's going to be a little bit weirder because you need to specify it for multiple forks.
00:47:26.710 - 00:47:35.010, Speaker B: I think by engine API makes more sense. If that's the approach we're going with anyway, we can configure it on the Cl and the Cl passes it through to the El.
00:47:35.710 - 00:47:36.450, Speaker C: Right.
00:47:42.970 - 00:47:52.950, Speaker J: When we get blocks from the network, we don't know how to, how to test this. Right. We don't know how to verify that we have enough blobs.
00:47:53.930 - 00:48:02.070, Speaker B: I think that was the same question also for sync. Right. Because even if you're syncing, you kind of need to know how many blobs should have been there for the estimation.
00:48:03.140 - 00:48:03.920, Speaker A: Yeah.
00:48:06.420 - 00:48:12.628, Speaker J: I think we can only change the set. Hard for boundaries anyway. So I would make it dependent on.
00:48:12.644 - 00:48:13.600, Speaker E: The hardware.
00:48:15.900 - 00:48:17.640, Speaker B: Or we put it in the header.
00:48:26.740 - 00:48:35.670, Speaker A: Okay. Various. Your connection is not great for me. I didn't quite catch that.
00:48:37.170 - 00:48:39.190, Speaker J: Not morphews into the header.
00:48:40.610 - 00:48:55.790, Speaker A: Okay. He's saying no more stuff in the header. Right. Okay. So we might need to do a little more design around this. But yeah, this has been good feedback and I think we can take it from here.
00:48:59.620 - 00:49:37.540, Speaker J: While we are at it, one thing I would really like is if we could have a limit on max blobs per transaction so that we don't have like one transaction sending six blobs, or like the maximum amount of blobs per block. And this would make also our lives transaction pool and everywhere easier. Because right now someone could just like always send six blocks transactions and either they will get included or they won't and then no one else. So.
00:49:38.000 - 00:49:38.780, Speaker E: Yeah.
00:49:42.720 - 00:50:04.900, Speaker A: Right. Okay. So I mean, there's some chat content around just saying one blob, one transaction and having that be the limit or otherwise it sounds like maybe we just want a fixed, whatever the maximum is. We just say that is the actual limit with respect to a single transaction because I think with 444 right now, it's just not specified. Onskar.
00:50:06.120 - 00:50:55.030, Speaker F: Yeah, I would personally relatively strongly oppose enforcing such a limit on the protocol level just because it seems like there's no strong reason for it. And it just removes a lot of flexibility in the future because it's really hard to predict these usage patterns once we go through, just like larger blob counts. I do think, though, because I've been hearing that quite a bit, that it causes problems on the mempool side. So I think it's perfectly reasonable for the El clients to just coordinate on a maximum to enforce in the mempool and just ignore all transactions above that maximum. That way, L2 can choose if they have a specific way to just reach builders directly or something. They can always just send transactions with higher accounts. But the public mempool is basically just open for transactions up to certain size.
00:50:55.030 - 00:50:59.770, Speaker F: To me, that seems like a much more sensible, minimally restrictive approach.
00:51:07.470 - 00:51:27.432, Speaker J: In general, I don't like this pattern of having some transactions, or most of the transactions valid by the public mempool, but some transactions not. And so we need to go. Those people need to go through the builders. That's just a general comment.
00:51:27.496 - 00:51:27.840, Speaker A: I don't.
00:51:27.880 - 00:51:35.580, Speaker J: I don't really like this pattern. This enshrines the builders way too much. It gives them a lot of power.
00:51:40.970 - 00:52:18.300, Speaker F: But it's not just about kind of like private ways to reach builders or something. It also, just like the protocol, should only ever enforce rules that basically are necessary. Because, say, in the future, the mempool, we have a somewhat more efficient implementation of the mempool, and then we can go from, I don't know, maximum of three to a maximum of eight or something. Once we have higher kind of maximums. In general, in that scenario, it would just be really unfortunate to have to wait for a year for a hard. Because if that limit. If that limit is just not enforced in the protocol, we can always just change the implementation on the mample side whenever we want.
00:52:18.300 - 00:52:33.020, Speaker F: But enforcing it on input is significantly restricts our design space. Or if, say, an individual client wants to have a higher limit or something, it just, to me, seems like way too heavy handed to enforce it. Yeah.
00:52:38.610 - 00:52:48.070, Speaker A: So the max would be whatever the protocol level max is, right. So it's not that we would say like, I mean, unless we wanted to really restrict transactions to say like one blob or something.
00:52:53.930 - 00:53:02.270, Speaker F: Wait, that's my proposal. Marius proposes to restrict it per transaction to something that's much, much smaller than the block maps, potentially all the way down to one.
00:53:08.220 - 00:53:41.380, Speaker J: Yeah, I don't want to take it down to one. But the problem is when you're fetching these transactions and you fetch a blob transaction, and you don't really know yet how big it is, and then it arrives with like eight blobs that's like, I don't know how big that is, but it's. It's way bigger than, than a blob transactions within like two or three jobs. So, uh, yeah, I don't know. It is.
00:53:41.840 - 00:53:43.880, Speaker A: Wait, that can be fixed just by.
00:53:44.040 - 00:53:46.648, Speaker G: Fixing the networking protocol and announcing how.
00:53:46.664 - 00:53:48.060, Speaker D: Many blobs it has, right?
00:53:49.760 - 00:53:50.740, Speaker J: Yeah, I could.
00:53:55.610 - 00:54:00.082, Speaker G: Because as it doesn't matter. It exists anyway. I can always send you pretend that.
00:54:00.106 - 00:54:06.698, Speaker A: I have a huge, like a transaction. Send you like, megabytes of data, but then you're.
00:54:06.794 - 00:54:09.750, Speaker J: But then you're violating the protocol and we can kick you.
00:54:11.890 - 00:54:16.066, Speaker G: Well, you can, you can do the same for this. You can also say, like, right now.
00:54:16.098 - 00:54:17.442, Speaker D: It'S a validation of the network.
00:54:17.506 - 00:54:19.830, Speaker G: You said more than I.
00:54:23.520 - 00:54:24.936, Speaker A: Like. You're still free to do that.
00:54:24.968 - 00:54:35.424, Speaker G: That's independent of what you allow in consensus. Basically, you're trying to use consensus to.
00:54:35.472 - 00:54:40.100, Speaker A: Define a rule for this. But, like, that rule can also exist on the networking layer.
00:54:50.450 - 00:55:35.030, Speaker E: Yeah, I'm not sure how relevant it is, but I would ask for input on roll ups about imposing a limit of, say, of one block per transaction. I saw Francesca's comment that amortization, eventually, that's it. But this might actually benefit some roll ups over others, like roll ups that are posting blobs without execution, versus roll ups that are posting blobs with like, expensive execution in the same transaction would see a different benefit into having a limit of one blob versus six blobs. And depending on what's the price of call data, this might actually make a big difference. So I would ask them for input on this matter.
00:55:38.860 - 00:56:19.880, Speaker J: I'm not, just to be clear, I'm not advocating for a limit of one block per transaction. What I also see is that if we had some rule about this, that you cannot get one roll up, cannot fill up a block full of blobs with one transaction. I think it might actually be more competitive because. And you cannot, like, just fill up the blank space to be sure that your transactions go in. And the other stone, I don't know.
00:56:22.820 - 00:56:24.524, Speaker A: I mean, you can always just create.
00:56:24.612 - 00:56:37.274, Speaker D: Two transactions with three blocks of use. Builders each get those in as a sandbox. Like right now, you can send fanboats.
00:56:37.322 - 00:56:41.390, Speaker G: And they will get in as I make you.
00:56:44.850 - 00:56:50.750, Speaker D: So this only makes a difference for cell phones anyway.
00:57:03.180 - 00:57:27.470, Speaker A: Okay, yeah. Thanks for the discussion, everyone. Sounds like a thread to keep pushing on and otherwise, let's see. I have the agenda somewhere. What was next? Right, okay, so that was all we had on pure dos for today. Yeah. Any other closing comments? On the blobs or ds or anything.
00:57:27.470 - 00:58:16.182, Speaker A: Okay, I will just call out Etan's comment here. Let's see, see there are some updates for stable containers. Let's see. Let me just check this out. There's a couple things in here. There was this pr here. So I think that this is generally informational or at least rather it's not like a critical issue to fix at the moment.
00:58:16.182 - 00:58:54.614, Speaker A: But please take a look at this pr. There is something with the engine API and around transaction serialization. So everyone take a look at that. And what else is in here? Updates for stable container and yeah, I think that's generally it. Cool. So we had that to follow up with. And right, next up, I did want to circle back to the name of the f star and I'll just grab this eth magicians link here.
00:58:54.614 - 00:59:50.176, Speaker A: But ultimately after, you know, some community input, both. Well, from many different people, it looks like there was some support around Hulu. And you know, we could call the combined name between the LNCL Fosaka. So yeah, I think it'd be nice to go ahead and pick a name for the f star. Anyone opposed to moving ahead with Hulu? Artifice says fusaka rather than Fosaka. We got another fusaka. Okay, so yeah, let's move ahead with Hulu then.
00:59:50.176 - 01:00:12.580, Speaker A: And yeah, Fusaka is a perfectly fine portmanteau. Cool. So that was that. And then I think the last thing to touch on today would be an update from probablab, I think around some work on gossip sub. Let's see someone here from probablab on the call.
01:00:19.720 - 01:00:22.424, Speaker G: Yep, yep, I'm here. Can you hear me?
01:00:22.552 - 01:00:25.360, Speaker A: Yep, yep.
01:00:25.440 - 01:00:28.576, Speaker G: Do you mind if I share my screen? I have some slides prepared.
01:00:28.728 - 01:00:29.620, Speaker A: Yeah, sure.
01:00:40.320 - 01:00:44.060, Speaker G: Do you know if the action is limited.
01:00:47.000 - 01:00:48.980, Speaker A: Is it not letting you share your screen?
01:00:50.080 - 01:00:55.620, Speaker G: I'm not able to find the option. Okay.
01:01:00.600 - 01:01:03.980, Speaker A: Let'S see. Is there like a share icon at the bottom that you see?
01:01:06.040 - 01:01:11.940, Speaker G: I just have participants checks ration more, but nothing. Next year.
01:01:17.530 - 01:01:28.550, Speaker A: You should. Yeah, let's see. You should be able to at least on the settings I can see for this zoom room.
01:01:41.060 - 01:01:42.000, Speaker G: Interesting.
01:01:42.860 - 01:02:04.160, Speaker A: Yeah, sorry, I'm not sure there's a way to disable it for the room, but it's enabled so I'm not sure why you wouldn't be able to do that. Maybe you could just give us just a brief overview.
01:02:05.750 - 01:03:30.890, Speaker G: Yeah, so mostly what I was going to do is make a small introduction of a report we did on the performance of gossips app at Problab. In collaboration with the theorem foundation. My colleague Guillaume did previous update on the last call on the Discovery five status and this one was going to be on the gossip chop one. The main idea was also to prepare the tool that we build to generate this data which is called herms which basically acts on the network as a light network node which has like a custom DPP tracer with light network node. I don't mean like this is like a light consensus client, it's mostly like a networking node who supports all the protocols, let's say discovery five gossips app and all the DPT protocols like pin exchange, metadata chains, all these ones. And the interesting thing is that it's generic plug with a trusted prison node which allow us to reply any change status that someone is asking us in an honest way so that we keep honest connections and stable connections. This is the biggest, let's say change if we compare it to other tools that are out there that pretty much do the same thing.
01:03:30.890 - 01:04:31.650, Speaker G: And the final purpose is that we want to reproduce the stability of any node that is out there in the wild. What do we do with this? Basically this custom DP two P tracer. It's streaming all kinds of events at the host level. Let's say connection disconnections, send and receive rpcs, but also at the gossip sub level. So we have control and we trace down all the control messages that are happening at the gossip sub level. Let's say graph that prunes that any mess that we are subscribed to on all topics subscriptions to these messages control ihealths and everyone's internal peer scores and also like message arrivals to each of these topics. And there is some extensions towards the Ethereum field where we are able also to trace down request response on pings, beacon status, metadata chains and so on and so on.
01:04:31.650 - 01:06:12.050, Speaker G: I don't want to take much of your time, but the idea was I had some slides with some graphs and the idea was mostly to introduce of the outcomes that we presented previously in some research posts. I'll try to make sure I share on the GitHub issued at least the link to the slide so that anyone that is interested can check it. But something that we were really excited about was that we were able to retrieve the gossips app effectiveness. This means how many I wants do we send or receive based on the ones that we send or we receive? Sorry, my voice is going over, but something that we identified is that this ratio of I ones that we send or receive per all day, hubs that we send or receive it's pretty low, which isn't bad, but it shows that the network is healthy enough to the point that we might be spending a lot of bandwidth on control messages. And this was something that was pretty much stable for all the topics except for the blocks which had like sudden spikes where we could see radius of 600 messages per each. I want that we were sending or receiving. There was also like further interest on researching duplicates.
01:06:12.050 - 01:07:39.550, Speaker G: This was a pretty well known issue, but there was no public data on it. And this is something that we were consciously analyzing. And what we realized is that of course the bigger the message size, the bigger the number of duplicates that we received. But something that we were able to trace them with all these traces was that the time between the first or the inner arrival and the first duplicate on a mean basis, at least for blocks, it was around 80 milliseconds going up to a full second in some occasions. Which means that, for example, we were pushing a lot towards protocol upgrade towards I want, I don't want because we understand that the time games that it's or that are involved in Ethereum allow us to pretty much send either one messages and try to avoid all these extra bandwidth that we are using. Because right now all the messages that we are sending and receiving represent around 64% of the total bandwidth. And we are able to reduce the duplicates from, let's say a median of three, four messages per each unique message id.
01:07:39.550 - 01:07:59.520, Speaker G: We were saving like a huge bandwidth. I'm sorry. And yeah, I have a bunch of links and interesting outcomes that we came up from this study. Some of them were related to the Java virtual machine implementation.
01:08:02.660 - 01:08:03.252, Speaker F: Where we were.
01:08:03.276 - 01:09:01.560, Speaker G: Able to identify that they weren't implemented the control messages, especially the ihops, on the same way as the other ways were doing, which mostly were making them not taking full advantage of gossips at all. And furthermore, we also push a little bit more towards the 1.2 version of Gossips app to be only scoped to the addon one message inclusion. And this is pretty much the update that I have for you. I'm sorry that my voice is pretty much trash like with all these acs. It's pretty much over and that I couldn't really share the slides but I will make sure and make them PDF and I will share them on the issue itself or anyone that is interested. Something that we are also taking care at the moment, which is a little bit on a work in progress.
01:09:01.560 - 01:09:29.720, Speaker G: We were also analyzing the block arrival time and we are about to make this on an automated way in our website, so I would like to share the link with you here in the chat. Feel free to drop any question that you have out there. Any feedback? There are possibly new collaborations with Ethereum foundation towards peertas. So yeah, happy to reply any question if I can.
01:09:33.040 - 01:09:58.220, Speaker A: Great, thanks. Yeah, no, super exciting. I think that from what I hear, your analysis kind of correlates with other analyses people have done around this. So super good to see some confirmations and just more data. Yeah. If you have any links we should take a look at, you can put them in the chat or otherwise. Yeah, just follow up on the GitHub issue.
01:10:04.920 - 01:10:05.980, Speaker G: Thank you very much.
01:10:07.440 - 01:11:07.920, Speaker A: Yeah, thank you. Okay, so yeah, we'll be looking for any links there on the issue for the analysis and otherwise. I think that was pretty much it for the agenda today. I don't know if anyone has any other topics they'd like to discuss. We could circle back to the blobs if there was more to discuss there. Okay, well then that's it for the day. Thanks everyone, and I'll see you next time.
01:11:09.740 - 01:11:11.020, Speaker J: Thank you. Bye.
01:11:11.180 - 01:11:11.700, Speaker C: Here's everyone.

00:03:11.450 - 00:04:10.600, Speaker A: Okay, we should be live. So welcome, everyone, to acde number one. Six three have basically a lot of cancun stuff on the agenda today, and then some engine API decisions also probably fall within that. And then if we have time, we can even talk about the validator spec. I guess, to start off, is Denkrad here? Yes, Dencrad is just joining, amazingly. Okay, so I guess to kick us off, Denkrad, you wanted to propose a change to the blob limit for EIP 4844. Do you want to take a minute to walk us through? Well, obviously why you want to do that, but mostly sort of the tests you've been doing that you think justify the change.
00:04:10.600 - 00:05:11.670, Speaker A: Yeah. So, I mean, I'm not going to repeat everything, because I presented that already on HTDC last week. So if you want to have the extended version, then I recommend listening to that recording. So the summary is, we ran some tests on main net where we created blocks of large sizes, so we simulated a sustained load, and we tried that between 128. We did twelve, 360 between. In all those tests, the network looked stable. We didn't see lots of validators going offline or anything like that, or like attestations being massively delayed.
00:05:11.670 - 00:05:49.080, Speaker A: So none of these happened. What did happen on one of the 1 mb tests is that one of the blocks got reorked. So that block was late after the four second deadline just passed, like, by just hundreds of milliseconds, so very close, and so majority of validators didn't attest to it. And so the next proposer reorganed didn't happen on any of the other tests. And as a comment, even under normal conditions, we sometimes see blocks up to like 3.5 seconds into the slot. Sometimes.
00:05:49.080 - 00:06:56.140, Speaker A: We probably did cause this, but probably not by delaying the block by 4 seconds. But probably our delay was only added up to, like, a proposal that was already pretty slow. So I would attribute that to the very aggressive four second deadline and reorgang, rather than to our tests, like nothing else went wrong other than that block being late. And so my recommendation based on these tests is that we should consider raising the limit to six blocks rather than four and the target to three, because we didn't see any problems with these loads. 168, if you can agree with that. Also, as a comment from last week, I think so, the tests were sustained loads, so we created ten blocks in a row with these capacities, so we didn't just send a single block. Got it.
00:06:56.140 - 00:07:50.584, Speaker A: And maybe. Final comment, if anyone has a look at these tests and finds something that they would really like to see. We still have all the infrastructure up to do these tests, so ideally if there are any more tests we should do, I don't think we need more, but if anyone thinks we do, then we should do these soon because it costs a lot to run these notes and we probably want to sunset them in the next few days. Otherwise. Awesome. Thanks. Anyone have comments or thoughts on this? And I guess, please go ahead.
00:07:50.584 - 00:08:27.690, Speaker A: I was just going to say it seems pretty reasonable. Maybe it's worth doing the experiment one more time. Although they're kind of expensive, but if no one has any reason not to, then yeah, I think we should consider it. Any specific experiments? You mean 768 kb because that's what we're attempting. Or what would you like to see? We did two of these, by the way, two at 768 megabytes of sustained. Yeah, maybe we're more just at like the numbers. Just try a different day, different network conditions, see what happens.
00:08:27.690 - 00:09:35.344, Speaker A: Do you want to suggest to increase these numbers right from the beginning or after a month of valuation on the main net? I mean, I would suggest doing it from the beginning. Like changing it each time is at least according to the current setup is a hard fork. So that's a lot of coordination and takes a lot of our time here. So I think it's reasonable to just do this from the beginning. And we are doing the decoupled blocks, which should actually be a lot more gentle than the experiments I've done if what we're claiming and simulating is true. So I would suggest doing this from the beginning. Does anyone think we shouldn't do this or has issues with this? Gary has a question about like, yeah, what's the max? We've pushed the network.
00:09:35.344 - 00:10:20.896, Speaker A: Did we reach 1.52 megabyte blocks? Um, so it's hard to create sustained blobs of that size because you just are not going to get all your transactions in and you're competing with other people who want to put in transactions. So 1 although even there we didn't all get into all the blocks that we wanted to. We did in that process create some blocks that were significantly larger. I think the largest was 1.7 megabytes. But yeah, first, I don't think we will see instability.
00:10:20.896 - 00:11:13.332, Speaker A: I don't have any indication on mainet that this will create instability. And second, it's difficult. I don't think we're going to learn that much because we're going to see very erratic loads in practice. Okay, I guess. Does anyone disagree with this change angar? Well, I don't disagree per se and I don't think this is a high chance, but I wanted to, at least very briefly, also do temperature check around, pushing it to all the way to four eight. So like up to one megabytes maximum. I assume most people would be.
00:11:13.332 - 00:12:05.060, Speaker A: Would feel uncomfortable with that because we do have the blob decoupling chunking to give us some extra robustness. So I would still think it's worth considering. But if people, of course, feel uncomfortable, three six is also good compromise. I think Daplion has a question around what's the added disk requirement going from two to three to four target. Right. I don't know the numbers out of my head, but I mean, it's an easy computation in this case, right? Yeah. One block is 128, retention period.
00:12:05.060 - 00:13:15.640, Speaker A: Um. Okay, so, okay, so Ben is saying two per slot is 33gb over 18 days. So three would be like around 50 ish and four would be 66, I guess. And then up to potentially. Well, yeah, I guess that's the average result you're going to get, but probably a bit more given you can go past the target, I guess. Question. Yes? Is it too late to do three six on Devnet six? I mean, basically, I think we should just roll this out as soon as possible and see what happens.
00:13:15.640 - 00:13:47.922, Speaker A: Yes, I think if we decide this, we should decide it. If not now, then on the call Monday. So that it's part of Devnet six. Yeah, it seems like it's worth doing because. Sorry, go ahead. No, go ahead. So we started off with Devnet six yesterday and we had made some progress on it, but there's still quite some teams that have not joined yet.
00:13:47.922 - 00:14:45.482, Speaker A: So this is more of a pre six launch. We're going to be relaunching it with most clients, hopefully in the coming week. If we want to make some kind of modification, it's entirely feasible. Okay, so there's a question as well as like, testing this in the transaction pool. So basically, yeah. Are there any issues potentially before the block building funnel? I don't know if there's any thoughts on that or if that's something we can maybe try on Devnet six. If not, this is kind of an orthogonal question.
00:14:45.482 - 00:15:41.836, Speaker A: Right. But separately, yeah, we should probably span mempools and make sure nothing falls over. Okay, so I think we can probably move forward to have this, at least on Devnet six and test it out there. We can also do tests for the mempool and then. Yeah, once. Yeah, once we have that running, we can reevaluate if we want to keep it like that, potentially move it to four eight or even lower it back down to four. Any objections to moving it to three six for Dev six? Ansgar? Yeah, I was just going to say, as long as there's any chance for void, I would rather have it started void.
00:15:41.836 - 00:16:28.730, Speaker A: And we can always lower it back down because I think we get just better insights. Right. Because there's nothing that would be a problem with three six that won't show up with void, but the other way around it might. So if we want to consider it at all for four, I think it would be better to start with a larger limit. Does anyone think we should consider four eight? Aside from ice cover, how much data do we have from the experiments donkey did at four eight? Yeah, we have two series of that. As I said, nothing major happened to the network. It's just that one of the blocks was delayed, so one block was often.
00:16:28.730 - 00:17:01.584, Speaker A: Right. Okay, I feel like I heard chatter about Devnet seven. So we could do three six and if that looks good, bump it up. We could also go the other way. Yeah, I think I'd also go that route. There's a question by Lucas around increasing the attestation time, which, yes, seems like a whole different can of worms. I don't know if anyone.
00:17:01.584 - 00:17:53.254, Speaker A: I think that would be a topic for FEDC, but yes, I think that's a good idea. Okay, so we can discuss that next week or. Danny, I see you coming off back up. I was having technical difficulties right when Onsgar was suggesting 48, so I kind of missed that. My gut was that we didn't have data indicating that that was a good idea and that on testnets we're not going to get that data because it doesn't look like main net. Is there an argument that I missed? I apologize. Argument was just that we will do the block decoupling so we get some extra and chunking, so we'll get some extra robustness with that.
00:17:53.254 - 00:18:34.420, Speaker A: And even without that extra robustness, we already only had very minor issues at that size. So it seems worth at least considering for Mainet. And if we want to at least consider it, it seems better to start the testnet on the upper side to see any potential issues come up there. And then we can always lower it for later testnets rather than the other way around. But if the strong consensus is three six, then I think it's also fine to do that instead. Yeah, I guess I'm not sure that I would see testnet data and then be convinced that we're good on main net because it's just extremely different topology. But we can take the step towards three six and keep talking.
00:18:34.420 - 00:19:09.590, Speaker A: Yeah, okay. Yeah. Okay. I think three six probably makes sense to start. So let's do that. Ansgar says he can open the pr for it on the el side. So if someone can do the corresponding pr on the CL specs, we can move the count to three six and have this part of Devnet six.
00:19:09.590 - 00:19:55.382, Speaker A: Does that make sense, everyone? And when is Devnet six? Just so I can time if we are doing this release like ASAP or if I can do this release next week. So Devnet six already had started, but will be relaunched next week. Okay, so this is a get this out tomorrow with desktop versus and things, rather than wait till the couple of other things we're working on. Thank you. Yes. I guess next thing on the agenda was Devnet six. Barnabas, I know you've been tracking down all the prs this week.
00:19:55.382 - 00:20:48.890, Speaker A: Do you want to give a quick update on where we are both from a spec perspective? And like you mentioned earlier, basically the first release or live test of the net six. Sure. So basically our contents in spec has been released and we have all agreed we're going to do. If we're going to change this to three and six, I think this will require another release, maybe. I don't know if there's any changes in the consensus spec for that. And then for execution eips, we also have all the prs merged and for engine API there is one more open 98. And other than that everything else is merged.
00:20:48.890 - 00:21:45.020, Speaker A: We currently have the Devon six running with Lodestar and Deku on the CS side. And we have Nethermind, Ethereum, JS and Bezu is not working just yet, but they are already part of it. And gas is also not working just yet, but they are also part of it. So hoping to the lighthouse also by the end of today without any validators, just to see if they can join the network and sync it up. And then hopefully next week we're going to be able to onboard a few more client teams with the relaunch. Nice. Okay, so you mentioned this execution API PR.
00:21:45.020 - 00:23:05.970, Speaker A: This is about adding fields to the receipts for transactions. So I'm curious, is the blocker there? I guess, what is the blocker there to get this merged? I see light client and Roberto were going back and forth on. Be curious about the opinion of the CL devs on this one. I think on this pr for execution APIs add data gas used and data gas price. That's what we are talking about, right? Yeah. So this mean it's not contentious and it was sort of mostly agreed upon and Roberto asked to include an extra field. So this basically includes these fields in the RPC and basically does not affect Devnet or the consensus.
00:23:05.970 - 00:23:51.688, Speaker A: But also I think it's non contentious so we can just approve it. There are some edits regarding some typos. I think we can just include them and try to merge this pr. And I see there's a comment by Lightsayant around there's more RPC changes for Cancun, so we wanted to merge all of them together. Is that still the case? I don't know. If you have a mic, that's fine. Hey, I think this is mostly it.
00:23:51.688 - 00:24:59.060, Speaker A: I'm not sure if there needs to be changes for the RPC to submit blob transactions and I don't know, I'm not sure if there's anything else that needs to be changed. Probably something for the actual transaction objects to denote to their blob transactions as well. Okay, so are you saying even if we merge this, there's some other change that will need to be done in order to expose the blob transactions via JSON RPC? Is that right? We have the blob transactions defined for eth get block and we don't have them defined. I mean we kind of accept them for send raw transaction because we just get RLP. So I'm not sure if that anything needs to be done if I want to submit a bob transaction to the transaction pool. But I think that there are still some things around like the actual transaction object that need to be specified. Got it.
00:24:59.060 - 00:26:16.290, Speaker A: So in that case, I don't really think this is blocking the Devnet though. Yeah, right. So does it make sense to whether or not we merge this have as like a target get for Devnet seven, the one after this, to have full JSON RPC support for blob transactions. I have one thumbs up, two thumbs up. Okay, we can or cannot merge this, but I think yeah, let's not have the full RPC support and scope for Devnet six and let's try to target that for Devnet seven. I have one more thing to mention that we would like every client to include a trusted stop file flag in their implementation where we could possibly override the TXT or Jim file for Dev. Yes, this should happen during runtime and not during compilation time.
00:26:16.290 - 00:26:51.204, Speaker A: Okay. Any client has a problem or objection with it in the top of the spec. Okay. I see, yeah, the blue section. Okay, nice. Okay, anything else on Devnet six? Okay, perfect. And yes.
00:26:51.204 - 00:27:56.516, Speaker A: So we have a call Monday as well, about four, four, four. So we can discuss any specifics with the client implementations and whatnot there. Okay, so next up, the rest of Cancun Alex, you had a question around the spec for 4788, so we can do this first. And I think after that it probably makes sense to hear from clients one last time about whether there's anything else we want to include alongside the currently included eips, so that we can start basically finalizing the scope of implementation for Cancun Alex. Do you want to talk about the issues around 4788 and state growth? Sure. So EIP 4788, this is essentially a cross layer EIP. So what it's doing is taking the parent beacon block route from the Cl, and the Cl sends that over with each execution payload.
00:27:56.516 - 00:28:58.792, Speaker A: The execution layer then basically writes that into the execution state in a place that everyone can look up. And so now we have access to this inside the EVM, which is really good for a lot of different applications. Yeah. So the question here is what exactly does this look like? The way the AP is written now is there's a pre compile that kind of exposes this part of the state. And the question then is like what is the interface to this pre compile? Essentially we've had a little back and forth about this and we talked about this some on the call last week, but essentially where things have gotten to now is that it's written by the root. And then basically what's behind the root is the timestamp from the header. So the idea is like if I want to use this thing, I can call the pre compile with the root, and if the root was valid, I'll get back the timestamp.
00:28:58.792 - 00:29:37.850, Speaker A: I can then use the timestamp if I want any vm to prove the slot and do all sorts of things from there. The thing is, the way this works is that there's no easy way now to limit how many writes there are before it was written by say the Timestamp in the header. So you could do like some ring buffer thing based on time. So what that means is as written now the eap has unbalanced big growth. And I did the calculation of something like 80 megabytes per year, assuming a block every slot. So it's not nothing. And generally it'd be good just to bound this where we could.
00:29:37.850 - 00:30:27.790, Speaker A: So the question then is how do we do that? A really natural way is just to flip how this thing is indexed. So rather than do, the key is the root and the value is the timestamp is you just flip it and then have some, say modular, some period of time for the timestamp. And then now this thing is bounded. So this works. The one thing that's a little weird is that if we really want to stick to this invariant, that the El does not know any Cl information, then what the El gets is every 12 seconds, every seconds per slot, you just get another route. And then the thing you would naturally do is just write every last second, or every second since you last wrote, you would write the root again. And what this means is that basically there's like twelve writes of which eleven will never be used.
00:30:27.790 - 00:30:53.548, Speaker A: Eleven of them will be zeros. Right. Because it doesn't know that what happened in the middle. Well you do because nothing changed. That's a design decision. I suppose it isn't. Well, yeah, and so here's the other thing, is that anyone reading this will just probably optimize it and be like, hey, there's only one write every 12 seconds.
00:30:53.548 - 00:31:29.340, Speaker A: That's just what I'm going to do. Okay. Actually Danny, the reason you wouldn't do that is because you want callers to probably be able to give any timestamp. So the idea is like for this timestamp, kind of which slot are you in? And here's the root. Well, you could also argue that callers know when blocks happened and can just call. The semantics are a bit weird if you have something that you can call on like modulo eleven. But I don't see anything wrong with those semantics.
00:31:29.340 - 00:32:26.696, Speaker A: Yeah, any questions? It would be best to bound the state growth. So then yeah, I guess we just go ahead and make the swap and then that's that. From there I'd really like to all agree on shipping this in Cancun. Okay. And yeah, just to separate those two things. So first, any objections of just bounding the size of growth, given the depth of history that we want, and given that we'd have the twelve x multiplier on timestamp, what's the size of the ring buffer? We could still target about a day. So that's what I was thinking, just to mirror the period on the Cl, because we have a similar construction there and we can figure it out.
00:32:26.696 - 00:32:47.682, Speaker A: So that's the same amount of data. Basically that's like 230 megs. Bounded 230 megs is better than unbounded 80 megs a year in my opinion. Not that it doesn't matter that much. I don't know. High. Yeah.
00:32:47.682 - 00:32:58.422, Speaker A: And that number is. I'm doing 225 times 32 times 32 to get the bytes. Okay. Yeah. Let's see. I mean, we can make the window shorter. Sorry.
00:32:58.422 - 00:33:18.186, Speaker A: Anyway, it's 230. Apologize. That's much better. That's fud. Either way, the numbers can be tuned, so it's like a small bounded amount of space. And I've talked to different staking pools. They're okay with any of these different designs in terms of index.
00:33:18.186 - 00:34:17.280, Speaker A: And as long as it's not like you have to get your transaction in the same block that the root is, I think they're okay with some amount of look behind. And I think it's probably much easier to start it off bounded, even if we eventually wanted it to grow unbounded for whatever reason. But if we do the other way around, we will never be able to bound it because someone will be relying on the first beacon route that was ever posted for something. Yeah, exactly. Whether it's a day, whether it's like an hour, whether it's a week, I think that will lead to different design and applications, and we should probably nudge towards that. I don't love the writes for every second. It doesn't really matter.
00:34:17.280 - 00:35:01.800, Speaker A: As I'm thinking about it now, it is nice because you could upgrade the slot time and the execution layer would never have to know, which is a nice property. So maybe that makes it worth it in and of itself. But I'm pretty fine with those if devs are any objections. I guess. Anyone think we should not do this? Okay. I also don't like the extra rights. The caller knows the timestamp, so they should just give it to us.
00:35:01.800 - 00:35:53.798, Speaker A: Yeah, but if you don't know seconds per slot on the execution layer, I think you do need to sweep the interim. Right, but you could just say the timestamp and the header is the value, and then like you're suggesting, the rest of them are just zeros and then it's. Right. Yeah, I mean, you either need to do that with a map or with a ring buffer. If you do the map, you have the unbounded growth. If you do the ring buffer, you have to write either zeros or the root to the interim times. Seconds, dano, not objection to the idea, but just some design questions.
00:35:53.798 - 00:36:22.678, Speaker A: Why put the pre compile at the high fs and not at the next pre compiled position? It can go wherever. So the pre compile and the state for the pre compiler are in separate places right here. Right. Like the pre compile is actually in the list slots. At least it's not right now, but it could be. Okay. Yeah, I think it's a little weird to have them be separate.
00:36:22.678 - 00:36:54.780, Speaker A: Right. Because you could still call the state separately. So I think it makes sense to have the pre compile be like an interface around the state at that address. From there. I just copied this from EIP, I forget, but essentially there was an earlier EIP that suggested moving block hashes from the execution layer to a similar method where you'd have them in the state. And I think the idea is this is a staple. So like, toss it at the top of the address space rather than at the bottom.
00:36:54.780 - 00:37:23.634, Speaker A: From an EVM implementation, it doesn't care. It calls it and gets a value. And now we have to check two separate ranges for pre compiles. So from an implementation, it would be easier just to group them together. And I don't think that the stateful distinction is terribly useful to an implementation, because it's going to be going to some method that's going to do something completely unrelated to EVM operation execution. Yes, sure. Yeah.
00:37:23.634 - 00:37:56.330, Speaker A: My gut is to not have it in the high ranges. If this is a stateful pre compile, just accept that we have stateful pre compiles and put them with the rest has been my intuition. Yeah, totally. Especially because we have already tests for it. And all the pre compiles have one way at least, like the first 1024. And we also have those set on basically every test. Net.
00:37:56.330 - 00:38:51.320, Speaker A: There's a bunch of things that can go wrong if a pre compile doesn't have any money. Just having them in the normal pre compile range can make sure that they are always funded. Yes, that's easy to do, and I can definitely do that. Okay. Any other comments or thoughts? Okay, so I guess. Yeah. Last thing for Cancun, I'd be curious to hear from client teams of the EiPs we've been discussing in the past few weeks.
00:38:51.320 - 00:39:28.020, Speaker A: Is there anything that folks think should go in Cancun? So I can post the link in the agenda or in the chat right here? But basically we have already 1153 48 44 and 67 80. So the transient storage blob transactions and self destruct removal. And then we had a bunch of cfidips. So 27 35. The BLS recompile 4788, which we just talked about. And then a couple opcodes. So m copy pay and then the revamped call instructions, which we discussed last time.
00:39:28.020 - 00:40:14.680, Speaker A: Yeah, I see. Is this Marek from Nethermind? Is also. Yes. Okay. Yeah, so some support in Nethermind for 4788. Yeah, I don't know if any client team wants to just share their thoughts about what they'd like to include. If not, I mean, does anyone not want to include 4788? Okay, this is the last chance.
00:40:14.680 - 00:41:23.270, Speaker A: Okay, so let's include 4788, final chance, if anyone has an objection, and then of the rest of the basically four other eips. So BLS, M copy, pay, and the revamped call instructions, is there anything else that people would like to include? Well, everyone would like to include the pay op code. Okay, so there's a comment for pay, a comment for M copy in the chat that came at the same guess. Yeah. Let's start with pay. Does anyone feel strongly for. Against the payoff code? Maris and Tamash are saying they'd like to keep the scope.
00:41:23.270 - 00:42:35.760, Speaker A: Yeah, go ahead. Yes, I feel strongly against the payoff code because it introduces a new way, basically how accounts can be touched, which is always kind of complicated. I also don't really see the point in having the pay op code when we have the call upcodes already. I know that there are some security issues with the call up codes, but I don't know, it doesn't strike me as very much needed right now. And so it's not really a priority for me. So I don't think we should rush it into. Yeah, Andrew, I don't know if you want to make the case for the payoff code.
00:42:35.760 - 00:43:03.100, Speaker A: No, I think. Well, there is no consensus. Then it's okay to skip it. Okay, I guess the next one. So like client, you mentioned M copy. And Charles, if you have your hand up, I assume it's about this as well. Either of you want to do a quick pitch for M copy? Yeah, I wanted to talk about McOpy and pay.
00:43:03.100 - 00:43:32.194, Speaker A: Well, let me address pay first. I think it's pretty important to. First of all, I work on Viper. I think it's pretty important to get into the EVM. I understand that there's concerns about implementation complexity, but it is important to be able to have a way to transfer ether without transferring execution context. There's a lot, really. I don't know.
00:43:32.194 - 00:44:51.594, Speaker A: I have to go through the list, but I think like 30% to 50% of these high profile hacks are related to actually transferring ether. And people are always switching to using weth instead of ETH. And we have a lot of warts in the EVM that are kind of like a result of having to deal with this gas stipend for call people are always trying to figure out how to transfer either, and then you have to do these either explicitly check for reentrancy or try to hard code a limited gas stipend in order to prevent, you know, these kinds of weird things with computation being transferred to not yourself. So that's the case for pay. I understand if it doesn't make it into this hard fork, but I think that it should be really strongly considered maybe for the next one. And then the case for M copy is, in my view, pretty straightforward too. It's pretty straightforward to implement.
00:44:51.594 - 00:46:13.770, Speaker A: It doesn't have too much. Well, as far as I know, any interaction with the other eips that are considered Cancun and it would help compilers generate much better code really. So improving on code size and gas, anybody's interested? I can kind of prototype some things to see really how much better code size would be ngas with m copy, as opposed to the current state of things where we have to issue a lot of the mstor's nodes, which is, in my opinion kind of wasteful, especially when we have call data copy and code copy and the semantics of it are pretty clear to everybody. Yeah, I think that's the case. Got it. Thanks Andrew. Yeah, I have a question about the pay op code versus the proposed code two app code.
00:46:13.770 - 00:47:40.710, Speaker A: Does code two also suffer from the reenterancy problem that pay solves? As far as I know, call two doesn't really change anything except gas observability and it removes the output buffer. So yes, it still transfers execution context to the colle, which is the fundamental problem with transferring ether using any call opcode. Understood. Okay, somebody asked in the chat if there's the transfer property of self destruct. Self destruct transfers all ether. Pay allows you to send some amount of ether, and it's also a lot less wasteful in terms of gas and I suppose touching state because you don't have to create and display think. Yeah, given the points Marius raised, it probably makes sense to not include pay for now and I know.
00:47:40.710 - 00:48:36.326, Speaker A: Yeah, I guess I'm curious to hear on the M copy side from client teams yet seems to have internal disagreement about whether to include it. Netherminds seems to be leading towards not including more in the fork, so I don't know yet. Do any of the team feel strongly in favor against including M copy? I really don't see the argument for not including M copy. It's extremely simple and a mix of functionality we already have with the identity contract. Is it a game changing feature for Ethereum. It's not, but it's a relatively simple thing. And if we want to have any chance of doing a lot of the changes that we're trying to do in the future, then we need to be able to do more than just the one thing that we want to do in the fork.
00:48:36.326 - 00:49:34.070, Speaker A: And so I don't think MCOP is adding that much to the service area. And I think there's a couple of comments in the chat about so baseu has a pr for M copy, but then maybe it makes more sense to be bundled with EOF. And then Marius is asking if anyone looked at memory expansion attacks with M copy. Charles, I don't know if you have an answer to this. I mean, why would it be any different than with the identity? I think we had issues with the identity pre compile. These are like separate things. If we have a problem with the identity pre compile, then we need to sort that out.
00:49:34.070 - 00:50:13.720, Speaker A: No, I think the issues, one of the issues with the identity pre compile having to do with having to transfer execution context to the identity pre compile and transferring call frames and stuff. So I think McOpy is actually simpler than the identity copy here. Yeah, it's definitely simpler. The memory expansion attacks on M copy is the same surface as M store and M store eight. It's all about where the highest bit of the write ends in the copy. So it doesn't truly open up any new novel surfaces. It's just the same, well, trodden surfaces from my perspective.
00:50:13.720 - 00:51:03.060, Speaker A: Yeah, exactly. And also called it a copy and code copy have the same surface for writes, maybe not reads, but for reads, the surface is the same as m load and identity copy. Sorry, the identity creepy file. And because it's priced the same as other copy operations. So yeah, that's basically what I was asking. If someone has already looked at it, and you guys seem very confident that it's not an issue. There is a cost, which is memory expansion cost.
00:51:03.060 - 00:51:48.236, Speaker A: Right. But there is no quadratic cost on the length of copied in the proposed solution. So if you copy a lot of words, then you have just linear increase of the cost, which opens potentially attack if you cannot load to memory just that particular copy, even if you copy in the same place. So you don't have memory expansion cost at all because you're not expanding memory, but you're actually expanding a lot to temporary memory needed for the EVM. Right? Or are you doing that word by word? No, you're not. The spec is written. It says that memory expansion works as if you copied to a temporary buffer, but all real memory copy implementations just branch to see if there's overlap.
00:51:48.236 - 00:52:16.930, Speaker A: And if the overlap is a certain way, then it copies backwards instead of forward, so there's no actual temporary buffer happening. Okay. Yeah. So a temporary buffer is practically doing word by word copy. Okay, thanks. Sorry. No, it's a reasonable concern, I guess.
00:52:16.930 - 00:52:41.780, Speaker A: Yeah, maybe so. On Geth and Besu seem somewhat split on this. Tamash, you said that you'd rather not have new things. Okay, you're neutral now. I don't know. Aragon, do you have. Yeah, neutral.
00:52:41.780 - 00:54:28.960, Speaker A: Okay, so it can wait for EOF. It is a fairly late ad, and with the pushback I just don't think it's worth pushing it through. Okay, I guess. Does anyone still strongly feel we should include it? And maybe one option is if the concern is mostly around the scope of the fork, does it make sense to leave that as like the one CFI thing, implement everything else and see how we're feeling in a couple of weeks in terms of implementation or if we wanted to do this, should we make the decision now so that we can start setting up both testing and implementations that support the entire scope? We'll need tests, but I think the block pre compiles are more important than these tests, so it need to be prioritized in order from the testing team. You mean the beacon root pre compiles? Yeah, the beacon root pre compiles, yeah. Okay. So that, I think people are like at best neutral around the EIP for the fork.
00:54:28.960 - 00:55:51.904, Speaker A: And I guess two options is one, we just push it back to the next fork, and another option is maybe we leave it as the only CFI things and we see how implementation goes with everything else and whether we want to add it in a few weeks. Yeah, I feel like if we can't do mcopy in this torque, then we have no chance of doing EOF ever. The surface of EOF is quite a bit bigger, I think, than what we're facing right now in terms of using things. So I would prefer that we try to do M copy now and try just to understand, is the surface too big? We can always remove it later on if we're like, look, people feel uncomfortable with this testing surface. That's been the biggest thing that I've heard so far, is that the increase with testing surface makes people uncomfortable. And I would rather go down the path and figure out what happens in a couple of months if we try and implement it, put it in the forks, do the test, and if people still feel that way in a couple of months, and if they do, then we just remove it. But if we don't do it, then we're never going to be able to tamash.
00:55:51.904 - 00:57:08.302, Speaker A: Do you still have your hand up for the previous time or do you want to add as you have no lower my cancer? I wrote in the chat I agree with the reasoning of light client that this seems to be simple, reasonable change in line with many of our goals, like moving away from pre compiles going towards UF. So for that reason it perfectly makes sense as an AP. And the only reason why I'm saying potentially no is if the teams feel like we don't want to add more things to test, more things to cross test. So it's more of a scope of the fork question rather than the IP itself, right? Yeah, I totally get that and I am boat around these things, but I think that we need to test ourselves a little bit if we're still thinking about having EOf on the roadmap. Because if we can't, again, I don't think we're going to be able to do EOF. The surface area for EOF is quite a bit larger in the EVM than what we're facing right now. And to me it's like if we go down this path and we think the service area was too big, we had to take out m copy the last minute.
00:57:08.302 - 00:58:17.420, Speaker A: That's a pretty good sign that we're probably not going to be able to do EOF. And maybe we should just make that. Based on Lucas's comments, I'd be curious to hear, just like from the testing teams. I don't know, Mario, if you're Vega, do you think McOpy significantly slows down testing efforts, or is it reasonably simple to write tests for? I think we can definitely paralyze at the moment. The problem might be that we also have hype testing, for example, for 48 four. So if anyone wants to jump in to test and copy the state tests, I mean, it's definitely welcome too. Marius had some comments that the scope might be too broad, but I don't think I totally agree.
00:58:17.420 - 01:00:00.540, Speaker A: In my opinion it should be doable. But yeah, if anyone wants to jump into implement those tests, the state tests for M copy, that would be very nice. And the state tests are the one using the new python execution test, right? Exactly. So left to do is we have to implement status for this 47 eight eight. We already have tests for 48 four and we have to transfer the 1153 tests to Python so that's the remaining to do in terms of status for execution layer? I think we can do it and copy, but yeah, if anyone wants to jump in also to help with this, that's obviously going to help a lot. I think Paul from the Ipsilon team was designing the tests and was starting to write them up, but I just ping him to see what the progress of that is. Okay, so I guess based on all of this, does it make sense to add M copy in and then in the next call or the one after? If we see that testing is bottlenecked by it, or client implementations feel like it's too much to add, we can always remove it.
01:00:00.540 - 01:01:05.546, Speaker A: So we can prioritize, basically implementing 47, eight and all the other eips that are already included, add this one as well, and then if it is a relatively small change, we keep it in. But if we find some significant cause of delay, then we should consider pulling it out. And also by doing that, close the door to anything else being included in Cancun. Yeah, sounds good to me. I mean, we can give it a try just to see how much of a remaining test we have to implement, and then we can give an update in two weeks and see if it was too much, and then we can simply remove it. Sounds good. Any objections or final thoughts? Okay, so we will add m copy in alongside 4788.
01:01:05.546 - 01:02:15.980, Speaker A: If in a couple of weeks we feel like M copy is significantly slowing down things, either from an implementation or testing perspective, we'll just kick it out. And we also will not add anything else to the fork. So this means the fork will effectively have eleven 5348-4678 so the transit storage block, transaction, self destruct removal, and then today we've added 4788, the beacon block route, and then M copy, and then the three other things that were CFI are just not included in this fork. Yeah, does that make sense to people? Okay, what else do we have on the agenda? Okay, next up. Yeah, Mikhail, you had this change to the engine API we discussed, I don't know if it was last week or three weeks ago on ACDC, about having a single structure. A single method, sorry for the v three engine API calls. Do you want to give some context on that? Yeah, thanks.
01:02:15.980 - 01:03:01.896, Speaker A: Just real quick update from that. So we decided to move with one method, one structure approach since we three since Cancun. So this is DPR. It has a couple of validations that your clients has to do. Please everyone, take a look. Any objections to how they back out? Price them? As I'm aiming to merge this early next week and after this gets merged we can outline the engine API stack for Cancun, which I guess will include probably a couple of other things. One of them is deprecation of exchange transition configuration that people were waiting for quite long time.
01:03:01.896 - 01:03:43.944, Speaker A: Another is probably the builder override flag, which worth discussion. So that's it. So please take a look at this pr those who are interested. Lucas? Yeah, I have a question. Would it be reasonable to. I know it would be a breaking change to also apply it to v two, to not allow v one there? I know it's a breaking change, but it shouldn't break anything. We already passed the fork, everyone is using v two.
01:03:43.944 - 01:04:29.536, Speaker A: So questions? Yeah, by default I would not change the fact that the duplicate is finalized. The main goal for this change is that it prevents us from ever growing complexity of support in all versions that we had before. And I think that for v two we can remain it, we can just leave it as is. It would slightly simplify our code base because we had this generic way of doing that and now we will be specific. But yeah, it's fine. And I think, never mind. Already has this implemented as your proposal.
01:04:29.536 - 01:06:08.088, Speaker A: Right now we have it. Cool. Any other thoughts? Comments? Okay, and then last thing we had on the agenda, this is more of a cl thing, but basically Enrico wanted to chat about honest validator behavior for data availability and duty production. Do you want to give some quick context there, Enrico? Yeah, sure. So I was bringing this up because I remember this conversation around probably discord with any other guys and the implication of that could have some engineering implication if we do one way or the other. But point is that should we start validating, testing and producing blocks before we actually have downloaded all the blobs up to the very end of the developability window. Or we could start doing duties once we reach the head and downloaded everything.
01:06:08.088 - 01:07:01.370, Speaker A: Because from the spec at least things I remember before, we could consider everything valid only until we have the entire data availability window downloaded and validated. Yeah. So based on past conversations and based on how the spec is written right now, you would be short circuiting the validity condition if you started testing before and it's not the intended behavior. So I believe that that's how the honest behavior would read based off of the is date available function. But if that's not clear, I think we should. Right. So actually the UDEX will be slightly affected here.
01:07:01.370 - 01:08:06.620, Speaker A: If you want to, for instance, switch CL and you just remain with the same El that is already in sync, then you wipe out the base, which means that you can checkpoint sync quickly, reach the head and then wait the full to be downloaded. And the client should start behaving like we should download all the deliverability as quick as possible. While it's not just an historical sync that currently is kind of low priority download. But now we should start changing internally how the client behaves there. Because we want to reach the availability boundary as quick as possible. Right. You could imagine some local UX affordance where you could just dump that data and import it directly if this Ux you thought was really high priority.
01:08:06.620 - 01:08:53.086, Speaker A: But I do think that if we don't do that da check and kind of just when you're initially syncing, then we kind of begin to break the honest behavior. Not radically so, but we're putting a chip in it in a way that I think could not prove. Right. Okay, so it's an item that we actually have to work on. Yeah. What's the amount of data on the current window? Gigabytes don't have the number at the moment, but 33gb. I don't know.
01:08:53.086 - 01:09:46.150, Speaker A: Is the calculated on four blobs? Yeah. Is that three six or forward two four. So yeah, it will take some time and it could be felt by the users for sure, if people want to think about the full data. Sorry, I was just wondering how much time it will take for this data. Because there is the El client, which is syncing as well. So it probably won't be terribly. Yeah, I'm focusing, particularly if you already have an EL that is up and running.
01:09:46.150 - 01:10:45.910, Speaker A: If you have to sync both of them, definitely you still have to sync the. Probably the Yale will take more time, but there will be contentions on the bandwidth for sure. So yeah, everything will be lower. Okay. I'm not 100% sure what the right next step is here. Yeah, let's pick it up on the flare call. If it's a UX that we care about, then there might be some standards around dumping and porting data and stuff.
01:10:45.910 - 01:11:11.102, Speaker A: But I'm happy to pick it up there when we have more people with context. Well, the action point here is maybe make things definitely clearer in the validator. Honest validator. Just drop maybe a line that says clearly honest behavior, at least for my understanding. Maybe other. Yeah, I can put up a pr to that. I think it's implicitly clear with the definition of the function.
01:11:11.102 - 01:11:52.266, Speaker A: But a note that just says note. Thus you must backfill. Yeah. Consider valid until all valid blobs have been downloaded. What do you mean by all? In this case, could be related to the blobs that you're validating at the moment for that block. All here is intended by all blobs for the entire availability window. Yeah, and I'll do a pass on it just to make sure the language is clear based off of a handful of iterations that might be, as you point out, not so clear.
01:11:52.266 - 01:12:51.358, Speaker A: But I'm happy to do. Thanks. Okay, so Marius wanted to talk more about the blob number. We can do that, but right before, I guess, Barnabas, you wanted to give a shout out to the new testnet call next Thursday so we can do that. And then if anyone who doesn't want to chat about blobs wants to leave, they can drop off and we can use the rest of the call to go into more blob conversation. Yeah, Barnabas. Yes, we will have our first hoyaski call next week on Thursday at 1230 utc time, and we would like to see everyone, at least one person from each client team to show up to this.
01:12:51.358 - 01:14:04.882, Speaker A: We would also like operators to also show up to this meeting. Sounds good. I guess on the call you're going to decide when Genesis would happen for the network? Yes, we expect it to happen on merge day. Okay, I assume this means for the purposes of Denkun, we should still consider Gordy and Sepolia as like the main testnets. And if there's a world where Denkun has already happened when this goes live, maybe not. But if this is going to go live in September, we shouldn't count on it as like a test net for this fork, correct? Well, I assume Denkun will. If it doesn't happen before September, then we can also use this testnet to test Dankun also, right? Yeah, I would actually say that we should definitely use this one because the idea is that this testnet, this is bigger than Curly and bigger than Mainet.
01:14:04.882 - 01:15:17.120, Speaker A: So it would be the first opportunity for us to test how we perform with a large number of validators. Got it. In that case. And unfortunately I don't think I can make the call because it's 430 A-M-I think my time, but I would potentially push to start it one or two months before September 15. If we're ready to fork a first test net or second test net in the summer, then having this one ready would be good. I don't think we would have the time, to be honest, to launch multiple months before the September deadline because we would need proper client releases and we would need quite some organization for this because we plan to run validator set on Minneap significantly larger. And for that, client teams will probably need dedicated infrastructure to run it.
01:15:17.120 - 01:16:00.480, Speaker A: So this is going to be a significant deployment. Got it. Require quite some planning. This is why it would be very good if we could have someone from client team to show up in this call next week because we're going to discuss the details there. Okay, sounds good. Any client team have thoughts or comments you want to share now? Okay, so if anyone wants to not talk about blobs more, this is your chance to drop. Otherwise.
01:16:00.480 - 01:17:10.100, Speaker A: Marius, you had some comments saying the get team felt uncomfortable with the three six change. Yes, sorry, I joined five minutes late, so I missed the discussion at the beginning of the call where apparently this decision was made. Yes. So I have prepared a statement. No, I've not prepared a statement. But the thing is, during these tests, we've seen that with 1 mb blocks, we start to lose attestations quite quickly. And what this suggests to me is, and these blocks are possible right now, what that suggests to me is that we already have too big of a gas limit.
01:17:10.100 - 01:18:06.760, Speaker A: And it could already be the case that if someone would send these big blocks for an extended period of time, then a lot of nodes would not have enough time them to attest to them. And thus we would lose a lot of attestations. Now, there's no indication, though, that this is like. So yes, we lose attestations, but why do we lose them? It is only due to the reason that these blocks are late. Like that they arrive past the four second slot time and blocks arriving very close to that already happens. Look at those graphs and see that even outside our tests, you see those late blocks not quite as late, but like, very close to that. And you see drops in at the stations.
01:18:06.760 - 01:18:49.856, Speaker A: Yes. So I think the argument here is not that there's no sustained effect on the network. Like, all those nodes are well able to catch up with the network. They just see that particular block late. So I think the case is actually just that our four second deadline is too aggressive and not that this is too much load for the network, but we have that four second deadline for a reason, right. Probably can change it. I mean, I would actually suggest that's not something we can do tomorrow.
01:18:49.856 - 01:19:24.000, Speaker A: That's not something we have a lot of data on. But whatever it is, I want to push back against the claim that this is net stability of the network. Okay. But it is one particular, very aggressive deadline that we have. I think the strongest argument here is that when you increase the target of large data payloads which you do with blobs. So you would regularly get that you decrease the cost to push that over a threshold with call data. Yes, totally.
01:19:24.000 - 01:20:00.350, Speaker A: That's exactly my point. We can do this right now. And the only thing that is prohibiting us from creating these big blocks is cost. And with four, eight, four, we make this attack way cheaper. And we have to all be clear about this. This is the case, and we are fine with it. And I'm also fine with decreasing the cost for this attack, because I still think this attack is kind of extremely costly and cannot be sustained for very long.
01:20:00.350 - 01:20:53.420, Speaker A: But I think we just have to be clear about this. We're making this attack more possible than it is right now. And with increased blob count, we make it even easier to do. My suggestion would be to start slow with two four, which is already kind of high in most cases. And then if we see that this works reliably on Mainet for a long time, we can increase it. Yeah, I just think that it's too conservative. Like, in my opinion, even three, six.
01:20:53.420 - 01:21:44.350, Speaker A: I mean, I'm pushing for that because I've seen that this worked reliably. But I know that there's a lot of demand out there. There are so many teams right now building on those blobs and really wanting those, and we're already very late at delivering these. It's just like we are always making the most conservative decisions. Yes, because we have to. It's a billion dollar ecosystem, and if we make rush decisions and we realize that 10% or 20% of the nodes are falling off the network because they cannot reliably follow the chain anymore, then that is really, there's no reason that indicates what you're saying. That is completely wrong.
01:21:44.350 - 01:22:15.816, Speaker A: I think that's ridiculous. We haven't seen. A late attestation doesn't mean that you are pushed off the network. A late attestation just means that you miss a little bit of your reward and you're still attached to the chain, you're still finalizing the chain and so on, and that the block has a higher chance of being reorganized. Yeah, that's true. But I mean, I would suspect that in this case, where this happened, because we have seen like a 1.7 megabyte block that was included, no problems.
01:22:15.816 - 01:23:08.884, Speaker A: So there's a high chance that this proposer already had other problems going on. They probably only published there. Maybe they were actually, like, gaming mev and published their block 2 seconds late already. And in this particular instance, it went wrong. So I don't know, Edgar, you've had your hand up for a while. Yeah, I would say just in terms of process here, I think Marius'concerns are somewhat warranted at least sounds to me like. But given that we debated this quite a bit earlier and there was again even some people in favor of void, I think I'd personally be against walking the spec now because some people have also already left the call and we can always change the spec at some of the future calls before we actually have the fork.
01:23:08.884 - 01:24:07.550, Speaker A: It seems like a sane default for the testnet at least. And I think if this is a concern, then I think we should just in general study potential ways to address this, the potential change of the four second window. Also I think a potential call data cost increase, a small one for Cancun, might be something you would want to consider. But I think walking the earlier decision back now would just not be the proper process here. Well, on the process bit, I think we're still in the main call time and I think pretty much all the four, four four people are still here. But the thing I'd want to avoid is if we drop having clients do useless work of implementing the change and then reverting it in two weeks, the change is just changing a constant. Right, right.
01:24:07.550 - 01:25:10.536, Speaker A: If that's the case, yeah, I'd probably lean towards we keep three six for the Devnet. But I do see Maris's argument where the devnet is not going to tell us about the potential concerns we'd see on main net. Right. And I don't think we're going to resolve that in the next five minutes, but we can discuss it on the call Monday potentially. So I'm not against having the definite 36 if we don't take this as an indication for mainnet because it's useless. It's just different for. So does it make sense? So, Marius, I mean, my counterclaim here is if you're making this argument, you should make the argument that actually we should limit current blocks much more than we should limit.
01:25:10.536 - 01:25:56.092, Speaker A: Like, I find this very strange that we're making always these decisions and we are always much more conservative on whatever new we are introducing compared to all the existing stuff. That's already pretty docile. Yeah, I'm sorry, why are you not coming with the same force out here and saying we should limit blocks to 700 kb? Because it's then I will take you more seriously. But this one, I feel like it doesn't make sense to me. That's nice of you. If you take me more seriously, then I've been saying for a really long time that 30 million gas is too much and is a lot. Sure.
01:25:56.092 - 01:27:10.784, Speaker A: But I mean, clearly the Ethereum community as a whole has not considered that to be what the direction they want to take. So I kind of feel like now it seems not fair that suddenly all core devs override the Ethereum community on this in the case of blobs. Clearly, if this is the case, then maybe we should add the voting to the network on blobs the same way it works on gas now and let the community decide on this what they're comfortable with. But then you delay for it for four by six months. So, yeah, I think clearly we're not going to resolve this now. I do think it's probably worth going ahead with the three six on the Devnet and then maybe using the call, the four four four call on Monday to focus on specifically what we would want to see to convince ourselves that this is safe for main net. If there's anything missing.
01:27:10.784 - 01:28:26.500, Speaker A: I don't know, Marius, if you can be there on Monday, or someone from Geth can be there, but, yeah, I think it probably makes sense to have a longer discussion about that there. Yeah, Lucas, I'm not sure how serious of a suggestion that was, but we currently vote on the gas limit, which is basically the same thing. Right. Okay, anything else before we wrap up? Okay, well, thanks, everyone. So we decided, okay, we're keeping three six for the Devnet. We'll see whether we want to make this the main net constants, and we can discuss on the four four four call Monday what potential issues there are with making moving three six to maintenance. Sweet.
01:28:26.500 - 01:28:42.180, Speaker A: Anything else? Okay, well, thanks, everyone. Talk to you all on Monday. Thanks a lot. Thanks. Bye bye.

00:00:00.970 - 00:00:17.200, Speaker A: Yeah, I don't actually have the agenda in front of me, but. Okay, maybe let's start with the client updates first. Dano is first on the list. So, Dano, if you want to go first.
00:00:20.700 - 00:00:52.172, Speaker B: I've been on vacation for two weeks, so I haven't gotten much done. I listened to all four devs call. I guess that means we're not canceled. I don't know. I'm getting some tasks finished at Hadera, then I'm going to pivot back into making sure that what we have in the mega Uf branch on Besu matches. What is with EVM one and working on getting testing and differential testing done? I know there's a lot of things that I haven't updated. The specs have changed because they were kind of floating.
00:00:52.172 - 00:00:57.770, Speaker B: But now that we got confidence the spec is mostly done. I think it's worth putting in time.
00:01:03.520 - 00:01:03.964, Speaker C: All right.
00:01:04.002 - 00:01:57.472, Speaker A: Yeah. We should get back to the testing question after the client update. Iman, you want to go next? Okay, your mic is not working. So you got back to implementing the mega spec? I suppose. Awesome. What's your status? What kind of parts have you implemented? Hopefully you're typing. Oh, nice.
00:01:57.472 - 00:02:30.220, Speaker A: Most of it. All right, hopefully you might going to come back later for the call? Yeah, keep writing if you have any more updates. Otherwise, I'm going to move on to. Okay, you're still updating the test from the previous implementation? Are you using any of the. Yeah, I mean, let's get back to a testing discussion after the Ram. I'm not your maintainer. Which team you are with, but you sound like you're maintaining a client.
00:02:30.220 - 00:03:11.244, Speaker A: Maintainer, eat. If you're talking, your mic is muted. All right. Apparently you won't talk. I know I pronounced your name last call, but I still don't remember what's the proper. Is it scorbaggio? I don't know. Sorry for the butchering it.
00:03:11.442 - 00:03:37.130, Speaker D: Yeah, scorbaggio. Yeah. Since the last meeting, I took a look into old implementation that was done long ago for the Ethereum js client for EOF, and I've just kind of been digging into that. It's not all the way up to date, but, yeah, that's the main thing since last time.
00:03:40.980 - 00:03:43.010, Speaker A: So that's on Ethereum js, right?
00:03:43.540 - 00:03:44.290, Speaker D: Yes.
00:03:48.260 - 00:03:52.340, Speaker A: Is this implementation from like 2022 December?
00:03:56.040 - 00:04:11.720, Speaker D: I don't have a specific time, but yeah, it seems like it was completed a while back when it was going to be included in one of the hard forks, but it was delayed, so it just kind of sat around and it needs to be updated.
00:04:14.400 - 00:04:43.620, Speaker A: Yeah, I think the base format shouldn't really have changed too much, but obviously we do have a lot of other changes. Yeah, just make sure to look at the mega spec. I think we could probably point you to the spec of that era, the December 2022 version, and then you can compare it against the megaspec and it should help you see what needs to be updated.
00:04:45.400 - 00:04:46.148, Speaker C: Yeah.
00:04:46.314 - 00:04:58.490, Speaker D: Is that a link will be shared in the chat or is it just going to be in the same repo, maybe like an older commit or something?
00:04:59.980 - 00:05:37.510, Speaker A: So the Megaspec is in a repo now. Let me give the link, but the December version is a note, just a HecMD. I will try to find it in a sec. Okay. Why I look for the link? I think we could move on to charts. I know you're not a client, but you're Viper, but if you want to give a short update.
00:05:41.450 - 00:05:57.750, Speaker C: The Viper implementation, no updates. I did submit the VLQ, the variable length spec update, though we can talk about in a minute if you're ready.
00:06:00.890 - 00:06:15.470, Speaker A: All right, so you made progress on that? I think last time we discussed that you could make like a pr just to see what kind of change to the EIP, just to see what level of changes it would require. Right?
00:06:15.540 - 00:06:30.260, Speaker C: Yeah, I thought for some reason that this meeting was tomorrow, so I procrastinated, but I just submitted it right before the meeting, so I pasted the link in the discord. I'll paste it here too.
00:06:31.270 - 00:07:03.446, Speaker A: All right. Yeah, let's discuss it after the round. Okay. Then I'm going to call up Ipsilon and somebody from ipsilon first just give an update on the implementation, like EVM one part and then separately maybe testing, and then finally we can move on to spec discussions. Pavel Andre Raddick in the implementation we.
00:07:03.628 - 00:07:45.730, Speaker E: Implemented return load and almost finished, I think, updating DAPN and swapn for the UF spec. And another thing is we have EVM max instructions on review. So this is only instructions, implementations part, as I understand. And yeah, some things are still in progress like create instructions and stack validation, new algorithm and exchange of code still not implemented. Yeah, that's about implementation.
00:07:56.050 - 00:08:00.430, Speaker A: Any updates on the testing aspect, like test generation?
00:08:06.780 - 00:08:49.770, Speaker E: We didn't do anything this last week. We still have this ER on test repo with tests in field format that's only for creation for grade three, I think. Yeah, we probably can work on generating fillers out of that too. But I should note that these tests are not all of the UF tests that are needed. These are only for creation, actually. Create three and create four, I think. So we will not cover with this all of the tests needed.
00:08:57.890 - 00:09:19.400, Speaker A: I think there were like several discussions to use the new testing format as well from Mario's team. Do we know what is the status of that? Are we still generating the state test format or are we generating data format? Are we generating both?
00:09:20.410 - 00:09:53.710, Speaker E: We're generating the old format because new format is just Python code and it also in the end generates blockchain tests of the old format. So it wouldn't make sense to generate python code. So we kind of generate the final form currently. And what's the status of the effort to write tests in new format? I'm not sure, probably no updates.
00:10:02.990 - 00:10:30.610, Speaker A: Regarding the clients, other clients and testing. Everybody is still using the state test format is my assumption. So this approach still is valid. Is everybody using the same version of the tests we have or what is the current way of coordinating the testing approach?
00:10:31.910 - 00:10:39.300, Speaker B: Are these the tests in ethereum tests or wherever it is?
00:10:44.320 - 00:10:49.660, Speaker A: Yeah, but I think it's in a separate repo now, right, because it's not upstream. Andrea okay.
00:10:49.730 - 00:10:50.350, Speaker B: Yeah.
00:10:54.000 - 00:11:08.180, Speaker A: No, I think it is already merged in the main ethereum test and yeah, I think the latest tests are already merging in the main. I think it's developed branch.
00:11:17.060 - 00:11:42.020, Speaker E: Yeah, but I think that it's mostly execution tests that are still working according to current spec. And there are many tests that use creation and they use still create upgrade two. So these need to be updated for new creation. So it's a mix of some tests still should be working and some are outdated.
00:11:50.390 - 00:12:03.800, Speaker B: So one test format that I think is missing is the validation format, because we went through a lot of validation format fuzzing about this time last year and had set up a file format, but that wasn't accepted by the Ethereum test team.
00:12:04.250 - 00:12:11.750, Speaker E: It was, there is one, and it's also in merge and develop. There are some number of tests for validation.
00:12:13.690 - 00:12:31.166, Speaker B: It's not the same thing. They're running it through creator, which is much slower, rather than just running the validation directly and getting the output, unless they've changed it since last time I've looked. But what? The first pass was just another set of tests where they try and make create fail, which was not the same thing.
00:12:31.268 - 00:12:38.290, Speaker E: Yeah, that was the first approach. But this posted the link. There is a new format specifically for validation. It doesn't run creation.
00:12:42.070 - 00:12:42.434, Speaker C: Well.
00:12:42.472 - 00:13:09.650, Speaker E: These are json tests. Maybe I will link to sealers. It's just bytecode, unexpected error. This is basically the format.
00:13:13.060 - 00:13:41.960, Speaker B: But it's not spitting out the discovered code sections. That's what I liked about the format that Marius put together, or Martin, whoever it was, is you either got a failure or you got the list of the code sections. And maybe we should put in the data section here as well. It would show some more validation about that you parse it correctly, not that you just detected invalid parsing. And I'm looking at this and.
00:13:44.330 - 00:13:44.694, Speaker C: Was.
00:13:44.732 - 00:13:52.970, Speaker B: There any examples that passed? Yeah, it just is all true. I think we're missing signal from this new format that we had. In the old format.
00:13:58.270 - 00:14:00.300, Speaker E: It has error message at least.
00:14:00.750 - 00:14:08.960, Speaker B: No, the error message is one failure. But when it passed, we passed in a string that represented all of the code sections we found.
00:14:15.640 - 00:14:52.384, Speaker F: So mostly what Martin did was that the tool that was running it was expected to also in the case of EOF being valid, he was outputting some details about the internals and that was kind of roughly specified what it's supposed to be. So it was mostly, I think it was just context of the sections. I believe something like that. The container was removed and the section were just separated by space. Something like this. I think we can add it. I'm not sure.
00:14:52.384 - 00:15:13.110, Speaker F: This is like super stable, super stable test format that all the people are interested in this are already here, so I think we can modify it. I'm not sure if they are up to date. That's the main issue.
00:15:15.880 - 00:15:20.330, Speaker B: Okay. Yeah, I haven't run these yet. I haven't got through that.
00:15:26.020 - 00:15:29.760, Speaker A: Do you have any tests on the creation transactions?
00:15:35.400 - 00:16:16.490, Speaker E: So the creation transactions, probably not yet, but we might be able to generate them easy, like similar to what we have for grade three. Probably not sure. Maybe it's because it's a new kind of transaction. Maybe it needs some special support on the tests. I guess it does like at least new field for any codes.
00:16:24.500 - 00:17:11.530, Speaker A: Yeah, I suppose it's not a blocker for the client implementations yet, if they mostly first have to be up to date with the spec. But yeah, if implementations do complete, then it's going to become a blocker. Do we have any estimation how long it will take to get those tests, like at least the first version of those tests out? Andre, do you have any estimate for creating the transaction tests?
00:17:13.870 - 00:17:43.250, Speaker E: If we come up with some format for these tests, then I guess we can generate them at least from those unit tests that we have. Yeah, we can have something in the next week or something, but also in state test format, in this new format derived from, derived from state test format.
00:17:54.600 - 00:18:18.248, Speaker A: Awesome. Yeah, I think that I do see that as a tiny risk, us fighting with the testing format and transactions. So it would be nice to at least get a smoke test running to understand if there are any questions there. All right. Do you have any other comments on testing before we move on to spec discussions?
00:18:18.424 - 00:19:06.510, Speaker F: Yeah, so I think rather quick summary is that we can follow the kind of regular, kind of, I don't know, pipeline of producing tests which will end up in this ethereum test kind of scheme. And we were doing that. It's a bit slow because there's multiple tools you need to have to do it, but I think this works. But this opened up some opportunities to improve the system and maybe that's just confusing that we talk about different things. But I think we can follow the old path for now and unless someone has suggestions how to change it.
00:19:16.090 - 00:19:16.406, Speaker C: I.
00:19:16.428 - 00:19:27.498, Speaker A: Have a feeling you won't get any feedback before people start using it. Other clients start using it and then once they do, then there's going to be a lot of complaints if something doesn't work.
00:19:27.664 - 00:19:56.740, Speaker F: Okay. I think it's fine. We kind of open for comments because there's multiple levels of issues. First one is the format itself, the JSOn that is missing some information. Sometimes it's difficult to debug and all of that. You're probably familiar with this, so I think there are some options to improve that, but I don't think we'll do much unless someone actually has specific request. I don't know.
00:19:56.740 - 00:20:05.670, Speaker F: Yeah, so I don't want to prolong this, but that's more or less think overview.
00:20:12.850 - 00:20:41.320, Speaker A: Sounds good. One more question on testing. Do we expect to upstream everything or do we expect to have a separate repo for the time being for these tests? And if we do expect it to be upstreamed, what kind of run trip time do we have for merging the changes? I know some of the old ones took like consider very long time, but maybe it's different now.
00:20:57.230 - 00:21:13.230, Speaker E: I think we can probably merge them because for now these tests go into this Eips folder, which is for some future updates and they don't care that much, I think, about those tests.
00:21:22.580 - 00:21:50.424, Speaker A: Yeah, obviously merging it upstream is the best option. Hopefully it's going to be merged quickly. All right. Before we move to actual specs, I see there's one more person on the qualify. I think it's written in reverse. Maybe Mac Ali would be the name. I'm not sure if you're with a client, do you want to give an update? Hi, I'm not actually.
00:21:50.424 - 00:21:52.852, Speaker A: I'm with blockworks. I hope I'm not intruding.
00:21:52.916 - 00:22:04.990, Speaker D: I regularly attend the ACD call on YouTube and was curious about Eof doing a follow up story. I cover a lot of the Ethereum ACD goals, if that's all right. I was just flying on the wall.
00:22:07.040 - 00:22:38.580, Speaker A: Yeah, that's fine. This is fully public. It may be a bit dry conversation wise, but happy to have you here. All right, let's move on to spec updates and discussions because we only have 30 minutes left. I'm not sure Pavel or Andre do you want to give an update regarding spec changes? And then I think we can discuss first maybe the proposal from charts.
00:22:43.820 - 00:22:58.700, Speaker E: I think the only change was we added return data load into Megaspec and nothing was changed in terms of design changes, just minor updates.
00:23:09.370 - 00:23:20.620, Speaker A: Sounds good. Charles, do you want to get started? Do you want to maybe briefly present what you did and what you have found?
00:23:20.990 - 00:24:21.562, Speaker C: Yeah, so I basically went through the spec and everywhere there was like an offset or a length I replaced it with. Well, okay, first of all I decided on the encoding format and I just picked VLQ because it's big indian and it's fairly easy to understand. There's a signed version and an unsigned version. Basically the unsigned version is easy to understand and then the signed version, I should write a reference implementation so it's clear. But you just sign extend it and then encode it like you would an unsigned integer. The only weird thing about the sign thing is that you sign extend to a multiple of seven bits instead of a multiple of eight bits like you're used to. Should I share my screen or something? That might be easiest.
00:24:21.706 - 00:24:27.310, Speaker A: Yeah, that sounds good. So this is a lab one to eight, right? That's the encoding?
00:24:27.470 - 00:24:31.330, Speaker C: No, I use VLQ. The difference is big versus little onion.
00:24:37.990 - 00:25:08.140, Speaker F: Yeah, I think going what specific encoding we want. It's probably like too much of bike shedding at this point. But yeah, I think that the quick summary, it's like lab one to eight, just like the variant of that. So kind of similar complexity, what I've read before the call. So let's see, variant of this, I would think it's like good starting point.
00:25:09.170 - 00:25:09.920, Speaker C: Yeah.
00:25:18.670 - 00:25:22.602, Speaker B: Did we lose audio? It cut out.
00:25:22.656 - 00:26:13.994, Speaker C: Yes. Hello, welcome back. Thanks. I guess it does that when you screen share it switches to the audio of the tab. But anyways, we're. Did I cut out? I think I was saying I'm not too concerned about the specific encoding, but it should be something that people expect and it should have this property that it's small for common cases where the value is small and yeah, I think variable length, so it just kind of scales with the size of the input is good anyways so we can go through.
00:26:14.032 - 00:26:18.410, Speaker B: I think your samples for 127 and 128 are wrong on the signed veil cues.
00:26:19.330 - 00:26:22.560, Speaker C: Yeah, I think I left a note to double check it.
00:26:25.810 - 00:26:33.614, Speaker B: 127 should be 87 f and 128 should be 810 zero. The positive values.
00:26:33.742 - 00:26:36.754, Speaker C: Yeah, that sounds right because you might.
00:26:36.792 - 00:26:43.780, Speaker B: Have 80 in the case where the low bit is a positive sign indicator and that's the only case you can do an 80 in.
00:26:44.410 - 00:27:44.470, Speaker C: I think what I want to do is actually implement it and then that'll be the implement a reference implementation, that'll be, I guess the final say. But anyway, so you can see here, a lot of stuff is just simplified because we don't actually need to decide beforehand how big things can be. We just say it's like feel, hue. Oh, one thing is I decided to add a size bound because I think most implementations want to use a native word to store these things when they actually not during encoding but during the actual running of the thing. And it's easier if things are fit in a pointer. Okay, so I just replaced a lot of these with the maximum is variable. There's some interesting things here where I actually should change this to variable because the 1023 bound is actually checked during code validation.
00:27:44.470 - 00:27:48.460, Speaker C: Actually, let me push my changes that I just had.
00:27:58.130 - 00:28:13.010, Speaker A: I do have one comment. It actually didn't occur to me that we were planning to use the encoding also in the instructions. I thought we were mostly concerned by the headers.
00:28:13.590 - 00:29:21.830, Speaker C: Yeah, I ended up just putting them in the instructions and it turns out that everything works quite well. But let me finish here first. The only weird thing is that we use ox 80 for the non returning functions. I think, oh fuck, that's a mistake. And I think that was proposed by Andre and it's a little inconsistent with everything else. So I would suggest that to indicate a non returning function, you set outputs equal to the max stack height plus one, and that's the new sentinel and I can update the code validation rules. I also took the liberty of, as Alex pointed out, it's a liberty of changing all the offsets in all the immediates for the instructions to be variable length two.
00:29:21.830 - 00:30:08.004, Speaker C: And I think this actually solves a lot of problems because we don't need to decide how big things need to be. So for example, I remember there was like some kerfuffle about R jump v, like how many bytes do you need to encode the immediate where did this go there? And like this guy. And now you just don't need to have a limit on how many things can be in the jump table. And a lot of things improve in the same way for our jump.
00:30:08.052 - 00:30:55.210, Speaker B: I don't like what variable links do to the implementation when it's fixed length. It's a lot of assumptions you can make about code location, about where jump five is going to be. It's a very simple math. Now you have to parse and read the entire table, which goes on to my second critique of this, which is, it's going to make some cases, because again, if you get an r jump into a large table that goes across multiple chunks, you can skip those chunks, but in this case, you have to parse the entire table. So when I went through my analysis, R jump is where I decided that variable length might actually reduce utility of some of the instructions that we have, that the fixed length actually serves a very valuable performance purpose in our jump v.
00:30:57.980 - 00:31:44.740, Speaker C: That's interesting. Yeah, we can revisit rjump v. I think that for R jump and rjump I, they should be variable length because that makes it easier to lift some code size restrictions in the future. And same here with call f. It opens up the number of possible code sections in the header. I think we can actually remove the terminator because we know. I actually was confused why there is still the terminator field because we already know the number of code and data and container sections.
00:31:45.320 - 00:32:11.280, Speaker B: So I view that as being forward compatible. If we add new type fields, this is the signal. Say we're done with type fields. So if an old system tries to read a new version with new type fields, and they see like type five before they see the terminator, they know they can't validate it. So the terminator is the signal that we're done. That makes it clear that we haven't added unknown types and it preserves forward compatibility.
00:32:13.700 - 00:32:31.510, Speaker A: So with the terminator in place, you can still implement this as a simple loop, like reading the header. Yeah, it's probably not what most implementation is going to do, because we have a kind of fixed header, but technically it still makes it possible.
00:32:33.240 - 00:32:46.300, Speaker C: I don't really understand the forward compatibility because what's going to happen is you run into a type kind that you don't know how to validate and then you need to bail out anyways.
00:32:47.120 - 00:33:03.824, Speaker B: How would you distinguish that type kind from the body section? What if the body section starts with a five or an eight, and we have a kind data that's eight? How do we distinguish a kind type header from legitimate data?
00:33:03.862 - 00:33:11.088, Speaker C: Of the next section, because all sections start with the kind, right?
00:33:11.174 - 00:33:34.830, Speaker B: But we're adding in a future version a new kind that just happens to be whatever the first valid input number of your body might be. How do we distinguish those? The way we distinguish it is we have a zero kind, which says we're done with the header, and then you move on to parsing the body.
00:33:35.920 - 00:34:16.190, Speaker C: Yeah, okay, I guess that answers my question. Yeah, so I think it becomes like a little bit important for these to be, um, variable length if we want to increase code sizes in the future. And by the way, I noticed that data load n is cheaper than push n, which makes it preferable for compilers to use push n.
00:34:19.410 - 00:34:20.046, Speaker A: Yeah, I think.
00:34:20.068 - 00:34:47.320, Speaker F: It would be nice to fix that, but I think we restricted ourselves from changing gas costs of existing instructions just to limit the number of changes. I don't think there's reason, there's no reason in current EVm to push have value three so much.
00:34:49.630 - 00:35:01.240, Speaker B: Even if it was more expensive, I would see compilers using data load n for duplicate values across multiple places. Anyway, let's say they're pushing the same constant.
00:35:02.060 - 00:36:36.610, Speaker C: It's like generally better to use data load n, except for maybe small values like push zero and push one. Basically. Um, by the way, with the, excuse me, with the variable length immediates, we can actually refactor swap in and exchange, which was kind of contentious for a long time. And the main difference is that is the encoding of the nibbles. So I haven't completely thought through it yet, but if we can use maybe Dano's encoding and we can do something like the immediate always has to have, we just divide like the number of bits by two, and then the lower bits are considered like the low, the first stack item. And yeah, there's some way of encoding it, but the low bits encode one stack item and then the other bits encode the other stack item. And then like solidity and Viper all get to have good properties.
00:36:39.210 - 00:37:03.386, Speaker A: Doesn't the variable length encoding kind of conflicts with the two nibble encoding? Because basically what this means that m always going to be restricted to the low nibble and n or the top n can grow to whatever.
00:37:03.568 - 00:37:07.840, Speaker C: Yeah, I think that swap n and exchange should be refactored now.
00:37:12.770 - 00:37:14.800, Speaker A: Refactored into what exactly?
00:37:17.030 - 00:37:28.500, Speaker C: Single instruction, which takes a variable length immediate, and then I think the low bit, sorry, let's see.
00:37:31.830 - 00:38:05.280, Speaker B: I think for simplicity of understanding, we just merge swap in and exchange into one that takes two VLq values and then you can go wherever you want. It makes swap three bytes. But the only reason we were packing into exchange is because we wanted one and two byte variants because we didn't have variable lengths. I'm concerned that if we get too tricky, I mean, if we do it, we should have swap n, have two values, and have one be the first and the second be the delta. And exchange be limited to a single byte that is not variable length, and use the old encoding if you're trying to save space. But I don't know how much that really saves us.
00:38:05.650 - 00:38:12.002, Speaker C: I think that having a two byte swap instruction is important for code size.
00:38:12.056 - 00:38:27.240, Speaker B: Right, for code size. Then let's make swap n a three byte where it's n and m and you swap n and the n plus m values and keep exchange, not make it VLq, keep the current single byte encoding on it and not even mess with the VLq stuff.
00:38:28.970 - 00:38:34.380, Speaker C: I think that you should be able to encode a swap in a single byte, basically.
00:38:39.070 - 00:38:45.520, Speaker B: That would be, well, opcode and immediate operand. You want the swap encoded in a single immediate operand, right?
00:38:46.930 - 00:38:47.680, Speaker C: Yes.
00:38:48.450 - 00:39:18.710, Speaker B: So we keep the current set up for exchange, make it a u eight immediate for exchange, and that gets us up to 16 and 32 and anything below that. Beyond that we use swap n, which actually has two arguments, n and n plus one. Not n and n plus one, but n and m. And you swap n and m. And m is the n plus m. If you need more than one byte, then you just encode them as VLq values. So if you're swapping 123 and 124, yeah, it's going to be four bytes.
00:39:18.710 - 00:39:26.090, Speaker B: But I think that at that point you're not really worried about code size. I think it's added too much complexity to move exchange to VLQ.
00:39:29.230 - 00:39:39.950, Speaker C: I think there should just basically be one instruction and it takes one VLQ immediate, and then we can be a little bit clever about the encoding, but not necessarily too clever.
00:39:40.530 - 00:39:42.030, Speaker B: I think it's too clever.
00:39:42.850 - 00:40:36.430, Speaker C: Let me write it up. But I think there's an opportunity here to simplify things and then everything else. What other changes did I make? This was just a clerical. It's just a clarification because they can have other operands besides the medias. I changed a bunch of things which refer to operands, and I changed them to immediate so they're not confused with stack operands. Um, push note. Yeah, I think that's about it.
00:40:37.600 - 00:41:02.976, Speaker A: I think those like smaller, like fixes, we probably could just cherry pick and merge anyway. Yeah, but otherwise I think this is great. Work. I do have a number of questions. First of all, did you had any chance to implement both versions in Viper and see any kind of size differences?
00:41:03.168 - 00:41:03.910, Speaker C: No.
00:41:08.060 - 00:41:13.320, Speaker A: Do you have the current version, the fixed size version implemented?
00:41:13.740 - 00:41:16.840, Speaker C: We have the version from 2022 implemented.
00:41:19.360 - 00:41:23.310, Speaker A: So that means exchange isn't implemented yet?
00:41:24.320 - 00:41:29.870, Speaker C: I don't think so. Yeah, we didn't implement dupen and swapn either.
00:41:32.580 - 00:41:53.060, Speaker A: I think it would be really great to really have some data helping our decisions, right, between the encoding of swap in versus exchange, and then also the fixed size versus the variable length.
00:41:54.200 - 00:42:00.484, Speaker B: So I did some of this analysis on solidity's output, and what I used to get my, I think 3% number.
00:42:00.682 - 00:42:04.184, Speaker A: Is I took a compiler, the 2022 version, right?
00:42:04.302 - 00:42:44.390, Speaker B: Yeah, the 2022 version. So I took a compiled output and I searched for the prefixes of all of the two byte operands, and I looked for ones that were like between zero and 127. I looked for all the operands that were below 127, and I considered those to be reducible by one byte, and there was about 3% of those occurred. So I think the analysis could be done on the 26 code with some clever greping, not for our jump fee, but I think we're looking at probably about 3% by adopting VLQ. But we could get hard numbers.
00:42:45.320 - 00:43:00.200, Speaker C: Another benefit is it allows us to not set hard bounds on a lot of these things. I noticed a lot of these things were like arbitrarily chosen as one or two bytes.
00:43:00.720 - 00:43:27.570, Speaker A: Yeah, I think some of the bounds do make sense, others don't. Even if we make it variable length. I would probably be in favor of having upper bounds on some of the header stuff, so that implementations, I want to avoid the case of what RLP and all these implementations have. And you basically made the decision already by hard coding what the VLQ upper bound is.
00:43:29.060 - 00:44:01.630, Speaker C: Yeah, I toyed around with using BLQN in the spec, so like VLQ 64 versus VLQ 32, where the difference is just basically the bound. So it allows the implementation to have some kind of bounds or types, but it seemed to make the implementation, the spec, more complicated without gain. But I could revisit that. A lot of these things could be like BLQ 32, no problem, right?
00:44:02.080 - 00:44:49.912, Speaker B: Yeah, and I think BLQ 16 should be some of them. The advantage there, it's not complication, it's about security, because I could totally see a security tack where they create 4gb, where they create 4 billion code sections to try and blow stuff up and like maybe more than 32,000 code sections and 33,000 code sections to catch implementations that use a two bit number for their indexes instead of a four. There's various places they could attack this. Which is why I think the limits are not about ease of implementation, the limits are not about complexity. They're about security. And if we keep them low, we could always raise them later in a soft fork where we just accept larger numbers. So I think putting them low on the first pass is not a death sentence to future size increases.
00:44:49.912 - 00:44:54.210, Speaker B: We can easily increase them. We can have newer versions accept larger numbers.
00:44:59.010 - 00:45:05.870, Speaker A: Daniel, the measurement you did with the 3%, was that the instructions only or was it the header as well, or both?
00:45:06.020 - 00:45:08.690, Speaker B: It was instructions. I didn't mess with the header.
00:45:11.540 - 00:45:12.048, Speaker C: Okay.
00:45:12.134 - 00:46:05.650, Speaker A: Yeah, I think it would be nice to have two separate pieces of data. Right? What is the saving we could achieve with the header and versus the instructions? And I'm kind of leaning towards that probably. These are separate questions from like a spec uniformity perspective. It does look nice that all of it is variable length, but I'm not fully sold yet that the instructions. I see a bigger risk with instructions having verbal length encoding, although we already have the RJMV as verbal length encoding in a different way. But this basically means that every single instruction, UF instruction with immediate would be variable length. Whether that has implications or not, I think that's yet to be seen.
00:46:05.650 - 00:46:52.050, Speaker A: But I would probably prefer to have different data set of arguing whether the header should be variable length and have the data supporting that versus doing the same analysis on the instructions. But that's my view. We only have like five minutes in the allotted time. Maybe we should have some rounds of feedback regarding all of the spec here. What is the feeling we have regarding variable length encoding in headers versus in instructions? Yeah. Anybody has strong opinions, please speak up now.
00:46:55.700 - 00:47:17.560, Speaker B: I think one possible downside is it'll decrease the speed of code verification, whereas for immediate, right now you just get the immediate opcode and you skip ahead too. Now you have to read each byte and do a bit check on the high bit for each byte before you continue. That's going to slow down code verification. I don't know how much of a big deal that is, but that is one side effect that I see just looking at this immediately.
00:47:23.720 - 00:47:30.936, Speaker C: There's prefix VLQ, which has fewer branches if there's a performance hotspot, but we.
00:47:30.958 - 00:47:33.560, Speaker B: Still have to read the byte and do some bit twiddling.
00:47:34.540 - 00:47:35.290, Speaker C: Yeah.
00:47:40.630 - 00:49:16.530, Speaker F: In this header context, I think I like this because it allow us to expand the sizes with future compatibility. I'm not so worried about the verification time, but the extraction decoding at runtime, which from our experience with webassembly, which uses kind of similar encoding of numbers. If you have a bounded size, it's not a loop, but it's still relatively complicated. I know even implementing push efficiently in client EVM is a bit of harder because you need to swap the bytes and all of this, so you can notice this overhead. And I think it's not so bad. I think we can work with this, but this is something to consider. So I'm not sure this is like I would prefer to uniformly select this for instructions or not, but seems it's not so easy to do, especially this jump v instruction.
00:49:16.530 - 00:50:13.990, Speaker F: It's really problematic if you do it with foreheadic encoding because now you have to build the table every time you visit this instruction. I mean, I still assume that we're going to implement, at least try to implement EVM interpreter in the way that it just process instructions without any preprocessing, because I think we should use it like most of the cases. I don't think we aim to some preprocessing as a kind of recommended step for EVM implementation. So I kind of consider that we will just execute instructions are there already in the container without doing any modification. So that means you have to decode these values every time you execute the instruction.
00:50:15.770 - 00:50:29.660, Speaker C: I was kind of assuming that the standard strategy for implementing UF will be to cache analysis, but maybe that was a little bit aggressive on that part.
00:50:33.060 - 00:50:56.050, Speaker F: Yeah, we kind of eliminated the need for analysis from legacy. So just the question, if you want to add some kind of different kind of analysis or preprocessing instead, because we fix kind of the issues of the legacy VM.
00:50:57.270 - 00:51:13.640, Speaker C: Yeah, it's not difficult, not difficult execution, and I think it's fairly easy to optimize, but. Yeah, I see your point.
00:51:14.330 - 00:51:49.314, Speaker F: Yeah, we would need to prototype, but I think it's not difficult to preprocess even during the validation. You can preprocess the code in the form that is easier to execute by expanding it a bit, but then you need to store both versions because one is needed for verification or for network to prove that this is the code that was deployed. You need it at some point, so you need to store the old version and the new one as well.
00:51:49.512 - 00:51:57.350, Speaker C: Yeah, this kind of applies to the header too, although I guess the header isn't really used during runtime.
00:52:00.970 - 00:52:11.754, Speaker F: Some pieces are currently. We tried to eliminate the need for this, but I think it's not really progressing to this direction yet.
00:52:11.952 - 00:52:22.638, Speaker C: Can there just be a length thing in the header instead of the terminator? So you just say what the length of the header is, but we need.
00:52:22.644 - 00:52:27.680, Speaker B: To parse it to get code data sections. So that optimization only gets us so far.
00:52:28.290 - 00:52:31.326, Speaker C: Code data sections, we need to know.
00:52:31.348 - 00:52:32.240, Speaker B: Where they start.
00:52:36.240 - 00:52:37.784, Speaker C: During runtime or during validation.
00:52:37.832 - 00:52:43.228, Speaker B: Yeah, during runtime you do a call f on code section five. I need to know what index that starts at. So we need to parse the header.
00:52:43.404 - 00:53:04.330, Speaker C: Yeah, so I think that you need to decode these things at runtime anyways. And I think that if you want, you can just keep a table of decoded VLQ things and it is kind of uniform across the header and code.
00:53:04.780 - 00:53:29.760, Speaker B: One option was to put the call section info as the first four bytes of the inputs and outputs and have callf point to an array index rather than a table lookup. So you jump f to the pc, not pc. It wouldn't be pc, but you jump f to the index within the container. And if the container has been validated, you know, that's where it legitimately starts.
00:53:31.540 - 00:53:41.616, Speaker C: Yeah, that has a code size implication. Right. Like it's likely that it's going to be a two byte pointer instead of a one byte pointer.
00:53:41.728 - 00:53:49.380, Speaker B: Right. But it depends on how frequently you do collapse. It's not going to be nearly as much as jumps.
00:53:56.620 - 00:54:43.060, Speaker C: Yeah, I think there's a similar issue for data load, and although there's only one data section, so you only need to like figure out where it is one time. I mean, I. Yeah, my current feeling is that it's okay even to do it at runtime. Like decoding a VLQ is mostly going to just be one or two branches. The pcs are all normal.
00:54:45.640 - 00:55:02.440, Speaker B: So the other impact is vertical tree encoding, because with that we would have to bring the entire header every time we do a parse of it. And there are probably strategies we could do where we could put length on the header and not have to parse the header at all for chunked execution.
00:55:03.180 - 00:55:07.564, Speaker C: Yeah, let's talk about vertical a little bit, because I want to understand how to.
00:55:07.602 - 00:55:10.850, Speaker B: Oh, we're three minutes over time. I'm late for a meeting, I need to go.
00:55:11.300 - 00:55:13.680, Speaker C: Yeah, okay, I'll ping you. Daniel.
00:55:21.540 - 00:55:29.670, Speaker F: If it's a quick question about Verkel, you can start, but otherwise I think you might want to go offline with this.
00:55:30.200 - 00:56:05.950, Speaker C: Yeah, I think the data for the header is fairly simple actually. I think most of the time you can save basically one byte per section. Is that. Right. And then there's some constant overhead that you save or relatively constant overhead you can save in the header.
00:56:43.260 - 00:57:00.150, Speaker F: It's. It's a good starting point. I think some of us may need some time to read it carefully and I think it's okay to comment on the prequest about details over next two weeks.
00:57:01.400 - 00:57:02.150, Speaker C: Yeah.
00:57:05.580 - 00:57:17.870, Speaker A: Charles, do you see any possibility to implement the mega spec in the wiper in the next two weeks? To some extent, especially the exchange part?
00:57:21.020 - 00:57:30.140, Speaker C: I don't think I'll have time to do that. But what is your concern about exchange?
00:57:32.320 - 00:57:41.570, Speaker A: It's not concern. It would be nice to have actual supporting data in the decisions for both exchange and swap in.
00:57:42.660 - 00:58:08.970, Speaker C: Yeah, I think that the design around exchange and swap in were kind of decided because the number of immediates was restricted, but I think that with variable length encoding of the immediates, the design space opens up a lot.
00:58:11.580 - 00:58:38.400, Speaker A: Yeah, I think my ask would be more generic, just implementing any version of swap in in Viper, because if we have like a base implementation in Wiper, then we could try out any of these different options and see how it fares. But do you think just implementing swap n. Sorry, exchange, would that be possible within next two weeks without the rest of uf?
00:58:39.400 - 00:58:56.440, Speaker C: I think it's kind of complicated because it touches the stack scheduler which is like, yeah, I can put together prototype, but it's not going to be really accurate. It's just a little bit kind of indicative, if you understand.
00:59:00.910 - 00:59:05.100, Speaker A: Could we use it to compile like urine and any of the bigger projects at least?
00:59:06.990 - 00:59:15.520, Speaker C: Yeah. I'll also have to check out the 2022 fork of Viper, probably. Actually. Let me see what I can do. I'll let you know.
00:59:17.170 - 00:59:23.090, Speaker A: Awesome. Yeah, I think that would be really good input decision process.
00:59:23.240 - 00:59:25.710, Speaker C: Yeah, with the disclaimer, it's like a prototype.
00:59:25.870 - 00:59:30.260, Speaker A: Yeah, everything is till it becomes production code.
00:59:32.070 - 00:59:34.600, Speaker C: Okay. All right, thanks everybody.
00:59:35.770 - 00:59:52.540, Speaker A: All right, thank you everyone. Sorry for going over, but it was an interesting discussion. All right, I think we are following the regular schedule, so we have the next call in two weeks and as always, we can keep discussing on discord until then.
00:59:53.070 - 00:59:58.490, Speaker C: Oh, the EUF repository. I was thinking it can be renamed to EUF specs.
01:00:04.970 - 01:00:31.414, Speaker A: Yeah, I think we even discussed that, but probably we had some tools there. I'm not sure. Yeah, we can take it offline. I personally don't have any reason against or for renaming it. All right, any other closing thoughts for me? All right, thank you everyone. It was great. See you in two weeks.
01:00:31.532 - 01:00:32.818, Speaker C: Thanks, everyone. Bye.

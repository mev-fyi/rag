00:05:14.470 - 00:05:39.462, Speaker A: Let's go for it. I didn't know what DOJ even meant. Done. Excellent. Cool. I'm subbing in for Tim today on the execution layer call. This is the execution layer meeting.
00:05:39.462 - 00:06:20.026, Speaker A: One, two eight, that's issue nine, six one in the pm repo. We'll spend as much time as we need on Dancun as that's coming up. We have a couple of touch points on these retroactive eips. I think there was some diligence that people wanted to do before they were put in. Then moving on to a number of Prague Electra el proposals, a quick discussion around engine API JSON RPC changes from Miguel, and then note about light clients breakout room on the 6th. Okay, well we have an upgrade coming. Hard fork coming.
00:06:20.026 - 00:07:11.300, Speaker A: Dan Kun there is blog post out on the F's blog with all the latest releases I believe. If you do have updates let us know and we'll get it in there. I've also seen on release newsletters and things from client teams information coming out that way. So great. Are there any other updates related to testing related to releases related to anything unexpected? Barbas Yep. So I can conclude what happened with the miniature fork last week we tried to run with everyone's latest release. There was a couple of clients that had an rc release that have since made releases.
00:07:11.300 - 00:08:10.320, Speaker A: During the test we did a different kind of spam transactions and everything was handled very well. We had very close to 100% participation, but the machines are very much overpowered so each of the machines had 64 gigs of ram and cpu overhead just to be able to run them in that we had to choose a bigger instances. Was that across the board on our particular client combos that required 64 gigs or is that just firmly to get due to the disk? So the primary reason is the disk requirement. So in order to get 1.5 terabyte of NVMe disk we had to pick up bigger instance. That's why we just had a few nodes with very big cpu. Annoying.
00:08:10.320 - 00:09:06.160, Speaker A: Got you. Any questions about the main net shutter fork? Cool. There is one more thing I would like to mention that Gurley is going to be deprecated very soon. Or it's already deprecated but is going to be shut down and client can make their exits three months after the Dankun activation or one month after the Dankun mainet activation, whichever comes later. That was the sentence we put out in the blog post. So the Gurley fork was on the 17 January and Mainet fork will be on the 13 March which means Gurley is going to pretty much die on the 17th April. Got it.
00:09:06.160 - 00:09:58.320, Speaker A: So everybody has a date in mind now and I'm looking at it right now, it seems to have participation on the order of like 70%. So fluctuating right around the finality threshold. Did people already begin exiting or turning their machines off? Yeah, we have seen some large node operators that have decided to exit their validators and discuss some finalty issues last night. Starting from last night. They seem to have recovered since then, but the participation rate is still quite low. I do not expect it to even last 17 April to be honest. But let's try and something interesting to watch nonetheless and that we're kind of floating in that.
00:09:58.320 - 00:10:40.724, Speaker A: Thank you. Other dang Coon related items. We could possibly also discuss Devnet twelve and when we want to shut it off, maybe a few days after Mainet fork. Is anyone using Devnet twelve? It's basically just still a place where we can quickly roll out some new client releases if anyone needs to test something. So it's nice to have around. Gotcha. Yeah.
00:10:40.724 - 00:11:18.720, Speaker A: Deprecation after soon after maintenance. Sounds great. Yeah. I'll echo Justin's comment. Just overpowered machine seems like repeated mistake we made in Paris. Can we kick around with some ideas to in subsequent versions of this type of testing, get to more types of resource machines that we'd expect? Obviously there are probably extremely high powered resource machines on the network, but seeing some sort of distribution there might be good. Is that because of the cloud infra that we're using? Yeah, so the cloud infra basically offers us two different options.
00:11:18.720 - 00:12:02.000, Speaker A: If you want NVMe, we have to go with a bigger machine. They don't offer large disk closed cpu and low RAm machines. Alternatively, what we could do is attach volumes to the different machines and sync that way. But it's possible that the I ops of those mounted volumes are not high enough for me not to be able to sync. It's something we are testing right now and possibly we could encounter going forward in the future. Minnesota shadow forks, right? Okay. Yeah, it's definitely worth investigating something here and we can pick it up down the line.
00:12:02.000 - 00:12:57.676, Speaker A: Anything else related to the upcoming upgrade? Cool. Well, in plus two weeks it will have happened, so we can talk about it then. And of course in one week there's anything else to discuss, we'll discuss it then. Thank you everyone. Okay, there are a couple of retroactive eips that were discussed two weeks ago. Let me look at my notes. I believe 76 ten there was going to be an investigation just to sandy, check.
00:12:57.676 - 00:14:17.736, Speaker A: There'd be no vertical issues. Did anyone look into that? This is revert creation in case of non empty storage. I think the blocker of this app is whenever we switch to vertical, there is no easy way to determine if the account has empty storage or not. Martin has this idea that actually we can. So whenever we switch to the vertical, during the transition, whenever we encounter a account has zero nouns, empty runtime code, and numpty storage, we can just discard the storage, which means we will not move the leftover storage from the merkel to Veracle. And in this way, after the transition, we can make sure that in the Ethereum state, these kind of accounts will no longer exist, and we can then deprecate this eep. The idea is that because for this storage, it is impossible to access them and also impossible to modify them because of the empty runtime code, so it is totally safe to discard them.
00:14:17.736 - 00:15:21.768, Speaker A: And also for this account, they all have non zero balance, so they will still be kept in the state even after discarding the storage. So if we discard the storage, then it will not be a blocker for vertical. So maybe, Gim, you have something to add or want to mention? Not really. Yeah, whatever. It seems like it will deactivate itself, and it's not going to temper or destroy anything during the transition or impact anything during the transition. So I think this is the right approach. Dana, have they taken the potential of the EIP 58 six? I mean, it's not committed yet, but it's on the table, and that's where you can do a delegate transaction from your EOA.
00:15:21.768 - 00:15:53.336, Speaker A: Eoas might gain storage. How would that interact with that? It might not. We might not do the eip, but it's something that's been discussed in the EOA circles. So I don't know if Adrian is here, but if he's not, I can just add that I've been thinking about that as well. Okay, go ahead, Adrian. No, I'm leaving you. Yeah, thanks.
00:15:53.336 - 00:16:37.492, Speaker A: So my understanding is that those accounts have no code, so you cannot delegate call them. And they were created as the result of a contract, so there's no private key controlling them, so you cannot use EIP 58 six. Yeah, they are not affecting 58 six. At least that's my point of view. But 58 six will be fine for vertical if we put. If regular end user accounts gain storage, right? You mean in that sense? Yeah, I mean, regular end user would gain storage. Yes, but.
00:16:37.492 - 00:17:09.320, Speaker A: So you would not be able to create. Yeah, you should be able to create a contract to deploy code at this time. Right. This is exactly what Gary was saying. We forbid this all the way to vertical. I'll follow up on eth magicians or somewhere. I'm still a little concerned.
00:17:09.320 - 00:17:59.320, Speaker A: Okay, so there might be a couple more things to talk about here. If those are resolved, then the intention is to add this to Petra and with a note that in the event of verkel, it's deprecated. Or it would be an additional EIP at the point of vertical to deprecate. Or does it auto deprecate? Can someone clarify in its current definition it's auto deprecate? Yes. Got it. Okay, so it seems like there's at least a couple of things that people want to still mull over. This will likely show up again in plus two weeks to just bat around those hopefully final couple of little issues.
00:17:59.320 - 00:18:56.580, Speaker A: Okay, the next one was 75 23, which I believe there wanted to be a final validation. There were no more empty counts on main net because I think there was some unexpected ones found previously that were handled. But just a final check. Did anyone do that final check? I'm also not 100% sure who was going to do that. Okay, we'll kick this two weeks. Tim will be able to carry the thread better than I. Apologies on to Prague Electra.
00:18:56.580 - 00:19:32.972, Speaker A: There was an account of traction future of AA breakout room yesterday. I think there's two things that we want to touch on here. One is if one or maybe two people can give a recap. If one person gives a recap, and if anyone wants to fill in the gaps, that'd be great. Also, Yoav was not able to join the call yesterday. So if Yoav can help give some additional context on four, three, seven, or I can't remember the number, but the native version of that, and open up for any follow up questions from yesterday's discussion, that'd be great. So let's start with that recap.
00:19:32.972 - 00:21:43.946, Speaker A: Does anybody want to take that? Yeah, I mean, I can just start by summarizing some of what we talked about. Basically, I think one of the big topics then was just making sure we were aligned on longer term goals of account abstraction. Basically the longer term, just fundamental desire that eventually we have to have some kind of account system that is like, one allows key rotations and key deprecations, two allows quantum resistance, three allows batching, four allows sponsored transactions and a couple of other smaller things. And out of those, of course, the first two goals are very clearly not satisfiable with eoas. And so present a pretty clear case for moving the ecosystem to a place where it's beyond eoa centric. But then this brought the discussion to what are actually the means to get there and what are some of the specific details that are less resolved here and what actually is a shorter term roadmap that gets us goals that people want in the short term, but it is at the same time compatible with this longer term future. So one of the questions is basically trade offs between 2938 style design and for 4337 style design questions around short term trade offs between 30 74.
00:21:43.946 - 00:22:53.614, Speaker A: And I think it was five, eight, six, which is basically eoas being able to delegate call from inside of a transaction which would essentially let them execute code. I don't think we came to particular conclusions on that though. I think there's a general agreement that the longer term stuff is something where there's some kind of medium urgent need for to try to actually align on that and sort of figure out the remaining disalignments. And then at the same time there is this short term need to improve functionality for existing users. And that's something that has more urgency because there's upcoming hard forks. So let other people continue from there. Yeah.
00:22:53.614 - 00:23:39.370, Speaker A: Before we move on to Andrew, does anybody else want to add. Unless, Andrew, you want to add a bit more to the recap or provide any sort of competing view on what went down yesterday? Andrew, if somebody wants to add something to the recap, please go on. Yeah, go for it, Andrew. Thanks. Okay. Yeah, I was thinking about, because my worry about EPA 30 74 is that you can sign a blank check forever. But then I think that concern was addressed recently and now it's revocable.
00:23:39.370 - 00:24:57.140, Speaker A: And then light client, during the breakout, light client raised an issue, raised a question that if we want to do something in the short run, then between 30 74 and the delegate transaction, 58 six, we should choose 30 74 because it's more generic, it allows sponsored transactions. So I kind of think if we consider 30 74 for Prague and if we have confidence, then it doesn't prevent us from the end game. Vitalika talked about then 30 74 is a reasonably complex proposal, but it will bring substantial benefits. So yeah, if there is confidence then it will not break things in the future or prevent things in the future. I think we should do it in Prague or at least consider it for inclusion. Great. Vital, do you have a response to that before we move on to.
00:24:57.140 - 00:26:22.734, Speaker A: No, I mean, I think that's one good set of the security concern issue is definitely one of the big sticking points. And I think it's good that we're talking about and have made a lot of progress. I think the other one that I feel like has been brought up less is basically that one thing that would be good to avoid is essentially creating two totally separate developer ecosystems for smart contract wallets and for eoas. And the auth opcode is in its current form fairly ELA specific. And I looked at it yesterday and it feels like there's a pretty natural path to eventually extending it to be smart contract focused as well. But then there is basically the long term issue then, which is like five or ten years from now, there is going to be a lot of applications that have this extra entrenched workflow where things happen using the auth op code. And does it feel right to have that kind of workflow just continue to exist and be part of the EVM in the long term? Right.
00:26:22.734 - 00:27:49.830, Speaker A: Basically there is a long term complexity concern and then it's not an argument against 30 74, but just like a thing that needs to be kept in mind, which is like the question of whether or not it should be extended to also cover smart contract wallets at some point. Aman yeah, so just one thing that I think wasn't clear from the last call. I think there was a notion that in the call that eoas are not to be continued to be supported, kind of. And I feel like this is not the way to go. This is something I wrote in the comments, but I wanted to voice it clearly that I believe that eoas needs to be supported up until smart contract accounts are properly usable. And right now we are not there. We need to keep supporting eoas and making their user experience better up until smart contract accounts catch up to become normal user usable.
00:27:49.830 - 00:28:48.250, Speaker A: That's just what I wanted. Yeah, I think there's a lot of support for that. And I think, like, that's exactly why both 38 four and five eight six are being discussed. And then I think one other thing that's. And that's short term, right. I think one other thing that's important for just people listening to this to keep in mind is that in the long term, if there is an end game where literally eoas get removed as a protocol feature, then that will not mean any kind of forced wallet change for users. Right? If that gets done, the way that that would have to get done is basically that the EOas would get automatically replaced by smart contract wallets that have equivalent functionality.
00:28:48.250 - 00:29:53.160, Speaker A: Right. Ark, thank you. So, yeah, I think yesterday was a very interesting conversation and a lot of good concerns came up coming from the wallet side. I think one of the important things for us to say is that sponsored transactions is a very important capability, and for us at least, this is one of the big differentiating factors between 30 74 and 55 eight six, although they both bring value. But I think one of the main things that came up yesterday is how could we possibly align the roadmap between 30 74 and 4337? We've been thinking about this today. We came up with some suggestions. I'm not sure they're by definition the solution, but it does feel like there could be, like Vitalik mentioned, there could be good alignment between 30 74 and 4337 if we make the effort to make this alignment.
00:29:53.160 - 00:30:59.052, Speaker A: And so that makes me a lot more positive about this. A couple more comments and then I want to give you some time to talk Onscar and then Vitalik. Yeah, I just wanted to briefly mention that back when we kind of first talked about 30 74 three years ago, that at some point, of course, we kind of gave up pushing for it. But basically this kind of forward compatibility with smart contact wallets was kind of the last thing we did think about. And we basically were thinking back then that we could have invokers become the de facto standards for new features across smart contact wallets and EOA. So basically, like say, if there's a batching invoker, right, for batching multiple transactions, then that could also, we can structure it in a way where that same invoker can also be used by smart contact vaults. But that does mean, I mean, Vitadik already kind of touched on it a little bit that we would have to be okay with the future where for all of these features, forever, we are fine with smart contact worlds having to make this extra call to the specific invoker that then does that for them or something.
00:30:59.052 - 00:31:38.000, Speaker A: It seems not necessarily like a very natural flow. Basically, it adds extra overhead forever to this, my contact world. It's very opinionated on that side, but it does give us this kind of interoperability and it does kind of keep us from fracturing these two paths. So if we want to go with 30 74, I think it should really come with us with the understanding that that would mean on the smart context wall side, we also start using invokers for standardization for these features. Vitalik, did you have anything to add before we give you off a minute? No, I did not. Yeah. Okay.
00:31:38.000 - 00:32:31.026, Speaker A: I just want to give you a chance to add some more context around both four, three, seven, as well as the native version and where you see this fitting into either the short or even the long term in game of account of traction. Sure, yeah. I'll give a brief overview of overview for those who are not familiar, and then we can talk about what we can do now. So can I share my screen? Yes. Okay. Sorry. Can you see it? Yeah, we can see it.
00:32:31.026 - 00:33:15.870, Speaker A: Great. Okay, so first of all, what we're trying to build in the long term is full account obstruction. What are we actually trying to obstruct? Sometimes in some conversations it's not clear to everyone. So our definition is we abstract all the aspects of the account, which means authentication. Authentication, meaning proving who you are, proving your identity to the account. Then we have authorization, which is something that usually there is a separation. In every security system except the blockchain, there is a separation between authentication authorization, like who you are and what are you allowed to do.
00:33:15.870 - 00:33:39.074, Speaker A: So in EOA, this is implicit. If you prove that you are the owner, you can do anything. Otherwise you cannot do anything. Authorization. We have a replay protection. We want to enable parallel transactions when the order doesn't matter, for example. And we have some multitenant use cases.
00:33:39.074 - 00:34:29.778, Speaker A: There is gas payment, of course, we want to be able to pay with ELC 20s want to do gas sponsorship. This is a very popular feature. And execution obstruction, which is execution abstraction, which means allowing things like batching and batching delegation. That's the kind of thing that 30 74, for example, does. So we want to abstract all of this problem is that this is a hard problem because we have to. Doing state dependent validation means that there are many ways to invalidate, to do mass invalidation, and therefore to do the narrow service attacks against the system. And the easiest way to solve it, of course, is by using a centralized relay.
00:34:29.778 - 00:35:33.686, Speaker A: But that's not what we're here for. So instead we need to have a complex mempool protection, something that allows us to have a permissionless mempool. And the first meaningful work in this space was 29, 38, which really paved the way to this line of thinking. And we learned a lot from it. But we also noticed that it hit a certain dead end, because some basic account obstruction features are broken by requiring the AA prefix, which is really a must. If you don't have this protection, then block builders can be easily attacked by transactions that invalidate each other. And the validation rules are also far more restrictive than in more recent proposals, which actually preclude most of the use cases that we're already seeing live in some 43, seven accounts.
00:35:33.686 - 00:36:35.338, Speaker A: So the goal of ERC 43 seven and later Rip 75 60 is to solve this problem, and it does so by separating validation execution. Since we have a separate validation stage, we can avoid many of the DoS vectors without being too restrictive. So four three seven was never meant to be enshrined. It's an ELC, it's meant to be tested. It allows us to experiment with account obstruction on different EVM chains without having to reach consensus on how account obstruction works. And the focus is decentralization, so there are no centralized components anywhere in the system. And of course it has some limitations because it's not native, it's less gas efficient.
00:36:35.338 - 00:37:28.634, Speaker A: We have to waste some gas on overhead that could have been avoided with native carbstruction. It cannot migrate existing EOas, it cannot add code. So we'll need a separate eap for that. And there are already a few good proposals. And one big issue, since we really care about census resistance, is that it's harder to support with inclusion lists if the protocol is not aware of this. So ERC 43 seven has launched actually here at if Denver exactly one year ago, and since then it's been getting a nice traction. Last time I checked there were 3 million deployed accounts, like eleven or twelve, actually 12 million user ops.
00:37:28.634 - 00:38:17.006, Speaker A: And we see many great projects, many new wallets being built, many projects that use it. So it's an interesting experiment to work on. Now, what is our IP 17, IP 75 60? This one is a bit, it seems like an OD animal, because it's not meant for. We are not fully sure yet about how obstruction, how account obstruction should work at a protocol level. And yet we went ahead and wrote it. So why did we do that? Turns out that some layer twos were not willing to wait and actually wanted to have native account obstruction, native account obstruction already. For example, Zk sync had it from day one.
00:38:17.006 - 00:39:20.322, Speaker A: Starknet also did. And the problem is that each of these, they all took ERC 47, but they created an enshrined version of it in different ways, which first of all caused a lot of wallet fragmentation. Suddenly you have wallets like argent that only support one chain, and you cannot use the same wallet on any other, which is of course not a great UX for users. And in some cases it introduced attack vectors, because we did spend a lot of time on preventing the narrow service vectors, and not everyone identifies every such case. So the solution we came up with is to standardize, to have a standard version that all layer tools can use. And then wallets only have to be written once and can work anywhere and we can help ensure that it's secure. So in short, it's something that's going to happen with or without us.
00:39:20.322 - 00:39:58.670, Speaker A: So we may as well help them get it. Right now it's going to be ELC 437 compatible. So on chains that choose not to implement this rip or on Mainet, you can use the same account. You'll be able to switch to deploy the same account on different networks. In some cases it will work more efficiently with the rip, in others it will use the ERC. And this is all still early work, so it's work in progress and we are seeking feedback from core devs and from layer tools. We are getting a lot of great feedback.
00:39:58.670 - 00:41:09.080, Speaker A: Now, all of this, I think is out of scope for the current discussion, because right now we're talking about what can we do for the next fork, how can we improve things? There is strong demand for the strong demand for some EOA improvements. The most common requirement I've seen is batching in order to remove things like the approve and transfer from flow. So that's something that I think is worth addressing. And there's also things like gas abstraction, which is actually much harder to do in a decentralized way, but it's also something that is a strong demand and we should be thinking about. So I think that in this context, if we ignore the really hard stuff like validation, because that's where all the dose vectors lie. So if we ignore it and we only focus on these two, then right now we have these options. We're discussing the 30 74 route and the 58 six.
00:41:09.080 - 00:42:22.922, Speaker A: So I'm trying to look at them and see what do they give us and what risks do we take. As I said, the most common case is batching, and with batching, both of them can support batching, although I think that the latter is a more natural way to support batching, because with 30 74, if you have a batching invoker, the transaction actually has to contain two signatures. You have a signature for the EOA transaction and the signature for the auth, and also the commit that is a part of the transaction. So the transaction becomes bigger, which may be a cost issue on roll ups, but more importantly, who is going to sign these two transactions, these two signatures. It's not reasonable to ask the user to sign the batch twice in order to submit it, so it's more likely that it will be used with a relay. So like a centralized relay is going to sign the transaction and it has to be centralized because otherwise there are easy ways to griff it so it will have to be permissioned in some way. And then the relay submits, the transaction submits the batch on your behalf.
00:42:22.922 - 00:43:07.430, Speaker A: With 58 six, it works naturally. You just delegate ICBC IP as a way to run a script in your account. So the user just signs a normal transaction only once and it runs a script that does batching, does sponsorship is something that 30 74 can do natively, unlike 15. Real quick on the batch call. Can 30 74 be used trustlessly with 4337 or they at ods with each other in that? No, it can be. So I wrote a post about the synergy between 30 74 and 43 seven. They are not mutually exclusive in any way, and that's important.
00:43:07.430 - 00:43:53.894, Speaker A: Something I should have said earlier, that we need to make sure that no proposals we introduce now, no current eips make it hard for us to do account obstruction later. And both of these eips are fine in that sense. There are nothing here preclude us from doing account obstruction later. You can use an ELC 43 seven account on top of it in order to do batching, but then you are basically using 43 seven. You're using an invoker, but it's still going to be a 43 seven. If you just want to do batching like you have an eoa, you don't want it to become a four three seven account. You just want to send a batch.
00:43:53.894 - 00:44:23.026, Speaker A: Most likely you're going to use a relay because it's not reasonable to ask users to sign twice. Does it make sense? Got it. Okay. But you can use 30 74 with four three seven. So it's not centralized. Gas sponsorship. Actually I'm not sure, other than making it a full 47 account, which means you're no longer using it as an eoa.
00:44:23.026 - 00:45:10.946, Speaker A: I'm not really sure how you're going to use it for batching. If you have an eoa and you're using four three seven, you want to do batching. What does it look like? Does the invoker not just implement the interface of a four three seven wallet? Yeah, you could delegate to an invoker that is essentially, essentially like that. But I need to think about it some more. But I remember when I thought about it, it's not as trivial as it may sound, but it may be possible to do that. Well, you couldn't have a decentralized mempool then. Basically.
00:45:10.946 - 00:45:51.796, Speaker A: Right. So you're still in the same position that you've just pointed out. Even if you did have the same on chain logic, you'd basically have to also replicate the same mempool logic for these. Otherwise, same problem, not decentralized. Why? I would like to address two things that I noticed on the table. First batch call, I think the signatures can be aggregated by the wallet. So instead of having the user sign multiple times, the wallet can make the user press a single button to aggregate and sign all of the signatures at once.
00:45:51.796 - 00:46:54.310, Speaker A: That's one thing. The second thing is one has to be a signature on the commit on the auth commit, and the other one is a transaction signature. It's not even the same signature format. Sir, I understand, but the wallet can take care of that. But let's say you are using a ledger, using a hardware wallet, you will be prompted to sign twice on your ledger, right? I mean the ledger needs to start upping their when you're pushing this to ledger to sign, ledger needs to support this new approach or it will fall behind. Like instead of having to press multiple times approve on ledger, ledger needs to batch this information in a single go and have you sign the whole thing in one go. Or what's the point? That's one thing.
00:46:54.310 - 00:48:15.164, Speaker A: The other thing that I wanted to say about this table is the authorization is irrevocable and replayable, which is not true with the non suggestion that is going to be applied soon. Yeah, we can get to that in a minute. But regarding batching, I think what you're proposing is not that ledger will support 30 74 in general because it's hard to do it generally. We did not know about invokers. It means that ledger needs to be aware of a specific batching invoker because it needs to show the user what are you signing? So it's okay if Ledger prompts the user to sign only once and actually produces two signatures if it knows what it's signable to present to the user? I'm not sure that every hardware wallet will want to do that, but maybe they will. It's definitely worth exploring a revocation. Yes, if it's only valid for the next nons, which is what Matt just proposed in the chat earlier, then it is much easier to revoke all authorizations by just submitting one EOA transaction.
00:48:15.164 - 00:48:48.244, Speaker A: Of course there are some downsides, but it does solve this problem. It's replayable. It's replayable, and that's actually a feature, not a bug. In the 30 74 design. Some use cases you want them to be replayable, but it is revocable. So that's correct. And in 58 six, it's one time by definition, for better or worse, it's just a transaction.
00:48:48.244 - 00:50:00.220, Speaker A: So you have no way of making it replayable whether you want it or not, and you don't have anything to revoke because it's a transaction. Now. Gal sponsorship is something that 30 74 solves natively, but again requires using a centralized relay because it's really hard to do it in a way that cannot be where the relay cannot be griefed. So it will require a lot of design. And with 58 six doesn't allow gas sponsorship in itself, so it would need the new EAP draft. The new EAP draft we've seen the 79 49 which adds gas sponsorship, but it would need since it's a transaction type, it means that it would actually have to be merged into 58 six, which adds some complexity, but then it will be able to have gas abstraction as well. Now there's another use case that people like to talk about is of course account recovery.
00:50:00.220 - 00:50:59.088, Speaker A: Now recovery can be the case of a lost keys or stolen keys, and 30 74 does give us a way to recover from a lost key disaster. If my key got destroyed, if I signed an invoker that can move the assets out of my account, I'll be able to do that as long as I haven't used the next nons. If I'm going to use the EOA as an EOA and send a transaction from it, then of course it's going to break this lost key recovery. 58 six does not enable any form of lost key of a lost key recovery. But none of the proposals solve the case of a stolen key. Or in some cases you don't even know whether you no longer have the key and you don't know whether someone has access to it or not. This requires full account obstruction.
00:50:59.088 - 00:51:56.180, Speaker A: There's no way to solve it by improving your ways. Now, something that we sometimes don't pay attention to is the principle of list astonishment. It's a principle in user experience where you want to make things as intuitive as possible to the user. And since I'm looking at delegation, which both proposals do, as a way to run a script in your account, then what 30 74 asks the user to do is to sign an authorization to authorize a script to run anytime in the future or now. Anytime in the future, as long as you haven't sent a transaction from the EOA, which burns the nons. 58 six means just I want to run this script in my account right now. I'm going to send a transaction that runs the script, and I think that the latter is much easier for users to grasp than the former.
00:51:56.180 - 00:52:49.770, Speaker A: Where you are saying I'm allowing this script to run in my account now or in the future, as long as they don't say otherwise, I think it can surprise users in some way. Now there's another thing, complexity. And I think that on all core devs we often only look at complexity of the client itself, which makes sense since if that's what you're building, you want it to be simple. But I think that we have to look at the total, at the entire system. The complexity in 30 74, the implementation is really simple, which is great, much better for the network, but it does add complexity in other components. For example, wallets will have to whitelist, will have to whitelist certain invokers. These invokers are not.
00:52:49.770 - 00:53:49.890, Speaker A: Every wallet will have to audit, decide which invokers it support and keep maintaining this list. Whereas I think with 58 six, because there is no future exposure, it's much easier. You don't need to maintain this whitelist, I think. Anyway, I think both proposals can add a lot of benefit to benefit to. And anyone has any questions about what we talked? Yeah. Any other comments for Joe? There's a lot in the chat. Does anybody want to surface anything from there? Okay, I'll have to stop sharing it and I'll see it.
00:53:49.890 - 00:54:30.456, Speaker A: Andrew? Yeah, I just had a thought. So in ep 30 74 it says that a pre compile was considered initially, but that as a means to prevent, replace or whatnot. But it was decided against because there is no precedent of pre compile with storage. But I think in Cancun. Oh sorry, not in Cancun. In Prague. 7002 actually introduces stateful pre compile.
00:54:30.456 - 00:55:53.120, Speaker A: So I was thinking if we actually entertain this idea of a stateful pre compile, can it replace invokers just real quick? 7002 is going to be migrated to look more like the Beacon route opcode eip such that it will be a pre deploy, essentially a system smart contract. Okay, so it won't be a stateful pre compile. I see. But say the concern is that smart wallets have to whitelist invokers. So can 30 74 be redesigned, perhaps with a stateful pre compile so that we have a kind of standard invoker? Or maybe there is no need for an invoker at all. Lakeland or anyone an author on that one want to take that? Yeah, I mean it's definitely a possible avenue and that's the only way that we can improve eoas. Maybe it's something to discuss, but I think it just goes against my philosophy and probably some other people's philosophy about what we're trying to provide to developers, which is a powerful framework for building applications.
00:55:53.120 - 00:56:56.748, Speaker A: If we have a pre deploy, which is the only context that auth and auth call are available to be used, and it's something that the all core devs group is dictating, then I think that we're going to miss out on some innovation that could happen at this. But again, if that's what we have to do, then maybe that's what we have to do. I just personally don't think that's the best path to go down for 30 74. Gary yeah, I'm wondering since Yov didn't really speak to 7377, it seems to me that 7377 is a much lighter touch approach for enabling account abstraction and kind of getting users from eoas to a smart contract account abstraction future. It allows 4337 can develop in parallel. And this doesn't have to be enshrined early. What we're trying to target for Prague is light fork.
00:56:56.748 - 00:58:00.404, Speaker A: And it seems to me that at least 30 74 and 5003 in combo would create a lot of test and kind of attack surface that we need to be careful about. And that starts to grow. The fork starts to grow the Prague fork. It seems like, in my opinion, 7377 is really the approach that is light touch enough and still future forward, but also includable in Prague without making this into a larger feature fork that is kind of against the principles where we were set out for having a small feature fork before Berkeley. So I agree this is something that is orthogonal to the other two proposals. Maybe I should have talked about it separately because 43 seven or even 75 60 currently don't talk about migrating an existing EOA and adding code to it. And the end game for account obstruction does require solving this problem as well.
00:58:00.404 - 00:59:46.020, Speaker A: So yeah, if it's possible to include an account migration eap, then I think we should consider it. I only have a side note for something that had been said before. Maybe if Vitalik wants to talk to address what Gary said, he should go first. Yeah, I mean, I think just a kind of response to the general idea of why not basically give up on eoa improvements entirely and try to fast track making it easy for existing aoas to participate in four, three seven. I think probably the biggest objections to this are one is of course there's kind of like general fear of new things, but that's something that just continues to be being derisked with every passing year, but a really substantial one is higher gas costs, right? So four three seven does have significantly higher gas costs than eoas do. And this is something that sort of, in some sense, in principle, should not be true because you could have a 4337 account that's like literally running the same workflow as an ECDSA based EOA. But in practice, basically, EOA gas pricing is cheaper than the storage operations the four three seven does.
00:59:46.020 - 01:01:17.410, Speaker A: And I think, as I mentioned in the chat, this is something that can be fixed by basically overhauling the gas cost system and replacing it with something more principled that charges for storage accesses in a neutral way. And the vertical tree eip actually does have a component which does exactly that. So that's one big thing. But that kind of goes against the idea of doing something that gives users functionality that becomes available pretty quickly and before vertical trees do. And then of course, the other one is just like cross layer two stuff, right? Like if l one has amazing four three seven, but layer two is do not, then that's also an issue and also a thing that's going to contribute to time, delaying any attempt, at very rapid attempts to get everyone over to smart contracts. Guillaume. Yeah, so just a side note on what you said earlier, that there was another contract that was going to be deployed, the 4788, I think, way 7002.
01:01:17.410 - 01:01:59.584, Speaker A: Yeah, right. Exactly. The issue with this, that might not be clear to everyone, but is going to have a huge impact. Okay. At least to have an impact in vertical mode, is that if you start deploying contracts that are part of regular block execution, you find yourself adding code chunks to the witness. And so the choice actually no longer exists whether you want to use the evm bytecode compiled version, or if you want to take the shortcut and go right directly into the contract's memory. I don't think we should discuss this right now.
01:01:59.584 - 01:03:01.716, Speaker A: I'm just pointing out you might want to hold off your horses on this one, because I think 4788 should be, I mean, the contract should still exist, but the execution, the bytecode execution should actually be removed so that the witness gets smaller. I kind of see that as a feature. Like when you put anything into the EVM here, then you get it by default. But it does just kind of suck to send the exact same bytes around the network every single block. Like, if people are interacting with that contract, it makes sense. But if it's something that we, as developers of the protocol, just sort of enshrine this shackle on our witness, it's a little unfortunate. I mean, 4788 contract is 86 bytes or something.
01:03:01.716 - 01:03:15.944, Speaker A: So it's not a huge deal. It's just a weird thing. Sure. But if you don't, then it just becomes an additional input state transition. Right. That you have to be carrying around. That's a function.
01:03:15.944 - 01:03:44.848, Speaker A: I mean, maybe pass blocks rather than just one. Well, it's not a function of pass blocks, it's just enshrined in the client. Like the code just lives in the client. The code component got you as the binary. Okay, we can pick that up another time. So we are at the hour. There is a desire potentially to get small versions that iterate us towards improvements here.
01:03:44.848 - 01:04:29.504, Speaker A: It's very unlikely that in the next work that we're going to hit some sort of. I think it's. Maybe I'll change that from very unlikely to impossible to hit our kind of final account abstraction goals. I do think in the next couple of calls we do need to hone in on if there's going to be one or two, some amount of small eips. So we're going to have to pick up the conversation again. I think also in parallel there's a renewed vigor to try to hone in on what does the short, medium and long term look like, and to make sure that both the eips that we might consider today, as well as that want to layer in over time, do help us get there. So let's keep the conversation going.
01:04:29.504 - 01:05:07.630, Speaker A: I don't think we're going to schedule another breakout at this point, but it does seem like there might be an appetite to be regularly touching on this outside of all core devs. So we'll throw this on the agenda in plus two weeks to at least think a bit more about the strategy and to consider a couple of discrete eips. Thank you everyone. We do have half an hour. We'll try to get to what we can. Next up was EIP 76 23. Tony was going to give us a view on this increased call data cost.
01:05:07.630 - 01:05:18.690, Speaker A: Yeah. Hi everyone. Thanks, Danny. I will be very quickly. Your mic was really bad. I think maybe it's a little bit better, but make sure you're talking into it. Okay.
01:05:18.690 - 01:06:09.042, Speaker A: I hope it's better now. It's worse now. Let me check. Maybe you're going through your computer instead of your headphones or something like that. Is it better? No, seems pretty bad. Pretty bad. Test crunchy, but much louder.
01:06:09.042 - 01:06:56.090, Speaker A: Might be doable. Okay, let's try. Yeah, so basically the goal of the EP is to adjust the maximum possible block size by increasing the cost of call data, particularly for non zero call data. Bytes. It does so by increasing the cost for call data for those transactions that are mainly using Ethereum for data availability. And you can look into the EAP, it has this conditional formula, so with a floor and a standard token cost. And if you spend basically enough gas on EVM operations, then the call data cost will be.
01:06:56.090 - 01:07:40.882, Speaker A: Yeah, it will remain at 16 gas per call data byte and otherwise it will be at 68. Yeah, currently the maximum possible block size is around 2.5 megabytes, something like that. And with that EAp one could reduce it to around 0.5 megabyte. I just posted a link into the chat, so you can see a lot of more details, some analyzes which accounts are affected, but basically normal regular users wouldn't be affected at all. So they would just continue paying 16 gas per call data byte, while the data availability users would pay 68 gas per call data byte.
01:07:40.882 - 01:09:03.850, Speaker A: And I did some quick analysis for the last twelve days, and it looks like that around 96% of the transactions would have remained unaffected, which means only 4% of them would have paid 68 gas call data. And most of them are data availability or users writing comments in their call data. And those 4% that will be affected, it's basically 1% of the users, and the large chunk of them is using call data for data availability. Are there any clever ways to try to get around this threshold, like batching across multiple transactions? Or does the 21,000 hit break such strategies? Or are there any other things like that under consideration? I've actually not thought about batching. I don't think there should be a possibility to get around that. So the only way to get to the cheaper price would be to spend money on EVM operations, which is then counterintuitive. Great.
01:09:03.850 - 01:09:45.420, Speaker A: Anskar. Yeah, I just want to say that I'm strongly in favor of shipping a kind of call data price increase in general in the next fork, so that we can limit the kind of maximum worst case box size. And in this case, the CBP does this very well by going down from three megabyte maximum to 0.5 megabyte, which of course is a huge improvement. And that way it would give us also room to include an EIP to increase the virtual four throughput. Ideally, I don't know, depending on how stable. Then it turns out after we ship tinker, and ideally I think something like 816 or so would be a good target, which still would result in a lower maximum throughput than we have today.
01:09:45.420 - 01:10:41.194, Speaker A: I do think kind of this question around this mechanism for basically rebating I mean, I know it's a bad word, but rebating basically kind of the cost, the catahai cost for call data if transactions also consume more normal gas. I think it's interesting. I could imagine that this is a bit more contentious. So maybe this is in a way like an optional part of the AP, in my mind at least, but it's actually a very clever mechanism. And just to basically give a little bit more context, right. In the past we've looked into multi dimensional resource pricing, and the idea is that it's kind of unfortunate that we always price things for the worst case, and the worst case is that the block only consists of a single, like only consists of using that one resource, right? So basically we price compute for the worst case block processing times if you only use compute operations, and we price data for if you only have a block that's full of data, and we price storage for if you only access storage like multiple times in a row. Right.
01:10:41.194 - 01:11:39.330, Speaker A: And the beautiful thing here is that basically now it still has this high price for that bad case, for the attack case, basically, but it gives you lower prices if you actually have a much more realistic mixed usage block. And this is actually a mechanism we might be looking into applying even for other types of resource mixes as well. Basically, it's a way of kind of elegantly making the total kind of resource usage in the block more efficient. So I personally like that part of the mechanism as well. But I feel like basically, even if people might take issue with that part, I think shipping any form of call data price increases is very important for the next fork. Any other comments or questions? I'm not sure if clientein's had a chance to look at this before. Any initial reactions for consideration in the next work.
01:11:39.330 - 01:12:37.584, Speaker A: So I've implemented it in Geth and it was like a five line implementation. I did make some mistakes. Thank you, Vitalik, for pointing them out, but yeah, I fixed it now. Glad we have good code readers. Any other initial reactions? If not, we'll probably give everyone a couple of weeks to chew on it and bring it up for more reactions. Okay, thank you, Tony. Next on the agenda, Antonio did put EIP 25 37 on up for discussion.
01:12:37.584 - 01:13:24.774, Speaker A: I'm not certain if he had seen that it was already late for inclusion in the meta EIP. Was there anything else we wanted to discuss on 25 37, or was that it? Yeah. Can you hear me? Actually, you sound like you're in an echoey faraway room, but we. Okay, 1 second. And if you can't get the mic working. Is there anything else you want to discuss other than just see if it was going to be included? Is it better by chance? Yes. Great.
01:13:24.774 - 01:14:44.014, Speaker A: Yeah, actually this EIP seems to be like getting traction and actually I will have some folks, me and some other people started to look at this text more. Indeed. And actually I will have a question if you guys have an opinion on kind of not an issue but an implementation choice. Basically like this specification is pretty different than EIP one nine six in a way, because we have operation like add and scalar multiplication like the bn curve. But the bn curve is a prime order curve and this one instead is not. So it tesco factor. So now while it's clear that for pairing we want to do the operation on the magic subgroup, the one that we are using in the consensus layer, it's not clear what we want to do for the scalar multiplication and the addition for the CIP if we want to stay on the magics group or acting on the full order of the curve, and if we choose to stay in the group, we have to pay a bit the price of validating the points.
01:14:44.014 - 01:15:57.530, Speaker A: So this is pretty actually I've been start to bread the test for this specification and it's not clear at all what we want to do here. And I was wondering if anyone has an opinion. Just like to give another perspective. In the consensus layer we don't have this issue because we are using only the BLS signature scheme, but here we have as well adding points and scalar multiplication perception. If no one has any comments here, maybe it's best to write this down and see if we can get some view on it in the next couple of weeks. Right now all of the libraries are using the doing the subgroup check right? At least as far as I saw preparing, yes, for the operation of adding and scalar multiplication, not all, and for sure it's not specified by the spec at the moment, but I agree with Danny that we can talk about it offline. So maybe I will open an issue on the repository.
01:15:57.530 - 01:16:47.120, Speaker A: Okay, that'd be great. Mark has his hand raised as well. Yeah, I just wanted to add one thing on this EIP. I felt that maybe it was missing the ability to do operations in the result of the pairing group. So at the moment you can do operations in G one and G two, but then you can't and you can verify the result of two pairings are equal, but it doesn't let you get the pairing result and do a further arithmetic on it, which is useful, I think, primarily for verifying some aggregated snocs. So I felt that this would be an improvement to the EIP. All right.
01:16:47.120 - 01:17:31.990, Speaker A: Yeah. I will suggest as well to maybe discuss this on the GitHub and we'll follow up there. Okay. Yeah, I think to get the right set of eyes on this, a written version of it will be helpful. Thank you. Before we move on, Charles wanted to bring up both EIP 59 20 and EIP 76 nine. Both these were discussed on a previous call, but we're looking for a revised kind of temperature check if anyone client teams had given them more thought or wanted to bring in any comments on those.
01:17:31.990 - 01:18:58.020, Speaker A: So EIP 59 20 payout code. Any comments or further thoughts on that since it was brought up? Yes, we kind of had a team meeting with the Eels team and the east team, the executable execution layer specs and the executable tests. And one of the things that we did was sit down and talk through a random EIP, and we picked the pay opcode and kind of discussed all of the implications it has and all of the contexts that it can be that we need to think about, that we need to test when doing this EIP. And it turns out it's quite complex. The testing. The EIP itself was under specified, but I don't know if Peter is here, but he wanted to add some more specification to the. Yeah, in theory, I think the EIP is okay.
01:18:58.020 - 01:19:54.148, Speaker A: It's just a lot of stuff to test for it. Okay. And does Peter intend to do the revisions in a PR for the clarification? Dana, one minor thing is that the pay op code and the auth code are currently slotted for the same opcode number. So that needs to be resolved. Got it. Any other temperature checks on this one for the transient storage pricing? I don't think we should do it. We should even think about it before we have the transient opcode in the chain and see how it's used.
01:19:54.148 - 01:20:25.680, Speaker A: And then we can start having a debate whether it's mispriced. Well, we should have the debate whether it's priced too high right now. Too low right now. But I think this EIP actually wants to price it down. Okay, well, we will begin to have data in 1314 days. Please. Sorry.
01:20:25.680 - 01:21:32.180, Speaker A: Yeah, I think it's good to wait for data, but that data won't be complete in the sense that there's use cases that revising the pricing down enables, which you won't see in the data. So you can kind of get some benchmarks or some ideas how much resource usage you get, but you won't get a clear idea of how it will be used after the pricing change versus before. And one very important use case is reentrancy locks. So Viper would like to enable non reentrancy locks by default. It's like kind of iffy whether that makes sense if T store is 100 gas, but if T store is cheaper then it's pretty much a no brainer. And I think that's a big step forward for smart contract development. UX and ethereum.
01:21:32.180 - 01:23:19.666, Speaker A: Were there any other thoughts or comments on 76 nine? I guess one we can get data on usage. Yes, that will be incomplete with respect to essentially not unlocked use cases, but also I'd rather Tim be here on either of these to kind of better gauge consensus, but any other comments on this before we go on today? Sorry again, I'd like to also point out that the EIP actually improves resource usage in that for small number of slots the pricing is cheaper, but it actually caps the number of transient slots that can be used at a much lower number. So you go from being able to use like I think ten megabytes with the current pricing to under 1 mb after the pricing change. Sorry, and this is just a function of the pricing change, or is there another change? It's a function of the pricing change because the pricing is super linear. So it's cheaper for small numbers of slots and more expensive for large numbers of slots. Okay, we're going to move on. Light client I did not get this on the agenda.
01:23:19.666 - 01:24:54.690, Speaker A: I didn't see it this morning. EIP 76 39 cease serving history before POS can you give us some context here? Hey, no worries. Yeah, so this is really a splintering of EAP four four s. I don't think that we are proposing four four s to be completely realized in the next hard fork, but there does seem to be quite a bit of demand from client teams to improve the situation with how much data they are required to store on disk. And since we have been working quite a bit on a standardized format for sharing pre merge history, I think that trying to target this next fork as a time where we can stop serving that premerge history over the network is a pretty good direction to begin looking. And I just wanted to get it on the call now and to start discussing it a bit and see what the appetite is from teams to maybe make the commitment that in 6912 months that it's not going to be possible to get that information over p to P and you will have to use some external data source. The other big piece of this EIP, which I think some people have left some comments on the pr, maybe we'll split it into a slightly different thing that I think is important to have a green light from ACD is this header accumulator.
01:24:54.690 - 01:26:17.224, Speaker A: The header accumulator is really an interesting pre merge data artifact that is inspired from the historical roots accumulator on the consensus layer. And it just gives us an efficient way to communicate about the entire premerge chain with just a hash tree root, and then make proofs about the history of the premerge chain in log size rather than in linear size. So I want to get agreement both on this is something that we want to do. We want to try and stop serving this data over the p to P in the next hard fork, and that we have been able to verify that this is what the pre merge chain looks like. So in a sense we're committing to a later authenticated route per se of the chain. Sorry, and I haven't looked at the IP. Where would the pre merge route show up? This is just baked into the client, or is this some sort of state transition change? It's a lot more up to what clients want to do with this, given that there will be other ways to access the data.
01:26:17.224 - 01:27:09.240, Speaker A: If your client is going to still provide users the ability to download that historical data, then it's going to be important for client binaries to include that root hash and then verify the data they're downloading is authenticated against that root hash. Okay, so this just defines a canonical way to kind of come to that. Root hash dictates that root hash in the IP such that it can be easily included and agreed upon in binaries. Yeah, exactly. I don't know. This could possibly live outside of an EIP. It may definitely live in a different EIP, but I think it's probably important that if this is the user story we're going to provide for downloading history, we should probably as a group agree that that's the route that refers to the data before the merge.
01:27:09.240 - 01:28:40.520, Speaker A: Any questions for light client or any initial comments or temperature check on this? Yeah, I assume that this also about not just blocks but also receipts, right, like all chain data before the merge. So I just wanted to say that probably the cap is kind of like dependent on something like 61 ten, because otherwise some CL clients will not be able to reconstruct the deposit tree because logs will no longer be available. That's true. Are there any other consensus on either consensus or execution layer that requirements on logs or is that the single thing? I believe that's the single thing. Okay. Anything else on this one before we move on? Seems like something that is worth chewing on and surfacing in a call or two to see if there's any additional consensus here. Okay, Mikhail, engine, API and JSON RPC changes.
01:28:40.520 - 01:30:07.406, Speaker A: Yeah, so I want to quickly talk about engine and JSON or VCPI changes potentially entailed by the confirmation rule. The confirmation rule, as a reminder, is CL construct that under certain assumptions allows to confirm a block within one slot. Confirmed block. Yeah, it's assumed that the confirmed block will remain canonical, will remain in the canonical chain and eventually get finalized if those assumptions are true. So this is kind of like quite cool feature for dapps and services that use blockchain data to get early block information. And yeah, obviously we want to expose this information somehow to those parties who work on dapps and services. And the way that is kind of like we can do it is to basically take the confirmed block hash from CL, propagate it to El as we do with the save block hash, and expose this confirmed block from the El side via jsoner CPI.
01:30:07.406 - 01:31:31.630, Speaker A: So this is basically like the default way to do it. And yeah, there are a few discussion points due to a lack of time. I think we can go over them later on, on some later calls. I just wanted to say that potentially if we decide to propagate this information and to expose this information to users in this particular way, we'll have to do these changes to the APIs and considering that the confirmation rule research is being finalized and then we'll be able to finish the spec work which has already been started, I anticipate that this kind of change will probably be required as a part of our work on electroproc. And I just wanted to rise developers'awareness, that potentially we will have this change alongside other EIP and I can answer some quick basic questions, there is time. Or we can move the discussion where the execution layer can be. Not care about this at all and it's the requirement where you just get it from the RPC on the consensus layer and then utilize that hash for queries on the execution layer.
01:31:31.630 - 01:31:54.760, Speaker A: Yeah, exactly. But probably beacon APIs aren't the thing that is commonly used by DAP developers. Yeah, I don't know. I don't want to claim this. This is more like a question to me. Yeah, I think there are plenty of places where they're not accessible or just not commonly used. That's certainly correct.
01:31:54.760 - 01:32:34.978, Speaker A: Yeah, we could also use save block hash change to expose the confirmed block. But was the kind of a point that the save block hash probably is treated by people more as a more safe block reference than the confirmation rule can provide. So this is why we would probably want to have a new thing. And that was the intention. But I think given the use of that word safe, which is probably an abuse of terms to begin, most people are not. My temperature gauge on that has been. People are kind of afraid to undo that.
01:32:34.978 - 01:33:11.822, Speaker A: Also, given that this might be rolled out at variable times, the confirmation rolled in, all of a sudden, depending on the client you're using, and the version you might end up safe might have very different meanings. Okay, let's pick this up. Either on the contest, their call and the execution their call next time. Thank you, Mikhail. And the final thing is, there will be a light client spikeout room March 6 at 02:00 p.m.. UTC there is a link to this agenda in the PM repo. This is issue nine seven one.
01:33:11.822 - 01:33:54.686, Speaker A: Any other notes on that, phil, you had put on the agenda? No, that pretty much covers it. Thanks, Danny. Okay, great. Well, we are. Any final comment? We have 30 seconds. Yes, I would like to propose a new ETH client version where we don't send the bloom filter in the receipts. Basically, we figured out that no client is actually storing the bloom filters for the receipts, because this data is for the two and a half billion transactions that we have right now, or 2.2
01:33:54.686 - 01:35:00.450, Speaker A: billion transactions right now. This data is roughly 550gb. And the problem is, whenever someone syncs, we will request the receipts with the bloom filters. So the person that we're syncing from has to pull up the receipts from disk, generate the bloom filters, send it over the syncing node, verifies that the bloom filter, or that the receipts are correct, and then deletes the bloom filters and stores everything else to disk. So instead of that, we can just send the bloom filters with the receipts without the bloom filters. And the node, on the other hand, has to then generate the bloom filters themselves and not store them just to verify them. This would save us roughly 550gb of bandwidth during initial sync and also a bunch of bandwidth during normal block.
01:35:00.450 - 01:35:42.202, Speaker A: Oh, actually no. During normal block production, we generated also, so it wouldn't save us any bandwidth there. But yeah. So I'm preparing an EIP for a new e protocol version. I can send a link of the draft, and this will also remove two other messages and the TD the total difficulty from the handshake, because we don't need the total difficulty in the handshake anymore. Okay. We're going to keep an eye out for that EIP, circulate the draft.
01:35:42.202 - 01:35:55.340, Speaker A: Andrew, I see you have a comment, but I have to go. I'm sure a number of others have to go. Take care. Thank you, everyone. We can discuss on this. Thank you.

00:00:03.670 - 00:00:04.170, Speaker A: Okay.
00:00:04.320 - 00:00:31.970, Speaker B: Welcome everybody, to virtual implementers, call number seven. We have a solid but not huge agenda today. I have shared it in the chat. If anyone has anything that I neglected to add, please feel free to drop it in the chat. And we are starting off with an update from Guillaume on the testnet on Kalstenin. Guillaume.
00:00:32.310 - 00:01:06.234, Speaker A: Yep, thanks. Absolutely. So finally we were able to relaunch the testnet. I'm going to share my window to my screen to show the landing page. So yeah, it's at Kelstine Testnet. It used to be Kelstin, but now it's Kelstin testnet. There's been a few changes, so the first one is that we now have a block explorer.
00:01:06.234 - 00:01:58.350, Speaker A: So it's not vertical specific. It does say Electra though, but it doesn't show anything really vertical specific. So that's still work in progress, but at least we're very happy to have it, because we can follow what's going on a bit better. There's still the RPC, of course, we have a faucet, we have the fork, mon. So currently the only consensus client is Lodestar, but Mac from Lighthouse wrote us this morning that he was ready to go. So it's only a matter of taking the time to roll out some lighthouse notes and we should be good to go. But the thing has been really stable.
00:01:58.350 - 00:02:46.350, Speaker A: So initially we were planning to have a couple epochs of MPT and then perform the transition, but that would mean that only the client that implemented the transition, which is geth, could join it. So the goal is to also have nethermind test the sync. So we decided to go back and change that to a client that does the verge at. Well, technically there's no conversion. It starts with. With a vertical block, like vertical tree at Genesis, and yeah, a few other changes. So we now have the post state in the block.
00:02:46.350 - 00:03:38.800, Speaker A: There was a misunderstanding of what the post state should contain, at least I thought that the proof should contain both the prestate values and the post state values, but it's actually not the case. It's only the witness that contains the. There will be, there's an agenda attempt to get a bit deeper into. So currently the proofs that are being provided on Kalstinin are not exactly the right format, so that means we will restart it. But currently it's good enough that we can try getting all the els and the cls we know are working to see if they can discuss. And then when we have everything working out, we will relaunch it, so that should be I don't know, maybe next week, maybe in a couple of weeks.
00:03:39.570 - 00:03:39.982, Speaker C: Yeah.
00:03:40.036 - 00:04:13.290, Speaker A: One thing that I should mention also is that for whatever reason takes Fuz doesn't work. So I have my own fuzzer that sends very simple transaction. It's not as comprehensive as fuz but yeah we tested that deploying contracts work that we've been sending a lot of transactions. We tested withdrawals. Another new feature of that testnet. I don't know if we can see the withdrawals here. If we look at the latest, I don't know, some block.
00:04:13.290 - 00:04:56.082, Speaker A: Yeah it's got to be in the slot of course. Withdrawals. Yeah there were three withdrawals right here. So the withdrawals because the traffic is not so intense, the amount that is being displayed is almost zero. It's not zero, it just looks like it's zero because the values are extremely small. But yeah overall quite happy with that. So still a lot of work to do but yeah at least we got somewhere right? And when it comes to what's happening next I think we're going to launch another test net to perform the transition.
00:04:56.082 - 00:05:52.730, Speaker A: So a dedicated testnet as a first step towards the shadow fork and otherwise. Yeah if people need we might also create a testnet without proofs. It could be useful because at least guest is going to slowly merge the content of that branch into mainnet but the first step they want is to only have enough features to just join the testnet. A testnet that doesn't produce proof, something simple that they can review. And when they're done with that they will start merging all the proof stuff. It would make sense to have a simpler testnet but currently Kalstinen works great for most applications so hopefully other clients can join. But we'll see that during the client updates I'm sure.
00:05:52.730 - 00:06:02.370, Speaker A: And yeah that's pretty much it for the presentation. Great.
00:06:04.660 - 00:06:10.630, Speaker B: So yes, client updates actually diam, do you want to continue and give a quick update for.
00:06:11.960 - 00:06:38.990, Speaker A: Uh yeah actually basically that was my update cal student working all those new features. Otherwise just working on like I said, trying to merge some prs into geth like mainline geth and then yeah like we've got some discussions with inacio so we keep the optimization compatibility work.
00:06:42.190 - 00:06:48.960, Speaker B: Awesome. Anybody else want to give an update next?
00:06:50.210 - 00:06:51.726, Speaker D: I think I can go next.
00:06:51.828 - 00:06:52.800, Speaker A: Just a second.
00:06:56.950 - 00:07:39.702, Speaker D: Yeah, so never mind. Also joined the question and testnet initially there were some issues, we were failing to process some blocks during some basically after three, 4 hours but now it's been stable for last five, six days. So I think everything seems to be working now. I didn't get around to test the sync part yet. I think these servers should be working, but yeah, I didn't get around to testing the syncing yet, but yeah, I'll try to get to it as soon as possible. I'm just busy with some other things right now and yeah, I think that's it. So Tanish, can we integrate?
00:07:39.846 - 00:07:44.010, Speaker E: Nethermind's working in Lordstar Quickstart?
00:07:46.110 - 00:08:00.686, Speaker D: Yeah, I think we can because the client is now stable. I've tried restarting and everything and it seems to be working. Yeah, I think we can add another mind to the quick start guide. So only the image would change or.
00:08:00.708 - 00:08:03.220, Speaker E: Are there some arguments that are extra needed?
00:08:05.510 - 00:08:21.990, Speaker D: No, I'll send you the details because there are some arguments for if you want to enable proofs, verify proofs while processing, and multiple things that I need for testing, but just for simple things, I don't think so. We'll need anything else. I'll just send you the image.
00:08:26.720 - 00:08:28.560, Speaker F: Tanju, do we also have the option.
00:08:28.630 - 00:08:31.730, Speaker A: To have a light node without state?
00:08:33.060 - 00:08:44.710, Speaker D: Not with the configuration. Right now I have to change a few things. I have another branch where it works, but it's hard coded. I'll just add a few configuration and we can work with that.
00:08:46.120 - 00:08:50.870, Speaker A: Okay, that also would be a bit interesting potentially for people to test.
00:08:51.980 - 00:08:57.530, Speaker D: Yeah, I'll create a configuration for that and then probably send both of the instructions to.
00:09:13.610 - 00:09:14.630, Speaker B: Dignity.
00:09:17.390 - 00:09:44.386, Speaker E: Yeah, I just wanted to mention something about costine. I'm sharing documents, so I'm taking advantage of now costine running for getting some metrics about how things are working. So I won't go into details about this document. You can read this later if you're interested.
00:09:44.488 - 00:09:45.140, Speaker A: But.
00:09:47.350 - 00:11:28.660, Speaker E: I have like a modified guest that is collecting some information and I will be updating this talk once in a while because I was interested in seeing things like the average depth of the state tree considering how many key values you have on it, and just to have some sanity checks about some expectations considering the design of the tree. Also, we have been talking about for a while about proof sizes. So another report there is the witness size for each block and I do some de aggregation of how much of the size comes from the state dis, so the pre values and the post values and how much comes from the cryptographic proof, just to get some better understanding on real proof sizes from some real in quotes chain. And then I also collect some metrics regarding proof generation and verification times. This is a bit experimental in the sense that we have much loading calculate yet. So like these witness sizes and proof generation times and proof verification times are a bit not that meaningful. But whenever we have more load or the state is bigger or things like that, at least we can have some more real numbers.
00:11:28.660 - 00:11:41.640, Speaker E: So yeah, I will be updating this doc maybe once per week or something like that. Maybe we can start concluding some stuff regarding all this.
00:11:57.550 - 00:11:59.850, Speaker B: Anyone else would like to share an update?
00:12:06.510 - 00:12:59.760, Speaker F: Thomas, do you want to share something? I can. On Bezos side we are working on some libraries, so we are trying to implement Java implementation of verkel tree. We are also moving forward on cryptographic stuff in order to generate the state route, a valid state route when these libraries will be available. We want to integrate this library into bonsai in Bezu. So I hope that maybe next week we will start this work and at the same time we will also start to do the modification to be able to join the testnet. So I don't know when we will be ready to join the testnet but yes we will start some integration into Bezo maybe next week or something like that.
00:13:04.850 - 00:14:07.330, Speaker G: Yes, just to complement what Cam said, there's one or two bugs left to get the specs right for the rolling up the commitments. So it's just a matter of that concerning the testnet. But as Kalim said, there's also the extra feature of integrating with bonsai, which is something to my knowledge is new. So that's an interesting part also with this client. But yeah, hopefully we can start joining the testnet like Kalim said next week and hopefully also getting by then the bugs fixed in terms of the root hash.
00:14:16.190 - 00:14:26.800, Speaker C: Just wanted to add that to join the testnet. Do we need proofs now or not? I didn't understand from the previous, because.
00:14:28.530 - 00:14:47.080, Speaker A: If it's just about following the testnet, which would be a first good step, you do not need to verify proofs, you can just ignore it. You need to be able to deserialize the proof or at least receive an execution engine payload that contains them and you can just ignore it. So you do not need the proof to do that.
00:14:48.810 - 00:15:28.050, Speaker C: Okay, because we have crypto primitives ready and only crypto primitives needed for computing the root hash and inserting key value is the pedersen hash for the try key and the Pedersen commitment for the commitment in the tree. And we have that ready now it's only about constructing the tree and computing the root hash. And also what Thomas mentioned, how to integrate this into beso. Yeah, we are making progress.
00:15:31.110 - 00:15:50.620, Speaker A: Nice. I had a question regarding that. Are you still pursuing the rust route or are you just reimplementing everything locally when you do that integration work next week? Is it using rust vertical or not?
00:15:52.190 - 00:16:04.240, Speaker G: It's using rust. Not sure about rust vertical, but the libraries that rust vertical are using for the crypto and we'll continue using.
00:16:07.490 - 00:17:02.210, Speaker C: Yeah, it's basically we are just exposing the call to Pedersen, both hash and the commitment. It's a bit different, but it's the same thing. But we are just taking the code from rust Veracle and exposing this to Java. Java sends bytes. Rust receives bytes and process it, turns it into field elements and computes the Pedersen commitment or hash, and then serialize it based on whether it's try key or it's commitment in the tree, and then returns it. And we just save bytes in Java and the same thing we want to do with the proofs. So we just need some time to understand how exactly it will be done because we don't want to create bander wagon and pander snatch elliptic curves in Java.
00:17:02.210 - 00:18:02.126, Speaker C: And actually idea that I had is because I don't know about other clients. Do they also want to do this way like ffi cryptographic primitives? Because if they want, it would be useful to create maybe a separate repo with these, quote unquote calls, cryptographic calls to these primitives. So they can also do the same thing like just call the Pederstone hash or just call the Pederstone commitment. And in the end just call like the tree data, which is needed to construct the proof. Like just following the Kev's article about five calls that crypto API needs to expose to the tree. So, yeah, maybe I'll do that next week, at least for Pedersen hash and Pedersen commitment, because it's useful.
00:18:02.318 - 00:18:10.600, Speaker A: Sorry, I don't think there's anybody else that wants to do that. Maybe theorem js, but my understanding is that everybody else is not doing that.
00:18:13.290 - 00:18:14.040, Speaker C: Okay.
00:18:16.810 - 00:18:32.300, Speaker A: I'm not telling you what to do. I'm just saying if it's an effort that you're doing, just because you think other people are going to need this, I don't see it at the moment. Maybe there is, maybe I'm completely wrong, but. Yeah, just for your information.
00:18:33.070 - 00:18:45.362, Speaker C: Yeah, just in my opinion, it takes a lot of time. Creating the curve, testing the curve, then bander wagon understanding. What's the bander wagon? It takes a lot of time, but.
00:18:45.416 - 00:18:46.020, Speaker F: Okay.
00:18:51.080 - 00:19:14.290, Speaker A: Right. And regarding the wasm wrapper, is it up to date? I don't remember. Kev. Looks like we lost. Kev.
00:19:21.050 - 00:19:22.294, Speaker H: Can you hear me now?
00:19:22.412 - 00:19:23.080, Speaker B: Yes.
00:19:24.570 - 00:19:32.230, Speaker H: Yeah, I said it got modified about two weeks ago to include the same API as GoiPA.
00:19:45.490 - 00:20:18.866, Speaker D: I just wanted to confirm for Besu when you say that you implemented pedestrian hash and pedestrian commitment when calculating the root of the tree and when you insert something new. So one thing that we can do is we can just add the differences in the commitment and recalculate the state root. Are you using that or are you recomputing the entire commitments again, because I just want to ask, basically, did you implement the addition subtraction of the commitments also, or just the hash and commitment functions?
00:20:18.978 - 00:20:51.810, Speaker G: I can answer that. For now, it's on the ND issue board to do that optimization of updating the commitment hash. Right now we are recomputing everything but a single time anyways. We're just updating like every, we're not updating commitments at every insertion. We have to trigger the updating the commitments anyways. But it's in the issue board to actually do that optimization.
00:20:53.670 - 00:21:19.206, Speaker D: Just wanted to ask, I just want to see that what kind of performance hit that those kind of operations have on the FFI. Because I was using the rust worker for Netherland implementation earlier and I faced some performance issues. That's why we decided to implement in our client. That's why I just wanted to understand how much of a performance do we have on SFI?
00:21:19.238 - 00:21:31.870, Speaker G: Yeah, it's a good question. It's a good question, but we are not there yet. We are at integration and then we'll do that kind of optimization afterwards.
00:21:36.280 - 00:21:47.960, Speaker A: Sorry, quick question. Did I understand that correctly? Tanish that when you have an FFI interface from C sharp, you also have a huge overhead.
00:21:49.180 - 00:22:23.270, Speaker D: I'll not say huge overhead, but basically I did that, I think a year ago. And to basically pass the arguments to the functions over FFI, we need to do some conversions. And because of all those things, the performance gain I was getting from using rust was not that much then implementing everything in C sharp. So that was the problem then. But I didn't try it out recently and it might be possible that I missed out on some optimization. So yeah, that's also the case.
00:22:24.200 - 00:22:33.320, Speaker A: Right? There's Kev's question. Yeah, if he was doing normalization in the serialization, that would definitely have an impact.
00:22:41.430 - 00:22:45.460, Speaker D: I don't remember that. So might be the case.
00:22:46.710 - 00:23:02.710, Speaker C: We didn't test the performance yet, but at least doing something and understanding. I think it will be then easier to re implement everything in Java. But for the first step I think we should be fine with rust. Jni.
00:23:06.870 - 00:23:30.540, Speaker F: From what I know in general, in Bezu, for cryptographic stuff, we are using c library, sometimes rust libraries. In general, it's better. But as Dragon said, we didn't have time to test performance with this library for the moment, but we will see.
00:23:49.590 - 00:23:52.050, Speaker B: Anyone else like to give an update?
00:23:52.630 - 00:23:54.478, Speaker C: I think we might be missing.
00:23:54.574 - 00:23:57.510, Speaker B: Let me see. Lodestar and Nimbus.
00:24:01.450 - 00:24:39.090, Speaker I: Yeah, so I can talk about Nimbus. So on our side, there is good progress. We've done substantial work on the mat primitives, so credits to Advaita and Agnes that have been really focusing on. So in the nimWd, we have a library called Constantine, which has been around for a while, and my man developed most of it. So we extended that library with the primitives we needed for better wagon.
00:24:41.030 - 00:24:41.780, Speaker A: So.
00:24:43.670 - 00:25:26.100, Speaker I: The rough development is done. Now we're in the process of taking that library and integrating it into the Nimas plant. So I guess that hopefully we're something like two or three weeks away from seeing the first root commitment being computed correctly. We are still a bit farther off from joining the testnet. I guess that will take a good two or three months from now. But, like, seeing commitments walk, I think we're about like two or three weeks away. So that's it from our side.
00:25:41.570 - 00:25:42.350, Speaker A: It'S.
00:25:43.570 - 00:26:13.170, Speaker B: Last call for anyone else. If not, we can move on. Okay, the next agenda topic was Guillaume, I believe you wanted to have a conversation on this topic of per block versus per slot during the conversion.
00:26:14.390 - 00:27:34.430, Speaker A: Yeah, so that came up, I think, last time, or maybe the time before, and I was trying to look for the conversation because I remember after NCC, where I discussed the topic with. Yeah, I announced what the solution was, but I haven't been able to find the exact moment. So, yeah, I need to ask the nCRat. But regardless of that, yeah, I think the decision should be made whether we want to go for doing the conversion like n values per slot, or if we want to convert n values per block. My current favorite model is that we convert per block because in the case of a reorg, we would have to re execute every block, like the conversion copy n values per block that we have to re execute during the reorg. And that's less difficult than. At least that's less computationally intensive than doing it per slot.
00:27:34.430 - 00:28:14.220, Speaker A: The problem with this approach is that it makes the. If a lot of reorgs happen, it will delay the conversion by this much. So let's say half of the slots get missed. The conversion lasts twice as long. Twice as long. Of course, if half the slots were missed, that would mean the network has a huge problem. But, yeah, let's say if one third of the slots get missed, we would take one week longer, or, sorry, not a week longer.
00:28:14.220 - 00:29:12.734, Speaker A: Yes, actually. So, yeah, that's the problem of doing it per block. The advantage of doing it per slot is that all the problems I mentioned just now would not happen. But if you have a big reorg, the nodes that Reorg will have a significant amount of work to do before they can join the branch they reorg to. And that could still be okay. I think it would actually be possible to save the amount of conversion that was done, at least in guest, where we have this layered system, we could save it at every layer. And so, if we need to unstack the conversion, we could save it so that when we redo it, it's possible.
00:29:12.734 - 00:29:38.440, Speaker A: I mean, this optimization can be used either in the case of slots or blocks. But, yeah, my preference right now still would be with blocks. So, doing n values per block, I wonder what you guys are thinking, if there are any opinions. But, yeah, that's one decision we should try to make, if possible, before the end of the year.
00:29:41.530 - 00:30:03.390, Speaker F: I think on business side, I think didn't have time to look at this part a lot. But from what I understood, I think per block, it's better. Regarding how bonsai is working. For the moment, my preference will go to per block.
00:30:15.910 - 00:30:19.140, Speaker A: Danishko Wukash, do you have any opinion on that?
00:30:19.930 - 00:30:27.880, Speaker D: I think last time also, we discussed that if we do per slot, I think we need some information from the Cl.
00:30:29.850 - 00:30:34.570, Speaker A: That's actually not quite true, because you could just look at the timestamp.
00:30:36.030 - 00:30:36.394, Speaker D: Okay.
00:30:36.432 - 00:30:36.634, Speaker A: Yeah.
00:30:36.672 - 00:30:38.858, Speaker D: From timestamp, we can calculate the slot number.
00:30:39.024 - 00:30:39.740, Speaker A: Okay.
00:30:40.350 - 00:31:14.390, Speaker D: Second thing is, I was just saying that I'll also prefer per block. It'll be easier to work. But if doing it first slot gives us a guarantee that we can finish a conversion in a particular amount of time, then I think it might be better, because I'm not sure how many deep reorgs we see on the main net. So, like the case where we have to do a lot of computation, again, due to reorg, how frequently would that occur?
00:31:16.810 - 00:31:41.040, Speaker A: For me, per block is no brainer, and we should just move on. Okay, good, because that conforts me, in my opinion. But is there any dissenting opinions? All right, it looks like we are moving on.
00:31:44.610 - 00:31:50.750, Speaker B: Okay, I think the next one is also you, Guillaume. Post date and the cryptographic proof.
00:31:52.290 - 00:31:54.094, Speaker A: No, actually, I think it's in.
00:31:54.292 - 00:31:55.550, Speaker B: Sorry, apologies.
00:31:58.390 - 00:33:01.720, Speaker E: Yeah. So, last week, when I was working in fixing some bugs in the proof generation verification in f, I got into thinking that since we included the post state values in the witness, we also, in GEF implementation, included the openings for these post state values in the cryptograph proof. So the way this works, or works now, I would say, is that the cryptographic proof of the witness, it is proven the openings for both the prevalues and the post values. And if you think about this for a moment, the reason that we want to include these post values is because we want to allow potential clients to know a about the state difference.
00:33:03.690 - 00:33:04.102, Speaker A: That.
00:33:04.156 - 00:34:10.970, Speaker E: Happened in a block without actually executing the block. Because if you are executing the block, clearly you will compute yourself the new values. But what this means is that if the parties that are using these post values aren't executing the block, they are actually trusting the new root of the tree. So if you are trusting the new root of the tree, it doesn't make any sense really to have a cryptographic proof that the post values are part of this tree simply because you are trusting the root of the tree. So I can give you some post values. I can generate a correct cryptographic proof that these post values are part of the new tree, but I can be simply cheating on what is really the new tree. And since you are trusting that roots, you're not gaining anything really from having this cryptographic proof.
00:34:10.970 - 00:35:32.306, Speaker E: So the bottom line is that I talked about this with Kev and also with Ancrad. This was mostly, I think, a confusion between the specs in quotes and the implementation. Mostly because I think we never kind of formally define what the specs for post values is. But this is kind of good for performance because this means that the cryptographic proof will have less openings because we don't have openings for the post values. And that's good for proof generation and verification. Not like a huge amount because there won't be a lot of post values, usually because that's quite expensive for transactions, but this is a bit less work. But the TLDR is anyone that is using post values should be kind of careful in the sense that it is fine to use these values, but you have to be getting these blocks from trusted or semi trusted sources because we still don't have any kind of proof of block execution.
00:35:32.306 - 00:36:54.800, Speaker E: So you will have a new state root length by the block, but you still don't have a proof of correct execution from the prestate to the post state. So yeah, if you are aware of that fact, it is fine to use the post values, but if you are getting these blocks from an untrusted source. Well, you have to be more careful about using these values because they can be failed or invented or something like that. Yeah, so that's kind of the update I already changed. I have a working version of get with this fixed, but it isn't really yet deploying costine. Probably we will do that in the next days, or will. So this basically means that the proof for this version of Kofsinen are like the same of the previous version of Kofsinen, which basically means that the cryptographic proof only has a proof for the prestated, which is also good for, I guess, tanyanshi, since that means he doesn't have to do any changes there.
00:36:54.800 - 00:36:58.020, Speaker E: So yeah, that's it.
00:37:02.180 - 00:37:39.710, Speaker A: So I have two questions based on that. One of them is for tennis because your sync uses those proofs and especially the post state which is untrustworthy. And my understanding is that you are not reexecuting the block every time. How attackable is this? And should we somehow come up with a sign mechanism to require that people that provide proofs somehow sign them so that we can slash them somehow? Yeah, so that's the first question.
00:37:44.080 - 00:38:07.940, Speaker D: If we think about the worst case then I think it's quite a big problem because I think not actually, because eventually if the values are wrong and we already have the correct state route, then eventually when the sync finishes we'll have a problem. We'll not be able to get the correct route.
00:38:10.680 - 00:38:11.430, Speaker A: Right.
00:38:13.660 - 00:38:35.310, Speaker D: Anyways. Again, sorry I missed this. So if you are not providing the posted proofs then anyways, for healing every time we need to calculate all the internal nodes and recalculate the state route. So anyways we'll be able to verify if the posted values are correct or not.
00:38:35.760 - 00:38:36.620, Speaker A: Yeah, that's true.
00:38:36.690 - 00:39:12.596, Speaker D: Every time. Another way is to just directly re execute the block. I'll have to check how much time, extra time would that take? But if the post values are actually a very big problem, then we can just re execute the block. I don't think so. It will be that big of a problem. And since we are doing it in a stateless way, so what we can do is while the sync is running, we can re execute every block in the background and collect posted on our own. And whenever we need the posted for healing, then we can use that collected posted to heal.
00:39:12.596 - 00:39:15.450, Speaker D: So yeah, that is another optimization that can help.
00:39:17.040 - 00:39:48.230, Speaker A: Yeah, that's very nice. Yeah, I didn't realize that. That's pretty cool. The other question was for Kev. Yeah, because we're no longer including the post state in the to do we need to change the proof verification code in either rasvirocal or go IPA multi proof? My understanding is that we don't, but yeah, you know the code base better than I do.
00:39:49.640 - 00:39:57.530, Speaker H: Not as far as I can tell, but I can double check for you.
00:39:58.620 - 00:40:02.730, Speaker A: Cool. Yeah, that's all for me.
00:40:10.180 - 00:40:28.150, Speaker C: One question. Is there an implementation or the specs of stateless client? Is this what Nethermind does? Is that the most close to stateless client, or we are not there yet.
00:40:30.200 - 00:40:57.100, Speaker D: So Nethermind has an implemented version of stateless client, but I don't think so. There's a spec, but it's very straightforward. The idea is that you get pre state in the block, so you generate a status tree from that prestate and you verify that the prestate proof is correct. Now you have all the values you need for block execution. So instead of using the actual state from the database, just use this state for block execution.
00:40:59.760 - 00:41:29.770, Speaker A: Yeah, I don't think you need to spec for that. It's just a regular execution, like whether it's stateful or stateless. I would say it's an implementation detail. So it's up for clients to decide what kind of store they want to have and if they want to implement stateful or stateless. It's whatever they want to do. It's really left. So yeah, there's no such spec because at least I don't think we need one.
00:41:33.700 - 00:41:34.930, Speaker C: Okay, thank you.
00:41:35.460 - 00:41:47.220, Speaker A: EVM remains the same. The only change is that you get the state from the proofs and not from the actual database.
00:41:54.840 - 00:42:02.090, Speaker C: Okay, makes sense. We'll read more about post state values, how that comes into play.
00:42:10.510 - 00:42:15.210, Speaker B: Okay, last up, we had the verification pre compile Guillaume.
00:42:17.330 - 00:43:48.220, Speaker A: Yes. So that's actually been asked by Zahari from Nimbus. He was asking whether there's a pre compile or not. And it's true that a pre compile, that could help everybody, all the DAP developers get onboarded with Verkel, because right now everybody understands the concept of Merkel proof. But if you have to wait for the tooling of Verco to the tooling of those libraries that currently are relying on Merkle proof to start using Verco instead, because of the math, because of all the problems we're currently talking about with every client trying to implement, vertical dapp developers and people who provide like EVM level libraries are going to have the exact same problem. So yeah, I came up with a proposal for a pre compile, yet another pre compile proposal to verify vertical proofs so that, for example a bridge or whatever could call this pre compile in their contract and just get the proof verified so that they don't have to really understand the workings of Verco right off the bat. If people want to start doing optimization later on, that's always possible.
00:43:48.220 - 00:44:24.050, Speaker A: But yeah, maybe speed up the adoption of vertical via this pre compiled so I created an EIP. I'm sharing my screen again if it shows. Is that the one? Let me see. Sorry, always having an issue. Sharing. Yes, that's the one. So there's the text of the EIP.
00:44:24.050 - 00:45:16.280, Speaker A: The EIP number is 79, sorry, not the EIP number. It has been changed to 75 45, which is easy to remember. And yeah, it's currently half an EIP because it explains how the pre compile itself would work. So basically it receives a version number. If the version is zero, then it will deserialize a vertical proof like they are currently not specified. I guess not specified fully, but are currently used on Calstinin or what will be the proof format that will be part of the verge. And then further down the road, if we switch to ZK proof, if we invent a new system for verifying those proofs, newer versions could come.
00:45:16.280 - 00:45:53.198, Speaker A: If we decide to move from vertical back to some quantum resistant tree or whatever, we could do that as well via this pre compile. So this pre compile would be future proof. Maybe. One thing that's missing currently from that pre compile is the gas model. I have not really given it much thought, so I'm happy to get input on that if people have ideas. But yeah, that's pretty much it. Just wanted to mention this exists.
00:45:53.198 - 00:46:28.392, Speaker A: There's an Ethereum magician thread as well. So yeah, if you have any idea, if you have any input on this, please share it there. And yes, that's all I wanted to talk about on this topic, just a little bit of context here. I think the many use cases, indeed bridges between EVM different EVM chains. Usually what is secured transmitted by a bridge, say a zero knowledge syncing clamp.
00:46:28.456 - 00:46:30.680, Speaker C: For the chain is just the root.
00:46:30.760 - 00:46:58.840, Speaker A: Hash of a particular block. And usually in the block you will find the root hash, the root commitment of the entire ethereum state. And then when you actually need to kind of materialize some data from the other blockchain, it could be a receipt, or it could be EVM variable and so on and so forth. You will need to provide vertical proofs when this data is transmitted over the bridge.
00:47:16.390 - 00:47:21.320, Speaker B: Okay. Any other things that people would like to bring.
00:47:25.610 - 00:47:38.522, Speaker A: Was last time we didn't get around to do that, but Jason from. We wanted to have a quick discussion. I'm just checking if Jason is here. No, he's not. Okay. Yeah. So.
00:47:38.522 - 00:47:40.620, Speaker A: Okay. Nothing more from my side.
00:47:42.030 - 00:48:10.760, Speaker B: Yeah, I ping Jason. I will follow up and see if we can get him on a future call. It is not the best time zone for Jason right now on these calls. Okay, if there's nothing else, just one very quick update. We will be changing the cadence of these calls to every two weeks. That is, unless there are any objections, concerns, or recommendations from anyone here. Otherwise, we will move forward with.
00:48:10.760 - 00:48:16.678, Speaker B: And thank you everyone, for being on these. Oh, Guillaume, go ahead.
00:48:16.764 - 00:48:33.020, Speaker A: Yeah, sorry, just a question. I'm not against increasing the cadence. I'm just wondering because in two weeks, supposedly that's devconnect, if I'm not mistaken. So do we start increasing the cadence after devconnect or. Yeah, that's my question.
00:48:35.150 - 00:48:49.730, Speaker B: Good question. That would make sense to me. Any quick thoughts from anyone else here? Otherwise, that's probably a good idea. Yeah, I know a lot of people are getting ready for their own presentations and traveling. Milos.
00:48:51.830 - 00:48:52.386, Speaker G: Question.
00:48:52.488 - 00:48:57.074, Speaker A: Is there going to be some kind of special event or somewhere on the.
00:48:57.112 - 00:49:00.034, Speaker E: Devconnect where we can chatter, meet in.
00:49:00.072 - 00:49:02.854, Speaker A: Person, or is workland not going to.
00:49:02.892 - 00:49:04.790, Speaker E: Participate in any of the events?
00:49:06.650 - 00:49:12.760, Speaker A: There was going to be an event that just got canceled. So I guess the answer is no. For the moment.
00:49:16.550 - 00:49:28.890, Speaker B: We could still try to do something. It's getting to be a little bit last minute. Maybe it's something that we can talk about more offline, but yeah, it's a good question as well. Dragon.
00:49:29.790 - 00:51:02.280, Speaker C: Yeah, I just wanted to share a few things regarding vertical in circuits that I'm still researching that based on zet, which is a ZKE EVM project from risk zero ketchup takes more than 50% of the resources for proving the block. So because in Verkel there is no catch up, I guess the improvements when the vertical goes mainet and these roll up or whatever ZK technology projects move to, my expectation is that we should see much of an improvement for the proving time, and it's just exciting that we have that. And I'm moving forward with that project, doing more research and contacting people and see if there's any interest around teams to implement Verco in circuit. And mostly I'm getting positive feedback. So we'll try to report on other calls, like by the end of the call if there's time, because it's a bit far away, because if I understand correctly, there are people thinking that the workhorse won't even happen on Mainet because of the complexity. So yeah, I'm careful with this.
00:51:05.050 - 00:51:08.700, Speaker A: It's only uninformed people who think that.
00:51:12.750 - 00:51:21.070, Speaker C: Yeah, I get it. And if anyone wants to share thoughts regarding this approach, feel free to share thoughts.
00:51:22.770 - 00:51:29.680, Speaker A: I do have a quick question. You say ketchup. Did they try shuttle 56 instead.
00:51:31.650 - 00:52:07.610, Speaker C: For this specific project? They are just replicating MPT as is now in Ethereum, so they are doing catch up. But I think with shuttle physics it should be similar because it's a bitwise operation and it's hard to prove that in ZK circuit. It just takes a lot of time. So the tree structure is a big bottleneck for all the ZKE EVM projects which try to prove the block in Ethereum as is right now without any changes, without introducing different hash like Poseidon.
00:52:11.730 - 00:52:34.420, Speaker H: Yeah, I guess my thoughts are that it'd be good to figure out 50% of how much time. And also the scalar multiplication might not be cheap for them if they're sort of not using BLS twelve. Like if they're using bn two five, four. There's sort of a mismatch there.
00:52:36.010 - 00:53:23.170, Speaker C: To my knowledge they have the most performant and they are not even using BLS. They are using fry small field. I think it's Goldilocks. So I know vertical is designed to be compatible with the proof system which uses BLS curve, but more and more projects are using fry small field. So fry goldilocks, I think it's 46 bits. So I think as the times goes by, things will just get more and more improved. So we will have multiple proof systems, but I don't know which one will be used in production.
00:53:23.170 - 00:53:36.920, Speaker C: But I think there will be multiple proof systems. But it's still good to know this when designing vertical pedals and which curve is using and stuff like that.
00:53:39.230 - 00:53:57.360, Speaker H: Yeah, it'd be good to figure out sort of what is the cost of doing basically a bander wagon scalar multiplication using the field that they're using, since it's not going to be cheap if it's not Bns twelve straight one.
00:53:59.330 - 00:54:04.850, Speaker C: Yeah, I plan to do that. That's the first step which I plan to benchmark.
00:54:08.230 - 00:54:08.980, Speaker H: Thanks.
00:54:23.420 - 00:55:00.950, Speaker B: Okay, well, so with that, just a final thought I wanted to quickly mention if anyone has any other thoughts or ideas on ways we might be able to further improve collaboration around virtual. Please ping me anytime. This is just a small change that we're making to increase the cadence to every two weeks post devconnect, but open, of course, to any other ideas and would welcome any feedback. But I do think we are doing quite well, considering where we are. So, yeah, thank you, everybody, for being here, and we'll see you in a month if we don't see you at connect.
00:55:02.600 - 00:55:04.790, Speaker A: Thanks. See you.
00:55:05.160 - 00:55:06.448, Speaker B: Bye bye.
00:55:06.464 - 00:55:07.920, Speaker A: Bye. Thank you. Bye.

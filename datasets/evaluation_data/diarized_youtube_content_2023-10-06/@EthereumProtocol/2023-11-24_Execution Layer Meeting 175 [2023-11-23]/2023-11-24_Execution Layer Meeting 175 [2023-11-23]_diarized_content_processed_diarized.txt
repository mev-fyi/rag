00:05:23.080 - 00:06:21.760, Speaker A: And we are live. Welcome, everyone, to acde number 175. Today, as always, we'll be talking about Denkun, get some updates on testing. I believe there was an execution API pr we wanted to discuss as well and then figure out where we're at with regards to launching Devnet twelve and what we see as the next steps after that. And related to this, we discussed in the past that this would be the last fork on Gorli. In a world where we forked Gorli before the holidays, it would have made sense, I think, to announce that as part of the hard fork announcement. But I think if we're not going to hit that, we should still announce how long we plan to keep Gordy around for after Dan Kuhn.
00:06:21.760 - 00:06:56.690, Speaker A: And so if we could get a feeling from teams today around how long we want to maintain at least the client nodes on Gordy, that'd be great. And then to close off, Micah has proposal for a new RPC, endpoint East multicolor. Yeah, so I guess to start, I don't know, Perry, Barnabas, either of you want to give an update on testing so far and Devnets where we're at there, and then we can go to the client teams as well?
00:07:00.220 - 00:07:43.896, Speaker B: Yeah, sure. I can give you an update. So basically we are running Devnet eleven right now, and everything seems pretty stable. The only pair that is not able to keep up is ethereum js with Lodestar, but it seems to be some peering issue. Probably Gajinder can look into that. We wanted to launch Devnet twelve next week, but we heard some feedback from the Prism team that they think that this is a bit too soon. So we might as well hold off for a bit longer because this week is Thanksgiving week in the states and we expect that maybe not all client teams would be ready to go with Devnet twelve.
00:07:44.078 - 00:07:54.910, Speaker A: Got it. And just could you remind us, Devnet Eleven does not have the laylist Cl changes, right. Devnet twelve is the one that will have the blob silicon changes. Got it.
00:07:56.640 - 00:08:04.624, Speaker B: Yeah, that's correct. So I do have a spec sheet also for Devnet twelve. Give me 1 second, I will get the link.
00:08:04.822 - 00:08:12.240, Speaker A: I have it in the agenda. Let me post it in the chat here. Okay.
00:08:12.310 - 00:08:19.270, Speaker B: Yeah, so the only change should be just that one change that we discussed last time.
00:08:19.640 - 00:08:20.630, Speaker A: Got it.
00:08:21.400 - 00:08:44.988, Speaker C: We did test a couple of things for the lighthouse team. I think they changed what gets gossiped, in which order as well as quick support. And I think Pawan has like a bunch of information he's collected out there. And then we turned on map back in Devnet eleven. So we're going through the entire map workflow on Devnet eleven as well.
00:08:45.074 - 00:08:48.520, Speaker A: Nice, Bennett.
00:08:48.600 - 00:09:04.400, Speaker B: We should probably. Sorry. So we still want to enable all Meb boost for all the different clients. Right now it's only running for Loadstar and Nimbus, but by the end of this week we're going to enable it for all cls.
00:09:04.920 - 00:09:11.940, Speaker A: Got it. Sorry. Anything else, Barnabas Perry? Otherwise I will go to Ben.
00:09:13.320 - 00:09:15.110, Speaker B: Yes, that's it for me.
00:09:18.600 - 00:09:39.470, Speaker D: Yeah, I just wondered if we should do a straw poll, really, on Devnet twelve starting in a week. If it's only prism who is unable to make it, they can catch up later. So just in terms of kind of keeping up the cadence, whether if everybody else is ready or not, we could just put a finger in the air and see Teku. We believe we shall be ready.
00:09:41.540 - 00:09:49.890, Speaker A: Awesome. Yeah. How do other clients feel about that? Is anyone else ready to start Devnet twelve next week?
00:09:50.900 - 00:09:54.470, Speaker E: Lordstar can start Devnet twelve next week as well.
00:10:00.480 - 00:10:01.950, Speaker A: Anyone else?
00:10:02.880 - 00:10:05.032, Speaker B: I think all the execution layer clients.
00:10:05.096 - 00:10:43.920, Speaker A: Probably can, yeah, I assume there's no changes. I don't know if there's anyone. So prism said they can't. I don't know if there's anyone from Nimbus or Lighthouse on the call. Okay, well, if we have all the Els and then at least two of the cls, potentially up to four. Yeah, I'm curious, Perry. Barnabas, do you think there's value in standing up the devnet, even with a subset of clients? It feels like we might learn about something breaking, especially given like the new cl change.
00:10:43.920 - 00:10:48.766, Speaker A: By doing that next week, I think.
00:10:48.788 - 00:10:55.570, Speaker B: We can do kutosis test for sure. And then if we have like three clients, then we can start the devnation.
00:10:56.710 - 00:11:40.168, Speaker A: Okay, that sounds good. I guess what I'll do then I'll post in the discord asking for if there's more cls. And we have a testing call on Monday as well, scheduled. So yeah, we can bring that up there as well and see if there's a third client. But I think, yeah, let's try to do it even if it means it breaks and then there's a Devnet 13 or something. I think we'll learn a lot by trying to get the Devnet twelve up. Yeah.
00:11:40.168 - 00:11:51.230, Speaker A: Okay, so cool. I'll do that. I'll ask in awkwardev and then we can discuss this on Monday. Any other.
00:11:52.320 - 00:11:54.564, Speaker B: Would midweek work for Lodestar?
00:11:54.712 - 00:11:55.410, Speaker A: Sorry?
00:11:56.340 - 00:12:00.080, Speaker B: Like Wednesday or Thursday would work for Lodestar and Teku.
00:12:02.580 - 00:12:08.640, Speaker D: Yeah, I think so the 30th was the original plan. I think that's good with Teku possibly earlier.
00:12:09.380 - 00:12:14.470, Speaker E: Yeah, Lordstar is ready even this week as well, so. Yeah, very good.
00:12:17.240 - 00:12:23.640, Speaker C: Yeah, I think Lighthouse is ready as well. So we can just try to make sure the devnet is up before the call next week, Thursday?
00:12:24.540 - 00:12:33.960, Speaker A: Yeah, that would be amazing. If we can get it up on Wednesday, try to run it for a day and see if it's still up or broken by ACDC.
00:12:38.830 - 00:12:48.210, Speaker B: Okay, sounds like a plan. Just ping me your branch that I should use for Devnet twelve and then I will build the images.
00:12:49.910 - 00:13:23.970, Speaker A: Awesome, thank you. Anything else on Devnet twelve? If not, Mikhail, you'd link the PR and the agenda by. Sorry, I'm linking but the pr around disallowing the invalid equivocations. This is an execution API PR. Do you want to give some context around that?
00:13:25.140 - 00:13:47.880, Speaker D: Yeah, thanks, Tim. So a bit of a background hasten from Nimbus raised a problem in the Istanbul and the problem looks as follows that actually some El clients, when they first time receive some execution payload.
00:13:49.980 - 00:13:50.344, Speaker A: Can.
00:13:50.382 - 00:15:04.610, Speaker D: Validate it and return the invalid status. So saying that this payload is invalid, but if the same payload sent to the same client for a second time, the response could turn to valid, which must not happen. And obviously it must not happen. And basically it is implicit in the spec that the valid or invalid status is like the end status and it must never change for the same payload. And because we have some clients which does not follow these implicit requirements, we decided to make them explicit and rise awareness that this thing should be fixed. Because on the Cl side this is really unexpected behavior. And I guess that for other reasons, not only for Cl side, like receiving something, then that will be changed in the future for other reasons, this is also the behavior that your clients should not have.
00:15:04.610 - 00:15:14.710, Speaker D: Yeah. Dustin, do you want to give more context from Cl side what bad things can happen because of that?
00:15:16.600 - 00:16:14.308, Speaker F: Yeah, sure. So the main issue from the Cl side is that it is defined in spec that a valid block cannot be the descendant of an invalid block and an invalid block cannot contain, again, perspect. On the Cl side, an execution payload declared to be invalid by an El. So what this means that it is valid and legal and actually a quite common optimization, for example for gossip rejection, for things like this, for a Cl say oh no, the El already told me that this execution payload was invalid. Anything I see that refers to that just skip and discard and move on. And what this means is that this stalls chain progress for the Cl. Now, different cls do handle the details of this differently.
00:16:14.308 - 00:16:55.350, Speaker F: Cls can retry, some do, some are more strict about just saying no, they saw it once and just stop and never use it again, at least in the past, I believe that some have saved the rejection to disk in some format, but I think they stopped doing that a while ago. So most restarting will wipe the slate clean on this point. But essentially though, is that it really cuts off the validity of the chain and that's the harm that it causes. And to the degree that some cls seem to tolerate it, that's because they're just retrying. And honestly, it's not clear to me whether they should.
00:16:57.720 - 00:17:28.610, Speaker D: Yeah, so basically, if some payload is deemed invalid, and this is actually an incorrect status of this payload, it may also cause temporal network splits because validators will not vote for invalid blocks for blocks containing invalid payloads. So this is quite important to fix these bugs if they exist in EL clients. And yeah.
00:17:33.460 - 00:18:07.100, Speaker A: Sorry, just to understand, is this an issue where the spec on the execution API is currently more permissive than the spec on the consensus layers and therefore we only need to fix the spec? Or have we seen actual cases of this happen on a devnet? I guess I'm trying to understand what leads an EL to first classify something as invalid and then valid. And if we've seen examples of that, or is this just a spec issue that we want to make sure everybody's following.
00:18:09.360 - 00:19:12.796, Speaker F: Both are. So first, is the case that this is in the link spec or issue pr that Mikhail links? Actually the very first link within that description is to the optimistic sync spec. And the optimistic sync spec already essentially requires very, I think explicitly. If people want to debate that, that's fine. But as far as I'm concerned, this is basically just implementing what's already in CL specs in the engine. And for various reasons, I guess the engine APIs had not strictly required this. And what had happened was there's, let's say some evidence that engine API implementers on the El side have not always looked at, nor should they have to, if the specs are well factored out, pure Cl specs, which is to say the optimistic SIG spec got it, which is how the operates.
00:19:12.796 - 00:19:43.916, Speaker F: So they did not necessarily see the dire outcomes of this equivocation necessarily, because the El spec doesn't clarify this. That's part of this. That's half your question. Now the other part is, is this essentially theoretical, or is this just sort of a spec alignment for the sake of spec alignment? No, it's motivated. There are multiple els. This is very clear. I'm not picking on one El here.
00:19:43.916 - 00:21:10.070, Speaker F: I have encountered this with multiple els, and there are GitHub open GitHub issues and discord threads in the Eth R D discord, where the latter are theoretically public. Kind of hard to find just because discord ux, but where I have discussed this with said els and provided examples from their logs and compared from these devnets. Yes, because that's actually a great way to harvest these things, because then I can log in and see the exact same network situation with Nimbus Geth, nimbus Nethermind, Nimbus Besu, nimbus Aragon, and just compare them and how they react to each payload beyond just looking at the beacon chain instances. And there are absolutely examples of this in the devnet, up through Devnet ten or eleven. So it's become less common, sure. But I think almost the fact that it has continued kind of at albeit a lower frequency these days than it used to is part of what suggested to me that maybe it's an issue of, well, it should be in the specs, because it's clearly not. Look, hive tests many, many things.
00:21:10.070 - 00:21:53.700, Speaker F: I don't mean to make this a digression that will last longer than a sentence or two, but it's going to feed directly back into this. Hive tests many, many things. And empirically, els are quite responsive to when Hive finds issues with them, because hive tests El specs. And what this I was reading out of this was that this was one of those regressions that was never really tested for. Therefore, it kept happening again and again because it was not one of the metrics people were trying to hit. And so my goal is essentially to add this explicitly back into one of the constraints about how els work, as els see it, when they implement their own code, not just when they happen to look and into CL specs.
00:21:54.920 - 00:22:33.010, Speaker A: Got it. Thanks. Yeah, that's really helpful context. And then there's a comment in the chat by Gary saying, one case where this could happen is if you have a state route mismatch and then you restart your node and it turns out fine, and then you're processing the same payload. But yeah, I guess I'm curious to hear from El folks. Like first, does anyone think we should not do this change? And then two, how should we test for it? Because something like this, where it's like a state root mismatch and you have to reset, is there a way to test for that in Hive or somewhere else so that we can catch those bugs earlier in the process.
00:22:37.680 - 00:23:19.390, Speaker E: Here I want to seek some clarification on behalf of Ethereum Js. So is the oscillation. So the problem is the oscillation between valid and invalid, or between invalid and syncing as well. I mean, it could happen that the node would not keep the cache of invalid blocks, or would clear out its cache at some point, and might if the Cl again is trying for an invalid block, which it should not, but let's say because of their syncing strategy, they're trying again to sync a block, and that is responded as syncing. I think this is also being mentioned in the PR, but I want to sort of confirm that. Is this also sort of a no go?
00:23:21.440 - 00:24:16.012, Speaker F: Not as unambiguously so. This is discussed in the issue linked the PR and between Mikhail and I. Actually, as far as, and obviously other people's input, yours, anyone else's is welcome. So strictly speaking, for compatibility with the CL specs, optimistic sync, which is sort of the reference I'm going with here, because that's how CLS work. All the CLS implement this, and so an EL which breaks this sort of contract really makes things difficult. But the only thing that strictly requires is exactly what you said at first, which is it cannot cycle between invalid or invalidated, obviously block, cash, et cetera, and valid the syncing is okay for this purpose. There is a question, it's a good question.
00:24:16.012 - 00:24:45.610, Speaker F: I think what the correct thing to do about the syncing is, because what you describe, of course, is true as far as keeping pre states around and all that. It, strictly speaking, though, is a little bit distinct from this issue. And that's one of the questions actually, that I think we would love. Mikhail and I would, I think, welcome input into how to incorporate that or not into this PR.
00:24:52.460 - 00:26:20.660, Speaker D: I think that previously we decided that invalid synchron is probably fine, but valid sync is not fine, and also invalid, and valid switching between the two is basically something that must never happen. And as it's been said that one of the easy ways to fix that could be say we have a cache for invalid blocks, and when the next lot comes with the same block hash, so we can hit this cache and see if the block is invalid and respond invalid, even though this cache makes sense for other reasons. But I would like to emphasize that this easy fix for this particular problem should not be applied, because really, jumping from invalid to a valid state can be quite detrimental depending on the share of the market for the risk market. That certain client that do this has been said chain split, and some co clients will have to be manually restarted to accept the block that was deemed invalid incorrectly.
00:26:24.120 - 00:26:25.700, Speaker A: Thanks Lucas.
00:26:33.110 - 00:27:37.190, Speaker G: Change discussed here things I want to add that one, I think those are mainly bugs, right? And they're unexpected bugs. So bugs that something got corrupted, either corrupted and stored, but that's a bigger bug, or corrupted like in memory, like you have something and restart fixes it, for example. This is especially the case for state try state root mismatch. And they are unexpected bugs. We don't expect this to happen, but they are there sometimes. So I think it would be hard to test for it because the scenarios can be really wild. And the other thing, I think this is mostly a social problem that we need to just treat those bugs with high priority and try to fix them and communicate them well between cls and Els.
00:27:37.190 - 00:27:53.600, Speaker G: If this happens, that's kind of the thing. I don't think there's much of changes in make sure this communication goes well.
00:27:57.090 - 00:29:13.456, Speaker A: Got it. And to be clear, I assume this means you're in favor of making this explicit in the spec and then treating any issues we see that break this as basically a consensus issue. In terms of severity or potential consensus issue, there's a plus one to this from Teku. Any other el team have thoughts on this or how to approach it to make sure that ideally we don't hit this, but then also that we document or test it. Okay. And yeah, so there's a comment by Gajinder around basically a plus one in yet, as long as we can still have invalid going back to syncing. So maybe we can give a couple more days on the PR.
00:29:13.456 - 00:30:05.090, Speaker A: But assuming nothing else comes up, it seems like making it explicit that you can never go from invalid to valid as part of the spec. I don't know if we want to explicitly call out invalid to syncing, and then for now, unless the testing team comes up with a really unique way to test this, we probably can't add more tests because of how hard it is to create this bug. But if we do see this on devnets or somewhere else, clients should fix this with really high priority. Given it can affect what a validator attests to on main net, does that make sense to everyone?
00:30:10.400 - 00:30:51.640, Speaker F: Sure. I have a question, actually as a wrapping up question in terms of how to phrase this in terms el implementers, is the preference for kind of enumerate all cases, or very specifically address the cases which change, which is to say, I specifically have in mind things with the invalid syncing thing here. So if this PR functionally would not change anything with invalid syncing. It can happen now, it can happen after it's fine. Is the preference to say so explicitly or to leave it out and then have that inferred?
00:31:03.770 - 00:31:33.390, Speaker A: Any thoughts from El folks? Okay, there's one comment saying it's good to have everything explicitly in the spec. Okay, another comment in favor of being explicit. Sorry, Mikhail.
00:31:33.970 - 00:31:55.400, Speaker D: Yeah, I just want to say that we'll work on the exact statement how to spec this out, taking into account that invalid sync and is fine jumping between these two, and we'll just then publish it in some of the channels that it is ready for review.
00:31:56.410 - 00:32:41.820, Speaker A: Awesome. Yeah. Thank you both for bringing this up. Anything else on this? Okay, so next up, I guess I wanted to bring up Gorli. So originally I think we thought we would upgrade Gordy to Denkun before the holidays. Obviously with the CL spec change, that's pushed things back a bit. So I think realistically if we wanted to upgrade Gordy before the holidays, the laylist we could do that is on December 20, which means in like one or two week we need client releases out to do this.
00:32:41.820 - 00:33:35.692, Speaker A: My feeling at this point is this is unlikely. Unless, I don't know if client teams disagree with that, maybe now is a good time to voice it. And okay, if that's the case. So if we're feeling like it's really unlikely that we do get Gordy fork ready to go out in the next week or two, I think we should have a proper announcement about Gordy being shut down. So we've already said it was deprecated, but just to clearly announce to know when is the network literally going to go off. And obviously anyone can validate on Gordy. So it's not a call that client teams make on their own, but client teams do run the vast majority of the validators on the network.
00:33:35.692 - 00:34:45.160, Speaker A: So the day that all the client teams decide to shut their validators down, at the very least it's going to cause a lot of instability on the network. And it's unclear how many other entities or orgs will keep running validators long term there. So I was curious to get a feeling from teams around how long should we keep running teams validators on Gordy once it's upgraded to Denkun? I talked with a couple people ad hoc this week and the rough number that I got was maybe something like three months. And then potentially we do like one month where we start doing slowly shutting down validators to maybe do some controlled chaos testing or stuff like that. But yeah, curious how people feel about that. So there's two comments in the chat saying until we fork Mainnet, which would probably be less than three months, it'd be closer on the order of like one to two months. If that's the case, then I think that raises.
00:34:45.160 - 00:35:10.180, Speaker A: If no one wants to run the nodes for three months after the fork, I think that raises the urgency as well that we should announce this because it might be effectively like three months from now or something, I guess. Yeah. Does anyone think we should do longer than after the magnet fork happens? Because a couple comments in the chat about that.
00:35:13.910 - 00:35:22.022, Speaker D: We know how many infrastructure providers are still using Gorli as a primary. Yeah, that would.
00:35:22.076 - 00:35:23.686, Speaker A: Primary concern, I think, is that we.
00:35:23.708 - 00:35:26.582, Speaker D: Want to give them the controlled chaos option.
00:35:26.636 - 00:35:47.920, Speaker A: I think. Yeah, my personal feeling is like Mainnet is maybe a bit close. Obviously we don't know when we're going to fork Mainnet, but if it happens like a month and a half after Gordy, that feels a bit short. But it's maybe the shortest possible we can do. I think there are. Sorry, go ahead.
00:35:48.450 - 00:36:10.658, Speaker C: My main argument against announcing until we merge Mainnet is that there's no date for Mainnet. I would prefer just a static girly fork plus three months, something like that. It's easier to communicate and it's easier for people to, and that can by default mean that Mainet is already merged at that point. Sorry, already forked.
00:36:10.754 - 00:36:20.250, Speaker A: Yeah. Gary, I think.
00:36:24.700 - 00:36:25.208, Speaker C: So.
00:36:25.294 - 00:36:36.430, Speaker A: Perry, I think is arguing we should gate the Gorli shutdown on the Gorely fork date, but then there's some comments saying we should gate it on the main net fork date. One thing that's nice.
00:36:37.600 - 00:36:38.750, Speaker H: Sorry, go ahead.
00:36:41.600 - 00:36:59.670, Speaker B: Based on the girly fork. Because if something very happens during the Gurley fork, then maybe it's going to take more than to get it fixed before we can even fork Sepolia. Or maybe if we push out a fix on Gurley, it might take weeks or months.
00:37:00.360 - 00:37:01.156, Speaker A: Right.
00:37:01.338 - 00:37:12.810, Speaker B: I think we should assume that everyone is going to run their validators, at least the client teams, until we hit main net plus a few weeks here and there.
00:37:15.660 - 00:37:54.074, Speaker A: Yeah. There's a comment by Anzgar saying maybe we do the later of Gordy plus three months or main net plus one month. I kind of like that. It'll be a weirder thing to explain in the blog post, but I think it's probably the soundest approach. Yeah. Does anyone disagree with that? And then there's another comment also in the chat, know, didn't we fork Sepolia first last time. But we agreed to fork Gordy first this time because it's end of life.
00:37:54.074 - 00:38:48.846, Speaker A: So if we break it, it's less bad. Whereas Sepolia, we want to keep around for a longer. Yeah. Does anyone disagree strongly with Gordy plus three months or Mainnet plus one month? Whatever happens, the latest. And obviously in a case where we have something break on Gordy so badly that it takes us three months to fix, we can also write another blog post saying we're going to extend things, but that feels unlikely. Okay, I'll take this as a yes. And then the other question I had.
00:38:48.846 - 00:38:50.560, Speaker A: So once we hit that point.
00:38:53.650 - 00:38:53.966, Speaker B: Are.
00:38:53.988 - 00:39:30.940, Speaker A: There any specific tests or anything we'd want to run or ways we'd want to handle shutting down the client validators that, I don't know, give us more valuable data? The obvious thing is just triggering inactivity leaks. But is there a period of time over which we'd want to run some tests in a more chaotic mode on Gordy? And should we preannounce that? Some saying, you know, after three months, it's going to move to this chaos testing period for a month, and then we'll shut everything off? Does anyone have strong opinions on that?
00:39:42.810 - 00:40:04.126, Speaker C: Perhaps we can just time point where we said we're stopping support for girly as the time point chaos stuff starts, you can do chaos for roughly a month, and I would advocate for everyone then doing honest exits so that whoever's left over can just continue validating until they feel like it.
00:40:04.308 - 00:40:15.220, Speaker A: Yeah, a month feels sufficient. I assume a month gives us enough time to try out any flow or thing we'd want to try out.
00:40:21.720 - 00:40:25.364, Speaker C: Yeah, I would say so. I can't imagine too many things that we want to try.
00:40:25.482 - 00:40:36.430, Speaker A: Okay, there's a question. How long will the exit take? Months.
00:40:39.360 - 00:40:45.660, Speaker H: Should people who are exiting continue to be good citizens and validate until they successfully exit?
00:40:47.280 - 00:40:52.450, Speaker B: I think we could just do a math. Flashing that would be a lot more fun and a lot more quick.
00:40:53.940 - 00:40:55.440, Speaker A: It's not quicker.
00:40:56.580 - 00:40:58.630, Speaker B: They would still need to exit, right?
00:41:01.480 - 00:41:12.570, Speaker C: Yeah, they would still need to. I would actually just case that it's per validator basis. So if you decide to be good, you can keep it up. If you don't, then network's dead anyway.
00:41:19.640 - 00:42:09.060, Speaker A: Okay, so I think overall this makes sense. So three months after Gordy or one month after Mainnet, whatever comes the latest, then we have one month where we do some testing, and then we assume, at least from the point of view of client teams and EF DevOps, it's no longer maintained or supported. But obviously anyone can choose to run their validators on Gordy if they want. And then the other thing is we won't have it as like a canonical test net for the future hard forks. So after this fork it'll start being out of sync with Mainnet POTUS. Half joking, but if it's really an issue for DevOps, we can always hardcore a higher exit churn on Gurley.
00:42:12.650 - 00:42:14.440, Speaker C: I actually don't hate that.
00:42:15.690 - 00:42:36.094, Speaker A: So meaning that you changed. Does Gorli has specific configs basically that are different from we can hard code more validators exit per block? I know on the el we never wanted to do changes that were just like only applied on testnets. But if you're all fine doing that.
00:42:36.132 - 00:42:38.606, Speaker H: On the CL side, isn't it just.
00:42:38.628 - 00:42:40.000, Speaker C: A peg value though?
00:42:41.330 - 00:43:45.770, Speaker A: Yeah, and I assume this has to go live with the hard fork. Maybe let's I don't know if somebody can make, I assume this is like a literal one line pr where you change the number. If somebody can make that pr and then just post it on the agenda for ACDC next week, I think it'd be good to get like a proper consensus layer discussion on it and it might be a good idea to do it, but we should decide soon. So I think if we can get a pr for this in the next couple of days and then confirm it on ACDC, but I think for everything else, and I guess if anyone has objections to any of this on ACDC next week as well, we can bring it up, but I'll draft the announcement following everything we discussed today, but I won't publish it until the call next week.
00:43:47.740 - 00:43:51.790, Speaker B: But this is not yet implemented in any of the clients, right?
00:43:55.600 - 00:44:39.210, Speaker A: Officially, I was just joking. But every client implements, we take a file with the spec constants, so we just need to change the spec constants, the presets that we're saving for each net and I guess are the presets network specific or is there just minimal and main net? I thought there were two, but is it one per testnet? So they are minimal and Mainnet. However, you can just load anything. The fork id is one of the values. So this is something that we can just change on two networks. Repo okay, so okay, they're config values, not reset values. Got it.
00:44:39.210 - 00:45:32.220, Speaker A: Both of them? Yeah. Look, I think if we want to make this change on the CL and it's easy and teams like it, then we can discuss it. But yeah, we should probably make that decision on the CL call next week and I assume it's a small enough change that if we decided to do it, wouldn't delay anything. Okay, sweet. So let's do that. And then hopefully by the end of next week we can post an announcement about Gordy, just to let people know. Anything else on that.
00:45:32.220 - 00:45:56.340, Speaker A: Okay, in that case, last thing we had on the agenda was a proposal by Micah. Not by Micah, but advertised by Micah for eat multicol. Do you want to give some background on this?
00:45:57.510 - 00:46:44.126, Speaker H: Sure. So the short version of ETH multicolall, basically the same as ETH call, except for you can do multiple transactions in a row that are applied in sequence on top of a shared state. And so the simple example of this is, very commonly you need to do an ERC 20 approval, followed by an ERC 20 transfer, and you can queue up both of them basically, and simulate both of them against head of main net, for example, and see what the outcome is. Whereas right now you can't do that. You have to do the approval, get it onto mainnet, and then do the call afterwards, unless you use specialized tooling. This has come up in multiple times. So a long time ago I wrote a plugin for another mine that I use that does this hard hat and Anvil have similar features called main networking and whatnot.
00:46:44.126 - 00:47:30.886, Speaker H: Sina from the guest team wrote a proposal up in the execution APIs a while back, and then another team built off of his proposal and had another proposal. And so this basically keeps coming up that people want this. And so we finally got together and Nethermind and Geth have implemented the spec that we have for this. And currently we have tests, and we're basically just fixing miscellaneous bugs and coordinating resolving differences between clients. And so we're not quite to the point where we can't make changes to the spec anymore. And so we wanted to run it by the core devs and see if anyone has feedback before we lock in the spec and actually put out and release clients. And so again, this is currently implemented Nethermind and guests.
00:47:30.886 - 00:48:05.446, Speaker H: We'd love to get it implemented in Aragon and Besu as well. The spec is linked in chat by Tim there. The big differences between ETH call and this is besides just the ability to do multiple calls in a row, is the JSON RPC method is named ETH underscore multicall v one. And so the purpose of this is of course versioning, because we've run into problems before where you need to make a small change or something that's backwards incompatible to a JSON RPC endpoint. And so we added the v one there. And this is something that maybe is a little bit controversial. People have other ideas.
00:48:05.446 - 00:48:32.870, Speaker H: We talked a lot about various ways to do versioning of JSON RPC. We don't necessarily have to do it this way. This is the way we all decided was the best, but it's open for discussion. We also added in here eth transfers now show up as ERC 20 logs from address zero. This is because people who are doing accounting on chain. It's very frustrating to have ERC twenty s and so we felt like this is a good place. We can kind of test this out.
00:48:32.870 - 00:49:03.534, Speaker H: And this idea of having e transfers show up within a transaction as logs. And there's a config flag in your JSON RPC request where you can enable or disable this. And I think it's off by default. So we don't confuse users who aren't used to receiving e transfers in their logs. It also allows for block override. So because you can do multiple calls, we also have the concept of these calls are inside of blocks that you can control. So you can set things like the timestamp on the block, the block author, basically any field on the block you can set.
00:49:03.534 - 00:49:43.082, Speaker H: This is particularly useful for things where you want to maybe simulate what happens if I vote for this proposal and then three weeks later I want to see what happens when that proposal is actually executed for like governance contracts and whatnot. And so the idea is that by overriding the block you can set the timestamp of the next block to be two weeks in the future or whatever, and then your EVM is going to execute as if it's two weeks in the future. So this allows you to do better simulation of things like that. It has state overrides. State overrides I believe already exist in ETH call for several clients. So that shouldn't be anything new there, really. It also does allow precompile overrides though, so you can replace a precompile with some EVM code.
00:49:43.082 - 00:50:23.286, Speaker H: This is particularly useful for EC recover because it makes it so you can simulate what happens if you did have an accurate signature for a thing. You can see how the execution would flow. And so you can override the EC recover precompile with some code that just always returns success or whatever. And it's very powerful because it allows you to do things like simulate permit two or permit and ERC 20 contracts. It also ignores the normal validation of no calls from contracts. And I believe Etholl does this as well. So I don't think this is new, but this is important because a few hard forks ago, we disabled the ability to do calls from contracts.
00:50:23.286 - 00:50:58.542, Speaker H: And this makes it kind of re enables that for this ETH multicol context only. Of course not for execution on Mainnet. This allows you to do the simulation of governance contracts, time lock contracts, stuff like that. And the last thing that's a notable difference is we have two different modes. One is validation on, one is validation off, validation off basically just keeps the client's current ETh call validation semantics. So whatever your client does for validation, keep doing that. Whereas the validation on serves two purposes.
00:50:58.542 - 00:51:27.982, Speaker H: One, it's standardized across clients. So ETh call, currently the clients all validate different amounts of things in different ways. Like I think, for example, nethermind just completely ignores your ETH balance and allows you to go negative effectively in terms of gas spending, whereas I believe Geth does not allow you to go negative in the layer. And so you get these weird little idiosyncrasies between clients with Eth call. And so we're trying to use this EtH multicol as an opportunity to try to standardize that. And so this validation mode allows us to do that. It also allows us to have a kind of more strict eth call.
00:51:27.982 - 00:52:11.654, Speaker H: And so when you're trying to simulate something that just before you deploy it, you run it on Mainnet, you want to make sure that this will actually run on Mainnet ahead of time. And with ETH call previously you could run it, but because it wasn't fully validating the transaction, you could still error on Mainnet. And it was very frustrating, so you'd waste gas. And so by having the validation mode on it basically makes it so you are doing exactly like if this was on a mainnet chain, almost all the validation is on and you can look in the spec. There's a couple of things that are not validated. Of course, transaction signatures are not validated in that mode, and I believe the no calls from contracts is also not validated. The ask for the core dev team here is basically just take a look at the spec and please give us feedback.
00:52:11.654 - 00:52:46.242, Speaker H: We would like to get this out into mainline on the various clients sooner rather than later, so people can start using it and apps can start building on it. But we also want to make sure that everybody has an opportunity to give feedback and discuss it. The last thing we want is to deploy a spec that everybody, if they would have been given an opportunity, would have said, oh wait, this is a bad idea, because X or Y. And so really what we just want here is everybody to take a look at the proposed spec. And like I said, there's implementations and get another mind if you want to fiddle around with them. You're also welcome to join us. We have a little weekly call between the various implementers and parties involved.
00:52:46.242 - 00:52:59.980, Speaker H: And so if anyone wants to join, talk on there or feel free to talk to us. Discord or telegram or wherever if you have any. And that's it. If anyone have questions, happy to answer.
00:53:06.050 - 00:53:06.990, Speaker A: Dano.
00:53:08.290 - 00:53:26.950, Speaker I: So I just barely seeing this spec. One feature that I would find useful to some of the work I'm doing is rather than moving a pre compiled call and giving it code, is the ability to say here's a set of inputs and here's a set of outputs you're supposed to give if you get a call to this address. Is that something that there would be space for that in this specification?
00:53:28.330 - 00:54:26.202, Speaker H: We talked about different ways of handling the pre compile contract. Someone have a saxophone in the background? So we've talked about a few different ways to handle the pre compile overrides. One option we talked about is just like doing EC recover, just special case where you can just override EC recover, because that's most commonly think of the rest of them are like math things. There are not a whole lot of reasons to redefine math in your execution. The tricky part I think is with what you're describing, with the kind of here's some inputs, here's some outputs, is that it makes, it's actually kind of hard to get that into JSON RPC, right? So we can do kind of byte arrays. We have a mechanism for that via zero x strings. I think the other solution I would suggest for that, what you're describing is someone can make a contract and even deploy it on main net if they wanted.
00:54:26.202 - 00:54:56.010, Speaker H: And that contract can just have some state. And because we can do state overrides as well, we can give the pre compiled contract in question some state. And so you could basically say override it with my fixed input to output mapping thing. And then you define in your state overrides what the input output mapping is. And so you can just literally put kind of write a mapping in. And so I think there is a way to do what you want. That being said, I am definitely happy to talk more about this, and if you have other ideas on how we can get this in, I'm not against what you're describing.
00:54:56.010 - 00:55:02.120, Speaker H: I do think what we have could satisfy your needs. It just might not be quite as simple as rate as that.
00:55:02.650 - 00:55:35.386, Speaker I: Okay. Because I mean, thinking of using this for like l two s. Let's say there's a system contract called like l two l one bridge and all sorts of stuff that may not be reflected in Ethereum state. So I guess I'll call in to call and I'll put up a proposal. I don't think it would be a byte arrays, I think it'd be an array of structure. We have input and response. But yeah, I'll definitely call in and workshop this because I think there's a huge market for here's a magic value, here's a magic output, and it's completely external to the EVM, what those are, and it's not necessarily derivable from the call values.
00:55:35.578 - 00:56:13.360, Speaker H: Yeah, I definitely think we can make something like that work. I don't know what the exact design is going to look like, but if you reach out to me or any of the other people mentioned in the PR or just comment on the PR, we can definitely have a discussion. I think it's definitely possible to do what you're looking for regardless of how we do it. When are these calls currently? They are Monday morning UTC. I don't know the UTC time checking real quick. Monday around 13:00 UTC is when we currently have them. And we're also all available on various messaging platforms if you want to talk there.
00:56:17.410 - 00:56:21.418, Speaker I: And where's the website with this information? Is it in the log somewhere?
00:56:21.594 - 00:56:35.730, Speaker H: Yeah, I'd say if you scroll up a little bit in chat here, Tim posted the spec PR. I don't think we actually link to the calls in there, but we can do that and feel free to just drop a message to remind us in case we forget.
00:56:38.870 - 00:56:42.520, Speaker I: Yeah, I'm not seeing a link to a call in the spec PR. I'm looking at that.
00:56:42.970 - 00:57:02.926, Speaker H: I don't think it's in there yet. So either message me on discord after and I can get you invited. We actually talked about this just before the meeting about making the calls a little more public previously. They're kind of invite only between the teams implementing and so we do have plans on getting that link out there and if you just subscribe to that PR, it will almost certainly show up.
00:57:02.948 - 00:57:03.680, Speaker G: On it.
00:57:06.510 - 00:57:57.510, Speaker H: Before Monday, I hope. There you go. I just post a link to the calendar, invite any other questions, concerns, thoughts? Sounds like not okay. So just please reach out to us if you have any thoughts or feedback. If we don't hear anything from anybody, then we'll probably move forward with getting this merged into mainline Geth and Nethermind. Once all our inconsistencies and clients are worked out, we're pretty close, unless we get feedback from someone. So please reach out and read the spec when you get a chance.
00:57:59.800 - 00:59:02.610, Speaker A: Thank you. Before we wrap up, so in the chat, there were some more discussion around this idea that POTUS brought up, and I think we've landed on a consensus that it's a bad idea and we should not do it. So instead, simply keeping Gordy configs and presets, as is keeping the Gordy plus three months, mainnet plus one month, and then some chaos testing, but not trying to mess with the amount of validators that can be exited from Gordy per epoch. So I just want to call that out one last time. If anyone feels strongly we should change those config on Gordy. Otherwise, I think we can just call it a day and move forward with the same plan, but no proposed changes for Gordy. So last chance if someone wants to make the case for it.
00:59:02.610 - 00:59:37.810, Speaker A: Okay, doesn't seem like it. So this is everything we had on the agenda. Was there anything else anyone wanted to bring up before we wrap up? Okay, then, yeah. Thank you all for hopping on, and we'll see some of you on Monday's testing call, and then most of you on ACDC next Thursday. Have a good day, everyone. Thanks. Bye.
00:59:37.810 - 00:59:39.230, Speaker A: Thanks. Bye.

00:00:27.855 - 00:00:28.395, Speaker A: Sa.
00:00:53.265 - 00:03:21.765, Speaker B: Sa. It's Sa.
00:03:51.365 - 00:03:52.265, Speaker C: Okay.
00:03:54.525 - 00:03:56.585, Speaker B: Can someone on Zoom talk.
00:03:58.365 - 00:03:58.701, Speaker C: Like.
00:03:58.733 - 00:04:13.825, Speaker B: Someone who's not me? Yeah. Okay. Hello, Is this coming through to the stream? I. I'm seeing something suggesting that, like, everyone else's audio is not streaming.
00:04:17.175 - 00:04:17.679, Speaker C: And.
00:04:17.767 - 00:04:19.675, Speaker B: I have no way to change that.
00:04:26.135 - 00:04:27.115, Speaker A: Let's see.
00:04:29.055 - 00:04:30.195, Speaker B: I'll try this.
00:04:33.375 - 00:04:33.911, Speaker A: Okay.
00:04:33.983 - 00:04:38.955, Speaker B: Christine says yes. Can someone who's not me just say something again?
00:04:40.265 - 00:04:41.245, Speaker D: Good morning.
00:04:41.945 - 00:05:14.505, Speaker B: Yeah, I don't know. Okay, we'll go. So cool. Hey everyone, this is consensus layer call 135. I'll grab the issue here for the agenda and we'll just go ahead and get started. So first off, there's just a few announcements. The first one is about kurtosis.
00:05:14.505 - 00:05:18.229, Speaker B: If Barnabas is on the call, I think he can give us some more details.
00:05:18.277 - 00:05:18.865, Speaker D: There.
00:05:20.845 - 00:05:22.585, Speaker A: I thought I saw him somewhere.
00:05:23.885 - 00:06:10.250, Speaker E: Yeah, I can. So we wanted to just announce that we were taking a more active maintainer role in the Kurtosis ecosystem, slash Ethereum package in general. And one of the steps is that we've done a migration from for the Ethereum package itself. So it's moving from Kurtosis Tech Organization to Eth Panda Ops. You can find the redirect URL and a few other instructions on what might break in Twitter or in the Kurtosis discord. But if you wish to continue using the old setup, you can always clone the last release and continue using that. But in case you want to keep up with future changes, then Please update your URLs and target the latest release onwards.
00:06:10.250 - 00:06:14.855, Speaker E: So 4.0 onwards would be maintained mainly by Eth Panda Ops.
00:06:19.115 - 00:06:33.385, Speaker B: Okay, great. Next up, Tim, I think had an announcement around adding some nuance to CFI in the IP process. Tim, if you just wanted to give a quick shout out.
00:06:34.645 - 00:06:40.305, Speaker F: Yeah, so we discussed this on the last acde, but there was a proposal.
00:06:40.965 - 00:06:43.425, Speaker E: That came out of Kenya that was.
00:06:43.845 - 00:06:49.725, Speaker F: To basically improve how it defines CFI and also add a formal way for.
00:06:49.805 - 00:07:00.867, Speaker B: The community to propose the IPs to hard forks and then just rename included the scheduled for inclusion before stuff ships because we sometimes remove some stuff that's.
00:07:00.971 - 00:07:02.375, Speaker C: Been marked as included.
00:07:02.835 - 00:07:06.995, Speaker F: So if people want to, yeah, review this Async, that'd be great.
00:07:07.035 - 00:07:10.475, Speaker B: And then hopefully by the next ACD.
00:07:10.555 - 00:07:17.055, Speaker E: In like about a week, we can just move forward with some version of this as official.
00:07:20.795 - 00:07:21.895, Speaker A: Cool, thanks.
00:07:24.485 - 00:08:32.395, Speaker B: So next up is Electra, and I think the next step that is on everyone's mind is going to be DevNet1. There's a spec floating around for the el set of EIPs. I don't have that handy right now, but we can discuss the CL set of specs and that's generally going to be the Alpha 3 release. So I just dropped a link in the chat here and I think it's pretty ready to go. Shout out to Xiaowei for assembling all this. There was one open question, I think, on this EI or, sorry, this PR 3768. Before we get into that, is there anything else around DevNet one that people would like to discuss as it's more like higher level, or should we turn to just these few open questions for the specs? Okay, so.
00:08:32.395 - 00:08:35.023, Speaker B: Right, let me grab the link.
00:08:35.159 - 00:08:35.655, Speaker A: Let's see.
00:08:35.695 - 00:08:50.865, Speaker B: It's three. Yeah. This one. Okay. So three, seven, eight, six. This PR is really just changing the layout of the fields in the new attestation type that we have. And it looks pretty simple.
00:08:50.865 - 00:09:24.645, Speaker B: There's some implications just around how SSC works and how these things are laid out. So that was kind of, I think the original motivation was to not break essentially these indices that come out of the Merkelization. Yeah. And so this PR suggests moving this field basically to the end. The way it works is like appending things is much nicer than putting stuff in the middle in terms of the layouts. Yeah. So it looks like there's been quite a few approvals on the pr.
00:09:24.645 - 00:09:58.967, Speaker B: Does anyone have any comments about this? I think I do. At least just because we do have this pattern that the signature of a thing comes after everything else and this kind of breaks the pattern. So it feels at least aesthetically wrong to me. But yeah, no one else has really chimed in otherwise. So if there are any comments here, now would be the time to walk through them. Otherwise, I suppose we can just go ahead and merge those. Yeah.
00:09:58.967 - 00:09:59.795, Speaker B: Kamin.
00:10:00.975 - 00:10:17.113, Speaker C: Yeah, I just wanted to note. So if we do end up approving like a stable container eips that if, like in the future, like stable containers kind of require us to append only. So in this case, this is not.
00:10:17.129 - 00:10:18.713, Speaker B: A stable container, it's just a normal container.
00:10:18.769 - 00:10:21.897, Speaker C: But that's just something to keep in.
00:10:21.921 - 00:10:24.361, Speaker E: Mind that, like, even if it's something.
00:10:24.393 - 00:10:25.845, Speaker C: That has a signature.
00:10:27.745 - 00:10:33.765, Speaker E: Kind of by the rules of the EIP that we're setting forward, you would. We would still be appending in that case.
00:10:35.635 - 00:10:52.335, Speaker B: Okay. Yeah, that's good to know. Yeah. Anyone else have any feedback on this pr? It sounds like I might be in the minority on the field ordering, so I will defer to everyone else in that case.
00:10:52.955 - 00:11:40.625, Speaker D: Like you mentioned the pattern of signature last I'm not sure if that's still the case. Like the way how it's done now is that there is this envelope that has like the payload and the signature and it's just these two things combined and the only thing that keeps changing is the payload. Right. So it's a bit weird in the attestation because the signature is actually not signing over all the fields. It's only signing over the attestation data, but it's not signing over aggregation bids and committee bids. So I'm just wondering if this pattern that you mentioned, like, where is it actually being used? Like the signature loss?
00:11:43.165 - 00:12:35.219, Speaker B: Like everywhere. Like, is there an SS type we have where you don't have like a bunch of stuff? And then the signature, like, I don't think there's any. Like, I guess that's my point here is like this would be breaking the pattern and it is arguably just aesthetic. So again, you know, this is not the end of the world, but it definitely sticks out to me. Casey was asking why did we put the signature last originally? And I think it was again more just sort of like an aesthetic thing. Justin has a comment. Typically rlp, you need to read the data that is signed over, right? Yeah.
00:12:35.219 - 00:13:03.895, Speaker B: So, yeah, you could. If you're doing some like streaming SOC thing, then yeah, you could kind of argue that it's helpful for that. Yeah, I mean, I think it's really just a pattern that we kind of settled on and I also don't think we've broken yet. But yeah, that being said, I think we should ship Devnet one, so unless there's any other objections, we can go ahead and merge this after the call.
00:13:10.075 - 00:13:12.555, Speaker F: Sorry, I don't know how to raise.
00:13:12.595 - 00:13:15.931, Speaker G: My hand in zoom, but I think.
00:13:15.963 - 00:13:17.755, Speaker F: This is not something that we can.
00:13:17.795 - 00:13:32.891, Speaker G: Do without breaking things. But what if we had attestation data, signature, aggregation bits and committee bits. That way signature would come after the stuff we are signing and then we'll.
00:13:32.923 - 00:13:34.255, Speaker E: Have the rest of things.
00:13:36.755 - 00:14:22.655, Speaker D: It would also be fine. But we should only do that if we adopt the stable container. Because right now, like aggregation bits is generalized index 4, data is 5, signature is 6 and committee bits is 7. So 4, 5 and 6, like this PR, what it achieves is that 4, 5 and 6 stay the same. So aggregation bits is still 4, data is still 5, signature is still 6. If we adopt a stable container, then these indices break anyway. So we can use that as an additional reordering.
00:14:22.655 - 00:15:01.475, Speaker D: But yeah, I mean, it would make sense to put the aggregation bits after the signature because they are not being signed over anyway. It's safe to say that we can go for it and then if stable container become real thing, we can think about reordering the last time. Yes. Like if we adopt stable container we can reorder everything because like the proofs break. Yeah, okay.
00:15:12.255 - 00:15:55.339, Speaker B: Okay. Sounds like at least on the call we have support for the PR as is. So yeah, let's ship it. Okay. I think that was the big thing left on the specs release. Is there anything else that we should discuss right now? Otherwise the plan I think is to get release out later today or tomorrow and have that be deadnet one. I think there was something in the chat.
00:15:55.339 - 00:16:01.395, Speaker B: Okay, Perry, link something here in the execution APIs. Let's see.
00:16:01.619 - 00:16:09.218, Speaker D: Okay, maybe can someone from the EL.
00:16:09.441 - 00:17:15.925, Speaker B: Speak to EL consolidations being ready to go for DevNet1? No one knows. I think that Mikael is. Yeah, either McKayla or LightClient working on that and I think they're both out this week, so. Okay, we can follow up on that one after the call and otherwise. Yeah, I think we are in a good place for Devnet one with CL specs. Next up, I wanted to touch on timing if any CL team is here. Have you started implementation on this release? Do you have any sense of done that one timing? I think it'd be helpful for everyone to kind of start coordinating on what time we could see the devnet up.
00:17:22.225 - 00:18:03.395, Speaker D: Yeah, I can speak for tecu. We are okay. We are waiting for the attestation field to the end to be merged but we have the PR already prepared and ready for merge and the other thing that we are waiting for is this 3783 we haven't started doing anything there but it's supposed to be not that. So as soon as we have that merged, I think we are kind of safe to having clients ready in days.
00:18:09.305 - 00:18:25.685, Speaker H: For loadstack. We will basically integrate consolidations as the spec gets finalized and then I think with small amount of changes we should be ready for Devnet 1.
00:18:34.635 - 00:18:42.775, Speaker C: For Lighthouse. I haven't really gone through the new spec changes, but I think we should be in good shape for Devnet one.
00:18:46.875 - 00:19:02.505, Speaker B: Right. So is everyone thinking like weeks or mini weeks or. We don't know. It's fine if we don't know that. People have been asking.
00:19:06.085 - 00:19:06.725, Speaker D: I mean if.
00:19:06.765 - 00:19:11.145, Speaker H: Spec is sort of finalized then by end of next week.
00:19:14.885 - 00:19:15.705, Speaker E: Okay.
00:19:18.205 - 00:19:18.597, Speaker B: Yeah.
00:19:18.621 - 00:19:37.205, Speaker A: So from Grandinia side we also didn't look for the latest changes in the spec and we're actually waiting until it's fully finalized, but the rough estimate, something like a week or two for us. Week or two after the spec is finalized.
00:19:44.305 - 00:20:05.475, Speaker D: I would like to have a reference test to run against consolidation stuff. So code is there. But yeah, once we got some reference test to run everything over, we get more confident. But yeah, we are kind of in the next week. Ish.
00:20:08.535 - 00:20:15.635, Speaker B: Okay, great. James, I think I saw you on mute. I don't know if you're going to give a Prism update.
00:20:17.895 - 00:20:24.495, Speaker E: Yeah, we have a couple PR still waiting. I think just like everyone else, probably.
00:20:24.575 - 00:20:31.285, Speaker C: Like a week or two, we'll need to reform a new dev dev Net one branch.
00:20:38.785 - 00:20:43.161, Speaker B: Cool. And I think that leaves Nimbus. I don't know if anyone from Nimbus.
00:20:43.193 - 00:20:44.353, Speaker A: Is on the call.
00:20:44.529 - 00:20:48.057, Speaker B: Oh, Dustin. Hey. Sure.
00:20:48.121 - 00:20:50.725, Speaker G: Yeah, we haven't looked at this.
00:20:52.475 - 00:20:52.859, Speaker B: In.
00:20:52.907 - 00:20:55.075, Speaker G: Totality, let's say, in terms of dead.
00:20:55.115 - 00:21:02.491, Speaker E: Net 1 readiness and a lot of detail. That said, I mean I didn't see.
00:21:02.523 - 00:21:05.095, Speaker G: Anything too alarming in it.
00:21:06.795 - 00:21:07.739, Speaker E: But what.
00:21:07.747 - 00:21:14.895, Speaker G: I would certainly echo is I would want the tests, the consensus back tests in place.
00:21:15.275 - 00:21:31.224, Speaker B: But aside from that. Okay, cool. Right. So specs are on the way, hopefully in the next couple days. And then it sounds like people are thinking small number of weeks for DevNet1.
00:21:31.465 - 00:21:36.040, Speaker A: So that's super cool.
00:21:36.281 - 00:21:49.805, Speaker H: I think for DevNet1 el implementing 7702 would be sort of the key milestone that would need to be achieved.
00:21:55.425 - 00:21:57.325, Speaker B: Sorry, was it? I didn't miss that.
00:21:59.505 - 00:22:04.925, Speaker H: I think for Devnet run we want 7702 on the El side, Right?
00:22:08.425 - 00:22:19.015, Speaker B: Yes. This is the. Yeah, this is the account obstruction 1. I don't know if we landed on that being in.
00:22:19.955 - 00:22:39.545, Speaker E: Yeah, yeah we did. That was the main change between 0 and 1. And I think Red said they weren't ready with it yet, but potentially next week and Bezu said they'd have it this week. We haven't gotten updates from the other EL teams yet, but we will follow up and keep an eye out in the interrupt channel.
00:22:43.925 - 00:23:13.263, Speaker B: Cool. Okay, so it sounds like we have a pretty good plan for devnet one. Anything else there? Otherwise, I think we'll move to pure dos. Cool. So. Right. Peer dos.
00:23:13.263 - 00:24:21.565, Speaker B: So I kind of just wanted to reiterate the thinking around having the separate activation epoch to kick us off. The way I was looking at it is that basically there would be this separate epoch to activate the feature set. And the idea is that we could theoretically imagine having Pector ship with some delayed peer dos within sort of the same fork as Spectra. That sounds really complicated and I really don't think we should like if we think peer DOS is ready to do that, then we should just ship it with the fork, right? So I think the plan was generally to say, okay, either this activation epoch will be equal to Petra or it won't be, meaning it would be delayed until the next hard fork. That then means that it gives us room to implement Peer DOS as part of petra, sort of on top of Pectra. And then what do we gain? What we gain not having to have this separate hard fork with all the code infrastructure to implement that as we go and develop these things in parallel. So that at least is how I was thinking about it.
00:24:21.565 - 00:24:51.775, Speaker B: I don't know if anyone has had time since the last CL call to like think about this some more or if there are any issues kind of with that approach, but that's how I was seeing it. Barnabas says developing in parallel doesn't sound like a thing if it's built on top of picture. Why not?
00:24:54.515 - 00:25:22.005, Speaker H: I think in the PDAS breakout call we decided that we will continue doing devnet one of peas on top of dab and at a much later state we'll basically see whether we want to, we want to revise it on top of Lecra, but I think the plan for now is to just continue doing devnets on top of Danup.
00:25:26.905 - 00:25:48.559, Speaker F: You had a agreement on like how this fork should actually be activated though and every team seemed to have a different opinion on this. So it would be very good to make an actual decision whether it's going to be a hard fork or whether it's going to be a CL only fork.
00:25:48.727 - 00:25:49.515, Speaker A: Basically.
00:25:50.615 - 00:26:41.105, Speaker H: I think on this, following the discussion that has happened on R and D discord, basically it doesn't matter whether it's hard for or not or if it's for activation epoch as long as the fork version doesn't change. So for now clients may try to may implement it anyway they want if they can sort of guarantee that peer does fork version is same as whatever was on the previous fork. So basically I think we are following following the approach of activation in pork only. But yeah, the clients who still want to use their, their hard fork machinery can do so by keeping the four question same.
00:26:44.245 - 00:27:02.715, Speaker C: So did you say. Well, I, I don't see much of a point in building it on top of Deneb though. You, you said that's what like I don't, I, I don't know yet. Yeah, but there's no plans as far as I can tell to push pure DAS before Electra.
00:27:04.295 - 00:27:07.475, Speaker B: Yeah. What was the rationale there? I could make the breakout.
00:27:07.775 - 00:27:28.479, Speaker D: I guess it's just because they don't want to be following the spec changes of Electra, having more stable spec that they can focus on beer Das and when Electra spec solidifies more then they can rebase on top of Electra. That's my impression.
00:27:28.647 - 00:27:50.955, Speaker H: Yes, it pretty much orthogonal to Electra and I don't think basically basing on top of Electra is going to be a challenge at any given point. But yes, rather than spending time on the cycles now and sort of getting entangled in the Electra development, I think we can keep peer as sort of orthogonal from Electra as of now.
00:27:54.185 - 00:28:20.035, Speaker E: Kind of mirroring that point from testing as well. For example, if we do merge the two branches and we're testing pure dust specifically and there's a bug in Petra, we might actually trigger the bug purely because the branches are changed and we're going to have to spend cycles figuring out if it was a pectoral bug or if it was a peer DAS bug as opposed to if it was starting from Denab, then at least then we know with most certainty that Piradas bug.
00:28:22.935 - 00:29:05.335, Speaker B: Right, okay. I mean, yeah, it sounds like the trade off here is like either we have like sort of more upfront development complexity by putting it on top of Petra, or yeah, we can kind of focus more exclusively on Parados by living on top of Deneb. With the implication being that sometime down the road we will have to rebase on top of Vectra. That sounds okay to me for now. I mean it. Yeah, I, I guess the tricky thing would be if we're like six months from now and we're still on top of the knob and then it's like okay, are we going to ship this or not? But also it doesn't seem like that's a huge issue.
00:29:06.075 - 00:29:15.358, Speaker H: Maybe DevNet 5 onwards we can sort of reverse on top of Spectra DefNet 5 of Spectra.
00:29:15.470 - 00:29:20.405, Speaker B: I'm assuming the DevNets will go till DevNet 10.
00:29:20.517 - 00:29:22.087, Speaker E: Okay, why 5?
00:29:22.199 - 00:29:23.265, Speaker F: Why 10?
00:29:24.405 - 00:29:28.901, Speaker B: Yeah, I don't know if we can put numbers to it, but I mean.
00:29:28.973 - 00:29:39.715, Speaker H: Just from the past experience that the amount of testing cycles that we give to a particular fork, and assuming Pekra has so much stuff going in, so just a hunch.
00:29:41.735 - 00:29:55.715, Speaker E: Maybe a good time is to say once we are sure what's going in Petra and we sort of have a feeling that things are stabilizing, that's when we can talk about when the fork is going to be shipped and when we start merging stuff.
00:29:59.495 - 00:30:13.785, Speaker B: Yeah, yeah. I mean if everyone Thinks it's a blur. I think that sounds like a good path forward for now just having pure DOS on top of genev and then you know, maybe even as soon as like a month or two from now we can revisit the rebase.
00:30:24.765 - 00:30:40.195, Speaker F: How are the client teams feeling about Pure Desk by the way? Pure Desk Definite one. When could we launch that and would we need any spec change or is everyone happy to keep all the same flags as it is set right now.
00:30:45.215 - 00:30:46.655, Speaker E: For Devnet one?
00:30:46.815 - 00:30:48.639, Speaker B: What are you planning to test?
00:30:48.767 - 00:30:50.195, Speaker A: Is it the same stuff?
00:30:56.825 - 00:31:04.445, Speaker F: Yep, I guess so. There hasn't been many peer desk PRs to the consensus packet as far as I can see.
00:31:06.345 - 00:31:12.257, Speaker E: Okay. Yeah I think it should be good on our end. So we would definitely like to test.
00:31:12.321 - 00:31:15.801, Speaker B: Reconstruction in general to see how it.
00:31:15.833 - 00:31:17.205, Speaker A: Works across the network.
00:31:20.625 - 00:31:21.525, Speaker C: Taurus.
00:31:23.275 - 00:32:10.075, Speaker A: Yeah, I would suggest to think about Peerdes DevNet1 when we have a quite stable network which doesn't split in cortosis setup. So I think it's still not there or there is some cortosis config that has like three or four clients that can keep on the same chain for a long time. What is the current state of Firidas? Can somebody comment on that? Because in the interoper we ended up with a network that was splitted to. I mean every point was on sound for as far as I remember.
00:32:14.745 - 00:33:24.755, Speaker H: I think in my assessment nodes need to make sure that they are consistently considering the data columns that they are supposed to even if they restart. And that was one of the big reason, big reasons. Basically Lodestar was not able to sync devnet0. I mean it was able to sync for a few epochs but then it will hit into this particular problem that the columns, the nodes that should be custodian, they didn't have it and so most likely it could also be the reason for the split. Otherwise I don't really see. I mean the fork choice was simple, that the availability is the same as that we have on Blob. So ideally there should not be any other reason for the fork split in the nodes but I think this could be the reason for it and if sort of we can make sure and have the stability around this then I think we should be ready for Devnet one.
00:33:26.895 - 00:33:52.365, Speaker A: Yeah but we can test that in cortosis. I mean it should be possible to make a cortosis config that that has a few clients with the issues that you mentioned fixed and if the network is stable there then I think we can think about the DevNet one peer does that's my opinion.
00:33:53.065 - 00:34:01.583, Speaker E: So Interop I think the Devnet images that were running, they were all images which is why client split. So we had a few bugs on.
00:34:01.599 - 00:34:03.383, Speaker A: Our end that we fixed, but it.
00:34:03.399 - 00:34:12.835, Speaker E: Wasn'T deployed to DevNet 2. But yeah, before DevNet 1 we can run a kurtosis setup with all the clients to see how it works.
00:34:23.295 - 00:34:37.285, Speaker F: The client teams just put their latest branch. Your peer does branch in Interop so we have a good idea of like which branches we should be using on Devnet one and on Kurt assist.
00:34:42.545 - 00:34:42.833, Speaker B: And.
00:34:42.849 - 00:34:55.295, Speaker F: What is the status on peer Desk with Loadstar because they didn't participate in the previous net they have something ready.
00:34:56.155 - 00:34:57.415, Speaker H: Yeah, I'll share.
00:35:16.635 - 00:35:31.125, Speaker B: Okay, so should we. Is it worth thinking about timelines for a pure dose net one then like do we want to try to say okay aim for something in like a month just to give people like sort of a deadline to work towards.
00:35:33.585 - 00:35:47.575, Speaker C: Not that I want to accelerate things, but it seemed like people felt like two weeks as a gut feeling was all right. Could go three if you want to give more time or whatever. I mean a month it should certainly be fine but depends on how fast we want to go.
00:35:47.995 - 00:35:52.099, Speaker B: I mean yeah, sooner's better but I'm not sure where people are.
00:35:52.147 - 00:35:59.615, Speaker C: I would, I think most people felt like two weeks didn't seem crazy, but correct me if I'm wrong.
00:36:02.035 - 00:36:05.015, Speaker H: Yeah, two weeks end of the month. I mean that sounds fine.
00:36:08.715 - 00:36:19.945, Speaker B: Okay, so let's aim for that and then yeah we can run a devnet and I think that'll give us a lot more clarity on the next steps. Sound good everyone?
00:36:23.005 - 00:37:16.955, Speaker A: One more suggestion I would like to do is maybe Barnabas or someone else from DevOps teams could. Or maybe this already done could find at least two peers of clients that interops correctly so. So this would help for the rest of the teams to you know, to take this, these reference to clients and interrupt with those two clients that almost sure that are correctly working. So maybe it's already known that there are two clients that interoper very stably. Is it the case or it's unknown that there are two pairs?
00:37:17.655 - 00:37:32.675, Speaker F: We haven't been testing lately because there has been just a development. So as soon as at least one of the clients say that their branch is ready to go then we can start testing but without anyone saying that they are ready there is no point.
00:37:33.175 - 00:37:52.571, Speaker A: Yeah but it's kind of chicken egg because for example for us we really would like to have two clients working together so we can join it and it could be that the Other teams feel quite similar or at least some.
00:37:52.603 - 00:37:56.815, Speaker F: Teams has a working implementation, you think?
00:37:58.435 - 00:38:41.315, Speaker A: No, I mean the idea would be if there are two teams that are quite confident that they are. They are quite done with peer das. I mean, given that it's still early stage, but that they believe that they should have everything to interrupt, then let's get these two teams to make cortosis setup that is very stable so the rest of them could join. That would be my proposal. But do we have these teams that are very confident about their peer DOS implementation?
00:38:45.535 - 00:38:56.275, Speaker C: So I'd have to check with Jimmy because he's been doing most of the peer DOS work in Dapline, but I think Lighthouse has a pretty solid implementation if I'm following things correctly.
00:38:57.815 - 00:39:04.305, Speaker A: Okay, is there any. Is there a second one that feels similarly.
00:39:05.325 - 00:39:08.029, Speaker E: Yeah, yeah, yeah.
00:39:08.077 - 00:39:10.745, Speaker B: Maneuver. Okay. Yep.
00:39:11.805 - 00:39:14.205, Speaker F: And say for example, we are quite.
00:39:14.245 - 00:39:29.405, Speaker A: Confident about peerless as well. Okay. So Varna was just take a Prism and Lighthouse and try to make a stable network. And if it happens then I think soon we will have a DevNet one.
00:39:35.305 - 00:40:03.305, Speaker H: One thing I want to know that the PR regarding specifying the blob count through on the FC params and the associated change for it on. On the EL block header for adding block gas limit that is part of PETRA or is that part of I appear as. And I mean I guess it will be part of pectoral. This is not really a fork.
00:40:10.045 - 00:40:11.545, Speaker B: Sorry, what were you asking about.
00:40:13.605 - 00:40:13.965, Speaker D: So.
00:40:14.005 - 00:40:30.107, Speaker H: Up regarding adding max blobs. Max blobs per block to the FCU pattern. So is that PR part of Pekra or is that PR part of peer dos?
00:40:30.291 - 00:41:09.735, Speaker B: Yeah, so that was next on the agenda. Do we feel good about devnet1 just in terms of development timelines? I mean it sounds like people are on top of it. When clients are ready, we'll start testing soon and then we can move to the blob count conversation. But do we all feel pretty good with the DevNet One Plan for Paradise? Okay, I got at least one thumbs up. I got two. I'll take it. Let's see here.
00:41:09.735 - 00:41:16.951, Speaker B: So, well, okay, there was actually one quick thing before we get to the blob count itself. Tim.
00:41:17.143 - 00:41:17.943, Speaker A: Let's see.
00:41:18.039 - 00:41:36.035, Speaker B: Tim has a draft PR here for including pure DOS into Petra. And yeah, this kind of starts to all touch on the same thing. Tim, did you want to say a few words about this? Because I think there was some novelty around the PR and our usual EIP process.
00:41:38.335 - 00:41:40.455, Speaker E: Sure. So yeah, I had the.
00:41:40.575 - 00:41:41.543, Speaker F: The reason I kept that as a.
00:41:41.559 - 00:41:44.135, Speaker C: Draft is it Just felt a bit like.
00:41:44.175 - 00:41:49.847, Speaker F: So peer to Ask, as expected, is currently a networking change and not like a core protocol change, but at the.
00:41:49.871 - 00:41:52.151, Speaker B: Same time, it's literally the biggest feature.
00:41:52.223 - 00:41:54.263, Speaker F: That we have going into picture, so.
00:41:54.279 - 00:41:56.155, Speaker B: It feels like we should include it.
00:41:56.895 - 00:42:00.391, Speaker F: And then, you know, the activation stuff.
00:42:00.423 - 00:42:02.487, Speaker B: We can add to the meta EIP later.
00:42:02.551 - 00:42:03.567, Speaker C: But I guess.
00:42:03.631 - 00:42:06.479, Speaker F: Anyone think we should not list it.
00:42:06.567 - 00:42:08.367, Speaker B: In the meta eip and if not.
00:42:08.391 - 00:42:09.875, Speaker E: I'll just merge this now.
00:42:12.705 - 00:43:01.565, Speaker B: I think we should because it just signals that we're serious about this and we are. Okay, cool. Let me go check. Okay. Yeah, so I think we kind of covered the peer dos things themselves. And then the next question then is like, yeah, somewhat, how do we actually ship this? Do we increase the blob count? How does it all roll out and all these things? So Ginger was just talking about a pr. I had to suggest a way to have the CL drive the blog count.
00:43:01.565 - 00:43:50.525, Speaker B: I don't know if you both had a chance to look at it, but the motivation was essentially to uncouple. So right now there's basically a hard coded constant both on CL&EL for the blob count. This couples together the layers, and so it kind of makes things a little less flexible in terms of us having these shipping timeline discussions and fork scoping and all of this. So it would be kind of nice if we can uncouple them. You could then theoretically have a CL only fork where if we want to change the blob count independently, we wouldn't need to update all of the execution clients, but just the CL plans. So I think there's a good reason, there's good motivation for doing this. And the question is just how would you do it? The suggestion that I have in the PR right now is basically just to send it over with every payload.
00:43:50.525 - 00:44:43.505, Speaker B: So whether you're validating a payload or building a payload, the CL would just send it as part of the parameters that already exist to tell the el, hey, for this block, there can only be this many blobs. The catch here now is that this kind of breaks optimistic sync because the EL can be in regimes where it basically can't talk to the CL synchronously like this, and then it might not know what the blog count should be. So, yeah, the question then is like, what do we do about this? And yeah, I think gender, maybe. Terrence, there's some conversation on the discord around this, but the suggestion was basically to actually include the blob count and some representation in the EL header, which does. I Think nicely. Solve all these issues. Yeah.
00:44:43.505 - 00:44:47.645, Speaker B: Has anyone had a chance to look at this PR or think any more about this?
00:44:55.075 - 00:45:31.715, Speaker F: I mean, I think not knowing whether it's valid for Optimistic Sync isn't a problem per se. Like you can simply accept like whatever you're told it is and then like verify it once you get the beacon block. I think the only problem is that you need to know everything in order to be able to compute the blob gas. Like I think that is, that is the problem with that approach. So as long as you can do that, I think like it doesn't matter. Like you don't have to care about Optimistic Sync.
00:45:34.015 - 00:45:46.465, Speaker B: Right. But then you like that suggestion that it doesn't have to go in the header, which is. I think at least it's a different type of change, which is fine, but that just needs to be something that then all the execution clients.
00:45:49.445 - 00:46:12.547, Speaker F: Yeah, I tried to think about that as well and it is like a conundrum how to do that part. I mean the optimal way would be to change the computation. I think it's probably a mistake that block, like the gas price computation happens in the el. Like that should have been in the cl. But yeah, that's more difficult to change now.
00:46:12.571 - 00:46:25.335, Speaker B: I guess we could, but I think you didn't have the same issue. Right. It's just more about communicating the information at the right time. And the blog count and the blob gas are kind of the same thing.
00:46:27.155 - 00:46:47.321, Speaker F: I mean, one thing you have to remember as well is if you actually want to change the blob count, there is a computation that has to happen to update the excess gas as well. Right? I guess that works automatically if you do.
00:46:47.353 - 00:46:47.737, Speaker H: Yeah.
00:46:47.841 - 00:47:02.735, Speaker F: Maybe the easiest. Is that what you suggest? Yeah, like adding the blob count would solve that because then you can just keep track of the excess gas. Except that the unit changes.
00:47:03.115 - 00:47:03.619, Speaker D: Right.
00:47:03.707 - 00:47:49.965, Speaker F: Because like when you have more blobs, the constant you want to divide by changes. This is actually like yeah, this is not easy. This is why it would be easier to have it in the cl because then it would be part of the. Part of the fork. Like in the fork you would just recompute or recompute all the constants. Whereas if you have it in the El, then there's like a some weird backward math to figure out what the right excess gas and what the right ERP1559 devices.
00:47:52.635 - 00:47:57.415, Speaker B: And this is just at the fork boundary when we change the blob count. Is that what you're referring to?
00:47:59.515 - 00:48:38.273, Speaker F: So there's basically. Right now the gas cost is computed as an exponential of the excess gas divided by this blob gas fee constant. I can't remember what it's called. And whenever you change the number of blobs, you have to adjust both of these numbers as well because they will be like first the constant changes. But that at the same time means that the old excess gas is no longer in the right units either because it was measured in terms of the old constant. Essentially.
00:48:38.409 - 00:48:40.525, Speaker B: Right. Yeah. Okay, that makes sense.
00:48:42.025 - 00:49:00.969, Speaker F: So the better way would be. Yeah, if there is an easy way. I'll have a look at this later. If there isn't is a way to transform the whole thing so that all the gas computations happen in the CEO then this is actually more elegant because then it's just part of the fork boundary.
00:49:01.137 - 00:49:01.441, Speaker B: Right.
00:49:01.473 - 00:49:04.565, Speaker F: Which we'll have anyway. As far as I understand for.
00:49:06.945 - 00:49:07.233, Speaker B: That.
00:49:07.249 - 00:49:24.799, Speaker F: We have like a blob cutting where in the el there's actually no such thing because for the el we wanted thought to be a fork. Yeah. So this could be easier. Otherwise we can figure out another way in which the CL messages the EL or the change in those constants.
00:49:24.847 - 00:49:25.435, Speaker B: But.
00:49:27.975 - 00:49:29.435, Speaker F: Yeah, it doesn't need to be.
00:49:32.615 - 00:49:34.395, Speaker B: Right. Asgard.
00:49:36.015 - 00:50:06.633, Speaker E: Yeah, just to mention, if we want to keep it in the El, then one way to get rid of that annoying discontinuity where basically you need a thing where you basically need to make an update to that excess gas at the fourth point you can. You can basically just accept that you will have a discontinuity in the base fee. So basically if you say you double the blob count, then the. Basically your base you would have. But there's only. It's like a five to ten minute period until you're basically you just for. For a few minutes you have.
00:50:06.633 - 00:50:32.105, Speaker E: You basically have cheaper blobs and then you're back to the same price. These adjustments are very quick and it's a little inelegant, but that would turn those constants back into pure functions from the count Bob count. So if you communicate the count Bob count then you can compute this adjustment ratio. You just cannot compute the. You just can't detect that. You would have to do this one time update to the excess guys.
00:50:39.095 - 00:50:39.719, Speaker B: The.
00:50:39.847 - 00:50:47.035, Speaker F: Constant like the one in the exponential. But I assume you just want to make that a function of the blob count.
00:50:49.535 - 00:50:57.835, Speaker E: Yeah, exactly. That one can be a function of the blob count because you don't have to detect the fork itself. It's just basically always Some constant ratio.
00:50:58.535 - 00:50:59.275, Speaker A: Right.
00:51:00.135 - 00:51:11.163, Speaker F: That is, I mean that's probably the simplest solution. The question is, is it the most, like the smallest, like, is it the most elegant solution?
00:51:11.219 - 00:51:59.315, Speaker B: I guess. Okay, so there's two things here. Like we kind of started talking about just how to communicate this generally. If we took the data away from the EL and then having to go from CL back to the el and then also now we're talking about, you know, if we do actually change the blob count, there is going to be this discontinuity with how we compute the ACT blob base fee. And that needs some thought as well. So yeah, what I'm hearing is that this is not that simple to change, but I do think it's worth changing. So yeah, I would suggest people take a look at the PR and then yeah, this has all been good discussion and from there we can try to figure out another path forward.
00:51:59.315 - 00:52:59.305, Speaker B: If anyone wants to take another look at. Yeah, maybe even the more invasive change to move more of the computations of things into the cl, that would be great. And I think we'll just kind of keep turning on this. Cool. So yeah, I think we've kind of covered a number of the peer loss things on the agenda that I had here. The other big thing is just actually like, yeah, do we raise the BOB counts and how and all of this. Is this a conversation anyone is keen to have now the general, you know, the intent is to raise the BOB counts in petra, obviously the question is how much? And you know, is it coupled with pure dos? Is pure DOS coupled with Petra? Like I think there's a lot of uncertainty here still.
00:52:59.305 - 00:53:31.993, Speaker B: But yeah, I don't know if anyone has any thoughts or updates on this. We're sharing right now. Yeah, Tony had a comment here. We also want to be mindful of the worst case block size. If we do raise the BLOB count and this calls up EIP7623 I believe is the number. That's more of an execution layer change, but also worth calling out here. Otherwise.
00:53:31.993 - 00:54:24.555, Speaker B: Yeah, from the data I've seen, honestly it looks like even already weaker nodes in the network are having issues with the current BLOB parameters. I had a document where I was talking about the uncoupling of the CL and EL with respect to blob count that we were just discussing. I also suggested another feature essentially where you could like customize your local BOB building to help with this issue. I think these are all things we want to keep in mind as we move forward and Yeah, I think otherwise, at least where I'm at right now is just having more time to have more data and analysis around how blobs are actually going on mainnet. It seems a little bit early to me to say, oh yeah, we definitely want to go to like 8, 16 or like some concrete number, especially without seeing how the peer DOS devnets go and all of this.
00:54:28.135 - 00:54:59.315, Speaker E: Yeah, I think that makes sense. I just wanted to briefly flag that in the chat we had a conversation quite a while and there were some people that were under the impression that we basically did not specifically did not want to increase the blob count at all during Pictor, just because it would add quite a bit of testing overhead and other people that were very adamant that we actually should really increase the popcorn. So I would just want to flag it as a topic where we will at some point have to have the conversation and neither side should fully assume yet that that decision is made either way.
00:55:01.655 - 00:55:18.545, Speaker B: Yeah, definitely. I mean, I would say if peer dos is ready with Petra, then we would also raise the blob count just because of the demand. So I think that's understood at least. Hopefully it's understood.
00:55:20.405 - 00:55:26.105, Speaker E: Isn't that starting to get a bit risky though? Because we don't actually know how peer does will play out on mainnet.
00:55:27.325 - 00:55:29.269, Speaker B: Sure. So the conditional on peer dos.
00:55:29.317 - 00:55:29.645, Speaker F: Right?
00:55:29.725 - 00:55:52.129, Speaker B: I mean, I don't know, like, so that does raise an intermediate step that I think Francesco is calling out in the chat just now. Like we could imagine. Well, that's the thing. There's a couple of things. So one option is we ship peer to us, leave the blob counts alone. Again, I think if we're confident enough in peer to us to ship it, then we're probably also confident enough to raise the blob count. We could also just.
00:55:52.129 - 00:56:09.655, Speaker B: Yeah, we could ship peer to us and not raise the blob count. We could just raise the blob count with 4844. I think that's probably not as preferred to everyone, but that's an option. And yeah, so there's many things to work through here, Barnabas.
00:56:10.275 - 00:56:22.175, Speaker F: Just because we are confident enough to ship peer death, that is not. That's not going to give us confidence to increase the blob count though. That's not the same thing.
00:56:22.755 - 00:56:23.615, Speaker B: I agree.
00:56:26.315 - 00:56:37.675, Speaker F: Because that's what you just said like one minute ago, that if you have enough confidence in shipping, period does, then we have the confidence to increase the bob count as well. But those two are completely different things.
00:56:39.055 - 00:56:47.155, Speaker B: They're pretty Different. I mean, I would hope we get to a place where we have confidence in both that like one implies the other. But yes, I agree with what you're saying.
00:56:49.255 - 00:57:26.025, Speaker F: The point is we have so many IPs and I feel like we just keep shoveling more and more and more into it and it's just never going to end. So we will have to draw some lines somewhere where we say, okay, this is where we're going to end it. And I think shipping peer death and increase the block count in the same fork is just not something that we can do in the next year and a half testing wise, as well as all the other EIPs that we have included as well.
00:57:27.565 - 00:57:44.775, Speaker B: Yeah, I mean, I don't know how valuable it is to have a fork scraping conversation today, but you know, I think if we get to that point and it becomes clear in a few months, then that motivates splitting peer dos into a different fork or. Yeah, rethinking Petra. Francesco?
00:57:46.875 - 00:58:45.385, Speaker G: Yeah, I just wanted to point out something which I think Dans already mentioned in the chat that like the block count means something quite different with peer do peer dos. So I mean this doesn't mean that necessarily we can feel confident having, I don't know, like six or eight or whatever, like target. But it doesn't mean that we can't really just say, you know, we are okay with a block count of three because we know we've seen in a main net like it means something different peer dos, like it's the throughput that, I mean the bandwidth that you need to handle 3, 6 is very different in peer Das it would be like much less. So yeah, I don't think that necessarily. It seems a bit of like a bias there of like, you know, we ship your dos without doing any change to your block count, then we can feel confident that it works. But that's not really, to me, that's not really necessarily the case. This doesn't mean that like you know, necessarily we should increase it, but that's one thing to keep in mind.
00:58:45.385 - 00:59:43.175, Speaker G: And also another thing is I think if we're not willing to do that, which I can understand there's like, I agree there's, there's a ton of EIPs and things going on and it's hard to test all of it. But if we're not willing to do that, what benefit are we actually getting from doing peer dos with Pectora? If that's that that ends up being the case, like at that point, does it not just make more sense to De risk the whole thing. Just do pectra without peer dos. Just do peer commit to doing peer DOS as its own fork, like much before Verkal. Because I think, I think the only really like stupid outcome that we should avoid at all costs is trying to type your dos and with a blob count increase to some fork far away in the future, that's really the only outcome that's just to me unacceptable. But other than that, whether we do peer dos in January or April or whatever, doing it earlier without block count increase to me just doesn't really add that much.
00:59:47.605 - 00:59:54.413, Speaker B: Right. I mean it would give us evidence on mainnet that peer dos is working like we expect. Right. So like it does actually de risk.
00:59:54.469 - 01:00:00.145, Speaker G: Shipping parados, but it also increases risk to everything else and like to the whole fork.
01:00:00.965 - 01:00:13.545, Speaker B: Well, I think that's a different conversation and that's where this starts to get tricky is. Yeah, like aligning pector timelines with paradise timelines with bulk increased timelines. Parash.
01:00:15.765 - 01:00:59.915, Speaker E: Yeah, so the one point I do want to bring up is like we're talking about testing, but the issue is that testing networking is extremely hard. We did do a lot of 4844 related testing, but the way blobs played out on mainnet is not a one to one analog to how it played out in testing. We do see weaker nodes having issues. We do see timing games being played and stuff like that. And that's the main reason why even if we can simulate a perfect world in which pure does along with the blob increase does work in all of our devnets, it doesn't actually mean anything for mainnet. And that's my main argument for why we should probably do things step by step rather than all at once. Because just testing doesn't mean anything here.
01:01:04.825 - 01:01:07.809, Speaker B: Oscar, did you have your hand up for.
01:01:07.857 - 01:01:49.777, Speaker E: Yeah, I just wanted to. Yeah, I just wanted to briefly say that to me really like this point of score is super important that like the meaning of blobs already changes in the peer does. So I don't even think it makes sense with peer does to call it a blob count increase because we have to pick a new number of blobs for peer does anyway. Even if we happen to go with this kind of 36 that we also have today, that doesn't mean we can actually reuse anything. I mean maybe like a tiny sliver of El side logic around the gas computation, but that's the easiest part. Anything else changes anyway and then I don't know specifically why mainnet might break under, say, I don't know, 816 or something, but it would not break under 3.6. It could also break under 3.6.
01:01:49.777 - 01:02:38.199, Speaker E: And so the only world in which I see that there's any reason to stick to as a default to the values we happen to have in a pre peerdes world would be if we ship peerdes with some sort of fallback mechanism to disable it if there are issues and fallback to the existing version. But that seems so incredibly complex, including for. For implications, that I don't think it's realistic to ship it that way. So if we already ship it as its own standalone thing, that has to not break, otherwise mainnet breaks, then I don't see why 3.6 would have any more value as a default than any other other count number we could. I just don't think calling it an increase makes sense when we have to pick a completely new number anyway. Actually, Francesco, I think said something earlier that made a lot of sense.
01:02:38.199 - 01:03:02.065, Speaker E: If we are moving to a paradigm in which the CL is setting the blobs, we could potentially increase the blob count. And we already have this mechanism with the circuit breaker where if we see a bunch of missed slots in a row slash, non finality slash, a lot of other circuit breaker conditions that we use for mev, we could reuse that same circuit breaker conditions for blobs as well.
01:03:03.685 - 01:03:24.115, Speaker C: I think that isn't. I don't think we can do that here because all the clients have to be consensus on the maximum blob amount. And the circuit breaker rules are not something that all clients have consensus on. And I don't think they could either because what they see is, can be different.
01:03:25.935 - 01:03:49.545, Speaker G: But you could, for example, just locally say, like, I'm not going to propose a block with more than, I don't know, two blobs or something. If I see that things are not working, I don't know how viable it is. But I mean, if someone else does propose a block with a lot of blobs and it turns out that like that the network is not able to handle that, I guess that just. You just get reorged.
01:03:51.725 - 01:05:01.365, Speaker C: Yeah, I guess. But you know, if you see a block with three blobs and your node is feeling like the network's in bad shape and only two need to, like, yeah, we should only ship with two or something like that, then you have to reject that block. And then what if the rest of the network, like, I don't know that that seems. Can you really do that Unless we have special rules where it doesn't actually make the block invalid to have more blobs than you expect. But that's weird. But I would, I don't just want to say, I second what Ansgar was saying. Like if we have to pick a number even, I mean, what if we even just picked a small blob size increase? I mean if we're going to test with 6 with pure DAS, we might as well test with 8 and then leave it to some future date to increase it further.
01:05:01.365 - 01:05:06.005, Speaker C: That would. That seems like a safe option. And a small increase.
01:05:06.905 - 01:05:19.605, Speaker F: What's the point of increasing if it's not significant? Like why, why risk of increasing if. If there's no actual benefit?
01:05:21.065 - 01:05:50.415, Speaker C: I think this is Francesco's point where it's not that we're. We're not increasing from a known value. If we're implementing peer to us, we are just like kind of picking a number that we think is right. And like, yeah, lower is maybe safer if we imagine there are going to be bottleneck bottlenecks with upload download. But it's not necessarily like we don't know anything about the new limits. Also, 8 is the power of 2. Just saying.
01:05:51.635 - 01:06:03.195, Speaker B: So we can target the same amount of bandwidth, right? Like we can do that calculation and we can know that with peer dos, you know, the blob count might change, but it's going to be the same amount of bandwidth. So that's a good starting point.
01:06:09.375 - 01:06:09.687, Speaker E: Yeah.
01:06:09.711 - 01:06:10.555, Speaker B: Francesco.
01:06:11.375 - 01:07:06.175, Speaker G: Yeah, just, I mean, I don't know how meaningful this is, but just to give everyone like a very, very rough idea with the current parameters in the spec, for a validator you would be using basically like if you're like a really low power validator that's running like one or two or a few, then you would be using roughly like 8x less bandwidth for the same amount of data. So maybe we don't increase the block count by 8x but maybe safer to increase it by 2x or something like that. And as a full node even it would be even less. Like you'll be using 1 16th. I mean, of course we should actually confirm these numbers on testnets. Like compare for the same amount of blobs, what is the bandwidth usage from 484 versus peer DOS? But in principle that's what it should be.
01:07:08.755 - 01:07:30.077, Speaker B: Right? So it seems like there's plenty of headroom to argue for a double. But yeah, I don't know. I think at least I would hope we're going to have a better understanding of how this stuff works. You know, once we have devnets that are running and pure DOS is actually live and then hopefully the conversation is a little less uncertain and I guess I.
01:07:30.261 - 01:08:04.485, Speaker C: Sorry, I mean it jumped. But I, I just want to say like if the problem is that we're putting too much in the fork, like I just think the blob increase and pure DOS are something coupled like changing the blob size by a little bit compared to the other things that we're putting in this fork is such a small change. If you already assume that pure DAS is going in. If we have to pull things from the fork. I wouldn't, I don't. I don't think a configuration where pector ships or where pure dash ships and the increase doesn't ship makes sense. I think we would pull something else.
01:08:10.275 - 01:08:12.255, Speaker B: Enrico, I think you had your hand up.
01:08:13.075 - 01:09:22.875, Speaker D: Yeah, Just a comment because we are saying that we are going to the with the peer does activation epoch in Electra. It means that peer does will activate later. So it's weird that we get a blob increase and then the peer does activates just later. So picking up the right blobs count at fork seems like weird to me. Unless we increase the blob does activation, which is a different story. So we end up not increasing enough because we have to cover the first month of non peer DAS activation and we don't get the full benefit of the right number of blobs that we can support in peer does, which is weird.
01:09:25.385 - 01:09:30.045, Speaker B: Great. And you're just referring to having like some delayed activation of pure dos.
01:09:31.865 - 01:09:39.805, Speaker D: Yes, I mean in the moment of if we agree on the delayed activation of the peer does.
01:09:40.505 - 01:10:02.735, Speaker B: Yeah, I don't see why we would ever do that myself because it just seems to complicate what's already very, very complicated. I think we either ship pure DOS with Petra or we don't, basically, because otherwise. Yeah, she's going to add even more sort of huge decision points on top of something that's already quite complex.
01:10:09.755 - 01:10:52.555, Speaker F: In terms of the blob count. I think it's also not crazy to think about what if we just do the same as with call Data and make validators, just vote on it. I mean it's working. There's no crazy increases and it allows us to change it without a hard fork. Because I think largely in the end, like the way it's always worked with the gas limit is that the, the miners and other stakers just like listen to the core defs what they think is a safe limit. And then increase it to that. So this would allow us more flexibility in the future.
01:10:56.855 - 01:12:03.735, Speaker B: Right. I mean, do we ever think we're in a situation where, you know, people on this call, for example, want to raise the Bob count, but then the validators, let's say, aren't listening? Not because they don't want to, but just because, you know, they don't understand how to, like, go and change target limits and all this stuff? Okay. Um, so, yeah, I think we just keep charging ahead here. I again hope that having pure DOS test meds will give some certainty to, or at least some insight into some of these things and hopefully we can. Well, I mean, we will figure something out. So we just have to keep pushing ahead. Um, is there anything else on pure DOS or blob counts or anything like that? Otherwise we have an as the update.
01:12:03.735 - 01:12:17.055, Speaker B: Okay, Eton, I think you're driving this. Would you like to give an overview of the latest there?
01:12:18.075 - 01:12:57.735, Speaker D: Sure. So progress has been going well. Techo has joined SSE 7688 Devnet as well. That's the CL1 with the stable containers for all the data structures in consensus that keep changing across forks. Last time Grandina mentioned some questions about type systems. I'm not sure if those are resolved otherwise. I think we can just give it a brief discussion.
01:13:01.995 - 01:13:41.555, Speaker A: Yes. So for, for us, we. We think that we will go with the approach where we will try to keep the types that we have, the type system in general that we already have in the application, and we'll just try to. To build something like Metastructures or so that would accommodate functionality required for stable containers. So that's the current plan for us, but the implementation we have, it's. It's not, it's not finished and I think we will tell more after it's done.
01:13:43.135 - 01:13:49.709, Speaker D: Ram, do you see any blockers? Like, same goes for Lighthouse and Prism. Like, is there something that we should.
01:13:49.757 - 01:14:17.295, Speaker A: Know about at the moment for Grandina, we don't see blockers, but, you know, as the rest environment is quite restricted, restrictive and not too flexible. I think until we finished, we cannot fully confirm you that there are no. That there will be. There will not be any blockers. But so far we are progressing.
01:14:21.675 - 01:14:35.735, Speaker D: Okay. And from Lighthouse, I see in the chat that there is also no blocker so far. No, not no Prism. I think Casey made some comments on the spec as well.
01:14:39.275 - 01:14:43.595, Speaker E: Yeah, we're. We're still looking into it. We should have an update by the next acd.
01:14:44.655 - 01:15:44.035, Speaker D: Okay, cool. Yeah, I, I think we should Target the next acdc like it seems that everyone started implementing it and that we could resolve the questions there and it would be really great if we can have the full devnet with all the clients so that we can decide if we want this in Pector or not. For remarkable the like the implementation in Python that we use in consensus specs. I have pushed that one to production quality, but I'm still trying to get hold of Proto Lambda. It's a bit hard to reach. If anyone could ping him about this PR that I just put in the chat would be great just because we need that in consensus specs to do any tests. Right.
01:15:44.035 - 01:17:28.307, Speaker D: And also a small update on the SSE transactions. Ethereum JS has started working on that one and Nimbus has a corresponding consensus client. One question that came up is that right now in the CL we need to know about all the fields in the EL block header. So every time that there is a new field in the EL block header, the CL execution payload header and the CL execution payload have to be updated in logstat. And one thing that happens if we go with the SSE transactions in the same way is that the CL also needs to know how to hash the transactions in order to do the optimistic sync and also in order to have the transaction type as part of the execution payload. So that would be a small restriction for the el, because right now they can introduce new transaction types unilaterally without a CL fork. But with that it would mean that whenever there are new fields in the transaction, that the CL also needs to be updated at the same time the same way how it's already done for the EL block header.
01:17:28.307 - 01:18:13.775, Speaker D: I'm wondering if that is fine. The alternative that I'm seeing is just to make two trees. One with the serialized transactions like the same how we do it today, and then a second tree with the transaction IDs in a list like all the hashtags in a list. But that would mean like that we essentially double the amount of hashes that are needed and I mean most of the blockies transactions so a bit suboptimal. So yeah, just wanted to point that out that whether that's. Someone sees a problem with the CL knowing how to merkelize transactions and what fields there are.
01:18:20.405 - 01:18:28.105, Speaker B: Yeah, I don't think there are really any issues, it's just. Yeah, it's. It opens a lot of sort of feature set things to consider.
01:18:29.085 - 01:18:29.865, Speaker D: Yeah.
01:18:31.005 - 01:18:34.665, Speaker B: But thanks for the update potus. You had your hand up.
01:18:35.445 - 01:18:36.053, Speaker D: Yeah.
01:18:36.149 - 01:18:39.827, Speaker F: So yeah, I have a horrible connection. I don't know how much is on.
01:18:40.021 - 01:18:42.495, Speaker H: Cutting off, but I think we should.
01:18:42.655 - 01:18:46.087, Speaker F: Probably revisit or evaluate whether or not.
01:18:46.151 - 01:18:49.543, Speaker H: We can remove completely the execution payload header.
01:18:49.719 - 01:18:53.875, Speaker F: For currently there's no in protocol usage of it.
01:18:54.375 - 01:18:57.247, Speaker E: We only check the block hash.
01:18:57.351 - 01:19:08.931, Speaker F: We check against the parent hash. In my EPBS branch I have it essentially with minimal data removed, most of it. I understand that there are some concerns.
01:19:08.963 - 01:19:11.987, Speaker H: About light clients, but like clients currently.
01:19:12.131 - 01:19:13.963, Speaker E: Don'T really use the header and they.
01:19:13.979 - 01:19:16.707, Speaker F: Can probably use it check it on the Yale side.
01:19:16.851 - 01:19:19.547, Speaker E: I think we should probably think about.
01:19:19.611 - 01:19:21.363, Speaker F: Removing all of this information on the.
01:19:21.379 - 01:19:25.695, Speaker E: Execution payload header that we're not using. And that would solve also Ethan's problem.
01:19:28.475 - 01:19:39.513, Speaker D: The light client stuff should still be fine. Like full node that serves that data, it can still inspect the block and construct it. Right. It's just that.
01:19:39.569 - 01:19:40.161, Speaker E: Exactly.
01:19:40.273 - 01:19:42.057, Speaker F: So, and we are not using at.
01:19:42.081 - 01:19:44.125, Speaker E: All the execution payload header.
01:19:44.545 - 01:19:45.537, Speaker B: We can only.
01:19:45.641 - 01:19:51.005, Speaker E: We can replace the last execution payload header in the beacon state by just the last block hash.
01:19:59.825 - 01:20:25.045, Speaker D: Yeah, in the beacon state, yeah. In the builder API it's still relevant, of course, but that one is not on chain. Right, but it's a good point. Like maybe we can go the other way and make the execution payload opaque as well. And then the EL would be the one to.
01:20:25.125 - 01:20:27.405, Speaker H: Yeah, that makes the life of us.
01:20:27.565 - 01:20:31.787, Speaker E: Of everyone, much better. There are some things that we need anyways.
01:20:31.891 - 01:20:33.163, Speaker F: Even in the builder API you need.
01:20:33.179 - 01:20:39.175, Speaker E: The KCG commitments and a bunch of things. But it can be reduced quite a bit.
01:20:41.115 - 01:21:35.565, Speaker D: Yeah, we can think about that once we have an implementation. Luckily it's quite orthogonal. So the SSE transaction, it can be implemented on an elite and then we can figure out how we want to like whether we want to add the transaction as well to the CL or whether we want to remove the execution payload. Yeah, could you. Could you send me that branch as well? Like the EPBS branch from the chat would be cool as well. Yeah. Anyway, so yeah, that's the SSE update for this time.
01:21:35.565 - 01:21:56.615, Speaker D: Goal is next ACDC to have the full devnet with current DNA, Prism and Lighthouse as well. Then we can decide whether to include it. And yeah, if someone can poke Proto Lambda about the remarkable pr. Yeah, that's all from my side.
01:21:58.315 - 01:22:02.415, Speaker B: Is this a Petra devnet or Deneb or something else?
01:22:03.035 - 01:22:10.095, Speaker D: It's an Electra devnet. It's on stability now box. The cortosis config is there.
01:22:12.245 - 01:22:51.625, Speaker B: Cool, Nice work. So we only have a few minutes here at the end of the call and we did have one more thing on the agenda to talk about the name for the F star I think there have been a couple different suggestions flying around. Sounds like we have some leading favorites either Fulu or Felis I don't know if people want to discuss now I think there's also I'll go find a link but I think there's an eth magicians post for it. Does anybody want to champion their favorite?
01:23:03.455 - 01:23:04.735, Speaker C: Is there a name for the El.
01:23:04.815 - 01:23:08.995, Speaker B: Side Osaka.
01:23:13.495 - 01:23:18.435, Speaker C: So it's kind of between like bro soccer or Fisaka for the combination.
01:23:33.105 - 01:24:34.265, Speaker B: Par suggested a Sulu which I kind of like oh yeah Fosaka. Okay well I would suggest going to the seed magicians post if you feel strongly and otherwise if there anything else anything else on the F star name it doesn't sound like there's enough demand to make a decision right now. Okay anything else to wrap up the call Otherwise I think that is it for the day. Okay sounds good thanks everyone and see you on the next call.
01:24:36.325 - 01:24:37.333, Speaker D: Thanks Alex.
01:24:37.509 - 01:24:37.821, Speaker B: Bye.

00:00:04.120 - 00:01:00.430, Speaker A: Okay, so welcome, everyone, to our 19th Ford four call. So Mophie had a spec update to discuss, but I guess at a higher level, just to put this in context, last time we talked about wanting to get the Chappella releases out and kind of use that as a foundation to build future devnets for four four four on, and potentially chat about if those four four four devnets should just become the dencoon devnets and whatnot. So I think that's probably the main thing to chat about today, beyond the specific spec issue. If there's anything else, obviously, we can always go over that. That's sort of what I had, but, yeah, let's get into it, I guess. Mophie, you posted this pr to the EIP that adds some checks. Do you want to give some quick context about it?
00:01:01.360 - 00:01:38.120, Speaker B: Yeah, sure. It's a pretty straightforward check. This is just an admission in the EIP. We're not validating the excess data gas. And hat tip to Marius for bringing this up. So it's possible to provide a block with an invalid excess data gas, but all the other block headers and transactions are valid, and that block gets accepted prior to this pr. Now this just fixes that such that that field is also checked correctly.
00:01:40.620 - 00:01:44.030, Speaker A: Got it. Anyone have thoughts on this?
00:01:50.250 - 00:01:53.270, Speaker C: Yeah, I mean, to me, it seems like an oversight.
00:01:54.170 - 00:01:54.750, Speaker A: Who are you?
00:01:54.760 - 00:01:56.060, Speaker C: Bad not to have this.
00:01:58.030 - 00:02:24.930, Speaker A: Yeah, I agree. Okay, so I guess we can get this merged into the EIP. We probably just need an author to approve that pr. Okay. Yeah. So I guess next up, I'd be curious to hear from the different client teams. So now that we have the Chappella releases out, I know there's been some progress as well.
00:02:24.930 - 00:02:47.260, Speaker A: I saw, Andrew, you were sort of looking at this in the chat last week on the four, four, four implementations, I guess, where the client teams generally feel in terms of readiness. Does it make sense to start targeting Devnet launch that's built on top of shapella in the next couple of weeks? Yeah. Any teams have thoughts about that?
00:02:49.870 - 00:03:27.702, Speaker D: Yeah, I can give a quick update on the prism side. So we have been working on the implementation mostly on the free, the blobs mechanism, because that's the one that has been teaching the longest. So as of latest, we can do local testnet between prism and get, and then we can spam the blobs process. The blobs. We have blobs by root implemented and tested. Blobs by range is also implemented and tested. So we're working on this whole initial sync mechanism, such as we can sync from Genesis to the latest head.
00:03:27.702 - 00:03:46.650, Speaker D: And that's what we're working on. So I think after that is done, we're pretty close to like a multi client devnet. We don't have backfill yet. That's something that we were working on, but I don't think that is the blocker. So right now our main blocker is getting the initial syncing to work. So I do think target in a few weeks is fairly reasonable.
00:03:49.150 - 00:04:07.650, Speaker A: Thank you. Any other teams have updates? Yeah, both Loadstar and FTMJs are ready and can do a multi client devnet. And basically we already are running Devnet locally with Ethereum, js and loads of combo.
00:04:10.950 - 00:04:46.160, Speaker E: So for Lighthouse, we're at the point where we're trying to get something working locally, but we're not quite there yet. We have a couple sort of features we're still working on, one of which is making our caching smarter, more practical in bad cases. And then also we're working on the mechanic of single block or blob lookups in different scenarios if you miss them in gossip or if you're getting something via RPC, but not everything. So yeah, I think we're close to having something working, but we're not quite there.
00:04:51.750 - 00:04:59.140, Speaker C: What do you think? I guess for a Devnet, multi client Devnet, what is a reasonable timeline for you guys?
00:05:00.950 - 00:05:11.960, Speaker E: I think for us like two weeks, I feel like we could get something running. Yeah, but I guess the further back it is, the better our implementation will be.
00:05:14.090 - 00:05:20.442, Speaker A: And this would definitely be. Well, I know it's not the first devnet, but call it the first post Chappella Devnet and not the last.
00:05:20.496 - 00:05:25.034, Speaker C: Right, the first free the blobs Devnet, I guess.
00:05:25.072 - 00:05:25.660, Speaker A: Yes.
00:05:29.150 - 00:05:30.380, Speaker E: It won't be perfect.
00:05:31.470 - 00:06:29.022, Speaker F: Okay, so forget basically we've not even started looking into it because Mophie and Roberto have been doing such great work. Peter has been working on the blob pool, on the transaction pool for blobs. And I think that netted a pretty nice implementation. But yeah. So I've been working on SSC library with what's his name. Sorry, Casey from the prison team. Yes, and that also looks kind of good.
00:06:29.022 - 00:07:00.940, Speaker F: Now we kind of have the prerequisites down and we should get someone on for it for four soonish. Let's put it like that. But until then, it's great that we have the implementation by Roberto and Mofi. And we will probably build on that at some point.
00:07:02.750 - 00:07:27.940, Speaker A: Does Peter plan to put some sort of write up around the transaction pool design when it's done. I know, because he had the one from Austria which was like all the constraints and things to solve for. It would be nice if once the implementation is done, he could have all the solutions or ways get his approach, the problems.
00:07:29.910 - 00:07:47.818, Speaker F: Yes. So in his pr he has a kind of a brain dump of ideas. I can link to that.
00:07:47.904 - 00:07:55.420, Speaker A: Yeah, if you have the pr, that'd be awesome. Thank you.
00:07:59.330 - 00:08:06.042, Speaker F: And I think I sent an old version.
00:08:06.186 - 00:08:08.480, Speaker A: Okay. Yeah, because there's no comments in this.
00:08:10.610 - 00:08:17.860, Speaker F: Yeah, there are no comments. It's a comment in the code.
00:08:18.790 - 00:08:20.100, Speaker A: Okay, got it.
00:08:24.250 - 00:08:54.270, Speaker F: This one should be the. Anyway, but yeah. Okay. I was already on the latest version, but basically it's a comment in the code in the blob pool line 128. And yeah, this is like 150 lines of comments, which explains some of the ideas.
00:09:01.760 - 00:09:02.510, Speaker A: Awesome.
00:09:06.400 - 00:09:29.430, Speaker C: We've had discussions around this before around whether this stuff belongs in the spec or not. Kind of these layer zero types of things. Exactly what we're doing with transaction pool rules. And another thing I think is do we add data gas field to the transaction receipt? Are these the kinds of things we put in the spec, or do we put them somewhere else.
00:09:33.100 - 00:10:32.170, Speaker F: Like the data gas in the receipts that needs to be put in a spec, the transaction pool? Not in my opinion. And I think it's always better to have. For these kind of things that are very dos critical, it's kind of good to have multiple different implementations. So, for example, we had this issue on Gurley recently that we were getting DOST. Geth was getting dos, but because Nethermind doesn't handle future transactions in the same way we do, it didn't really matter to them. So having different implementations of the transaction pool really makes sense to me.
00:10:34.160 - 00:11:31.340, Speaker G: I agree and disagree with the statement. So from how our transaction pool evolved, it was a lot different than gaff's in the beginning. In terms of rules, maybe internal workings is still different, but in terms of the rules. But the rules evolved very similar to GEF. And the one thing that Marius is mentioning is the one place that we were more strict. But overall, because of security and performance reasons, our transaction pool actually converged to have more similar rules than GIF implementation. Just from the practical reasons, we can think that we can do blobs differently, but in the end, probably common sense would put us on very similar paths.
00:11:31.340 - 00:11:33.950, Speaker G: That's from experience.
00:11:35.680 - 00:11:35.996, Speaker A: Yeah.
00:11:36.018 - 00:11:52.100, Speaker C: I guess my concern is clients need to know what the expectations are right around submitting transactions. I mean, maybe blobs are unique enough that people are sophisticated enough to figure out the quirks of different clients, but that was my main concern.
00:11:57.880 - 00:12:31.680, Speaker A: Yeah. So at least if we have the code well documented, like, I mean, you know, the Nethermind team can obviously read the comments in the get pr, but it's true that we don't have somewhere for those non consensus design docs. Maris, anything else on guests?
00:12:34.420 - 00:12:35.170, Speaker F: No.
00:12:36.100 - 00:13:19.392, Speaker A: Okay. Any other teams have updates, stuff they want to share? Yeah, on the nimbus side, I think roughly tracking what Lighthouse describes schedule wise, I think in a couple of weeks seems feasible. Basically a lot of stuff is kind of backed up going into prs this week. The free the blobs implementation is mostly done, but still needs to get submitted and merged. So I think, yeah, a couple of weeks ish seems within the realm of possibility. Yeah. An update from Tagu as well.
00:13:19.392 - 00:14:33.716, Speaker A: We are working on different streams now in parallel and mostly on the orchestration between the gossip blobs and lookups and the arrival of the block and also in the API signing flows. So there are still plenty of work and make everything glue together and do some internal tests. So yeah, two weeks seems to be tight at the moment. So yeah, maybe if we can't join the first version we will join the second one for Ericon. Thanks to Roberto we have a draft implementation, but we have only started looking at the changes, understanding all the changes and we've started merging them, but not like the entire PR in one go. We started merging it piecemeal and it'll.
00:14:33.748 - 00:14:37.130, Speaker C: Take us some time to take in all the changes.
00:14:38.540 - 00:14:38.856, Speaker A: Yeah.
00:14:38.878 - 00:14:49.100, Speaker C: And Andrew, I'll do my best to get it merged with upstream this week. It's probably divergent because I haven't touched it in quite some time, but I'm planning to get on that.
00:14:49.170 - 00:15:15.298, Speaker A: Super. Thank you. Yeah, please. We'll be happy to join Devnet to check our export solution and improve it in the future, but we are ready basically. Thanks, Fabio. Yes.
00:15:15.464 - 00:16:07.860, Speaker H: On Besu side, we are at Devnet four feature level at that point, so we need to check what we need to do after that. My understanding is that from the execution engine side the number of changes is smaller. Hard to say if we can target tweaks depends on the priorities of team that we are working on the moment. There are some stability and the new features in development, so it's hard to say if we can hit the two week target at the moment. Need to check with the team.
00:16:10.170 - 00:16:45.026, Speaker A: Got it. Any other client? Think that was everyone. Okay. And so Mophi has a comment in the chat about the next Devnet should be long running. So basically I assume we probably aren't going to make any major spec changes. Obviously if we do, we can reassess from there. But yeah, it does seem like the spec is in a pretty stable spot.
00:16:45.026 - 00:18:10.420, Speaker A: So I agree that that's probably what makes sense to do is to target the specs. Assuming Mophie's change goes in with some minor change and then potentially aim to get the first defnets with like a subset of clients in the next two weeks. I don't know if it's possible before the next one of these calls or maybe right after. Obviously we have the fork on main net scheduled a few days before the next of these calls, but I think that if by the next one of these we could be in a spot where if we haven't already launched the next Devnet, we are ready to. Ideally we have more than one El and more than one Cl just to make sure that multi client stuff works. It seems like on the Cl side it should be possible on the El potentially if we're not running off, I mean, potentially we can get and net Aragon running off the branches, but it won't be running off master. But yeah, I think if we had like a Frida Belabs devnet with two plus els and cls would be in a spot where we can have something stable, gradually add more clients to it and keep it running.
00:18:10.420 - 00:19:00.962, Speaker A: Does that make sense to people? Oh yeah, Ethereum Js, that can, right? Yeah, so. Oh, that would actually be great. Yeah. So one non Roberto and Mophie implementation as well on the Ethereum Js, Geth Aragon and I guess prism and potentially lodsar. What's like the quickest we could launch this? Definitely. Do you think, is this something we can do in the next week or so? Are there still some changes that we need to merge in or rebate? Like Roberto, you mentioned you need to rebase Aragon. Yeah.
00:19:00.962 - 00:19:03.202, Speaker A: What do we think is like a reasonable target for.
00:19:03.336 - 00:19:12.920, Speaker C: Yeah, I mean, I think I can get it done this week. So maybe next week is a reasonable target if we just want those clients that seem to be reasonably ready for it anyway.
00:19:15.770 - 00:19:45.790, Speaker A: Cool. Although the load and Ethereum Js can be made ready at any moment. I mean, they are already ready. So I can cut the images on the latest code. Okay. I don't know, prism? Terrence, do you have a feel for if this is something like a week from.
00:19:45.940 - 00:20:03.606, Speaker D: Yeah, yeah, no, I think we'll probably need another week after that. So maybe two weeks. But yeah, like I said, more than feel free to even start with dollars. I think for us we're fine gossiping blobs, but we might have issue initial thinking. I would say between one week to.
00:20:03.628 - 00:20:53.222, Speaker A: Two weeks sounds reasonable. Okay, so how about we try and obviously it's going to be like an Easter weekend this weekend. So some people, I suspect might be away bit more than otherwise. But why don't we aim for early next week to try and start setting this up so this week we can do the changes to Aragon, kind of get the Els in good shape. And then maybe early next week we try to launch this, see how it goes throughout the week. And then on our next call, if we can have an attempt to launch the devnet, whether successful or not, I think that'll be good. In the best case, we have a couple of clients running next to each other and others can gradually join in.
00:20:53.222 - 00:21:27.520, Speaker A: In the worst case, there's something that's working and we'll have time to debug it. But I think that seems reasonable, cool. And obviously we'll have the CL call in the alcohol devs if there's the other awkward devs if there's anything that pops up before our next four four call. I think that's pretty much all I had. Anything else that people wanted to discuss? Yeah.
00:21:29.650 - 00:21:47.160, Speaker C: What was the verdict on data gas and the receipt? There was some discussion in the chat. Should we just add that to our clients and not worry about putting it in the spec proto. I guess you had some comments there I didn't quite understand. If you were taking a position.
00:21:52.510 - 00:21:58.730, Speaker A: It was pretty clear it could just be metadata, something not affecting consensus.
00:21:59.230 - 00:22:04.038, Speaker C: Yeah, it's definitely not affecting consensus. That's why I was curious whether it belongs in the spec or not.
00:22:04.224 - 00:22:15.550, Speaker A: In the execution APIs. Would it be there? It will be in the execution APIs then if we decide it's useful. So are the other received fields that are considered metadata?
00:22:16.530 - 00:22:40.078, Speaker C: Yeah, this is Andrew from Ethereum Jazz. When we raised this issue way back during Austria, that was where we decided to put it was in the execution APIs. I just haven't gotten to actually opening the pr against the APIs on it yet. So I had started that a while back and then got sidetracked with other stuff. So I can circle back to that and try to get that in the API. Get a pr open against the execution APIs.
00:22:40.114 - 00:22:40.746, Speaker A: I think we talked about.
00:22:40.768 - 00:22:50.860, Speaker C: We wanted to bring it up to the execution. All core devs call before we do any flaggers. I think Tim is. That's my recollection I have to look at.
00:22:51.550 - 00:23:27.720, Speaker A: Yeah. So I think we can definitely open the PRS app. It's good to mention it on all core devs, just so people know it's there. I think the thing we should do as well once we have that pr, this is probably a good opportunity. I don't know if the execution APIs can be linked in eits quite yet, but I know they wanted to do it at some point. So that would probably be a good opportunity to once we have this pr up, we can potentially add it to the EIP itself. So we can mention in the EIP itself that the changes, that the receipts are tracked there.
00:23:28.250 - 00:23:45.998, Speaker C: Okay, I'll try to get a pr. I mean, I think I already had even written it up, I just haven't ever pushed it to the I'll try to get a pr up today or tomorrow and then as I remember, I'll drop a note in the sharding channel on Ethernd and you can figure out how you want to go from there.
00:23:46.164 - 00:23:52.680, Speaker A: Cool. Anything else?
00:23:57.600 - 00:24:09.650, Speaker C: Did we want to shoot for any transaction pool specific denial of service goals for our devnet or should we just let figure that out later?
00:24:10.740 - 00:24:13.120, Speaker A: What do you have in mind in terms of goals?
00:24:16.580 - 00:24:51.310, Speaker C: Let me look it up. I had posted in the ETH magicians forum. I made a couple proposals based on the discussions from the workshop. I'm trying to look it up because I can't remember exactly what it was. Oh yeah, here we go. Blob holding transactions should only be replaced by blob transactions consuming at least gas. And then there can only be one blob containing transaction per account that protects against two specific denial of service.
00:24:51.310 - 00:25:03.428, Speaker C: Mean I can go ahead and implement them in Gath and Aragon, at least others can take it or leave it, I suppose.
00:25:03.624 - 00:25:34.650, Speaker A: Yeah, I think it would be good actually to have a draft, if you have the time to have the draft implementation, run it in the devnet and see if we send a bunch of spam transactions, or in another case do we see bugs or any kind of unexpected issues based on that. And obviously we can revert to change without working the defnet if we see issues. But I agree, we said we should try that and it makes sense to do it.
00:25:35.260 - 00:25:37.130, Speaker C: Cool, I'll do my best to get that.
00:25:38.460 - 00:26:49.544, Speaker A: Similarly, if we're ready to launch a Devnet and we're just waiting on that, we can launch a devnet without it and do the transaction pool change, upgrade the nodes and see after. But yeah, I think it makes sense to aim for drops. Yeah, prototype implementation. Anything else? Okay, then I guess we can wrap up, and I think we did discuss this, I think a call or two ago, like how useful these calls are. If we've moved to Denkoon, I feel like they're probably still useful for at least a little while. So I would keep our two week 4844 cadence at least, I don't know, for the next call or two, and we can always drop them after that. But it seems like as we're setting up this devnet and kind of working through the initial implementations, it probably makes sense to have a bit more focused time on this.
00:26:49.544 - 00:27:02.110, Speaker A: But I suspect in the next couple of months, as we're fully into this as part of Denkoon, maybe they're not as relevant. So yeah, at least the next one or two, I think are probably important to keep.
00:27:02.960 - 00:27:05.996, Speaker C: Yeah, for sure. I don't think definitely the next one.
00:27:06.018 - 00:27:14.450, Speaker A: If we're trying to, for sure the next one, and I suspect we'll probably want one or two after that as well once we have the early deaf net.
00:27:16.340 - 00:27:24.870, Speaker C: What do you think the timeline is for the next fork? I can't remember what the are, but I'm just curious if there's been any discussion around that.
00:27:27.320 - 00:28:30.840, Speaker A: I don't know. I think the biggest question is obviously the work of doing four four four, and then is there like what else comes alongside it? I think on the last alcordevs there was a pretty strong desire, at least on the El side, to not add anything that would significantly delay. So for example, it seemed like for SSZ we're probably leaning towards doing, not doing a full SSZ overhaul alongside four four four. There were some similar concerns about EOF, although it's not clear exactly where the consensus is going to land there, but definitely every time something big comes up it seems like the response is like, will this significantly delay four four? I don't think we have like a set date or anything like that yet, but at least from my view, it's like people are aligned on not adding some other kind of huge thing that would make a big difference, but hard to say beyond that.
00:28:30.910 - 00:28:36.570, Speaker C: Yeah, that was my impression from the calls as well. I just was wondering if there have been other things that I wasn't privy to.
00:28:38.540 - 00:28:45.790, Speaker A: Alexa, you have a question like what's the feedback from l two? What do you mean in terms of the timeline? In terms of the EIP itself, in terms of.
00:28:47.220 - 00:28:49.490, Speaker F: Yeah, it seems like.
00:28:51.700 - 00:28:54.240, Speaker A: Solution we are developing.
00:28:54.660 - 00:29:01.360, Speaker F: It requires basic feedback from the main consumer.
00:29:02.100 - 00:29:40.016, Speaker A: Okay, yeah, I see. From the optimistic side, obviously optimism has invested quite a lot in getting this to happen. And so has, and we've gotten really positive feedback from arbitram as well. So I think from the optimistic rollup side, they're all quite on board. I think for ZK roll upsides this is usable by them. So we've checked that technically this provides good scalability. But I think this might not be the number one thing they prioritize using as much as optimistic roll ups as soon as it come out.
00:29:40.016 - 00:30:00.260, Speaker A: So I don't think any of the ZK rollups have an objection or incompatibility with this, but their roadmap just seems like potentially less focused on like, as soon as this is live, we're going to shift everything to it, which is more the feeling I got from optimistic roll ups.
00:30:03.660 - 00:30:15.850, Speaker C: Yeah, it's a pretty easy change to adopt too. Well, we haven't done all the details, but we've done an initial hack of starting to do it.
00:30:21.420 - 00:30:41.990, Speaker A: I think this is more on the SDK side. If there are any that have problems, then now would be the time for them to sort of step up and mention those. But we have done some outreach and sent this to them several times in the past year. And yeah, there hasn't been anything that's come up like critical or blocking or anything like that.
00:30:43.880 - 00:31:29.440, Speaker D: I would say nothing critical from the off chain lab side. So we are implementing the arbitran protocol, but I do think it's worth discussing more, maybe not this call, because this is more implementer, so it's worth discussing. Just like the data guess, essentially data guess what parameters to use and how often do we increase and decrease the percentage. And there is like a research thread about this and then optional labs have a research team looking at this problem we posted, Akake posted his latest feedback. So yeah, we can bring any further discussion to this research forum, but I think for layer two, it's fairly important to figure out those librarimeters.
00:31:42.260 - 00:31:48.210, Speaker A: Got it. Do you think we should discuss this on the CL call this week?
00:31:52.920 - 00:31:54.900, Speaker D: Who are the right audience?
00:31:55.400 - 00:31:56.150, Speaker A: Right.
00:31:57.240 - 00:32:06.244, Speaker D: I think whoever wants to come in and come into the research form. I don't think most of the occurred Devco has the right audiences.
00:32:06.292 - 00:32:06.456, Speaker A: Right.
00:32:06.478 - 00:32:20.644, Speaker D: Because the right audiences will be people from the rig team and representative from the layer two teams as well. I don't think they mostly show up in this type of implemented code.
00:32:20.702 - 00:32:46.340, Speaker A: Yeah. Okay. We can definitely try and pass this along to get broader feedback in the next couple of weeks from l two s and the rig folks. Yeah. Cool. Anything else?
00:32:53.930 - 00:33:00.170, Speaker C: Alexey asked. So there's no chance that things like blob size or count block will be changed.
00:33:01.070 - 00:33:53.142, Speaker A: I keep forgetting is our limit one two or two four right now. So I would be extremely surprised if it got changed to the upside. I doubt that that would happen. I could see a world where if we do some tests and whatnot, because there were, I believe, some networking tests that were run and that showed that there was some delays with large call data blocks. They weren't huge, but they were kind of noticeable. I think if there were to be a change, it might be possible to go from, like, two four to one two. But aside from that, I would be very surprised.
00:33:53.142 - 00:33:56.780, Speaker A: I don't know if anyone else has thoughts on this.
00:34:02.640 - 00:34:30.230, Speaker C: Yeah, I think I haven't heard any huge worries about the current numbers. Although having the only change that I think would make things a little simpler is to just say that there's one blob per transaction. That kind of makes transaction pool issues management a little easier. But I'm not proposing that. But it wouldn't surprise me if it came up is.
00:34:33.240 - 00:34:45.492, Speaker A: All right. Okay. Got it. Right, so we've removed zero blob transactions, but we can still have two blob transactions. Yeah.
00:34:45.546 - 00:34:54.792, Speaker C: Or more mempool management a little bit. I mean, like, right, if you have a transaction with three blobs versus two transactions with two blobs.
00:34:54.936 - 00:34:55.340, Speaker F: Yeah.
00:34:55.410 - 00:35:08.560, Speaker A: Is there a use case from layer twos to have more than one blob per transaction? I guess if the batch is bigger than fit in one blob, but that seems kind of weird.
00:35:09.540 - 00:35:12.130, Speaker C: And then you can always submit two transactions. Right?
00:35:12.500 - 00:35:53.570, Speaker A: Right. Yeah, actually. But I don't know, proto or terrence from the optimism arbitram side. Can you think of a use case like that? So, optimism, at least with the next step, does support arbitrarily splitting of data between multiple transactions. I think the bin link feature, where multiple blobs are linked in a single transaction is something that's more useful to the ZK run ups. Okay, so, yeah, again, we should ask them for more feedback. They are not as active in this call.
00:35:53.570 - 00:36:47.300, Speaker A: Okay. Yeah, I'll try and see. Maybe if we can get some ZK roll ups, people to look at the latest specs and share any feedback. Cool. Anything else? Okay, then, yeah, we can wrap up, talk to you all in two weeks. And, yeah, let's try and send up the devnet early next week. We can use the discord to coordinate that.
00:36:47.300 - 00:36:50.000, Speaker A: Great. Thanks.

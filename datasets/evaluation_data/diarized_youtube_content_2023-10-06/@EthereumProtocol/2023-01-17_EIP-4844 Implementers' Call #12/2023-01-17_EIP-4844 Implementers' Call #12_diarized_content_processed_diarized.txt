00:00:00.250 - 00:00:29.574, Speaker A: Okay, let's get started. This is now call number twelve for 4844. A couple things on the spec side today. So there was an update on the cryptography side. Alex, I don't think he's on the call, but he spent some time looking at their pre compile and shared some thoughts right before. So if anyone wants to discuss that, we can. If not, please share it then.
00:00:29.574 - 00:01:00.126, Speaker A: Terrence had a bunch of stuff around Devnet four and there was some testing updates. And I see Sean has added something related to the engine API, so we'll cover that as well. So I guess to start, there was this Cl spec for the crypto side of things. I know. Is George on the. Hello Tim? Hello. Hello.
00:01:00.126 - 00:02:12.838, Speaker A: Okay, so I can give a very tiny update on this because it's a pretty non intrusive change, but it concerns perhaps the people who are writing alternative KCG libraries other than CKG. So I don't know, Gok or soleils with the rust KCG thing. Basically, on the evaluate polynomial in evaluation form function, we used to assert when the input was the root of unity when the input was in the domain, we were not handling that edge case because it was extremely, extremely unlikely it would ever happen given how the function was used in the spec. But now we are exposing that function publicly as well, that perhaps roll ups might want to use it. So in that case, we decided to handle that edge case instead of asserting. So the spec has been updated so that it returns the correct value. Even in that case, it's a pretty trivial change.
00:02:12.838 - 00:03:14.634, Speaker A: But because we want to have the same behavior in all the crypto libraries, it might be worth checking it out if you're writing your own implementation. That's it. Thanks for this update. I just wanted to generally ask. At some point there was decision to verify or to validate the inputs, for example, that something fits into models and it's canonical. Do we have this as a general, let's say idea or general way or. This is for particular case what you mentioned, this is a different mean, it's a separate discussion.
00:03:14.634 - 00:04:26.174, Speaker A: But the fix that George just described is handling one special case that is in the previous way the function was used extremely unlikely, and extremely unlikely means like two to the -250 so it really should never happen unless it's much less likely than a hash collision. But we now added another way to use this function in which it is not that unlikely, because we're also exposing the API to computer KCG proof, and especially optimistic rollups will actually intentionally, usually want to evaluate in the domain and then it would actually be useful if a function can handle that. So that's why we made the small change. I think the question of validating inputs is a separate one, and I think we are only handling it inside the domain, if I remember that. Right, George? I think we made that explicit. Right. Are you talking about the pre compile, or you mean in general for all the functions? What do you mean? Yeah, I think in general for all the functions.
00:04:26.174 - 00:05:24.242, Speaker A: Right. All field elements have to be reduced in order to not have non canonical representations, right? Yes. So the pre compile has been modded such that you need to provide the canonical input and. Yeah, that's for the pre compile, which accepts arbitrary elements, basically. Now for all the other functions, for all the other functions that are public, we have also like, at least for the library side, we have edited the CKD library to accept bytes to make it easier for the clients to use it. But I still haven't fully understood your question. I think the question is whether those bytes have to be reduced, whether they always have to represent reduced field elements.
00:05:24.242 - 00:05:50.814, Speaker A: And I think the answer is probably yes. Yes, I think so. But I can double check. That might be worth checking, but it feels like. Yeah, because what are we handling? Where are we handling? This one is in the free compile where we said it's better to have this reduced so that there's no malleability kind of issues going on. And the other is in the blobs. Right.
00:05:50.814 - 00:06:17.080, Speaker A: Which are also just like basically bytes that represent field elements. And also there we want blobs to be canonical. So my intuition would be that all inputs should always be canonical field elements. Correct. And the roots of unity that were concerning the previous discussion are canonical, like they're within the field modulus. So they are indeed very orthogonal discussions. Yeah, this is a completely different issue though.
00:06:17.080 - 00:07:17.628, Speaker A: Okay, thanks. So what I would like to ask if it's possible. It would be really great, whenever there are such details changed, that there is also some tests that covers this. So this would be very helpful for the other implementations to track and be compliant with these small changes. I think George has added tests for this. Where are those tests? Because so far I think some of the tests are in bindings, in CKZG bindings, but there should be somewhere else. I mean, it would be really super nice if there is one test suit where everyone who does the changes, they make sure that these subtle things are covered.
00:07:17.628 - 00:08:03.064, Speaker A: So that would be perfect for this particular pr. I wrote tests for the consensus specs, for the spec, for the spec to validate itself that it's correct. I'm not sure how one adds tests that all the clients, all the libraries need to be conformant with. I'm not sure what's the process to do that, but maybe you're right that it would be good to have formal tests for that. Maybe. Kev? Yeah. If you wrote on the consensus layer, then eventually these different library permutations will notice it.
00:08:03.064 - 00:09:00.942, Speaker A: That's right. Am I thinking correctly or should I rephrase my question? I mean, if there is test that covers this subtle change in the cryptography library somewhere deep inside, but the test is on the consensus layer tests, then eventually somebody who will use this alternative PCG library will find that it's not compliant. I guess that's one way that it's probably easier to have them separate since they're for the cryptography. Yeah, that would be much better. Yeah. If that's at the unit level, somewhere close to the cryptography library. Yeah.
00:09:00.942 - 00:10:00.050, Speaker A: I had a repo for the fuzzy test vectors, but I haven't updated them because I'm still a bit away at the moment. As Proto wrote in the chat, I basically was trying to copy what they did, what Antonio did with the BLS twelve free one test. But instead of python, it's in go. Okay. From my side, the message is that if there is capacity and if somebody could collect and also maintain from there all these cases in one place, that would be really perfect. Right? Yeah, I guess there's an argument to sort of rewrite those dego stuff in Python so that it just copies what Antonio did. It's a bit easier to read as well.
00:10:00.050 - 00:10:50.836, Speaker A: Okay, anything else on that front? If not. Okay, there was a question in the chat a bit earlier on about data hash. Yeah, hey, this is Andrew from Ethereum Js. I was just reviewing my test coverage and realized I hadn't done written any tests for this, for the new opcode. And the EIP doesn't say whether we're supposed to put the. If you get a version hash because I mean the data hash just supposed to pop, it's supposed to see if it has the version hash referenced by the input. Is it supposed to push that data hash back onto the stack? That's what it looks like.
00:10:50.836 - 00:11:09.930, Speaker A: Geth is just couldn't. I'm not a go expert and so I just want to make sure my understanding was correct because the EIP just says return the data hash, but it doesn't say push it back on the stack or what have you. And so I just want to make sure. I'm doing the same thing as pushing back on the spec is the correct answer. I'll try to clarify the spec. Thank you. Yeah, no, that's fine.
00:11:09.930 - 00:11:35.040, Speaker A: Return has a very. I was just returning the value, which wasn't actually doing what was intended in my code, and then I realized that and so I made that change. I just wanted to verify that I understood correctly. So thank you. That was up. Cool. Okay, next up, let's cover the engine API PR as well.
00:11:35.040 - 00:12:36.950, Speaker A: So pull request three five five. So, okay, and so this just got merged. I can talk about this one quickly please? Yeah, so I just want to make sure that the El clients 4844 implementations allow for this. So Lighthouse tries to query the latest available endpoints when it starts up and through whatever forks occur. Previously we've had some incompatibility issues where EO clients would only serve the V two at Capella and then v three at four four or something. So I just wanted to make sure people were on the same page with this one. They might already be, I'm not totally sure, but that's about it.
00:12:36.950 - 00:13:40.490, Speaker A: Sean, do you know if the current withdrawal, I forgot what the test name is, but the current one or the upcoming one will have this as well? Yeah, I think so, because recently this was incompatible and then I think we sort of made a fuss about it. I think it's now implemented for the Capella El implementations. Okay. I think the action item here for Roberto and I to find out which commit El is using and using get as an example and then put that in the Coinbase repo. Okay, cool. And you were originally asking about El teams. I don't know if any of them had some thoughts they wanted to share.
00:13:40.490 - 00:14:50.980, Speaker A: I wouldn't be surprised. I just want to add something on this, that if we are making this fork agnostic, then why do we need v three version? Just reduce the versions and stick with it. Yeah, I'm not sure about specific reasonings. I think we can remove the v three version later on when we get into a more production stage, but I think for dev four it's probably too soon to remove it. Just client will have to change the code of that. I think he's saying can we just remove v two as well and just change the return type depending on if we're past Shanghai or not. Yeah, I'm not across the reasoning in the execution API.
00:14:50.980 - 00:15:32.420, Speaker A: I think it's possible if we're making versions backwards compatible, to not have to upgrade the version every time. But I don't know we'd have to talk to the spec maintainers there. I just want to make sure we're on the same page for Devnet before really. Right. And I think that was basically the next thing on the agenda. So if you want, we can just kind of COVID Devnet before now and see in terms of what's included that we're on the same page. Does that make sense? Sounds good to me.
00:15:32.420 - 00:17:08.060, Speaker A: Okay, so I guess starting. So, Terrence, I'll share your comment in the chat, but you had a comment about this, basically saying that your impression for V four is we use consensus spec one 30 rc one, which has on the cl side the GUi amount for withdrawals through the engine API, the historical summaries and the Genesis fork version for BLS changes on the El. We have this Guay unit in the engine API as well, this pr that we just discussed. And then basically all of the eips that are included in Shanghai. So withdrawals warm coinbase, push zero limit in it code and the fork id checks based on timestamps, I guess. Does anyone disagree that this should be the spec for Devnet four or that there's something that isn't included here? There is one thing. Since withdrawal three has moved from we to v change, am I correct to assume that since EIP for it forward net four will also be rebased on Capella so we'll have that change over there because.
00:17:08.060 - 00:17:50.120, Speaker A: Correct. We can't really. Okay. And I think, yeah, Terrence had already listed that at least in the engine API, but I assume given it's this one in the engine API, the assumption is like it's also stored on the El in Gui. Yeah. The problem is that it would get difficult to cherry pick out the commits since all our work is now in unstable our main coding branch. If possible, we should make sure that everything that is in withdrawal is definitely in the IP for it.
00:17:50.120 - 00:18:42.026, Speaker A: Yeah. And just to be clear, this weighted Gui change was part of withdrawals. We're going to have to do it anyway. And so we would rebase on kind of the same withdrawals code for four four four. Okay. Does any client team disagree that this should be the spec? It means that we do not include any changes in withdrawals root calculation. I heard guys wanted to switch to tree hash like that.
00:18:42.026 - 00:19:57.730, Speaker A: Mercottree. Right, because we haven't decided that yet for the route. Is that what you're saying? So we're going to make this decision on Awkwardev's Thursday. I'm not quite sure where it's going to land, but it seemed like last time I checked, the consensus was that the El route should match the Cl route, but I'd rather not have people kind of do work and have to change it because of all core devs. I think clearly we're going to use guay. The question is then how do you calculate the routes? But is that something people need to know before Thursday? Basically, are we blocked on this in the next two days? If not, I think that's maybe just the only thing we'd need to confirm for the spec. Yes.
00:19:57.730 - 00:20:36.610, Speaker A: Okay, so then just to summarize. So it means basically we would. Oh, there's a Devnet three that's launched today. This is just to include the very tick way. So now all the clients have that implemented already. Okay, this is for Shanka, this is not for. Yeah.
00:20:36.610 - 00:21:02.648, Speaker A: So does it make sense to just use this as well? Is there a reason to not use it? I would talk. Okay. Right. So if you look at the notes that Burnaby posts. Thank you for that. And then if you look at the spec version needed at the end, I think that's just a very good baseline, basically what I said. But now it's actually based on commit, so that's even more clear if you want to look at the code.
00:21:02.648 - 00:21:41.920, Speaker A: Yeah. Okay, perfect. So I think let's do this and I'll put together a hack MD just so we have it all in one place, basically based on your comments. But we can use the spec versions that are listed here at the bottom of the Devnet three for withdrawals. And the commit, we actually have the commit number that's missing on that hack MD because the PR got merged. Yeah. Cool.
00:21:41.920 - 00:22:25.764, Speaker A: Anything else on Devnet four, Tim? Do you already have. Go ahead, go, Terrence. I just want to follow up on the timeline for this. Do you see something that we want to do it before next Monday or next week when we're there? Yeah. Curious to hear what client teams think is achievable. I mean, I think we should shoot to do as much as we can beforehand, but it seems likely it'll slip in next week. I think.
00:22:25.764 - 00:23:35.462, Speaker A: Yeah, one of the things that is valuable is like if we have the implementations mostly done in clients and then we spend the time in person debugging cross client issues, that's always more useful given that all the folks, given that all the folks who aren't part of your team will be there in person. So I think, yeah, if we can try and have the implementations done this week, and then basically early next week we set up the Devnet in person. That would be pretty good. Cool. Anything else on Devnet four? Okay, the next thing on the agenda. So Alex from the Epsilon team was reviewing the 4844 pre compile. He shared some thoughts this morning.
00:23:35.462 - 00:24:19.090, Speaker A: He's not on the call. I don't know if anyone has had time to go through this. If so, he just texted saying he can hop on. Let me just answer that. Okay, so let's see if he can hop on. And then the other thing to cover was just testing updates. Let's give him a minute, see if he can join it.
00:24:19.090 - 00:25:47.764, Speaker A: Small question to discuss is we are all preparing some configurations and docker images for new Devnets and so on, but I don't know any proper place to post it all there. I mean, we have interrupt repository to start a private network, right? Not a Devnet for configs, are there? So maybe we could collaborate and post configurations and some cremages somewhere. So it would be start Barnabas, do you have any opinions on that? So basically just told me that I would not be responsible for this, but it would be Rafael and Sam that are actually going to the event and I will be just working from home. So they are going to be the one responsible for the Devnet? Actually, yes. Sam's already trying some local devnets, et cetera. And the idea is that the two of them will be there to help support you guys. Okay, but I guess that doesn't really answer your question, Lexa.
00:25:47.764 - 00:26:35.750, Speaker A: Like, where should the configs be shared, if I understand correctly? Yeah, I guess. Hang on. I think we might have already made a repo for this. Let me just check. The idea was to kind of stick to the same strategy we have eat panda ops withdrawal testnet, and we have four, eight four testnet configs that can be shared here. If someone needs access to push or maintain this repo, then let me know and I can add you guys. Same thing.
00:26:35.750 - 00:27:06.812, Speaker A: Cool. Okay. Yeah. Alex, you had looked at the pre compile and wrote down your thoughts. Shared that this morning. Do you want to give people a quick summary of your hackmd? Yeah, sure, maybe. Let me just also paste the link here.
00:27:06.812 - 00:27:35.080, Speaker A: Oh, I got it. I just pasted it. Okay. Yeah, so I actually looked into the pre compiler a while ago, probably last in September, and left a number of questions on it. Magicians. But now the reason I looked into it because I was wondering if it could be even implemented with EIP 25 37. The BLS pre compiles EIP.
00:27:35.080 - 00:29:08.470, Speaker A: And basically I started to write an implementation in solidity while only looking at the 4844 EIP description, and that turned out to be insufficient in order to understand what exactly the pre compiler is doing. So I ended up looking at the pyecc as well as the killic or killich. I'm not sure how to pronounce it BLS implementation. So I spent quite a bit of time in digging down to understand all the parts, how it can be implemented, and this second delist, my progress and my findings while doing so. And the outcome of this is number one, I think there are a number of points which could be clarified in the EIP in regards to the pre compiled .2 is it cannot be fully implemented with EIP 25 37, because there is one feature missing in the pre compiles to deserialize a g one point, and I looked into trying to implement it in the EVM itself, but I think that would be rather excessive. And then finally, sorry, I don't understand.
00:29:08.470 - 00:30:11.056, Speaker A: So you try to implement an EVM native version of the pre compile using BLS precompiles? Yeah. And why would that not be possible? I mean, that should be possible, yes. There's one feature which the precompile set is not including is the deserialization feature. Deserialization. It's also called decompression in some of the source codes, basically the commitment and the proof, if you want to turn it into actual points. There's a helper for that in most of the implementations, and doing that requires modular arithmetic operations to be implemented on top of the EVM, which you could. Sure.
00:30:11.056 - 00:31:16.150, Speaker A: Okay, so the BLS precompiled don't have point decompression. Yeah. Oh wow, that actually feels like something that should be added to them. But did you try to do that on the native evm? Is it just too expensive? I mean, it would be definitely, yeah, I think you could do it, because I looked at some of the implementations had these accomplished, and it definitely could be done. Probably price wise it wouldn't be horrendous. But there is a calculation in the HECMD which summarizes the cost of the 25 37 pre compile and the pieces which are needed for this. And if I only even just sum those up, the cost comes out at roughly 210k.
00:31:16.150 - 00:32:20.760, Speaker A: Okay, that's huge. Yeah. And the decompression I think would be natively in the EVM probably around like 200k. Interpolating from the pre compiled cost, probably decompression could be done around like twenty k. Twenty, thirty k. But there's also a number of places where byte swapping is needed from little indian to big indian, because the point evasion pre compile expects little indian inputs, while the PLS precompile expects big indian inputs. Is there a rationale for not including decompression of pre compile? Is it that it's cheaper to just provide decompressed elements in the data? Is that the reason? That will be the reason, right? Honestly, I'm not sure what's the reason that it was skipped.
00:32:20.760 - 00:34:11.856, Speaker A: I mean, obviously there was like a lot of debate around even the number of precompiles that contained this would be an extra two. But yeah, I mean there's a lot of notes regarding what could be clarified and yeah, I actually opened one pr already, but I'm going to open a number of other prs to the EIP just clarifying these points. And I also looked at trying to find some state tests for the execution layer, but I couldn't really find it. So I'm not sure how well the pre compile is tested, but I think some of the validation rules I collected based on the implementations, those would be like a good starting point for writing actual state tests. And I guess just on the BLS side, obviously they're not part of mainnet yet, so that's something we can modify, I guess. In terms of next steps here, do you think there's anything we should be doing? Alex? Yeah, so I think the first step, clarifying the current implementation details in the IP, that would be good, and I'm happy to help with that. But also it would be interesting to see where the current proposed pricing is coming from and even like the BLS pre compiles, whether they have accurate pricing.
00:34:11.856 - 00:35:22.056, Speaker A: And I think, you know, if, I mean given 4844 potentially going to go live like in six months, based on likely that's like ECD discussions, I think there may be a possibility to at least discuss the potential whether this could be done with the BLS pre compiles. I think at least there's time to have the discussion, but I'm not proposing at this point that that should be the way. Got it. Well, there is an argument against using the BLS pre compiles, which is that the idea of using the version hash is that in the future when we upgrade to new commitment scheme, the pre compile could be upgraded to automatically support that using just the version hash. And so smart contracts would not need to be changed at all. Like you could have completely static smart contracts that support an upgrade for the commitment scheme, and you can't do that if you use BLS pre compiles to implement this. Yeah.
00:35:22.056 - 00:36:00.810, Speaker A: The way I imagined if this would be using the BLS pre compiles is that it would be an actual preequid EVM code. Like this implementation. It would be placed into the state at the pre compile address. So instead of having people to implement it, there would be a given version which you could upgrade. I see. But that can be done transparently, right? Like if we were to go that route, then we can do that independently from. Yeah, I think the only.
00:36:00.810 - 00:36:52.616, Speaker A: Exactly. But the only blocker would be on that is the pricing, because there's like a discrepancy with the pricing currently. Right. Well, I guess it seems dangerous to not override the pricing when you do that, because then all kinds of things could affect the price. Yeah, I don't know. Alex, do you know where the rationale is for the current pricing of pairings, like for BN? Two, five, four? Because they look pretty overpriced the last time I checked, but I couldn't find where they were coming from. The BN or the BLS? The BN ones.
00:36:52.616 - 00:37:43.352, Speaker A: Because the BN ones should be cheaper than the BLS ones in terms of like pairings and stuff. Yeah, I think the BN ones were actually repriced a couple of years back, and they were repriced based on actual measurements at the time. I'm not sure if that was already the cloud flare implementation, but obviously all of this is really tied to the pricing and go Ethereum, right? And that's what the benchmarks are based around. Okay, sure. Yeah. I really don't have too much else to say. If there's like a channel or appropriate location to discuss this further, let me know, I guess.
00:37:43.352 - 00:38:32.472, Speaker A: Yeah, we have the 4844 testing channel on discord, so that's probably a good spot to have this. Cool. Thank you, Alex. I appreciate you jumping on the last minute. Okay, so I guess lastly, I wanted to check it if there's any updates on the testing side. Anything people want to bring up, if it's useful to anyone. I updated ZCUi to parse and transition eap Ford for data, so it's video up to date.
00:38:32.472 - 00:39:12.380, Speaker A: Both consensus changes for capella and well, DNA fort for nice. I've been doing some differential fuzing between CKZG and GokZG. No findings for the past like two weeks. I'll keep going. Cool. Thank you. Anyone else? And if not, I know the other thing we talked about last week was to try and have another run of the Gordy spam tests.
00:39:12.380 - 00:40:57.630, Speaker A: This didn't really happen. Is it worth trying to do that this week, or should we maybe hold off until interrupt? I'm curious, how are people feeling about that? How valuable is it to get another round done as soon as possible? We'd be interested in seeing the information on Gorely. We recently had some monitoring set up like Friday, so on the lighthouse side we'd be interested. Okay, any other team have thoughts on let's okay, let's try and get something done in the next couple of days just on Gordy and go from there. Anything else before we wrap up? This is Andrew again from Jess. Has there been any more thought given to getting an audit done of the rust version of KZG that Kev is working on? Because I'm hoping that we're going to be like I said, we're going to switch hopefully from CKZG to the rust version just so we can have the WASM compiled version of it available to our browser implementations of our code base. Is there any thought there, or should we really consider trying to figure out how to WASM compile the CKZG library for that? Because otherwise that limits our code to only running in node JS, which is fine, but we try to support the browser environment as well with our code base, so I don't know if there are any thoughts on that.
00:40:57.630 - 00:42:02.844, Speaker A: So the current audits are scheduled only for CKCG and GOkZG. I'm not sure right now if we can justify having a full audit for Rust KCG as well, just because it doesn't currently seem like there are any production clients wanting to use it that couldn't also use CKCG instead. So I don't know. Yeah, I mean there will definitely be differential fuzzing and all, but I don't know if there's demand from a production client then I think that might change. Okay, yeah, I think that's fine for now. Our code is not strictly always used in client. Obviously we do have a non production grade client, but our code will allow people to construct blobs and if we want people to build it, I don't know if there may not be a use case for really doing it in browser.
00:42:02.844 - 00:43:15.128, Speaker A: Right? But I mean, do you need an audit in order to construct blobs? Because the phase is used in production in some places? I mean, some people do use our code, but that's a different question, right? The question is what are the critical failures that could happen? I don't know if I can judge that at this point. I don't know all the use cases for blobs yet. Yes. The most critical things to me is always validation, where we don't, definitely don't want things to go wrong is like verifying blobs, as in the point evaluation, the blob verification, and then the point evaluation pre compile, and those really, if your software produces incorrect blobs, the amount of harm that you can do with it is very small. Right. You just produce an invalid transaction. So what? Like someone can go and fix it? Sure.
00:43:15.128 - 00:43:43.890, Speaker A: Okay. And that's said, unless Lighthouse was planning to use rust KZG for some reason, which I know that right now they're not. So that would be the other use case I could think of, since it's a rust based implementation. But I'm good with that. I just wanted to ask. Yeah, just a note on this thing, so I'm not sure what. By the way, there is more than one case g library and another one which Kevin is working.
00:43:43.890 - 00:44:41.060, Speaker A: I'm actually not sure what ECC library it uses, because the thing is that if you have a rust library that uses. So in our rust KZG, we have option to use different libraries, even the ones that are written in rust. However, if you use rust KZG, which uses, for example, BST, then you still end up with the same thing that you need to compile BST to WASM. And I'm not sure what is the state of that. Is it possible to compile BLst to WASM? Yeah, it is. Yeah. The rust KzG used to use arcworks, then it switched to the filecoins bLST wrapper, and it compiles to wasm.
00:44:41.060 - 00:45:11.372, Speaker A: Okay, if this, for some reason, by the way, did you check that? And it actually works? I currently use it. Okay, then it's good. Okay. So, yeah, that's all. Thanks. It should be fine, because if it's just c code, you just change the clang target to like WasM 32, and then it just works. Okay.
00:45:11.372 - 00:45:50.070, Speaker A: Because the small note for the ECC libraries that are implemented in rust, well, they are much slower. Like significantly slower, but at least you have rust, which could be safer or easier to paralyze or so. Right. Thanks. Yeah, I think that's mainly because the libraries like BLST, they have just better algorithms for field arithmetic, for example, just why they're usually faster. Yeah. Okay.
00:45:50.070 - 00:46:44.850, Speaker A: Okay. Anything else? Okay, and I guess you're all probably aware of this, but the KCG ceremony is live, so it's accepting contributions. It's still a pretty big queue, but we've already exceeded the biggest record for the number of participants. So hopefully in the next two months we can grow that even more and we'll then have a month for special contributions. And I think after that we'll likely just reopen it until we decide to go live on main net with four. Four. Four.
00:46:44.850 - 00:47:00.516, Speaker A: Yeah. So it's happening. 7.3 thousand contributions as of right now. Yeah. Cool. Do you know what the previous record was? It was like four point six k.
00:47:00.516 - 00:47:33.452, Speaker A: And maybe Proto or Denkrad can talk about this. Our ceremony previous record was 2600 contributions. Okay, so we've already far exceeded that. Yeah. I thought there was something Trent was saying around, like, because ours has less computation, the total amount of entropy collected or something. Might not be the record yet, but I'm not sure. I don't know what the total amount of entropy collected is.
00:47:33.452 - 00:47:54.084, Speaker A: Yeah, the number of contributions is already far exceeded. Any other ceremony? Yeah. Um. Yeah, so we'll probably get closer to 50k than the five k we were hoping for, which is really cool. Sweet. Yeah. Thanks, everyone.
00:47:54.084 - 00:48:00.020, Speaker A: I'll see you all on a quarter of two days from now. Thank you. Bye.

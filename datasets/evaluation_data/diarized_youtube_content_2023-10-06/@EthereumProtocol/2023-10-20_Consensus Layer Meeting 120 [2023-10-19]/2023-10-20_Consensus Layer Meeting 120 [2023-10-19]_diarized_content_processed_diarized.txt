00:07:09.950 - 00:07:57.414, Speaker A: Should be live. Hello, welcome to consensus layer. Call awkward Dev 120. This is issue eight nine two in the pm repo. I guess kind of as some of the last calls, dominantly just kind of checking in on, you know, testing Devnet analysis. If there are other discussion points, let me know when we get to the open discussion. Okay, so first of all, I believe most of the sensors devs probably saw that their v one 40 beta three is out in that is the main net KZG configuration, which is already baked into CKZG.
00:07:57.414 - 00:08:40.870, Speaker A: So I don't think it's much of a change for you to be able to use it. As well as an additional gossip condition that Enrico found essentially weren't properly bounding the blob index. It allows us to prevent spam of totally invalid messages from being passed around. Big shout out to Enrico on that. I think other than that, there are some additional tests, maybe a whisk update, but should be generally pretty good. And I believe that that configuration is to be used in Devnet ten. Does Devnet ten exist? Let's transition.
00:08:40.870 - 00:09:00.230, Speaker A: Or any questions on the consensus specs release. All right, cool. Let's jump into devnet update. First of all, does devnet ten exist? What's the status on that?
00:09:00.380 - 00:09:25.760, Speaker B: So we are waiting on client releases and some prs to be merged and we're hoping to launch tomorrow. Currently, the only image that we know that might work on Devnet Ten is Prism. No other El or Cl team has reported that they have a working image or a branch. Yeah, we don't need a full release, just a branch that we can use, that we can build.
00:09:31.730 - 00:09:32.880, Speaker A: What was that?
00:09:33.330 - 00:09:37.150, Speaker C: Are we supposed to use the new KCG setup for this devnet?
00:09:37.730 - 00:09:38.480, Speaker B: Yes.
00:09:40.290 - 00:09:52.690, Speaker C: So golan clients cannot, unless we coordinate among GokCG that it hasn't included these changes. Get and prism.
00:09:56.510 - 00:10:01.950, Speaker A: Okay, so it's not an outer kind of configuration. It has to be baked into GoKCG.
00:10:03.410 - 00:10:34.786, Speaker C: It's a problem with the way that we have dependencies. Gas depends on GoKCG and Prism depends on gas. So the way this needs to be updated is GoKCG needs to first make the changes, then guest needs to point to a master branch in GOKCG, then prison needs to point to that. And then GoKCG needs to make a release. Guest needs to point to that release, and then prison report needs to point to that. Yeah, we probably need to solve this. This is not maintainable.
00:10:34.786 - 00:10:37.000, Speaker C: Any change in GoKCG is a pain.
00:10:38.490 - 00:10:58.666, Speaker A: Yeah. One of the major intentions of Devnet ten is to use that setup. So I guess we're blocked. We could move forward and add Geth and prism, but yeah, for Ericon, we're.
00:10:58.698 - 00:11:03.890, Speaker D: Also waiting on Go KZG release with the trusted setup.
00:11:06.390 - 00:11:25.640, Speaker E: Got it on the lotus side and ethereum js side. I will release the node bindings by tomorrow and try to integrate it. But I think even without all this, we have the flag to run with a custom trusted setup, right?
00:11:36.090 - 00:11:36.550, Speaker A: Yes.
00:11:36.620 - 00:12:01.220, Speaker F: There's kind of two blockers right now for Devnet ten. The first one is the trusted setup, and the second one is the issues we saw on Devnet nine yesterday. We can, of course, go ahead with Devnet ten without acknowledging any of those issues. That would just basically be devnet nine, but bigger. Or we could wait until we fix both of them and then start Devnet ten at the cost of time.
00:12:02.710 - 00:12:11.380, Speaker A: These are the issues that Mario found in testing and then escalated to tests in the testnet environment, right?
00:12:12.710 - 00:12:13.780, Speaker F: Yeah, exactly.
00:12:14.310 - 00:12:29.020, Speaker A: Okay, so we know they would be hit if we do send a certain series of bad and good blobs in relation to each other, right?
00:12:30.030 - 00:12:33.340, Speaker F: Yeah, exactly. Yeah, exactly.
00:12:34.910 - 00:12:37.600, Speaker A: Mario, do you want to give us a quick on that, please?
00:12:38.290 - 00:13:28.442, Speaker G: Yeah, of course. So basically, we are using the new tool that we are using on Hive. So this thing is like a proxy that sits in between the beacon node and the validator client. We set it up yesterday on a devnet on a single client combination. So every time that this client combination proposed, what it did was basically just receive the unsigned block and blobs from the beacon node, and then it signed the block and the blobs. But it also created an extra, seemingly valid blob. So the only difference between this blob and the correct blob is that the KCG was correct, the signature was correct, everything seemed correct, but it was broadcasted to a different peer.
00:13:28.442 - 00:14:31.040, Speaker G: So basically, one peer had the correct blob with the correct KCG signature, and it can attest to the correct block, and the other one received this other incorrect blob. So what happened was, when the block was eventually broadcasted, the clients received the block, and the ones that received the incorrect blob, they were ignoring the correct blob. So at the end of the day, one side of the recipients that didn't prune the incorrect blob from their database, they were unable to follow the chain. This tool was configured this way, and it kept doing this every time there was a proposal from them. So this was what we were seeing yesterday on Devnet. We have a hive test for this, it's reproducible. So the clients can, if they want, just run this as many times as they want.
00:14:31.040 - 00:14:45.910, Speaker G: The hype test is very simple. It does the same thing every single slot over the course of an epoch. If there are too many missed slots, the test will fail. So they can immediately know if they have fixed or not the dish.
00:14:46.970 - 00:14:51.430, Speaker A: This is really exciting that this is in hive now. Enrico.
00:14:53.210 - 00:15:02.026, Speaker H: Just to clarify, you said that some clients have these blobs into database, but I guess this is incorrect. Should be.
00:15:02.128 - 00:15:05.194, Speaker A: That might be more of a cache, right, right.
00:15:05.312 - 00:15:24.450, Speaker H: So this is a thing that we discussed recently. So you kind of poison the client cache and the client is not able to recover because it's not even trying to look up by root another time. Is this correct, Mario?
00:15:25.590 - 00:15:34.070, Speaker G: Yeah, I'm sorry. My understanding was guess. I guess that is correct. It's not database.
00:15:34.970 - 00:15:39.720, Speaker A: It's persisted somewhere that prevents it from wanting to do the work again.
00:15:41.450 - 00:15:49.530, Speaker C: POTus, I just want to mention that this abstraction is better presented somewhere because in prison it is actually currently database.
00:15:50.590 - 00:16:00.880, Speaker A: We're not using a, I mean, and from the perspective of the test and where it gets both are coherent, it makes sense.
00:16:07.640 - 00:16:47.920, Speaker H: I think Tegu is not affected by this. We fixed this recently and basically we delete everything. And if the next block builds on top of the one that some of the network nodes seen as complete and good, we do then look up by route to everything. So we're going to redownload, block and blobs again, and we should be able to follow the chain with a bit of lag.
00:16:49.140 - 00:17:22.412, Speaker A: That makes sense. So you kind of protect yourself from doing way too much work in the single slot, but then use additional signal to catch up. Okay, Mario, so now that we have this additional ability to test both on the testnet and inside of Hive, do you have an updated list of what you intend to get there such that maybe some of the devs here could take a look at it and add or modify in any case?
00:17:22.546 - 00:17:49.684, Speaker G: Yeah, of course. I have a list of the test cases that we are doing in Hive, which is basically related to the possibilities of the blobber. There's a list of actions that the blobber can do and we can configure them in Hive. And this is basically the same thing that we are running on the Devnet. I can share the list. It's very simple. There are not that many solid actions at the moment, but we can increase that.
00:17:49.684 - 00:17:58.410, Speaker G: If there are comments from the devs that the stuff that you guys want to test. We can also include them. I will share the.
00:18:00.460 - 00:18:14.844, Speaker A: I'm again, this is awesome to get some basic networking testing in Hive. Enrico, Enrico, is your hand.
00:18:15.042 - 00:19:34.304, Speaker H: Sorry, sorry, I was in mute. Just want also to mention what we discussed during a nice conversation with Mario, which is related to this latest thing that Mario was talking about. So is it another condition in which a proposer, actually the proposer, if the block doesn't contain, is not full of blobs. So there is still a room of one or two blobs there. So he could play with these two additional slot, kind of creating a blob that is invalid and still related to the block and slot with an index that doesn't match any commitment in the block. So technically the data is available because all the data that is required by the block is available. But there has been seen by the node something additional that is incorrect for taco is incorrect just because we saw a blob with an index that doesn't match to any commitment in the block.
00:19:34.304 - 00:19:48.380, Speaker H: So what we do, and we do it on purpose, but I'm not sure if it is at the end, is a flow in the client. So we actually don't import the block.
00:19:52.640 - 00:20:00.400, Speaker I: Yeah, this is not necessary. I think the block would not be available in that case because it hasn't been committed to in the block.
00:20:02.740 - 00:20:08.832, Speaker A: But the block has everything it needs, so you have to import the block, otherwise that's going to cause.
00:20:08.966 - 00:20:21.750, Speaker I: Yeah, I agree, but I would just want to respond to the concern that they get free data availability. They don't, no, because there's nothing provable on chain that that data.
00:20:22.520 - 00:20:26.330, Speaker A: Correct. But it can be passed around on the p to P. Yeah.
00:20:28.540 - 00:20:59.392, Speaker I: The proposer can basically put some extra load on peer to peer. That is true, but they don't get any benefit from this. And they get a slight downside, which is that their block is slightly less likely to confirm because they increase their often risk because it has competition with the other blocks. So I don't see any reason why any proposer would do this.
00:20:59.526 - 00:21:22.250, Speaker A: I don't think Enrico is trying to make a claim that there's free data availability. I think he's trying to make a claim they can induce load on the p to P. And if we're doing different import strategies on this, it can cause a network split. And it's really important that we don't do different strategies on this. And it's really important that we import, even if you see invalid extraneous blobs, because somebody could easily not have seen those and do the import.
00:21:23.020 - 00:21:35.768, Speaker I: Right. What you could do is not attest to such blocks. That would be okay. But yeah, you should not like on a node level, you should not exclude them from the pork choice, otherwise you risk a split.
00:21:35.864 - 00:22:06.504, Speaker H: Well, I'm not saying that I'm not importing that anytime in the future. I'm just saying that I'm not importing that in that moment. So I'm going to test on the previous head. But if the next block again builds on top of it, then we just look up by root the data that we need and we actually not even realize that we're an extra blob floating around because we are not even requesting for it.
00:22:06.702 - 00:22:17.260, Speaker I: But we would at that point verify that all the blocks that are referred are available. Yeah, I mean, that seems okay, but maybe too much complication.
00:22:18.000 - 00:22:43.510, Speaker A: Yeah. A mixed strategy here is at least going to cause some clients to be more profitable than others in relation to such an error attack. Because some are going to attack. It depends on kind of if you sit on the majority or not, in terms of the attestation on whether it's going to come in or not. This is probably something that should at least have a note in the spec.
00:22:46.200 - 00:23:09.630, Speaker H: But I think there is also, well, assuming that there might be something malicious attached to this behavior, maybe there is no advantage to do that. But if taco is the next proposal, we're going to reorder that block. That's the thing.
00:23:15.200 - 00:24:07.150, Speaker I: If it has enough attestation, you can't. I would be much more careful with these things about reorgang a block because you are interfering in the fork choice rule and we don't want to normalize that. So anything like that, I feel like should actually be an agreement that we all have. I have a similar feeling about the other reorganate blocks thing, that it was a bit too hasty to just say it's okay if some clients do that. It seems to me something that affects the fork choice is something that we really need to have quite a strong agreement on, that we're okay with that because otherwise anyone else will also think they can also interfere with the fork choice in such ways. And that's just not.
00:24:10.100 - 00:24:40.504, Speaker A: Enrico, Enrico, to your point, this is much more dangerous for the local client than even this other fork choice reorg for late blocks, because you make yourself blind to the block and unaware of even the probability in relation to what you assume is going to happen in relation to the attestations you've seen by doing so, it seems strictly worse than just having it in your view.
00:24:40.622 - 00:24:53.710, Speaker H: Yeah, and moreover, we already know that probably we are the minority because we are probably the only one that does this if we know in advance this.
00:24:57.940 - 00:25:51.680, Speaker A: Right. I do think that a note about invalid blobside cars beyond the highest index of the commitment in the block should not invalidate the block. I think just an explicit note about that is probably pretty important, such that anyone reading the spec doesn't accidentally put themselves in a forkable spot. Again, barring knowing network distributions like not doing the import and then building upon what is prior and not having a view of attestations seems strictly just more dangerous than doing the import and knowing the knowledge.
00:25:59.950 - 00:26:43.046, Speaker I: Should. I also think this is much so. I also think this is much less important than say like the late block reorg. At least there is a gain that the proposer gets from this, which we kind of don't like, which is why we do kind of like punishing them in some way here. There is no gate. There is a potential slight load increase by a maximum of a factor of two, which we kind of say is like at least as a temporary load is okay anyway, because that's just the maximum of blobs. And so the attack vector seems very limited, like basically, oh yeah, nodes.
00:26:43.046 - 00:26:54.880, Speaker I: Bandwidth requirements will go up not even by a factor of two. And yeah, you don't really get any gains from that. I would say do nothing is the best.
00:26:57.010 - 00:27:28.450, Speaker A: I think I generally agree. I do think that anything in the play around additional blobs, these are just primarily like a vector for potential network splits, like sending invalid ones invalid ones at the same time sending ones in excess and potentially having people consider their block differently. These all hinder your ability to get a block in, but become strategies for split views.
00:27:28.530 - 00:27:46.366, Speaker H: Enrico, just another side comment. If this becomes something that we consider important, should we consider to introduceable events next work? At this point that would be the.
00:27:46.388 - 00:27:56.406, Speaker I: Correct way if we're actually concerned about it, but it seems very excessive to me in terms of the extra risk it adds for the gain it provides.
00:27:56.458 - 00:28:08.050, Speaker A: Here, the potential slashable event becomes more valuable probably for sending conflicting blob commitments than sending these extraneous blobs.
00:28:08.390 - 00:28:10.710, Speaker I: Sorry, what was the conflicting.
00:28:12.730 - 00:28:33.770, Speaker A: A valid and an invalid one for index zero double signing right now you just have these gossip conditions that try to do antidoss. We don't really have a crypto economic reaction to it because the consensus doesn't know anything about these sidecars. I think it's certainly worth having the conversation.
00:28:35.570 - 00:28:39.354, Speaker I: If we can get both of these into one slashing condition then it would be preferable.
00:28:39.402 - 00:28:44.446, Speaker A: Yes. Well, and if we were prioritizing, I.
00:28:44.468 - 00:29:10.086, Speaker I: Think slashing conditions are realistically very high cost, though, in terms of how deep the changes are. We have to touch the validate client, which we haven't really for a long time, and what risks they add, how that changes the cost benefit analysis for stakers and so on. But yeah, I mean, it's not out of the question.
00:29:10.268 - 00:29:32.126, Speaker H: I think the condition have to be two, because there are condition comparing two blobs, one blob with another blobs conflicting, and one is comparing a blob that is inconsistent with the corresponding block. So comparison between block and blobs and.
00:29:32.148 - 00:29:45.780, Speaker A: Comparison between blobs both could potentially reduce to being inconsistent with the current block. But that's a bit different. Right.
00:29:46.790 - 00:29:52.038, Speaker I: So then basically the cost of sending conflicting position commitments is not sending a.
00:29:52.044 - 00:30:14.214, Speaker A: Block, which is like a big opportunity cost. Yeah. The double signing is also much easier to make sure you're not doing in the context of a validator client, whereas making sure your signing is correct in relation to something is much more difficult and likely for error.
00:30:14.262 - 00:30:24.186, Speaker I: All right, I was thinking of going for the other one. I was thinking of only having it with respect to the correctness, with respect to the block.
00:30:24.378 - 00:31:30.820, Speaker A: Yeah, but that's intuitively a much more difficult thing for the small validator client to get correct. I think that there's some read on here on slashing versus not and some desire to do so and not. It's certainly a worthwhile exploration, but I don't think it's something we need to continue on the conversation today. Certainly when we had these conversations in Austria and after around blob decoupling, we did make the decision around using essentially our p to p antidos and peer scoring conditions to handle this. Obviously, if we've gotten more information around some of the issues and concerns here, we could escalate it to essentially do a crypto economic condition. Well, you do get the block eventually.
00:31:34.440 - 00:31:54.572, Speaker C: Yeah, I'm just talking about this thing of the peer scoring. We cannot downscore the peer that is giving us these bad blobs because we haven't got the block to check this. So this is a real problem here, that we have someone that is actively malicious and we cannot penalize it because when we find out that he was malicious, we already lost who this guy was.
00:31:54.706 - 00:32:11.350, Speaker H: Well, you could also track the peer that's sending you, but you could receive things from two different peers. So even if you track who is the sender of a given message, then you end up in the same situation. Yeah, I agree.
00:32:17.690 - 00:32:56.900, Speaker A: Right. Okay. In two relations, peer scoring in a lot of these scenarios is not possible. But the antidos conditions combined with the fact that it's not incentive compatible to get your block in is kind of what we're lying on here. If you send a bunch of these messages, it's very likely you just increase the likelihood of orphaning your block at the potential gain of view splits and compounding things in relation to view splits for gain. So that's kind of the trade off space here. Without adding a slashing position.
00:32:56.900 - 00:33:30.214, Speaker A: I can make an issue around this and toss it in the electra tracker, and it's something that we could potentially talk about as we move into that conversation. Are people comfortable with that, or is it something we need to continue to hammer on right now? Mario? Yeah.
00:33:30.252 - 00:33:41.302, Speaker G: So, pOtus, you mentioned that you want this documented. Where do you want for us to document this? What's the best place to document this for you?
00:33:41.436 - 00:33:56.720, Speaker C: Any place is fine. I think we're all in discord. Whatever. You put the few lines just to make sure that I understood the problem correctly, but it seems to me that tech one prism are acting exactly the same way. That also seems to me to be the incorrect way.
00:33:57.810 - 00:34:06.162, Speaker H: Yeah, I think we can discuss on the issue that Danny is about to open so we can maybe define the thing.
00:34:06.216 - 00:34:53.830, Speaker A: Yeah. So I'm going to make an issue around the potential trade offs around the DoS conditions here and flashings for a future conversation. I will make a pr about a note about not invalidating blocks. If you see invalid sidecars in excess of the index in the block in that pr, we can talk about if we want more explicit guidance than that. Cool. And I'll share both on discord so that people are aware once I pop them in there. Let me take a quick note about getting both of these in.
00:34:53.830 - 00:35:50.460, Speaker A: Okay, cool. Duncan, it might be worth at least putting your thoughts in the chat in relation to hotels's recent question. Okay, so we do have devnet nine. Currently we're moving marching towards Devnet ten with some of these known blockers. And Gojinder, you had some sort of analysis in relation to lodestar and Devnet nine on Twitter the other day. I didn't realize until you put the comment up this morning. Would you mind going through that and giving us some context?
00:35:51.840 - 00:35:56.832, Speaker E: Yes. So I basically, last weekend, when the.
00:35:56.886 - 00:36:05.090, Speaker A: Do you want to share your screen? I guess once you get to that point or share a link. Okay, thanks.
00:36:38.350 - 00:36:39.820, Speaker E: Is it coming through?
00:36:44.730 - 00:36:45.480, Speaker A: Yes.
00:36:49.150 - 00:37:45.870, Speaker E: Over the weekend when blobs were being spammed in the Devnet nine. So I collected some data around, got save arrivals of full block plus blobs. So basically blocks having one blob, two blob, three blob, four blob, five blocks having one blob, two blob, three blob, four blob, five, six blobs. And so these timings are pre any validation done on them. And what I did was basically, then plotted histogram and as well as the percentile scores. And basically this graph shows that how drastically blob, where the blob. Where there are six blobs in the block, how drastically, basically those arrival times are quite late.
00:37:45.870 - 00:38:36.520, Speaker E: So if we look at this metrics, which is the percentile scores of when the blob and blocks are fully available, even though these numbers look small, because it takes no time to produce a block on Devnet nine, because these are the only transactions that were being bundled over there. So we can see that where blob is equal to six, it introduces quite a large amount of latency. And we can also assume that all these nodes are in the same data center. So that latency is still not factored in. And basically this leads to my projection.
00:38:44.160 - 00:38:45.500, Speaker I: What projection?
00:38:50.480 - 00:38:53.410, Speaker E: Wait a second. I am not able to move this bar.
00:38:56.100 - 00:39:08.100, Speaker I: So this is import times. This is when the block is actually recognized. Is there any significant delay from having seeing them on the network?
00:39:09.080 - 00:40:04.806, Speaker E: Yeah, so 1 second, I'll just take you over the projections. So these are the blob projections that what I did was I took a lodstra node for the main net and basically calculated its percentile scores for various arrivals of the block. And the column that you see for blob is equal to zero. Those are the actual percentile scores that might not saw for using loadstar. And then I added the diffs of the latency that I got there. With respect to the baseline blobs is equal to zero to give a nave projection. So if I add the extra latency that has been introduced and if I look at this 95 percentile score, what.
00:40:04.828 - 00:40:07.800, Speaker I: Do you add it to? What do you add your latency to?
00:40:08.590 - 00:40:14.810, Speaker E: I add my latency to the current latency of blocks that I see on my node.
00:40:17.150 - 00:40:31.918, Speaker I: That doesn't seem like the correct thing to do though, because there are things happening concurrently here. Like these blobs are not. It's not like once your node has done everything that it does now, now they propagate the blobs, right?
00:40:32.004 - 00:41:05.930, Speaker E: But if we look at the original, what I have done is that these scores are respect to the actual blobs latency that is observed on Devnet nine. So blobs is equal to zero is basically when you see a block with no blobs. And if there is a significant diff between, blobs is equal to zero and blobs is equal to six. That means that increasing the number of blobs is adding to the Latency.
00:41:09.030 - 00:41:16.342, Speaker H: And this is pure network latency. This is not considering any. Yeah, right now blocked import, right?
00:41:16.476 - 00:41:17.160, Speaker E: Correct.
00:41:18.330 - 00:41:37.158, Speaker I: Wait, so that's what confused me. That's what I just asked. If this is after. This measures when you actually import. Like when your client actually says, everything is done. Now I have a block. Or is it when you saw them.
00:41:37.184 - 00:41:44.350, Speaker E: On the network is as soon as my node saw this. And this is pre processing.
00:41:45.330 - 00:41:46.080, Speaker A: Right.
00:41:47.490 - 00:41:57.310, Speaker E: So that's what I did. Basically, I added latency to the actual latency that my node is seeing and did a nave projection.
00:41:57.390 - 00:42:04.070, Speaker I: I do not understand why the blobs are arriving after the block then, because we're propagating everything in parallel.
00:42:06.970 - 00:42:37.374, Speaker E: So blocks can arrive at, or it can arrive before or at anywhere between or after. I mean, it's not really following a particular order. But what I am saying is that blobs is equal to zero is the baseline that I am matching with the latency that I am seeing on the main net today. And whatever is the diff. For example, blobs is equal to six, minus blobs is equal to zero. So whatever is the diff. I added the diff.
00:42:37.374 - 00:42:44.180, Speaker E: So basically I added the extra latency introduced in my projections. I mean, it's a naive way to do it, but that's what.
00:42:48.390 - 00:43:05.558, Speaker I: To. Because something Anska already commented in the thread, these are more than the main net latencies we saw from actually just adding extra data to the block. So it feels like something can't be right about this.
00:43:05.644 - 00:43:08.600, Speaker A: Granted, these are 95% and 98%.
00:43:10.410 - 00:43:13.000, Speaker I: Right, I know, I agree.
00:43:13.610 - 00:43:17.840, Speaker A: Which some of much smaller than some block. Yeah.
00:43:24.050 - 00:43:38.580, Speaker E: I can't claim that this analysis is comprehensive, because obviously it has not been done over multiple nodes and multiple network conditions, but some other client team can sort of reverify and recheck all this. That would be nice.
00:43:43.050 - 00:44:15.086, Speaker A: I do think it would definitely be valuable to get such data from another client. I mean, we did see, with our main net experiments with using these kind of events, some wide disparities across clients, but yeah, also, Docker, I'm not 100% sure that these tails are much different than what we saw in Mainnet, because we do have tails in excess of the 4 seconds. But by and large, in most cases seeing them pre 4 seconds, we didn't.
00:44:15.118 - 00:44:27.030, Speaker I: See large drops adaptations though, which like if we saw this beyond 4 seconds, we would have seen like not at below 1 mb blocks.
00:44:27.930 - 00:44:28.680, Speaker A: Right.
00:44:30.970 - 00:44:54.074, Speaker I: So it doesn't feel like this data can be correct, is my feeling. I mean, I'm happy to recheck what exactly I felt with on what we had there. I think we can still find the dashboards, but I feel like also the way of computing these is overly pessimistic, because it seems like it makes the assumption that blobs are not propagated in parallel.
00:44:54.122 - 00:44:54.960, Speaker A: In a way.
00:45:05.570 - 00:45:17.634, Speaker E: I mean, it's not really making that assumption, because what it's doing is that it's actually comparing the data that the node is seeing on blobs. Blobs is equal to six and comparing it.
00:45:17.672 - 00:45:29.430, Speaker I: So what is the baseline latency on this testnet for blobs that are with zero block blocks? With zero blobs, what's the baseline latency? Because you said you normalized it to 0 second.
00:45:30.090 - 00:45:49.470, Speaker E: Yeah. So baseline is present in the data itself and I think 1 second. So you get 95 percentile within half a second, and then you get 98 percentiles with zero point 65 seconds.
00:45:51.730 - 00:45:52.286, Speaker A: Right.
00:45:52.388 - 00:46:20.440, Speaker I: Which is much lower than Mainnet, which you kind of have to take into account, because this time is still available on main net to propagate blocks. Like if this is like, I don't know, 2 seconds or three, I don't know what the exact number is on main net, then during this time blobs can still propagate, assuming Mainet is not saturated with in bandwidth. I don't know if you see what I mean.
00:46:20.890 - 00:47:00.870, Speaker E: The analysis that I have done on some of the main net blocks, for example Lordstar missed on. So I have done these kind of analysis, and I see that generally the proposal is published after 2 seconds, because by one and a half second you get blocked from either execution or from the MEV itself. And then basically you sign it and then you propagate it. So by the time you end up propagating, it's already more than two plus seconds. And that is what loads are. Node also shows that that is the latency that the loads are node is seeing on the main net blocks.
00:47:03.050 - 00:47:03.800, Speaker A: Yeah.
00:47:06.970 - 00:47:23.020, Speaker E: So right now, in this particular definite nine, we can assume that all that time is squished to zero, is squished to whatever blobs is equal to zero. So whatever is additional latency will definitely add up when the blobs will also surface on main net.
00:47:26.290 - 00:47:59.880, Speaker I: I strongly disagree with that statement. You cannot just add this when we're explicitly doing things in parallel. It's not like because what you're saying is basically, oh, currently blocks take 3 seconds to propagate and now we're adding the blobs and that's another like 1 second or something when in reality all of them start at time zero. And yes, the blocks takes longer and maybe the blobs take longer, but they're still in parallel, so you still can't add these things.
00:48:00.410 - 00:48:21.338, Speaker C: Are you sure they start at second zero? Dankrad. Because most blocks come from the builder and I don't know how the builder path is going to be on disseminating blobs. There's a big latency now in actually negotiating with the builder. So if the builder actually is going to be starting to send the blobs later, then I think your point is no longer valid.
00:48:21.514 - 00:48:44.882, Speaker I: That I agree with. And we can also like it might be possible that people are playing latency games already. Well, we very likely know that some people are, but these are economically incentivized. So these people will, if they see that now they are missing blocks because they're sending blocks late, they will just have to decrease their latency.
00:48:45.026 - 00:48:46.742, Speaker A: If it's that, and to be fair.
00:48:46.876 - 00:48:54.274, Speaker I: The difference between technical negotiation process, then I agree with you. But it doesn't feel to me like that takes 2 seconds.
00:48:54.322 - 00:49:03.770, Speaker A: That seems very and there might be some fixed latency added from there, but that's not the same as the latency added from the parallelization of the network dissemination.
00:49:05.950 - 00:49:57.840, Speaker E: Yes. So towards that argument where we are saying that the blobs should alive parallel, but that is not something that we are seeing in Devnet nine, because there is a huge disparity in latency between blobs is equal to zero blobs and blobs is equal to six blocks. So maybe we need to look at the clients or we need to look at the implementations where the blobs are not being transmitted in parallel, or they are being transmitted one by one. I think so it would be, yes, definitely nice whether a second client can sort of confirm my observations, and it would be nice if all the blocks, if there is a very little discrepancy between blobs is equal to zero and blobs is equal to six column indefinite nine itself, then I can sort of agree with you that things will happen in parallel and it will not really add to a different latency number over there.
00:50:04.540 - 00:50:17.230, Speaker A: I don't think Dr. Point is that there won't be additional latency for full gathering of information if you have three verse six. But it shouldn't necessarily be like a strict layer relationship.
00:50:20.510 - 00:50:23.762, Speaker I: Yeah, just adding it just seems overly pessimistic.
00:50:23.846 - 00:50:25.120, Speaker A: That's what I say.
00:50:27.490 - 00:50:28.240, Speaker C: Right.
00:50:29.010 - 00:50:38.100, Speaker E: But we should basically do an experiment and sort of figure this out. I think at least that this experiment warrants at least this much.
00:50:38.870 - 00:50:54.006, Speaker A: Right, I agree. Especially getting another client to gather similar data and for those that are gathering it to think about if the current presentation and extrapolations make sense or if we want to modify some of that.
00:50:54.028 - 00:51:24.640, Speaker H: Enrico, currently Teku is not able to show the arrival time of the gossip message, the actual one. So we are adding a little bit of latency there. But we are working on gathering the exact arrival of the message down from the p two p layer. I don't know if there are some other clients that are currently better showing these arrival times.
00:51:29.130 - 00:51:42.430, Speaker A: And Powan said he's going to try to gather some data on Lighthouse by tomorrow, which is great. Are we still spamming blobs though in the same way on Devnet nine or do we need to turn that back on for this data analysis, data gathering?
00:51:45.490 - 00:51:51.600, Speaker B: I don't think we have blobber running right now. We turned it off because prism had.
00:51:52.530 - 00:51:58.560, Speaker F: No, that's not blobber. We have Marius's transaction flops memo running.
00:51:59.750 - 00:52:09.922, Speaker A: Is Prism still borked? Okay, so probably be good to get Prism back into the fold so that I just updated.
00:52:09.986 - 00:52:12.454, Speaker F: Prism gets one. So I'll have a look at how.
00:52:12.492 - 00:52:15.414, Speaker C: You run that pr. It should be fine.
00:52:15.612 - 00:52:21.980, Speaker F: Yeah, I just ran it on Prism gets one. I'm validating if it's fine. And if it is, then I'll run it on the rest of them.
00:52:22.510 - 00:52:25.370, Speaker A: You also need to resync the DB.
00:52:26.350 - 00:52:32.830, Speaker C: I don't think so because we never imported those blocks. So it's going to remove the blocks from the DB.
00:52:35.250 - 00:52:36.014, Speaker I: Oh that's right.
00:52:36.052 - 00:52:36.640, Speaker A: Yeah.
00:52:37.890 - 00:52:41.120, Speaker I: But we need to do that for initial syncing, right?
00:52:47.020 - 00:52:48.650, Speaker C: Yeah, that's probably right.
00:52:52.010 - 00:52:56.140, Speaker F: You can Fsh into prism gets one and have a look at what it's doing.
00:52:57.230 - 00:52:59.580, Speaker A: That sounds good. I will look into this.
00:53:02.530 - 00:53:35.800, Speaker H: Another thing. We can still gather some data from Teco, maybe are not super accurate, but could be worth to have. So when you run Perry this session, if we can enable those famous logs, maybe you can ping me and so I can grab all these logs and already have some toolings and scripts that crunch this data and put it in a spreadsheet so we can do some analysis on our side as well.
00:53:37.930 - 00:54:11.930, Speaker F: Sure, I can run that, but in the meantime, do have a look at the Grafana dashboard here if it's something we can modify in the dashboard directly, because we're listening to the event stream and we're adding how long blob sidecars are taking to propagate and how long the blob associated with a block has taken to propagate as seen by each of these nodes.
00:54:22.060 - 00:55:39.090, Speaker A: Okay. Any amount of additional data and additional perspective on how to parse this data would be super valuable. I would recommend, in the event that we do collect a bit more data, to pop this on the ACde call for at least a quick look next week if we do have additional data to look at, because obviously safety of propagation of data in a relatively small environment is very important. Any other comments on blob data load in relation to devnets or testnets or main net before we move on today? Great. Thank you guys. So generally the big things to further talk about if anyone has anything, is anything in relation to Devnet, anything in relation to testing anything in relation to NEB for today?
00:55:42.740 - 00:56:00.230, Speaker F: Just wanted to clarify the conditions for Devnet Ten right now. Do we just wait for the trusted setup file and as soon as everyone's updated that we roll out Devnet ten? Or do we want to wait for further changes on collecting data on Devnet nine or figuring out a slashing condition or whatever it is?
00:56:02.200 - 00:56:52.810, Speaker A: No. So definitely on slashing conditions. That is not part of the DNEB conversation currently. As for the clarification around invalid blobs in excess of the index and block, that will be like a probably small conversation in the specs repo that might modify a little bit of behavior in some of these extraneous scenarios, but I don't think we need to wait on that. I would want to see a fixed prism, which it seems like we're on the border of having that. So I would put the main blockers on, getting the set up in place everywhere and making sure prism works over the next hour. Sounds good.
00:56:54.060 - 00:57:07.180, Speaker B: In order to have a launch tomorrow for Devnet, then we would need to have working branches. For most clients though, is that something that we could get done probably by end of today? So we can start that thing tomorrow?
00:57:17.300 - 00:57:19.730, Speaker A: Yeah, for Lighthouse we can do that.
00:57:23.320 - 00:57:31.430, Speaker C: It looks that for prism it's going to be very easy. Light client already posted a branch with the changes needed and our changes are very small.
00:57:36.500 - 00:57:47.132, Speaker A: Okay, can anyone not meet that with.
00:57:47.186 - 00:58:07.890, Speaker B: All the client teams, please leave a comment in interrupt regarding which branches we should use or which latest images we should use. Then we can start working on it tomorrow morning and possibly make a launch around noon or 01:00 p.m. Central european time.
00:58:10.500 - 00:58:30.520, Speaker D: Sorry, a question about trust setup because we could have an Aragon version without waiting for a go KZG release, but I would prefer a go KZG release so that we can switch to a released version of Gokisg for the trusted setup.
00:58:37.970 - 00:58:52.580, Speaker C: I don't think GoKCG can release. I don't know if Kev is here, but he was explaining that if GoKCG releases then it would break Gaff until gas actually points to the new changes.
00:58:58.020 - 00:59:05.680, Speaker D: So there is some kind of weird infinite dependency between Gok and gas.
00:59:06.200 - 00:59:34.470, Speaker C: So the problem is that Golang is going to think that there are breaking changes. And if you update GOKCG then with a release, then if you download geth, Golang is going to pull the new changes from GOKCG and those are actually breaking changes. This in turn also breaks prism.
00:59:36.190 - 00:59:39.260, Speaker B: We had the other trusted setup. How did that work?
00:59:41.070 - 00:59:42.060, Speaker C: I'm sorry?
00:59:42.750 - 00:59:49.920, Speaker B: We had a previously working trusted setup that was not the real data and that did not break anything.
00:59:50.530 - 01:00:23.750, Speaker C: Yeah, but the thing is that now these changes are actually breaking changes, but Golan, since they're both pre version one, Golan will not recognize them as breaking changes and it will automatically update for a new release. So anyone that downloads the gas repo and tries to build is going to build a broken client. There's a channel, I'll link a discussion in the RNG with an explanation from Kev.
01:00:25.070 - 01:00:39.850, Speaker D: It sounds strange to me because in go you can fix a specific version of your dependencies in Go mode, right? So I don't quite understand why you can't do that with Prisma.
01:00:40.930 - 01:00:47.040, Speaker C: Yes you can, but that's the thing that then we need to coordinate the three clients to actually have these changes.
01:00:49.570 - 01:00:57.700, Speaker D: But does Gok depend on Geth or Prism still?
01:00:58.070 - 01:00:59.700, Speaker C: No, it's the other way around.
01:01:19.950 - 01:01:27.660, Speaker A: Okay, can we take any additional particulars around this dependency issue outside of the call?
01:01:31.500 - 01:01:32.490, Speaker D: Yeah, sure.
01:01:41.180 - 01:02:31.170, Speaker A: Anything else on Deneb today? Any other discussion points on anything today? All right, get those images and branches to Barnabas DevOps team and we'll keep moving. Thanks everyone. Talk to you soon. Bye. Thanks everyone. Thank you.

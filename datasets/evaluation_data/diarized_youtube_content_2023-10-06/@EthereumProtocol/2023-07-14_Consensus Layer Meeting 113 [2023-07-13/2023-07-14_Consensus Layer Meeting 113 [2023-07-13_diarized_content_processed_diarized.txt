00:00:18.500 - 00:00:53.490, Speaker A: I'll put the agenda here in the chat I'll be moderating today, and it looks like the agenda itself is pretty short. So, yeah, I guess we'll just go ahead and dive in. The first thing would be updates on testnets, testing, development of different things for dnub. So I know we have been working on Devnet seven, and there might have been some chatter about Devnet eight. Does anyone here feel compelled to give an update or would like to?
00:00:55.400 - 00:01:23.212, Speaker B: Yeah, I can go with the update. So we've had Devnet up for a while now. It's mostly stable. We have almost every client combination represented there. I think Ergon's yet to be added, but that's the biggest one that's missing. There's an issue tracker. I will share the link in a little bit where we're tracking the different state that each client is in.
00:01:23.212 - 00:02:02.490, Speaker B: We also have a bunch of open issues there. Once we're figuring out the root cause and this batch, we also just update the issue tracker. In the meantime, anyone who's working on tooling for 4844, please feel free to test it out against this. Devnet blob scan has been updated as well to include data from 4844. I think we have something like 9000 ish blobs at this point, and this is still as of yesterday, but there's like a blob spammer and there's like a whole day's worth of blobs that should be indexed at some point, I guess. And we seem to be doing okay there.
00:02:06.060 - 00:02:26.448, Speaker A: Cool. That's exciting to hear. Do we want to just briefly touch on Devnet eight? I think that was the one that was slated to have, like, the full cancunab eip set, but maybe we're not quite there. Go ahead.
00:02:26.614 - 00:03:10.590, Speaker C: Quickly. Before we go to definite eight, one thing I noticed on definite seven was when I let my lighthouse gas node full sync and it got really slow just when it arrived at the head. So it would be nice if all clients could check their performance. Performance right around the head. I think the issue was that needed to download all the blobs and verify the blobs of the most current blocks. So it would be nice if other consensus clients could test that on Devnet seven already anyway, sorry, definite eight more?
00:03:12.820 - 00:03:13.520, Speaker A: Yeah.
00:03:13.670 - 00:03:37.204, Speaker B: So the link for the devnet eight specs are there. Either barnabas or I will try and make sure that it's up to date over the next days. But the idea is that we want to first have hype tests looking good, and then we want to be able to run like a local testnet, and then we'll spin up devnet eight. So I think there's still like a couple of phases before we're ready to coordinate.
00:03:37.252 - 00:04:15.080, Speaker A: That got you. That makes a lot of sense. Cool. Okay, so sounds like maybe we want to look at performance on seven if your clients near the head, and anything else anyone wants to bring up right now for Devon seven, the forward syncing is still possible till next week, Tuesday, and then after that we're going to be outside of the period. Then only checkpoint sync will be available. So if you want to check something with syncing from Genesis, you have like a few more days to do.
00:04:20.120 - 00:04:30.910, Speaker B: Also, if some client has an archive flag where you just never delete blobs, I think that's the perfect time to be testing it. And if you don't want to test it, let us know and we'll test it.
00:04:43.620 - 00:05:12.520, Speaker A: When you said forward sync, you mean with blob expiry? Yes. Okay, got you. Yeah, I mean, that's actually a good thing to see live, see how it works. Once we go through that first window. We done it in devnet six, I think. And from that point on, you have to do checkpoint sync. Otherwise you would not going to be able to sync anymore if you don't have any archive nodes.
00:05:12.520 - 00:06:06.390, Speaker A: Okay, well, so yeah, client teams who are listening take note. And yeah, otherwise it sounds like things are moving along. So that's exciting to hear. Next up on the agenda, we have this note about continuing the p to p discussion. I think it was the last four at four four implementers call. We essentially had this note around gossip sub the p to p and part of how this works. So my understanding is that basically there's like a flood sub mode that kind of runs by default, and there's some concern that it will slow performance of things once we add the much bigger messages with the blobs.
00:06:06.390 - 00:06:21.900, Speaker A: Does anyone here have anything to add? I know, I think some client teams are looking into this feature. Maybe if it could be enabled or disabled more granularly than it could be now. Different strategies around publishing and things like that.
00:06:30.090 - 00:06:34.186, Speaker D: So I was hoping to catch up with Adrian from our team before this.
00:06:34.208 - 00:06:36.620, Speaker A: Call, but he's off this week.
00:06:37.630 - 00:06:54.714, Speaker D: I did a little bit of digging though, and I found some work that he and Akihito from our team had done around this, and they had made an implementation of a smarter flood publishing.
00:06:54.762 - 00:06:55.630, Speaker A: Strategy.
00:06:57.430 - 00:07:13.670, Speaker D: In Russell at p to P, and had seen a 30% improvement on latency in publishing for messages at around 50. That's just like a bit of the scale context.
00:07:17.840 - 00:07:40.710, Speaker A: Cool. Yeah. As I understand, this isn't a blocker for, but definitely something that we'd like to ship at some point sooner rather than later. Yeah, sounds like we can maybe just wait, see if h has anything to add. Any other clients thinking about this or have looked into this issue?
00:07:44.730 - 00:08:23.220, Speaker E: Actually, we have a list of improvement that we want to do with gossip sub protocol, but we are discussing that the first thing that we can do right now is to disable the fat publish because actually we can still enable the fat publish and change how it works, but that requires the sharing, right? It require the patch. We can just disable it right now because it's the fastest thing that we can do and we can improve the fast publish protocol later.
00:08:30.340 - 00:09:03.684, Speaker A: Okay, sounds good. Sounds like that might be it on this lip to p topic, so we'll just keep moving through the agenda. Next up is this estar upgrade name? Let's see. This is this comment here. So yeah, we are here. We have enough visibility into the next hard fork that we can start to think of a name. The El fork will be called Prague.
00:09:03.684 - 00:09:35.170, Speaker A: Following our scheme and following our CL scheme, we would like to pick a star in this universe, or maybe not even in this universe, but some star. And the name should start with an e. So I'm just looking at this comment. It looks like there's an Eth magicians post here. People like Electra. It says Danny liked Enif. Danny is not here though, so I'm not sure how strongly he feels about that.
00:09:35.170 - 00:10:27.690, Speaker A: I'm assuming this is Evan van Nas suggested AI. There's a couple different posts here, so yeah, I don't know if anyone wants to chime in their opinion, but we're not going to spend much time on this, at least synchronously. I'm seeing a bunch of electras in the chat uniform electras. And we can call it electrog. Thank you, Guillaume. So anyway, I suppose if you really want to chime in, I'll put these posts here where there's been some other discussion. Although it seems like people here really like Electra and yeah, maybe we'll just go ahead and assume that.
00:10:27.690 - 00:10:50.380, Speaker A: And if we all say it, everyone else love to say it as well. Cool. Thanks everyone. Eip. I'm looking at this next agenda item comment. I don't know where we're talking about this. Well, okay, interesting.
00:10:50.380 - 00:11:12.100, Speaker A: Has anyone thought about eips? They would like to get in for this next work. Then this is on the agenda. I think Danny probably added this. He linked to 7002. So I think that. Oh, sorry, there's a few more down here. So 7002, execution layer, triggerable exits, 6110, which is.
00:11:12.100 - 00:11:48.080, Speaker A: I think this is moving the deposits, like reworking how the deposits work. There's 7251, the max effective balance proposal. I don't know if Mike is on the call, but that's something he's been working on. Okay. I think Danny put this on here. He just wanted people to be aware of this. And if there's anything else that you would like to start to get into the discussion, especially with respect to the Cl or any cross layer features that would also involve the Cl, go ahead and add them to this issue.
00:11:48.080 - 00:12:20.540, Speaker A: I'll drop the link in the chat. There we go. Vertical and BLS. Yeah, those would be nice. So there's some chatter in the chat around some other ones, but I'll just let that be for now. Point being, start thinking about it. Presumably we're shipping Dinkun very soon, in the next couple of months, and we will get to decide at that point we'll get to think about what comes next.
00:12:20.540 - 00:12:53.582, Speaker A: So that's for that. And next up we'll just move to general, more like research spec topics. One is here, I think, from Matt, who wants to talk about web three signer standardization. So I think basically there is a standard for this API and maybe. Let's see. Is Matt on the call? Yeah. Do you want to give us an overview of this?
00:12:53.716 - 00:13:57.314, Speaker D: Yeah, sure. So the goal here is to basically standardize a remote signing API similar to the rest of the APIs that we have in the specifications. The reason being is that there's traction around remote signing and integration with clients and all these other things that we're working on, we want to make sure that it's pretty easy to integrate essentially remote signing into the consensus layer clients. So the goal of this is to take what we already have in web three signer, basically clean it up a little bit, and then put it out for kind of a comment and feedback period. And then whatever we decide as a community, we will basically standardize back into web three signer. And then of course going forward we can maintain that against new forks, new functionality, and we'll be working out of that kind of standards repo, as opposed to just setting a standard within the product itself. Yeah, basically the goal of this was just to bring attention to it.
00:13:57.314 - 00:14:30.720, Speaker D: We're going to work to open up a repository in the Ethereum, GitHub for these remote signing APIs. And when that's done. We definitely want a little bit of feedback and comments to make sure that we have a pretty reasonable view of the API. And then again, it's intended to be long lived. And we'll continue to update it through hard forks and through spec changes so that when clients go to integrate remote signing, they don't have to go through a lot of headaches with web three signer, they can go straight to the standard. So that's pretty much it.
00:14:34.020 - 00:15:02.040, Speaker A: Cool, thanks. Yeah, I mean, I think that makes a lot of sense. It seems like an API that has a good amount of adoption. So the general strategy of making it a little more polished and kind of more formally supporting it, I also think it makes a lot of sense. So yeah, thanks for the notice. If anyone's listening and you rely on this, take note. And yeah, come back when there's an update on the API.
00:15:02.040 - 00:15:27.820, Speaker A: Okay, so next thing on the agenda, there's an issue from Daplion. Actually this is a pr, so let's see, is dapline here. I'll just let you take over, otherwise I can give a little summary as I understand.
00:15:27.890 - 00:15:28.812, Speaker F: Yes, I'm here.
00:15:28.946 - 00:15:29.950, Speaker A: Okay. Hey.
00:15:32.560 - 00:15:58.964, Speaker F: The background of this proposal is that as you know, different items of the roadmap, most, namely SSF, are much higher to deliver if we have a big state, a large count of indexes. So we have different proposals floating around to deal with it. If we don't deal with it, we need different crypto and other stuff that is good proposals around this.
00:15:59.082 - 00:15:59.460, Speaker A: Anyway.
00:15:59.530 - 00:16:47.990, Speaker F: So the point of this proposal is we could very easily, for Denep, potentially limit the churn. It's questionable if it's positive for Ethereum and it's positive to have such a big count of indexes. So we could limit the churn and then buy us some time to deal for the electrofork for a more proper solution like limit increasing max FXD balance or having some in protocol consolation. So this would just cap the max churn so that we don't find ourselves with a 2 million validator count in about nine to ten months. Yeah.
00:16:54.600 - 00:17:37.136, Speaker A: Okay. Yeah. I mean, it's not a wild option. I do have to wonder if we were to do this, it does kind of marginally affect small stakers more just because essentially you're capped now, everyone slows down in terms of exiting and it seems like if you have more validators, then that's more or less of an issue for you. But yeah, on the other hand, we don't want the set to be 2 million invalidators like you said, yeah. I don't know if anyone else has had a chance to. Look, this is something we could do.
00:17:37.136 - 00:17:39.990, Speaker A: I don't have a much longer opinion on it at the moment.
00:17:41.640 - 00:17:50.330, Speaker F: So I'm aware the discussion is for electra, but this could be considered for. I don't know it has that much of a use case.
00:17:52.540 - 00:18:05.950, Speaker A: Yeah, it seems like because we don't want to be changing the dynam schedule this late in the game, and I do kind of agree that it might not matter as much if we can't do it that quickly.
00:18:08.810 - 00:18:20.650, Speaker F: So I would say technically, this is a very simple change. Probably just a couple of lines on every single client. I think it's most about getting it right in terms of security and political implications.
00:18:25.030 - 00:18:43.848, Speaker A: Those are important concerns. Hodis, you have your hand up. Are you talking POTUS? Can anyone hear him?
00:18:44.014 - 00:18:45.624, Speaker F: I hear something very.
00:18:45.822 - 00:19:30.770, Speaker A: Yeah, it's like really tiny. Okay. Yeah, try that one more time. Yeah, now it should work. All right. The issue that I find is that since this involves a political discussion, and it's very unrealistically that's ever going to happen, that we're going to get into consensus on this by the net. And since this seems like a very simple change that we could actually put in just purely consensus hard work, that we can just ship quickly.
00:19:30.770 - 00:20:23.650, Speaker A: I'd suggest looking into other alternatives, and if we don't find anything, we can just ship this. I would prefer, personally, to use a different pr from Dablion. I would prefer that we actually compromise ourselves to quickly ship the reuse of indices with this. We could just think about this Max EB increase, because that would certainly allow us to reduce the number of validators quickly. And I think that's a cure more than just, as Danny put it, as a band aid. Yeah, I tend to agree. I mean, this is something we can do, and it's almost know, if we found ourselves overnight in a terrible situation of too many validators, then yeah, we could think about this.
00:20:23.650 - 00:20:53.550, Speaker A: It doesn't seem so urgent. We need to do it in the next couple of months, and then when we're on a longer timescale, we have other options to think about as well. So it's more just probably a process of considering all the different trade offs of these different options and picking the one we like. The don't. It doesn't feel like we should be thinking about changing the schedule now. If anything, we should just be shipping de like in the next couple of months.
00:21:00.150 - 00:21:07.060, Speaker F: So I don't think it's realistic to think that we will ship so fast that hope I'm proven wrong.
00:21:10.070 - 00:21:47.360, Speaker A: What I do think is that we need to lose the fear of having consensus layer only forks so that we can actually deal with these issues. I don't know if there's like fear, it's just like even if we do a Cl only fork, it's just so much overhead. Like even for just the Cl doves on the call. Right? So it's just not something to really take lightly. But certainly if we got to an issue, if everyone was convinced that the network is going to be in a really bad place soon, then we could have a Cl only fork soon. It doesn't seem like we're quite there yet, or anywhere near it really.
00:22:03.080 - 00:22:09.720, Speaker F: I guess just to test the waters now we're here, is there any strong opposition from anyone on the idea of capping the churn?
00:22:16.620 - 00:22:31.950, Speaker A: The only thing I would say is if we're doing something in parallel, like for example, max effective balance, where we know we're going to also be touching the size of the set, then we don't necessarily need to be doing other things. And that would just probably come down to the timing of these various features. Right?
00:22:33.120 - 00:22:48.690, Speaker D: Correct me if I'm wrong, but we've brought up these other issues of max effective balance and reusing validator indices, but neither of those are specked out to the degree that we would need to implement them quickly.
00:22:50.420 - 00:22:50.928, Speaker A: Correct.
00:22:51.014 - 00:23:13.770, Speaker D: So this could be done real, quite simply. This is almost like difficulty bomb pushing back level of trivial. But yeah, I would just say this seems like a much easier thing to do to buy as time for those other things because I don't think they're specked out.
00:23:19.500 - 00:23:48.210, Speaker F: Yeah, and I want to point out if say the chain grows to the 2 million and then we find ways to shrink it, there is some debt baggage that we'll have to pay forever until we get to a point where consensus clients can deal with state in a very significant way than they do today. Because as I'm aware of, every single client needs to have the full state loaded in memory to do anything, basically. So the dead weight in the state has a cost.
00:23:53.810 - 00:24:52.674, Speaker A: Mikhail, I personally don't think that reusing indices will help us that much here, as if the activation queue will remain full as it is today. So we'll see this 2 million valderies, as lion has mentioned, quite soon. I don't see how Michelle reusing indices is used with the increase of is tied with the increase of max effective balance. So these two together reduce drastically the number of validators okay, yeah, sure. But before that time, before we have this max effective balance increase, we can get to this number quickly, assuming that the queue will be full. I mean like we will not deliver max effective balance before these 2 million validators in the set, before we see them in the validator set. That's the point.
00:24:52.674 - 00:26:28.150, Speaker A: So it is like a kind of a countermeasure. If we have these to millionaires in valid set, it would mean that in terms of attestation and attestation aggregation, the load will increase three times or. Yeah, three times at least. I don't know how this is sufficient, how bad it is in terms of aggregation, but from what I've heard that the aggregation is almost at its capacity today and if we drop mobile layers on the network it will just can get really worse. And I don't believe that we will have a hard fork to deliver this feature only. Even if it is a cl hard fork, it requires software upgrade, so it requires coordination of node operators and all this and all the related things. Yeah, I think unless it was very obvious like almost an emergency, then the temptation would be too high to slip some other stuff in and then suddenly we just have another regularly sized hard fork.
00:26:28.150 - 00:27:10.260, Speaker A: But yeah, again this is like card to keep on the table. I don't know if we need to make it. I mean it feels like we don't need to make a decision right now. And certainly I don't think we need to think about putting it into NEB. So we'll just continue the conversation as things evolve. Obviously if we come back in two weeks and the state is twice as big, that's a different conversation. Yes, again, assuming that the activation queue will be full all the time, which is unrealistic assumption, I guess.
00:27:10.260 - 00:27:57.500, Speaker A: And if we don't do something about weather set, the speed of growth of weather is set. So we will get this 2 million weathers in nine months. And yeah, if clients are fine with that, I mean like in coping with this load, then that's probably fine, really, and nothing to care about. But if not, then I think we should pay more attention to thinking on whether to do this or any other countermeasures really quick. That point. You have something to say?
00:27:58.450 - 00:28:49.950, Speaker F: Yeah, so I see with this pr we have to choose a value, and choosing that value comes with an opinion that can be controversial. But I think it's important to accept that before the bitcoin chain started, we chose a base reward. And that's a very opinionated decision that clearly motivates the market into staking more or less. So if we took that opinionated decision at the time, I don't see why we can do that again, especially as the landscape has changed dramatically from when the beacon chain was designed and today. So yeah, I want to motivate or at least disperse the fears that this is not such a controversial thing that we have done in the past. And we could do that again to adjust to market conditions.
00:29:02.880 - 00:29:14.610, Speaker A: Wait, sorry, maybe I misheard you, but are you trying to link the reward schedule to this change with the churn limit? Yes.
00:29:16.020 - 00:29:30.790, Speaker F: If we chose a base reward that produced widely different APY that we have today, we may not see the queue as full. So that's a direct incentive for it that's causing this big state.
00:29:32.840 - 00:29:56.110, Speaker A: Sure. Yeah. So again, touching that knob, you're now touching our security spend, which is just something we want to very carefully think about, which, zooming out some, this is like all of these different proposals kind of touch on either very core security or economic concerns or otherwise very political concerns, which is why they can get kind of hairy quickly.
00:29:56.960 - 00:30:25.370, Speaker F: True. My point is on the design phase when the base reward fee was chosen. If we could look into the future and see the growth of the beacon chain, I'm not sure that that value was picked. I don't know if anyone anticipated that there would be such a demand for staking. So acknowledging this reality, just we are not going to change anything. We're just going to slow the inbound. It doesn't look like such a dramatic change.
00:30:28.270 - 00:30:38.960, Speaker A: Right? I mean, there is a curve that's responsive to demand. Right. So there was some decision made. It's not that it's like flat. Right.
00:30:45.440 - 00:30:57.100, Speaker C: I mean, I would say I agree that the reward curve is the most thing to adjust if we want to change the amount of eth.
00:31:00.120 - 00:31:25.410, Speaker D: I don't think he was necessarily saying that we changed the reward curve. I think he was just saying that it was a sort of political decision to begin with and that this is a much less dramatic decision. This is simply limiting the rate of incoming validators. It's not saying you can't stake or anything, it's just the growth is quite high.
00:31:27.860 - 00:32:45.270, Speaker C: Well, but effectively it does change. Basically it means that you are giving preferences to those who have already staked over those who want to stake. So it is also an economic decision. So the fairer way to adjust it is to adjust the rewards curve to get into new balance rather than giving preference to those who have already stated. Yeah, I just wanted to briefly say on this topic that there have been some thoughts in the past to just basically completely change the way we basically pay validator rewards to more explicitly kind of target specific participation sizes and amounts of each stake. I do think kind of just shifting the reward curve might be a good kind of just pragmatic first step in that direction before we make the kind of bigger, more kind of deep rooted change. But even before then, maybe I would say one thing that would be very, just useful to do in the very short term would be to just start communicating that the way we pay out rewards for staking might just change in the future.
00:32:45.270 - 00:33:03.200, Speaker C: So basically, no one should make a decision about staking. The e relying on that. Basically, the payment schedule will still be in place a year from now, five years from now. I think preparing the community for that, this might change in the future would be very valuable to do in the short term already.
00:33:10.970 - 00:33:52.750, Speaker A: Yeah, I mean, that makes sense. And one way we do that is having these conversations on these calls. So if people are listening, then they can start to understand that maybe something will change. So that being said, I think we might be done with that topic. Unless there's any final comments. Otherwise, I'll open this up. Are there any final remarks or things not on the agenda anyone wants to discuss? Otherwise, we can go ahead and wrap up a little bit early today.
00:33:52.750 - 00:34:14.890, Speaker A: Okay, sounds like. No, I'll go ahead and call it. Thanks, everyone, for attending. And we'll go ahead and close.
00:34:19.810 - 00:34:25.380, Speaker F: Thank you. Bye. Sa.

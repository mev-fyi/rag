00:00:16.330 - 00:02:12.390, Speaker A: I've been working on the like client implementation and in this presentation I would like to talk about how far we have already progressed with that and also discuss the future ways of development concerning scalability, security and decentralization. I am proud to announce that we already have a proof of concept implementation of the light client protocol. As many of you probably already know, the purpose of a lite client is to provide safe access to the Ethereum network without having to download and process every block and keep and update an entire copy of the state locally. For all these purposes, we have developed the last protocol. There's a topology shown in the slide which shows that just the blue diamonds who represent traditional pool nodes and the green diamonds who have light nodes connecting to them, and the green light nodes are downloading only block headers as each new block appears in the blockchain, which is a lot less network traffic than downloading entire blocks and they only download block and state data as it is required by the applications. This protocol is for on demand recovery and block and state data, and also it can relay transactions to the ETH consensus network. Because the last network is somewhat separated from the consensus network, the full nodes definitely support both ETH and less protocol serving the light nodes, and the light nodes are only communicating with the last protocol.
00:02:12.390 - 00:03:37.998, Speaker A: This structure is working and it is quite efficient with a low number of light nodes. But as the network grows, we will come into scalability and centralization issues because as you can see in the picture, light nodes currently can only connect to full nodes and this is also both a performance battleneck and after some time even can be a security issue. So it would be beneficial if we consider serving light node the service that if Lightnote could become providers of this service too. If we are talking about centralization problems in the context of a light client, we have to address two important questions. One of them is the concern of security. How can we trust our headers? Because the liteoians work in a way that the Petrisha three structure ensures that if we download any block or state data, we can check its validity by checking a Merkel proof and checking it against the root hashes found in the block headers. So if we had correct headers, we have a secure access to the network.
00:03:37.998 - 00:05:24.970, Speaker A: But as we are not processing light nodes are not processing the blocks, they cannot directly check the validity of the headers. So we definitely need some security measures to prevent attacks. One obvious way is checking the proof of work and later proof of stake found in the block headers, which makes it harder and more expensive to forge false blocks or headers. Proof of stake will definitely provide a better level of security in this aspect, but proof of work will also be sufficient and if we can also increase its security, if we demand a few confirmations before we accept each header, we can also increase security by fetching headers from multiple peers, preferably randomly selected peers, and only accept headers as part of the canonical chain when we have received them from the majority of our peers. The other question brings us to the main topic of my presentation, the efficient distribution of the blockchain, the block and state data. And the general idea about this was originally that the lite node should collectively run a DHT service, either swarm or ipfs or whatever, and store the state data in the DHT. This approach is demonstrated on this next slide where one node shown on the left tries to do a state retrieval.
00:05:24.970 - 00:06:57.870, Speaker A: He wants to retrieve a key starting with b, four, f, three, whatever he needs to retrieve the state try node, take the hash from the element b of the node and then use it as a hash and retrieve that node and sequentially retrieve try nodes until it finds the final node, which is the value it is looking for. There are lots of other light nodes shown on this picture, because if we are putting the state on DHT, well, dsts use most dhts use the so called Cadmia structure, which is a great and efficient DHT topology. Both swarm and ipfs use it, and it requires nodes to access a few intermediate other nodes before finding the node that can serve the data they are looking for. They are getting closer to the address they are looking for, and even closer and even closer, and after some time they are finding the data. So this DHT approach is great. It has one minor drawback that a DHT lookup is not particularly fast. I don't want to give any estimates of how fast it is, but it takes some time and it is usually not a problem with a general purpose data storage application where if you are looking for lot of small pieces of data, you can usually do those lookups in parallel.
00:06:57.870 - 00:08:50.470, Speaker A: But this is not the case with a trial lookup because you only get to know the hashes sequentially. So a state lookup could take pretty long to address this problem. Let me present an alternative approach which is quite similar to the DHT approach actually, and it can use mostly the same code base. It's just a slight modification, but a great improvement in efficiency. So while in a DHT, each node is assigned a range of hashes and stores data whose hash falls into that range we can modify this approach to be more state drive specific and assign each node a range of the state keyed state addresses. So basically each peer would store and constantly observe and update a slice of the state, basically technically a few adjacent subtrees, which is quite efficient in terms of storage and updating. And the advantage of this approach is pretty obvious because these notes can be organized in an academia table the same way the DHT's nodes can be organized, basically with the same code, same implementation, and it only takes one global lookup, which is expensive, to find a node who can serve us an entire Merkel proof, which is basically all the nodes starting from the state root up to the value node.
00:08:50.470 - 00:09:53.514, Speaker A: This picture shows two such nodes. One of them is observing the key ranges b four c to b four f. The other one is observing the right one is observing be zero to be seven prefixes. And this next slide shows how this approach actually works. Would work each node as new blocks appear in the canonical chain. Each peer can update their part of the try from a node who is observing the same or larger key range. And in this aspect, full nodes are nodes who are observing the entire state, of course, but evolite nodes can choose to observe the entire state, but not process blocks, just download state.
00:09:53.514 - 00:11:57.128, Speaker A: There is a big advantage of this approach, in addition to increased performance, which is the fact that if you are updating your try, downloading the new try nodes that exist in the new version of the state in that slice of the try, you can exactly know when you have received all those notes. This is basically similar to downloading and checking a merkel proof. It just works for an entire range of keys, an entire subtree, but it can be similarly checked against the state root found in the block header. This is a big advantage because this way we can easily measure the quality of the service. If we consider serving either subtrees or individual keys, which is a service, and which eventually nodes will be paying for, then it is very beneficial if we can exactly measure the value of the service, the quality of the service. And this is especially beneficial for smaller nodes, because if they are choosing a key range that is not yet so heavily served, they can provide a service that is just as valuable as the service of the full nodes, of course, with a smaller volume. And so far I have already talked about the distribution and storage of the state, and we also have to make the actual blockchain accessible, which includes the transactions and the receipts belonging to those transactions for each block.
00:11:57.128 - 00:13:35.372, Speaker A: This is a much easier problem than distributing the state for this the traditional DFT approach is just as efficient as any. But maybe if we already have peers who have ranges assigned to them, it might be beneficial to store every transaction, and especially every receipt by reference by the block hash of the block they are belonging to. Because if we are processing logs, yes, live clients definitely need to process logs efficiently. Then log processing consists of checking bloom filters, and if we are finding a positive match, we have to download all the receipts belonging to a block. So storing the receipts belonging to one block at one place might be a good idea. And it is also worth mentioning that the relaying of transactions can be how we should approach this problem in a network where we have a lot of light nodes. If we have much more light nodes than pool nodes, which will hopefully be the case in a healthy network, we will probably have to propagate every new transaction to the ETH network through multiple light nodes because most of them won't have direct access to a full node.
00:13:35.372 - 00:15:35.240, Speaker A: And if we do that, it would be beneficial to demand that every new transaction is propagated through the peers whose address ranges include the account that has signed the actual transaction. It is very useful because this way every propagating, every forwarding peer can check the validity of the transaction because they have information about the account that assigned it and the checking. The validity must consist of checking the available funds of the signer and the transaction nons. So if every propagating lightnote can both check the account balances and nonsense, and also do some filtering and ordering by the gas price offered by the transaction creator, this forms a very effective stem protection from the consensus network by only forwarding transactions to the main network, which will probably be actually included in the canonical chain. And finally, to conclude my presentation, I would like to talk about a future plant, give a quick roadmap of of the future developments. As I currently see it, we have planned several stages of release. The first stage, which will hopefully be ready pretty soon, may be released in our next version of the Go Ethereum client will already be able to retrieve data on demand to the first version of the last protocol right now only from full nodes, and probably also be able to relay transactions.
00:15:35.240 - 00:17:05.910, Speaker A: This will be a more or less usable light client, but full functionality will be reached at stage two, which will also be able to process and filter logs, and probably the multisampling header. Retrieval will also be included, which is what I talked about before fetching headers from multiple peers to increase security. This release will still have will still have centralization issues with very great networks, but for the time coming I think it will be quite sufficient, and in the subsequent stages of development we should definitely address the scalability issues. It should still be up for discussion whether we try to go with the regular traditional DHT approach or the state splitting by state fees approach, whatever. We have to develop a distributed service which also includes a simple micro payment system. And for this purpose we can probably use the so called swept protocol, swarm accounting protocol, which is a very simple but very useful kind of payment channel implementation that is used by Swarm. And we can also use it for like client services.
00:17:05.910 - 00:18:11.640, Speaker A: And when the development of the proof of stake consensus protocol advance, we can also employ those mechanisms. So basically, porting the life client to proof of stake will provide a much better protection against fraudulent notes and civil attacks. Basically it works with a reputation system, because nodes with a stake that they can lose by trying to attack it gives them some kind of reputation and definitely makes attempted attacks more expensive. So by the time we will reach the point we can switch over to the proof of stake consensus protocol. We will hopefully also have a massively scalable and secure light science network too. And I think this is all I could tell you about these developments in 20 minutes. So thank you for your attention.
00:18:11.640 - 00:18:16.170, Speaker A: You.

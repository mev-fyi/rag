00:00:26.020 - 00:05:06.728, Speaker A: SA we will proceed. Okay, great everyone, let's see. This is ACDC146, it is issue 1200 and the PM repo. I put the link here in the chat and yeah, there's a number of things here on the agenda today. I will touch on Macon Testnet. The intent is to finalize Petra for Devnet 5 and presumably that's the last sort of spec updates we'll need for Vectra itself. Otherwise yeah, then some other research things at the end here.
00:05:06.728 - 00:06:09.790, Speaker A: So in any case let's go ahead and dive in because there's quite a bit here first. Yeah, I wanted to talk about Macan. This was essentially from Devnet 4 as I believe and it was a public facing testnet. There are a number of deposits I think Monday or Tuesday that caused some issues and I think every client, well at least every SEAL client had some bug. That being said, the testnet is finalizing again which is very nice. So good work everyone. And in any case is there anything else we should be discussing here? Any follow ups or contacts clients would like to add around this bug? Okay, we got an all good from our side in the chat.
00:06:09.790 - 00:06:59.340, Speaker A: Fair enough. Okay, great. So yeah, there are some issues with the deposits and yeah, I think there's a number of different places we can add tests just to make sure that there aren't any regressions. And yeah, we definitely need more spec test as produce calls out here. Mikael, we just want to do it on the spec test side. We have tests already in the PR for this specific case and for other potential cases. There is an issue that I've recently opened so we need tests to cover the epoch processing in a bit different way than it's covered today in the consensus spec test.
00:06:59.340 - 00:08:17.070, Speaker A: So today we use kind of like code coverage metric for or like for the epoch processing tests which is the code used that the spec has. And the problem with the on the Mekong that happened recently was because the spec and the client code are different because clients use caches. So we need to do more extensive testing and find potentially in ideal situation we find all these kind of dependencies when one hip hop processing function does the change to the B constraint and the other function uses this change in its logic. So if anyone wants to, if anyone wants to help with this writing these tests, there is an issue and yeah, I'm happy to help on that. Cool. Yeah, I'll just send a link to this issue. Yeah, another thing to add, there is at least I looked at one of the bugs and it wasn't so much a caching issue, it was just like an accident really.
00:08:17.070 - 00:09:07.366, Speaker A: And spec test should catch this kind of thing. One thing to add is the spec test though are I would say primarily more like unit test, not so much like end to end integration test. There are some types of spec tests that start to get towards more end to end things. But that being said, yeah, clients should be careful writing code and you know, do testing on their end as well and not just rely on the spec test. Terrence, sort of mutation testing that's happening with the cicd. Sorry for the stupid question. I think like a couple months ago I went through basically why I did in Prism is that I started commenting out every single line of the state function and to see whether basically the spec will still fail.
00:09:07.366 - 00:10:02.612, Speaker A: And if it doesn't fail, I make a note of it because that typically means that there is a spec test missing coverage. And I think I opened like three PRs on the spec test because of that. So I wonder if it's worth doing again from my end or do we feel like there is sufficient coverage on the SPAC test today? I would say if you, if you're willing to do this, please go ahead and you know, just, just do it. But for this particular case on Mekong, even if, yeah, even if this, this pack would have a perfect test coverage and probably it has in this particular case, it would not mean that we would reproduce this bug using those tests. Yeah, definitely. Yeah, yeah. I think with testing the more the merrier.
00:10:02.612 - 00:10:39.220, Speaker A: So everyone should always be thinking about testing from, you know, the more angles the better. Cool. Well, that being said, we quickly resolve the bug and I think everyone has shipped fixes or will soon. Nice work. And yeah, anything else on that? Otherwise we'll go to Devnet 5 spec. Cool. There's a number of things here.
00:10:39.220 - 00:11:14.390, Speaker A: Let's start with this first one. There was an update to 7685 to change how we handle empty requests with the hashing and the commitment on the el. So this one. Yeah, so it's in a bit of a weird spot because I linked the execution APIs PR here. These are the updates with Engine API. There was a corresponding EIP update and then also a CL PR update. The cloud specs PR and the EIP have been merged.
00:11:14.390 - 00:12:01.612, Speaker A: This has not been merged, but it sounds like. Just going off of a comment from Felix here on the agenda that there's maybe still some open discussion. My understanding is that we wanted this change and we were going to merge it and yeah, I guess we should Figure this out. Now, if we want to walk it back, which I don't really recommend at this point, we'd need to go unmerge some things in other places. So then I guess the question is. Yeah, does anyone feel strongly against this change at this point? We have support. So yeah, and this is my sense.
00:12:01.612 - 00:13:05.610, Speaker A: So I think we just go ahead and merge this one in. Yeah, just Felix wrote that probably we should not like have a requirement on a strict order on the Engine API and just leave this requirement to the CL side so the requests are sent in the right order. This is kind of enforced by CL specs rather than by Engine API. This is one of the recent Felix comments. Other than that, I had some, you know, some comments about this order and why not doing it on el, but I don't mind to merge it as is. It's not like super strong, super strongly opinionated that it should not have the order statement in the engine API spec. So if there is a strong consensus, if there is a strong willing to merge this as is, and there is no opposition from the client teams, then let's just merge it.
00:13:05.610 - 00:13:36.260, Speaker A: Okay. Yeah, I mean that sounds like that's where we're at. We're getting support in the chat and yeah, I think given that we've merged other things that move in lockstep with this one, I think we go ahead and merge this and we can close out this question for Vectra. So let's go ahead and merge it. And that was pretty straightforward. Next up. Okay, so the next, I think the big thing here with Devnet 5 would be 7742.
00:13:36.260 - 00:14:51.720, Speaker A: So let me grab this update and there are a number of 7742 PRs for the feature. They've kind of been ready to go for a while now and let's say maybe like a couple weeks now ago in the process, as people kind of dug into this, there was a question about changing the fee market, because especially as we go to more flexible target and max values that 7742 unlocks, you get to a place where the fee market that sort of was hard coded in 444 doesn't respond in the best way. So that all being said, there's an Update here, it's PR9407. And what we had said from a discussion at DEVCON was that we'd have this PR and essentially make a decision today. So there's been some comments on it. But yeah, I guess the question here is what's the consensus? Do Client teams want to include this change or just move ahead with 742 without it. That's great.
00:14:51.720 - 00:15:10.252, Speaker A: Yeah. I just wanted to say for. For context that basically there's like two different. Like most of these changes in a way nice to have. They definitely all make the fee market somewhat nicer and. And forward compatible. Like we will have to do this anyway.
00:15:10.252 - 00:15:57.890, Speaker A: But we could also do a lot of this in Fusaka. The one thing like if we end up rejecting this kind of bundle of features that is proposed in the pr, then what we should do is at least have a minimal change. Although I think the better target would actually be the throughput increase EAP itself. So 7691, which just. With just a small adjustment to the update fraction. Because if we don't do this, if we basically don't make that one small change, which is literally one line change, then what would happen is basically after the fork now any empty block would reduce the base fee by 21% which I think is a little bit much because basically because the sensitivity just becomes higher. Because now basically we are six blocks under the target in a single block.
00:15:57.890 - 00:16:22.098, Speaker A: And so that would be like a 21% drop which I think we should adjust that value which is literally like one parameter change. So that would be the very minimal change. I think I would recommend at least doing that. The other things are still nice to have, but if, if clients preferred we can do them in Fusaka instead. Yeah, and you're talking about the update fraction. Like we would just change that to reflect the new target. Yeah.
00:16:22.098 - 00:16:47.004, Speaker A: And there's some ugliness. Like for example by doing that at the time of the fog, the base fee jumps a little bit. Which of course this is part of the things that would be cleaned up with this more expensive change. But. But if we are saying we are going for like the bare bones version here, then we could basically just ignore that. Only change the update fraction that's a one line change and do the nice cleanup in Fusaka. Right.
00:16:47.004 - 00:17:15.410, Speaker A: Yeah. So I'm. Well, does anyone else have thoughts? I have thoughts on this, but I. Yeah, just to some extent. So one of the tensions that has come up in these discussions is this question of incentive to propagate blobs at all. And so they're obviously expensive and getting more expensive and they're good for the network as a whole. Yes, but.
00:17:15.410 - 00:18:35.210, Speaker A: And so one of the. And it would be, I think maybe we'll say maybe my what I would ideally target and I don't know what other people think about this is actually for the target price, the target market to be a little more to incentivize people to care about Bob a little more. Right now cls actually are better off avoiding Bobs mostly honest validator shenanigans aside and because they're just not paid enough for it to be worthwhile. And then the trouble is as soon as you get above the target it this price ramps up fairly quickly and so there's not a happy equilibrium really above that either which would have been otherwise kind of nice. So it would be one possibility. I don't know if this is feasible in this particular time frame for Petra or if people want this is to explicitly target a slightly higher like just enough of base fee that it is reasonable for people to actually want to carry blobs in the same way that people complain when they miss attestations or other things, sync committee messages, etc. Right now nobody complains if they miss blob so to speak.
00:18:35.210 - 00:19:13.000, Speaker A: But that's a problem with blobs and people are being browbeaten into like you know, you have to have to do blobs. So yeah, that's what I'm my thoughts, I guess. Yeah, I mean blobs are a critical part of the protocol so we should make sure that they're supported. Onsgar has the comment here that you could have like client side that basically a floor for inclusion as you build. So yeah, that's an option. And in any case that was another yeah, I mean there was another EIP for raising the floor. That's something we get into.
00:19:13.000 - 00:20:28.210, Speaker A: Tony, you had your hand up. Yeah, first of all I would agree with I think the nice to have EAPs can be or the nice to have changes can be postponed until Fusaka. And regarding the question to put them into 7742 or not, I would say we don't put them into there and keep 7742 and 8 anything that touches the blob base V separate just because I think it's much cleaner that way and then we can still put like the thing Anska said with the blob base refraction into the ERP that eventually changes the blob and the max. So that could also work. And yeah I think we have it on the agenda at a later time anyway to talk about the blobs and what Dustin mentioned would basically be something new we can also think about as a nice to have when we eventually touch the blob base fee. Yeah, it makes sense and it does sound like A simple path forward for Petra Dencrad. Yeah, I mean it's two different things, right? We have both the base fee and the tip and I think this like confused them a little bit.
00:20:28.210 - 00:21:47.930, Speaker A: But we, what we want is like that yes, like block builders want to include blobs and that's like, that's already possible right now. You can just set a minimum tip at which you include them. It would be nice if like blobs just came with like a little bit of a tip because they do was like increase the risk of being reorged more significant and more significantly than other transactions. Like I would also be very much for like setting some minimum base fee for blobs and like I think like it's been really obvious like over the last half year everyone's complaining, oh roll ups don't pay and like they don't contribute, they are parasitic. Which is of course complete bullshit. But I think like having a small just like base fee would like end this annoying charade where we will increase blobs a little bit and then suddenly everyone like oh now we're not burning anything again and we'll make it a little bit more kind of a little bit smoother. So I would actually think that it would be a great idea to actually increase the base fee a little bit.
00:21:47.930 - 00:22:28.092, Speaker A: Okay, potus. Yeah, I agree. And I think roll ups also agree that that increasing the minimum base fee is something that it's useful unless we are always on congestion as. Now regarding the issue of like deep the markets with chip inclusion, there's a bunch that are not really well studied in my opinion. One of them is the issue that tip applies the same for blobs that carry execution, the blocks that don't carry execution. This makes a huge difference for different roll ups. That's one thing.
00:22:28.092 - 00:23:28.864, Speaker A: The other thing is timing games. Even if the builder has the blobs with paint tips, as long as the pool is requesting the headers late enough because they know that they can and they do it now, then the timing game dynamics changes. Whether or not you are or not going to include blobs. If you increase the limit to 10 blocks then either pools are going to start like requesting earlier and playing less time in games or they will continue requesting as they do today and the builder will have to adjust the number of blocks that it includes. So I think these two problems need to be taken into account and they need to be studied if we're gonna be like counting with tips as to decide on the blob limits or blob Targets or blob inclusion. Even so I would suggest that we keep it to base fee considerations when we talk about the market until we understand these other topics. Yeah, I think that makes sense.
00:23:28.864 - 00:23:59.870, Speaker A: Just around gaining a better understanding of the actual market out there and a quick interjection it sounds like maybe from the chat people are confused. So like right now we're talking about just this one update to 7742 that would touch the blob fee market. We are not talking about raising the target or max or anything. We will talk about that in a second. But that's very separate from these base view mechanics. We're like very zoomed in right now. Yep.
00:23:59.870 - 00:24:45.594, Speaker A: Just want to add that, I mean this. If we don't have any plan to update any target before Fusaka, I mean then this PR is basically rendered useless in the sense that it won't add any value. But if we are trying to update the target then this PR is a bit relevant. Although we can also update Target with some hard coded update fraction like we have done in 4844. But I feel that this is, this is a good way to go forward and maybe we can even have time based target unlocks with Fusaka. But yeah, that can happen. That can.
00:24:45.594 - 00:25:25.810, Speaker A: This PR can be merged with other PRs at that point as well. Right. So I mean the question answer now is do we. Yeah, essentially what is good enough? We could do a very simple thing. There does seem to be quite a bit of demand to raise the target and max in Petra. And because of that then we can ask about the fee market and this current PR as one proposal. Another proposal that Onsgar and Tony were just talking about that is even simpler is just changing essentially this update fraction that we have that would do exactly what we want.
00:25:25.810 - 00:26:11.810, Speaker A: That's like literally a one line change. You're exchanging a constant. This one that is under discussion at the moment has some normalization involved. It's a little, little bit more complicated. So the alternative would be to do like they were suggesting like we just change this update fraction and then we kind of bundle this with a number of other things because as we're discussing there are other things around the fee markets that we could imagine changing. I don't think they're quite, you know, in the quote endgame state. So that would be the idea is to go ahead and do the simple thing that works now and then hold, you know, these more invasive changes off until Fusaka.
00:26:11.810 - 00:26:46.140, Speaker A: Yeah, One thing I want to add so there are two changes in this one is normalization which, which as you are saying is a bit more complex. And the second thing is to add targets, target blobs per block in EL header. So maybe I think we should at least keep that one. Well, it's already in 7742. Okay. All right, thanks. Okay, so we have essentially a plus one from Tony to what we just described.
00:26:46.140 - 00:27:47.656, Speaker A: Basically ignoring this update for now and just bundling it with then in Petra. This is a topic we will get to soon around actually changing the blob counts and yeah, just having 7742 for that possibly with updating this update fraction there. Does anyone feel strongly about doing this more invasive change at the moment or would you rather go the simpler route? Sounds good. Yeah, just, just to say, basically like I also said it in chat to me there's three questions. It's the definitely do the simple or definitely do the one simple change which is the update fraction. And then probably it seems like the majority wants to push the bigger change, the normalization that Kajino was working on to, to Fusaka, which would then still leave. The one extra decision that we have to make is the minimum base fee change.
00:27:47.656 - 00:28:14.778, Speaker A: That's the one that Max Resnick originally proposed. Dankrat argued for it just now like 5 minutes ago on this call. We can also push that to Fusaka. It's basically in the middle of those two. It's like small but not a one line change and also nice to have but not as important as the other one. So basically we should still. If we want to do the very small thing and push the very large thing then we should make the, an extra assessment of the.
00:28:14.778 - 00:28:59.538, Speaker A: Do we also want to increase the minimum base fee in Petra or do we also push that to Fusaka? Yeah. Well, does anyone have thoughts? I would say it's like pretty late in the game because my sense is that Max vip. Well I guess that's the question, like was Max's VIP ready to go? It's almost a one line change. The only reason it's not a one line change is that we would have to basically at the time of the fog then reset the excess gas to zero. So basically there would also. It's like, basically it's two lines. It's like in the, in the, the way you now calculate the excess gas there has to be an if statement, you know, if it's the time of the fork return 0 and, and change the 1 value.
00:28:59.538 - 00:29:26.960, Speaker A: So basically like the max EIP is like a 2 or 3 or 4 line change. But my, my understanding is that that is not fully specked out. I think he only speced the one line and not the the if statement. Right. Yeah. So I'm trying to ship Vectra and my concern would be that if we take another cycle to get that ready then it's just going to delay things even further. So I guess I'd want a sense of like how important raising the base fee would be or maybe I'll say minimum fee.
00:29:26.960 - 00:30:13.680, Speaker A: Yeah. My sense from previous conversations is that there wasn't like strong consensus that it was super urgent. Although the normalization with 9047 is that it will give a nice treatment to the current excess gas that is out there and make sure that when the target is updated that is sort of taken care of in a nice way and there is no irregularity. So that is something that is there in 9047 which could be considered. Sure. But then that's still a slightly different point to actually raising the minimum fee. There are some comments in the chat that this is a nice tab but not existential.
00:30:13.680 - 00:30:40.838, Speaker A: Do we all agree to that? Anyone disagree? I don't know. Duncrad, you feel strongly about this? Okay. Yeah. Peter. Sorry, I just joined. This is 7742 you're talking about, right? Well, we're talking about a number of things. So right now we're talking about raising the Blob base fee.
00:30:40.838 - 00:31:18.090, Speaker A: So right now the way the protocol works is it's spec to one way and there have been proposals to raise it to some higher number. Oh, okay. Yeah, I feel it isn't existential but like if we're going to do a version of 7742 we kind of have to. Because I don't want that. Because we don't want the consensus layer to have to deal with greater than U64s. Right. So this would be within the domain of the el and so the CL should be fine there.
00:31:18.090 - 00:31:46.164, Speaker A: So I think we're forced to do it eventually because we're talking about if we do, if we do a version of 7742, this is a prereq. No. So the thing that we're talking about now is essentially a number that's only on the el. This EL never has to deal with it. Oh yeah, sorry. Not confusing something else. Sorry.
00:31:46.164 - 00:32:07.800, Speaker A: Yeah, it's okay. No, there's a number of things in play at the moment. Okay, so it sounds like from the chat there's support to table is for Fusaka, the Min fee just because. Yeah, I really would like to move things forward here. I think we all would. And if we, you know, again take more time then it's just going to delay. Petra.
00:32:07.800 - 00:32:55.272, Speaker A: Oscar. Oh, okay, sorry, sorry. I just wanted to briefly ask because we want to actually get true freeze. And so if we say we go ahead and I mean obviously there's still then the next agenda point for the actual BLOB throughput increase. But assuming we decide to go with a BLOB throughput increase then that it does require this one small adjustment to the update fraction. So the question is what is the timeline there? What is the process there? Do we do that async in a pr? Who's going to open the pr? There's different alternative options for the update fraction. I think it's insignificant enough that we can just say that we will figure that out in the PR and just go with any thing that has weak agreement over there.
00:32:55.272 - 00:33:18.850, Speaker A: But how do we basically. What's the timeline on that decision? Yeah, well it sounds like we should just get into that now. I think there was a suggestion just to put it into the 69 EIP which is EIP 7691. I think that's perfectly workable. So. Yeah, Ben. And then we will talk about the blob counts.
00:33:18.850 - 00:33:46.150, Speaker A: Oh Ben, I don't know. You had your hand up. I don't know if you. I think, I think the min fee is related to the blob count. So if you're not touching the blob counts, that's fine. But if you, if the blob cancer changing then the min fee becomes more important because it will immediately crash the market and go back to one way. One way which is like a crazy small one.
00:33:46.150 - 00:34:09.924, Speaker A: I mean the, the way fraction is, is used to be able to calculate the fractions of gwei. It's not used as a. You know, you wouldn't launch a token on Uniswap at one way. You could. No, but. Well, Uniswap would break because it can't handle. There's no decimals further.
00:34:09.924 - 00:34:37.352, Speaker A: There's no, you can't go smaller. You know what I mean? So you either. Yeah, I mean so if you're going from, let's say you need to put the price up. Where do you go from one. One way or you, you can't put it up by 10%. You have to put it up by 100% because there's, there's no, you know, there's no fraction of a way. For example.
00:34:37.352 - 00:35:01.834, Speaker A: Right. Yeah. Francis, do you? Yeah, I guess I do want to move to the blob counts, but yeah, yeah, yeah, that's what I'm suggesting like because I think a lot of this depends on like what kind of target do we want to set. Right. Okay. Yeah. So we will come back to this next agenda item.
00:35:01.834 - 00:35:40.682, Speaker A: There is a change to 7251. But since we're already here, let's talk about the blob throughput increase in extra. So to kick things off, I think many of you have seen this EIP already, 7691 which proposes raising the target to 6 and the max to 9. I'll just grab the link here and maybe to kick us off, Sam wanted to give a quick overview of some work that he did. Is Sam here? Yeah, I'm here. I think Parry. We were going to actually get parody present first and sort of combine them.
00:35:40.682 - 00:36:18.060, Speaker A: Okay, sure. Yeah, yeah. I'm just going to give a bit of context first. So there was concern, at least in the past to that we're going to have issues once we increase the blob count in terms of long range syncing as well as how the network heals once there was non finality. So in order to collect some data we did do some devnets over the weekend. You can find a summary over here as well as a deeper blog post on the topic. But the TLDR is that we're not at least the indication from the devnet is that we're not purely bottlenecked by bandwidth.
00:36:18.060 - 00:36:52.286, Speaker A: There are some optimizations that could help sync as well as peer performance. But all of these optimizations are something we're going to need to apply on Mainnet today, even with the current 3.6 limits. And at least the indication is that even if we were to increase the lob count, we wouldn't necessarily immediately suffer that we would be able to handle an increase. In order to the question of what we can increase to. I will pass it on to Sam. Yeah, thanks.
00:36:52.286 - 00:37:37.350, Speaker A: I'll just share my screen. I hope everyone can see that. Yeah, I'm Sam from the Panda Ops team. I'd just like to quickly go over this post I made yesterday about block rivals, home stakers and bumping the blob count. We as a team recently just started ingesting data from community members who are running nodes at home and this is what made this analysis possible. So quick shout out to those community members. So our analysis mostly focused on the case where blocks are being built locally by home stakers and then observed by home stakers on the other end.
00:37:37.350 - 00:38:37.250, Speaker A: Home stakers are the most bandwidth constrained participants in the network and this makes them particularly sensitive to any increase on the blob count. So we asked three questions. The first question was how is 3 target and 6 max performing today for these users? And it appears to be pretty good. Most bundles are arriving well under this four second deadline. Onto the second question, does the arrival time of these blocks and blobs scale with the count? And yeah, to the surprise of really no one, it does. So onto the the third question here, how can we, how much more can we actually support our mainnet? The long story short is that we believe that both 4 target 8 max and 6 target 9 max are achievable as far as arrival times are concerned. It's just one piece of the puzzle.
00:38:37.250 - 00:39:18.390, Speaker A: Yeah, while this analysis made some pretty naive assumptions, I, yeah I personally believe these numbers are realistic and safe. We also on the way just forecasted how this would look with EIP 7623 which reduces the maximum compressed block size from 1.8 meg down to 720 kilobytes. And yet in this scenario, even in the worst case scenario possible, it's still yeah, possible to do a blob count bump. That's pretty much it for this. I'll throw the link in the chat. If anyone has any questions, hit me up.
00:39:18.390 - 00:40:54.020, Speaker A: Cool, thanks Ahmad. Yeah, so one thing that I'd like to mention here is that there's also a push for raising the gas limit for the L1 gas in general and this needs to be taken into account because this rays will probably bump up the block size to around 1.1 even with 7, 6, 2, 3, 1.1 or 1.2 mix because like the bump is to around the maximum of 45 million or something like that. So might be also play an effect here. Oliver, we think not bumping the blob count would be a big mistake in Petra because we're like essentially waiting for pure dash to scale blobs but that's in Fusaka and there's no like clear timeline on Fusaka and it's already pretty apparent that from the presentation that base did a few ACDs ago that they are looking at needing more blobs on top of all the L2s being announced at the moment that they're also going to launch on mainnet so it would be a huge mistake in our eyes to not do anything at all.
00:40:54.020 - 00:41:54.570, Speaker A: We think 69 is preferable but I see in the chat that maybe 510 is easier to do and I think we'd be fine with that as well. Obviously I'm an EL dev, so from my perspective this seems pretty easy because we have 7742 now and I don't have like a full view of exactly what changes need to be done on the CL here. So I would like some input on what CLDEVs think. Yeah, thanks. So we do have the EIP for 6, 9 and from what I've seen mostly in the chat over here that there's some concern that 6, 9 is not a perfect double. So yeah, I guess I'd like to hear more about that. My understanding is that really the only issues there were that it would make the fee market, you know, have some weird kinks, but it's nothing existential.
00:41:54.570 - 00:42:47.602, Speaker A: Tony. Yeah, one of the issues, I wouldn't even say it's a, it's a big issue, but if we kind of move away from the target being half of the max, then what we could end up with is the base feeder blood base fee scaling faster in one direction then into another, which is not a big problem, I would say. So six nine should, would. Would basically work as five ten would work. So I don't really see a concern there why 69 would be from the base fee perspective worse than 510. I mean in, in the case of empty blobs you will get the base fee going down a lot, whereas with full blobs you will get the base fee raising less than that. So yeah, this is true.
00:42:47.602 - 00:43:48.148, Speaker A: This is. This is also one of the points that we talked previously about about those base fee improvements. There's one point called making it symmetric again and by doing that we can also kind of account for that. So we agreed earlier on that we might want to do those optimizations at the later fork. In this case, if we say that this asymmetric blob base V update is a big problem, then we should stay somewhere where the target is half of the max. Yeah, I put some examples in the choices we could have. So indeed, with the current mechanism, the sensitivity of an empty block and a full block would be different because say for example, for 6, 9, right? Like if an empty block is six blobs under target and a full block would only be three blocks under target, so we could say be very sensitive to downside, then we would have 21% maximum decrease and 12% maximum increase.
00:43:48.148 - 00:44:20.986, Speaker A: But we can also choose the the opposite. So like 11% maximum decrease like today and then it's only a 6% increase or anything in between. Right. Like literally this, this update fraction. We can literally just pick any point of that curve. It will always be more sensitive to the downside than to the upside. The reason why I strongly would argue 4, 6, 9 over a symmetric change is that in both cases only really the rollups are concerned as consumers to blobs, the network doesn't care about a slightly more flaky base fee.
00:44:20.986 - 00:44:44.582, Speaker A: Right. That's only UX problem for rollups. And from talking to rollups, it really seemed like they are much, much more concerned with overall throughput than the UX of a slightly more volatile base fee. So basically they would much rather have overall more room. Yeah. And are not so concerned about the base fee. So of course, I mean we have other concerns here, right.
00:44:44.582 - 00:45:07.028, Speaker A: About average throughput levels and all these things. But in terms of like the base fee, I don't think we would actually act in the interest of the people that we're trying to protect by avoiding this asymmetric base fee situation. Right. Which argues for like 6, 9 over say 510. Because the point here is to raise the target as much as we safely can. I think it was potus. I'll just go in the order I have here on Zoom.
00:45:07.028 - 00:46:03.122, Speaker A: So potus, I want to give a perspective on Sam's result. While it looks as though that increasing to those numbers would be safe, when we are in congestion, when actually blocks are needed to be posted regularly, then we will be in a situation where we hit on every slot the maximum if the builders are behaving correctly. And then if you see for nine or ten for limits, then you're reaching a point where all of those blocks are being trying to be reorged. At least five, not all, I'm sorry, at least 5% of those. Because the line of the 95% is very close to the 4 cents to the 4 seconds. And this is without counting execution, without counting validation, and without counting four choice on clients. So your blocks are arriving near the deadline, which is four seconds and we need to still attest, we need to process and we need to make a signature of those.
00:46:03.122 - 00:47:00.504, Speaker A: So I would expect that at least 5% of those blocks are going to be being reorged. Besides the validators like losing the attestation and instability on the network. If we see every single block 9 or 10, my proposal would be to not do something radical, distribute fork move to four, eight that we kind of know that we can handle. Probably 5, 8 if you want to increase the target 6, 8 might work, but I wouldn't increase the limit without more measurements. Okay, Sam, I imagine that you're in response to what is the saying? Yeah, so like the analysis was done off the Beacon event stream and the clients submit those events at different times. It essentially looked at each slot the latest time for a client to emit the head, the maximum blob sidecar or the block event. So I don't actually know.
00:47:00.504 - 00:47:40.610, Speaker A: I guess it's a client specific thing on when those events are emitted. But it's probably worst case scenario at every stage of this and reality is that we're actually way under when we say that 5% of those blocks will be coming in after four seconds. That's yeah, probably like a bit too much I'd say. I'd say the real world picture is way better than that. We've just left it there to be as safe as possible. And this is also 5% of like home users, not 5% of the network. I know we care about home users but yeah, it's just worth bringing up I think.
00:47:40.610 - 00:48:34.424, Speaker A: Yeah, thanks Bankrupt. Yeah. So I wanted to say something about the limit targets. I think like in terms of predictability and everything like right now at least like most roll ups like what we're seeing now, people starting to build base roll up. But other than that the timing often roll ups get their blobs in. It's like not very important to them because they like sequence separately anyway. So I think the, the only concern about it is really the, the potential economic attacks that that can be done like basically I think at 6:9 like 1/3 of this the stakers could potentially just like set the base fee to the minimum and start extracting value via the tip.
00:48:34.424 - 00:49:49.914, Speaker A: So that's like the classical EIP 1559 economic attack and quotation marks. But I just think like that this is at the current state just like a very, very unlikely scenario and like we should just eat that and like basically like as soon as we can like put it back into the, in the normal range and then like it's, it's much more important to temporarily have this target increase. Right. So yeah, I am hearing a lot of support for 6, 9. I think one way forward would be 6, 9 and then a simple sort of patch would be changing this EIP to include the target value that we want or sorry, let me be more specific, I mean the update fraction that we want to help the fee markets in the meantime. Anyone want to argue against what I just said 69 with the fee update? Yeah. Mikol, you had your Hand raised.
00:49:49.914 - 00:50:20.514, Speaker A: I'm not sure if you want to respond to what I said or someone else. No, it will be something else. Okay, well is it relevant? Because I would like to go ahead and just make the decision now. I mean, it's slightly related to this. At problab, we already have a session in Bangkok when we were discussing the whole bandwidth measurements that we were doing. We've been able to do these measurements from another regions in the geographical location. I can share the screen and show some graphs if there is time for that.
00:50:20.514 - 00:50:59.638, Speaker A: But otherwise something that I want to raise is we are going to post this anyways around tomorrow. But the idea is that all the tendency to say that six, nine, it's fine. It's basically on the idea that you still have bandwidth, big bandwidth available to download everything. What happens if you see that people struggle to fill that bandwidth? Eventually you just get things worse. What I want to say is that it's not linear. What we see is that from home stakers, pretty much half of the network has less than 20 megabytes per second. And increasing the target and the max, that could pretty much become a bottleneck when you are trying to resync stuff.
00:50:59.638 - 00:51:24.580, Speaker A: I think that this was also something raised by POTUS and Nissan on the Discord channel. So yeah, I don't know. I would like to bring a bit more the concern about having such a big increase. Right. I mean that is definitely important data, but it sounds like it's a little bit different than the analysis that Panda Ops did. So I'm not sure if there's a discrepancy there. Dankrad.
00:51:24.580 - 00:52:00.712, Speaker A: Sorry, what? Oh, the hand was raised on zoom. Oh, sorry. Maybe. Yeah, no, it's all good. Ben, that is an important point. If the. If we're running at sort of nine blobs per block, isn't that a problem if you're also snap Suddenly if you're snap serving, will you start losing acidations? Because yeah, I mean there are a couple things here.
00:52:00.712 - 00:52:57.690, Speaker A: So you know, the max, like we wouldn't stay at the max for a sustained period of time. It'd be very expensive to do. And then, you know, I guess another thing to note is that we did do some like syncing experiments to this point and that was, you know, considered in the suggestion from Pandops around their work for 6, 9. So my understanding is that at least with respect to the work they did, they feel this is safe to do. Otis, I think there's a misunderstanding in the chat regarding timing gains and how builders will react to the cost of like the probability of reorgs of their blocks. By including more blocks, it's not so easy that the builders are going to now charge more tip and then they will include those blocks because they might be more likely to be reorg. But the situation is that the proposer doesn't have a visibility over this.
00:52:57.690 - 00:53:32.020, Speaker A: So the proposer that is currently requesting the header later now makes that decision. So if the pools are requesting late enough, then the builder is forced not to include blobs even if they will. If they would include blobs with a higher tip, they would not when the request for the header comes already late. So this is a matter of like the chicken and egg. And I think people should keep this into account when they are thinking about higher limits. Sure. But if this happens then the blob producer would start paying a higher tip.
00:53:32.020 - 00:53:56.036, Speaker A: The builders more incentivized to include them the proposal. No, they are not. Because the header comes late. That's the point. The header or the request for the header comes late and the builder doesn't have control over this. The pool request from the builder at the time that the pool decides. If the pool were to like start adjusting their timing games because of this extra tip, that could be something.
00:53:56.036 - 00:54:50.714, Speaker A: But the thing is that the pool doesn't have visibility over this number. But the builder would have already made the block with the blobs in it right at the time the builder would change the header according to change the block according to when the header is being requested. If the header request comes like 10 milliseconds before 4 seconds, the builder would include zero blocks because they know there will be reorder. Okay, so I do think timing games are relevant to consider here. That being said, let's zoom out a bit and circle back to my question. So six, nine and that's fraction change for eight. Okay, so there's.
00:54:50.714 - 00:55:23.400, Speaker A: Okay, Oliver, I just want to quickly ask. I. I know like obviously this is very late in the process. We want to freeze pector and all that. What is the potential delay here and is there anything my team can help on alleviating the delay? Like I would imagine it's mostly testing correct or incorrect. I think that would be most of it. And just any analysis, you know that we can squeeze out of the network basically.
00:55:23.400 - 00:55:54.180, Speaker A: Okay, Terrence. So I'm not aware of any consensus client team they has implemented in a way that you hard fork to a different block number that the max and target are different. So we're working on PR right now. I presume Other consensus layer client team are working on PR right now. So after that's done we need testing basically. But yeah, this is something new to us. Right.
00:55:54.180 - 00:56:17.450, Speaker A: Which is what 7742 introduces. So it's not really a surprise but it is new. Okay. So right. I mean I guess there are some, there's some demand to consider. 48 over 6 9. I think we've narrowed it down to at least those two.
00:56:17.450 - 00:57:11.968, Speaker A: From there I would lean towards moving ahead with six nine again just to provide the most bandwidth roll ups that we can. And you know, if we are a month or two down the line and have some reason to think 48 is better, we could always change that because what we can start doing today is everything around this change. 7742 and everything fee updates, the actual numbers will ultimately be a configuration change. So it is easy to scale back down if we really feel like we need to. So do we feel okay moving ahead with this with 69 and the fee update? Okay, I'm just going off the chat. There's support for this so let's do that. And I do think it is important to keep doing analysis here.
00:57:11.968 - 00:57:53.706, Speaker A: If we find something that is really going to change our minds we should definitely discuss it as soon as we can. Okay cool. So I had another note here which is, you know, let's live in this world where we're doing 6 9. Do we want to include 7,623? I really think at this point we should only be thinking about things for network security for Petra. So for example, you know, I would think it would make less sense to talk about raising the base fee for the bobs or sorry the MIN fee for the bobs but this one actually impacts like worst case block numbers. So I think it's at least worth discussing. Yeah.
00:57:53.706 - 00:58:33.700, Speaker A: Tony, you have something to say here? Yeah. Quickly about 763. I think we should ship it together with the blob increase. And this was the plan for 7623 for quite some time now. So if you remember it was CFI for months now because we were always unsure if we will ever touch the blob count in Pactra. And without touching the blob target, 7633 wouldn't have had that impact really because now the actual median throughput will increase with the target increase. And 7623 only touches the worst case scenario.
00:58:33.700 - 00:59:24.244, Speaker A: So I would argue that with the increased maximum block count we should also decrease the maximum possible EL payload just in order to make sure that on the EL side we cannot have like almost 20 blobs in size while we are discussing like one or two more blobs on the cl. Right. That's a good point. I will surface this comment in the chat from Light Client. I think this is probably the main argument against 763 and Vectra is just that it adds more things to do and there's already way too many IPs. We just had a pretty bad bug on Makong, so it's not that, you know, it's not that we like are super ready to go and this is just like a marginal ad. It will add complexity to, you know, the whole fork.
00:59:24.244 - 01:00:19.470, Speaker A: And yeah, we need to make that decision carefully. I don't know, like Client, if you want to add anything to your comment. I mean, I think we need to ship actually and I'm just worried about adding more stuff when I don't think that we have super high confidence on either the EO or the CO about what we have already committed to shipping in this fork. And onscar is saying this is an active security vulnerability, but no one is actually taking advantage of it. So I don't really think it's that big of a security vulnerability. Should we fix it at some point? Yes, but I see not a strong reason to fix it in the next fork. Yeah, there are a lot of emoji reacts to his message though.
01:00:19.470 - 01:01:46.750, Speaker A: Anyone want to say something else to 7623? Yeah, if all the people doing emoji reacts, maybe two or three of them should unmute and share that perspective. I think this is the point that has been made multiple times. But we cannot safely increase the number of blobs without decreasing the maximum possible size of the block. This is my reasoning for adding the emoji reactions. Ben, if we're worried about increasing the gas limit because of 7623 and you know, you're compounding it with increasing the blobs if you don't have it in, it's the same issue. So then why did we agree to ship a blob increase before agreeing to do the thing that apparently is the prerequisite for the blob increase? Like now we're kind of just giving this as a writer because we agreed to do a blob increase and we're just saying that we should, you know, it's a prerequisite. We have to do it too.
01:01:46.750 - 01:02:11.974, Speaker A: I feel like it's always been sort of in the meta, at least over the last couple months. So this is just now the time to discuss Tony. Yeah, no, I just wanted to say the same. So it was always kind of bound to the. To a potential blob increase or a gas limit. Gas limit increase which is also still in the room. And yeah, for that.
01:02:11.974 - 01:02:54.150, Speaker A: We were basically saying now for months that 7623 will be kind of this measurement against. Yeah. Any DoS attacks that might originate from Scaling. Scaling everything up. Okay, so I'm hearing a lot of support for 7623 along with the BLOB increase. So let's go ahead and move forward with that. Anyone opposed? Guys, we're adding three EIPs in the call after we just had a three fork testnet bug.
01:02:54.150 - 01:03:19.534, Speaker A: It's two EAPs, right. It's the blob increase and 7623. It's the blob increase, 7623 and fee change. But the fee change is in 7, 6, 91 because it's basically only. Yeah, but there's discussion about putting in its own eip. So. Yeah, you know, we could put these all into one eap.
01:03:19.534 - 01:04:03.922, Speaker A: But these are like three conceptual changes. Yeah, I mean I would like to decide today. However, I think there's grounds for making a decision on this on next week's acde because this is primarily an EL change. I don't know what would change in the next week though. Francis. No, I want to provide a like raw data that I collected for like 7, 6 to 3. So although the theoretic like block size limit is 2.8
01:04:03.922 - 01:05:12.290, Speaker A: megabytes now from my kind of like analysis over the last month or something, the P9999 block size is well under the 700 or 500 kilobytes. So theoretically this could help. But it could be like in the real world it could be like, okay, it's not that big of a deal. But I think it could be helpful to include that if we are worried about the worst words case scenario. But you'll be, you'll be running for. Because of the base C being one way, you'll be running an hour at nine blobs per block before it gets to anything that's even remotely pricey. So then you're opening up plenty of time for somebody to start sticking in last sized oversized blocks for no purpose.
01:05:12.290 - 01:05:58.434, Speaker A: Just for fun. What is the failure case here if someone does do this? I haven't really heard a compelling argument for what actually happened to the network. Like you don't kill the solo stakers if this happens. So are they offline for 10 minutes? Are they offline for 3 hours? Could you kind of keep them offline or like a very low participation permanently? What's the. I mean, you. You won't pay the gas for the block that didn't happen, so you can keep putting it back in. I don't think that there's that much of the network that's going to be negatively affected.
01:05:58.434 - 01:06:54.956, Speaker A: This, like, we're talking about like the bottom 5 or 10% of validators from, what is it, 13 megabyte blocks? The addition of nine blocks, 13 megabytes uncompressed. Like, what's the compressed value? The compressed value is like 2.5. Okay. I would like to make a decision today and there's some chat to that end. I would lean towards including this myself. It sounds like only like client is the one opposed at this moment. Okay.
01:06:54.956 - 01:07:42.800, Speaker A: I mean, that being said, I do feel like we probably want ELs to like, have signed off on this because they're going to be the ones implementing it. So that does really motivate pushing into next week, I guess. Does anyone oppose that? The downside is just we have one week loss of, you know, a spec freeze. Yeah, Tim saying 6, 9 today and then TBD 7623 next week and. Yeah, that's the suggestion. Yeah, I'm happy with that. There's some thumbs up.
01:07:42.800 - 01:07:56.700, Speaker A: Okay. Lots of thumbs up. Cool. Okay, great. So let's do that. And yeah, if you're here and. Or if you're an EL client listening to this, please have a view for ACD next week.
01:07:56.700 - 01:08:38.202, Speaker A: Cool. Okay, thanks everyone for that. There's a lot of discussion there, but it's a very important topic. I think that's everything on the bobs we wanted to touch on today. Let's circle back to this item that we skipped over with the sequencing of the agenda. So There is a PR to update how consolidations work under 7215 and yeah, basically. So I think where this is coming from is that the way that Electra is scoped now, you could essentially trigger consolidation for any validator, not just the ones that you control.
01:08:38.202 - 01:09:03.250, Speaker A: And that's weird. It would be a very expensive attack. But you could imagine someone is wanting to troll some other validator and basically force a consolidation on them. So there was some back and forth on ways to address this and we got to this. PR4020. Mikhail, I'm not sure if you want to say anything else. This is from you in any case.
01:09:03.250 - 01:09:34.921, Speaker A: Yeah, it looks good to me. I think we should go ahead and move forward with this and yeah, I would rather go ahead and agree to this today rather than wait another cycle in the interest of a spec freeze. Yes. Maybe just add one more comment from what Francesco said it would cost you your stake. So it is a very expensive attack, but it could be done right. You still can do consolidation. So but what this PR is about.
01:09:34.921 - 01:10:08.077, Speaker A: Yeah, yeah, sorry, sorry, go ahead. Yes, there was a concern that could cause some. So basically this PR prevents the target to be switch to compounding. So if it's compound and the. Anyone can do consolidation to the target. And the concern was about that anyone can switch any validator to compound and credentials and that can have some legal implications in some jurisdictions. So that's, that's one of the reasons.
01:10:08.077 - 01:10:51.610, Speaker A: The other one is the. We have just this in, in this place, the like there is the way to switch to compounding upon request. And in protocol we have this automatic switch to compounding on consolidation too, which a bit of quirk in the design. So we're just removing that as well. And yeah, that's about it. And also, yeah, there is the, the UX trade off. So if you want to consolidate your validator you will have to first switch to compounding target and then do consolidation.
01:10:51.610 - 01:11:45.580, Speaker A: This is going to be two different requests and. But that's not a big problem because if you have like say 10 valers to consolidate, you should just do the switch once and yeah, then send those to 10 messages. 10 requests for consolidations. If you're a solo staker and you have just two validators, you want to consolidate them, then it will result in two messages instead of just one as existing logic. So it's not a big UX reduction. And also to a bit alleviate this UX thing, I think we should increase the max consolidation requests to two instead of one. So we can basically switch to compound and then do consolidation in one block.
01:11:45.580 - 01:12:38.776, Speaker A: Yeah, I think that makes sense. And I guess one other point here is like this does actually simplify the whole state transition just thinking about validator lifecycle states and how you transit between them. So I really like that there was a confidence here is the compounding just gets set today by whenever you have something as the destination of the consolidation it becomes compounding. And the problem is that you can set any target without authorization from the target. Yes, one of the concerns come from that. So now you're separating the compounding from consolidation. Right.
01:12:38.776 - 01:13:27.632, Speaker A: So you cannot do. You will have to authorize the compounding switch first before doing consolidation. Yeah, and I'll just voice Francesco's comment here. It is a very simple change and I think it does simplify things quite a bit, which is nice. Do you authorize it a lot of times? How do you. Sorry, what was that like? Today we authorize consolidations by looking at the like using the message sender, comparing it to the ETH1 credential. Is it going to be like that again or is it different? No, it's the same.
01:13:27.632 - 01:13:48.810, Speaker A: Okay, sounds good to me. Yeah. Yeah. This just restricts what you can do, basically. Okay. So I think the people who have looked at this before this moment are in favor. And it sounds like there's.
01:13:48.810 - 01:14:11.890, Speaker A: Yeah. Some support on the call as we talk through it. Anyone want to avoid this? Not move ahead. Otherwise I think we go ahead and do it for. Okay, great. I believe. Let's see.
01:14:11.890 - 01:14:45.924, Speaker A: Yeah, so it does need test still, but yeah, this is something that we can get to the next release and yeah, Mikhail, I can help you get this tidied up ASAP so we can keep things moving. Cool. It also requires the update to the consolidation SMART contract to bump the max value from one to two, but it's trivial change. Right. Okay, yeah, we should track that. It is worth noting that it's okay if that doesn't change in the SMART contract. It would be nice if we do it.
01:14:45.924 - 01:15:09.134, Speaker A: It's not the end of the world. Cool. So let's see. I think that was everything for the next Devnet spec and should have in a pretty good spot. Okay. We don't have a lot of time left, so we'll just keep going. Okay, I guess.
01:15:09.134 - 01:15:45.758, Speaker A: Were there any very quick updates with pure DOS or anything? Any devnets there? My sense is that they've kind of been waiting for Petra to settle down. Exactly. So the idea is that Peer Deck is going to launch once Vectra DevNet 5 is stable and then everyone can rebase their code. I think Most of the CLs are already working on a based on top of packer, so we didn't want to complicate things by launching some very old pack. Yeah, yeah. The same true for EOF devnets, by the way. Okay, great.
01:15:45.758 - 01:16:13.356, Speaker A: They both expect to arrive once Vector Development 5 is stable. Okay, sounds good. Thank you. And for picture Devnet 5 then we can probably calculated a 69 change already, right? Yes. Yeah. So Devnet 5 would be essentially the final extra spec. Can we confirm the scope of the next.
01:16:13.356 - 01:17:06.340, Speaker A: I mean the picture definite five right now we talk about many. It sounds like 7623 is still up in the air for next week. I did want to leave some time for the other agenda items, but yeah, I guess. Are there any specific questions right now? Shall we? Do we have for the CEO update? Do we need to wait for this discussion before we cut the release? Not for 7623. That's a good point. So let's see. Right, so from this list here on this issue 7691 which is the block throughput increase that would need an update for the target or sorry I keep calling it that, the update fraction.
01:17:06.340 - 01:17:37.790, Speaker A: Let's see, do one of the authors want to go ahead and handle that change like Perry, Tony, Sam, Andrew, some of you are here on this call. Okay. We at least got a thumbs up from Tony. So yeah, if we could do that like I mean today's holiday for some of us but yeah, if we could do this like in the next day or two, that would be great. Okay. George says he's writing one right now. Perfect.
01:17:37.790 - 01:18:02.130, Speaker A: Cool. So otherwise, yeah, this list looks pretty good. Shall we? This issue 4026. I can follow up with you after and we can double check everything if that sounds good. Cool. Okay. Okay.
01:18:02.130 - 01:18:28.616, Speaker A: So I think that was everything on Petra and or Pirdos to discuss at the moment. Again, very nice work everyone. I can do this point. It's been, it's been a big one. Yeah. So now let's keep moving to the agenda. Next up, we had a request to discuss another EIP 7805 which is fossil and this is a solution for sensory resistance.
01:18:28.616 - 01:18:37.742, Speaker A: Let's see. So I spoke. Are you on the call? Yeah, yeah, I'm here. Hey. Yeah, yeah, take it away. Hi. Thanks.
01:18:37.742 - 01:19:27.890, Speaker A: I'll share my screen. It only shows like the upper quarter of your screen for some reason I'm not sure why does this work now? It's better. Yeah. I think this is everything. Yeah. Okay, I'll. I'll just start.
01:19:27.890 - 01:19:56.490, Speaker A: Yeah. Thanks for letting me present this. I'm Thomas. I'm a researcher in the Robust Incentives Group at def. And yeah, today I want to talk to you guys about EIP 785805 which is on four choice inclusion lists. Short is also. So yeah, I don't want to take too much time so I'll dive right in and just give a quick context.
01:19:56.490 - 01:21:02.460, Speaker A: But yeah, Proposal Builder Celebration was kind of quite successful at keeping the validators that relatively unsophisticated and decentralized I think. But builders have become like super, super centralized on the Other hand, probably more than we expected. And so today we rely like literally two very sophisticated and centralized entities to build more than 90% of all blocks. And this is obviously like super bad for censorship resistance properties because now those two entities can basically arbitrarily decide what transactions get included or excluded from almost all blocks. And so for example, like a couple of months ago you have like a major builder that just decided to stop censoring some transactions and for some reasons that are actually still kind of unknown, at least to me. And we got like this huge job in censorship out of kind of nowhere. And so yeah, it's directionally good in this case, but it also just kind of shows how fragile CR is on Ethereum right now.
01:21:02.460 - 01:22:40.790, Speaker A: And so you guys know about this, but one good way to drastically improve the censorship resistance properties is just to use inclusion list. And just to say it again, the very basic idea is super simple. It's to let the decentralized set of validators define a set of transactions that must be included in builder blocks for them to be considered valid by testers. And yeah, there was like a lot of research done in the past couple of years on inclusion list, obviously since there was even like EIP 7547 that was considered for inclusion, but it was then rejected because of some issues regarding its compatibility with account abstraction and il equivocation. But there was also some like really cool and relevant research on block co construction by multiple parties or the concept of view merge for fork choice. And so we took kind of inspiration from these different research threads and came up with Fossil, which is actually like a very simple mechanism and that allows multiple validators to propose inclusion lists plural and co construct a template roadblock made of transactions that have to be included in builder's blocks. And so we kind of think of it as like a very important step forward because Fossil what actually allows to give some power back to the validator set and allows them to reclaim some control over block production and reintroduce some kind of neutrality at the protocol level.
01:22:40.790 - 01:23:53.000, Speaker A: Another like important aspect worth mentioning is that Fossil can also kind of be seen as a way to boost the signal provided by the solo stakers. So today if you assume like there are like 6% of solar stakers, we have to wait quite a a long time, like a 1770 slots on average, I think, before a block gets proposed by a solo staker. And we cannot rely heavily on solar stakers to ensure the censorship resistance properties of the network or that censorable transactions are eventually included and With Fossil still assuming around 6% solar stakers, there would be a 63% chance of at least one solo staker being in an IL committee If we had 16 IL committee members per slot. And so yeah, here's how it basically works. There are like three main steps that I'll just briefly describe. The first step is about building and broadcasting ILS. So each slot you have 16 validators that are randomly selected to become IL committee members.
01:23:53.000 - 01:25:24.350, Speaker A: And each of them will just like monitor the public mempool and include transactions that are pending there in their is up to 8 kilobytes which is about 40 transactions per I if you take like the median transaction size. And then they broadcast their ielts on the global topic over the CLP to P network. And what validators and testers have to do is just like monitor the P2P network and store IELTS that are broadcast until the view freeze deadline which is at nine seconds into the slot. And basically at this point they keep forwarding is but like stop storing new ones. And in the second step it's about what the like the builder actually including ILS and IL transactions in its block in its payload. So yeah, the builder will do just like the validators and we collect and store ils, but it actually has additional time after the view freeze deadline to ensure there is enough time for him to see all the available ils that were broadcast by committee members and so about like around 11 seconds into the slot. So two more seconds after the view freezer deadline the builder just basically takes the union of transactions across all its stored ILS and he includes them in the payload before the full block is then just proposed to the rest of the network by the proposer.
01:25:24.350 - 01:26:16.730, Speaker A: And the step three is how it's enforced. So a tester will do exactly the same. They will take the union of transactions from ielts they stored but in their case until the view freeze deadline and then they will check whether all these transactions were actually included in the blocks execution payload that was proposed. And this is kind of where the fork choice enforcement comes from because a tester will only vote for the block if it satisfies IL conditions according to their view. And yeah, I'll go quickly but I want to highlight fossil core properties. I guess the first one is that ILS and the payload are actually built in parallel and they only kind of need to be merged together towards the end of the slot. So that's quite nice because it's it provides some almost real time censorship resistance.
01:26:16.730 - 01:27:25.764, Speaker A: Having multiple proposers makes also really robust to commitment attacks, but it also actually allows us to get a super nice one out of an honesty assumption. So we only need one IL committee member to build its IL honesty and just include transactions from the mempool without censoring for the mechanism to work. And then we have the conditional property. That just means the builder must include all IL transactions but until the block is full and the builder is also not constrained on where IL transactions of the order of IL transactions in its block. And so these two last properties are actually quite important to just prevent ils from being prodded out by MEV transactions. Like imagine if there was some dedicated block space or if IL transactions had to be included at the top or end of the block, then we probably have seen something like IL boost emerge. But in the Fossil case, like transactions have like no ordering guarantees and they must be created before the builder actually has the last look and builds the full payload.
01:27:25.764 - 01:28:12.480, Speaker A: They are also broadcast publicly, so there is really no point in trying to include valuable or MEV transactions via Fossil. Yeah, and all our all these are. I'll just mention them quickly because it also addresses like some issues that were present in like the previous proposals. There is no freed problem because in our case ILS stay on the CLP2P network and they never go on chain. We've thought about like handling scenarios in which transactions can be invalidated. We made sure it's compatible with other aips, those that are considered for inclusions and others like account abstraction, EAPs and PRDAs and EPBs. We handle IL equivocation.
01:28:12.480 - 01:29:19.970, Speaker A: I already said that. But it's quite robust against commitment attacks, so bribing and extortion because we do have multiple validators and multiple IL committee members and against falling attacks. And yeah, it's also like critical if you want to move towards aps, so attestor proposer separation. It's actually critical to have a mechanism like Fossil to ensure there is validators that are unsophisticated and decentralized involved in building these raw blocks before moving towards a world in which we might want to set off execution proposing rights to sophisticated artists. And yeah, finally I just want to say that Fossil can be seen like as a core mechanism to enforce chain neutrality and improve censorship resistance quite drastically. But it's also like quite well suited for extensions in the future. So so far we've thought the most about extending Fossil for block transactions because like that's very obvious but we are also actively researching how for example to properly reward IL committee members if we wanted to do so.
01:29:19.970 - 01:30:08.340, Speaker A: Because in the current version we rely on altruistic behavior or how to secretly select IL committee members so they can contribute to the mechanism without actually revealing their identity, which also might be very useful. And all of these are like, yeah, super exciting research direction that can extend Fossil to give even better censorship resistance guarantees in the future. So thanks everyone for listening and thanks to all the authors of Fossil. And we just released today a censorship resistance website using ENS and IPFS for resources that are related to Fossil. So it's called Midforsul if lymo, so check it out. Thanks. Cool, thank you.
01:30:08.340 - 01:31:02.420, Speaker A: Yeah, I mean it's really exciting to see and especially like the history of research that got us to this place. I guess one question I have that might be relevant for people here is if you thought about implementation at all, I don't know if you've thought about prototypes or anything like that to accompany the eip. Yeah, we. So we opened the IP a few weeks ago and now Jihoon, that's an author, has started working on a Geth implementation, although that's quite recent. Terence is also planning to work on a PRISM implementation, but that's all like that's a great problem because like anyone who's willing to work with us on this, we're like pretty active and we are looking for other people to help us on the implementation side. Cool. Awesome.
01:31:02.420 - 01:31:58.590, Speaker A: Yeah, we will not get into future forks today, but this is something definitely everyone should have on their radar. We only have a few minutes. There was a question here. How does fossil work with EPBs? Are there any caveats to us with EPBS or Fossil, anything like this? No. So we discussed about like the potential compatibility with EPBs and it is about like timing things right. So we allow for enough time for, for deadlines and View freeze and everything. Not to each too much time for each of the proposals to go together, but it seemed like it was actually quite compatible and that we can make it work.
01:31:58.590 - 01:32:42.020, Speaker A: So we had a lot of back and forth discussions in the inclusion list channel around the eth RND discord. So if we want to check it out, you can and happy to like yeah, work on this even more once. Like I don't know, maybe we have also more clarity on what gets included or not. Cool. Okay, well, we are actually at time now and yeah, I think we'll go ahead and wrap up. I guess I'll ask. Are there any closing comments very briefly, otherwise that will be that real quick.
01:32:42.020 - 01:33:04.220, Speaker A: Yeah, we didn't have time to get to it and it's fine, but I had some ACD process stuff on the agenda. If people can review those before next week's call and leave any comments, I think that'd be great. Yeah, just posted the link in the chat. Cool. Thanks, Tim. Great. Okay then.
01:33:04.220 - 01:33:13.980, Speaker A: Nice call, everyone. I think we made a lot of good progress on pactrege and I'll see you next time. Bye. Bye. Thank you.

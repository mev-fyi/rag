00:00:00.690 - 00:01:06.220, Speaker A: You okay? We can probably get started. So this is our 22nd .44 call, so yeah, I guess it makes sense to go over all of the spec changes that we discussed in AW Cordev's last week. I know there's been some new prs about that and yeah, then at the end, if we have time, we can cover the state of devnets and if we want to get a target for Devnet six. But I guess to start, Matt has draft pr, basically that removes RLP, sorry, that removes SSD from 4844 on the El side. It's been open for a couple of weeks, but he asked on awkwardevs if people could review it to see that there weren't any issues with it before we merged it in. So I don't know if anyone has thoughts on the prs or anything they wanted to discuss about it.
00:01:06.220 - 00:02:02.934, Speaker A: Okay, so everyone happy if we go ahead and merge this as it is? Okay, I'll take that as a yes. I'll ping Matt after the call and let him know. Yeah, so we can go ahead with this. Mikhail, you had a pr to add to validate the blob version hashes in the engine API. Do you want to give a bit of context on that? I saw you just opened the. Oh, is Mikhail here? He is. So, okay, so this is a pr.
00:02:02.934 - 00:02:12.618, Speaker A: I see Gejinder and Terrence have both plus one bit. Do either of you want to give a bit of context? Sure.
00:02:12.704 - 00:02:39.310, Speaker B: So last week we discussed on pushing the RLP validation from the Cl to El. That means that on the consensus side, when you receive a block, you will convert the KCG commitment to the version hash and then send it to the El via the new engine API code. So it's the same as the new validate payload code, except now you have a parameter that includes the version hash.
00:02:39.390 - 00:02:39.586, Speaker A: So.
00:02:39.608 - 00:03:02.060, Speaker B: Yeah, so that's what we discussed. And on the Cl side, luckily, we don't need to add the new version hash to the blot field because we have the key to g commitments. We can do the conversion instead. But we do need a minor update on the spec. They just basically say that, hey, now we have to use this new API code. So that should be a very simple cl change. I'm not sure if anyone's working on it, though.
00:03:07.140 - 00:03:39.684, Speaker A: Yeah, I don't think anyone's working on it. Shaoi and I should chat about it. Hey, shall we? And one of us should pick it up. It's really the removal of a function and then the change of the interface to notify, of notify payload which is kind of our abstraction for the engine API to pass those fields in. It's very minimal and it's really kind of a subtraction rather than addition on the continuous layer. Sorry, I just joined. I can pick up the changes after that.
00:03:39.684 - 00:04:14.370, Speaker A: So when I was looking at it, one minor issue is that the place we handle the version hash in co code is a little bit far from the process execution payload. So it just diagram. I have to move the sequence of state transition, but that should not be a big issue.
00:04:21.710 - 00:04:33.060, Speaker C: I mean, just check for the validity of the payload and I can sort of make the corresponding change in consensus specs to reflect this.
00:04:42.660 - 00:05:31.578, Speaker A: Okay. Anything else on that pr and the upcoming change we need to make to the specs? And I saw Proto just had a comment. Okay. So he's basically saying he's fine with updating everything to SSD at a later date. Okay, next up. So the other thing we discussed on awardes last week was the endianness from the El side. I know there's been some more discussions on the discord and specifically about the scope of the change.
00:05:31.578 - 00:06:12.710, Speaker A: Didn't necessarily seem clear to everyone. Sorry. And I'm trying to pull it up right here, but yeah, I guess. Does anyone have thoughts about just this transition of using big indian completely on the El? Ok. Yes, and I have your. Oh, and Matt, I saw you just said that Blake two uses little indian on the execution layer.
00:06:14.090 - 00:06:16.002, Speaker C: But I think it's the only exception.
00:06:16.066 - 00:06:21.522, Speaker D: Like everything else, all the other pre compiles and the EVM, it's beginning.
00:06:21.586 - 00:06:23.530, Speaker C: Blake two is the only exception.
00:06:27.790 - 00:07:08.150, Speaker E: Did we look through all the other pre compiles? I'm not super familiar with the inputs on them. I mean, it doesn't really matter that much to me. I just know that we are kind of saying this is an argument that everything else is big indian. And I realized that Blake two was not. And so there is precedent of having some little indian. Maybe it was just an oversight. We should do whatever the best thing to do is.
00:07:08.150 - 00:07:19.130, Speaker E: And I just am not the person who's going to be interfacing with this or writing the software that interfaces this. So whatever those people think is the right indian ness is what we should do. In my opinion.
00:07:21.550 - 00:07:44.450, Speaker A: It seemed pretty clear on awkwardness that people wanted to do big indian from the El side. And then the question is just if we do that, does it impact the libraries to too large of an extent. And I know Denkrad and Kev had some spreads about that in the discord.
00:07:47.030 - 00:08:19.150, Speaker F: So if we make the pre compile big. And then basically it would also make sense to then make the blobs themselves big. And because otherwise you will have the same data. Potentially when you use the pre compile on in range, you'll have the same data once in big onion, one in little onion. And that seems really confusing. So if we do that, it feels like the right choice is just to make everything big indian.
00:08:20.450 - 00:08:24.190, Speaker C: So the prs include making blobs big indian.
00:08:36.370 - 00:08:46.100, Speaker A: So if the blobs are big indian, yeah. Doesn't that mean that the CL then needs to deal with the big indian and we're going to have the mirror problem?
00:08:46.710 - 00:08:57.240, Speaker F: Yep, correct. Which is probably why it was a terrible idea to start with, to have the CL be in little engine.
00:09:00.910 - 00:09:43.830, Speaker C: To just verify the blobs using KZG libraries. I don't understand where the CL would actually be interpreting the content of the blobs. And now we also have version hashes that CL will supply, which El will check. So CL does not actually has to check whether the transaction and the version hashes match. So basically transaction and the commitments match, because CL is creating the version hashes for El to check whether the transactions and the created version hashes match. So as of now, I don't see whether CL actually needs to interpret the blob.
00:09:57.460 - 00:10:01.490, Speaker A: Sorry, I really didn't follow. Could you repeat that?
00:10:03.300 - 00:10:42.910, Speaker C: So the only point the CL was interpreting the blob as of now was checking whether the KZG commitments and the transaction version hashes match. So as of now, if there is a change, that CL will send the version hashes, computed version hashes to EL to match. So basically CL only has to do kicker of the. So CL right now does not need to interpret what the blobs are. So it does not actually need to know what the content, whether the content of blob is.
00:10:46.660 - 00:10:57.200, Speaker E: Doesn't the CL have to interpret it? Whenever it computes the KCG commitment, it verifies the KCG commitment.
00:10:58.180 - 00:11:56.970, Speaker C: So that is happening through KCG library, which will basically sort of transfer. It's opaque to the CL. And as far as I can remember that CKGZ Gauss, I think have told me that the KZG libraries will automatically check whether the BLS field elements, they are basically under BLS modulus. So basically CL doesn't need to do any check, they just need to pass verify blobs batch or whatever, and everything else will be handled by the KZG library.
00:12:08.890 - 00:12:20.620, Speaker A: Right? So light client has a comment saying like, it seems like based on what you just said, we can use big Indian in the EL and Lilondian in the CL, is that correct?
00:12:22.270 - 00:12:23.660, Speaker D: Sounds like that's the case.
00:12:31.690 - 00:12:50.380, Speaker C: Only deals with SSD types of the blobs to sync them. And essentially I don't see how it has any impact on how to interpret the blood interpretation as of now is happening on CL five.
00:12:56.390 - 00:13:00.740, Speaker E: Yeah, it seems like I don't see a reason to make a big indian on the CL.
00:13:04.790 - 00:13:08.900, Speaker F: What do you mean, Matt? You don't see a reason to make the blobs big?
00:13:11.830 - 00:13:24.780, Speaker E: Should probably. The thing should probably just be the normal SSD values, and if they're stored little indian, then that's how the libraries are called. It doesn't seem like that's an issue.
00:13:25.630 - 00:13:45.060, Speaker F: Well, so I think they should be encoded as big indian. If we make a pre compiled beginning now, you can say that from the CL point of view it's just blobs of data rather than being an integer. So that's probably a fair argument. You can argue that.
00:13:46.870 - 00:13:47.620, Speaker A: But.
00:13:50.150 - 00:14:25.230, Speaker F: I guess I'm not completely sure how this abstraction will stand up with future upgrades. Say proof of custody and data will be something probably fine for data availability sampling. Not so sure about proof of custody, to be honest. Just like it does. Yes, theoretically at this point, when it's just blobs, you can probably say oh no, it's just data. So yes, in actual CL code outside of the libraries, you will never have to actually implement anything big. And that's agreed.
00:14:28.370 - 00:14:38.800, Speaker C: Yeah, I agree. Cl doesn't need to do anything big. And again, it's just blobs and some unique array for Cl.
00:14:39.890 - 00:14:58.840, Speaker F: But I'm saying this is now. I think you're not seeing what the future upgrades might. I mean, I still agree it's our best option, but I think future upgrades might make it necessary that the CL will actually have to deal with this as integers and then it will become big.
00:15:05.550 - 00:15:22.634, Speaker C: How can the Cl deal with it? Sorry. As far as I understand, future updates only have erasure coding in it, and I think it can be easily handled.
00:15:22.682 - 00:15:46.600, Speaker F: No, there are other, I think. Do you know about the proof of custody? That definitely involves computations on this data? I mean, again, we will see how much we can put them into libraries, but it will be more complicated because it also involves the private key on the CL side.
00:16:08.450 - 00:16:38.598, Speaker A: Okay, I'm not quite sure where to take it from here. It seems like, I don't know, people have a bit of a different view on what's possible and whether we can actually not have the big engine dependency.
00:16:38.694 - 00:17:14.014, Speaker F: Leak into the clinical. Right. I mean, you can deal with any endeavor, it's just an engineering problem. The question is how annoying it will be in the future. And I agree that right now it seems just making everything big indian is the right thing. And that, yes, right now the Cl can contain all that in the cryptography library, which is good. I'm just saying as a warning, there is at least in the proof of custody.
00:17:14.014 - 00:17:30.540, Speaker F: I see a future upgrade where that abstraction might break down. That's just something to be aware of now that we're introducing. Now basically down the line, I think this might cause us to having to deal with 26 bit big andian integers in the Cl.
00:17:33.390 - 00:18:25.290, Speaker A: Okay, so I guess just to move on, on this call, does it make sense to agree to this here? Probably want to mention it on the Cl call later this week when we have all the teams there. But yeah, basically have proposed having bigendian on the Cl. And it would probably be good if we can have a pr showing this by the Thursday's call. Okay, no objections. Okay, let's do that then. Yeah, we can bring it up on the agenda for Thursday and hopefully, I guess. Does anyone want to volunteer to write that pr on the Cl side?
00:18:33.790 - 00:18:35.610, Speaker C: What is this PR temp.
00:18:36.110 - 00:18:36.860, Speaker A: Sorry.
00:18:38.750 - 00:18:41.134, Speaker C: What exactly is this pr. Sorry, I didn't get that.
00:18:41.172 - 00:18:49.470, Speaker A: So using big indian, like, what would require big indian on the Cl, which is what I.
00:18:49.540 - 00:19:09.030, Speaker C: So that pr is already. Okay, so it's just basically introducing a new constraint. Ndns underscore KZG. And that is basically being used in all the polynomial commitments.
00:19:11.130 - 00:19:26.910, Speaker A: Okay. Yeah. Is that the one, Gijinder? The one that Andrew just shared in the chat?
00:19:27.330 - 00:19:28.734, Speaker C: Yeah, that's the one.
00:19:28.852 - 00:19:57.366, Speaker A: Okay, cool. So let's just make sure to briefly touch on that on the Cl called. At least make all the Cl teams aware. Okay, next up, Jimmy Chen had an update to the builder spec. He can't make the call, but he wanted to share this here. I don't know if anyone had any feedback. I know, Gejinder, you left.
00:19:57.366 - 00:20:06.700, Speaker A: No, sorry. This is from January. Oh, you left some feedback as well three days ago. But I don't know if anyone else had anything they wanted to mention or concerns about this.
00:20:13.790 - 00:20:24.080, Speaker C: It mostly looks good. I mean, feedback was just some issues with how the typing was done, but everything else seems good.
00:20:25.010 - 00:20:46.600, Speaker A: Okay, great. And then, yeah, people can comment on the PR directly if there's anything else. But. Yeah, just wanted to flag that. Then. Next up, Matt, you had a renaming to call data hash blob hash instead. Do you want to give context on that.
00:20:50.650 - 00:21:32.740, Speaker E: Yeah. So on EOF, there is this notion of having data sections within the contract. So you have your executable code, and then you have data that's not executable. And so there's some opcodes that you'd expect to interact with that data, things like data copy. And the data hash sort of conflicts with that naming scheme from EOF, and it's not really clear. Is it the data hash of the blob call data, or is it the data hash of the data section? So I think the blob hash is just a little more aligned with how we're talking and thinking about that blob data.
00:21:33.530 - 00:21:46.070, Speaker A: I don't like it. No, actually, I also like it. It makes sense to me. It's weird you're disagreeing with yourself there, red lion.
00:21:46.430 - 00:21:51.530, Speaker E: I have severe multiple personality disorder.
00:21:53.630 - 00:22:08.470, Speaker A: Does anyone dislike blog hash? I really like it. Okay, I guess no objections. Let's merge it.
00:22:10.760 - 00:22:17.270, Speaker E: Can a four four four author approve it? Do those exist here?
00:22:19.000 - 00:22:35.516, Speaker A: Decrad is a four four four author, I think. Right? Yes. Okay, so, Bankrad, if you can approve Matt's two prs, that would. 6985 and 7001, just so he doesn't force me.
00:22:35.538 - 00:22:39.150, Speaker F: Yeah, once I get back to a computer, I can try to do that.
00:22:39.540 - 00:22:57.890, Speaker A: Awesome. Thank you. Okay, anything else on the spec? Okay. If not. Yeah. Anyone want to give an update on.
00:23:06.340 - 00:23:12.130, Speaker D: Oh, before we do that, there was a pr showed in the. Mario shared a pr in the.
00:23:14.740 - 00:23:35.992, Speaker A: Chat. Yes. I just wanted to chime in just because it also needs author approval. And this is the one we discussed on, right? Yeah, exactly. Okay. Yeah, I guess Matt can approve this one. I think the point with Matt is just because he's an author, he doesn't want to approve his own pr.
00:23:35.992 - 00:23:38.600, Speaker A: Like force merge his own pr.
00:23:38.670 - 00:23:43.388, Speaker E: But, yeah, if it's okay, if this pr is okay, I can approve it.
00:23:43.554 - 00:24:04.144, Speaker A: Yeah, I think on OD core devs, we were all in agreement that we should move forward with this. Okay. Yeah. Devnet five. Anyone want to give a quick update on where things are at?
00:24:04.342 - 00:24:51.650, Speaker D: Yeah, I can give a quick update, I guess. I haven't checked on it this weekend, but last state was we were running into some issues with prism being able to sync, and I believe the only remaining Cl that was still healthy was lighthouse. So on the execution layer, we had some issues with Aragon as well. Those I tracked down the issues and fixed, which is when we turned up the issue with being able to sync from scratch, and things started to get stuck. So last I checked, we still had a prism geth client that was running successfully because it had been going since Genesis and hadn't been restarted. Any of the ones that were restarted have since died. But the lighthouse Aragon lighthouse prism clients were still going.
00:24:51.650 - 00:25:11.910, Speaker D: I think maybe Lighthouse Ethereum js as well. So yeah, I think Lodestar was having issues as well. I don't know if Gajinder can give an update on that, whether that's been fixed or not. Gajinder, you are still on?
00:25:12.680 - 00:26:18.090, Speaker C: Yeah, I think the issue was that after 95,000 slot, basically lobster or any other Cl that I noticed was not able to find a peer to sync the blocks from and of. See, I didn't see any issues with regard to request response. It felt like that the ping to the peers that was not getting successful. So it was not at the level of any of the request response blob methods. I'm not sure why Lighthouse was not able to serve the peers. So it seems to me that as of now, the stalled because except Lighthouse, no other peers, no other clients can drink from it. This is sort of my analysis of western situation.
00:26:18.940 - 00:26:33.710, Speaker D: That's right. There was some concern that lighthouse may be blocking non lighthouse peers, and I guess someone provided us with a flag to disable that. I don't believe we've turned it on yet, so that's probably the next step to try.
00:26:36.880 - 00:26:43.710, Speaker C: No man. Still, it didn't work. That was my question.
00:26:44.980 - 00:27:08.840, Speaker G: Gajinder, I'd be happy to look into this with you if you want to catch up after the call. But yeah, I think we are still, like, we're finding bugs locally with lighthouse peering and with serving by roots request, for example. So I wouldn't be surprised if there are issues with serving other peers.
00:27:13.300 - 00:27:17.510, Speaker D: Yeah, I don't know. Terrence, are you on the call? Is there any update with prism? Do you think this is the same issue?
00:27:19.720 - 00:27:50.396, Speaker B: I'm not so sure. I haven't looked at it. So prism is stuck at the issue where. Remember we talked about that? So blobs by range uses the slots as the gap. But right now there's also the number of commitments in the middle too. So sometimes it's weird if it's all about bond because you're supposed to multiply the slots by the number of the commitments. So there depends on how the responder peer does it.
00:27:50.396 - 00:27:59.600, Speaker B: Sometimes they may serve you too many, sometimes they may serve you too little, but when they serve you too little, in Prism's case, we just couldn't sync.
00:28:10.280 - 00:28:17.320, Speaker D: I'm not sure I followed that entirely. Is this what's returning too few commitments.
00:28:17.980 - 00:28:18.584, Speaker A: Oh, yeah.
00:28:18.622 - 00:28:38.220, Speaker B: So it's the blops here. So blops by range. If in the event that, say, today, there's like four commitments in a slot, and then we get the cases where only one is being returned instead of the four, because it's not multiplying the commitment number by the slot.
00:28:39.600 - 00:28:45.456, Speaker D: So I guess the question what is doing that sounds like you're describing a bug. Where is this coming from?
00:28:45.558 - 00:28:56.822, Speaker B: Right. This is like a bug on the. Some clients have this bug. I'm not sure if it's fixed. That's what we talked about on discord.
00:28:56.886 - 00:28:58.060, Speaker A: Like, a week ago.
00:29:00.430 - 00:29:06.110, Speaker B: So there's some disagreements there between blocks by range and blobs by range.
00:29:10.850 - 00:29:12.510, Speaker A: Did this show up in Hive?
00:29:13.330 - 00:29:31.620, Speaker B: Yes, it could show up in the hive. Right. So say today, if you do blocks by range and then you do blobs by range right after, you should get the blobs that reflect in those block. But then we were not getting that. And, yeah, I think Hive is a very good test target for this.
00:29:32.710 - 00:29:58.654, Speaker A: Are we lacking about returning the blobs from the execution client or is this some other point? This is p two p. So it's not the El. Yeah. Okay. Yeah. The only test we have right now in Hive is for returning the plus from the execution execution client to the Cl inside the get payloads. But I think this is something else.
00:29:58.654 - 00:30:22.102, Speaker A: Right. Okay. Yeah, I need to check on this because we don't have tests yet for that. Okay. Do we have any tests against the independent just Cl P to P messages? No, it has. We have only for the engine API right now. Yeah.
00:30:22.102 - 00:30:27.400, Speaker A: Basically the intermediate might be a good thing to open up.
00:30:28.970 - 00:30:37.850, Speaker G: I think there are a couple of tests in the 4844 interop like Docker compose repo.
00:30:50.500 - 00:30:52.690, Speaker D: Is there a spec ambiguity here?
00:30:56.100 - 00:31:06.470, Speaker B: There shouldn't be, but other clients just maybe interpret it, run. But, yeah, I think the spec is fairly clear here.
00:31:07.000 - 00:31:14.264, Speaker D: Okay. But we're not aware of which clients are interpreting it this way. But it sounds like it's probably a lighthouse since that's the one that can't see.
00:31:14.302 - 00:31:14.952, Speaker A: I don't know.
00:31:15.006 - 00:31:25.416, Speaker B: I forgot. I think I have to look at Discord conversation. But we talked about that a few weeks ago. But I guess people are busy with something else. We haven't gotten into fixing the bug.
00:31:25.448 - 00:31:29.836, Speaker A: Yet, but there is a bug I.
00:31:29.858 - 00:31:50.150, Speaker G: Can look into if Lighthouse is incorrect here. Yeah, I remember the conversation last week and I thought we interpreted it correctly. Apart from we just had like, a maximum response that was too big. But I might be wrong. I'll double check.
00:31:57.990 - 00:32:00.500, Speaker D: Something. We can check on a lode star side as well.
00:32:17.490 - 00:32:20.200, Speaker A: You are mute is in.
00:32:23.770 - 00:32:40.250, Speaker C: Yes, I have two mute buttons. One is on the software and one is the real button. Sorry. So yes I will check on the loadstar side but I think we also take it as slots. The count to be as slots.
00:33:01.980 - 00:33:18.860, Speaker A: Okay. So I guess if this is clear in the spec, is it just a question of Lodestar and prism fixing an issue on their end and then potentially adding some hive tests or somewhere else to catch?
00:33:22.640 - 00:33:33.030, Speaker G: Yeah, it might be a lighthouse issue. And we haven't been testing against high hive yet, so we can work on that in the next week or so.
00:33:36.120 - 00:34:18.960, Speaker A: Just to give a little bit more context about hive. I don't think at the moment we have any similar tests from peer to peer in the VCON client. So we need to write a new test suite for this. But yeah, it's going to take a little bit longer than usual to write the test because there's no test suite that specifically does this kind of test yet. Yeah, that's it basically. Yeah. It would be high value to at somewhere in a deterministic place before we get the test nets test some of this stuff.
00:34:18.960 - 00:34:55.050, Speaker A: Obviously we don't really have a systematic way to test the CLP to p and haven't since phase zero, but if we can move in that direction, it would be a good idea. Yeah, definitely. I think there's a lot of this is specifically what hype is for. It's just that we haven't used it for that. But definitely I will start to work on it and if I need some help from you guys, I will let you know. Awesome. Thanks.
00:34:55.050 - 00:35:06.110, Speaker A: Is there anything else on Devnet five that we're seeing that we feel like we should take time and address?
00:35:09.280 - 00:35:28.416, Speaker D: I think that's the main thing. Right. It's pretty an unhealthy state right now because of this issue. I think once we get that resolved, that's the only one that I'm aware of that's still holding things back. Other than that, we just have to get implementing the new changes that came in in all core devs around dssaification.
00:35:28.528 - 00:35:31.860, Speaker A: Yeah. Rlpification.
00:35:32.520 - 00:35:43.690, Speaker D: Right. So I don't think we want to put too much into this devnet. It would be good to resolve this issue and confirm at least that everything's healthy when this is taken care of. But at that point I think it's probably worth shutting it down and going on to the next one.
00:35:44.380 - 00:36:37.400, Speaker A: Yeah, I think that makes sense. And then also if we can write some test suites in parallel to fixing the devnet so that when we have people joining the next one, we also have better static tests that we can run the clients against. That would be amazing. So does it seem realistic that in the next, basically week or two we resolve these issues and get the implementations done for the RLP changes and the endiumness. And in our call two weeks from now, we can spend most of the time discussing Devnet six and trying to get that set up. And obviously we have the two all core dev calls before that if we're quicker than that. But at the laylist.
00:36:37.400 - 00:37:26.360, Speaker A: Yeah, we can chat about that two weeks from now. Sweet. Anything else anyone wanted to discuss today? Yes, sorry. Okay, just go ahead. Thanks. That small issue which is still not resolved is about CKZG library for old mean. We need to know will blst library be updated or we just need to implement that switch by ourselves as execution layer developers and CKCG library developers.
00:37:26.360 - 00:37:52.850, Speaker A: And additionally we could try to test this case by adding some nodes to the devnet, maybe next Devnet with these old cpus to confirm that verification is performant enough and works on every site. That's two issues. That's it.
00:37:57.990 - 00:38:02.690, Speaker D: This is the compile time detection of, I mean runtime detection of cpu capabilities.
00:38:03.350 - 00:39:00.944, Speaker A: Yeah. Should we do that in CKZG or B list will be updated, consider such case. I don't know how you would do that in CKCG. I think it has to be done in blast. Okay, but shall we wait for this week's ballistic side or not? Because this is a problem, but not sure if it will be resulting zero at any time in the future. Because I get what you're saying. They don't seem very interested in fixing it.
00:39:00.944 - 00:39:36.460, Speaker A: From my perspective, it would be great if we could as a community. I'm not even sure that they would accept a pr that fixes thought pr. I thought Peter had suggested writing a pr, but I haven't checked the thread. Yeah he did. Once again, I don't know how complicated or simple it would be to do that. I'm leaning towards like, I think it'd be pretty complicated.
00:39:39.760 - 00:39:41.230, Speaker H: There were few.
00:39:44.400 - 00:39:55.190, Speaker F: Unfortunately there's this Perl script which generates the assembly, so it is like kind of annoyingly complicated to make changes to this if you don't know exactly.
00:39:59.480 - 00:40:06.570, Speaker A: Not okay.
00:40:08.540 - 00:40:12.452, Speaker H: There is a discussion, a few comments.
00:40:12.516 - 00:40:16.090, Speaker F: In this we will call.
00:40:21.360 - 00:41:22.160, Speaker A: Bankrupt. You're really breaking up. We've basically lost you. Yeah, I think he said they're going to have a call with supernational maybe. I did reach out to someone at supernational privately and they did see the comments, they just haven't made a comment back yet and they were going to discuss it internally sometime this week. Okay, that's good. The second question was, is it real to have such cpus on Devnet next time? Seems a good test case in terms of stability and performance.
00:41:22.160 - 00:41:35.430, Speaker A: Yeah. Well, is there something else we can do?
00:41:39.460 - 00:41:42.980, Speaker H: You mean something else for this runtime detection?
00:41:44.200 - 00:41:51.190, Speaker A: Yeah. Okay, with the runtime detection, this is a change we want supernational to do, correct?
00:41:52.440 - 00:42:39.670, Speaker H: Yeah. The only one workaround I know is on this issue number ten, where you can basically work around this problem by loading two instances of BLST libraries and then in your app change, in your client change, check the cpu and call the corresponding copy of BLST. This is something you can probably do if you need as soon as possible. But if supanation is considering, I mean, if they see these comments and are willing to do something, then probably best to wait a bit and then see what to do. But there is an ugly workaround for this problem.
00:42:54.110 - 00:43:20.034, Speaker A: That's great. We agree to change. Well, we can try. And in the meantime. Yeah, use the workaround. Okay, anything else? I know there was a second. I think Mario was you who also had something you wanted to share.
00:43:20.034 - 00:44:12.920, Speaker A: Yeah, basically. Okay, so first of all, I want to share the link to the test that I will be referring to. So this is the one. So yeah, basically this is the EVM test vectors in the form of blockchain tests, and they do contain a lot of 44 EVM focus tests. So I wanted to propose that before the next Devnet, we make the running of this execution spec test mandatory for the next devnet. Because I think most of the execution layer issues that we found in the previous run could have been caught if we had run this test on all plans. So yeah, basically I think if we clear out this issue before the devnet, we will save a lot of debugging time and we will find more productive issues, more relevant issues that will be definitely more interesting.
00:44:12.920 - 00:44:55.920, Speaker A: So right now there's some spec changes that are not getting tests, but I will make sure that all of these spec changes are in these tests and we will make another release before the next devnet. So I don't know if that sounds good with everyone. Yeah, I agree. That would be really useful. Okay, cool. Yes, so we will be releasing another file with newer tests with the spec updates for everyone to run before the next. Awesome.
00:44:55.920 - 00:45:01.620, Speaker A: Sweet. Anything else.
00:45:06.210 - 00:45:17.250, Speaker D: In the chat there was another mention of the removing contract creation from the blob transaction. I assume that's still not controversial. And added that to our list of prs to get merged.
00:45:20.890 - 00:45:21.974, Speaker A: Which PR was that?
00:45:22.012 - 00:45:29.766, Speaker D: Sorry, Matt had it. We discussed it, I believe it was last week to disable contraction, the optional two field, remember?
00:45:29.948 - 00:45:58.400, Speaker A: Right. Yeah. Does anyone here have thoughts about this? And I assume it would be, sorry possible to add this in another hard fork if, if we wanted to. Right. Like we could launch with it disabled and then six months after enable it.
00:46:02.150 - 00:46:14.600, Speaker D: Now that it's RLP. I don't know, I don't know enough about RLP optional handling. Who's our RLP expert here? Is that an encoding format change if we decide to make it optional later on?
00:46:16.010 - 00:46:24.060, Speaker E: It's just that we don't allow contract creation transactions so the two address has to be present.
00:46:26.910 - 00:46:40.880, Speaker A: Yeah, it would change the RP encoding. And one thing I'm thinking about it would add another thing that we need to check.
00:46:41.410 - 00:47:02.680, Speaker E: We need to make sure that it doesn't do the contract creation. But that's one check versus a bunch of checks around different things. Does it work whenever you create a contract with a blob? Does it work when you create with four blobs? There's a lot of little things that you end up having to check. Does it work when you return code? Does it work when you don't return code?
00:47:16.670 - 00:47:22.746, Speaker A: Yeah, I don't know if it's you that's typing Matt, or double checking with.
00:47:22.768 - 00:47:49.620, Speaker E: The, it needs to change like the RLP encoding spec in the EIP. But we would need to add something to say the two address has to be present. The 4844 transaction type does not allow contract creation, which I can update the pr if people are still okay with.
00:47:51.590 - 00:48:37.394, Speaker A: This. It's, I guess it would, if people are okay with this, can you voice support? I don't know if people are okay with this or have not thought about it and don't understand the implications or something. One thing was we added this when we were going to have to deal with SSD optionals. Right. So now that we're not doing that, I don't think it's as important. And then we have to ask do we want this non standard or non uniform property compared to other transactions?
00:48:37.522 - 00:49:02.960, Speaker E: Yeah, I think that I and some other people that I've spoken to in the past have wanted to move away from having contract creation in transactions in general, just because it adds a lot of complexity when we add transactions and we have the ability to do it from the EVM. So this may look like it's lopsided right now, but I think that going forward we should consider just not allowing new transaction types to create.
00:49:05.490 - 00:49:49.674, Speaker A: Sure, but so this is like SSD in general. If we have this discontinuity, when do we actually make the change? Right now. Okay. I'm leaning towards this, but I think we should have one more week to discuss it with the RP experts in the gas team. I'm weekly in favor of moving this along, but also having the option to say no at some point this week. Next week. Okay, yeah, let's do that.
00:49:49.674 - 00:50:06.080, Speaker A: Then. Let's try to discuss it async this week. If for whatever reason, we can't get agreement this week, async, let's bring it up on all core devs next week. But hopefully we can do. Yeah. Okay.
00:50:06.690 - 00:50:09.360, Speaker E: I'll update a pr and post uncharted data.
00:50:11.170 - 00:50:44.816, Speaker A: Okay, thank you very much. Anything else anyone wanted to cover? Okay, well, thanks. Everyone can wrap up here and talk to you all on the discord. Thanks. Thank you. Bye bye. Bye.
00:50:44.816 - 00:50:47.760, Speaker A: Thanks, everyone. See you guys. Bye.

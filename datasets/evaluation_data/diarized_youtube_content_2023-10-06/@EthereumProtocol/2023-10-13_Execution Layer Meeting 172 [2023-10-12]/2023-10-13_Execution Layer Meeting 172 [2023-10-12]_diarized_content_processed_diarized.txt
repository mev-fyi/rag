00:02:47.690 - 00:03:24.246, Speaker A: We should actually be live now. Welcome everyone to Acde 172. Not a patent on the agenda today, but we'll obviously cover Dan Kuhn. So updates around devnets, around client implementations, and any issues that are coming up. And then after that we have an update on the eof work. So there's been eof breakout calls happening for the past several months. So yeah, the folks working on that will let us know what's been happening there, maybe to kick it off.
00:03:24.246 - 00:03:29.740, Speaker A: I don't know if someone from the DevOps team wants to give a Devnet update and we can start from there.
00:03:30.990 - 00:03:58.580, Speaker B: Sure, I can begin. So Devnet nine is still running. We have about 93% participation rate right now. We have gas and teku submitting bed blocks. So that's about 100 validators off the 1300 that we have around. So that's another 7%. So if you would bring gas and taco back online, then we would be very close to the 100% participation rate.
00:03:58.580 - 00:04:58.390, Speaker B: We have a few pairs that are not working though. I think Prism and Aragon is one of them. And Ethereum JS is struggling to keep up with the rest of the chain because we've been submitting transactions and blobs pretty much nonstop and certain blocks have over 200 transactions and Ethereum JS is just unable to keep up with that. So is supposed to launch this week, but I don't think we're going to be able to manage that. So we postponed it to next week and hopefully next week we can launch it. We would want to have the KCG library available in the consensus back report so each of the clients can include the proper KCG files in their next release. Another note, mvv boost is working progress.
00:04:58.390 - 00:05:34.006, Speaker B: We have working relay powered by Flashbot team and they also have a working builder and we have quite some blocks that were proposed by them, proposed by their builder. So things are looking good. But I haven't been able to replicate their relay infra just yet. But we have the relay running right here. I just think the link for that. And currently we have 265 validators registered for this relay. All of those are loadstar.
00:05:34.006 - 00:05:38.740, Speaker B: I haven't had time to mess around with the reply just yet.
00:05:41.110 - 00:05:41.860, Speaker A: Nice.
00:05:42.230 - 00:05:46.930, Speaker B: Are all the cls ready to test the builder flow?
00:05:54.710 - 00:05:59.750, Speaker A: I guess. Is any cl not ready? Okay. Yes for takeu, yes for prism.
00:06:01.770 - 00:06:03.800, Speaker B: Yeah, that's a better way to ask.
00:06:06.010 - 00:06:06.386, Speaker A: Yeah.
00:06:06.428 - 00:06:24.950, Speaker C: I think the only open question was if Nimbus merged the required prs because earlier, I think all the other clients, we were able to test them on kertosis, but we weren't able to do nimbus yet. Okay. We can ping them later on.
00:06:26.520 - 00:06:30.490, Speaker A: Yeah, I don't see on the screen, but more than one screen.
00:06:32.060 - 00:06:47.950, Speaker B: So there's a good question regarding blobs going through MeV, and we have not been able to confirm any blob transactions using the is anyone from fleshbots here?
00:06:50.320 - 00:06:54.464, Speaker D: I think they have an off site this week, but yeah, that's just something.
00:06:54.502 - 00:07:10.436, Speaker B: We should pay attention to in the next couple of weeks. Yeah, it would be very good if we could have blob transactions going through Mev also, because right now it feels like all the blobs are getting dropped, even when there's some blobs in the.
00:07:10.458 - 00:07:16.470, Speaker D: Pool, like the builder is ignoring them or there's some error. Yeah, okay.
00:07:19.180 - 00:07:26.810, Speaker B: But this is not confirmed behavior just yet. It's just a few examples that I've taken a look.
00:07:28.220 - 00:07:54.610, Speaker C: Yeah, the main issue is that we're spamming so many blobs that we're almost always hitting the limit, and that just increases the base fee. And we're not necessarily sure yet if the missing blobs are due to the base fee being too high and there's no valid blobs that could be included, or if the builder is in fact, actually not including blobs that would have been otherwise included. But we'll try and get an answer for that over the next day.
00:07:55.460 - 00:07:56.210, Speaker A: Cool.
00:07:59.760 - 00:08:23.092, Speaker B: And I don't know if there's any other builder other than the flashbox one. It would be very good if we would have at least one more that we could test out. Yeah, I'm working on one and it should be ready soon. Pm, but yeah, I can circle on with you guys. We can work on that. Yeah, sure. As soon as you have any kind of prototype, we are happy to give you the test.
00:08:23.092 - 00:08:52.150, Speaker B: Also, just let us know. And regarding Devnet ten, we would like to iron out all these Mev questions before we proceed to devnote ten because there's not much point of running with 300,000 validators if we still have open questions regarding Mev bill in. So we're going to hold off with that till we have all of this confirmed.
00:08:54.010 - 00:09:26.430, Speaker C: And the other thing is, because Devnet ten will be bigger, we want to make sure we have enough of the visibility tools to understand how blob propagation looks. Zatools added support for monitoring the event stream for blob related events. And as far as I can tell, Teku's already included that PR, and Prism has the PR as well. If the other clients could include that soon. That would be really helpful because then we can get a visibility on every client and when they're seeing globs.
00:09:37.120 - 00:09:37.772, Speaker A: Got it.
00:09:37.826 - 00:10:16.810, Speaker B: Yeah. And one more quick note, that we plan to have about 330,000 validators, which is a churn limit of five. And we're hoping to make some deposits and exits right after Genesis. And then we're going to have Dankun maybe a day or a day and a half later when all the deposits have reached the chain. And then hopefully we're going to see a cutback from five to four because we're not going to be able to test for the main net defaults or there's no point of testing for the minute defaults. I think it just makes sense to test going from five to four.
00:10:18.700 - 00:10:56.560, Speaker A: Yeah, that would trigger the same code pass, but using the smaller presets. Minimal presets, is that right? Yes. And I guess I assume we'll keep Devnet nine running as well while we have devnet ten, if we're still doing testing on it, because I think it's probably valuable to have it, at least for a while. In the case, let's say there's 300,000 validators, causes an issue or whatnot, to have devnet nine still as a fallback. Is that possible?
00:10:58.850 - 00:11:17.700, Speaker B: Yeah, Devnet nine is pretty low cost, so we don't mind to have it around, but we don't know how long we plan to have Devnet ten. And the whole idea is that Devnet nine should be very stable before we proceed to devnet ten with no more big questions, which we still have at this point.
00:11:18.810 - 00:11:47.680, Speaker A: Got it. In terms of getting ready for Devnet ten. So you said there's the pr that Perry just linked that helps better track the blobs, making sure that the Mev pipeline works well, making sure things are relatively stable on Devnet nine. And you think in the next week or so we can probably deploy Devnet ten, is that right?
00:11:49.250 - 00:11:49.806, Speaker B: Yes.
00:11:49.908 - 00:11:52.510, Speaker A: And the trusted setup. Yeah. Thanks, Barry.
00:11:54.850 - 00:12:03.090, Speaker B: The trusted setup needs to be updated by all the different clients. And I think some of them recompilation or whatnot.
00:12:04.310 - 00:13:23.760, Speaker A: Got it? Yeah, I guess. Do any clients feel like it's not realistic to get this up in the next week or so? Okay. And then I know we had talked a couple of times about Devnet ten being like the last Devnet if things go well. So assuming Devnet ten goes well in the next week or so, does it make sense to then start targeting Gordy in the weeks after that? So either, I don't know if by next Cl call we'll have seen the results, but the verities by the next alcohol devs we should have at that point, assuming things are working smoothly, are people comfortable moving to, say, gordy? I guess. Any oppositions or pushback?
00:13:27.700 - 00:13:30.950, Speaker B: I think we should definitely wait for the results of Devnot ten.
00:13:31.400 - 00:14:13.050, Speaker A: Okay. Yeah, I think that makes sense. So yeah, I think if we can have launched it by the next CL call next Thursday, that would be amazing. Yeah. And we can discuss it further. Yeah, I guess any client team want to share more about their progress or any issues they have or anything related to the fork itself. There's a comment by Marius in the chat about Peter wanting to have a discussion about bandwidth.
00:14:13.050 - 00:14:26.450, Speaker A: I don't know. Is Peter on the call? No, I don't know. Marius.
00:14:29.530 - 00:15:45.310, Speaker E: Yeah. Doesn't seem like he's here. I don't fully remember, but he managed to get his node up and running on definite nine and kind of saw the bandwidth that it was using because of all the blob spam and it was kind of ridiculous. So he started implementing a transaction handler that will only fetch one block transaction per run, whatever time that is. So it will not over like our current transaction handler would just overload itself. Because if you connect to someone that has a lot of block transactions, they will announce them all and we will just fetch them indiscriminately. I don't know if other clients have thought about this or if other clients also implemented it the way we did because the gas transaction pool actually now tops out at 10gb for block transactions.
00:15:45.310 - 00:16:28.250, Speaker E: And if you connect to a guest node and the guest node announces 4000 blob transactions, it will murder your bandwidth. So yeah, I think we should have a discussion about. I think the consensus layer should have a discussion about three six, like the bandwidth for blocks and like blobs and blocks. And we should also have a discussion about the bandwidth for just the transaction spam.
00:16:32.710 - 00:16:39.830, Speaker A: And when you say I have a discussion about three six, the implication being that like two four would require less bandwidth?
00:16:45.080 - 00:17:06.460, Speaker E: Well, definitely two four would require less bandwidth on the consensus layer. But it doesn't have anything to do with the execution layer. Right, the execution layer. Client teams have to make that decision if they can support it, but they have to keep in mind that there will be blob spam.
00:17:12.220 - 00:17:45.710, Speaker A: Yeah, I know that there was some work done on the gossiping on the CL side. I don't know if anyone who's familiar with that is on the call. Right. And yeah, otherwise I don't know like I'm saying, the CL networking issues is different. Do you have the other els have thoughts on this?
00:17:49.010 - 00:17:56.050, Speaker F: I think we are working on similar things in Nethermind right now, but Marcin, could you share details?
00:18:00.540 - 00:18:02.504, Speaker A: Yes, we are planning to have some.
00:18:02.542 - 00:18:11.900, Speaker G: Kind of rottwing about sending and requesting block transactions, but it's not done yet.
00:18:12.050 - 00:18:15.980, Speaker D: But it will be done before the arc.
00:18:25.350 - 00:19:35.850, Speaker A: I guess. Does it make sense to maybe go into this in more detail on Monday's testing call? I don't know if this gives a couple days for the El client teams to look at it a bit more and then maybe we can have Peter come up there or otherwise someone else from get sort of walk through it in more details. Okay. Okay. Marius, I will be waiting for you on Monday and then yeah, if other client teams want to look at. Yeah, by then we can discuss it more then any other issues that any client teams want to bring up about the fork. Okay.
00:19:35.850 - 00:19:51.870, Speaker A: Anything else that we want to cover before going into EOf otherwise, dano, I think you're the one who's going to share the update, is that right?
00:19:53.940 - 00:20:03.760, Speaker D: I think so. Don't see any of the other typical people on the call who've been giving feedback on my slides. Do I have screen sharing capabilities?
00:20:04.420 - 00:20:11.750, Speaker A: Try. We'll see. Yes.
00:20:13.480 - 00:20:52.124, Speaker D: All right, cool. So let me get to so the big proposal today. Well, in the update is to move Prague towards being headliner for, to make EOS headliner for the upcoming Prague release. And we're going to give an update of where we're at and what's been developed and what EOS is. Make sure everyone's on the same page for what it is. So first, when I say we and R, I think that's important to talk about that and I can figure out how to work the slides.
00:20:52.172 - 00:20:52.720, Speaker A: Okay.
00:20:52.870 - 00:21:23.550, Speaker D: And there's four major groups of people working on the EVM object format. The first team, the team that created EOF and did a lot of the early legwork in getting it up and running is team Epsilon. This is an EF funded team and it's focusing on EVM improvements. They also have another project that they run. They make a standalone c plus plus interpreter, EvM one. And they used to work on the ewasm. So they know a lot about why Wasm won't really work from doing it, which is really important to know that through doing it, why it won't work.
00:21:23.550 - 00:22:12.788, Speaker D: Second group of people is we have execution clients. Representatives from there have people from Geth basically would never mind. And occasionally we've had some aragons, but they're going to work with mostly gets VM, so it's going to be fairly easy to port there. And at least back in January all the teams had the same quote unquote big EOF implementation, and we were actually doing fuzzing on a container format and on implementations before it was decided that EOF was not ready for Shanghai. Part of the reason we discovered why EOf wasn't ready for Shanghai was the third group that's been involved, very involved in the past few months, the compiler teams. We've had representatives from solidity and Viper giving very valuable feedback on some details of EOF. A few new features have been added to support them, but mostly it's been working on the finer grained details of we need this for the compiler.
00:22:12.788 - 00:22:50.980, Speaker D: This will solve some size regressions, it's mostly there. We have most of the solutions we have we know that we need to do in either this release, in a big release, or maybe in a few opcodes in the next release. But their input has been invaluable in validating that what we work for EOF is going to work within the compiler teams. And another important thing is that the downstream users of EOF, the compilers themselves, are on board with it. And I think another important group that has shown up is we've had some people come in from various data contract teams s store. Two is one of them. They want to use the contracts for data, and they've been interested to see how some of the changes we've been doing from EOF will impact their work and what we have.
00:22:50.980 - 00:23:44.936, Speaker D: There's one opcode they have proposed that would make their job a lot easier. But even if we don't have that opcode, they're confident that what they're doing, test or two, will work with EOF and will be acceptable for what their needs are. So what is EOF? EVM object format is mostly a container format for EVM code. The big thing is it separates code and data, which is one of the big base problems when it comes to taking EVM and converting it to any other format is where's the code and where's the data? And can we make hard and fast rules about it. Solidity and Viper have adopted some conventions, but those aren't enforced as part of the container format. Container format makes a separation mandatory, and it also requires that all code is valid. So if you see bad data in there, you can't see bad code in there that is masquerading as data or data masquerading as code.
00:23:44.936 - 00:24:37.412, Speaker D: If it's code, it must be valid and it must be executable, and data can be whatever it needs to be. And the two never mix. And because of this, we're able to fix a lot of EVM evolution problems. A famous one is we're not able to add any opcodes that take immediate arguments because of an interaction that if a jump desk is inside of what would become covered by invalid code, that would make the next immediate the jump target and get rid of that jump target. In theory, you're changing the execution of the contract. So that was something that was done away with pretty early in the process. And we're also able to prohibit a lot of problematic behavior, a lot of things that get in the way of supporting things like ZK and translation to other formats and just translation between different versions.
00:24:37.412 - 00:25:15.152, Speaker D: Know the EVM if we need to change things. So that gets it to the next question. How many versions of EOF are there going to be? How is it going to work? The idea is that EOF will operate in parallel with legacy EVM smart contracts. I don't think there's a reasonable way, short term, to ban legacy EVM code. Maybe in long term, once EOF has wide adoption, and we can lock down the addition of new contracts and do that deliberately. But as far as EOF, I think the plan is there will only be one version, and if we need to update the format, there would be standard translations between the two. But that's not set in stone.
00:25:15.152 - 00:25:43.116, Speaker D: But what's planned today is there's just one EOF version and one legacy version. Now it sounds like we're putting two vms in Ethereum, but we're not. The difference between EOF and legacy EVM are almost entirely in the packaging and the validation of the code and in some of the opcodes that are supported. But once you get away from that, the EVM, legacy EVM and EOF are the same. They use opcodes, they use stacks. They access storage in the same way. They access accounts in the same way.
00:25:43.116 - 00:26:02.100, Speaker D: They work with message frames the same way. They revert in the same way. Memory and transient storage are performed in the same way. It's just a different way to package it. It's whether you're driving a truck or a car, I guess is probably the best way to describe it. There are still four wheels. You still have to follow all the traffic rules.
00:26:02.100 - 00:26:56.390, Speaker D: There's just a different place to put all of your equipment goes in the back of the truck. So I would say EOF is the truck because we separate the cargo from the people. Now, what are the major features of EOF? Now that we've an overview of how we're going to do it and where it fits in, what are these big, major problems that EOF is fixing? And I've identified about eight major things that EOF addresses. The first thing is the container itself is a big feature set of EOF to separate data and code static jumps, something that people have been asking for for years now that we can do immediate, it's something we can build into EOF. Another thing that people have been asking for for years is subroutines. We have a facility that does subroutines really nicely. Code and data separation is another issue that gets up.
00:26:56.390 - 00:27:27.964, Speaker D: And finally some of these things down. Here are some more recent discoveries as we're working with the EVM and working with these ZK systems and everything else. Some things that will be very useful and valuable to make sure that we don't have to mess with EOF. That in theory, this version of EOF could be the one, and forever, if we get everything done right. The first thing is we're removing code introspection capabilities. That means that you can't take code, put it into memory, and then deploy that. What you execute and what you deploy come in two different streams.
00:27:27.964 - 00:28:08.584, Speaker D: I'll talk about that in a slide later. Down gas observability is another problem. Let's say we need to change this gas schedule dramatically again. If you can't tell how much gas you're using and can't control some things about gas, then there's easy solutions to change those schedules. Code and stack validation is another important thing that we can make sure that we're actually putting in real code, and that makes it easier to add things to EOF without having to reboot the world. If we can guarantee that an opcode that is not used doesn't show up until it's used. And the last one that came up in the past couple of weeks that we've been talking about, haven't committed to, is to maybe prepare for address space expansion.
00:28:08.584 - 00:28:49.096, Speaker D: A little bit of EVM trivia. Any opcode that takes an address will only take the lower 160 bytes of the stack argument, and the top 100 so bytes or whatever is left over are trimmed and this is used. Sometimes it's useful in some ABI decoding tricks, but if we want to use address based expansion, we need to make space for that, and EOF would be the right time to do it. If we're going to break things that need to be broken for the future. Let's break them now in the EOF container. That's kind of the theme going on there. So the first thing is the EOF object framework described in EIP 35 40.
00:28:49.096 - 00:29:43.880, Speaker D: It defines a container format and it's got basically five sections, the header, the types for stack validation, the code itself subcontainers, which is something we'll talk about in code creation. This is basically if you have a factory contract that's deploying other contracts, it's going to show up in these subcontainers. And finally the data section where you can store your data and your constant variables. The next EIP 4200 static relative jumps, fairly simple. We ban three instructions jump jump I and PC and we add three instructions, r jump r jump I, and we take the opportunity to add a really useful instruction, a vector jump operation which will save a lot of code in things like solidity and viper compilers. They can do some really useful things with that operation. 47 50 we add functions, aka code sections and this is the subroutine support solution.
00:29:43.880 - 00:30:09.580, Speaker D: Code is broken into separate code sections. They're self contained. To support this we need to add three opcodes, call f, return f which is basically your go sub and your return sub, and jump f, which is basically tail recursion support. This is something that could be really useful for a lot of recursion solutions. You could jump f into yourself and other things. It's something that compiler people get really excited about. Java wishes they have it and we don't.
00:30:09.580 - 00:30:49.488, Speaker D: So we're going to put it in EOF. And there's also stack height restrictions that are enforced with the opcodes when you go between the functions. So they actually act like functions you pass in three stack items. One stack item comes out, you can conceptualize it like that. EIP 663 Unlimited dupe and swap is a really old request to access the full depth of the stack. Right now it's looking like it's going to be a dupe n, which dupes an arbitrary depth in an operation called exchange. This used to be swap n, where you'd have two immediate arguments, but there's duplication like swap two three and a swap three two are doing the same thing.
00:30:49.488 - 00:31:15.080, Speaker D: So if we do some neat tricks with requiring them to be in order of the stack, you can access twice the distance. With smaller operation codes. We may have a two byte variant of the exchange. These are some of the details we're working throughout. Now the old dupe and swap instructions will remain even though we could get rid of them. We don't want to disrupt the instruction set too much. EIP 74 80.
00:31:15.080 - 00:31:58.116, Speaker D: So now we're getting to some of the higher level requests, and this is for remove code inspection capabilities, and this is the read half of that. So in order to prevent code from being introspected, you shouldn't be able to read code that other contracts have. So we're going to have to ban the ability to read your own contract code, code size and code copy, and also to read other people's contract codes. Exe code size, exe code copy exe code hash. So the problem is, we discovered in Shanghai, is that solidity will use this data to write immediate, to write constants. They'll rewrite their code, sometimes for constants for the constructors. So to accommodate that, we allow access to the data section from within your code.
00:31:58.116 - 00:32:32.572, Speaker D: You can load data from your data section, data load, data load end as an immediate argument variant data size, data copy. And you can access your data in your contract and you can expose it to other people if you want through methods. It goes in the stack and the data works just fine. Now, a couple of compatibility things is that the legacy EVM will not be able to use exe code into EOF contracts to ensure this readability results. There are some standard responses that we have planned. It'll look like really short contract and they can't read it. And also datastar.
00:32:32.572 - 00:33:00.948, Speaker D: I should have dropped that last line. That is something that's under discussion. These may or may not be available to. There's an ext data copy that may or may not be available. So I should have fixed that last night. The right half of the code introspection capabilities comes from the creates. And as we know, when we do creates now we take the entire contract, we put it into memory, we wrap around it to memory, and we deploy those bytes.
00:33:00.948 - 00:33:33.168, Speaker D: That is not something that's going to work when the underlying execution is not necessarily interpreted in UVM. If you're taking these contracts and compile them to a ZK circuit, it makes it really difficult. And you got to have these like terabyte RAM systems to generate the proofs when you do that. So we're going to propose a replacement called create three and create four, where you create your contracts. But the code does not exist within the EVM. It comes from outside of the EVM, from two different places. Create three handles it where the EOF container contains the code you would be deploying.
00:33:33.168 - 00:34:17.756, Speaker D: And this is useful in factory situations where you're like deploying another liquidity pool, you know what that pool looks like. So it's going to be in the EOF code and you're going to deploy it straight from there to get your factory together and it comes all in one contract and it's all self contained, so you never have to see the code and you can deploy it. And the other option is create for and that's where you get it from someplace outside of the EOF container or the EVM completely. And the initial plan is to have it from a new field in a new transaction type. We're going to need to see where SSV winds up in the next few months or we're going to need to put a new RLP type to get these transactions. To get the contract data in a transaction type and create four is a bit flexible. We could go crazy if we want with L2s.
00:34:17.756 - 00:34:54.690, Speaker D: We could have L2s that have a small stable of contracts that will allow you to do and create fork and access those. But for mainnet we're just going to do it in transaction type. We need a new return code to handle adding data onto the end of these contracts. And this is something that solidity have explicitly requested for their immutable values. So if you say that you have a constant, finally to initialize in your constructor, we actually write that into the code that's deployed as part of data at the end of the existing data section. So return contract also allows for auxiliary data to be added on to these contracts. Just data, no code.
00:34:54.690 - 00:35:24.472, Speaker D: Now to handle the remove gas observability capabilities, we need to address gas and the call operations. So call code is on this list. But whether or not 70 69 advances call code is not going to be an EOF. It's going to be one of those ban instructions. Call code and self destruct will not be an EOF regardless of how things shake out in any of these other eips. But the remaining four operations banned would be gas. You can't query how much gas do I have left? And call static call and delegate call.
00:35:24.472 - 00:36:10.404, Speaker D: The reason we need to replace call with call two. Static call two and delegate call two is to remove the ability to specify how much gas. Instead replace it with passing in all the gas you have with some stipend restrictions and reservoir restrictions so that it's mechanical and whether the 63 sports remains or gets changed is all transparent to the contract. And what's interesting is we're also going to take the opportunity to remove the output location stack operands to make it even tighter and smaller, because a lot of people just use the return data and we could do return data copy at an opcode. That can make things smaller and tighter. So your calls can be as low as four bytes or three bytes, depending upon which variant that you're doing, if you're passing in value or not. Delegate calls, not three bytes.
00:36:10.404 - 00:36:49.732, Speaker D: Delegate call would be like a three stack argument, which would really make things a lot more compact on calls. Now the fallout of this is a really valuable thing. If we need to change a gas schedule and increase SDor operations five x there's not going to be any contracts in EOf that are going to be frozen because you can't specify too little gas going on to the next call. This is the problem we had back in Constantinople and something we fixed in Berlin with the access list. But if you can't specify gas, which is by the way, that's the default operation of all compilers. When you do a call, unless you specify gas, it sends it all that. If we increase the gas, then the solution to a gas schedule changes.
00:36:49.732 - 00:37:37.660, Speaker D: Always send more gas at the top level transaction. And finally we get to some of the more just details of making sure the EOF works well. 36 70 specifies the code validation. We check things like make sure the jump destinations are fine, code sections exist, the containers exist, and it also makes it so we can make future evolution of EOF. If there is code that is not going to show up, we can use an opcode and we can be sure that it's not being used elsewhere. 54 50 adds EOF stack validation this is some inside stuff for compilers to make sure that we can do optimizations and interpreters. This will allow us to create minimal size stacks for contracts, rather than creating the big 1024 stack and hoping they don't overflow.
00:37:37.660 - 00:38:22.204, Speaker D: We can guarantee through code it's only going to consume ten and we only need to make a stack of ten, and we can optimize a lot of performance in the interpreters because of this. I'll come back to Mary's discussion at the end of this, but that's a good point. Some miscellaneous notes. There's some corner cases that we need to put in to make sure that things work out well. One notable thing is EOF and legacy can freely call each other, with one exception, EOF cannot delegate call legacy. And the reason we do that is because the next point, which is self destruct, is banned. So if you have an EOF contract, you could delegate call to a legacy contract that all it does is self destruct and all of a sudden we have to deal with self destruct inside of EOF.
00:38:22.204 - 00:38:47.864, Speaker D: So that's why we don't delegate calls. You can't use delegate call as an escape hash to get access to functionality. We banned inside of EOF. And another thing is eof and legacy cannot cross create. Your EOF factory can only create EOF contracts. Your legacy EVM can only create legacy contracts. This keeps the two worlds a little more rational and a little more sane so we don't have to deal with this big matrix of what if this happens and what if that happens.
00:38:47.864 - 00:40:09.252, Speaker D: It's just a lot easier to implement. So quick summary on the opcodes there is a net plus two of opcodes available inside of EVM. There may be some more coming there may be about four more coming to accommodate compiler performance regressions size and mostly size regressions for code. But the minimum required are these opcodes to address Anscar. We're kind of removing self destruct in Dencoon but in the EOF code you can't even have the opcode we can't even have the sweep operation. We're just getting rid of it completely. There's none of this games about can you do it on the same transaction? So we have nine operations that we are replacing functionality with to deal with the improvements we're trying to do within EOF and the worlds we're trying to change there are seven opcodes that we are straight up removing with no replacements gas, Delta, strut, Callcode, PC, the ext ones and we are adding nine opcodes to add features that make sense within the EOF vector jumps, subroutines, unlimited dupe and swap and the data support to handle the exe code.
00:40:09.252 - 00:40:54.124, Speaker D: I mean it's kind of a replacement for the XT but kind of not really for the code copy and code size and return contract for creates. So talking about some of the more inside baseball features of what's going on one of the biggest issues is of course testing when you ship things for hard forks. And I think we're going to have a little bit of a different, little easier time, a little more well defined time than some of these larger network changes. The reason is the EVM is fairly self contained. We don't need to worry about network interactions we don't need to worry about pairing with different Clel combinations. I don't think we're going to need the same level of Devnet and Testnet and that's because of the way that we're able to test it. We're going to write explicit reference tests.
00:40:54.124 - 00:41:23.628, Speaker D: These are the gold standards for are you a compatible EVM? Is. Do you run these EVM tests? The client teams can help out because we need to test our own code and some of our tests become great reference tests when we test the edge cases. The big advantage that we have is this differential EVM testing that's been going on. Martin wrote some differential testing, Marius wrote some, guido wrote some. And they've made some amazing findings. And it's been pretty boring recently with their differential testers. They've been running them for a while and haven't been finding much.
00:41:23.628 - 00:41:59.968, Speaker D: Guido's got to be able to find for basis. So far is a few performance issues, some corner cases that are really creative and inventive that the fuzzer was able to find. Probably get a blog post about some of his findings here in a few months once it's shipped on Hedera's main net. But these fuzers are great at finding these strange problems. And we also have container fuzzing that Martin had written back in December, January to test the container fuzzing. So we can test that. So the big proposal is when EOF is that it would be the headliner for Prague.
00:41:59.968 - 00:42:31.360, Speaker D: And I would think it'll be three to six months after Cancun actually ships on Mainnet is when we would start or actually ship it on Mainnet. My thought of you would ship at least three months after Cancun. We would start the testnet cycle, but we'd be doing Devnet cycles well before then. So that over three probably. So I think Martin said we can't modify the gas schedule anyway since most contracts will be so. Right. So this gives us the flexibility for EOF to charge different gas schedules.
00:42:31.360 - 00:43:17.836, Speaker D: But as far as thinking outside of Mainnet, if we had L2 s that were just EOF, they could have much more flexibility in their gas schedule definitions. If we had ZK systems that were all EOF, they already are doing crazy things with their gas schedules and self destruct. EVM is used to have consistency issue, which some issues don't happen. Yeah, that's why we test very thoroughly on evms, very extensively. So it's not that it's without risking testing. The risks are just shaped differently and Anscar in my opinion. I would really like to see one more round of is this as Ford compatible as possible regarding gas introspection without excited use.
00:43:17.836 - 00:44:03.000, Speaker D: This brought to Mainnet ideally in the next fork. So yes. So if anyone has any opinions on things that need to be addressed to ensure that EOF is maximally forward compatible, please bring them up. We have calls every Wednesday on weeks off of the execution call. At about roughly the same time, call in with the EVM channel, share all the information that you have, share your opinions. Now is absolutely the right time to bring anything else up. Yeah, the best discord channel is going to be EVM and the EFRNd discord.
00:44:03.000 - 00:44:09.840, Speaker D: That's the best place to discuss this. So that's the end of my presentation. Open for questions, concerns, comments.
00:44:13.540 - 00:44:28.060, Speaker A: Thank you. Okay, Barton and Beth has a couple of questions. Do you want to read them off? Yeah, answer them.
00:44:29.150 - 00:44:37.120, Speaker B: Yeah, sure. So my main question is, who is the UOF champion and who is pushing for all of these changes to happen?
00:44:39.410 - 00:44:56.520, Speaker D: I would say team Ipsilan probably has the strongest ownership of it. I happen to have some slides ready because I presented about this asean Chicago. I'd be willing to slide in that role if Ipslon doesn't want to, but I think strongest has the strongest stake in this right now.
00:44:58.570 - 00:45:07.480, Speaker B: Okay, my next question would be do we have a spec list ready? And is the spec list like pretty much good to go? Is it ready?
00:45:07.790 - 00:45:32.254, Speaker D: So we have hackmd. That is a fairly complete list. Basically it's complete list. We're not adding new features. We might add some things like jump Fi for conditional jumps and conditional calls and an exe code copy. But the list of possible ads is really slow and yeah, light client pasted it well. That's the full spec right now.
00:45:32.254 - 00:46:10.454, Speaker D: There's some additions that we're talking over with Viper and solidity that might be added, but that list is also small. There's another list that has the open issues and those are discussed there. I don't have that on hand currently, but if you go into the EVM channel and scroll back, you'll find the open issues link for sure. But as far as specs, I think the only specs we are missing are the data spec and the create three create four spec. And I think what's holding off to the create three create four spec is we're trying to get some signal on whether we should propose a field in the SSV or whether we should propose a new transaction type like the blob.
00:46:10.502 - 00:46:11.100, Speaker A: Type.
00:46:12.910 - 00:46:47.014, Speaker D: Where instead of passing in blobs, you pass in contracts. And so there are a couple more eips that will be posted and also just the whole drama with the EIP split. I haven't been writing eips until we get more credit on that because we weren't sure where those were going to land for the Prague release. But it looks like the split is actually going to happen. They're just working on final technical details. Can we begin planning EF only devnets? So we're about a month away from. Go ahead.
00:46:47.212 - 00:46:56.780, Speaker B: Yeah, you mentioned that we don't need proper devnets for interrupt, but I think testing the fork transition is one of the major questions here.
00:46:57.470 - 00:48:14.130, Speaker D: Yeah, so yeah, we can test the fork transition for the devnet. I guess my comment about the devnets is we're not adding new network behavior, we're not shaking out network behavior in the new clients. So doing a shadow fork really wouldn't do much unless we're going to inject new transactions and put in new EOF contracts and execute and exercise the new EOF contracts. Whereas when we were doing the merge and when we were doing withdrawals, shadow forks were invaluable and the best way to test them, I think when I say testing is shaped differently, things that were invaluable for the merge, I think more useful is going to be the fuzzing and probably test networks. And I think the best thing we could do is just get everyone to get their contracts when they got versions of solidity and viper that will emit EOF and just compile them down into EOF and see how things work out there. Of course, some features won't work if you're relying on exe code copying, but the stuff that does work, that would be probably the best thing is to take these existing contracts, just probably go through ether scan, get all the contracts and just compile them down and just turn on the EOF flag. So that would probably be the replacement for Shadowforks.
00:48:18.250 - 00:48:24.454, Speaker B: Yeah. My next question would be, is any er, clients have any implementation of this.
00:48:24.492 - 00:49:04.500, Speaker D: EOF since we're not finalized on the spec? No, we did have stuff on big EOf that was going to be finalized in Shanghai. That was finalized in Shanghai. I think Nethermind, Geth and Besu had prs ready that were fuzzing to the same results, so that shouldn't take too long. All the heavy lifting has been written into the clients or in the prs, which is parsing the container and making sure that there's interop between the legacy and the EVM. And a lot of the stuff is already still there. We're using the same mop code loops, we're using the same facilities to access accounts and storage. So just wiring those things in there.
00:49:09.000 - 00:49:13.300, Speaker B: Okay, thanks for all the answers.
00:49:17.430 - 00:49:27.190, Speaker A: There's a question around ercs. So some ERCs have tests for contract like ERC 721, unreceived. How would that work without the code introspection?
00:49:28.570 - 00:50:16.326, Speaker D: So if it's, what I'm thinking is there's supposed to be an interface where you can send, where you call a contract with a certain interface, with a certain function, and if it understands the interface, it says, yes, I support that. Otherwise it returns, I don't have that interface. So when you check for on received, you're not actually inspecting the bytecode, because in theory it could be solidity doing. It could be viper, it could be Faye faking it out and accepting an unreceived ABI. So that preambles for these various even solidity versions change a bit differently. So you don't actually check the code to see if you're compatible. You call a function that says, hey, do you support this? And if it understands it and comes back and says yes, then you know it's a 721.
00:50:16.326 - 00:50:21.880, Speaker D: So EOF supports the current framework transparently. I expect it to.
00:50:24.090 - 00:50:33.260, Speaker A: Thanks, Ben. I don't know if that answered your question fully. If not, feel free to either speak up or post a follow up.
00:50:33.790 - 00:50:50.240, Speaker D: Yeah, I think it's ERC 165 is the one I was thinking of. So that's got the standard of how you would call a function to say, hey, do you support? And you would be doing that off chain typically to test for it, although sometimes you wouldn't when you're being sent.
00:50:58.160 - 00:51:26.090, Speaker A: And Alex says none of the y to use ercs actually inspect the code of contracts. Okay, so Lucas has a question. I think, Daniel, you sort of covered this earlier in your slides, but what are the direct benefits of EOF? What does it solve? The complications of the EVM are quite huge. So why is it worth it? Why should we ship it? I know you had a slide with like eight benefits, so maybe it makes sense.
00:51:27.740 - 00:52:06.180, Speaker D: So these are the eight things that we're going to support in EOF. And probably the biggest reason we need to change some of these things is the core of the EVM was written over the weekend. These are people that knew what they were doing with computer science. They done compiler stuff, but they only had a weekend to work on it. And some of these design decisions, they didn't have time to think about what were the 1020 year implications of it. And one of the things that I think that snuck in is the push with immediates, and that blocks out the ability to add other immediates. And then there's also the segmentation of the code that you can't have code and data separated.
00:52:06.180 - 00:53:13.364, Speaker D: So in order to support all that, we can't change those with legacy Eof. But in EOF object framework we get a format where that is logical. So what this is providing us is an opportunity to get a path to make this rational to where when we get the broader EOF adoption, we can slowly tamper down the legacy, make it more expensive, discipline legacy, maybe just shut off legacy and get all the features in EOF and then we could possibly figure out a way to transition legacy to EOF. So that is one long term possibility. But I think the bigger problem that this solves with EOF is ability to evolve the VM in a more efficient and modern way because otherwise we're going to start losing language development to other systems. And that may or may not be a bad thing. But if it's not the main system that mainet is using, there's a risk that we lose the whole is greater than the sum of the parts.
00:53:13.364 - 00:53:26.290, Speaker D: So yeah, there is risk in doing this and risk that it may not be valuable. But as far as making an EOF, making the whole combination of Ethereum mainnet valuable, this provides a path to solving some of those old problems.
00:53:30.560 - 00:55:09.150, Speaker E: Yeah, so I just don't see which use cases would this unlock. Basically everything this kind of unlocks is just making existing patterns in compilers kind of cheaper. But is this really what Mainet should evolve to? I like this idea of having EOf only l two, but then I think in order to support this kind of, we need to completely have these two separate eVMs, have the legacy Evm and the UF EvM, and they cannot interact and this will break composability. So it's kind of a just not, and I've been quite vocal about it, that I don't think uf is a good idea at all. And it's just like, yeah, we're adding some stuff, but we can add most of the things we could add in the existing EVM. And the things that we can't are not quite worth it for me. I haven't really seen a big push from compiler teams really wanting this.
00:55:09.150 - 00:55:19.090, Speaker E: Maybe they want this. And the other thing that I really dislike about it is that now.
00:55:20.980 - 00:55:21.296, Speaker D: Kind.
00:55:21.318 - 00:56:16.896, Speaker E: Of this verification of the code becomes part of the consensus. When you deploy a contract, the contract code has to be verified, right. And this thing we can shoot ourselves. The verifications, as I understand, are not that complex, but we might want to do more complex verifications. In the future. And the thing is, if I deploy a contract that can evade one of those verifications, then I've kind of totally broken the chain. It's a new big class of consensus issues, of potential consensus issues that we might get with this.
00:56:16.998 - 00:56:28.470, Speaker D: Right? Yeah, Anskar's got his hand risen on this question, so I'll let him. Seems like he wants to answer some of it. Or do you want to ask the.
00:56:29.960 - 00:57:14.756, Speaker G: Yeah, I was. It's only a partial answer, but basically to the question of what is this useful for and why would we want this? To me a value of this that I think is maybe a bit less tangible but also very important is that right now, a lot of the times when we wanted to make changes, we were always very hesitant because it breaks existing code or at least potential edge cases. Like anytime we want to do repricing of opcodes we have to be very careful. And with address based extension. One of the reasons we didn't end up doing is that it kind of is really hard to make backwards compatible. One of the things that would excite me a lot about UF is just that of course it doesn't fix that. We have existing contracts that will still have the same problems.
00:57:14.756 - 00:57:59.180, Speaker G: But once we have this out there and maturely supported with all the compilers, we can tell people that best practices to start using EUF. And then at least that means that two, three years down the road we can start to be a bit more easy with making some compromise, breaking a small amount of legacy contracts in a somewhat more aggressive way with three pricing and all these kind of things. Because we have this great new, more robust world that we want everyone to be in anyway. So to me it just makes it a really nice transition to hey, this is the world. If you really want to make sure your contracts are long lasting and have completely reliable behavior, please move over there over the next one, two years, something. So to me that's very appealing.
00:57:59.340 - 00:59:03.340, Speaker E: Yeah, but this only works if we suppose that EOF is the end all, be all of always. And I don't see it this way. There have been changes to EOf even quite recently. And so I think in five years we will say, okay, EOf version one didn't have these five features that we really want and we're going to do e of version two now. And then we're pushing all this work onto client teams. They have to maintain two different versions of the EVM and maybe in the future even a third version. And also the argument that L2 specific e of versions would be nice because the l one teams have to maintain or are maintaining the EVM.
00:59:03.340 - 00:59:52.100, Speaker E: Yeah, sure. Like l two teams, they don't want to maintain the EVM because it's honestly a pain in the ass. Now because they don't want to maintain one evM, they're going to push all this new EVM work onto the client teams as well. And we have to maintain two. So I don't see this as just conceptually as a great way. I think l two teams should maintain their own software and not really depend on l one teams kind of providing the software for them and them building like small pieces on top. But that's just a personal opinion.
00:59:52.100 - 00:59:56.688, Speaker E: All of everything I'm saying is a personal opinion.
00:59:56.864 - 01:00:15.388, Speaker D: Right. So there's a lot of issues there. But the one I want to pick out is the idea that in five years you're going to keep adding features. We've been adding features to legacy EVM since the beginning. We've been dribling opcodes. We just added opcode two weeks ago. But there's two categories of changes that EVM and EOF would both still support.
01:00:15.388 - 01:00:37.700, Speaker D: The first set of changes are compatible changes. You drop in a new opcode, that's easy. And there's incompatible changes like say we change what self destruct does. Those take a lot more changes. So what we're trying to do in EOF is we're trying to make as many of those incompatible changes at one time. So we do it once. So the container format ideally doesn't have to change again and can evolve in compatible ways.
01:00:37.700 - 01:01:18.140, Speaker D: So if we need to add a new profile type section, there is an EIP about EVM profiles. We could add a new header type and that falls into the second point on the left as we would make invalid byte sequences valid. So if you had that before you would add it, you could now have it. By requiring validation and requiring things become valid, we make sure that garbage doesn't accumulate on the chain. By submitting random bytes to the chain, we're not blocking out stuff that we couldn't do before. The only validation that happens in EVM right now is at runtime. We make sure that your jump destinations are not in immediate arguments pushes.
01:01:18.140 - 01:01:58.110, Speaker D: So we really do some validation, some jump test analysis. But the validations we define are their linear time. We're charging for them now with deploy. And a lot of these decisions that we're making for these compatible changes make us so that all the things that we need to add to EOF don't require us to change the operating structure and don't require us to change new bytecode so it allows it to live there just the same. One example would be EVM max. If we want to add modular exponentiation, we can add operations that have immediate arguments on it now, which we cannot do in legacy EOF. If we want to add a new argument that has legacy operations, we break stuff.
01:01:58.110 - 01:02:47.470, Speaker D: A couple of my slides here show the story of how if we wanted to add our jump with an immediate, we would take stuff that was invalid and all of a sudden move it into immediate data. So we change a jump desk and we would move it into immediate data, and we would break things if we add an immediate. So stuff like that is what we're trying to fix so that we can grow the EVM in the future. I don't think that we're not going to be able to ossify the EVM until we ossify the consensus layer. So that the EVM is going to be frozen forever is only going to work once we freeze forever the consensus layer. Once things stop changing, then things can stop changing. But this structure allows us to grow rationally and to be able to do more things and grow in better ways to deal with these new.
01:02:47.470 - 01:02:48.670, Speaker D: So.
01:02:51.200 - 01:02:56.416, Speaker A: Thanks. Andrew's had his hand up for a while. Yeah.
01:02:56.438 - 01:03:44.230, Speaker E: To my mind, a big benefit of EOIF is that it's more constrained. So you have separation of code and data, and you disallow dynamic jumps. So because it's more constrained, it should improve security of smart contracts and facilitate verifications. Verification of smart contracts, either manual or automatic or semi automatic. So I think it's a step forward. So I kind of disagree with this, that we cannot freeze the EVM without freezing the consensus layer. I think those are kind of different things.
01:03:44.230 - 01:04:32.510, Speaker E: And at least I like this assumption that once you deploy a contract, it's mostly mutable. But I don't know, it would not be. We are breaking this assumption with self destruct, but I see the need for. Yeah, I don't know, for the EVMX. I think we can build EVMX without immediates. It would just not be super gas.
01:04:35.170 - 01:04:35.582, Speaker A: Of.
01:04:35.636 - 01:04:46.740, Speaker D: That's where we're going to start losing compiler people. If we say you can still do it, just not gas efficient, they're going to say, well, I should just build it in swayer, I should use stylus. So that's the risk that we're looking at.
01:04:59.000 - 01:05:05.370, Speaker E: I see. I understand the risk. I have to think about it.
01:05:07.900 - 01:05:11.240, Speaker D: It's not a security risk, it's more of an existential guillaume.
01:05:12.240 - 01:05:29.330, Speaker F: Yeah, that was actually a question for Maris. I don't see exactly. Could you detail the argument where it would be harder to maintain different versions of EOf as opposed to a different fork? To me it looks exactly the same.
01:05:36.470 - 01:06:33.202, Speaker E: I don't think so. Like if we change the behavior of an opcode in different versions of DVM. In different versions of DVM. For example, if we have now one opcode that does gas introspection and one opcode that does not in our code, that's twice the amount of opcodes. And testing kind of explodes because we have to test all possible, all possible versions of it. And if we go, for example, now we have one call making something up now. But if we have one call upcode that does gas introspection, one call opcode that does not gas introspection.
01:06:33.202 - 01:06:52.800, Speaker E: And now we have a new version of the. We have a hard fork that changes the order of arguments for the call up code. Then we will have to maintain four versions of the call up code. That's kind of my.
01:06:53.250 - 01:06:59.870, Speaker F: Wouldn't you just change the format and then maintain one per format version?
01:07:02.210 - 01:07:02.960, Speaker E: Sorry.
01:07:04.210 - 01:07:34.118, Speaker F: Okay, maybe I misunderstood, but I mean, I don't see where the four comes from. Because for me, if you change the cold op code, you would just. I mean, we can also take this conversation offline. I'm not trying to hog the whole thing the whole time, but yeah, basically I don't understand the four version. I only see two because one of them would be associated to one format version and the new version of the call up code would be associated to the new format version.
01:07:34.294 - 01:07:58.100, Speaker E: Yeah, but then we have, then we have a hard fork that changes the ordering of the arguments, for example. And then we would have to either, like, we would have to apply it to both versions. And with this we would have to maintain four versions. Two old ones.
01:07:58.550 - 01:07:59.682, Speaker F: Okay, I get it.
01:07:59.736 - 01:08:34.406, Speaker D: Thanks. I think a more concrete version of that would be address based expansion. If you have a balance operation, one that takes the 20 byte version, one that takes a 32 byte version. That's something that is, if we're going to do a stress space expansion is going to be a real issue. And that, I think is the best example of how one, you might choose Eof for things you can't do in EvM. Because we can't just take off the top twelve bytes of all address operations. Because there are AVI decodings that depend on the top bytes being ignored.
01:08:34.406 - 01:09:21.062, Speaker D: And there are some call datas that you can put in that will break if there are not trimmed with some of the pack call data. So there are contracts that would break with address based expansion. And that's why even though it's a recent thing that's brought up is what if we undo a dress space expansion for rent or whatever other use for it if we don't bring it in? In a situation like this now we can't just break old contracts and with container format we could flag to say hey, this one trims, this one doesn't. That's probably not the best solution. I think the best solution is just from day one to not trim. Address arguments in operand stacks and have it be different in EOF and EVM. But these are some of the things going in Georgia.
01:09:21.062 - 01:10:05.610, Speaker D: Given that all this complexity is through a six month timeline postcard can realistic I believe it is because we're shutting down the final features and there's no new features added. We're adding maybe a few more opcodes address these features and we're going to spend a lot of the time testing and implementing. I have been very impressed with the differential fuzzing work that's been going on and it's found a lot of strange corner cases in very creative ways that I don't think we could write tests to cover. So in addition to writing the deliberate tests, I think the differential fuzzing is going to be a game changer in our testing. I think differential fuzzing and compiling old contracts are going to be, which is kind of a different way of doing differential testing, is going to be our equivalent of shadow forks for EOF.
01:10:07.390 - 01:10:09.660, Speaker A: Ansgar, you've had your hand up for a while.
01:10:12.030 - 01:11:25.362, Speaker G: Yeah, I just wanted to mean it sounds like it's probably going to be a multi call conversation around whether UF is a good idea or not. I do think basically one aspect of this that was briefly mentioned but I think will be important is kind of the relation going forward between layer ones and L2s. And with regards to EVM governance, I think so far, basically for better or worse, it always felt that we evolved the EVM and then L2s in a way almost blindly follow. I think in the past there have been some ideas around. At some point maybe L2 is just forking off, having their own L2 EVM standard L2s don't seem to love that idea so far at least. Just one thing I wanted to point out in that context is that Carl, you have and I, we recently decided to initiate some sort of L2 EVM governance call for more L2 specific topics that's going to kick start off next week and then have an in person event during Devconnect. I think basically there will be a lot of similar questions coming up from the other side, and UF might be one example.
01:11:25.362 - 01:11:50.810, Speaker G: Know basically to what extent L2s want to just follow the layer one EVM. So I just want to already flag. Obviously it's too soon now to talk about that, because obviously that hasn't happened yet. But I think this will be a more important conversation around how do we govern the EVM? Will we forever have the same EVM between layer ones and L2s? How do we basically merge the interests of these different groups? So I just wanted to raise awareness.
01:11:51.970 - 01:11:55.806, Speaker A: Thanks. Yeah, and maybe we can post the link in the chat as well. But it's on.
01:11:55.828 - 01:11:56.400, Speaker G: The.
01:11:59.090 - 01:12:06.320, Speaker A: Call is next. What? The first call is next Wednesday. Guillaume, you were next.
01:12:06.950 - 01:12:56.610, Speaker F: Yeah, I just wanted to give some pushback on the claim that we could have a fork three months after Cancun. It's true that the differential fuzzing tools are really useful, but they've been around for a long time. If they had sped up forks just by the magic of their might, we would know that already. And I think, yeah, we're looking at a much longer time, because then Kun was also supposed to be a fast fork. I don't think if we look at the two options, vertical and eoF, both of them are. We're looking at one year of work in any case. And the problem with vertical is that the clock is ticking.
01:12:56.610 - 01:13:34.950, Speaker F: Whereas all those advantages that have been touted brought by EOf, they are very nice to have. I want to make that clear. I am a supporter of EOF. I just don't think it should be coming before vertical. Because vertical, we have to go through a transition, and the more we wait, the worse it's going to get. And there's really bandwidth, like core development bandwidth for one team. I don't see the urgency for pushing EOf right now, especially if it is that complex.
01:13:34.950 - 01:13:41.630, Speaker F: In my opinion, there should be, since this is a format, you can have several format version, you could deliver.
01:13:43.650 - 01:13:44.014, Speaker G: All.
01:13:44.052 - 01:14:12.646, Speaker F: Those features little by little. And if EOf was a very simple container, like if that was the only thing the fork was about, I'd have no problem having it delivered before vertical. But because of that complexity, I think it's very important to focus on vertical right now and deliver EOF afterwards, or simplify greatly the scope of that first EOf fork. And then, yeah, I don't have any.
01:14:12.668 - 01:14:55.240, Speaker A: Argument against it, I guess, yeah. Just to chime in on the timelines, I think historically three months is extremely unrealistic. What we've done in a three month range is like a difficulty bomb pushback. I think as soon as you start to have actual features, regardless of what they are like, somewhere between six and nine months seems to be our pace. It's also worth noting there's a bunch of other stuff people are going to want to do in the next fork. And so it's probably unrealistic to say we're just going to do EOf and nothing else, and therefore the fork is going to take that amount of time. Same thing with.
01:14:55.240 - 01:16:10.800, Speaker A: Yeah, I think it's probably a mistake to analyze it at any level beyond just relative complexity. Is Vercol going to be more work than eof or not? And then, as you said, is there more urgency to do? Yeah, historically as well, over the past couple of years it's been kind of interesting where we tended to do like one big fork and one small fork. So we had 1559 and then a couple of difficulty bomb forks and then the merge and then withdrawals was much smaller. And I would argue Denkun is actually a pretty big fork. I don't think it's like a quick fork. The amount of work on the blobs is quite huge. So coming out of this big fork, I think it's worthwhile to consider, do we want to move on to something really big right now? And if there's a time pressure with regards to vertical because of the state growth, does that raise the urgency or do we want to do something that's potentially smaller and then do Verco after that? And I think client teams should start thinking about that.
01:16:10.800 - 01:17:25.558, Speaker A: I understand that obviously a lot of the bandwidth right now is spent on Cancun, and so it's worth keeping the focus on Cancun and shipping that before we make a decision about what the next big thing is, at least having it starting to roll out on testnets and whatnot. But I think it seems, at least on the execution error side, that eof and vertical are the two biggest potential candidates so far. So, yeah, I think if EL teams can start just looking into those more closely and understanding the trade offs, both in terms of the value they bring and then the timelines, hopefully in the next month or two we can start having a more focused conversation on what do we actually want to prioritize. And by then, yeah, we should be rolling out Cancun onto testnet. So the amount of work that's actually focused on Cancun should be going down, and we'll obviously have dev connect as well, where we can spend plenty of time going over both, all the vertical and eof updates. Yeah. Es security.
01:17:25.558 - 01:17:27.480, Speaker A: Maris, is that still you?
01:17:28.010 - 01:18:39.040, Speaker E: Yes, that's still me. I think Anska said something interesting. He said maybe Devconnect could be a good place to have the do we want to go with EOf at all? Discussion. And I think just the fact that this is still a discussion means that we cannot even talk about timelines. There's no consensus that this is happening at all. So we shouldn't talk about timelines. We should talk about whether it makes sense to have this, whether it's a good technical change, and if we all say this is something that we want, if this is the consensus, I'm fine with it, but then we should talk about, is this a priority over Virko or not? And then we can talk about timelines, but talking about it right now, where we have no clear, this is good, or this is something that we want, makes no sense to me.
01:18:39.040 - 01:20:20.400, Speaker E: I seem to be in the minority in this course because I'm the only one arguing against it. But I know that a few people are also not very happy with it. So I would like to. I know the Ipsilon team and Dano have spent a lot of time working on it, and it's quite harsh to say that after all this time, we might not be shipping it, but I think it's even worse to say, let's see, and then we push it another two years, and then we say, oh, we are not going to ship it after all. And so I think we should make a decision at Devconnect that whether this is something that we want, and if it's something that we want, then we are going to do it, except for technical challenges. And if we are saying this is something that we don't think is going to happen, I think it's just fair for the team that has been working on it for all this time to have a clear decision from. Yeah, I already talked to the Ipsilon team about this, and I think it would be really nice to all come together at Devconnect and discuss in person and make a clear decision about.
01:20:25.960 - 01:21:28.984, Speaker A: Like, I don't think anyone disagrees that figuring out if we want it is sort of a first thing before when we'd want it and how long it could take. I also think, yeah, it makes sense to discuss both EOF and Verco quite extensively at Devconnect. I'm not sure that we necessarily want to take. I'm not sure if like a month from now we'll be in a spot where we're ready to take a final decision. But my hope is if teams can get up to speed on both vertical and devconnect, both vertical and EOf in the next month or so that we can spend the time in devconnect, like going deep into both of those as well as a bunch of other proposals. Yeah. After that, we should be in a pretty strong spot to take a decision both for the next work, what we want to prioritize, but also.
01:21:28.984 - 01:22:32.528, Speaker A: Yeah. If for whatever reason we don't think eos is viable, make that called at that point as well. Yeah, I feel like we've been going on, on Eof for quite a while at this point. Obviously there's the EVM channel we can use to discuss it, but. Yeah. Does anyone have any new topics or questions, things that we sort of haven't covered? Obviously there's a bunch of objections around the backwards compatibility and figuring out how this works with l two s. Is there any other potential concern or question that people feel we haven't touched on so far? Okay, if not, then yes.
01:22:32.528 - 01:23:10.230, Speaker A: So there is the EVM channel in the discord. We're going to have the l two call next Wednesday. I forget the exact time, but the agenda is in the pm repo. Anything else anyone wanted to cover? Before we wrap up, I have a question on this general set of changes that we're discussing around the overall what is the right way to think about l one and l two? Divergence. For example, you implement vertical, maybe it's not implemented on l two. Push zero is not implemented on l two. EOf would plausibly take some time to make its way on.
01:23:10.230 - 01:23:49.776, Speaker A: I think that's exactly what we want to discuss on the l two call next Wednesday. Got it. Part of the reason why it's probably worth discussing there is to have l two people chime in. Right? Yeah, because I agree. I think a lot of people realize that we don't have a super clear vision there, so at least getting that conversation started with l two s is a good start. Yeah. And then Anzgar is a comment.
01:23:49.776 - 01:24:06.992, Speaker A: The first step of this is also bringing the l two s together to chat about this stuff where there isn't as clear of a forum. As for l one devs and l two s are obviously way more divergent in how they approach things. Hopefully we can start.
01:24:07.046 - 01:24:29.530, Speaker G: Yeah, I just want to make sure that people, if you want to show up next week, that's of course fine, but they shouldn't expect it might just be a 1 hour call where 555 minutes is about just like what weekdays do we want to have this call and who should show up and these kind of things? And then maybe we have 5 minutes briefly touching upon already, like how do we see our relationship with layer one or the layer relationship with layer one or our DBM? But it won't be a big topic yet for next call because it's just too early in the process.
01:24:30.060 - 01:24:49.650, Speaker A: And then yeah. We're also planning though, a full day at Devconnect as part of the l two days focused on this topic as well. So I expect in the next few weeks there'll be more information coming out on that too. Um, anything else before we wrap up?
01:24:54.180 - 01:24:54.930, Speaker D: Cool.
01:24:55.300 - 01:24:56.530, Speaker A: Oh, yes, please.
01:24:57.700 - 01:25:05.680, Speaker E: Can you make sure that we all get invites to those events so that we can participate?
01:25:05.840 - 01:25:42.130, Speaker A: Yes. All the l one teams should have events for the l one workshop. And then if anyone wants to join the l two l one day, you can apply publicly. I think it's the l two beats event. But if you have an issue getting in or getting your ticket and you work on l one, yeah, I guess ping me and I'll try to help get you a ticket. Thanks. Or just tag l two beats on Twitter and ask number one.
01:25:42.130 - 01:25:56.150, Speaker A: Anything else? Okay, well, thanks, everyone, and talk to you all Monday on the testing call.
01:25:56.920 - 01:25:57.990, Speaker D: Thanks, Tim.
01:25:58.520 - 01:25:59.556, Speaker B: Thank you.
01:25:59.738 - 01:26:00.276, Speaker A: Thanks.
01:26:00.378 - 01:26:01.910, Speaker B: Thank you. Thanks.

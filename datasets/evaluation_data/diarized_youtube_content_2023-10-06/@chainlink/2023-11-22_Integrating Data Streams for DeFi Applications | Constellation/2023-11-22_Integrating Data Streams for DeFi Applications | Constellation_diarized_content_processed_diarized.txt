00:00:05.060 - 00:00:35.730, Speaker A: You. Hello. Hello. I hope you can hear me, see me. We're going to start pretty soon, but until we do, please drop some gms in the chat so I can know that you can hear me and see me well. And we're going to start just in, in a matter of minutes until we all join the stream. Welcome.
00:00:35.730 - 00:00:57.580, Speaker A: Cool. I can see, yeah. Hi. Hello. GM. Perfect. That's perfect.
00:00:57.580 - 00:02:01.390, Speaker A: We're going to just wait for a bit more until everyone joined the stream and then we are going to start until we are waiting. Let's see the topic for today's workshops. A workshop is going to be an intermediate Hudson workshop on building a low latency DAx using Chainlink data streams. Chain link Data Streams is a brand new chain link service announced three weeks ago at smart contempt three at Barcelona. And today we're going to have a handsome workshop where I'm going to show to you how you can use Chainlink data streams on arbitrary sephola. And then we are going to see the example of a low latency Dex built using chain link data streams, both UI and the code itself. And I'm going to explain to you how you can build your own version of low latency decks.
00:02:01.390 - 00:02:51.418, Speaker A: Okay? And I think we can easily start. So, yeah, before we start, my name is Andre Rakich. I'm one of the developer advocates for training protocol at chainclabs, and here you can see my twitter and lens handles. If you have any follow up questions or anything that is unclear to you and you didn't have time to ask in the chat during this workshop, feel free to write a tweet on my wall on Andre underscore dev, and I'll make sure to answer you either there or on our discord during this constellation chainlink hackathon. Cool. But first, before we start, let's quickly understand what Chainlink is. So I came from Devconnect just yesterday, held in Istanbul.
00:02:51.418 - 00:03:44.160, Speaker A: So it was really nice to see all of you, to see the majority of the community there. And I had some interesting conversations. But the thing is that whenever I ask someone like, what do you know what Chainlink is and what you can do with Chainlink? The majority of answers were just Chainlink is an oracle protocol, decentralized oracle protocol, which can provide you off chain data and computation, or you can use Chainlink to get prices, price data, price fits, et cetera, for your defi dapps. But Chainlink is much, much more than that. In the same way that Internet is not just for email, Amazon is not just for books. Chainlink is also not just for price data, it's much, much more. Chainlink essentially is a web three platform which allows you to use its multiple services.
00:03:44.160 - 00:05:06.714, Speaker A: Either one service or multiple of them combined depends on your web three DAP use case. So price feeds are just a subset of data feeds where also we have nFT floor price feeds, rate and volatility feeds, l two uptime sequencer feeds and more. With chain and PRF you can get random values on chain because getting randomness inside a smart contract is not safe. Then data streams data streams is the latest product or latest service announced by chain link Labs at smart Conte, and it is a way to get price data with low latency in less than a second. And this workshop is going to be all about data streams. Then chain link automation, which is a way for you to automate your smart contract either on a fixed time interval like a fixed cron job which is time based upkeep, either if you have a custom based upkeep like custom scenario where you're going to create automation compatible contracts or using log triggers. So log triggers is something that has also been announced at Smartcon 23 and together with data streams we are going to actually use log trigger automation today.
00:05:06.714 - 00:06:10.718, Speaker A: So stay tuned where I will be explaining to you what log trigger automation is then CCIP crosschain interoperability protocol allows you to connect different blockchains, even which are by nature incompatible between themselves, to send cross chain messages. So you can send either tokens, arbitrary data or both proof of reserve feeds. Also a way for you to validate that some web two entity like bank or whatever has enough of this asset in our reserves, for example gold. And finally, chaining functions, a way to execute any given JavaScript code in a completely decentralized and serverless environment and get a cryptographically verified callback back to your calling smart contract and do something with it. So much more than just getting HTP get or post requests. It's essentially a way to execute any given Javascript code. Cool.
00:06:10.718 - 00:07:07.502, Speaker A: And obviously much, much more to come, like FSS Deco and more. So yeah, today we're going to talk, as I said, about chaining data streams. So you can go to data chain link to see details about this service. But basically it's a way to get low latency price data. So chain link data streams are built on pool based Oracle model. So to understand the difference between push based and pull based Oracle model, we are going to compare data streams with traditional price feeds, right? So with traditional price feeds, updates are written on chain on different aggregator smart contracts by a don based on some triggers. So the first one is certain price threshold.
00:07:07.502 - 00:08:19.894, Speaker A: So if for example, for this data feed, the price threshold is 0.5% if price goes up or below that threshold compared to the currently written one on a smart contract, dawn will push a new one, or if the price is stable but a certain time period have been met, for example, it was passed 15 minutes without a new price update, dawn will still write a new price on a smart contract. Pool based oracles are different. And with pool based oracles you're getting data only when you need it off chain. And then you can verify, actually you must verify that price data, that bundle report on chain which provides you a low latency delivery of that market data, which is a much, much faster solution. So literally in less than a second you will get the latest price data. And now with Datastream you can have access to on demand high frequency market data again backed by chaining dawn, which stands for chaining decentralized Oracle network.
00:08:19.894 - 00:09:55.080, Speaker A: So if you take a look at this diagram on the above part of the picture, you can see the traditional push based oracle model. This is essentially price feeds, right? So you have various different data providers then don. So dawn is constantly getting data from data providers and also comparing that, reaching a consensus, then comparing that final result with the latest price written on reference contract. And that's why we need to specify the address of an aggregator when using aggregator V three interface, we're specifying the address of our aggregator contract because this is the contract we're querying from the latest price details. And then our apps or Dapps will consume that data with pool based oracles, aka data streams users, as you can see. But in reality that will be automation bots will ping Don to get the latest price data, then the dawn will provide the bundled report, and then with that bundled report you're going to provide it on chain to your smart contract, which will need to call the verifier smart contract to verify that the bundled report actually came from Madon and it's the latest one, it's legit, et cetera. And then once verified, you will have the actual price in it along some other data which we will show later.
00:09:55.080 - 00:10:59.834, Speaker A: Cool. So again, in the previous slide you saw that there was like users that are going to ping the dawn. So in theory that's possible, but in reality it will most likely combine that with chainic automation and you will have dedicated automation bots listening for a specific events provided by your smart contracts and specific triggers. And then based on those triggers will get data from the dawn. By data I mean bundled report about data streams, prices and then provided back to you and inside perform upkeep function. You will essentially call the verifier contract to verify the report. Now with data streams aka pool based oracles, you have a couple of new use cases which you can build on during this constellation hackathon for example perpetual futures, options, prediction markets and more.
00:10:59.834 - 00:12:17.410, Speaker A: Probably the most popular DAP or defi platform that currently use data streams in production is GMX which is essentially pretty popular DAX in Defi space. Now if you take a look at this slide now, it's a bit you can see updated this pool based Oracle picture in a way that it use automation dawn to monitor your DAP and to get data from the data. And by data again I mean data streams prices. So for automation dawn, our trigger will be log trigger. And this is the new thing also announced at Smartcon, a new thing that came with Chainlink automation. And with log triggers you're essentially listening to the specific events from specific smart contracts and also you can filter them if you have any indexed parameters inside those solidity events. So whenever those solid events are getting emitted on your smart contract in your DAP, automationdon will pick that up as a trigger.
00:12:17.410 - 00:13:08.110, Speaker A: Ping the data streams or data done to get the latest price of the data. Data done will provide like a bundle report to the automation done which will pass it to your smart contract or to your DAP through that perform upkeep function. And then inside that perform upkeep function it is advisable to you to call the verify contract on the verify function, sorry, on the Chainlink verifier smart contract which will verify that bundled report. And when you have the verified report, you can actually get the latest price. So log trigger is something new, as I already said. So with Chainlink automation there are three types of triggers. So the first one is time based trigger and you're just going to create a smart contract.
00:13:08.110 - 00:14:05.062, Speaker A: You don't need to make it automation compatible or whatever, it can be whatever smart contract you want. The thing is that when you go to automation chain link which is a UI or subscription management for Chainlink automation, you're going to specify that you want to create a new time based automation based on time based trigger. And you're just going to provide the address of a smart contract that needs to be updated. And you will specify a cron job. So you can specify at each 15 minutes or whenever, each first Wednesday in a month, or however you want to decide it and decide. And chainic automation will ping your smart contract on that given cron job time interval. So if you want to for example, pay salaries on a monthly basis, you can use time based trigger for that.
00:14:05.062 - 00:14:46.962, Speaker A: When it comes to custom logic trigger, you are in a full control. So you're going to implement something called automation compatible interface. And that interface consists of two functions only. So check upkip and perform upkip. Check upkip in 99% of the time will be a view function which doesn't consume any gas. And automation done will trigger check up kip function on a fixed time interval on each block, on each several blocks to see do your smart contract need any type of automation? Right, so your checkupkip should return true or false. And if we return false, well nothing's going to happen.
00:14:46.962 - 00:16:03.950, Speaker A: If return true, perform upkeep function will be called automatically and if you want to provide any arguments to that perform upkeep function, also checkupkip can return something called extra data and then those extra data will be provided as an argument to the perform upkeep function which will do something actually on your smart contract. Right, log trigger is a new type of trigger and you can use log data or solidity event data as both trigger or input to specific triggers. Right? So we are going to use log trigger today to monitor for a specific event on our dex contract. And when that event gets emitted, for example, I want to trade these two tokens, right? We're going to emit an event, automationdon will pick up that event. We'll go to datadon to get a data streams report and then pass it to our smart contract via perform active function. And once we verify that report against verify smart contract, we're going to use that price data to do the actual swap and let's see how this thing works in action. Right.
00:16:03.950 - 00:16:46.060, Speaker A: So this is a bit complex image, but in reality it's not that much. So this is basically a UML diagram version of this image. Okay, so we have data done, automation done some contracts that we're using for automation and our smart contract and you can see the left side of the screen is off chain data. So you have user inputs done. Actually, sorry, not user inputs but data streams done. Automation done. And on the on chain side we have automation registry contract which communicates with the automation done.
00:16:46.060 - 00:17:35.542, Speaker A: Your actually smart contract, data streams, Dax, whatever the name is. And finally data streams chain link verifier smart contract on the top right. So how this thing works. So if we have user on the top left which wants to create a trade, which will call, for example, initiate a trade function, that initiated trade function will actually emit an event, or should emit an event. Or if you follow along at a basic example, which will be our exercise number one, we're going to have a tiny log emitter smart contract to do the same thing for us. So that log emitter smart contract will emit a log. So our user will, for example as a warm up first call emit log function to just create a log trigger.
00:17:35.542 - 00:18:29.626, Speaker A: And then in exercise number two, we're actually going to have like a fully functional smart contract which essentially will emit an event at the end. But that's the whole idea. So we have this log event which needs to be emitted, right? And when that log event is emitted, it will be picked up from automation automatically and a checklog function will be actually be called. So checklog function. This one will be called by automation. Done. And checklog function will have like a log struct provided, which is essentially needed to be decoded from data, done to provide the data streams report.
00:18:29.626 - 00:19:10.278, Speaker A: And inside that log you have multiple different data. We'll see that in a minute. But essentially this checklock function should revert actually with streams lookup error. So you can see that this checklock function does pretty much nothing. It just reverts with this error streams lookup error. And the reason why it needs to revert with this error is to be compatible with that CCAP read eap. So I don't remember the actual number of EAP, but basically to be compatible with it, it needs to revert with this specific error, with this specific signature.
00:19:10.278 - 00:19:50.130, Speaker A: Right. Next up, check callback function will be called by now datadon. And that check callback function will just return true alongside encoded values and some extra data as like bundled report. So values again, data for prices, some extra data. But check callback function needs to be called and to return true. So it's a signal for automation done to call perform upkeep function. So it's similar like check upkeep, perform upkeep.
00:19:50.130 - 00:21:06.510, Speaker A: We here have check callback and perform upkeep. And here is a perform upkeep function, which is a bit longer one, but essentially it's pretty simple. So the first step is to first of all, decode that data, that extra data from jack callback function inside pass to the perform upkeep as a function argument, which here is written as perform data. Right. So this is something that you probably are used to if you ever work with custom based automation in past, and we are just decoding that to get the actual reports. So from signed reports array, we're just going to get the first one because that's the only report we have and it's a bundle report which is unverified get report data here is just a helper function to convert this bytes data to basic report solidity struct, which I'm going to show you in a minute how it looks like. Then when we have this unverified report, what we need to do is basically call the verifier smart contract.
00:21:06.510 - 00:21:55.062, Speaker A: It has this verify function and we are just going to provide that bundle report to that verifier smart contract. And verifier smart contract will return to us verified report again in bytes. So we again going to convert it to the basic report solid extract. So with data streams there are two reports, basic reports and premium reports. We're going to use basic report today. Here we are again converting bytes data to basic report solid extract. And finally, when we have that verified report, well, yeah, sorry, I forgot to switch slides.
00:21:55.062 - 00:22:29.990, Speaker A: So this is the call to the very first smart contract, as you can see. So again, call to the very first smart contract to verify function, get the verified report. And now when you have the verified report, we have the actual price. And here in the first example, we are just going to do some dummy stuff. We're going to emit an event or console log that price. But here from Verifiedreport price you actually have int value, integer value. So it's not Einstein integer, it's just integer.
00:22:29.990 - 00:23:29.286, Speaker A: And this is the price. And now here you need to do something with your price, actually. So do the swap, maybe do loan, whatever you want, but here at this very moment when you verified report, when you verify report and you have that verified report, you can get the actual price and do something with it. And now we're going to do this in reality. So we're going to create a log trigger automation. We're going to deploy data streams compatible smart contract and we are going to get the actual price on arbitrum sepolia. But before we start, if you have any questions, feel free to write them down in the chat and I'll make sure to answer it in a timely manner.
00:23:29.286 - 00:24:15.450, Speaker A: So now I'm going to share my screen and you should be able to see Remix ID. Remix id. So I created already a new workspace called Data Streams workshop. So you can create your own here by typing blank and just name it data streams workshop. And hit ok, I'm going to hit cancel because I already created one. Cool. Now I'm going to go to this gist which consists of smart contracts that I'm going to deploy today.
00:24:15.450 - 00:25:26.980, Speaker A: So log emitter is just a tiny smart contract. You saw it on the slide which needs to emit this log event which will be a trigger for our streams lookup chain link automation smart contract to get the actual price. So this one is a bit bigger. So let's quickly examine it. So we have this interface which is trims lookup compatible interface with this error streams lookup error which needs to be emitted or reverted, whatever to be compatible with that eap. And also check callback which will always return true as upkeep needed and inside perform data will have the whole bundled report provided by datadon. You can see here that here is this struct log which we pass at the beginning and it has a lot of stuff in it, but more on that later.
00:25:26.980 - 00:26:42.694, Speaker A: Then when it comes to automation or log trigger automation, this is a signature for that checklog function that we called alongside some comments and also the perform upkeep which will be called. So check log perform upkeep is like check upkeep perform upkeep pretty similar, right? And finally this is just some libraries, we have this verifier proxy interface with this verify function which needs payload and some parameter payload data as well. And it will provide verified response. Also here there is the add address to the fee manager smart contract. So your smart contract at this very moment will be paying links to get the verified response and to actually get the price from the verified smart contract. So here the payment of links will be handled. So that's why you can see the address of a fee manager smart contract if you need that info.
00:26:42.694 - 00:27:33.450, Speaker A: And finally this is the main contract. So streams lookup chaining automation inherits ilog automation and streams lookup compatible interface. So as I said, we have basic reports, basic report and premium report. We are using basic report for this example and these are just some data that we can get through it. That's why we constantly decode that huge bytes chunk of data coming from the non or from the verified smart contract to the basic report so we can easily consume it in our smart contract. The most important for us is definitely this price, but this expires at timestamp can also be really useful for you. This is the latest timestamp where the report can be verified on chain.
00:27:33.450 - 00:28:12.674, Speaker A: So you have like a small time frame, small time period to verify the report against the verifier smart contract. If you don't verify it, it will always revert. So you will need to request a new data streams price. And also you can pay for data streams price data in both link and native coin. So depends on your preferences. I'm going to use link token address, but you can also use native. So native is essentially master value so you're just going to fund it with native coin.
00:28:12.674 - 00:29:24.122, Speaker A: So narbitram sepholia that would be arbitram sepholia eat. And finally a couple of timestamp details like earliest and latest timestamp, sorry for which price is applicable. Finally, this is just a feed id and when it comes to premium report, two extra stuff are these bid and ask parameters, which is basically a simulated price impact of a buy order up or a sell order up of some x percentage depth of liquidity utilization which is different events on the data feed. And here we have car coded ETH to USD price report. But obviously if you go to dogs chain link and scroll down to data streams over here and click on data streams. If you go to stream ids, you can see all the available stream ids on arbitrance Apolia and this is the one that we are going to use. So EtH in terms of USD, this is the basic report, this one is premium.
00:29:24.122 - 00:30:09.290, Speaker A: So be sure that you decode that data from data done correctly. And this is the verifiers proxy smart contract address that I can maybe zoom it. Never mind that, I'm going to query to get the verified report check log. Now we have implemented that chat log. So you saw this on the slide, basically reverting with this error check callback return true alongside values and extra data so passed by data John and the actual perform up Kip. So this is the function that will be performed on chain as stated here. So getting a report from site reports handle billing.
00:30:09.290 - 00:31:24.082, Speaker A: So again I'm paying in link. So that's why I'm using link address here. And also approve this reward manager smart contract to spend some of my link tokens, actually some of link tokens locked inside this smart contract. When I call this verify smart contract verify function on the verifier smart contract and again providing report and also encoded fee token address which is an address of a link token on arbitrance Apollia and getting the verified report back decoded as a basic report. And finally again logging or emitting an event with this price, but here you want to do something more meaningful with that. And in the second exercise we are going to actually do the swap when we have this price. So before we start, I'm going to copy this gist URL to the chat so you can follow along with me if you want.
00:31:24.082 - 00:32:29.910, Speaker A: You can easily copy paste content from it. And let's say we have a question for salv. If I've got a project that lets users deploy custom derivative where they specify the settlement time, should we use custom logic or log trigger automation for settling? I would suggest log trigger because you can get data streams data streams data pretty much by adjusting mine contract a bit and then inside perform upkip you should specify someone time. But also you can combine both custom logic and log trigger automation before if you go back to some of previous slides, you can see that you can also use log log trigger data as input to custom logic automation as well. Cool. Let's, let's now deploy these two smart contracts, shall we? So the first one that I'm going to deploy is this streamslookup chaining automation as well. So to do that, I'm just going to copy the content of this file.
00:32:29.910 - 00:33:15.346, Speaker A: And so let's create a new file. So streams lookup chainingautomation sl and I'm going to paste it here says that. Okay, I'm okay, zoom it a bit so you can see it better and compile smart contract. So I'm going to compile it with version 8.19 because I'm an average monsofolia to avoid issues with push zero opcode. And I can see here that I have artifacts built in for all that stuff and here that everything's green. So my contract is successfully compiled.
00:33:15.346 - 00:33:52.254, Speaker A: So the next stuff that I'm going to do is now I'm going to deploy it to arbitrum sepholia. So to do that, I'm going to switch to inject provider metamask from this environment drop down menu in remix and I'm going to connect my metamask wallet to this instance. I'm going to just refresh this because sometimes it does not work. Let's try one more time. So let's again compile this switch to inject the provider metamask. Okay, now it works. And here I can see that this is an id of a custom network.
00:33:52.254 - 00:34:31.534, Speaker A: So 4216 114. So if I go to my metamask, I am connected currently on arbitrage sepolia. If I switch, for example to sepolia, my chain id now changed. So if I switch back to arbitram sepolia. Now from here you can see that chain id changed again. So that's how you can change networks using this injector provider. Also if you're not sure what this 42161 114 number means, you can type something like arbitram sepolia chain id.
00:34:31.534 - 00:35:09.002, Speaker A: And you can see this is the chain id for arbitrum sepolia 42161 114. And if I go to remix, that's the exact same chain id. So I'm now sure that I am on arbitram sepholia. Cool. So I'm going to deploy this streams lookup chain link automation smart contract. And what I need to do is that I need to provide the verifier address, right? So again, when it comes to verifier address, we can grab it from here, which is this one, right, and just paste it. So again, going to official docs stream ids, deep gen data streams stream ids and get it from here.
00:35:09.002 - 00:36:12.030, Speaker A: Or because I hard coded the address of ETh in terms of USD stream, if I go back to the constructor, I can also grab it from here and you can see that this one is exactly the same one as this is two ff and here is two ff one, et cetera. So I'm going to just provide this address here, validate is that one and hit transact. I have a metamask pop up now which tries to deploy a new smart contract on arbitrarium sepholia. And I'm just going to deploy it and wait for a transaction to be included in block, which just happened. So I have this new instance of streams lookup chain link automation smart contract. Now as I already said, to verify this report against the verifier smart contract, I need to pay in either native asset or a link. So I'm just going to use link and I'm going to fund it with five link.
00:36:12.030 - 00:37:06.050, Speaker A: So where can I get link so I can go to fossil chain link. So fossilschain link. Let me put that URL in the chat as well. So fossil chain link. And if I go back here, you can connect your wallet, I'm on metamask and it will ask me to switch to sepolia, which I'm going to not do that because I'm going to cancel it and specify here that I want to be on arbitrage sepolia. So sepolia is like the default one. So if I want to switch to avalanche fuji for example, again new pop up to switch from arbitrary to avalanche Fuji C chain, which I'm going to cancel and I want to be on arbitrary sepolia here.
00:37:06.050 - 00:38:17.030, Speaker A: I'm just going to need to solve this captcha and then once solved. I will just ask for 2020 link on arbitrary sepolia by clicking on this button. If you need arbitrary sepolia eat there is a URL to arbitrage faucet to get some so you have some arbitrary sepolia eat for gas when deploying these smart contracts. Cool because I already have more than enough link tokens which you can see 105 I'm going to fund my smart contract with five link. So how to do that? I'm going to copy this address. This is the address of this dreams lookup chain link automation contract and also if I go to arbitrum sepolia block explorer this one and if I search for this address you can see that this is a contract which we created 2 minutes ago. So copy this address and send.
00:38:17.030 - 00:38:54.290, Speaker A: I'm going to send five link. That's more than enough by the way. I think with one link it will work. I'm going to just do five. So I'm sending file link to my newly deployed smart contract and I'm just going to confirm click confirm button which means that I'm signing this transaction and this transaction just got included in an x block you can see here. So if I refresh this I should be able to see here it is. Five link great.
00:38:54.290 - 00:40:26.286, Speaker A: I know that I successfully funded my smart contract so if we follow along at the slides, we now need that log trigger smart contract which will just emit specific log to trigger getting new price data. This is intentionally just as a U as a separation of concepts to understand it better, but in reality you can emit that event from the same smart contract. From this one it will work the same and this is what we are going to do in exercise number two. But for now we're going to deploy this log emitter contract. So I'm going to now copy this ten lines of code extremely simple smart contract and create a new file. Name it log emitter sol paste the content here so you can see log emitter smart contract just has this log event and nothing more and a function to emit log which anyone can call but I'm going to filter it to trigger the getting of data streams, price data only when I call it because I can also filter by this message sender topic because it's indexed, use this index keyword and I'm just going to compile this smart contract again. Everything works as expected and deployed this one as well to arbitrance Apollia.
00:40:26.286 - 00:41:14.346, Speaker A: So I have this log emitter so I'm just going to click deploy button metamask pop up again and hit confirm. We're now going to wait for this smart contract to be deployed. And that just happened. So we have this log emitter tiny smart contract here and if I click emit log it will emit this log event. Finally, to connect that with chainlink automation, I need to create a new log trigger automation. So to do that I'm going to go to automation chain link. So automation chain link, let's get this URL and I'm on arbitrum sepolia.
00:41:14.346 - 00:42:01.658, Speaker A: So you're going to connect your wallet and specify the blockchain you want to be it. You see there's like a lot of options here. I want to be on arbitrum sepolia so let's now copy this to the chat as well. This is the URL to automation UI. And here I would like to create a new upkeep to register a new upkeep. So how to do that? I'm going to click register new upkeep button and I have three different triggers as being said already time based custom logic and log trigger. I'm going to use log trigger and here you can see you can use log trigger to trigger following matching on chain log events alongside your Ilog automation compatible contract.
00:42:01.658 - 00:42:57.374, Speaker A: So I'm going to just hit next and here this is a contract to automate. So this one should be automated and this one should have that perform upkeep function which needs to be called. So in our example, contract to be automated is that big one, aka streams lookup chaining automation. So I'm going to copy its address like this and paste it here. So again it's now specified that it's unable to verify if this is automation compatible contract because as you can see here, I haven't verified it on etherscan, but once you do that it will definitely have like a green check mark here that this is indeed an automation compatible contract. So I'm going to hit next. And now we need to specify contract emitting logs.
00:42:57.374 - 00:43:53.246, Speaker A: So in our second example that will be exactly the same address, but here we have this tiny smart contract which emit those logs and I'm going to copy its address. So address of a log emitter. Here it is and I'm going to hit next. It was unable again to fetch the ABi because it's a contract which is not verified on etherscan, but I'm going to just provide Ebi manually. So I'm going to provide it here, hit next and boom, it says okay, which log needs to be emitted? One and only event which is log. So this one, if I had multiple events, multiple events besides this log will be present here in this drop down. And also this log event has some indexed topic filters which is message sender.
00:43:53.246 - 00:44:35.200, Speaker A: See message sender with small m comes from here and I'm going to provide my wallet address. So that means only when this event being emitted with this specific message sender. So that means that whenever I call that function to emit this event, only then it will be a trigger to check the data streams. Data done. So I'm going to now need to specify some upkeep details. So upkeep names can be data streams. Constellation, constellation workshop let's say.
00:44:35.200 - 00:45:08.890, Speaker A: Okay, just constellation. Never mind. This is admin address. Gas limit is fine to be this height and I'm going to provide file link as a starting balance. I don't have any check data. This is optional field so I'm going to leave it empty and also my email address and project name are optional so I'm going to leave that empty as well. I'm going to just hit register upkeep and hit confirm here inside metamask pop up to finish with the creation of this log trigger automation upkeep.
00:45:08.890 - 00:45:53.030, Speaker A: Once this transaction gets included in the next block, I should be able to see my log trigger automation dashboard and this is my upkeep. So I'm going to click view upkip and here it is. So data streams constellation. You can see here that it's active. Couple of details. Log trigger event the address of that giant smart contract we see. So it has these five links we funded previously and also the log emitter smart contract address that event that needs to be emitted to trigger this automation.
00:45:53.030 - 00:47:00.974, Speaker A: And finally some history which is just a funding on upkeep. So yeah, if I refresh this, this is the empty state of this automation UI page for this specific upkeep. So the final step is just now to trigger this event so it can get the price from data streams and emit that price inside that bigger contract as an event aka console logit on blockchain to make like a proof of concept of our usage of data streams. So to do that I'm going to go back to my remix once again and hit this emit log function. So by hitting this orange emit log button, I'm calling emit log function on arbitrance polio and I'm going to just hit confirm and wait for a transaction to be included in the next block. Here it is. So what I'm expecting now is after a couple of seconds to see the new event here.
00:47:00.974 - 00:47:39.958, Speaker A: And it was that fast. So yeah, event is already there. So price update is the actual event that we specified and this is a console log of our new price. So if I go to automation UI as well, should be able that the last automation was run just now. So 21 November and this is the perform upkeep function. So it was log trigger. So this is approved to us like a transaction hash that we pinged data streams down using this log trigger.
00:47:39.958 - 00:48:36.314, Speaker A: But essentially what we did is that we emitted a price update event and this is our price. So this is a hexa value. So here on arbitrary there was a button to convert this to number. But if I go to hexadecimal converter like here and convert you can see the actual price of ethnic terms of USD with all of those decimal places that you need to handle. But again this is our latest price aka our price update. Let's now go back to YouTube chat to see if we have any further questions. If there are two types of automation on the same contract, will they respectively from upkeep's clash? No, because they will have different automation our upkeep ids.
00:48:36.314 - 00:49:05.510, Speaker A: And you can definitely use same contracts for multiple triggers because they're different. Right? Your check upkeep function, if it's like a custom one will be called and you'll return. True false. But if you emit some events from that smart contract as well, that will be a completely different trigger for a completely different upkeep. So yeah, no worries, those two are not the problem. You can combine them. Okay, cool.
00:49:05.510 - 00:49:55.474, Speaker A: Now go back to our slides. So that was exercise number one. Basically what we did is that we put in work everything we showed on previous couple of slides and eventually we just emit an event with the latest price like console logge. Let's now do something more meaningful with it. So this is how GMX basically use data streams in production so they have their own event being emitted, which is a trigger for automation. Done. Again, automationdon now communicates with datadon on a way we described during previous slides.
00:49:55.474 - 00:51:25.186, Speaker A: And then when we have a new bundled report, it will get passed or provided to their smart contract using preferred upkeep function. And then it will call this verifier smart contract to verify that the bundle report is indeed legit and latest and whatnot. Pay in links or native coin, whatever. It's easier for you for that verification and then settle the trade instead of just console log it or emitting a specific event like we did. So in exercise number two, we're going to see how you can build a low latency DAx using data streams and maybe adjust it a bit and apply for grand prize at this constellation hacked. So I'm going to go back to this shared screen, right? And if I go back to my browser, there is this data streams demo app chain and data streams demo app and I'm going to paste the URL in chat as well for you if you want to follow along. This one is built on Arbitram Guerrero, so that's why I have this run network tab here.
00:51:25.186 - 00:51:52.506, Speaker A: And let me see if I can switch from here. Yes, I can switch to arbitram wirelessly like this. Here it is. And boom. Now I have the full UI. And here it basically allows me to trade wrapped eth for USDC or wrapped avax for USDC on Arbitrum Gorli. And this is the latest update and the latest price from data streams.
00:51:52.506 - 00:52:52.000, Speaker A: And you can see how it changed dynamically. And also this is a comparison to some most popular tax providers to see their prices. But again, this is on testnet, so it's okay to be, you see how it changed automatically pretty fast. So what I'm going to do now is I'm going to trade some wrapped eth from four USDC. So to do that first where I have a wrapped ETH, well, I had arbitrage e, even normal one. So I just wrap it. So you can do that on either block explorer or you can do that on, for example by calling the smart contract manually, or you can do it on some decks on arbitrang or leave, for example there is unisop or something like that.
00:52:52.000 - 00:53:25.590, Speaker A: But yes, I'm going to click trade and here it says that I have 0.6 wrap tth and zero USDC. So what I can do is that I can specify, okay, I want to swap 0.1 wrap tth for USDC. And you can see that these swap values are approximate because while you're waiting, that price is getting constantly update and update. So in that moment when I type 0.1, I'll get slightly above 200 USDC again on arbitrum girl with Tesla.
00:53:25.590 - 00:54:16.310, Speaker A: So I'm going to click swap and I'm just going to confirm this in my metamask wallet and I have several steps to check automatically. So I'm going to just approve now this smart contract to spam some of my breath eth. And finally I will just hit confirm. And you can see that I successfully swapped 0.1 wrapped eth for 200 something USDC on arbitrary and I can also go to explorer to see the actual swap. But what is more important or more interesting to you is to understand its code base. So here if you scroll down and go to four developers tab, you can see a link to go to repository.
00:54:16.310 - 00:55:22.218, Speaker A: I'm going to click it and it will navigate to Datastreams demo GitHub repo which has this URL to the UI. And here I would like to examine what the contract looks like if I click on this contracts folder. So inside contracts folder I'll find a hardhead project. And here inside contracts there is this data streams consumer, also a couple of interfaces. So for verifier proxy and swap router, just to be a bit cleaner than to put all in that same file. But essentially I want to check this data streams consumer smart contract, right? So it use Uniswap for swapping. But also you can see here that there is this ilog automation and log struct coming from this import, right for automation.
00:55:22.218 - 00:55:54.810, Speaker A: So that's the content of that log struct we saw in previous exercise. And also there is this streams compatible interface which you can also import. We saw its content as well as in exercise number one. Or you can see it in that gist. And those two interfaces are just these two, one and yeah, so the same thing. Data streams consumer now inherits ilog automation and streams compatible interface. Couple of contents here and storage variables.
00:55:54.810 - 00:56:33.842, Speaker A: There is a struct for report. That means that it use base report. So there is no premium report here because it used basic report and that's why just report here. And also this is a struct with some trade parameters when we want to swap these two tokens. So token in, token out, recipient amount in. So this is all for Uniswap and feed id is the id for data streams. So whether we are going to use ETH in terms of USD or Avox in terms of USD, et cetera, this is the event that needs to be emitted.
00:56:33.842 - 00:57:33.558, Speaker A: So by emitting an initiate trade event, this is now a trigger for log based automation. So it will pick initiate trade event and also it will pick the content from it. So message sender, token in, token out, amount in and feed id. So in my example message sender was my address token in was wrapped, eth address token out was USDC, address amount in was 0.1 or one and 17 zeros because that's the amount I want to swap for USDC. And finally feed id which is the data streams id for eth in terms of USD. So I want price from that specific feed id, right? A couple of just events and errors and initializer functions, which is called upon creation of the smart contract.
00:57:33.558 - 00:58:26.358, Speaker A: Now let's see how this thing works. So user or I called first the trade function, right? So token in wrapped eth token out USDC amount was one and 170 feed id was passed through the UI. This is eth in terms of USD id for data streams. And this function, when got included in Xbox, that's like the very first metamask pop up emitted just this initiate thread event with all of these parameters as I described appear. So that was picked by automation. Done. And this checklock function got called immediately.
00:58:26.358 - 00:59:09.414, Speaker A: So again, this checklock function needs to revert with this trimstockup error to be compatible with that eap. So this function is exactly the same as the one in the basic example in the gist. So just reverts with that event. Then this is a trigger now for automation. Done. For data, done to call this check callback function, right? And it always returns true because perform upkeep needs to be called and we're providing values along some extra data. We're passing it here and then perform upkeep is being called.
00:59:09.414 - 00:59:53.894, Speaker A: So inside perform upkeep we are decoding this perform data. This bytes data from here to basic report. We're getting some trade parameters and also bundled report. So how we are doing that? We have this decode, underscore decode data helper function. Here it is, which as you can see, does this exactly the same in that contract from exercise number one and then some extra stuff. So populating the second struct. Here it is decoding and populating it and also getting some feed and bundle report again.
00:59:53.894 - 01:00:39.698, Speaker A: So bundle report and get report data again. Helper functions exactly the same as the one from exercise number one. And get free feed id from feed. It's just returning an index of feed id, which is like a view function and it will just revert if id is not found. So just some extra step for extra caution. And then once we have this unverified report, we're calling the verify smart contract verify function on the verify smart contract. And we are paying native now, so not in link but in native.
01:00:39.698 - 01:01:56.426, Speaker A: And this is a syntax for paying in native for link payments. It just goes without this extra piece of code. And again providing bundle report and providing the address for fee token, which will always be like a link token address, right? Finally we have this verified report again decoded to basic report or report struct and inside verified report there is verified report price which is the actual price. So in exercise number one we just emitted an event with that price. But here we're going to call this swap tokens function and provide verified report alongside this trade parameters to actually do the swap. And finally just going to emit a trade execute event. So if we go to swap tokens down here which is just below these helper functions, you can see that here we are scaling first to token decimals.
01:01:56.426 - 01:03:32.714, Speaker A: So reacting the number of decimals of that input token parameter and just scaling, you can see here to be compatible to not lose that decimal precision once we scale that for both input token for input token actually and we are going to now scale the output amount, right? So inside here we have this price for one token parameter which is just scaled using verified report and benchmark field, right? And then when we have like price for one token, finally we are going to calculate the approximate output amount because we have price for one token amount in and scaled input token decimals. So we have the exact output amount we need and we are just going to transfer token in from recipient to this smart contract. And then we're going to approve the Unisop router to spend some of these tokens. And finally here is going, going to do the actual swap. Actually this is a struct for params for actual swap. But here when we call this exact input single, we'll do the actual swap called by unison router contract. And yeah, finally we're going to go back to this calling function and as being said, this event is going to be executed, emitted.
01:03:32.714 - 01:04:11.602, Speaker A: Sorry. Which will be a nice trigger for us to also display that pop up message. And now let's go back to YouTube chat to see if we have any further questions. Hey Kelly, welcome to this workshop. Okay, if not, I'm going to just put these slides again. And this is essentially the end of our workshop. If you have any questions, feel free to either put them down in the chat or follow up on Andre Dev on Twitter.
01:04:11.602 - 01:04:51.400, Speaker A: But it will be really nice if you can get like 30 seconds of your time to scan this QR code and fill in the feedback form. This feedback form is important to us because it will help us to make these workshops even better because we are creating essentially for you guys. So again, if this was too boring, too hard, too easy, whatever, just write it down. And yeah, that'll pretty much be a jit. It'll be much appreciated from our side. And yeah, once you scan that, that'll be it. So yeah, thank you.
01:04:51.400 - 01:05:21.710, Speaker A: Thank you for joining me. Thank you for staying on until the end. I hope this was a valid usage of your time. In approximately 1 hour, we covered data streams, which is a brand new thing from training. Really exciting. So yeah, I hope you're going to build something amazing using data streams at this constellation hackathon. And yeah, wishing you luck at a hackathon and see you later.
01:05:21.710 - 01:05:22.170, Speaker A: Bye.

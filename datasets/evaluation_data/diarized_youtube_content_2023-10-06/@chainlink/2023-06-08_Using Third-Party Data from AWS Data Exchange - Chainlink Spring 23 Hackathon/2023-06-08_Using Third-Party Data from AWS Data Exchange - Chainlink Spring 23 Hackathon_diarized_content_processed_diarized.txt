00:00:02.810 - 00:00:38.522, Speaker A: Okay, GMGM everyone. We're live. I'm just going to give 1 minute or two for folks to start join and we will kick it off. But feel free to dock in the chat where you're watching us from. That's always interesting to see. I hope everyone is feeling great today. Last week to get those projects going.
00:00:38.522 - 00:01:16.114, Speaker A: So very important. Don't forget June 9. So this Friday until 11:45 p.m., et you have until there to submit your projects. We are definitely so excited to see what you're all building. I know for sure that some great stuff will come along and probably we can kick it off. So if you are building your project on AWS or you will apply for their prices, definitely stay tuned.
00:01:16.114 - 00:01:47.258, Speaker A: In this session we have Ron Miller from Aws. We have Karanthi as well from AWS, both solution architects joining us today. So they're here to talk to you about using third party data from AWS data exchange. So hopefully this can be useful for your project. And with that, I'll let Ron and Cronfi introduce themselves and kick off this session. So yeah, thanks guys. The stage is all yours.
00:01:47.434 - 00:02:10.710, Speaker B: Thank you. Thanks Sophia. So hi, I'm Ron Miller. So again, I'm a solutions architect. I live outside the New York City metro area and I support northeast customers AWS customers. Within that region we have Kranthian. Thanks Ron.
00:02:11.050 - 00:02:24.730, Speaker C: Hi everyone, my name is Kranthi Manchikanti. I'm a solutions architect based out of Boston. I work with financial services customers around the region on web3 and also web3 and generative AI solutions on AWS.
00:02:26.270 - 00:03:35.726, Speaker B: Awesome. So thanks for joining the session today. As Sophia mentioned, we will be talking about AWS data exchange and how you can use third party data on that service and how that may work for your chainlink hackathon. So first I wanted to go through what exactly is AWS Data exchange? And it's a curated catalog of data providers. So we have over 300 data providers and within those data providers there's 3500 data products. So this is a place where you can search and find data sets through various methods, either file based or API based, that you can use to either incorporate into your analytics. So if you're comparing different types of data sets together to arrive to perhaps a decision or an API based more real time response.
00:03:35.726 - 00:05:05.680, Speaker B: So basically feed it set of information and it'll come back directly from the data provider. So AWS data exchange provides this service between the provider and the subscriber and makes it easier to share and exchange data for that, meaning that it provides the orchestration and a single platform to procure and access that data. So we do support multiple delivery methods and we'll go into that in a little more detail. But predominantly it's file based, database based, and API based. The one advantage of integrating with AWS data exchange is that AWS data exchange handles the authentication and handles the security between the provider and the subscriber, so everything's encrypted. We use our identity management to provide that access between the provider and the subscriber. And of course, if you're developing your hackathon solution in AWS, there's native integration with different services such as S three and our analytics platform, either with Athena Glue or the likes of that.
00:05:05.680 - 00:06:01.920, Speaker B: So the big advantage is data exchange helps you scale. So it's one place where you can access the data. The data is already in AWS and we manage the subscriptions and it's at no additional cost to you as a subscriber, and we provide that orchestration to enable that unified access to that data set. And all this rolls into, if you're a larger organization, it rolls into your AWS bill. So it's a big savings as far as a procurement process because we manage the contracts between the provider and the subscriber as well as all the billing aspects of it. So providers really like that piece of it as well as larger companies.
00:06:09.950 - 00:06:10.518, Speaker A: It.
00:06:10.624 - 00:07:00.766, Speaker B: So again, the value is that there's one place to find these data sets. They're already in AWS. If you look out on data exchange, which we'll do shortly, you'll see that many providers give you a free trial or sample data set, so you could start to look at the data and see if that's something you want to actually subscribe to. So the value is there's less time to create to acquire data. So again, we handle the billing as well as the integration piece. I mean, all of us have too many passwords and keys these days. So data exchange handles that between the provider and subscriber, and then the provider is definitely incentive to help enable the data sets on AWS's platform.
00:07:00.766 - 00:07:27.640, Speaker B: So they're interested in creating updated data as well as new service providing services to the AWS clients. That was a really quick overview. I didn't want to spend too much on that, so I'm going to hand it over to mean he put together some use cases that might be interesting.
00:07:28.410 - 00:08:48.450, Speaker C: Thanks, Ron. Thanks for the overview of the data exchange. So now, since we have an idea of what AWS data exchange is, you saw a little bit overview on the type of data sets let's dive into. I know most of you are already building in different verticals. Let me walk you through how the same AWS data exchange could be used in multiple industries, like starting with the financial services. We see the customers in the financial service industry have been using these third party data for decades, and this could include the financial news data, the market data, ETF data, and even more recently like alternative data like sustainability, or even the demographic data itself too, right? So you see all of these data available already through the data exchange when we take that data, and if you see the column on the left. So we have multiple different options on the way you can build using that data, either through real time market data directly connected to the exchanges themselves, or even anything related to financial assets or even stocks or commodities.
00:08:48.450 - 00:10:02.390, Speaker C: Another innovative example is creating dynamic pricing models, all of them using taking the advantage of smart contracts and the web3 ecosystem itself. Some other use cases revolves around utilizing these data to create personalized financial services that could be leveraged directly based on the customer preferences and the personal details. We also see the digital credentials mostly tied around to faster verification processes. So those are some, again, so this is not an exhaustive list, but these are some ideas which you might already have been working. If not, you can leverage these data sets into the financial ecosystem. So moving on to the healthcare and life sciences, right? So customers in healthcare and life sciences are basically using and benefiting from these third party data by using things like medical imaging data or aggregated claims, for example. So most of these are tied to accelerating drug discovery or even creating novel therapies and improve health equity.
00:10:02.390 - 00:11:08.510, Speaker C: So you see all of these available data types in terms of molecular sequencing or patient records or EHR, or these lab results. The web3 use cases which could be tied around to these ones are starting with tracking and tracing of these, maybe starting from the patterns, or even identifying the trends and use those trends and the data to improve the treatment protocols. So all of them in a web3 lens, for example, the fitness programs. So these could be leveraged by using this specific personal and health data and tokenize. It could be a rewarding mechanism or even it could be used for community engagement. So all of these could be tied to personal training or nutrition plans and have that multiple people embedded in the ecosystem itself. So this will help in analyzing the health equity or even managing or figuring out the health disparities existing in the ecosystem.
00:11:08.510 - 00:12:11.170, Speaker C: Data ownership, privacy and health empowerment. That's like a broader use case which could be maybe a part of it is already in your use cases, or you could leverage the whole use case as part of your solution themselves. All of this which I spoke is all around the text data, most of it. But if you have images, so having AI based image analysis and then storing in a secure manner and use them like secure them and share them in a verifiable and identifiable aspect, that's a huge use case with secure data sharing as well. All of these will obviously tie around the interoperability areas too. So if you're working in multiple ecosystems and making these data available to different people with security keeping in mind. So these are all some use cases which could be tied to healthcare and life sciences.
00:12:11.170 - 00:13:02.750, Speaker C: So moving on to media and entertainment. So customers in media and entertainment are using data such as the entertainment content metadata, or even viewership engagement measurement. So all of these help ideally in improving discovery and recommendations. You can use them for track and measure the brand awareness, brand aspects, or even the content performance itself. So how your specific content is being performed. So you have these available data like the media catalogs or image libraries, or even specific to news and sports content. So decentralized content creation and tracking so that you can track the royalties, tying back to who the creators are and monetizing.
00:13:02.750 - 00:14:01.060, Speaker C: So those are all one huge web, three use case which we see, and there are a couple of already built in solutions on AWS. If you look in through the AWS blogs or I'll share in a second, that's one huge area. The other use case is improving the transparency and also the authenticity of the content in, in terms of news articles. So there are already a bunch of use cases which are being built. So you can take leverage of these data types like available through data exchange as well. Fan engagement, rewarding mechanisms, and obviously using the tokenized economics in this ecosystem, so you can create or improve the engagement between the provider or the creator and the fans. So that's a huge use case which we see in terms of the usage or the expectation in the market.
00:14:01.060 - 00:14:44.782, Speaker C: Connecting the dots, you have the digital rights. So all of these rights to be managed and tracking the licenses as well as the copyright protection, taking the advantage of the blockchain or even immutable nature of the web3 ecosystem. So those are some use cases too. This could also be connected to AR VR experiences if you are going above and beyond into metawars areas too. So that's an example which you can connect these available data types and use in your use cases as well. So marketing and advertisement. So in the marketing and advertising industry specifically.
00:14:44.782 - 00:16:02.822, Speaker C: So we see customers using business and professional segmentation as well as visits and mobility data. And mostly all of these could be augmented to improve digital marketing campaigns, for example, as well as even you can explore new avenues such as connected TV advertising, for example. So you can take advantage of this location data, weather data and all of these in general, the data types that you see on the right to target your campaigns, for example, or even if you have location based services or location based use cases where you could suggest some specific details around based on the location, or even having these customized consumer interaction possible through these data types. So you can also create data monetization. So you can monetize the data that you are having and you can basically take this data type in your use case. And once you have your data generated with your rest of these services, you can create a monetization aspect, build a business around it, or even one huge use case which we see is all around. Once you have all of this ecosystem, you can create token based communities.
00:16:02.822 - 00:16:53.126, Speaker C: So you can have them token gated and then provide them in the web3 ecosystem as like subscription model, for example. So moving on to consumer and retail. So in the consumer and retail. So retail companies use all of these location mobility, all of the data available to better plan. It could be site selection, or managing the supply chain, or even connecting and using the data for better customer experiences. So we have these demographic or even socio demographic data available through data exchange or even identity based ones or workforce related. So these could be used to enhance the supply chain transparency or even manage your product authenticity or even prevent counterfeit.
00:16:53.126 - 00:17:33.270, Speaker C: So these are some examples which there are solutions which are available on AWS as well. So you can basically tie them together either to create maybe even going beyond that is to have marketplaces. So it could be NFT marketplaces or even it could be specifically tied to the loyalty program management. So loyalty programs tied to your businesses. That's like some use cases connected in the consumer and retail with the data available on the data exchange. So I have one last one before I hand it off to. So moving on to sustainability.
00:17:33.270 - 00:18:54.210, Speaker C: So I did talk about a little bit earlier in one of the financial slides, but we have a specified or core details around ESG scores or even raw data or beyond that, what we see is all the climate and specifically tied to the agricultural data like crop vegetation, or even tied to emissions or transportation data. So we have all of those data types are also available through data exchanges. So some of these use cases revolve around creating carbon credits and offset marketplaces, or even creating the whole reporting and auditing mechanism so that you can find the lineage of, and you can ultimately create ESG scores. For example, tokenizing such ESG assets is also one use case that we see a lot, and also like tracking the climate and risk metrics as well as sharing the data securely across these industries. This is not specific to one industry, but you can leverage these to build your use cases. So these are again very high level, but more. I mean, these are supposed to give you some ideas on what if you have not already thought of, or maybe if you have already thought of adding more to your brain power.
00:18:54.210 - 00:19:09.350, Speaker C: So feel free to use and innovate as much as possible through the data types. You can start from the data types and explore how these could be leveraged in your use cases. So yeah, I think having said that, I'll pass it over to Ron to continue the discussion.
00:19:10.410 - 00:20:00.120, Speaker B: Awesome. Thanks property. I got a couple ideas out of that one. So let's get into a little bit of the nut and bolts of how to use AWS data exchange. So I mentioned before, there are five methods that are supported, and just to talk through those briefly, there's data files and s three as an option for distribution. So in this case, AWS data exchange orchestrates either access to a remote s three bucket, which is hosted by the provider, or maintains a central copy for the provider within there. So this would be file based data that could be ingested into either a database or some type of analytic process.
00:20:00.120 - 00:21:25.218, Speaker B: Further, we can query tables directly through AWS data exchange, so we provide the access methods for that. And these tie more directly into AWS's native services. So AWS Lake formation is one that's in preview right now, as well as a popular one, is using Amazon Redshift, which is our data warehousing service. So you can access the redshift tables directly from the provider. So you have the most up to date data and incorporate that into your own queries. So with these first two groupings, these are not API accessible, but here at AWS we have a wide breadth of services, so you could quite easily build an API that can call what you need for your chain link function, for example. The reason I point that out is that these methods are provided by the providers, so they may be used to database or file based distribution, but there are some that also have direct API access, which we'll dive a little more deep into.
00:21:25.218 - 00:23:00.044, Speaker B: So data exchange, as I said, works between the provider and the subscriber and manages things like authentication security and whatnot on behalf of both the provider and the subscriber. So if we look at that interaction, the subscriber would actually access AWS data exchange through the API. Data exchange understands like, and we'll go into this in a little more detail during the demo, but it understands like hey, who am I, what are the descriptions I'm looking or I have valid for myself, what data set am I trying to get? And it kind of figures all that stuff out on the initial request and then the actual API call that provider hosts is then created and pushed off into the data provider. Data provider provides the response back for that data query for that data result, and data exchange essentially monitors the method. So with APIs it's typically a metering method. So based on the number of requests, there might be a tiering mechanism. Data exchange figures out what the pricing should be and audits that, et cetera, before it actually goes back to the subscriber as an API call.
00:23:00.044 - 00:23:57.358, Speaker B: So from a subscriber standpoint, it looks like you're just talking to a data exchange. The provider standpoint, it's the same deal. So data exchange is kind of in between to orchestrate and simplify the things that we need to provide these data sets in the marketplace. So again, I've kind of said all this, but the biggest advantage also is, like I mentioned, metering. So all of our services are pay as you go when you look at APIs. So there will be a metered pricing. And again, usually there's a free tier where you can just try it out, make sure you're getting the data you need, kind of get your application working with it before you can actually commit to a subscription.
00:23:57.358 - 00:24:47.602, Speaker B: And I'll show you a little bit of that's. All right. So let's just show you how that works. All right, so I think I've increased my resolution enough so you can see it. So AWS data exchange is accessible within your AWS console. It's also publicly accessible through the AWS marketplace link, and we'll provide that after the session in case you want to browse it. But when you go to the AWS data exchange service, again, another thing I want to mention.
00:24:47.602 - 00:25:40.882, Speaker B: It is a cloud native service fully managed by AWS, so there's no thinking about where the servers live and whatnot. This is all handled by the service teams here. And as a first step, just browse the catalog. We can get a listing of all the providers that have published to AWS data Exchange. We can filter through by industry vendor method and just to look at one of the, let's pull up my test here. They look at one of the products that is available. So the provider is in control of all this information.
00:25:40.882 - 00:26:45.480, Speaker B: So what is the product? The mechanism to purchase the subscriptions is also handled by the provider. So you see here I have a custom offer, so private pricing is also a capability as well as the public offer here. So I'm just looking at a test data set, just to give you an example. And down in the overview, there's generally basic information. How do you use it? What are some of the metadata associated with these data sets? Just so you get an idea of what it is before you start looking at it. And another aspect that data exchange helps manage is the regulatory and compliance pieces of it. So we do curate the data to ensure that things like PIi or HIPAA related regulations are handled when a provider publishes this information.
00:26:45.480 - 00:28:00.638, Speaker B: So there's often or will be some type of information or disclaimer with those type of data sets. Then if we scroll down, we can see the data sets that are available with this product. In this case, this is an API data set. So I want to access the data through an API and then the provider can provide samples. For an API, it would be actually just HTTP request example, but for other file based or redshift distribution methods, like a data dictionary is typically provided. So you can get up and going with the schema and all the support information usage, all the kind of contractual, but all the paperwork is all kind of handled through this product and this offering. So once I actually subscribe to data set, just go over to subscriptions over here, I can view what my terms are.
00:28:00.638 - 00:28:46.346, Speaker B: When is it renew a license that I have. But more importantly, to get to the point, there is an entitled data set, which is what I'm granted with this subscription. And this is how I can start to go in and figure out how to access that data. So if I click on that, it'll go to the entitled Data section. I have a couple subscriptions here. When you start at the product, you kind of get all the basic information here about the subscription, but there's a hierarchy of how it's provided in data exchange. So you have a product which has one or many data sets, which has one or many revisions.
00:28:46.346 - 00:29:44.478, Speaker B: So if I look at the data set itself, I can see how that's organized, what offer I use to get it, and then the revision is where the actual techie stuff is. So if you drill into the actual asset that I subscribe to for the latest revision, this is where I can get the information of how to access it. So I got the endpoint. I need the revision ID and the data set ID and the asset ID to ensure that when I do the API call, it will access this particular data set and revision. We do provide a open API spec so you can just import directly into your code. Or in the case that I'm going to show you, I just have Postman running just to show you a query. And if you scroll down, there are some helpers here of how to access the API.
00:29:44.478 - 00:30:22.522, Speaker B: And further, with AWS's command line tool, you can also do an API call through that. So it gives you just an example so you can cut and paste and just see how this is going to react. All right, cool. So this is the part that's likely going to break. I'm going to go to postman. Basically all I did just to talk it through is I imported the API spec. So I can see like this is a test API.
00:30:22.522 - 00:31:21.440, Speaker B: So it's some resource and root methods there and actions. But what I wanted to show you is that when you make a call to AWS data exchange, you do need to figure out the signature, and that's basically a collection of your API key and secret key and token that you have available to access that API. So if I go, I want to show my signature here in postman, just under authorization. There is actually an AWS signature option. You can go in there. So we have a service called STs where you can get temporary credentials in order to access AWS data exchange, or you can set them up on your account. But essentially you need an access key, secret key.
00:31:21.440 - 00:32:26.678, Speaker B: We need to talk about which region it came from. So when you're looking at the asset itself, it will tell you which region that is hosted out of. Like here, I can just see it's us east one for this particular one, but it's more prominent on the data files and tables methods. The service name would just be data exchange. And I got to pop my token in there to make sure I have that access to the API. So all I did, I just called this API, I passed a dummy key and parameter and look, know based on that authentication, it's kind of come back and spit out a result for me. So it's pretty easy to do this in the headers, sorry, headers, you will have to pass the data set, id revision and asset, like I said.
00:32:26.678 - 00:33:50.170, Speaker B: But the kind of cool thing about it is it's the same API for multiple data sets, so you can reuse your code here and basically just change these request parameters if you're leveraging multiple API data sets. So I'm afraid to hit send, but it will work. So I did want to mention the point of us presenting about data exchange is just to get you familiar with how that is and kind of point out that chain link functions is a way that you can connect web 2.0 APIs to web3. So connecting on chain data to external systems based on real world inputs and outputs. So cronhthe went through a bunch of use cases where you can leverage either real time or data set data that could potentially feed into your chain link function and help make a decision based on real world inputs and outputs. So data exchange is the way that we can provide easy way to give you access to these API or data set methods in a curated fashion.
00:33:50.170 - 00:34:59.698, Speaker B: Also, you can also get the sample data so you can actually play around with it, see if it's going to work for you. So data exchange is a way that you can do this at scale, I hope. I've shown you you don't have to rebuild API every single time you do the API to data exchange and you just access the different data sets through that. So I did want to call out the Chainlink Labs team and post the link in the chat as well. So they've gone ahead and created an example that's much more relevant to your hackathon where they're leveraging AWS data exchange with Chainlink functions and actually built the scaffolding for this universal connector. So just one API integration, you just pass it different assets, data sets and revisions that you want to access. And it provides a really good, like in this example, they're using the currency exchange API.
00:34:59.698 - 00:36:06.620, Speaker B: I can't take credit for this, but I did want to call this out and they provide all the information how to incorporate that into Chainlink function and how you can actually leverage in this example, the currency data. So we'll be putting the link in the chat definitely is a good place to start as far as the hackathon is concerned. So definitely big shout out to that team. I also wanted to point out we do have a publicly available workshop. We'll also put this in the chat as. So like if you just want to see how to actually leverage the subscriptions, I took you through the API delivery method, but for the other methods you can see just some examples of how you can do that and also how you can start to visualize, even apply machine learning to that if you want to extend past the data set. So definitely worth going through, if anything, just to kind of easily see the steps to start using.
00:36:06.620 - 00:37:17.834, Speaker B: We'll provide those. And I think with that, that's all we had for the presentation. I think call to action is to start browsing the catalog, excuse me, seeing if there's any use cases for your web3 project that you can leverage this or enhance it and you have the GitHub repo from, and then you can start leveraging it and see if the chain link function is something that's going to enhance and improve your product. So thank you for your time today and I think we'll open it up to any kind of questions that we can try to answer. Thanks, John.
00:37:17.952 - 00:37:48.210, Speaker A: Okay, thank you, Ron. Thank you, Karanti. That was definitely very helpful. Very interesting. So guys, everyone, if you have any questions for them, feel free to drop them in the chat and we will answer them in these next few minutes. And if not, we'll just cut it short. But let's just see if in a minute or two anyone drops any questions here in the chat.
00:37:48.210 - 00:38:43.780, Speaker A: And in the meantime, just to remind you, submission deadline for your project this Friday is your 9th, 11:45 p.m. ET eastern time. So New York City time. And yeah, we'll definitely are super excited to see what you guys are working on and I don't think there's any questions, so maybe we can cut it short now and yeah, once again, Ron Cronthy, thank you so much for your time. I hope that everyone has found this useful. Go back to your project, kick off that hacking, and yeah, we'll see you back in the 24th for our closing ceremony while we'll announce the big winners. So thanks everyone.
00:38:44.310 - 00:38:48.078, Speaker B: Thank you. Thanks. Good luck. Good luck. Take care. Bye.

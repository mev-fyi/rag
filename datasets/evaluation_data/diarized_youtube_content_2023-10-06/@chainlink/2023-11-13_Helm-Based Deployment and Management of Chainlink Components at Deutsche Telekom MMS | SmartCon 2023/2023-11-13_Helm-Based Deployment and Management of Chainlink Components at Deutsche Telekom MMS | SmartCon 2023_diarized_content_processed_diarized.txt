00:00:02.490 - 00:00:45.258, Speaker A: Hey, everyone. So we at Deutsche Telecom, we don't build web3 protocols or web3 use cases, but at some point, someone needs to run the infrastructure for that. And this is exactly what we does, what we do. So I want to give a little background of our history, what we did in the past, how we came to web3. Then we will talk about our tech stack. This is a DevOps talk, so if you're interested in that, you're absolutely right. It's beside Web three a little bit.
00:00:45.258 - 00:01:25.702, Speaker A: So it's more general, but still very interesting, we think, at least. And with the tech stack or describing our tech stack, some internals, we also give a live demo how we deploy our web3 components, and this based on chain link infrastructure here. And of course, if you're watching online or here in the room, we are open for feedback. We are always looking to improve our feedback. So if you have suggestions, please reach out to us after the talk. We are happy to talk with you. Okay, yeah.
00:01:25.702 - 00:02:24.582, Speaker A: So not that many people know that telecom MMS, which is a subunit within Deutsche Telecom, already started with blockchain in 2016, but of course not with crypto. It was a unit based on consulting and proof of concepts. So a lot of companies were interested in the technology, and this is where they reached out to the, so to say, big players in Germany, which was a telecom. And yeah, they wanted to have proof of concepts, for example, for supply chain and all this stuff. And this is how we started. And then in 2019, a young ukrainian colleague came into our team and he thought, okay, telecom is building infrastructure for ages now. I mean, telecom is building stuff for mobile, being kind of some kind of backbone of the Internet with their cables and also the servers.
00:02:24.582 - 00:02:53.890, Speaker A: Why not also build web3 infrastructure? And he had some context and he need to talk to a lot of guys within the company. As you can imagine, we are not a web3 startup or something. So we are a legacy company. And you need to talk to a lot of people to convince them. Okay, let's go into web3. But it worked out in the end. This is where we came in contact with Chainlink in 2020, I think.
00:02:53.890 - 00:03:50.150, Speaker A: And after some time, this is how it started. But the issue is that, as I mentioned, our unit, we're just consultants and software developers, but we are now deploying infrastructure. And of course, as software developers, we know Docker and all these tools. But to run productive infrastructure, you need to know a little bit more. And luckily, the MMS is a bigger company and we had different DevOps units in there, or we have different DevOps units in the company and we teamed up with one of them. Yeah, we were really keen to get our hands dirty on the Chainlink infra and they said, okay, wait a minute, that's a productive environment, we need to talk to each other and you need to learn a lot. And this is what we did over the last years and becoming our DevOps engineers ourselves.
00:03:50.150 - 00:04:37.910, Speaker A: Yeah, and as I mentioned, we teamed up with an internal unit and they already had specific workflows, how to deploy infrastructure. And we just adopted that. We learned that. But after some time we thought about this is what I forgot, this unit had its own developed tool. It is and was based on open source software, but still it was self developed. And for example, to get always all the newest updates from all these big open source tools like terraform, ansible and so on. And self developed tool is really hard.
00:04:37.910 - 00:05:27.586, Speaker A: So to keep up to date, this is where we thought about our processes and then decided, okay, we fully go away from this tool and just use open source tools, which is better, we think. And yeah, this is actually how the tech stack looks like. We are heavily based on GitLab as you can see, not only for source code management and all the Ci CD pipelines. Luckily our business guys and all the administration guys are also really eager to learn new stuff. So we convinced them, okay, get rid of Jira and confluence as well and just use GitLab for actually everything. So it's our one stop tool for documentation, for task management and for CI CD obviously. And also source code management.
00:05:27.586 - 00:06:18.838, Speaker A: We use of course docker images. Not always, this depends of course on the use case, but a lot of times therefore we use Kubernetes for orchestration helm as the base layer in terms of how we define the templates, the Kubernetes resources. And what is really interesting I think for a lot of people is that we don't use AWS, Google Cloud or all these big players. We use telecom infrastructure, it's already there. At least that's an advantage being in the telecom. But we also use for example here gridscale, which is a smaller german infrastructure provider. Yeah, we are happy to work with them, they're really good and really we are really working close together with them.
00:06:18.838 - 00:07:13.526, Speaker A: And all of these clouds, different cloud providers offer or have their data centers in Germany, Austria, Switzerland, Netherlands, I think. Yeah, and then we use the kind of usual tools and DevOps like terraform, ansible and also I think the most widely spread monitoring stack here with Prometheus and Grafana. Yeah, wait one back okay. And during the actual showing the tech stack we just focus on Kubernetes, Helm and GitLab. And I just want to describe and show you a little bit about two specific repositories and three small little tools which are really helpful. If you are in the DevOps space, then maybe you heard of them, maybe not. So maybe this will help you as well.
00:07:13.526 - 00:08:05.480, Speaker A: So just as a short mention, this first repository is called cluster helmstack. We call it internally cluster helmsack. It is based on helm charts. And actually if you use terraform to deploy a new Kubernetes cluster in whatever cloud provider, then this Kubernetes cluster is naked, obviously, and you cannot just use it for a production ready environment. And this cluster helmstack repository includes all the different technologies, and these are not all which you just click the play button, they were installed into the cluster and then the cluster is actually ready for production. Then I mentioned three tools and the question is if you're aware or not. So really recommendation, unfortunately this is not really readable, sorry for that.
00:08:05.480 - 00:08:50.486, Speaker A: This is the renovate bot. So this one, this is the logo. Renovate is actually a dependency scanner. If you set it up in your repository, it works with GitHub. With GitLab, if you set it up in your repository, then as the name or as the description suggests, it scans for dependencies, especially for Chainlink. This is really helpful because for Chainlink we have the OCR client which we deploy, which is the actual oracle client, so to say. And then you have these external adapters, external adapters, if you're not familiar with that, these are the tools or the components which call different API providers like Coingecko, Coinmarketcap and so on.
00:08:50.486 - 00:09:22.470, Speaker A: And there are quite a lot of these external adapters. And as you can see there's a big list of updates in this merge request. And actually this is what renovate does. It opens up pull requests, merge requests automatically. I think it can even deploy this automatically, but this is not how we do it. This is in the end a human process to deploy it. Then a second tool which is really new, which is wrote or developed by former colleague is called Graphaml.
00:09:22.470 - 00:10:20.254, Speaker A: If you're a developer and ever wanted to build a Grafana dashboard using the UI, I think you will struggle with it. And Graphaml actually is a way to code Grafana dashboard using YAML. And in the end what comes out is a helm chart in Yaml and then it has more capabilities, but this is one. And then you can just deploy the Grafana dashboard as an helm based, so to say, which is really nice. And the third tool, really easy one, actually, too easy actually, but it's really helpful. It's just an RSS feeder. But what we do is here that we, for example, subscribe to a lot of different technologies we use to get updates, also renovate scans for these updates.
00:10:20.254 - 00:11:12.210, Speaker A: But it's also sometimes nice just to see this in the browser during working hours. And specifically in the upper part of the screenshot you see these Gitlip emergency alerts, if you can read it, gitlib critical alerts and so on. So we have separate repositories in GitLab where our alerting system opens up new issues if there are alerts for this specific severity. And then the RSS feeders subscribe to these repositories and you get an information, as I mentioned, during working hours, of course overnight this doesn't help. But there we have 24/7 on call duty, of course. Yeah, these were the three tools and I think the most cool thing which we developed over the last years, or what we use now for all of our developments. We call it common config.
00:11:12.210 - 00:12:05.970, Speaker A: This is where you need to be familiar with GitLab workflows, GitHub workflows or the GitLab Ci CD pipeline, how you build this in the end, because this is all Yaml based. Because as I mentioned, these workflows, these GitLab GitHub workflows and GitLab Ci CD is based on Yaml. And what it is is actually something like an object oriented programming where you have a parent class and this parent class has certain functionality, and then all the child classes inherit from that and have this functionality in it. That's actually how this common config works. So the actual real common config is just for setting up all our Ci CD pipelines. For example, it includes the setup of our stages. So the Ci CD stages, it includes the linding stages.
00:12:05.970 - 00:12:43.070, Speaker A: We are really looking for the code quality. We really want to achieve high code quality. This is where we have a lot of linding tools installed in our pipelines. And a bunch of other stuff is also set up in this common config. And then we have these technology based YAML files which then, as I mentioned, inherit from the common config. So have all these linting stages and so on in them. But for the specific technology like helm Docker, whatever we need to use for this specific Ci CD pipeline, they have then specific jobs.
00:12:43.070 - 00:13:55.026, Speaker A: So Ci CD jobs which are specific to this technology, just a short screenshot how this is structured here in the common yAml, this is the base layer. So the parent class as I mentioned. And what you can see here just shortly, you see here this for example, provider and this stage variable. And this is where we in the end, for example choose to which cloud provider and on which stage we want to deploy our infrastructure just by drop down and everything works automatic. And then for example, as I mentioned, you see here that the stages are set up and all the technologies are written here, ansible Docker and so on have then these stages also in the Ci CD pipelines, if we use them. So what if we want to deploy chainlink components, especially the OCR client and the external adapters, which we kind of packed into one helm chart. So in this case we want to use of course the common config because that's the base layer.
00:13:55.026 - 00:14:45.160, Speaker A: And then we want to use helm as a technology to actually run or to deploy the component. And as I mentioned, these technologies have then specific jobs defined in it, but not as a running job, but just as a template. So if we just would kind of add the common config and the helm configuration in the actual Ci CD pipeline, only the linting stage would run and the pre stage, but no real deployment because this is shown with the dot. Unfortunately, you don't see the laser point on the light on the white background. Sorry. But you see this dot in front of every helm, minus common minus job and so on. This means that it is a GitLab template job and not an actual job.
00:14:45.160 - 00:15:50.282, Speaker A: The idea is here that you can use on a modular basis which job you actually need. For example, we need helm, but we need not all of the helm jobs. For example, for the chainlink chart to build it, you don't need the deploy helm jobs which are at the bottom of this rectangle. You just need maybe linding the helm package and the helm release job. And on the other way around, when we want to deploy the actual component, then we don't need a package job and a release job, we just need the deploy job and all the other linting stages and so on as well. And this is then how the final GitLab Ci YAml looks like. So where you finally define your Ci CD pipelines, you see above that it includes the common YAMl and the helm Yaml as I've mentioned.
00:15:50.282 - 00:16:44.206, Speaker A: And then if you include these different yAmls, then you have all the stuff which is defined in these YAML files. And what we just do is we set the secrets here and then we have some smaller jobs. For example, here, the dependency build, and then we just have the deploy stage. And so this is, I don't know, a 60, 70 line yaml file instead of a 300 line Yaml file, which is better maintainable. And of course, also, the idea is we use this all the time. So, I mean, from the common Yaml, we use this all the time, so it wouldn't make sense to copy paste this all the time. And at this point, I will hand over to Christopher because he will do now a live deployment of our chain link OCR client and the external adapters, of course, not on prod, because as you saw below, the oracles are running.
00:16:44.206 - 00:16:49.338, Speaker A: We don't want to cancel that. Yeah. So, Christopher.
00:16:49.434 - 00:17:11.730, Speaker B: Hello, everyone. Can you please switch? Oh, you did already. Thank you. Okay, I will guide you through the presentation. What you see here is a basic GitLab pipeline. And what you see here, these variables tobias already described, configured in our common config. You can just pick it through the drop down menu.
00:17:11.730 - 00:17:50.318, Speaker B: In our case, we're going to deploy a dev stage on quidscale dev and going to watch for new environment coming up. I'm going to run this pipeline. So what we will do right now, we are going to deploy, in our case, would be the latest versions of OCR or the external adapters. So we want to test them. And what you can see right now in the pipeline is happening. It's the pre stages and the lin stages, they're all coming from the common config. So we just included the common config and the stages will run automatically.
00:17:50.318 - 00:18:25.070, Speaker B: And as you can see on the right, we cannot deploy until every of our prestages have run successfully. Okay, now we are good, and we're going to run the pipeline. I encourage you to watch the button now, because they will happen a lot. It will boot up the training dev environment to test if the theoretical new versions of the adapters or CR client will boot up successfully to reduce downtime before we deploy it on prod.
00:18:30.690 - 00:18:33.870, Speaker A: Okay, I'm silenced. Am I silenced?
00:18:34.610 - 00:18:35.806, Speaker B: Think you're not.
00:18:35.988 - 00:18:37.162, Speaker A: Okay, what do you.
00:18:37.316 - 00:19:05.420, Speaker B: Okay, pipeline is running now. On the top, you can see it's resolving the secrets from our hashico void. This will be pretty fast now. And on the bottom, you should see popping up the pods. So it's all of our environment. So it's the OCR client and all the external adapters we run in our environment. We have to wait a bit for them to come up.
00:19:05.420 - 00:19:39.620, Speaker B: You see some errors, of course, but this will handle itself. Since it's Kubernetes, most of the time it comes out clean for us. We just have to wait a few seconds. We can check this on the right. What's up already? As you can see, most of our environment is already up. I'm going to clear this again. Check again.
00:19:39.620 - 00:20:18.058, Speaker B: Okay, this looks better. We're getting to it. As you can see on the left, it's had some problems resolving the images, probably some network issues, but we should be good now. Let's check again on the right side. Yeah. As you can see, most of our environment is now up, except one redis replica, which is not so important for this live demo. So what we actually did, we deployed the whole dev stage with the latest versions of the adapters or OCR client.
00:20:18.058 - 00:21:33.282, Speaker B: We can be sure now that the adapters boot up successfully. But in the past, you not only wanted to test the adapters to boot up, you also wanted to test the calls when you call the APIs to the data providers. In the past, we could do this over Chainlink dev stage and run wrap hooks, but Chainlink got rid of the dev stage. So if you check their documentation right now, they're going to refer to curl commands and to test our environment further before we deploy it on prod, we have built a small tool which is basically running the curl commands from a pod and a pipeline will pull the status or the logs of the pod and the curl commands to our pipeline and then decide if the run is successful or not. We have to wait now until the preconditions are ready again so we can deploy this. Disclaimer this is an early PoC. I started a few days ago with this so it could fail.
00:21:33.282 - 00:22:14.260, Speaker B: But if it fails, I will explain why. It's okay, we're ready to go. So, same procedure. We're going to run the pipeline. You can see on the bottom now it's going to deploy another pod which will pop up and do all the curls and will be immediately shut down by the pipeline again, so we don't have to care about resource management of the pod. Awesome. The pipeline is starting now.
00:22:14.260 - 00:22:41.430, Speaker B: Yeah, you can see here it's starting the process. It's waiting for the adapters to come up. And unfortunately we have to do a small sleep here. I did some research on this. Sleep 15 was the easiest one. I could also pull the cluster. I made polling on the cluster, but due to resources, I'm not sure if this is recommended.
00:22:41.430 - 00:23:18.866, Speaker B: And yeah, the pipeline works as intended. We see some errors here. This is what I expected in this case because we have external adapters and there are also composite adapters which interact with the blockchain so they don't return 200, then they return error codes because we cannot test the call to the blockchain right now. So we're having some errors here. We're trying to resolve this in the future. This is, like I said, early PoC stuff. So we have the idea of leveraging tenderly to test these adapters further.
00:23:18.866 - 00:23:56.002, Speaker B: But yeah, this is an open question, like to be a set. Recommendations and suggestions are welcome. I have prepared also the success case where I commented out the composite adapters and the success case looks like this. So you can see at the bottom that the job has succeeded. And in theory we would be clear to deploy the new versions on our productive environment. Yeah, that's it. With the live demo, can you please switch back to the slides? We have to forward one.
00:23:56.002 - 00:24:38.126, Speaker B: Yeah. We have also an announcement. We have released these helm charts you saw in the first pipeline to deploy your training environment. The helm charts contains a template for every external adapter. It's one chart, you can use it for every adapter and the OCR client. We have included a peer to peer service for our cluster, so we could do peer to peer messaging with the other clients, but it's not necessarily needed for everyone who wants to leverage this. Yeah, it's released under Apache 2.0
00:24:38.126 - 00:25:30.786, Speaker B: license, so you can freely use this in your projects, and you are welcome to use this and contribute. If you have any questions or want to get involved, you can contact Tobias or me anytime. Yeah, big thanks to our team, the guys you see here, just the whole blockchain solutions center team of Deutsche Telecom. We're a lot of guys, and we also want to thank the compliance and legal team for helping us the last years because we are Deutsche Telecom, so handling crypto assets is not necessarily the thing they do every day. So, yeah, big thanks to them and, yeah, that's it. Thank you for listening. And you see our emails on the slides and you can contact us anytime if you want to.
00:25:30.888 - 00:25:31.200, Speaker A: Thank you.

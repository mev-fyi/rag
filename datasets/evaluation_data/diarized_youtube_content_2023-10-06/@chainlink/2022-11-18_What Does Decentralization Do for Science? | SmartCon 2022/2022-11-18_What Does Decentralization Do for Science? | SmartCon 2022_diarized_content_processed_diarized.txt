00:00:08.970 - 00:00:39.946, Speaker A: Coming in loud and clear. Yeah, I think I hear myself. How's everybody doing? I'm really excited to introduce today to speak about what does decentralization do for science. We have Chris from DSI lab and Ben Reinhardt from PARPA. And before we. If you guys want to take a seat, we can get nice and comfortable, and it looks like we have a few people joining us today. So before we get started, I kind of wanted to get a handle of the audience and maybe learn a little bit more about why you are all here or what your background is.
00:00:39.946 - 00:01:42.010, Speaker A: So who here is working on a DeFi protocol? Who here is working on blockchain infrastructure? Who here would consider themselves an academic or a researcher? And who here accesses papers or has to find papers to support their work or rely on papers? Good balance. Cool. Yeah. So I think today we're going to be talking a little bit about some non financial use cases of blockchain technology that allow us to address other coordination issues that stem from decentralizing a particular endeavor or task. And in this case, it's science. So I wanted to give a chance for each of our wonderful panelists to introduce themselves and kind of what they're working on before we dive into the meat of the question of what is decentralization, what is decentralized science specifically, and how did the two end up as bedfellows? Would you like to kick it off, Chris? Sure.
00:01:42.080 - 00:01:57.010, Speaker B: Thank you, Shadi. So, I'm one of the co founders of dSalabs. We're building infrastructure to decentralize a scientific record, to make it more reproducible, to make it more composable, to essentially accelerate the pace of finding, discovering, and creating new knowledge.
00:01:59.510 - 00:02:17.110, Speaker C: I run a nonprofit research organization that basically acts like a private DARPA to work on things that are too speculative to be a startup, but too engineering or coordination heavy to be in academia. We focus particularly on new paradigms in materials and manufacturing.
00:02:18.670 - 00:02:38.830, Speaker A: Interesting. Yeah. So materials manufacturing, that's kind of at the cutting edge right now of many, many different commercial and applied sectors, and probably very much led by centralized research institutions. So I want to open up with the first question or prompt for the panel, which is, what is decentralized science?
00:02:41.090 - 00:03:43.938, Speaker C: Go ahead, Benjamin. Yeah, I think it's like, what we need to do is establish that there's like, a narrow definition and a broad definition of decentralized science. So the narrow definition is, I think, the thing that you normally think of, which is applying blockchain technologies to do some kind of decentralized, basically infrastructure for. And I would say that's where Chris and Chaddy live. And then the broader definition, which is sort of where I live more, is what I would describe as decentralizing the incentives of. So right now, most people who do science and research more broadly are under one of a very small number of incentive systems. You either have basically like academia, large company R and D, or startups for the most part.
00:03:43.938 - 00:03:53.560, Speaker C: And so I think of that kind of decentralized science as saying like, okay, what if we have other incentive systems to enable different kinds of research?
00:03:56.010 - 00:05:04.406, Speaker B: Yeah, we were at the dinner last night with Ben, and that definition about finding alternative models of incentivization to address some of the blind spots in how science is not only funded, but verified and published today, is essentially one of the core aspects around DSI. We can also think about it from the point of view of a layered stack. So at the very bottom, you have everything that's about infrastructure, right? The decentralized infrastructure in which we rely. For instance, we could essentially store the scientific record in a decentralized repository that would allow universal open access, right? True open access beyond these data silos that essentially gather and close off portions of the scientific record, erecting paywalls, extremely high author publication fees for open access, and these different types of problems. Right? So there's the really infrastructural definition of DSI, then there's the operational and funding definition of DSI. And this is where individuals come together to address blind spots in funding. One of those particular primary applications is everything that has to do with patient groups, right? So patients could have suffer from a rare disease, they're ignored by the current pharmaceutical environment industries because it's not a wide enough market to be addressed.
00:05:04.406 - 00:05:41.990, Speaker B: But these patients have a very, very high motivations to find cures and find solutions to their problems. And they also have, what is extremely valuable is they have data on themselves that they can actually put available to researchers to essentially develop new theoretical models and cures that could also serve to return value to their specific scientific communities. Right? So you can think of those models as more of a Dow crowdsourcing model for these specific communities of patients that enable to address some of the blind spots in funding in the R D in the pharma and the biomedical world, right? So that's more of the operational layer.
00:05:42.650 - 00:05:45.998, Speaker A: Oh, that's great. That's absolutely chatty.
00:05:46.034 - 00:05:46.794, Speaker C: What do you think?
00:05:46.912 - 00:05:47.642, Speaker B: What do I think?
00:05:47.696 - 00:06:57.234, Speaker A: What do I think about decentralized science? So I have a pretty specific definition. I believe decentralized science is a really young movement that's kind of born out of the collision of the open science and web, three kind of philosophies coming together to empower web native knowledge creators to coordinate on problems around knowledge sharing, discovery and solving really difficult problems. Right. So how do we build software that doesn't belong to anyone, that's running on public infrastructure that lets us coordinate to meet and rise to existential challenges and solving problems together? So, yeah, I really like these definitions. Why decentralized science? And what if I came back to you guys and said, well, we've had NIH and DARPA and the NHS for more than half a century at this point, they're doing a pretty fantastic job. The COVID vaccine was made in just about a year, so why should I even care or believe that this is a problem?
00:06:57.352 - 00:07:00.946, Speaker C: Wait, are they doing a fantastic job?
00:07:01.128 - 00:07:02.690, Speaker A: I certainly believe so, yes.
00:07:02.760 - 00:07:03.380, Speaker B: Why?
00:07:04.310 - 00:07:37.646, Speaker A: Well, if I had to say, well, NIH is the largest public funding institution in the world for science. They allocate tons and tons of funding across hundreds of universities, both domestically and internationally. They have a proven track record for developing technology that otherwise would be captured by commercial interests, like in my field, for example, MRI reconstruction algorithms, which Siemens owns the rights to, which prevents kind of what you can do with them. Yeah, I'm running out of ammo here.
00:07:37.828 - 00:08:24.480, Speaker C: Well, there we go. You answered your own question. It's just like you look at the amount of input to the amount of output that we get, and people have done tons and tons of work around this, and there's the whole great stagnation thing. I don't have strong evidence for this, but the fact that we put so much more money into research and don't seem to get that much out of it than we did before. The NSF and the NIH. Sure, you throw hundreds of billions of dollars and sometimes good things will still come out, but it just suggests to me that we could be doing much better.
00:08:26.210 - 00:08:52.962, Speaker B: Yeah. And I think there's some very interesting work showing that there's a decrease in general research productivity in terms of breakthrough productivity. There's more and more scientists every year producing more and more papers, and there's something that is malfunctioning within that feedback loop. So there's incentive misalignments across science. Right. Many, many scientists are incentivized to produce as many papers as possible in the highest possible impact factor journals. There's.
00:08:52.962 - 00:09:40.466, Speaker B: System suffers from monometrics. There's also the problems that funders gather, essentially impact on the research they fund through what the publishing industry is essentially creating as a funder intelligence platform. Right? So essentially, number of pdfs weighted by number of citation counts, plus a few news articles at the end of the day. And when you think about it, these incentive structures, one of the clearest example of the failure of these incentives is this whole problem surrounding the replication crisis. So who here has heard of the replication crisis? Raise your hand so there's an audience just to understand. I'll give you one example. Amgen, a couple of years ago did a replication study on some of the most groundbreaking early cancer papers with new drug targets.
00:09:40.466 - 00:10:24.574, Speaker B: They had a failure to replicate, a rate of failure of replication of 90%. And that is a terrible indictment of the process of knowledge discovery. Recently, there was a wide cancer reproduction replication study that essentially found on the good news, it's like, well, 50% of the paper is replicated. You think, ah, we addressed it. And then you look at the median effect size and you're down 90%. Right? So you go from a clinically relevant drug to a drug that actually will have very little clinical relevance because of the size of these effect sizes. Right? And this is not just the case of medicine is the most conspicuous, but there's many sorts of crisis of replicability and reproducibility around science.
00:10:24.574 - 00:11:15.042, Speaker B: And this is also due to the types of incentive mechanisms that reward scientists for novelty. Right? Novelty is the most important factor that is rewarded right now in the scientific publishing industry that institutions care about, and reproducibility and replicability and independent replications. These are things that are typically underdogs in the prestige system of academia. It's very hard to say, hey, we've spent five years doing this amazing replication study. Please, can you publish it in your journal? Is this really novel? And that's a huge problem. Right? So we have a set of incentives in academia that put such a heavy emphasis on novelty and such a low emphasis on replicability and reproducibility. One of the reason for this is that it's very hard to measure these things.
00:11:15.042 - 00:12:04.786, Speaker B: It's very hard to track them. Right now, the indicator of impact is scholarly attention. That means the number of citations that a paper will get. You would think that in this day and age, we should have indicators such as, is the code and data open? Do the results replicate? Do the results reproduce? Has the authors published valuable artifact alongside its research? We've had recently a case with Alzheimer's disease. Who has heard here of the problem surrounding the amyloid beta hypothesis? Yeah. Okay, this is another house of cards that's falling down, and we're talking here billions of dollars that have been put into that specific field where there was a series of unreliable papers that have been produced. And when you think about it, $2.8
00:12:04.786 - 00:12:25.718, Speaker B: billion invested in this line of research, and the output of that is 10,000 pdfs. So just think about this for a moment. $2.8 billion for 10,000 pdfs. Right. What should we have for $2.8 billion, you could imagine? Well, we should have immense data sets with millions of measurements, if not tens or hundreds, millions of measurements.
00:12:25.718 - 00:13:02.840, Speaker B: We should be able to form large consortiums to investigate and analysis highly powered studies that would allow us to gather new insights and learn new knowledge about these conditions. So there's a problem around these general incentives. And one of the core tenets of DSA is, hey, there's this system that's running. It has blind spots. It has some misaligned incentives which are creating these black holes of reproducibility crisis. Can we address those system by providing funding, by providing incentives, and by providing infrastructure and support for sciences that actually engage in those types of work?
00:13:03.210 - 00:13:38.690, Speaker A: Let me jump in here real quick and try to guide the conversation a little bit to hammer in on some of the good bucket list of issues there. So let's start off with funding, because that seems to about kind of wrap around many of the problem statements that you two have put forward for us to think about today. So with funding, let's just take a moment to reflect on how it currently works. Right. So as a scientist, I typically have one track that I go down, and that's the NSF or the NIH route. I'm trained as a graduate student, usually by my first year, to submit a proposal.
00:13:39.030 - 00:13:50.734, Speaker C: I would expand that to more like the government. Right? There's the NSF. The DOE funds tons of things. The DoD funds tons of things. So just to correct that record.
00:13:50.792 - 00:14:25.620, Speaker A: Thank you. Yeah. So let's just zoom that out and say centralized state government, grant makers. And so there's an inherent culture, a certain set of bureaucracies, a bunch of checkboxes you have to strike off. And this funding, right, is going to come to the institution, not the scientists, because the institution carries liability if anything goes wrong ethically with the facilities and what have you. So that's an incredibly entrenched system for allocating capital to knowledge creators. How do we disrupt that? And if we do want to disrupt that, how do we start? And Ben, I want to start with you.
00:14:27.190 - 00:15:14.002, Speaker C: Well, I would add a little bit of nuance to that, to the fact that there actually is a lot of money. I think it's less, like, where the money comes from and how people think about spending it. So it all revolves around, like, okay, so we have committees to make sure that we're allocating money responsibly. And then we issue a grant to a researcher who says, I'm going to do this thing, and this is why I think it will be successful. And then a committee of people will say, like, oh, does this seem responsible? Are we going to be wasting our money?
00:15:14.056 - 00:15:14.274, Speaker B: Yes.
00:15:14.312 - 00:15:57.662, Speaker C: No. And then what they're targeting is grants that successfully achieve what the grant says they'll do. So they're always checking on that at a very high level. I think one way to address that is just have different mechanisms, right? What we specifically are doing is having a mechanism where instead of a committee, you have a program manager who's like, okay, here is a technology that needs to be built. Here are the specific projects that need to happen and then goes. And instead of making scientists, people apply with grants, they just go. And they're like, okay, you seem good.
00:15:57.662 - 00:16:34.662, Speaker C: Can we work together to figure out how we would structure a project so that it both satisfies what you want to do and what we want for the broader technology? But that's just like one way, right? There's other mechanisms. If you've read Donald Braven's book scientific freedom, where it's like you sort of do something, where you're just like, you seem smart here, have 510 years of funding and just go do something, which is wildly irresponsible, but at the end of the day, doing good research requires being a little bit irresponsible. So that's one approach.
00:16:34.726 - 00:16:38.330, Speaker A: Like the Peter Thiel model, right? Peter Thiel fellowships for smart.
00:16:38.910 - 00:17:06.680, Speaker C: Exactly. Like, just sort of, like, bet on a person. The thing that's exciting is that why DSi, those are two things. There are probably literally hundreds of different approaches, each of which is good for different kinds of work and will enable different people to do different things. And that's the diversity that we want.
00:17:08.170 - 00:17:39.120, Speaker A: I wanted to inject the discussion of culture around this, right? So I've been in a co bid grant for a IARPA grant, and I've been on a bid for an IH grant, and I noticed that the culture was completely different in those two universes. What role does culture have to play when thinking about terms like decentralization and specifically how different niche communities might cultivate different systems of practices to solve the challenges they're faced with?
00:17:39.570 - 00:17:42.640, Speaker C: I want to let Chris have a chance first. I have opinions about everything.
00:17:43.590 - 00:18:18.310, Speaker B: Yeah. On the topic of funding. So there's a number of interesting mechanisms that also the DSi space in general is experimenting with. One of them I'm sure you're all familiar with is gitcoin. Quadratic funding. These are experiments that allow us to distribute and allocate funds in essentially a way that is more optimal in terms of satisfying a certain ideal outcome and utility function. There's other methods that are not yet out there, but that are being discussed across various DSI communities.
00:18:18.310 - 00:19:04.586, Speaker B: One of them is this notion of impact certificates. So who here has heard of impact certificates or hyper certificates? We do have a really educated audience here. So impact certificates, it's still essentially a space that's evolving and there's different takes and different definitions around them, right. One of the way to think about it is imagine you have a credible funder like the gates and the Melinda and Gates foundations, and they allocate a price. You say, hey, cure malaria, right? Has a certain outcome to that. And then you're a scientist and you say, hey, okay, I want to participate in that, but I don't have the cash to undertake the research at this very moment, at this point in time. But I can go on an open market and I can sell an impact certificate of my work.
00:19:04.586 - 00:20:30.498, Speaker B: And the person who buys that impact certificate could be someone who's essentially a vc for science, who's looking at the work, looking at the team, he's evaluating the quality and the plausibility of the system working, and he produces, he's essentially funding that team with the conditions that he's going to have a stake in the success. Right? So when the prize condition, essentially the prize is achieved, what happens is that a portion of the funds of that price goes to that investor who puts the fund out first. Right? So for those of you that are proponents of market mechanisms, you could think that this would be a very effective way of reorienting the type of decision function that's done in funding, right. Because right now funding is all about mitigating public perception. Well, Ben, I'm sure you have a lot of opinions on that and love to hear about it, but when you think of the way funders, they're very aware of their image and they need to justify their spending decisions to committees, essentially it leads to quite a certain degree of risk aversion for moonshots, right? Whereas investors on a private market that are operating on this impact certificate market could have essentially a completely different way of appraising what is worth investing into. Right? They could go for the moonshots. Right? Essentially the zero to one high risk projects that have low probability of outcome, but high probability of payouts.
00:20:30.498 - 00:20:56.986, Speaker B: That would be massive if these work out. Right. So this is another mechanism. Then there's hyper certificates, which is something protocol labs is working on, and some others in the space, which allows fractional distributions of these impact certificates. They have other types of properties here. So to sum up, the funding landscape and DSI. So what do we have? We have, on one hand, we have the daos, right? That pool fund together to address the needs of patient groups, and they invest those funds.
00:20:56.986 - 00:21:27.046, Speaker B: And you have examples. For example, one of the prominent example is Vita Dao. Vita Dao is a longevity Dao. It's there to essentially produce, buy IP from scientists or fund them pro bono, depending on the model that they're using. And they're essentially doing that by pooling the funds of the people within that dow and that ecosystem. There's going to be more of such dows that will sprawl up with value propositions around patient groups, around climate change, around different very important public goods. There's the impact certificate market.
00:21:27.046 - 00:21:38.460, Speaker B: Right? That's another layer of funding. So these are the two types of mechanisms that will come to blossom across the DSI space. And, yeah, we're super excited to see what will come out of this.
00:21:39.150 - 00:21:50.554, Speaker C: Can I double click on what the cultural differences between the NSF and IRPA that you noticed were just to ground what cultural differences end up looking like in different organizations?
00:21:50.682 - 00:21:52.400, Speaker A: 100%, yeah.
00:21:52.770 - 00:21:54.482, Speaker C: Can you describe it? What was the difference?
00:21:54.536 - 00:21:55.186, Speaker B: Yeah.
00:21:55.368 - 00:22:48.606, Speaker A: Okay. So I would say in NIH, it was like interacting with my peers in a collegiate environment. I mean, kind of cutthroat at times, but I would say slow moving, not taking our time, kind of working through ideas and topics, whereas big picture impact. Oh, well, I'm going to study alpha betas and nucleon 152 in this mouse model. And the impact is society is going to be a wonderful place. Right? That's kind of how you write your grants, and that's kind of how they're evaluated, too, in a weird way. Whereas through ARPA, whether it's DARPA or IARPA or the new ARPA H that's just been spun out from that model, it's like being in a very fast paced startup environment, right, where you have very strict deadlines for tangible milestones that you have to meet to get to the next round of funding.
00:22:48.606 - 00:23:19.286, Speaker A: It's kind of similar in some ways to the X prize, right, where there's this competition to drive a car by itself, 10 miles, 20 miles, 50 miles. Right. Whereas for ARPA, these are very kind of constrained, specific sets of goals that you're in competition with, with other folks. And so there's less bureaucracy, more focus on results being delivered quickly and efficiently, and a faster churn rate of ideas and hopefully leading to innovation would be my take on the culture.
00:23:19.398 - 00:23:58.520, Speaker C: Cool. The thing that I want to point out is that what I would argue is that neither of those cultures are better. It's that one of those cultures is good for a certain set of work. Right. Where you probably need to spend a lot of time marinating on ideas and sort of hanging out with a blackboard. And then another one is much better for really pushing, bringing components together and really getting specific things done, both of which are important for research. And so the question is, what other cultures would be good for what other work?
00:24:00.090 - 00:25:01.742, Speaker A: Yeah, and I think that's kind of the beauty of decentralization, is that we build libraries of code that let us coordinate that, let us organize, let us decide our own evaluation metrics for grants, whether they're impact markets that prioritize verified reproducibility on data sets that follow community standards, for example, that are embraced by the wider science community, or whether it's perhaps self organization around a Gitcoin quadratic funding voting round. Right. Just like we saw in Gitcoin round 15, which was the first DSI matching round, successful. Really great news there. I think one thing that perhaps DSI, and please do feel free to push back on this, can offer that CSI, let's call it that can't, is a readiness to embrace and iterate over different cultures and practices and avoid the emergence of kind of monolithic communities of practice. Right. Like the NIH or the neuroimaging lab.
00:25:01.742 - 00:25:06.430, Speaker A: Like, you have to do it a certain way. So would you two think that's correct?
00:25:06.500 - 00:25:10.640, Speaker C: Perhaps, yeah, sorry, that's a boring answer, but yes.
00:25:11.490 - 00:25:45.260, Speaker B: No, I think there's a sprawling ecosystem. So the DSI movement has significant tailwind. There's a lot of people coming together, making a lot of projects, and it's going to be an interesting space to follow because at the end of the day we have to iterate around other solutions and see what sticks. We don't know what's going to stick at Priori, these are very complex systems, right? The whole infrastructure around knowledge production is very complex system. There's always this analogy of the elephant, that people are touching different parts of the elephant. Like this is a trunk. No, it's about the foot so everyone have.
00:25:45.260 - 00:26:11.074, Speaker B: There's this plurality of approach, and I think that term plurality here is probably more important than decentralization. Right. Having plural approach, we all agree that the pace of knowledge production today is not what it could be. There's no solution we can derive analytically to find a better model. We need to experiment, right? So experimentation is going to be the key. Yeah, that would be my take on that.
00:26:11.192 - 00:26:40.214, Speaker A: That's great. I wanted to. In the last 15 minutes or 14 minutes we have left, I wanted to make sure that we covered the full sort of space. Right. So decentralization is great, allows for greater cultural engagement, more diversity of thought and stuff like that. At what point do we need to start worrying about risks? Right? What happens when a particular culture becomes more entrenched and eats the others? Right? Or at what point does opening up and making permissionless systems introduce systemic risk?
00:26:40.342 - 00:27:24.886, Speaker B: So I think there's something that's interesting here about specifically web3 technologies, right? So what have we seen, for example, in the scientific publishing industry over the last 50 years, we've seen a trends towards consolidation, towards big players becoming bigger, stronger. More than 50% of the academic publishing market is controlled by just four entities. I would like to point out that these companies like LDV have the highest profit margin of. They have a profit margin that's higher than companies like Apple and Google. So just let that sink in for a moment. So these are mechanisms that have essentially prestige captured the entire community of scientists. And what we've seen now with the OSTP memo.
00:27:24.886 - 00:28:09.810, Speaker B: So the OSTP memo is essentially the White House mandating open access to papers, is that a lot of scientists are worried they're just going to get priced out of the publishing industry, because how much does it cost? So for those that don't know, scientists produce their work, they'll produce a paper. You write a paper, it takes you two years, you run your experiment. You spend so much time publishing this paper, you're ready to submit it. You submit it. The editor usually works for free, and he'll then coordinate the schlep around, finding peer reviewers that are competent to check your paper and to find flaws, improve it, and to essentially verify that it really kind of fits within the team of that specific journal. There's also computer science conferences. Communities have different ways of doing this, but essentially there's that stage.
00:28:09.810 - 00:28:43.390, Speaker B: And then what happens, what has happened for a very long time is the publisher will take and say, okay, thank you very much, everyone. Nobody gets paid out of this. And then they will sell that to libraries at exorbitant prices. This has been the subscription model. So that model has flipped around nowadays, and if you want to publish in a reputable OA journal, it'll run you anywhere from. Think about that for a moment. That is the price of having essentially your paper processed by a publishing house to get the peer review coordinated.
00:28:43.390 - 00:29:32.690, Speaker B: The paper typeset it and the brand of whatever journal ends up being on it. And that system is extremely exclusionary. And there's a lot of worries right now about what the future of open access publishing will look like, because we know that there's going to be distortions in those markets, right? So a lot of those pricing models are due to prestige. And when you think about it, scientific publisher should be competing for features, not prestige. And so there's all sorts of dysfunctions within that system that prevents it from being more equitable, more efficient. And it's not because it's impossible. There are academic communities out there that have so called plutinium open access, so they essentially do the verification process, the publication process, and there's no fee associated with that.
00:29:32.690 - 00:30:13.498, Speaker B: So it's not that it's impossible. So one of the ways we could also add value in decentralized science is create alternative platforms to essentially have the possibility to return value of curating the record to scientists. So you could think about that as systems where, imagine you had a button on the archive, right, where anyone could add a validation grant on a paper to get expedite peer review. How valuable would this have been when we had this, for example, this preprint on, I think it was med archive saying that there's HIV insertion in Covid. We've seen this. It went all like a trail of fire all over social media. And peer review is an extremely long and tedious process to coordinate.
00:30:13.498 - 00:30:24.910, Speaker B: How valuable would it be if we could have mechanisms that return the value of creating the scientific record to scientific societies that allow anyone to essentially interact with that record to make it more verifiable?
00:30:24.990 - 00:30:26.254, Speaker A: Yeah, absolutely, Chris.
00:30:26.302 - 00:30:27.300, Speaker B: No, definitely.
00:30:27.750 - 00:31:17.218, Speaker A: For some perspective, an open access fee for publishing in nature is going to run you anywhere between a third to a half of the salary for a graduate student, depending where you're at, up to like maybe 10% of a postdoc's salary. So that's insane to think about, right? That these four papers are worth one postdoc, whereas a postdoc might complete a study that dozens of papers are mined after they leave, perhaps. So we do have about nine minutes left, and I wanted to make sure that we engage with the audience and take your questions. But before we do that, in 1 minute or less, why should smart attendance of smartcon, perhaps chainlink engineers or infrastructure engineers in blockchain, why should they care about DSI? Would you like to start, Ben?
00:31:17.314 - 00:31:44.960, Speaker C: I mean, sure. If you buy into the premise that sort of like the scientific method, ecosystem knowledge production more broadly, is what has created basically all the abundance that we enjoy today, then if you care about humans and the world becoming just having more better things, then you should care about making the system better.
00:31:46.850 - 00:33:21.838, Speaker B: Yeah, I think in general there's an opportunity here because there's something about web3 which is about freedom, about open mindedness, about this idea of experimenting, about creating data structures that cannot be cut off, right? So this idea, when you do have information that's stored on chain or on ipfs or in these distributed system, there's not only immutability, but there's this idea of universal access, right? So that's an important part about the type of technology that underpins a lot of web3. Why should you care about it? Imagine we had ways to more efficiently produce quality knowledge and advances in, for example, cryptography, oracle research, distributed computing systems. If we could create systems that could empower these computer science communities, these groups, to essentially find better ways to coordinate, better ways to validate their research in a way that is incentive compatible, that would be beneficial to the entire space. Because web3 needs a lot of more of fundamental research, we rely on a small community of incredible cryptographers, incredible Zeke snark developers, people that are really at the forefront of these topics. And it's extremely valuable for us to be able to inject the right capital in those communities, to make our system scales, to find these breakthroughs that will make these dreams that are around blockchain, around more trustless societies a reality. Right? So that's why you should care.
00:33:22.004 - 00:34:17.274, Speaker A: So I'll add my two cent in there. I think that web3 should care about science and specifically distributed, decentralized science, because web3 is built on an ethos of openness. It's also, I would say that probably the core utility function of a smart contract compatible blockchain is consensus over knowledge or truth. I think about Sergey Nazarov, I think his first talk here at Smartcon, I think it was like 2019 or 2020, he talked about truth and linking off chain events that occur on chain. Well, what is that? That's the scientific method. So imagine if you had smart contracts that created interoperable, reusable, verifiable streams of knowledge production, right? And where you have the individual, the self sovereign individual at the heart of that, right? That's the dream.
00:34:17.322 - 00:35:25.650, Speaker B: And there's really a case to be made that science, just very much like DeFi, could be made much more composable. So if, rather than just publishing a know, we had systems to create interoperable research objects where you can have code, where you can expose a public API, where you can have data that systems that can be queried and compose and build upon each other, imagine, I don't know who's practicing scientists here, but imagine if you could essentially import the code and the data of a published paper as simply by using a citation, right. You could essentially create a scientific record that would be more composable, that would build more upon artifacts of high value. And we start seeing this in the machine learning community, in the transformer community. But there's a lot of scientific communities that have not yet fully embraced this incredibly accelerated potential that there is between sharing research artifacts, sharing data, sharing code, putting these quality research artifacts out there, and having mechanisms to accrue credit on these research artifacts so that scientists themselves are incentivized to do this extra work to create a more composable and buildable scientific record.
00:35:25.800 - 00:36:06.880, Speaker A: Absolutely. So that's our. Are there any questions? Oh, there's quite a few. I'm going to start with the back of the room first. Yeah. So the question is, for those that didn't hear it, how do we prevent, I guess, immutable dogma, right. How do we prevent bad actors from manipulating the system and perpetuating misinformation?
00:36:07.220 - 00:37:00.780, Speaker B: So the juxtaposition between consensus, what people believe, and what is the truth is a very interesting, it's a very interesting dilemma. Dilemma. There's these two forces that are intentioned. One of the ways we could do that. So one of the ways we're thinking about this is that imagine if, when there's published research that's put out there, imagine if, rather than having one set of peer reviewing experts that would go through the paper and say, well, this is valid, this is not valid. This is essentially heresy, right? In the case of Galilea, you've had that with the beta amyloid hypothesis. There was a whole phase during Alzheimer's research where if you were not postulating that that specific mechanism was causal to Alzheimer's disease, that it was very hard for you to get grants.
00:37:00.780 - 00:37:51.104, Speaker B: Right? And that's an illustration of this case of the Galileo trial. One way to do it is through plurality, right? Having plurality of funding mechanisms that have different models that don't follow, let's say one set of groupthink and standards. When you think about the scientific record and you think, let's say, of a piece of published research, one of the ways we're thinking about it is like, well, imagine if you could fork any paper, any type of research, right. You could fork it. You could create essentially a graph of people with particular opinions, particular takes on those, and have markers of reputation that are transparently communicated to the audience. And so they can start forming and building reputation around those and you can start comparing opinions of different experts group. Right.
00:37:51.104 - 00:38:36.400, Speaker B: And having that into the open is already a tremendous step forward. If we had all of the peer review reports of the people that were blocking others from getting grants, if you were not following that specific dogma, if that wasn't to the open, that would allow us to create track records of reputation, that would be very valuable in setting incentives to essentially counteract those types of gatekeeping behavior. Right. So to answer your question, I would say two things. One is plurality, having a plurality of funding landscapes and methods around science. And the other one is transparency in order to have reputable markers of reliability.
00:38:38.740 - 00:38:41.570, Speaker A: Okay, no more questions in the back. I'll take.
00:38:42.020 - 00:39:11.990, Speaker D: Sure, yeah, just in regarding the governance of those regulations, like upsetting that thoroughly of different sets of rules and it being reputation based, I like the idea, but judging and reputation based on those merits, how do you determine to help contribute to setting these policies?
00:39:12.330 - 00:39:13.842, Speaker A: Yeah, I think starting off, unless.
00:39:13.906 - 00:39:14.678, Speaker B: Ben, do you have.
00:39:14.764 - 00:39:29.520, Speaker C: Well, yeah, I don't know. So this is going to be a little bit heretical. But it's like, I think people in communities know right from the outside. Yeah, maybe you don't know, but if you just sort of like people know who the bad actors are.
00:39:29.890 - 00:39:51.500, Speaker D: Well, certainly, but again, the whole consensus thing, I mean sometimes you have a bunch of things, but the decentralized aspect of it means there has to be some type. I mean if it's truly fully decentralized, there has to be some type of somebody making those rules, whether it be somebody. How does that process, how does that come together?
00:39:51.650 - 00:40:38.350, Speaker A: I think you won't see something too far off from existing professional societies that have to self govern and figure out how do we store our data or what did standard should we use? If we take the maybe bad example from the w three c, I think what will end up happening is you'll see successful communities have their own methods that emerge because of the success of that community. Right. There'll be a self reinforcing loop. I think also just starting with the very basic replication, reproducibility and being able to verify those things as well as other components, like actually being a good mentor, because knowledge isn't really in the papers, it's in there. And that's why science is so hard to access. So we are out of time. I would love to take another question if they'd give us a little more time.
00:40:38.350 - 00:40:42.190, Speaker A: One more question. Okay, Josh, please.
00:40:43.060 - 00:40:45.360, Speaker D: The data lake.
00:40:51.770 - 00:41:00.420, Speaker B: When it comes to potentially be hacked, in that case.
00:41:01.610 - 00:41:17.320, Speaker D: But what about when it comes to summers? What if this innovating on themselves using information that then causes.
00:41:19.120 - 00:41:39.664, Speaker A: A bioterror attack like risks? So the question is one more time. If we put all the information out in a record, make it public, make it decentralized, immutable, you can't censor it, you can't take it back. What happens if somebody takes the COVID sequence and turns it into the Ebola Covid sequence, right. Do you guys have any takes on that?
00:41:39.782 - 00:42:18.030, Speaker C: I don't think this is really a. This is a broader question, right, of like, how do you keep people, like you make people more powerful, how do you keep them from destroying the world, right? And I think it's like some combination of building. It's like you have your Nick Bostrom, like white pills and black pills or black balls coming out of the urn. And what you want to do is grab the biggest handful you can. So hopefully the white balls like you build defensive technology as well as offensive technology. And then two, you trust that on net people are good.
00:42:21.360 - 00:43:07.820, Speaker B: It's a very hard problem. The question is always, who's a centralized sensor, right? Who decides what information should be available and what should not? I think this is really the point of contention. And I think there's two approaches to this. There's one saying we'll never fix that problem. So might as well make everything immutable in censorship resistance, right? There's obvious limitations to this, right. You can think of nuclear proliferation, right? So we can very easy find edge cases in which that model is not going to not realistic, it's too dangerous, right. But on the other side, it's like, well, what is the process by which we select what information would be erased permanently or just completely inaccessible, right? So here, having transparency in that governance process, I believe is going to be foundational.
00:43:07.820 - 00:43:34.896, Speaker B: So we need governance process that allow us to define guidelines and rules around these things. And at the end of the day, ideally we have systems in which you don't have just one centralized silo deciding what you can see, what you can't see, but you have this data lake, and you have a network of gateways. And if one element of this data lake is not something that should be out there, then it is simply not surfaced at the level of these gateways because they come to a consensus that information should not be accessible.
00:43:35.008 - 00:44:12.092, Speaker A: Yeah. A great science fiction kind of reference for this is the three body problem where humanity has to make a decision tree. So they're faced with an existential problem, and we need to coordinate all of the world's resources and talents and solar system resources and talent to figure out how to engineer ourselves out of this problem. And so there was a decision point that was made. The scientists wanted to go one way, and the state government wanted to go another way because it was safer. And what ended up happening was the use of force to censor the scientists decision to go the dangerous way. And it ended up actually working out against humanity's interests.
00:44:12.092 - 00:44:33.030, Speaker A: Not to give away the book, you should read it. I think it's useful to kind of think about long term horizon plays. Like, how are the systems that we're engineering? Do they set us up for failure as success in different boundary conditions and scenarios? But that's all the time we have today. I hope we've left you with some good things to think about, and thank you.

00:00:00.330 - 00:00:34.614, Speaker A: Welcome to Chainlink Research Reports, a YouTube series featuring research across web3 industry and academic fields with scholarship that expands our understanding of decentralized technologies. I'm Dr. Andy Boyan from Chainlink Labs. Today I'll be joined by Kelsey Nabin, a researcher from our MIT University in Melbourne. And our discussant is Dr. Jason Nastasopoulos, an assistant professor of public policy and statistics at the University of Georgia. Kelsey Nabin is presenting her paper titled is a Dao a panopticon algorithmic Governance as creating and mitigating vulnerabilities in decentralized autonomous organizations? A q a session with Dr.
00:00:34.614 - 00:01:07.250, Speaker A: Anastasopoulos will follow. This paper uses ethnographic and case study analysis of decision making and governance in DAOs that are working to decentralized organizational functions. Nabin highlights the potential differences and dangers of relying on algorithmic governance and then proposes that DAOs contemper authoritarian governance via algorithmically determined courses of action. She concludes that early DAOs demonstrate there are outcomes for autonomous systems to facilitate human autonomy, and that DAOs may be a valuable locust to explore that interplay. And now here's Kelsey Nabin.
00:01:13.830 - 00:02:49.710, Speaker B: Hi, my name is Kelsey Nabin and I am a researcher at the RMIT University in Melbourne, Australia. My research is connected to the center for Automated Decision making in Society, the Blockchain Innovation Hub, and the Digital Ethnography Research Centre. So today I'm joining Chainlink research podcast to speak about a working paper entitled is a Dao a panopticon algorithmic governance as creating and mitigating vulnerabilities in decentralized autonomous organizations. So this paper is really about resilience in Dows, and I'm specifically interested in the dynamics of threats and vulnerabilities. And so that's how I came to, I guess, further investigating the role of algorithms and what's happening inside and externally to dows in terms of the kind of emerging dynamics of how these sociotechnical systems are evolving and unfolding in practice in what is kind of referred to often in the academic literature and the blockchain space as kind of experiments. And so I want to start off with some fundamentals about dows and more in terms of a history lesson than kind of a definition. So what's specifically interesting about algorithms and dows is that there's a lot of literature, especially in the field of sociology, and kind of critical studies around algorithmic platforms.
00:02:49.710 - 00:04:16.954, Speaker B: So we know that in Web two, there's kind of general consensus that algorithmic platforms haven't gone well for the users because they're centralized because they can be kind of considered as exploitative. And there's these asymmetrical power relationships between the owners and controllers that set the rules that govern the algorithms, and thus the participants in those platforms and the users that may not necessarily understand how the platforms operate. And they have no control or agency over those rules in the system that they're participating in. So the difference with decentralized technologies is really about this ideology. So blockchains, as we know, bitcoin, the first kind of public decentralized, sort of fully functional blockchain and cryptocurrency system comes out of the cipher punks. So this very kind of countercultural political movement of the 1990s and kind of bled over into the early two thousand s, a lot of conversation and activity revolved around the cipherpunk mailing list, which was just this heterogeneous group of people, largely sort of computer hackers and software engineers and people that understood code. And these people believed in sort of self governance.
00:04:16.954 - 00:05:34.230, Speaker B: This idea of autonomy and political decentralization as the ability to govern yourselves and technology as a means to do that, as a means to take action and take kind of direct action and be able to write your own rules of the system and make that decentralized. So in such a way that it is a peer to peer participatory system and also one that cannot be changed where the rules are set and they can't be kind of tampered with for political control or kind of political perversion. So then we see the idea of dows emerge from these kind of cipherpunk origins. And Dan Larimer coined the term decentralized autonomous corporation. And then a couple of days later, Vitalik Buddha and the co founder of the Ethereum protocol, who at the time was writing for Bitcoin magazine, called it a decentralized autonomous organization. And he refers to some ideas about what this dao could be, and sort of leans heavily on the idea of automation. So using algorithms to commit or to conduct and execute sort of low level functions in this organization.
00:05:34.230 - 00:06:21.426, Speaker B: And then humans sort of have this role of higher order evaluation or judgment in these systems. And so it's building this picture and this goal in many ways of what a Dow could be and what a Dow as a system for collective self governance, where the individuals participating in that system get to write the rules, and those rules actually serve the participants. And so I actually have that on my blog on substac as well. If you want to read a bit more about that history. And I mentioned before the phrase sociotechnical systems. And I think that's really important when we're thinking about decentralized technologies. Often conversations about resilience begin with cybersecurity.
00:06:21.426 - 00:08:03.800, Speaker B: How do you defend a computational system or a software or hardware or a network? Whereas really, what I'm interested in as a sociologist and largely kind of adopting ethnographic methods, where I observe online forums and conduct interviews with people, is the social dynamics of these systems as well, and how people and technology interact. And so the question that I'm kind of asking in this paper is, what are the elements of these systems as they play out in practice that actually perhaps aren't going according to plan? Or in what ways are they perpetuating the panopticon, or this idea of corporate and governance surveillance that the cipher punks that sort of spurred this ideology of decentralization and autonomy were so counter to? And yet, when we see these decentralized algorithmic systems at play, there are elements of, really surveillance, some could argue. And so what I do in this paper is explore some of those things. So what's a threat to dows and what's actually emerging from within dows that could be seen as a threat to participants in them? Because at the end of the day, we're looking at the social and the technical elements. And so just a little more on that. The panopticon is this sort of philosophical or thought exercise by a guy called Bentham. And it's the idea that there's people in a prison and a watchtower in the center.
00:08:03.800 - 00:09:03.610, Speaker B: And the watchtower can see all aspects of the prison, but no one in the prison can actually see into the watchtower. And so the prisoners never know if there's someone in the Watchtower watching them or not. But because they assume that they could be being surveilled, they behave accordingly. And Bentham kind of extends this thought exercise to say, well, the extension of this is that people actually start to surveil one another. So people know that someone could be watching, and then they start watching their neighbor and would dob on them or whatever. And then the final extension of the panopticon is that people govern themselves. So with the uncertainty about whether you're being watched or not, you actually sort of adjust your own behavior anyway, even though the watchtower could be empty.
00:09:03.610 - 00:10:19.150, Speaker B: So how that translates to algorithmic systems is the idea of algorithms as kind of participants in governance. And still in decentralized systems, there's aspects where it's unclear that algorithms are at play. And so I want to go into some of those circumstances that I discuss as case studies in the paper and kind of share a little bit more on what I found. And so I mentioned there's algorithms at play, and some really interesting examples of this are around civil attacks. So that's kind of an external threat to a dow. So where people kind of create multiple online identities to kind of overrun or game the system for kind of selfish interest, which isn't in line with the sort of spirit or rules of the game as well as reputation. And so how this paper actually emerged was because I was on a forum which I sort of regularly participate in, in a decentralized technology community, and I got a little notification that my trust score had been increased.
00:10:19.150 - 00:11:24.498, Speaker B: And I thought that was really curious. I wasn't aware that my time on that forum was being monitored or the number of likes I do, the number of comments I make, or the number of posts that I read. And so what happens in dows is that scale is a massive factor in this at the micro level. So micro dows, and there are a lot of social ones around social tokens or kind of special interest groups, they're at the scale where people kind of know each other. So even if it's a pseudonym, but by reputation, if someone says they'll do something and they repeatedly don't do it, everyone kind of knows, oh, that person isn't very reputable or reliable. But as dows scale, or sometimes when they exit to Dao, which is a term that I coin in one of my blog posts, so a large community will exit to dao and decide to be collectively governed from the origins of a project. Then suddenly they have scale.
00:11:24.498 - 00:12:42.014, Speaker B: And what you have is owners that are token holders and participants that are oftentimes kind of the labor in the organization and in some cases volunteers as well. And I've really seen this emerging theme around labor in dows, where it's unclear and it differs across different dows, how this volunteer labor should be rewarded. Should they be paid employees? And in some dows, they are like DXDao has it published on their website. According to experience level, people are rewarded, or in some they're volunteers. And is it because they're vision aligned? Is it because they get kind of bonuses like swag or other kind of upsides, or because there's potential sort of to get token drops or those sorts of things. But with these larger cohorts and these kind of dows that scale to hundreds or even thousands of participants, labor needs to be monitored still and made accountable to know who's doing what in the dow, and to make sure they're rewarded in some way to continue participating. And so this is where the algorithms come in to monitor that.
00:12:42.014 - 00:13:42.020, Speaker B: And there's a number of systems in dows that rely on algorithms, such as source, cred, coordinate, and a number of others, such as the forum monitoring that I mentioned. And so that's where it gets really interesting. And so that's sort of one side where algorithms are operating, and it sort of becomes questionable about to what level are people being surveilled? And I guess the politics of DAos really lean on Hirschman's idea of exit, choice and loyalty. So if you don't like the rules of the DAO that you're participating in, then you can exit. So you're not ever sort of stopped from exiting. But I think there is a point here that there is a cost to exit. So if you hold tokens in this dow, if you have reputation, if you have experience and you want to port that to somewhere else, there's still quite a large cost.
00:13:42.020 - 00:14:36.090, Speaker B: And so another example I go into in the case studies in this paper is around civil attacks. And I was actually quite involved in observing gitcoin in its process from transitioning from a project which does crowdfunding. So they say that their mission is around funding public goods in and beyond the Ethereum blockchain ecosystem. And as they transition to a DAO, one sort of great threat to that DAO is civil attacks. So they use a function called quadratic funding, which was initiated by Vitalik Buterin and Glenn Whale. And that's where there are pools of matched grant funds. And rather than the person that gets the most donations, then also getting the most match funds.
00:14:36.090 - 00:15:28.018, Speaker B: An algorithm determines the amount of match funds based on community interest in a certain project. So if you get lots and lots of very small grants, you can actually pull quite a proportion of a pool of matched funds. And so obviously that incentivizes certain behavior and is inherently vulnerable to civil attacks, because if you can create multiple fake identities to give micro amounts to a specific grant, it will get a higher matching round of funds. Furthermore, there was certain behaviors that played out in this system that weren't predicted. So in one round, which was grants round nine, some projects decided to give surprise airdrops to people that had donated to them. So it's all the activities on chain. They could see those addresses and thank them with some tokens.
00:15:28.018 - 00:16:54.130, Speaker B: But then what that meant is people wanted to donate to every single grant available in case there was retroactive airdrops again. And so the rules of the system, again, kind of didn't align necessarily to the behaviors that were acted out, which is how it's so helpful and interesting to do observational research in these cases. And so what happened with the civil attacks, kind of in flight of this grant round, was that a machine learning pipeline was developed, and I was fortunate enough to be able to be inside and observing block science, which was the consulting firm engaged to help design and develop and implement this machine learning pipeline. And what's most interesting about this kind of algorithmic introduction was how the rules of that were really kind of a policy making process. And this kind of brings me to what I hope we can discuss further in question time around changing the rules of the algorithm. So I'm just kind of touching on a bunch of cases that you can read in the paper. But the third kind of case I discuss is what is called praisemageddon, or this praise debate in the common stack and token engineering commons community.
00:16:54.130 - 00:18:02.402, Speaker B: And again, thank you to them for allowing me to research alongside them and observe in that community. But what happened was this kind of heated discussion around changing the rules of an algorithm when some people believe that it no longer serves the best interests of the participants in that community. And so multiple times in communities that I've observed it. And dows, there's this real hesitancy because of those cipherpunk origins, where immutability of the protocol is seen as kind of absolutely necessary and desirable. It's really difficult, then, in these institutional governance settings, where there has to be rules kind of adapted and evolving as behaviors and circumstances change. But that becomes kind of at the level of a constitutional change for some, perhaps minor amendments. So learning to govern is the ongoing experiment of these communities.
00:18:02.402 - 00:19:16.090, Speaker B: And although it is kind of experimental and oftentimes very playful, it's also quite a high stakes game. And I think there's no doubt that these are human machine ensembles that I say in the paper are kind of co constitutive. So the algorithms that are part of the governance picture here are also shaping people as they're being shaped by people. And in terms of resilience, there's not only these exogenous attacks, so these external people creating multiple sort of identities and conducting sort of civil activity, but also these endogenous things emerging in terms of how the rules of the system are created, governed, implemented, and then how they're interacted with. So a potential threat to dows is really themselves as they're inherently and always going to be social systems. And so how people decide to coordinate in that interplay between community and algorithm is actually really important to resolve challenges as they arise. And really, that definition of resilience, there is kind of adaptability and transformability.
00:19:16.090 - 00:19:47.474, Speaker B: And I argue that in so many ways, it's the people that are going to be able to adapt and transform and evolve along with the system. And that's really what resilience is in these cases. And so I'll pause there. I would love to continue to discuss this with further questions. And thank you for listening. I hope you can read the paper. Many of these ideas are referenced on my blog and in other working papers as well.
00:19:47.474 - 00:19:48.460, Speaker B: So thank you.
00:19:50.030 - 00:20:27.270, Speaker C: Thanks so much, Kelsey, for this great presentation and a fascinating paper, which raises a lot of questions, a lot of very important questions about DAos. And so I have some big questions myself about DAos that I hope you can answer, and I'm looking forward to your responses. So the first question I have is a very big question that your paper tries to address, and that is, do you think that DAOs can actually avoid becoming a panopticon while maintaining important aspects like reputation systems?
00:20:28.970 - 00:22:00.020, Speaker B: That's a fantastic question, Jason. I think they absolutely can. I mean, really, the challenge that I wanted to throw out there was to the decentralized technology community to actually critically reflect on their own system. So I'm not interested in saying kind of dows don't work or decentralization doesn't work, but kind of asking people to think a little bit more deeply around these systems. And one kind of working hypothesis I have on this is really sort of borrowed from the co op space. So the response to sort of the idea of surveillance capitalism or platform surveillance by some scholars, is to advocate for platform cooperatism and co ops are this long standing way of community organizing in that people that labor in the organization are the people that own it and govern it. And I think what's happened in dows that has kind of been really subtle shift is that there's these token holders that own it, but then there's still this labor, which is, in many cases, volunteering in it because they believe in it or for whatever reason they're interested or they do get rewards or whatever.
00:22:00.020 - 00:23:01.750, Speaker B: But actually, it's a participatory system in that it's permissionless and anyone can access it. But it's not a participatory system in that everyone in it also owns it and governs it. And I think the people that initiate dows really have to reflect on that and reflect on the way that tokens are distributed and who is actually doing the work of the Dow. And the way I like to think about that work is that it's infrastructure. So I refer to it as digital infrastructure in a lot of my work. So there's going to be ongoing maintenance. And I don't think it's a case where the initiators of a dow or token holders that are governing, or people that are doing the coding, the auditing, the managing the machine learning pipelines, or the marketing can kind of think of as a short term game.
00:23:01.750 - 00:23:28.910, Speaker B: I think infrastructure is a very long term gain. And so I hope that kind of, that provocation really helps people steer away from the panopticon, where someone decides the rules of the system, and they're heavily enforced, using all means necessary to monitor the participants and more towards this really productive relationship between sort of participants and the rules.
00:23:30.050 - 00:23:43.410, Speaker C: Thank you. Related to that response and related to infrastructure. Do you think that infrastructure is the reason that dows tend to fail? Or is there perhaps another reason or reasons?
00:23:46.170 - 00:25:02.830, Speaker B: I argue in the paper that the predominant threat to dows is themselves. And while there are some external threats and the ones that are commonly talked about by kind of especially kind of major blockchain protocol founders, are civil attacks and collusion. As in collusion kind of originally referred to mostly sort of 51% attacks where miners would collude and break the consensus protocol. But people in dows are participating in governance. So it's really analogous to organizations in so many ways. But oftentimes people may not have had the organization experience to know kind of how to necessarily govern these things that are fully functioning with massive treasuries to make decisions on grants, programs, like I said, onboarding, labor, communications, community management. And so what I'm really interested in, in the paper is how people solve disputes when they arise.
00:25:02.830 - 00:26:06.740, Speaker B: And although it's a completely fuzzy concept, and I know that some blockchain people won't endorse it as the solution, but I argue that culture is a massive part of that. And what dows are doing today, and a number of kind of successful, as in continuing to adapt and function ones, are initiating the rules of the community based on a constitution. So there's this idea that we don't know everything, we can't determine all of the rules now, but what we can say is, like, we believe in these values, and in cases where something needs to be arbitrated internally and externally, this is how we will do it, using a decentralized court, or according to these principles, or whatever. And so what that actually allows the community to do is to then refer back to those principles, even if it's an unprecedented situation that needs to be resolved. And that was exactly what happened in the praise debate that I explore in the paper.
00:26:09.350 - 00:26:30.380, Speaker C: Thank you. So related to this idea of having a constitution within dows, how does that relate to something that you mentioned in the paper, which is that algorithmic governance itself is subjective? Curious to your thoughts on that.
00:26:30.910 - 00:28:01.186, Speaker B: Yeah, so I guess there's a substantial body of literature in the sociological space that's quite critical of algorithms and the idea that once code exists, it can't be argued with. And we're seeing real world cases now where decisions made by automated decision making systems, which are embedded in large institutional processes and government processes and all these things are actually standing up in court as a decision made by the algorithmic system. Whereas from everything I've researched and studied and observed, these algorithms are based on selective bias. So the rules are encoded based on someone's subjective beliefs and worldview or their ontology. And also machine learning systems, as an example, are trained based on data, so they're trained and optimized, but someone has to pick what data set that is based on and know work on that process to optimize it. And so I actually have a piece on my blog called algorithmic policy making, which I co wrote with Dr. Michael Zagham, and that talks about this kind of ontological and subjective bias of the people that encode algorithmic systems.
00:28:01.186 - 00:29:05.610, Speaker B: And also sort of is a bit of a call to action about taking responsibility for reflecting on one's own position and intention in creating infrastructural systems that then have implications for others. And what's really nice about that is it transitions it from a computer engineering activity within a function somewhere in a system to a policy making process. And so if you're going to make policy, you need to think about who are your constituents, what are their interests? How am I going to create the settings of this policy? How is it going to be adjusted over time and all these things? And it kind of takes it out of this black box or this kind of immutable position and really kind of brings it into the political sphere, which is a totally different game in terms of what people are engaging in creating and participating in these kinds of decentralized constructs.
00:29:06.750 - 00:29:38.920, Speaker C: So related to this idea of subjectivity in machine learning is also a problem that we see often regarding bias in machine learning. Particularly, some of the more popular examples are racial and gender bias. Since dows according to your paper, tend to use machine learning systems often, especially for things like reputation. Do you believe that these kinds of biases may carry over into dows? And if so, how do you think they might do so?
00:29:41.290 - 00:31:02.074, Speaker B: Yeah, I guess it's definitely very case specific, and I am hopeful from some of the things that I see and concerned by others. So sort of in passing in the paper I mentioned these play to earn games, and they've received a lot of attention and excitement. And there's been very genuine kind of on the ground feedback from entire countries in the global south, like the Philippines, where villages of people are playing these games and they're able to earn a living wage in tough times like COVID, which know really revolutionary in many senses. But also these kinds of sites are known as places of that algorithmic exploitation, which Kate Crawford calls it in Atlas of AI. And people's time playing the game is rewarded, but then it's also penalized. So if people step away for family commitments or medical needs, or to interact and engage with community and other commitments, they're no longer being rewarded or they're being penalized by the algorithms. And we've seen that in taxi apps.
00:31:02.074 - 00:32:48.978, Speaker B: For example, Sunava Sandbook does a great study in Indonesia on taxis and transport apps. And so that's kind of my concern, is that people get so excited around, like, this decentralized game is working and people are battling cute critters and earning really, you know, at the same time, there's still quite a heavy hierarchy about who benefits from that system. And there's people in the US that are recruiting teams of workers, really to work for them, to get NFTs in that game. In the other sense, I'm really excited by what I see in the consideration that some of these projects are giving to the design of their algorithm. And so they're considering this governance as how they structure the possible kind of activities for people. So Foucault refers to governance as structuring the field of play, which is a definition that myself and some other researchers in the metagov community often use. So when people are really considering deeply, all right, how do I structure this field of governance and what needs to be included in that, for it to actually sort of serve the interests of the community and for it to be able to direct the system without undermining those participants? I think that's really interesting.
00:32:48.978 - 00:32:56.440, Speaker B: And a number of communities have done quite deep work on that, and they don't kind of consider themselves finished, I guess.
00:32:57.690 - 00:33:22.880, Speaker C: Yeah. This idea of exploitation and algorithmic governance. I'm sorry, in Dows is actually particularly interesting. Do you feel that algorithmic governance can potentially solve these issues of exploitation, or is there another means through which they might be solved? Because we know that this is certainly a problem in online labor markets as well.
00:33:25.490 - 00:34:33.346, Speaker B: It's really interesting in Dows because there's such sort of technological determinism in these communities. Like, people are really excited about the possibilities of technology, and technology is the means to achieve social and political goals. And so, referring back to the kind of historical piece that I gave at the start of this presentation, which is another piece on my blogs called experiments in algorithmic governance. Continue. What the early ideas around dows were, was kind of fully automated systems leading to autonomy. And I emphasize that there is a difference between automation and autonomy. And so people were really optimistic about kind of AI agents conducting a whole lot of activities in these, and being laborers in these organizations, and automated ones at that.
00:34:33.346 - 00:35:34.194, Speaker B: So the idea is that eventually you can put AI agents or run algorithms on the blockchain so they're decentralized and can't be tampered with and all these things. And then they'll actually be going around. They can send their cryptocurrencies to one another to commit work, and they can subcontract certain parts of a job that they win to another algorithm to then conduct it. But really, from watching machine learning processes in action, there always needs to be that human oversight. So what I really loved about the machine learning process that was put in place for the Gitcoin civil detection was that it was conducted as a policy making process. And I was really fortunate to be kind of engaged in that and help kind of co write some of the blog that shared that with the broader community. It's called deterring adversarial behavior at scale.
00:35:34.194 - 00:36:48.798, Speaker B: It's on the block science medium. And that had a four step process, which was define the rules of the system that you want detect. So that's the algorithmic part where the algorithm detects, oh, like, flag this actor, they might be civil, and then evaluate, which, again, is a human process. So then people have to go in and evaluate what's actually happening here. Was that a mistake, or was the algorithm accurate? And then sanction? And they used Ostrom's commons principles, which, again, human process determine what's an appropriate sanction. Was it a first time actor with a kind of minor offense to the system? Or it's like, is this someone at scale, really heavily throwing resources at exploitation that needs to be in some way kind of banned or whatever. So that was just a fascinating process of how this was approached in terms of whether algorithms can and can't solve it.
00:36:48.798 - 00:37:08.100, Speaker B: And I guess it's that spectrum of where the algorithm stops and people are needed and that kind of ongoing interplay. And I'm really happy to talk more about that process in terms of how they tried to then decentralize the operation of that ML pipeline. But I'll leave it to you for the question.
00:37:08.790 - 00:37:44.286, Speaker C: Well, yeah, I'd like to let you go. You've spent quite a bit of time with us here, and we really appreciate your presentation and the fascinating work that you're doing. We hope to extend this conversation, perhaps through a post on the smart contract research forum, but that's something we'll talk about a little bit later. So thank you very much for your time, Kelsey, and for your fascinating work and for answering our questions here on Chainlink research reports. And thank you again.
00:37:44.388 - 00:37:50.180, Speaker A: Before you go, Kelsey, where can people follow you to find more of your work and make sure they stay up to date with you online?
00:37:51.430 - 00:38:23.034, Speaker B: Yeah, absolutely. So the best place would be to subscribe to my substac. It's under Kelsey Nabin. And then I generally, even if it's a working paper or something that's published elsewhere, I'll generally try and ping people on there. I also do okay at Twitter, where it's at. And, yeah, I would love any kind of constructive engagement on these ideas or more sort of case study examples of what comes to mind.
00:38:23.232 - 00:38:44.510, Speaker A: Fantastic. Thank you both so much for your time. I'll take it from here and sign off. I appreciate everyone for being here today. Thank you for joining us on chain link research reports. Be sure to like and subscribe to the chain link, official YouTube channel right down there. You can find links out to Kelsey Navin's paper down in the description, as well as well as a number of other resources for chain link research and web3 related research.
00:38:44.510 - 00:38:49.410, Speaker A: Again. Again, thank you for your time today, and join us next time for even more chainlink research reports.

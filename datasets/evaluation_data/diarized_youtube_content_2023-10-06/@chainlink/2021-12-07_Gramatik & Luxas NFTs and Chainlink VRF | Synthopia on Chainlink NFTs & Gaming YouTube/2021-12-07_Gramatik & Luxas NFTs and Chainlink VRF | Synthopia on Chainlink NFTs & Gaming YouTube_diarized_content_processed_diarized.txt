00:00:06.320 - 00:00:28.396, Speaker A: Welcome to Chainlink Live. We are live. Hey everybody, my name is Andy Boyan from Chainlink Labs. I'm here with a variety of musician avatars around me that we're going to talk a lot about synthopia today. We're going to talk about EDM, we're going to talk about music and chainlink Vrf and how these things come together. Awesome to have you all here. Let's go around the horn a little bit.
00:00:28.396 - 00:00:30.350, Speaker A: Lucas, how are you doing today?
00:00:30.960 - 00:00:46.208, Speaker B: Everything's great. Really excited to present and finally show the people I've been working on for all these months. It was quite nice journey and was a very nice collaboration and can't wait for everybody to see what's up.
00:00:46.374 - 00:01:09.320, Speaker A: I'm really excited. I've been super lucky. I talk to projects who are doing NFT plays and defi and all the time. And so a few months ago NFTs start coming out and now it's a bunch of projects who are a little more complicated. Projects sometimes are coming out to fruition and releasing stuff and so I got to talk to some pretty amazing projects like this one as well. Grammatic, how are you doing, man?
00:01:09.470 - 00:01:11.624, Speaker C: Doing great, thank you. How are you?
00:01:11.822 - 00:01:19.960, Speaker A: I'm great. Love talking to you guys. I've been a grammatic fan for a few years. I was on turntable Fn. Do you guys remember that?
00:01:20.030 - 00:01:21.450, Speaker C: Oh, yeah, I do remember.
00:01:22.060 - 00:01:31.536, Speaker A: And there was a ton of great lo fi there and so that's kind of where I got exposed to you and your music and so it's awesome to meet you and learn more about what you guys have been building.
00:01:31.718 - 00:01:50.244, Speaker C: Thanks, man. I appreciate it. We're stoked to be here. It's been a really busy day trying to make sure that we sync everything that's going on with code claiming and this Ama. So we're definitely high energy around here.
00:01:50.442 - 00:01:53.892, Speaker A: Good. Get your mountain dew in you and keep going.
00:01:54.026 - 00:01:56.724, Speaker C: It's three coffees so far.
00:01:56.922 - 00:02:03.096, Speaker A: I got my tea right. Oh, I love this. I can be like a hardcore tech bro, but I've got a fancy ladies tea set.
00:02:03.198 - 00:02:04.792, Speaker C: Oh, nice. I love it.
00:02:04.846 - 00:02:06.216, Speaker A: But it's Christmas time.
00:02:06.398 - 00:02:07.690, Speaker C: Yeah, it's perfect.
00:02:08.220 - 00:02:12.860, Speaker A: Nft boy. How are you doing? Where are you from? How you feeling today?
00:02:13.010 - 00:02:35.730, Speaker D: Hey, yeah, feeling good, man. I'm based out of northern California. Kind of crazy morning with the code claiming we just released the whitelist code claiming in our discord server. So that's fun. Things happen at the last minute even though worked yesterday. But it's so far so good.
00:02:37.560 - 00:03:01.164, Speaker A: It never goes perfect and if it does, you should be really suspicious. So that's, you know, people with questions. If people have questions, that's good. That means they're engaged and we're seeing more people enter here. Hi, everybody. My name is Andy Boyne from Chain Link Labs and we're starting our conversation with fellows from synthopia launching. Hopefully you're coming from their discord as well to see that.
00:03:01.164 - 00:03:06.732, Speaker A: I don't know how to say your name. I forgot. What is it? Tr six. Six?
00:03:06.866 - 00:03:28.948, Speaker E: Yeah, tr six. Hey, thanks for having us on. It's great to be here and exciting morning and it's nice to see you all like Lucas and grammatic and sort of, we did a bunch of in person collaboration early on and then we've kind of been getting last minute things done and talking on discord, but nice to be here in person today.
00:03:29.114 - 00:03:40.136, Speaker A: Oh, cool. So we get like a meeting of the minds as the release is happening. You guys collaborate and then you work and then you kind of come together at the end. This is kind of like a little summary space. That's kind of cool.
00:03:40.238 - 00:03:42.200, Speaker C: Yeah, it's awesome. Thanks for that.
00:03:42.350 - 00:04:03.820, Speaker A: Hey, I do what I can anytime to the audience watching. Welcome. We're going to get started here asking a lot more about the project. If you have questions, feel free to drop those in the comments. We will get to them as we can. We're going to get started here on Chain link live. Welcome to Chainlink Live.
00:04:03.820 - 00:04:31.130, Speaker A: My name is Andy Boyen with Chainlink Labs and I'm here talking to the synthopia project, Tr six six six. NFT boy, grammatic and Lucas, you guys have been working with your whitelist codes in your discord today. Congratulations on that. But let's get into a little bit about details about the project. Why don't you start? What do the synthopia NFTs really bring to the fans of music, to people who want to get involved with the music in some way? How do they stand out?
00:04:35.740 - 00:04:37.130, Speaker B: Who wants to go?
00:04:39.840 - 00:04:42.876, Speaker A: I can pick somebody. I'll use a randomizer. Ready?
00:04:43.058 - 00:04:43.836, Speaker C: Yeah.
00:04:44.018 - 00:04:46.108, Speaker A: Grammatic, you're off mute. Go ahead.
00:04:46.274 - 00:06:09.640, Speaker C: All right. Yeah. So Syntopia is very unique project and something that I'm personally really excited about because to the best of my knowledge, this has never been done before this extent and mainly because of the groundbreaking Dow, which is a digital audio workstation that NFT boy and TR six have built, that it's really mind blowing. It works inside browser and it works as a digital version of a modular synthesizer. And for people in the audio engineering community, and the music production community know what a modular synthesizer is and how difficult it is to actually make a simulation, and much less simulation that works in the browser. Basically what we were able to do by using their DAW, we produced a song all completely in the browser. And because it works as a modular synth and has oscillators and stuff like that, we were able to truly make a generative music project by being able to randomize parameters on every node that represents a stem.
00:06:09.640 - 00:06:47.780, Speaker C: Every node within the song represents a stem, like a musical stem in the song. And we have incredible, unprecedented options to randomize parameters and set ranges so that the results are musical, so that the merging doesn't result in some dissonant, unpleasant musical way. Because when you do that with JPEGs, you can do that all day. And even if results are weird, it's not going to be unpleasant the way it is when you listen to musical stems put together in a weird way, that dissonant and out of tune.
00:06:49.000 - 00:07:22.972, Speaker A: This is what's mind blowing to me, and I can't wait to get into this. If I look at your board, ape, right? If we took that and randomized the pixels, it would not show up as, like, a coherent project. It might be cool, it might be an artistic representation, like what I got back here, right? It's just a thing. But to have it come out as an actual piece of art is just mind blowing. But because of the mathematics of music and the way that it's built, they are randomized, yet they still are configurable. They're Legos and they fit together. And this is why this project is another level.
00:07:22.972 - 00:07:36.608, Speaker A: And I love it because I wondered about that in the past. How do you make this? It's going to be dissonant now, for the record, I'm a metalhead. I love dissonant music. I'm all about it. But the way you guys are approaching this is really exciting.
00:07:36.704 - 00:07:48.964, Speaker C: Yeah, that's what I said. Like, unpleasant dissonance. Because dissonance can be really cool, like jazz. It's all about cool dissonance. Dissonance. That's actually pleasant to listen to. But there's such a thing as unpleasant dissonance.
00:07:48.964 - 00:08:40.650, Speaker C: And that's what we were trying to avoid and to make sure that whatever the result is, it's still musical and it's within the parameters of music theory. So the fact that we were able to do that, it's the only reason, is because the way this doll works, and it wouldn't be possible otherwise, you can make kind of generative music nfts by merging stems, which you're already baked in audio. You can make a song in Ableton, for example, and export stems in audio and then try to merge those in different ways, but you're very limited because once it's baked in audio, it decimates the possibilities of randomization and manipulation of individual stems in the song. And that's why I think this is one of a kind and it's never been done before because this kind of DaW hasn't existed before.
00:08:41.820 - 00:08:55.676, Speaker A: NFT. Boy, can you talk a little bit about the nfts themselves? What do they represent? They're a digital asset. It's like a blockchain digital asset, non fungible. But what does it represent? What is it attached to in the DA or in the track?
00:08:55.858 - 00:09:49.180, Speaker D: Yeah, definitely. So we're using on chain data as the seed for everything else. That includes the randomization for the parameters that grammatic was talking about and also the randomization for the visual that you'll see once we reveal the. So that's where we're starting. And we have a method to add any libraries that are required to play the music in browser to the smart contract itself. So all this stuff will be on chain and you'll be able to create it. Say we all go away, all the data is going to be there for you to recreate this audio directly in your browser.
00:09:49.180 - 00:10:14.724, Speaker D: And that's kind of the really bleeding edge part, is that this audio is synthesized locally in the browser, right? So we can have an arbitrarily large amount of NFTs and the storage amount for all that audio is like a couple of megabytes, whereas that's just impossible before this technology.
00:10:14.922 - 00:10:32.460, Speaker A: So you don't have to host a wave file on the blockchain, but rather there's nfts. The blockchain already has, they're token standards, and when audioglyphs looks at the NFTs, it combines them and then it produces the music in the browser.
00:10:33.920 - 00:10:43.820, Speaker D: Yeah, kind of. So there's a seed which is associated with the NFT, and then the in browser libraries use that seed to create the audio.
00:10:43.900 - 00:11:26.830, Speaker A: Okay, cool. But that's cool, right? So there's on chain digital stamps of property of essences, these seeds that are just out there and they're there, they're hosted on chain and other places, but then locally right off chain things are produced. So you get this musical sound, but that at last, that's a really fascinating sort of angle on this. Can you guys talk a little bit about NFT? Boy and TR six six about the DAW about audio glyphs. Where did this come from? Why is browser audio workstations particularly useful right now? And is there a tie in with metaverse plays that you guys are thinking about with this?
00:11:27.200 - 00:12:25.500, Speaker E: Yeah, definitely. Putting the audio creation software in the browser is almost a strange fit. You really care about performance when you're making music. You're going to be using a lot of intensive effects and things like that. But what drives the need to put it in the browser is this idea of local synthesis, where we ship you the program that creates the music, and then you run that program on your own computer and it creates the music. And so that's really cool because it allows something like these NFTs where we can put things on chain, and from the program being on chain and from seeds on chain, you can sort of create these infinite variations where it would be like terabytes of audio files if we want to render 10,000 fully rendered songs. Also, you have all these options, like with local synthesis, you can have inputs from your own computer.
00:12:25.500 - 00:13:10.830, Speaker E: So we could ship one where you can play the keyboard along with it, or we could ship one where it reacts to a really slow cycle over years, or other inputs from your phone, like the weather locally or something like that. Right? So it has these other possibilities. And the other thing is, it can sort of have an infinite duration. So with the synthopia audio, we've made these generative song structures. So it really will sound like a song with new voices coming in and leaving and some build ups and things like that, but the structure will loop. And there are these other aspects of the modulation that aren't in line completely with the structure. So if you listen to it, the second repeat won't be exactly the same as the first and the third won't be the same as the second.
00:13:10.830 - 00:13:15.052, Speaker E: And that's something that's not possible with the traditional audio format.
00:13:15.116 - 00:13:15.730, Speaker A: So.
00:13:17.860 - 00:14:12.640, Speaker E: We'Ve called this the new audio format for the metaverse. And I think the idea is, as people's experiences of using the Internet, using computers, changes to be something that's more immersive, the way that we listen to music, can do that too, where instead of maybe just getting a song and it's the same song for everyone and you hear it, it's like you can buy an NFT and it's your unique version that can go on forever, that can react to what you're doing in the metaverse. And so the possibilities for what that means, I think, are not even figured out yet. But something like this format gives you so much more flexibility to make that happen. One thing that works really well with the metaverse is you can have three audio in this local synthesis format, right? So that as you move around in the metaverse, you can hear different things as if you're at a live concert. You could never do that with an audio file.
00:14:14.100 - 00:14:50.412, Speaker A: When I think about metaverse, I think about gaming and soundtracks and in a movie soundtrack, when something exciting happens, music pumps up. That's all curated. And if I had somebody follow me around curating my soundtrack in my head, that would be cool, but it's totally inefficient. However, if there is an adaptive track that updates based on weather or social situations nearby or whatever, engaging in activities in a virtual space, that's what this feels like. It feels like, oh well, things are updating based on on chain information or off chain information. That might be the start of that sort of thing. I could just be going crazy now.
00:14:50.466 - 00:14:59.840, Speaker D: On this, but that's very well said. A good way to put it. That's exactly what this enables, like music that responds to anything you want it to respond to.
00:14:59.990 - 00:15:26.970, Speaker A: God, that's a weird and wild idea. I love it, you guys. One question about the audio glyphs. The doB, before we move on is being in a browser. Does it change the performance? Like, can I run it on a lesser computer? Do I still need a pretty beefy machine? Or does that change that at all? Does it let other people with kind of sub top of the line machines come in?
00:15:27.980 - 00:16:17.864, Speaker E: There's some performance costs. We've done a lot to push the limits as far as we can for performance. So there's some things where we've written things in native code and compiled something called webassembly that lets you run near native code with almost the same performance that you'd get outside of the browser. But with grammatic and Lucas really pushed the boundaries of what the doc can do. So it won't play back on some people's phones and we're going to render audio files anyways for those people. But the local synthesis format will be on chain, and then as computers get better, it's going to play on your headphones or whatever. And the other thing is, if you have it, you can use the local synthesis format even if your computer wasn't strong enough to play it.
00:16:17.864 - 00:16:46.340, Speaker E: And it'll play on anyone's computer, but just like an older iPhone or something might not be able to do it live, but you can render it locally, not in real time and download an audio file and you can control how long you want that to be. And you can download the individual tracks so you can remix them yourself or anything like that. So even if your computer isn't quite strong enough to handle the local synthesis, you can still get the audio and interact with it.
00:16:46.410 - 00:17:09.132, Speaker A: And I can use it as a, like, it's in browser Daw. So I could make my own creations as. Okay, cool. So for the audio files and heads out there trying to figure out how they're going to use this, just wanted to make sure people have access. We're going to have links to all this stuff down below in the description too. So if you're watching, if you're just joining us, my name is Andy Boyen. I'm here talking to you since team.
00:17:09.132 - 00:17:48.448, Speaker A: Although each of you has pronounced synthopia slightly differently, I've noticed Tru said xynthopia, Grammatic said synthopia. So like whatever it is, maybe it's just up to our interpretation. That's okay. But one of the cool things we talked about earlier is and how you guys are using Chainlink. So. Hi, this is Chainlink, official YouTube, and Chainlink is being used in synthopia for Chainlink VRf, which is an on chain randomizer to randomize where these stems are going to make these unique creations of music. So how do you do it? What is the magic? Lucas, we haven't heard from you yet, so maybe we'll start with you musically.
00:17:48.448 - 00:17:55.560, Speaker A: How do you get a random assembly of stems and pieces of a song and actually have them come out in a musical manner?
00:17:55.900 - 00:18:52.910, Speaker B: So, yeah, first of already, as grammatic already said and all the guys. So we're working with the core from the oscillators. So that allows us to manipulate the sound without degrading it. If we were using samples, then applying pitch shifting or time stretching, that would all apply some. I mean, even if the algorithms are already good, there's still some distortion happening, right? It's adding or taking off bits. And since we can do that, then when we have the values, we spent a lot of time creating musical limits, right? So basically, just not to limit it too much, but not too little, which this was the challenge and the thing that took a lot of time because the audio blips door was already set up. We knew what was going on.
00:18:52.910 - 00:19:22.724, Speaker B: We had fun making the track, but then the next step, which was making sure that everything that will come out of the generation part regeneration park, I would say that was the tricky bit. And when it happened when we were all really happy. It was like, okay, don't touch it now. Leave it like that. Let's just speak details. Because it was quite one perfect song. Yeah, because it's true.
00:19:22.724 - 00:19:57.970, Speaker B: Because also, you don't want to limit it too much, because then it gets too conformed. At the same time, you don't want it to go wild. And also sounds to go out of our audio spectrum so we can even hear them. We're really happy with it and can't wait to put it out because, I don't know, it was really exciting hearing all these versions going over and over. It's like, oh, yeah, listen to this. We were sending each other stuff, like, listen to this one, this one. So really excited about that.
00:19:58.500 - 00:20:18.440, Speaker A: That almost feels like the music creation process. Right? You're producing something and you make something, you've got options, like, oh, this sounds cool, and this sounds cool. And maybe you find some piece that doesn't fit in this song, but that's its own new track. Right. And that's how you. But now you're doing it in multiple ways and letting people choose their own adventure almost. Or in this way, in one piece of music.
00:20:18.440 - 00:20:18.744, Speaker A: Yeah.
00:20:18.782 - 00:20:29.930, Speaker B: Everything changes, from tempo to pitches of each individual sounds to the arrangement. Everything, as much as possible. We put it in there.
00:20:31.660 - 00:20:57.920, Speaker A: One of my favorite albums, I was just looking for it. It's called recomposed. It's by a composer named Max Richter. It's a classical, but he takes the four seasons of all these four seasons, which is like this perfect epic symphony, and he revises it. He remixes it essentially, and does his take on it. And it's familiar, it's cool, it's interesting, but then it takes you to new places. That newness of music, especially probably for people here.
00:20:57.920 - 00:21:10.570, Speaker A: I love new music. I hate hearing the same song a thousand times over and over. I like new takes on it and exploration. It's part of what excites me so much. Grammatic, how did you approach this and think about the musicality and the newness of this?
00:21:11.740 - 00:22:31.200, Speaker C: Yeah, this was a hugely important thing, like what Lucas said, that we are able to manipulate sound at the core of it, so that every note is basically its own synthesizer, as if you would be adjusting oscillators and filters. And the generation of the sound itself, which at the same time represents one of the instrument stems in the song. And the fact that it all happens at lossless audio quality was crucial, because then, with warping baked audio, even if the algorithm is amazing, there's always going to be problems and degrading of the quality of the audio itself. Your possibilities are immediately very limited, unless you don't care about degrading the quality, which we're audiophiles, so we're very against that. So that made it possible. And the fact that if it wasn't for Lucas, I wouldn't even take on this project because Lucas is the patch bay master when it comes to modular synths. His brain just is connected with signal flow, thinking on a higher level that I will never be able to achieve.
00:22:31.200 - 00:23:59.996, Speaker C: He just knows he can do this all day in the studio. When we do it with hardware, modular synths, he can patch all day and understand in advance where he's going, which is, that's how you know that somebody is in tune with the signal flow of racks and modules and everything that comes along with rerouting sound from one module into another to achieve a musical goal. He's the backbone of this. When we first started working with audioglyphs, guys, it was actually a very ESP type of situation where we were discussing, Lux and I were discussing, like, I wonder if there's a way of doing generative music with merging. We were just considering that was probably in the summer, sometime in the summer, we were considering if we could merge stems, like I just explained, like, regular audio stems. If we were to just break down a song into audio stems and merge them in a way where it wouldn't be horrible, so they would make musical sense and also not be degraded in audio quality. And then I think I stumbled upon audio glyphs on Twitter when I was looking for.
00:23:59.996 - 00:24:06.572, Speaker C: We asked a couple of solidity devs that we knew and they were like, yeah, we don't know how to help you with that. We haven't really experimented.
00:24:06.636 - 00:24:07.516, Speaker A: Weird request.
00:24:07.628 - 00:24:08.000, Speaker D: Yeah.
00:24:08.070 - 00:24:53.324, Speaker C: Regenerative audio. Then we found audioglyphs and we were like, these guys seem to be already doing something similar with audioglyphs. It's not as musical as we would want it to be, but they seem to have the smart contract and stuff like that figured out. And then as I was getting ready to hit him up, I think Nft boy hit me up on Twitter and basically told me about audioglyphs, Daw. And asked me if I would be down to know with them. And I was like, shit. I was just getting ready to ask you guys if you can create a smart contract for, you know, I didn't even imagine that they have a Daw that is able to do this on such a high level because we were skeptical at, like, when they sent us access to the.
00:24:53.324 - 00:25:38.572, Speaker C: Like, Lucas and I was like, there's no way we can make a full song in the browser. Let's see what this is about. And then Lucas opened and started patching, and he's like, holy shit. This is a real modular synthesizer with everything, the whole nine yards. And it's like, then we were just blown away and got so excited that out of that excitement and patching and figuring things out, the syntopia prime song came to life. And as we were working on it, we were also helping them perfect some stuff in terms of the usability and capabilities of the DaW itself and discovering bugs that they were able to fix on the fly. And then we were like, well, can you guys make so that this has this much value or this many parameters? And like, yeah, that would be cool.
00:25:38.572 - 00:25:49.248, Speaker C: And then as we were making the songs, we were also making the jaw better. And the whole experience was like, to me, really exciting thing to be a part of.
00:25:49.414 - 00:26:08.804, Speaker A: Sometimes art demands to be created, and a confluence of factors comes together, and it's just like, no, this must happen. And it just sounds like this journey. It's an awesome story. I love the way the pieces kind of come together. You guys are searching for similar solutions, little serendipity. And then it forces itself, right?
00:26:09.002 - 00:26:30.380, Speaker C: It sounds cheesy, but it feels like it was meant to be because it was like a huge esp moment where I was getting ready to hit them up and they hit me up first. And that kind of stuff really excites me. When it happens in life, it just makes it feel like the life is more than just like what it appears to be on the surface.
00:26:33.140 - 00:27:21.324, Speaker A: You guys are musicians and NFT boy and TR six six six. You're obviously working in the music space. This discussion about modular synthesizer, hard to say modular synthesizers reminds me of an interview I saw with Moby. And he was talking about the early days when half, if not 80%, of building electronic music was finding a cable to go into your weird box that you found in Germany, and then this one from Soviet Russia and then this one from Brazil that got hacked. Like it was just a matter of technology and really splicing together things. And it sounds like that, right? But now you're taking a digital aspect, splicing them together and figuring out how to make them in a new way. And now you're extending it even further and adding things to distributed ledgers to blockchains, adding these NFT tokens to it, and really pushing those limits.
00:27:21.324 - 00:27:27.730, Speaker A: So I love seeing kind of music history coming to new innovation. Very exciting to me.
00:27:28.180 - 00:28:13.904, Speaker C: Yeah, actually that's exciting. And I know the thing that the Moby thing you're referencing, and he's also like a big sinhead. And that's another thing. Once the dog gets released with a dow and everything, I'm really excited to see what some of my peers and people in the music industry on the electronic music side who are really into modular synths and been doing it for way longer than us, who are like OGs. I'm really excited to see what kind of music they will create with it and what kind of generative projects that will yield. Because the possibilities are really endless. Even after working on it for four or five months, I'm still blown away that you can actually do this.
00:28:13.904 - 00:28:57.710, Speaker C: When you really think about it. That you can produce a song in a digital space the way you would with modular synthesizers in the hardware setup. And that stuff is really expensive. It's a really expensive sport. Like, just one rack is like 30 to 40 grand. And people like Dead Mouse and Junkie Excel, those guys have millions of dollars worth of modular know in their studios. And when they try this out and see how well it simulates that environment and that setup, there's no way they're not going to be excited and come up with something really cool.
00:28:59.280 - 00:29:33.880, Speaker A: NFT boy and Tr six six six, I'll start with you, but I want to hear from the musicians as well. Decentralizing music kind of takes it from this step. I step back and I look at music formats and channels. From composed music, written sheet music, to stamped or carved wax and vinyl, to magnetic tape with cassette tapes, to CDs. Right. And all the way to the MP3 and digital formats that we have today. I feel like this is totally my opinion.
00:29:33.880 - 00:29:57.010, Speaker A: Decentralizing these files and making them available on a blockchain adds this different layer of whatever it is. Tangibleness, something you can almost grip, even though it's digital. Do you guys think about this as you're making these tools, you're extending the musical revolution in very tangible ways. Have you thought about this? Do you process this? And if so, what do you think about that?
00:29:58.420 - 00:30:36.540, Speaker D: I think you're right. It's easy to get when you're building. You're caught up in what you're building. You don't think about the bigger picture as much, at least for me. I just get on the computer, I'm coding, and it doesn't really sink in that what you're building could be a game changer. But I guess me and TR six like early conversations did include stuff about, this can really change music. Like, this is a new way to make music, and it really is like a new way to make music for the metaverse.
00:30:36.540 - 00:31:13.076, Speaker D: And just combining the technology with NFTs, not only is it a new way to make music, it's a new way to monetize music. It's a new way to collect music. And it's just the beginning. Right? I think there's always a point of experimentation before there's world changing technology. And I think we're in that experimentation phase, and it's a very fun phase. It's like just seeing what works, what doesn't work. And we have a whole bunch of builders just experimenting with this new technology, which is nfts blockchain.
00:31:13.076 - 00:32:00.728, Speaker D: And now we've added generative music to the mix. It's still very early, but I've been in NFTs since 2017, and I've always known that they're going to change things. In what way? Yet to be seen. But we see the world is catching up, and the world is saying, yes, these do change things. Digital ownership is now a reality. Anything that an artist can create can now be monetized via an NFT, whether it's music or digital art, or there's people talking about chefs and recipes. It opens up a whole new world of monetization for different kinds of art and collecting different kinds of art in new ways.
00:32:00.728 - 00:32:10.170, Speaker D: So it's very exciting. And, yes, I think we are very aware that this is a game changer, and this will change, at least in some part, music.
00:32:10.540 - 00:32:34.204, Speaker A: Yeah. You think about when new technologies come out and you give it to inventive people. New stuff happens. And like I said, I'm a metalhead, so I love it when new amps, like with different vacuum tube formations come out and that you can get these classic sounds and all that to see that sort of newness come out. But it feels like that sort of thing is happening now in EDM as well, in digital music. Grammatic.
00:32:34.332 - 00:33:41.080, Speaker C: Yeah, I mean, the algorithms are getting better by the day, and we're soon going to reach a point like what they call in 3d world, like the uncanny valley and stuff like that. We're going to reach a point in the audio where we're basically like, the algorithms are so advanced that it's completely tricking our ears into not being able to detect whether the sound is analog or simulated. And then that's going to be a huge breaking point, I think, because to the regular listener, even today, it's already so advanced that they wouldn't be able to tell if this is coming from analog gear or simulated VST. But to those of us who are doing this every day and are deep in the culture of music production and audio engineering, we can still tell the difference. But it's getting like some stuff. It's already so good that even we get tricked, and it's just a matter of tricking the ear. It's same with movies.
00:33:41.080 - 00:34:11.120, Speaker C: There's no such thing as motion pictures. It's all like pictures. It only takes 24 frames per second to trick the eye into thinking it's seeing motion. With ear, it's much more difficult. It's a way more complex organ to trick, and it takes higher quality of algorithmic process. But we're getting it. We're really close.
00:34:11.120 - 00:35:11.248, Speaker C: We're really close. And that's the thing that excites me, because it also makes it possible to achieve the same kind of quality that you would get in an analog world, in the virtual and in the metaverse. Ultimately, of course, and not having to give up any of the quality and also makes it more accessible and affordable because studio gear in general, it's very expensive. It's like, historically, it's been very much only for privileged people who can afford to build a studio and stuff like that. Like when I was a kid, because I don't come from money. I never thought I would have enough money to build a real studio ever, because I knew how expensive it is. And it's like, in the metaverse, people will be building studios virtually, and everything that they will do in it will be on par with what you can accomplish in the real world with expensive hardware, gear.
00:35:11.424 - 00:35:26.616, Speaker A: And that changes the dynamic of art, of who's creating it. You have kids coming from nothing who can now log onto their library computer, maybe, and build some studio grade stuff. I can't wait to hear that. Right? That's a new experience. Yeah.
00:35:26.638 - 00:36:40.000, Speaker C: That began with the early 2000s when me and Lucas were in high school, and we were like, or like 8th grade to first year high school, 1314 years old when we started making music. That was like the beginning of that, where the first daws were coming out and you could make music in a computer, which was unheard of before it started happening in the mid 90s, but in the early 2000s was like the first really quality. There was some relative quality where you can actually make chart topping songs fully in a computer. And that began when we started doing and just like, to see it evolve and us evolving with it and just like how exponentially the growth has been with the evolution of technology and algorithms and what they can do. It's crazy. It's only going to get exponentially higher. Another thing I was going to point out about what's cool about syntopia is that we're also experimenting with putting the audiograph and script on chain, so that if someone wants to recreate their unique version of the song, they'll have all the required data to do so without the need for a third party.
00:36:40.000 - 00:37:15.630, Speaker C: And also collectors will be granted full music rights ownership, which I think is really important. You'll have the full music rights ownership of the unique song contained within your NFT. Not only you're able to download the stems or the data to recreate it and do a remix of it, but also you can use it for as long as you own that NFT. You have the rights to use it in whatever way you want commercially. Twitch streams and your monetized YouTube videos, whatever. It's going to be completely up to you.
00:37:16.400 - 00:37:38.176, Speaker A: That is awesome. I've just looked at the time and we've gone 37 minutes and so I don't want to keep you too long because I know you guys are doing whitelist stuff as well. We just got off on a cool conversation. I really had a great time. Okay, so here's what I got to know first. Whenever you guys do a live event, you start getting together to play versions of this song. Give me a ring, you got to send me a ping.
00:37:38.176 - 00:37:54.410, Speaker A: We'll see if we can come out and cover it from Chainlink because this is too cool to not cover. Two. I appreciate you coming so much. Please tell the people where should they follow you and find out more about synthopia. Are there any major things coming next in the next couple of days that we should keep our eyes out.
00:37:58.220 - 00:37:58.776, Speaker C: In?
00:37:58.878 - 00:38:12.440, Speaker D: We're currently doing the whitelist right now for audio glyph, grammatic, NFT holders and party degenerates. Those are in our discord servers, so you can find those on Twitter.
00:38:12.520 - 00:38:14.256, Speaker A: We'll have the links down below too.
00:38:14.358 - 00:38:15.680, Speaker D: Links down below, cool.
00:38:15.750 - 00:38:15.984, Speaker A: Yeah.
00:38:16.022 - 00:38:42.580, Speaker D: And then synthopia IO is where the minting will take place. So tomorrow we're going to open up minting for the code holders. Like we said, you can get a code in our discord servers if you were on the part of the snapshot. And then I believe on three days after that there will be a public mint for anything that's not minted during the code claiming.
00:38:42.660 - 00:38:59.516, Speaker A: So it's all happening this week. Code claiming, whitelisting public mint, strap in to synthopia and do what you need to do. Follow everybody down there. Nft boy. Tr six six. Lucas Grammatic, thank you so much for joining me today. I really appreciate guys.
00:38:59.618 - 00:39:01.310, Speaker B: Appreciate you both having good.
00:39:03.440 - 00:39:05.160, Speaker C: Thank you, Andy. Anytime.
00:39:05.320 - 00:39:23.332, Speaker A: All right, cool. I'm going to take it from here for just a minute. You guys can hang out or you can peace out if you got to go take care of stuff. Thank you for joining us. What a great session. I have a background in some music history and so get a chance to geek out with these fellows was so cool. I have a feeling we're going to look back on this in a couple of years.
00:39:23.332 - 00:39:42.664, Speaker A: It's a pretty cool moment. I hope so. At least grammatic and I talked about this Moby quote where he talks about electronic music. And I found the movie. It's from a movie called press pause Play. It's from ten years ago, but it's a Creative Commons free to download, so you can go look that up. It's just called press pause play.
00:39:42.664 - 00:40:03.824, Speaker A: It's on Vimeo. You can go see it. And it's a really cool thing about music and IP and all this sort of stuff. It's probably a little dated by now, but I used to assign it in my classes and so that's where I know that quote. Do me a favor, like and subscribe. Like so more people see this video, it'll go around the YouTube algorithm and subscribe. So you see more announcements of videos like this.
00:40:03.824 - 00:40:30.616, Speaker A: We do a couple per week with amazing projects like synthopia. Let me see if I can find who we're doing next week. We got a couple of defi ones next week. I'm really looking forward to. Wepiggy is a great name for a Defi project that's on Monday, super early on eastern time, but they're this defi protocol that is on seven different blockchains. So they are really multi chain. And then we're also talking to mintres that just announced a chainlink integration earlier this week.
00:40:30.616 - 00:40:52.650, Speaker A: So come and check those out. You can follow at smart underscore contract for announcements when these are going to be. You can follow chainlink at chainlink for all these chainlink official announcements. And you can follow me on twitter too at andy Boyen if you want to hear dad jokes and occasional chainlink shilling type things. I appreciate your comments and I appreciate you being around. We'll see you guys next time. Chainlink live.

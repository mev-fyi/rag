00:00:25.570 - 00:00:26.360, Speaker A: Thank you.
00:00:27.210 - 00:00:50.906, Speaker B: My name is Josh. I'm the community lead at chain Link Labs. We've assembled a powerhouse panel for all of you. Some of the top layer two teams and roll up teams are here to talk about the present and future of l two. If you guys want to go down the line and introduce yourselves, start with you, Ben.
00:00:51.018 - 00:01:07.822, Speaker C: I guess that starts with me. Hello, everyone. I am Ben, co founder and chief musician at Optimism. If you heard that horrible feedback at the start, that was me trying to play some Star wars to get you all to quiet down. But it didn't work out. Didn't work out. Anyway, optimism is an EVM equivalent.
00:01:07.822 - 00:01:18.900, Speaker C: One click deploy. Cheapest on the market, optimistic roll up for Ethereum. Thanks for having me, all. There we go.
00:01:20.570 - 00:01:47.040, Speaker D: Hey, everybody, I'm Ed Felton. I'm co founder and chief scientist at Off Chain Labs. We make Arbitrum. I'm a former academic, former government official, current jack of all trades. I lead research and protocol development at Arbitrum. Arbitrum is a fully implemented, fully featured, integrated and working today optimistic rollup that we encourage you all to use.
00:01:52.390 - 00:02:13.640, Speaker A: Hi, everyone. My name is Alex Kulkowski. I'm CEO and co founder of Matterlabs, which is the company behind ZK Sync. We built the ZK rollup for payments, which is live on Ethereum today. And we are currently working on the first EVM compatible zk Rollup, for which we have a live testnet, which you can all try.
00:02:20.430 - 00:02:38.080, Speaker E: Hello, I am Jordan Valina. I'm the technical lead at Polygon Hermes. We are building ZKBM of code compatible ZK roll up. And yeah, we are going to launch a testnet very soon. And yeah, working very hard and very excited for the project.
00:02:43.250 - 00:03:01.378, Speaker F: All right, my turn. So, my name is Joanne, co founder and tech lead at Metis Lab. So there are a lot of different ways of pronouncing metis. I think Metis is the official way. So. Hey, Metis. So we are a layer two solution trying to scale up the Ethereum transactions.
00:03:01.378 - 00:03:10.220, Speaker F: I think right now we are the cheapest layer two solutions on the market. Check us out, whether it's a roll up or not. Happy to base.
00:03:12.750 - 00:03:13.820, Speaker A: Thanks, guys.
00:03:14.670 - 00:03:57.320, Speaker B: So over the past year, we've seen layer two scaling solutions grow exponentially and fundamentally change the ethereum network for the better. With security fees on the rise, L two's stature in DFI is growing. They offer a unique combination of benefits such as trustless security, scalability and liquidation efficiency. And so we invited these panelists today to sort of talk about what's next for L two s. So we'll start with you, Jordy. What are the benefits and trade offs of L two roll ups versus side chains and l ones.
00:03:59.550 - 00:04:43.814, Speaker E: Mainly currently, the way we understand side chains, you have a trusted breach in general. So it's what we call, it's definitively possible to do what we call it the double pack trustless thing. But this is a side chain. Our layer two solution is just like a chain. It's another blockchain with its own estate. You can do transactions on top of that, but it's running on top of the layer one. You don't have consensus layer, you just delegate all the consensus to the layer one, and you are running and you are trusting all the security on the layer one.
00:04:43.814 - 00:04:48.840, Speaker E: So technically are very different. One thing and the other.
00:04:49.850 - 00:04:51.260, Speaker B: Ed, do you want to add?
00:04:52.030 - 00:05:11.610, Speaker D: Sure. No, I think it's really important to be talking about what are the security assumptions you're making in your system? Who do you trust and who could be in a position to corrupt your system or steal your data? Right. Are you anchored solely on Ethereum security or are you making additional assumptions?
00:05:11.770 - 00:05:12.480, Speaker E: Exactly.
00:05:14.050 - 00:05:16.274, Speaker B: Ben, did you want to add there?
00:05:16.472 - 00:05:18.100, Speaker C: Yeah, I mean, I think.
00:05:20.390 - 00:05:20.994, Speaker F: The things.
00:05:21.032 - 00:05:55.694, Speaker C: That have been said so far are all pretty accurate. I do think that it is the case that every l two makes some sort of additional assumption. Right. This is what gets it to be cheaper. But in general, it's the case that side chains make a very, very aggressive assumption, which is basically that there's some external set of validators that are independently securing the state. And when you do an l two, the whole point is that under some additional assumptions about what you can get out of the L one, usually, and most primarily, that's a liveness assumption, meaning we assume that we can basically submit a dispute ahead of time, at least the case for optimistic systems. Then you get that additional security.
00:05:55.694 - 00:06:11.410, Speaker C: So that's the real difference. When you have a side chain, you're relying on this external validator set. When you have an L two, you're trying to inherit the security guarantees of L one in this more scalable environment with a much more small set of assumptions. But everyone here makes some small additional assumption.
00:06:11.910 - 00:06:20.150, Speaker B: Alex? Ben brought up some assumptions. What is the difference between ZK sync and some of the more optimistic roll ups?
00:06:20.490 - 00:06:52.910, Speaker A: Well, we differ in that you rely either on some game theoretical properties of the system to secure it. In the case of optimistic roll ups, where you need at least one person, or like one player in the validator set, to be honest and to be constantly monitoring the system and looking for fraud. With ZKs based solutions, you essentially only trust math and implementation of the basically you don't trust fundamentally human component.
00:06:53.410 - 00:06:54.314, Speaker B: Ed, you disagree?
00:06:54.362 - 00:07:13.346, Speaker D: No, I disagree with that. Optimistic roll ups do not depend on a game theoretic assumption. They do not depend on an incentive assumption. It's true for arbitram. I think it's true for optimism as well, that we give an absolute guarantee of safe outcomes assuming any one honest party. It does not require.
00:07:13.378 - 00:07:14.578, Speaker A: Which is an assumption.
00:07:14.754 - 00:07:15.574, Speaker B: Yes.
00:07:15.772 - 00:07:18.054, Speaker D: If you have no honest parties, your chain is not.
00:07:18.172 - 00:07:23.642, Speaker A: That's what I was saying. You have an assumption of some honest players in the system. At least one.
00:07:23.776 - 00:07:26.598, Speaker D: At least one, right, but not a game theoretic assumption.
00:07:26.774 - 00:07:42.400, Speaker C: You do make one additional assumption, which is that within your dispute, period, you can get a transaction in. So I will say that there is an assumption that that one honest party within a week will not be censored for a full week. But if your l one is censoring you for a whole week, you got bigger problems.
00:07:43.810 - 00:07:51.630, Speaker B: Yuan. Let's move on and talk about dank sharding. What are some of the benefits this will provide to Ethereum? L two roll ups?
00:07:51.790 - 00:08:09.126, Speaker F: Absolutely. So actually data availability is a big topic. This dank sharding is actually a big helper for data availability. Even the lesser version, the proto data dank sharding that we just recently proposed. Not me, by me.
00:08:09.228 - 00:08:12.600, Speaker C: Not me either. But some legends on the optimism team.
00:08:12.910 - 00:08:57.910, Speaker F: All of us is also very supportive. It actually helps with the data availability cost of it. And the dunk shutting also has a very unique characteristic because the data and the commit is actually complete in one single block. That gave us a lot of opportunities for even the CK sync solutions where they can do cross chain transactions in an instant manner when the proofs are being committed. So a lot of opportunities. Did I miss some of you? Sorry. So I still have to do more research into possibilities of this because I think it opens a new door to how we handle layer twos.
00:08:59.390 - 00:09:12.350, Speaker B: Cool. So we're talking about this growing ecosystem. Is there anything that smart contract developers can only build on roll ups and layer twos that they can't build on the Ethereum base layer?
00:09:12.770 - 00:09:42.150, Speaker D: I guess I'll go first. Yeah. There are two big advantages that l two s will give you. One is much lower fees, and so transaction fees will price out a lot of applications. And many of those applications can come back in when you have an L two and the other one is higher throughput, meaning that you can spend more gas, you can have more transactions of the same size on the same chain. Those things, of course, are closely related because fees are high, because capacity is limited on L one.
00:09:42.300 - 00:10:39.750, Speaker A: So I would go even further and say that with l two s roll ups, maybe we'll start one step back. Dunk sharding provides you, technical details aside, just a linear improvement over Ethereum throughput. So if you can do 20 tps on Ethereum on roll ups, maybe you can do 2000 today, all roll ups combined with dunk sharding, it maybe goes up to 20,000 or 200,000, whatever, but you still have this limit. Now, if we're talking about l two s and not just roll ups, you can build systems that also tap into external data availability, something like Validia or ZK Porter for that matter. Those systems are limitless. You can have as much throughput in parallel on multiple systems that are all based on Ethereum and all sharing the same security as you need. So you can go completely unbound.
00:10:39.750 - 00:11:09.570, Speaker A: And now your throughput is not a bottleneck. So you stop thinking about what's possible in layer one or what's not possible in layer one, what's possible in layer two. You start thinking about what's possible in web two that we will now bring to web three and building the Internet of value, essentially making Internet for information. Now transfer value and taking all sorts of applications from Internet and powering them. Blockchain.
00:11:10.070 - 00:11:15.940, Speaker B: Is this one possible future solution to lowering gas fees in general?
00:11:17.110 - 00:11:59.170, Speaker F: Is that question to me, because we recently launched a very interesting experiment, I would say so. We did try to utilize external data availability more with the twitch. So what we did is having a proof of your data availability on chain in a way that people can actually request data availability on chain again if they find that something's wrong. So in a way, it's like a more optimistic data availability that we're implementing that lower the cost. But hey, there are always assumptions. That's the assumption that all the gentlemen are talking about. That's assumption we built in, and that's more assumption we put in.
00:11:59.170 - 00:12:05.742, Speaker F: So it's definitely something they can discuss in the future. More details.
00:12:05.886 - 00:12:26.890, Speaker D: So external data availability brings a lot of opportunity to cut cost across different types of architectural approaches. Dank sharding and protodank sharding allow you to do that, assuming only the security of the underlying Ethereum layer. You can also make additional assumptions about data availability, which all of these systems can do. And if you do that, then of course you can drive cost even lower.
00:12:26.960 - 00:12:35.470, Speaker F: Absolutely. And data availability, sorry, data availability is the biggest cost factor, I would say the most of the layer two cost is because of data availability.
00:12:35.970 - 00:12:48.530, Speaker E: But just to be clear, never will be a decentralized system that you don't have a minimum fee because the system needs to run and somebody needs to pay the system.
00:12:48.680 - 00:12:49.282, Speaker F: Absolutely.
00:12:49.416 - 00:12:54.802, Speaker E: So just when you see something, it's free? No, somebody's paying for that.
00:12:54.856 - 00:12:59.000, Speaker A: Yeah, but you can bring it down to a fraction of a cent, which is essentially free. Exactly.
00:13:00.010 - 00:13:01.798, Speaker E: Well, depending on the application, most application.
00:13:01.884 - 00:13:41.410, Speaker F: There is also a way, because if it's so cheap, you can actually use the guest network so that the project can fund the transactions for the users. Especially for a lot of web users, web two users and game users, they are so accustomed to be able to use the application without paying any transaction fees. So if you have a transaction fee as a barrier, that really hurts the adoption of those applications. So with a very cheap transaction cost, you can actually allow the projects to fund the users so they can actually access the application free and the project monetize it by using their business model. There are many existing business models that they can sustain a project without charging users transaction fees.
00:13:42.390 - 00:13:44.180, Speaker B: Did you want to add something there?
00:13:45.270 - 00:14:19.120, Speaker D: When we talk about these extremes of driving costs down very low, driving traffic up very high, we do need to remember that supply and demand still operates here. Right. You cut costs, transaction fees by a huge factor and a tremendous amount of traffic comes in. Right. The demand for computation in the world is enormous and practically unlimited. Right. And so as we scale these things up, as transaction costs come down, what happens is not that we reach the nirvana of everyone can do everything for free, but instead what happens is we move much more of the world's computation onto web three, which of course is what we're all trying to do.
00:14:20.530 - 00:14:22.334, Speaker B: Jordy, you want to say something there?
00:14:22.372 - 00:14:35.842, Speaker E: Yeah, I agree with them, but I wanted just to mention that it's going to be very low. But do not expect that the transactions are going to be free in the next year or next two years.
00:14:35.976 - 00:14:37.074, Speaker F: It will never be.
00:14:37.192 - 00:14:38.294, Speaker C: There's always a cost.
00:14:38.412 - 00:15:03.950, Speaker A: On the other hand, they might appear free to the end users. When you send a PayPal transaction or pay with a credit card, you also don't see a fee on your bank statement, but someone is paying the fee just hidden from the users. Your UX is like fee less, and we can have the same thing in those applications where the developers or the operators subsidize the costs.
00:15:05.010 - 00:15:08.362, Speaker F: By the way, the transaction of your credit card is actually pretty expensive.
00:15:08.426 - 00:15:10.000, Speaker A: People just don't realize it.
00:15:12.530 - 00:15:19.490, Speaker F: Hello. They complain about Ethereum transaction cost. I don't think they understand what they're paying for their credit cards.
00:15:21.030 - 00:15:26.580, Speaker B: Ben, what does a successful roll up ecosystem look like to.
00:15:27.110 - 00:16:32.058, Speaker C: Ooh, that's a good question. I think that I'll try to tie it into what everyone has just been saying here, which is that the successful execution, I think, of blockchain systems in general, of which roll ups are going to be a subset, is going to be basically the intersection of supply and demand being found. What the hell does that mean? So in general, what we see in these systems today with these blockchains is a relatively homogeneous security model, a relatively homogeneous block space. So what that means is if you look at a bunch of transactions on Ethereum, these all have the same security guarantees. So I think a successful roll up ecosystem in the future is really going to look like the coordination layer for all of these cheaper solutions that everybody has been talking about. So I actually think that what we see today is going to be a little bit different than what we see in the future, where we're going to see many, many sort of subchains or subdomains that are broken out with all the properties that we're just being spoken about. So some of them are going to be cheaper because people want you to use them and they're going to subsidize it.
00:16:32.058 - 00:17:07.620, Speaker C: Others are going to be cheaper because they're willing to make less strong assumptions or stronger assumptions. But I think what we are going to see is that the high security zones, which is basically what a roll up is, is going to end up being a coordination layer for all of those. So there's like the practical answer to this. The TVL of the roll up goes up, the transactions per second goes up, the congestion goes up. But I think realistically, if we look far enough ahead into what these systems are doing, all of the things to lower fees that all these people are talking about are going to be coordinated by a high security rollup. So that's what we see the future of rollups being.
00:17:08.070 - 00:17:11.654, Speaker B: I want to hear from the whole panel. So, Ed, if you want to talk.
00:17:11.692 - 00:17:53.490, Speaker D: About your future, I mean, I do think we're headed toward a future that is, first of all, is multi chain in the sense that you have different chains or chain like activities going on that are layered or bridged or interacting somehow, but also that those boundaries and differences will be less visible to users. The user experience will be more familiar. You won't have to do fussy things with wallets in order to use or onboarding that's going to be a lot smoother. But the mechanism under the hood that makes it work and that secures it is going to be probably multi chain and relatively complex, adapting to the needs of individual applications or use cases.
00:17:54.150 - 00:18:51.154, Speaker A: Alex so the original question was how we see success. Like, how do I define success of L two ecosystem? And for me, l two is just a means to making blockchains in general successful. So what that means is that we will see blockchains in the hands of everyone in the world. Like mass adoption, mainstream adoption of blockchain, where you have your blockchain account, it's as common, as important, as frequently used as your bank account, and maybe as your Google account or Internet accounts and so on. So to get there, we just need a technology which allows this boundless scaling as one of the prerequisites. And l twos specifically bring that reliant on the maximum security of Ethereum. And what's really important here is we rely on something that is fundamentally incredibly resilient.
00:18:51.154 - 00:19:35.406, Speaker A: It's more resilient than corporations, than some organizations, than your banks, if you want. It cannot be shut down by governments. Even if all the worldwide governments came together, they can't physically shut it down. So they also can coordinate to the extent where they can center it in any other way. So it's really, really important that we preserve this property while we're getting to scale. We don't want to get to the situation, which happened to Internet, that it started out as a decentralized network of networks, and then now it's controlled by five corporations. And those corporations can impose arbitrary rules.
00:19:35.406 - 00:19:54.586, Speaker A: They can shut down your account at any time with no notice and you have no rights there. We really have to invest a lot into making it mainstream, but still keeping this resilience and this sovereignty for every user. So that would be success for me. For l two blockchains in general, yeah.
00:19:54.608 - 00:20:47.274, Speaker E: I fully agree with Alex, especially in the long run, this is where we have to go. But in the mid run, in the midterm, I think that we are entering in a phase where a lot of chains will appear and we need to learn a lot from one each other. We don't understand yet how this ecosystem will work altogether. Zk technology, for example, is advancing really fast. We are using protocols that five years ago they just didn't exist, or nobody knew about that optimistic roll ups. They are doing huge advances in the last years. So we are very early stage yet, and we still have to learn a lot.
00:20:47.274 - 00:21:37.050, Speaker E: There are not so many in production working. You have one, we have start, but it's still very young, it's still very early. Applications are not mainly there. So it's still a long path. I think now it comes the years with many blockchains, with many technologies, with a lot of experimentation, and in the midterm, then I agree with Alex that at the end, what we need to build and we don't need to lose our goal, that's building this censorship resistant universal where anybody can access in a very cheap and you can build whatever you want without anybody stopping you on top of that chains.
00:21:38.190 - 00:21:38.940, Speaker A: Great.
00:21:39.550 - 00:22:27.260, Speaker F: I agree with everything that all the gentlemen said. That's advantage of me, of being the last winner in this panel to talk about it. Can you start? Hey, I agree with everything, but I do want to expand certain things. For example, when I access the mainstream adoption of web three technology, I do want to expand what it means. To be honest, I do not think if five years from now, if I see the same ecosystem that we have as Ethereum right now, or DFI, Genfi, all the other things, I think it will be a failure for us. I think layer two technologies unlocks a new door for a whole new type of applications, a whole new way of integrating web two and web three. So I really hope that five years from now, the ecosystem will be completely different.
00:22:27.260 - 00:23:06.918, Speaker F: We will see real economic activities happening on web three. We'll see enterprise utilize web three, both in the internal operations and also external interactions with other entities. I do want to see more women also participating in this industry, in this space. I see a lot of beautiful women here. Great to have you here. And we want to see more so that Web street becomes the dominant technology, the platform that people are going to use for their utilities, entertainment, utilities, monetary, utilities, financial investments, all included. I think that's what layer two unlocks going forward.
00:23:06.918 - 00:23:13.500, Speaker F: And we are all on the mission. And I do feel that we have consensus in this panel. Mainstream adoption is coming.
00:23:15.150 - 00:23:31.470, Speaker B: And final question, to increase cross chain composability among all this growing and rich l two ecosystem, what kind of technologies can we employ now and in the future to make that reality?
00:23:32.470 - 00:24:14.266, Speaker E: We just made proposal for interval up communication. At the end idea is use the layer one just to kind of communication. We just used an old idea that comes from the sharding, but not the current f two sharding. When Vitalik five years ago was talking about sharding and all that stuff a little bit, we recovered that idea. And the idea is that we can do all the value transfer of one chain to the main net with a single hash. We're just passing one hash and from the main net to the other, roll up with a main hash. So with this, we can transfer value between roll ups.
00:24:14.266 - 00:24:43.400, Speaker E: When I mean transfer value, I mean transfer nfts, transfer ERC 20s, transferring any value that any smart contract can hold on that. This is a proposal that is in ETH research, but this is the way to go the roll up, especially in this phase where many roll ups will coexist, it's important that this interroll up communication exists and are standards at some point.
00:24:44.090 - 00:24:44.774, Speaker B: Do you want to.
00:24:44.812 - 00:24:53.990, Speaker D: Sure. Cross chain interoperability bridging is easy to do insecurely, difficult to do securely and efficiently.
00:24:54.070 - 00:24:55.606, Speaker E: I'm talking about securely.
00:24:55.798 - 00:25:40.620, Speaker D: You can always bridge through l one. Everyone has a good bridge between their chain and the L one. You can go to l one and then back up to L two, and that will work, but it will be relatively slow and expensive. How to bridge between chains, how to bridge between layers, and how to do it in such a way that you're not just importing all of these security assumptions of all of the different participant chains is a much more, I think, deeper area where there's a lot of current research going on. I think we'll see progress on that. I think we'll see some real advances over the next year or two in that area. But I think there's a lot to still be discovered and to figure out what is the best, most efficient, and most importantly, secure way to bridge without having to go through L one.
00:25:42.590 - 00:26:22.854, Speaker C: Yeah. So it's interesting, when I hear the word which you originally say, which is composability, I take a very specific definition, which does not include cross roll up bridging, which I would consider interoperability, which I think you did use, Ed. So my hot take on this would be that the number one thing that we need to do to improve the composability of these systems is we need to shard them. And when I say that, I don't mean making multiple roll ups that talk to each other. I mean making one roll up. That is itself a set of parallel execution that increases the total throughput. So the ability to do a flash loan from one roll up to another is not the same as the ability to do a flash loan within a single roll up.
00:26:22.854 - 00:26:48.062, Speaker C: And fundamentally, we need the economic efficiencies that come with doing flash loans within one space. Okay, what the hell does that mean? In simple terms? It means that we need to make the gas limits of the roll ups themselves as an individual, roll up bigger, as opposed to making a bunch of smaller roll ups because you can't flash loan across a bunch of small roll ups. And so the more that you fragment the ecosystem in that way, the more that you introduce economic inefficiency. So that would be my hot take.
00:26:48.116 - 00:26:50.798, Speaker B: Answer, Alex, you got a hot take?
00:26:50.964 - 00:27:36.094, Speaker A: Yes, I have actually, a contrarian point here. So when we talk about compatibility is, for me also something that is inside a single system that can be synchronously executed and all roll ups will have it inside. But interoperability is really interesting, and I'm actually a big skeptic on interoperability. I think that roll ups win versus other alternative l ones, specifically because interoperability between heterogeneous chains requires trust. So you make a lot of trust assumptions in between. And the problem is you layer up those assumptions. So maybe you are on Ethereum and you want to bridge from, let's say, Solana, and you trust both Ethereum and Solana, and this is fine.
00:27:36.094 - 00:28:36.930, Speaker A: So you bridge some assets from Solana to Ethereum or like from to Solana, but then you want to bridge those assets further to some polkadot or cosmos ecosystem or whatever. And then all of a sudden, you have not just one hop of trust, but two. And then from there, it goes further and it compounds, and it compounds the risks and it compounds assumptions that not all participants are willing to accept. You have systems like makerdao that are specifically intended to keep all dai equal and fungible across all chains, which is hard, because when you start building those assumptions, they can make it on each individual chain, looking into assumptions about security of those chains and mitigating them. But layering them up is an entirely different story. So this is why roll ups are better, because they have this trustless line between l one and roll ups, or l two s in general. And this is why I'm skeptical that we will have efficient communication between roll ups.
00:28:36.930 - 00:29:24.526, Speaker A: We will have for sure, we can always go through l one. But that requires linear communication complexity, like linear cost. You have to pay for each transaction. It cost on l one, which is very expensive. So you can only move like expensive items. Large cars, you cannot move, you cannot send parcels per post. Right? And the approach that George just mentioned, where you would batch them together and only pass a single hash through l one, would work again if all roll ups trusted each other, or if the two roll ups that are trying to communicate this way not just trusted each other, but if you watched Silicon Valley, there was an agreement between the two characters, one told another, we need the blind trust here.
00:29:24.526 - 00:29:37.634, Speaker A: Just blind. Like, this is kind of blind trust you would have there, because if something happens on the other roll up, you're not only messing up this particular transaction, but you're messing with the supply of all assets in both systems, which would.
00:29:37.752 - 00:29:39.826, Speaker C: Doesn't that depend on the speed that you're going though?
00:29:39.848 - 00:29:40.034, Speaker F: Right?
00:29:40.072 - 00:29:43.446, Speaker C: Like, if you take it as a week long, like a hop exchange does this, right?
00:29:43.468 - 00:30:04.042, Speaker A: And there's no trusting, but you trust implementation as well. Like, if there are bugs in those systems, you merge the security and you make all of these roll ups all of a sudden as secure as the weakest link between them, like as the weakest one across all of them, even you have something really secure. But we make a mistake. At Gksync, optimism will be screwed.
00:30:04.186 - 00:30:30.440, Speaker D: People in the security world often work to build more secure protocols on top of less secure systems or less secure assumptions. This is an example of that, right? There is opportunity for research in this space to be able to bridge more efficiently without taking on all of the security assumptions of all of the component parts. It's not easy to do, but I think we're going to see a lot of progress in that area.
00:30:31.290 - 00:30:57.706, Speaker E: Yeah. Regarding what Alex said, for example, in the system, you can have, like, know, and this can be defined in some hole by the same user. So this is a token that can be transferred to this roll up and this roll up, and this can be limited by the user. Of course, this requires a lot of research because this complicates a lot the UI, and it's not easy, but I think there is a space there for working in that direction.
00:30:57.738 - 00:31:00.894, Speaker A: I agree. You could limit it to a specific token, but then you would create, like.
00:31:00.932 - 00:31:08.590, Speaker E: Two non funnels to limit different roll ups. I'm saying I just bridged this, and this can be transferred between this roll.
00:31:08.750 - 00:31:18.466, Speaker A: Up, but then you don't have Dai, which is dai everywhere. You have Zksync optimism die, and Zksync optimism Hermes die, and so on.
00:31:18.648 - 00:31:21.010, Speaker C: That's optimism, ZK sync dye.
00:31:21.590 - 00:31:53.520, Speaker F: So it depends on how many hops you have. You have a new token. I just want to add, even if the same technology, if you have the same security assumptions, if you just hop between them, you're already laying up the assumption, because there's also a possibility that your system can be attacked with that assumption. And every time you do a hop, you're increasing that probability that your whole transaction or whole chain of hub may be under attack. So that's something I do want to kind of stress, because it's not about the weakest link every time. It's really about the number of hops you have to do.
00:31:54.450 - 00:32:11.590, Speaker C: Almost all the solutions to this problem that we see today introduce collateralization as the way to keep things secure. And this is why they will cause economic inefficiencies. And this is why we need big roll ups that can do a lot. So we minimize the amount of collateralization per chain and increase the economic efficiency.
00:32:12.570 - 00:32:21.434, Speaker D: Yeah, we need big roll ups, but we're going to need more of them, because even as we scale up each roll up, it's not going to be enough for the demand that's out there.
00:32:21.472 - 00:32:25.290, Speaker A: In the world unless you use something like Ziki Porter.
00:32:26.590 - 00:32:27.050, Speaker C: Okay.
00:32:27.120 - 00:32:41.998, Speaker B: All right, let's start. Okay, we'll make a bet on whether you have infinite capacity. Let's take some questions from the audience. Now, if anyone wants to raise their hand, you in the white shirt, can you stand up and say it loudly? Yeah, I don't have a mic, I'm sorry.
00:32:42.084 - 00:33:12.970, Speaker G: Okay, so all of your protocols basically make use of flutter cryptography to make transactions cheaper and push more for them to prove. And that's great for the end user. It's also maybe a dirty secret that most of them are forks of guests, or very similar to forks of guests. So if you start to push more transactions through that, you're going to start to evolve in issues that you have. Running an L one node, the chain is huge. It takes forever to sync. How do you prevent that from becoming an even bigger issue with your protocol?
00:33:14.430 - 00:33:14.906, Speaker F: Take it.
00:33:14.928 - 00:33:15.654, Speaker B: Yeah, go ahead, Ben.
00:33:15.702 - 00:33:40.670, Speaker C: So you're totally right. We're good. So you're totally right. Actually, I think that it's the case. Well, first of all, I'll say that I think that's true for me and ed the most as far as using Geth. And in fact, it was our biggest upgrade ever that we did last year was our EVM equivalents upgrade, where we moved to a much smaller diff to Geth. And our next version of our protocol, bedrock, makes it about 400 lines change from Geth to Optimus at Geth.
00:33:40.670 - 00:34:20.846, Speaker C: And I view this expressly as a good thing, because the reality is, the reason that the problems that are going to be faced between l ones and l two s is the same is because fundamentally, these are the fundamental problems of blockchain scaling. You basically have three. You have data, right? The bandwidth, you have storage, and you have compute, right? It's your gas, it's your addition and multiplication. It's the size of your hard drive, and it's the size of data that you're downloading, the size of the blocks as you download them. So fundamentally, I agree that we're going to have to solve these problems. And the good news is that by making these problems the same for Ethereum as roll ups, we're going to work together to solve them. So that's a huge deal for us.
00:34:20.846 - 00:34:31.890, Speaker C: So you're right that these are going to be challenges, but it's an advantage to make them the same exact challenges on our l two systems as our L one systems. What's that?
00:34:31.960 - 00:34:33.646, Speaker G: Will they be challenges sooner?
00:34:33.758 - 00:34:46.920, Speaker C: Oh, will they be challenges sooner? Yeah, we'll have to see how the state growth plays out. We definitely are thinking about it actively, and my suspicion is they'll be solved on l two s before they'll be solved on l ones.
00:34:47.770 - 00:34:50.918, Speaker B: There's another question in the front here. Yeah, you.
00:34:51.084 - 00:34:51.974, Speaker A: May I also add.
00:34:52.012 - 00:34:53.046, Speaker B: Oh yeah, sorry, go ahead, Alex.
00:34:53.078 - 00:35:28.710, Speaker A: So I just want to add that we're not using gath in ZK sync. We're building an entirely new virtual machine. And a big advantage of zk systems compared to optimistic systems is that you have freedom to put more requirements on the validator of those systems because you don't expect the end user. You don't need all of the validators, like a large number of validators for those systems. The validators in ZK sync are block producers. They have the job of building blocks. And you can tell them, look, we don't need 10,000 of you.
00:35:28.710 - 00:35:51.718, Speaker A: Hundred will be sufficient. So your requirements on your machines are higher. You need more memory. This memory has to be faster, has to be better integrated with the CPUs you're using. You can have more parallelism, more optimistic ways to process transactions in the block. To complete this block and make the proofs so you can eliminate the bottlenecks.
00:35:51.734 - 00:35:55.934, Speaker B: Of cat respond there. No, sorry.
00:35:56.132 - 00:36:08.386, Speaker F: There's always a limitation on hardware specs, right? So how are you going to go through that? Spec limits cap? There's always a limitation on the hardware spec, right?
00:36:08.488 - 00:36:45.342, Speaker A: Sure. But your bottleneck will be much slower, so you don't have 20 transactions per second. You're getting 2000 on a single machine because your machine is just more power. Like the main bottleneck in GAF today is the data access latency, just specifically latency because you needed to read a slot, then sequentially, then read another slot based on those hashes. And this gives you like, you cannot just read memory in all big, sorry, not memory AGD. Disks in big chunks, right. So you have to do the sequential read, write, read, write, read, write.
00:36:45.342 - 00:36:50.750, Speaker A: And this creates a lot of latency. And this is like the biggest by far, biggest bottleneck of cat.
00:36:50.820 - 00:36:51.054, Speaker F: Great.
00:36:51.092 - 00:36:58.206, Speaker A: So you can instantly get away of it by saying, I'm going to keep all of my state in RAM in memory, and it's much faster.
00:36:58.318 - 00:37:01.986, Speaker F: Great, thank you very much. But there's still a limit, right? It's not limited, of course, but it.
00:37:02.008 - 00:37:31.050, Speaker A: Gives you a linear, you get around all limits by having many systems in parallel. This is what I said about ZK Porter before. It's not like the ZK Porter is, that is different. It's having really many parallel systems. How many infin infinite, like it's really expensive. That sounds expensive, including expensive. How many servers can you have on the Internet?
00:37:32.030 - 00:37:34.320, Speaker D: Depends if you have to pay for them all yourself.
00:37:34.770 - 00:37:38.414, Speaker A: No, in general, your prover is not.
00:37:38.452 - 00:37:40.878, Speaker D: Run by everyone on the Internet, right? It's run by you.
00:37:40.964 - 00:38:18.422, Speaker A: No, the proofer can be run by. There will be a decentralized marketplace for proof generation, which is going to be based on some hardware that a lot of people possess. Like you can reuse GPUs that will be getting free after the merge of Ethereum, and all those GPUs like enormous power that was used for essentially just burning, heating up the atmosphere will be put to use for generating zero knowledge proofs. And they are all decentralized in people's hands on individual machines, in data centers and so on, and you don't need all of them. This alone will give you huge power of processing millions of transactions.
00:38:18.566 - 00:38:20.794, Speaker D: That also sounds expensive, that is.
00:38:20.832 - 00:38:24.730, Speaker A: But when you divide it by a number of transactions, you get to your fraction of a cent.
00:38:24.800 - 00:38:32.782, Speaker C: Yeah, I do have to agree with you, Alex, that all of the scaling solutions are going to have to work by parallelizing. Right? That's how you increase the throughput as you parallelize things.
00:38:32.836 - 00:38:41.250, Speaker D: But the question is, how much computing do you need to service each transaction? And that's where optimistic systems have an enormous advantage over ZK.
00:38:42.070 - 00:38:45.650, Speaker A: Yeah, but your bottom lack is data availability, which you can't circumvent.
00:38:47.610 - 00:39:25.390, Speaker E: You're right, but it's getting very low. The cost per transaction is getting really low, and it's going to be very insignificant. We are generating proofs every time, faster. And of course it's a cost, you have to compute that, and it's not free again, but the marginal cost of the computation per transaction is going to be really low. And the earnings you get, all this delay that you don't have that you really trust you can withdraw the funds immediately. You don't need this collateralization on the system. So all these advantages, I think, that are better.
00:39:25.390 - 00:39:32.754, Speaker E: Of course you need to build this proof, of course it has a cost, but personally, and of course I'm biased here, but I think this is the future.
00:39:32.872 - 00:39:39.750, Speaker D: I would rather do one ad instruction than one ad instruction, plus hundreds of elliptic curve operations.
00:39:40.890 - 00:39:51.430, Speaker A: Me too, but that's not the bottleneck of your cost. Your bottleneck is data availability. So I would rather do a lot of ad operations rather than buying a lot of memory.
00:39:51.510 - 00:39:53.210, Speaker D: Everyone needs data availability.
00:39:53.710 - 00:40:05.040, Speaker A: Yeah, but with roll ups and non roll ups. With roll ups you can only rely on data availability from Ethereum, unless you make really heavy assumptions about trust.
00:40:05.730 - 00:40:09.678, Speaker D: If you're going to be EVM compatible, you have to provide availability for the state.
00:40:09.764 - 00:40:13.040, Speaker A: Yes, not necessarily, it works in a different way.
00:40:13.430 - 00:40:16.222, Speaker B: Let's move on to one final question from the audience.
00:40:16.286 - 00:40:18.478, Speaker C: I guess we have differences.
00:40:18.654 - 00:40:19.380, Speaker B: Yes.
00:40:20.790 - 00:40:44.410, Speaker G: Thank you so much, Bruno. Smile. Very entertaining. My question is about MeV. So I think it said for optimistic roll ups, it's the sequencers that capture mev. Not sure if the same for zk roll ups, but in a world where all users have migrated to l two s, what happens to layer one meV? Is there still MeV to be captured like cross roll ups somehow, or have you guys just absorbed all MeV?
00:40:45.550 - 00:41:43.514, Speaker C: I mean, there's a few parts to it, right? One thing is that cross chain MeV is very real, and this is something that is just starting to come up in the research light, right? So the idea of doing arbitrage across chains, where you can sell an asset on one chain and buy an asset on the other, and you're sort of doing this arbitrage on a way that requires you be able to get your transaction in on both. So there's really interesting questions there as to what are the circumstances under which that basically you can sequence both of the chains, because what you don't want to do is have a sell here and then the buy here fail and suddenly you're exposed to some random thing which you don't. So it's a very interesting new piece of research from the L one MeV that we see where you can just make a contract and enforces this because you don't have the composability, you've only have the interoperability between these chains. You can't do that same level of guarantee. So that's a very interesting question. In general, I think it will be everyone's opinion here that what we need to do is minimize MeV where we can. Right.
00:41:43.514 - 00:42:05.140, Speaker C: That's certainly something that seems beneficial to do. It's very unlikely that we'll be able to eliminate all MeV. It's our perspective that for the places that we can't eliminate MeV, what we need to do is have a measure of how much MEV there is there being captured and redistribute that MEV to whatever system you want. So anyway, that's a bit in general about that, and then a bit on our take at the end.
00:42:06.390 - 00:42:07.714, Speaker B: Anyone else have something to add?
00:42:07.752 - 00:42:34.480, Speaker D: Ed, just very quickly, I agree with almost all of that. I think most of us are probably in the camp of trying to reduce MeV. And certainly l one chains that give fast response time to user requests will necessarily have less opportunity for MeV. If you're going to give a user a response in 1 second or less, then your sequencer can't hold their transaction for seconds waiting to extract Mev. Right. The other thing I'd say is I'm giving a talk about this topic at Mev day.
00:42:36.770 - 00:42:37.520, Speaker A: Yeah.
00:42:39.330 - 00:42:55.458, Speaker B: Okay, let's give the panelists a round of applause, stick around, drink some beer, make some friends, connect.
00:42:55.544 - 00:42:56.180, Speaker A: And.
00:42:58.970 - 00:43:01.990, Speaker B: Should I try to play this piano?
00:43:03.530 - 00:43:04.534, Speaker A: What is this actually called?
00:43:04.572 - 00:43:06.610, Speaker C: This is called a melodica song or melodica.

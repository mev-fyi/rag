00:00:00.090 - 00:00:44.618, Speaker A: Welcome, everybody, to the Chainlink Q three 2023 product, Q and a with Chainlink Labs chief product officer Kamal El Mujadid. I just want to take a moment to explain how the call is going to work. I'm going to pose questions to Kamal based on the questions submitted through the Google form and a few that I wanted to ask as well. Special thanks to those of you that have submitted questions, and I will mention the handle of the person that asked if it was provided. We will also be joined by a special guest, Ben Cream, product manager for data streams at Chainlink Labs, who will also be answering some questions around Chainlink data streams later in the call. One quick thing, just to call out, Kamal will only be answering product questions directly related to Chainlink services. So to go ahead and get us started, Kamal, why don't you give everyone here just a brief introduction of who you are.
00:00:44.784 - 00:01:37.340, Speaker B: Hey, Rory, great to be back with you for this session. So, hi, my name is Kamal. I'm chief product officer at Chainlink Labs. And in terms of what I'm most excited about right now, well, we just got back from Smartcon in Barcelona, which was pretty incredible. And I was reflecting on that on the way back, and I think what happened is last year, we laid out a great vision for Chainlink as a platform in New York in Smartcon 2022. And the vision, why it matters, what problems it solves. And what I really liked is that since then, we've had this very strong execution against that vision to build a decentralized computing platform and power the verifiable web.
00:01:37.340 - 00:02:32.310, Speaker B: So that's really something that I'm very proud of, and that we spend a lot of time and energy on, is executing against that vision. I think another really interesting thing is that we talked about the concept of verifiability and how this is a key aspect of Web three, which I believe is going to permeate all services around us. Whether it's Web three, web two, everything is going to become verifiable. I like to go back to this impression I had with the first time I downloaded music and streaming. Downloading was just superior, and it was really inevitable that we will all be streaming as soon as it was technically feasible. I don't remember the last time I bought a CD, and I think it's going to be the same thing for verifiability. It's just superior to a just trust me service.
00:02:32.310 - 00:03:20.380, Speaker B: So all we got to do is just make it technically possible, easy to build, and it's really inevitable. This is, by the way, this is so clear, resonates with everyone, everyone at the conference, but also outside the conference, who's just reaching out to me and saying, can we make this verifiable? Can we make that verifiable? So it's really a fundamental need to build a society we all want to live in. And I really liked that we made that concept front and center. And I think it's going to just go way beyond our industry. And of course, at Chainlink Labs and Chainlink in general, we're accelerating that phenomenon. We're making it easier to build those verifiable applications and services. So it was a very nice articulation of our vision, I believe.
00:03:20.380 - 00:03:57.938, Speaker B: And Smartcon 2023 was just, I believe, the best smartcon yet. The plan that we talked about during the previous updates that we made, and you and I worried, we talked about those three bets. That was really the moment where it all came together. In particular, data streams going main net, showing the CCIP momentum functions beta going mainnet, automation 2.0 going main net. The developer hub, the ask AI, the quick starts. That's so much and much more on VRF and deco and FSs.
00:03:57.938 - 00:04:43.800, Speaker B: So it's really this great feeling because we have the right plan, we're executing, and then we just got all these positive feedback. Personally, I loved hearing from developers and more generally from our community. Our users always give up. They give us a check on how much impact we have, and that gives us this immense boost of energy. We work hard all year long, and getting this positivity just felt really good on a personal level. So now it's back to executing against us. And the next big milestone is going to be this hackathon, the constellation hackathon kicking off November eigth, that I'm really looking forward to what people are going to be building.
00:04:43.800 - 00:04:48.760, Speaker B: But as for today, very happy as always to connect with the community.
00:04:50.250 - 00:05:24.180, Speaker A: Awesome. Well, thank you very much. And I was super excited by this year's smart con in Barcelona as well, and shout out to those of you that were able to join us in person or if you watched us virtually, we're going to look to make it better and better sort of each and every year moving forward. So now we'll kind of move to sort of really the first official question, and this question was from Rahul Ahmed, 95. Kamal Swift handles about $5 trillion daily and about 50 million messages a day. Can chain Link scale at that level of infrastructure and for many other institutions as well.
00:05:25.110 - 00:06:13.700, Speaker B: Thanks for Ahmed, 95. Well, great question and answer is yes, chain Link's architecture is horizontally scalable, which means that we can just scale by adding more nodes or more dons to the system. That's how the system has been designed. We currently have over 1000 dons powered by diverse node operators and we facilitated over $8.5 trillion of value being the backbone of the whole DFI industry. And we're just going to continue adding more of this capacity while maintaining our very strict security standards. And this is actually one of the big advantages that Chainlink possesses, because scaling is not just a technical throughput problem.
00:06:13.700 - 00:06:53.200, Speaker B: You need security. Usually that's the first thing that get compromised when you scale, and your system is not designed for that. And we've invested a lot, a lot in security and reliability. And then you need flexibility, because as your system grows, you need to be able to plug into all the different weird and specific use cases that people will have, and you need a system that's flexible and that's also something that we spend a lot of time designing the system for. So on both fronts, we are very well positioned to scale to the amount of value, the crazy amount of value that we're seeing on the tradfi world.
00:06:54.450 - 00:07:14.230, Speaker A: Awesome. Well, I'm super excited to hear that that's the case. Moving on to question number two. This one was from an anonymous submission. How does Chainlink ensure the security and reliability of CCIP, particularly in the context of handling sensitive data, or when banks send large amounts of value between chains?
00:07:15.850 - 00:07:54.922, Speaker B: Great question. So I think first it's got to start with a conscious decision to prioritize these properties. You have to say, okay, I'm going to prioritize security and reliability because you can also just rush to market and just build something. Or you could do what we do and you could build it the right way. And there's something that I said earlier, there's this quote I really like, which is pioneers get the arrows and settlers take the land, and we want to take the land, we want to be the standard. So this means taking the right approach on these dimensions from the start as a conscious decision. And that's what we did with CCip.
00:07:54.922 - 00:08:54.722, Speaker B: And CCIP has cutting edge system designs with multiple layers of decentralization and risk management. Our researchers, world class researchers, have been working on this for years. So CCIP really offered this unrivaled security to unlock the whole crosschain economy, both for web3 protocols and for the world's largest financial institutions. In practice, CCIP practices defense in depth through, for example, rate limiting. There's a cap on the value that flows. The risk management network is a completely independent system, different languages, different teams, different nodes, that acts as a secondary validation service, and it detects and halts any anomalous activity. One of the principle that it uses is inversioning programming, which is a security principle used in aerospace and other safety critical systems.
00:08:54.722 - 00:09:03.260, Speaker B: So with all this approach, this is really a collection of different systems that guarantee maximum security and reliability for the whole system.
00:09:05.070 - 00:09:16.160, Speaker A: All right, thank you for that submission, anonymous user. I guess we'll ride into the next question, which is also an anonymous submission. What use cases are projects building with CCIP that excite you? The most.
00:09:18.130 - 00:10:03.070, Speaker B: Great question. So first I'll say when you have secure interoperability standard, then the possibilities and use cases are really endless. But one thing in practice that really I find magical as a developer is to be able to move value really securely with one line of code. And CCIP lets you do that as a developer. And conversely, if you're an asset issuer, what you can do is you can make your asset infinitely programmable by that developer. You put that asset on chain and all of a sudden your asset becomes demultied by the whole developer community because now they can move your asset with one line of code. And this is really unprecedented.
00:10:03.070 - 00:11:18.150, Speaker B: Any asset manager can go and say, okay, I'm going to tokenize my asset, and they get instant distribution to any DAP any developer can think about, again with one line of code. So I find this incredibly exciting in terms of the use cases that this opens. Another really interesting property of this moving the value is with programmable token transfers, you can send value and data together simultaneously. This is something that, for example, the ANZ said they thought this was a revelation, Nigel saying that they're hoping to see information value traveling simultaneously, as opposed to information value traveling sequentially, which is what happens now in swift messaging. And with CCip you can bundle both. So it's just much simpler to build and much more powerful to be able to send both things simultaneously. And other web3 projects are doing things like this, sending tokens crosschain and then instantly swapping those tokens on the destination chains versus having to send a token and then check whether the token arrived and then say, okay, well then, now do this thing.
00:11:18.150 - 00:11:39.130, Speaker B: So it's just much more productive, much easier, and also much more secure because the whole one instruction gets sent atomically. To answer the question, I think developers programming value with one line of code across all these heterogeneous systems is going to lead to phenomenal growth.
00:11:41.070 - 00:12:09.350, Speaker A: All right, we'll move on to our next question here. And this was actually posed by Rosh Patel. Rosh is actually one of the longtime chain link advocates and I believe he's based out of the UK. So thanks for this one, Rosh. Will the functionality of the CCI explorer CCIP chain link become what etherscan is, whereby all CCIP transactions from the beginning are viewable rather than only the latest five, along with Testnet and Mainnet being separated?
00:12:10.090 - 00:12:53.886, Speaker B: Well, thank you, Rosh, for your question, and also just thank you more generally for everything you do to help build the chainlink community. Very appreciated and everyone else who's helping build this awesome community. So yeah, we're always looking for ways to enhance the CCIP explorers to benefit our users and ecosystem. I think in the future it will show more transactions similar to efascan. It will also distinguish between Mainnet and Testnet. Both items are on the roadmap, so stay tuned. But in the meantime, all CCIP transactions are of course on chain and viewable using the search bar in the CCIP Explorer.
00:12:53.886 - 00:13:17.610, Speaker B: Personally, I think it's a really interesting product. It's a UI based product, it's very interesting, and we can drive a lot of value for developers. Debugging, auditing, monitoring is always a huge boost for developer productivity, and that's how I'm looking at this product and that's why very, very interested in the possibilities behind CCIP Explorer.
00:13:19.150 - 00:13:45.650, Speaker A: All right, thanks Rosh. You had actually a great second follow up one here around CCIP, so we'll go ahead and ask this one as well. CCIP has gone live on various blockchains over a relatively quick timeframe, and although they are all EVM chains, it was a staggered launch. What requirements or parameters are needed for them to go live on Mainnet? And is there a way for this to happen concurrently? And this question kind of also applies to other chainlink services such as data streams, automations and functions.
00:13:46.410 - 00:14:38.920, Speaker B: Yeah, great question. So I think this is something that we were very proud of at Smartcon to show the progress of CCIP since just mid July, in less than three months. So very impressive progress, which really shows how much demand there is for CCAP. We prioritize based on multiple factors, including chain activity, value flow scale, partnerships and other criteria. But above everything else, really going back to this very important principle, we take a security first approach when integrating on new chains, and this is something that we're going to continue doing as we expand to more EVM, non EVM, private and public chains in the future.
00:14:42.010 - 00:14:51.446, Speaker A: Kind of building off that question, let me follow up with one that I heard a little bit at Smartcon and I've seen kind of on social media. What's the difference between data feeds and data streams?
00:14:51.478 - 00:14:57.500, Speaker B: Kamal, do you want to bring event cream to ask this?
00:14:58.270 - 00:15:02.080, Speaker A: Yeah, yeah, absolutely. We can absolutely bring. Ben, are you around?
00:15:04.450 - 00:15:05.760, Speaker B: Yep, I'm here.
00:15:06.290 - 00:15:25.906, Speaker A: Hey, excellent. Yeah, so let's go ahead and transition to Ben since he's here with us. So again, thanks Kamal, for answering those questions. Let's bring our basically he's the Chainlink Labs product manager for data streams. Ben, maybe could you give us a brief introduction of who you are and what you do and then I'll circle back to that question. Sure.
00:15:26.088 - 00:15:47.290, Speaker C: In my past life, for most of my career, I was a derivatives trader and now I am the product manager at Chainlink Labs managing data streams, which is our new generation of low latency price oracles. Very happy to be here to be bringing real world assets and tradfi type operability on chain.
00:15:48.670 - 00:16:00.670, Speaker A: All right, well, let's go ahead and start with the first question then. As I said, I'll circle back to that one I asked a second ago. This is from backed by blocks. So how do you think data streams will impact hybrid smart contract apps?
00:16:02.050 - 00:17:02.734, Speaker C: Great question. I think that data streams will basically unleash a completely new generation of defi innovation, because the core premise of datastream is that we deliver fast, fresh price updates. So our legacy generation of oracles would push new price updates on chain either at discrete time intervals or what we call a heartbeat, or when we notice prices moving by a substantial amount in the tradfi world or on centralized exchanges. And that frequency is insufficient for the types of high frequency trading that are starting to take place on blockchains. Our new generation of data streams, oracles, produces new prices on a subsecond basis and delivers them on chain on a subsecond basis. So these are fast price updates that enable centralized like trading experiences and can power the applications that demand those kinds of experiences. And this product is built on top of our battle tested infrastructure, so it is secure and decentralized.
00:17:02.734 - 00:17:35.082, Speaker C: It's built on top of knops doms and our time tested OCR. And this entire aggregation stack is a credibly neutral infrastructure. There's no agent in this process that cares if prices go up or down. The entire stack prioritizes just clean, accurate, secure information. So we are credibly neutral. And best of all, data streams plays really nicely with Chainlink automation. So we know a lot of projects, spend a lot of time operating their keeper networks bringing off chain data on chain.
00:17:35.082 - 00:17:52.500, Speaker C: Well, Chainlink automation plays very well with data streams, so if your project needs a price update, we can recognize that on chain and pull a fresh price off chain on chain very quickly. So we're very excited to show how multiple chain link products can work together to power your application.
00:17:54.390 - 00:18:03.750, Speaker A: All right, so then I guess, circling back to the question I asked earlier, then, what's that easy explanation for people that you could share, maybe about the difference between data feeds and data streams?
00:18:04.490 - 00:18:15.020, Speaker C: It really comes down to different products for different use cases. So data feeds are ideal for lending use cases where you need fresh data on chain, but.
00:18:16.750 - 00:18:17.606, Speaker B: You might be willing.
00:18:17.638 - 00:18:47.750, Speaker C: To push it on chain yourself and give other people visibility into what the price is because the price is ultimately being used to secure collateral value and lending terms and things like that. Data streams is ideally suited for high frequency trading applications wherein you don't want the price to be known until it's actually served up on chain. You want some obscurity, and that's because you want to avoid opportunities where an affairs agent could front run you. So the core idea is different products for different use cases.
00:18:50.250 - 00:18:57.590, Speaker A: All right, well, thanks for that. Thanks for answering that question for me. Anything else, Ben, maybe you want to add before we circle back to Kamal?
00:18:58.810 - 00:19:17.150, Speaker C: We're thrilled to have launched data streams with GMX and be securing value on arbitram Mainnet, and we're continuing to see really strong demand from the market. If you are interested in data streams, especially integrating data streams into your application, please get in touch with us through datastreams.
00:19:18.050 - 00:19:31.074, Speaker A: All right, thank you so much, Ben. Really appreciate it. Thanks for stopping by. He is our first official guest on these product updates. I think it worked well, and hopefully sometime in the future, Ben, we'll have you back and get some more updates on what's happening with data streams. That'd be great.
00:19:31.112 - 00:19:32.094, Speaker C: Thanks, Rory. Thanks, Kamal.
00:19:32.142 - 00:19:52.202, Speaker A: Awesome, thank you. Perfect. Well, we'll go ahead and circle back to Kamal now and get back to some questions. This one actually has to do with automation, so kind of question, sort of number one here. This is from an anonymous submission. You seem very excited about automation 2.0. Can you really explain why?
00:19:52.256 - 00:20:39.206, Speaker B: Kamal? Yeah, thank you, Ben. Automation has been leading the verifiable automation market since we launched, and one thing that we've heard over and over again from developers is, well, we have this problem that on chain computation is very expensive and it's also pretty hard to predict. So if you're going to build a DaP and you don't know how much. You know, this is a big cost and you can't even predict it. Could you something about this, could we move some of that to automation? And that has been a very big ask from our community. And that's what automation 2.0 enables.
00:20:39.206 - 00:21:34.102, Speaker B: So you could take the same solidity code and then you move it off chain and it runs with OCR three on the dawns with super high security, very reliable. But then it reduces gas costs up to 90%. 90%, which means that either you now have only 10% of your previous cost, or for the same budget you can ten x the kind of computation that your DAP can process, which is really amazing. It's real game changer. So very excited that we were able to bring that to our community again. This is how this works. We listen to what our users are asking us, and then we deliver on that, and then we see them be successful.
00:21:34.102 - 00:22:20.394, Speaker B: The other big request that we received was about log triggers. So the ability for automation to react to log events emitted on chain, and that's what automation 2.0 now supports. And what this means for developers is that now they can think of any kind of flow and implement it in a very composable way. Because one component emits an event, another component listens to the event and then reacts to that event again. That's very composable. And the last thing that I'm also very proud of is that it's integrated seamlessly with data streams, and Ben just touched on it.
00:22:20.394 - 00:22:55.380, Speaker B: So if you're building an automation job, and you need access to low latency, high quality data, you can get it. It's natively integrated, and that's how a platform should work. It should be a one stop shop for developers. You got a connectivity need, we got you covered. And then you can focus on your business case. So that's another example of how those products work well together. So for all these reasons, very keen to see what developers are going to do with automation 2.0.
00:22:56.150 - 00:23:14.650, Speaker A: Great. Well, I think building on that, you mentioned a little bit around sort of this platform, so let's ask a question related to that. So is it possible to find out more about the decentralized services platform? Is it meant to be similar to AWS? And this was submitted by an anonymous submission.
00:23:15.310 - 00:24:10.614, Speaker B: Yeah, great question. So we're building these decentralized computing platform that connects web3 systems and web two systems at a high level. That's what Chainlink is. And data feeds, data streams, CCIP functions, automation, these are all primitives of this platform. But the vision is really to let developers design all the combination that they need of these primitives in a full self serve way. This is really how we unleash the full potential and creativity of our community so they can securely build those real world use cases utilizing the power of chains and the power of web two systems. And so this is what the slide that Sergey showed in his keynote at Smartcon, where you could see a visualization of how that could work.
00:24:10.614 - 00:24:54.220, Speaker B: And it's really inspiring to see this future state of the platform, which we're again, spending a lot of time thinking about and imagining how this could work for developers and how you could combine your own computation. You could design your own computation by combining those primitives in a very easy way. So it's an exciting vision, and I want to be able to build services like that as a developer. So this is the direction in which we're going to, and I think it's going to be a pretty incredible world where developers can implement verifiable apps in such an easy way.
00:24:55.950 - 00:25:03.850, Speaker A: All right, moving on to our next question. This one's from Dr. Reefer. Considering every bank will have its own chain, why not Chainlink?
00:25:05.490 - 00:25:45.500, Speaker B: Thank you, Dr. Reefer. Yeah, great question. Well, first, we really think there's a lot of value in connecting all these chains together securely and to web two systems, and then adding those services on top of this connectivity layer, very much like the vision that I just described for decentralized compute marketplace. So it's really a question of focus and focusing on solving this problem, which is very valuable and very hard problem to solve if we want to make it very easy for developers. And that's mainly why we're focusing on that. It's, again, a question of focus.
00:25:45.500 - 00:26:10.100, Speaker B: We're also chain agnostic. We work hand in hand with chains to connect them to web two and to the world with chain link. We're not making a single network. We're making this unbounded number, unlimited amount of these decentralized services. And again, this is getting back to this idea of the decentralized compute platform.
00:26:13.630 - 00:26:24.510, Speaker A: All right. Okay, here's a good one. You mentioned this before, earlier, Kamal. This is from anonymous submission. What is OCR 3.0, and how does it improve on the current version of OCR?
00:26:25.330 - 00:27:27.966, Speaker B: Yeah, great question. So OCR is the root engine that enables the smart contracts to interact with off chain data and computation and interconnects data and computation on different chains in a trust minimized way. That's the root of the whole system. And so OCR three, again, thanks to our amazing world class research team, is bringing very exciting improvements and features. So first on flexibility, it's a much more expressive plugin interface, which allows you to sequence generic outcomes, which then can, of course, be translated to reports, but also to a generic state. What this means is that you could create much more flexible workflows. And the second thing is that it has contiguous history, so you can maintain and pass state from all these different components.
00:27:27.966 - 00:28:29.880, Speaker B: So if you want to build something as generalized as the vision that I described with the decentralized compute platform, you need something that's very flexible and that can maintain state. And OCR three offers that. Then it has low latency, and even though it has stronger guarantees than OCR two, it actually maintains the same low latency. It also recovers faster under fault. So it's something that, as we go in the direction that Ben mentioned, it's going to be very important for us to keep the latency very low, and then it has very high throughput with report batching. So, getting back to the first question, I believe that you asked me on scalability, OCR three enables this high throughput by batching multiple reports into outcomes. So this new version of OCR, OCR three, is really a major update that will enable us to move toward the direction of that decentralized compute platform.
00:28:32.090 - 00:28:47.790, Speaker A: All right, thanks for taking the time to answer that one and moving on to kind of our final question of the day here. This is from an anonymous user or submitter. What was the difference between working with web3 teams? Or like, what is the difference between working with a web3 team and working with an institution, maybe like a bank?
00:28:48.610 - 00:30:55.442, Speaker B: Yeah, well, I think that we're very privileged to work with all the major big players in both world in Web three world in tradfi, we also work with a lot of startups. So I would say generally, and this is more of a startup versus large institution dichotomy, but web3 really moves at lightning speed and innovates, which makes sense because it's creating this new industry. And traditional institutions have longer timelines, which also makes sense because they have all these quadrillions of value to secure, and they've built systems that are doing that, and they're thinking about, okay, how do I get more of the other thing that I'm seeing the web3 space innovate in? And mostly, how do I tokenize my asset? How can I get into that game? And so, being in both worlds is really a fascinating way to compare both spaces, but also it puts us in a really interesting position because we can mix and match the innovation that web3 is bringing with the incredible momentum and amount of value secure that the tradfi world operates in. And when you can do that, then amazing things happen. Because with the tradfi world, they have all this momentum. They have people who really believe, internal champions who really believe we're very privileged to be working with honestly for so long and created these long lasting relationships. And we just keep working together on making this a reality and create those very sticky, long lasting relationships.
00:30:55.442 - 00:31:27.230, Speaker B: But then when it actually happens, then it makes a really big bang. And that's something we're very much looking forward to, bringing this vision to life. And again, we're super bullish on the tradfi adoption trajectory. We're seeing all the investments that they're making into asset tokenization. And yeah, Chainlink will link both worlds, pun intended.
00:31:28.450 - 00:31:39.540, Speaker A: All right, well, as we wrap things up, anything else you might want to add before we step away here, Kamal, and then get back to work making some of these things come to.
00:31:40.630 - 00:32:52.938, Speaker B: Well, you know, again, this was pretty incredible to see Smartcon. Barcelona was amazing. And as I was coming back from Smartcon, I was really thinking about zooming out at the big picture and thinking about how we're witnessing this once in a lifetime revolution, multi trillion dollar revolution towards verifiability. This is really something that resonated so much with everyone at Smartcon, but also just outside all my network was saying, hey, this verifiability thing really makes a lot of sense and consumers will demand it because it's superior. I think this is something that we're building towards a world where users are in control and there's this massive shift of power towards the people to have the tools to keep everyone around them accountable. And Chainlink is what is going to enable this transition. We're here to build the industry standard.
00:32:52.938 - 00:33:49.866, Speaker B: We have this huge advantage of already being a standard on data and then we're expanding into all these other very valuable markets and category. So that was very much an overwhelming feeling that was sinking in, especially when you could see the magnitude of the community and the impact. The other thing is, another thing I like to say is that shipping is great, but landing is better. What we've done is we've laid out our bets and we've worked hard to ship these bets and we're working hard with our users hand in hand to land these bets. And so the feeling was, okay, amazing vision. But now we're going to land this, right? We're going to land this thing. Also, I want to again, thank everybody who was able to attend or watch remotely.
00:33:49.866 - 00:34:19.830, Speaker B: Thank you everyone today for tuning in. Thank you for the amazing questions. I really enjoyed doing those things and just sharing more about all the exciting things that we've been doing and the things that we're going to keep doing. I personally enjoyed a lot meeting so many of you in Barcelona. It was really incredible to get all these positive energy. It's like fuel. It's like fuel that we're using, the whole team is going to use to keep executing on this plan.
00:34:19.830 - 00:34:25.750, Speaker B: So, yeah, again, thank you so much for your support and yeah, we'll get back to executing.
00:34:26.730 - 00:34:59.054, Speaker A: Thank you so much, Kamal, and thank you so much, Ben, for stopping by today and spending some time with us. Again, just another shout out, if you haven't checked it out, check out the new hackathon constellation that Chainlink is organizing. Chain link slash hackathon. It's really cool, kind of going in a different direction from previous ones. So check it out. Even if you're a non developer, a lot of times there can be an opportunity for you to find a home on a team, creating a website or kind of materials for them when they ultimately pitch their hopefully winning prize. So thanks again, everybody.
00:34:59.054 - 00:35:20.100, Speaker A: Definitely looking forward. Hopefully we'll do this again next time rolling into next quarter and yeah, appreciate it as well. Always remember to make sure before we do these, we will definitely put out a form to get everybody's questions. So I did see some questions in chat. Make sure you add those in for next time and we'll do our best to get to them. Thank you so much everybody. Hope you have a great rest of your day and rest your week and we'll chat again soon.

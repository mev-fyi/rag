00:00:00.170 - 00:00:14.814, Speaker A: Question actually, hold on 1 second. I'm going to go live on YouTube, right? Hello. Hello. Welcome everybody. And before you answer the question, let me actually set you up. Let me introduce you. All right, cool.
00:00:14.814 - 00:00:38.794, Speaker A: We are now live on YouTube. Welcome everybody. Thank you so much for being here. We are really excited for this workshop. We have Brech hope I'm pronouncing that right from the loop ring team. He's the chief architect to go over ZK roll ups and anything else he wants to go over from the loop ring platform. We're really excited to have them again.
00:00:38.794 - 00:01:00.320, Speaker A: These guys also have a bounty for using their projects. I believe it's three each at 1200. I think you can check the dev post to verify, but yeah, really excited that this is a really powerful tool. So with that, I will pass it over to you. Thank you so much for being here.
00:01:01.650 - 00:01:45.342, Speaker B: Thank you, Patrick. Let's start with. There was already a question for an in depth question about Zika rollups, but let me first, let's see. Share my desktop. Okay, let me first start with a small overview of what loop ring is and how we are like the main goal of the bounty is building an AmM on ZK roll ups on our new loop ring 3.6 release. So let me first give a small overview of what loop ring 3.6
00:01:45.342 - 00:02:47.922, Speaker B: is and how we can extend some basic functionality inside looping 3.6 to build richer functionality so things like Emms. So yeah, let's start with an overview what ZK roll ups are. So everybody kind of has an idea of what we are trying to do, what the specific problems are, and how we solve them. So let me first switch to the design doc, which has this Merkel speed format. So what we do is we batch a lot of transactions inside a block, very similar to like a normal blockchain, and all the transactions we do in the block work on this Merkel tree. So if you do a transfer, then you just move one balance over to another account and you approve that, just like in a normal way, you sign a transaction like you normally would.
00:02:47.922 - 00:03:26.762, Speaker B: And we update these variables using logic that's specifically written for zero knowledge proofs. So we have this fixed logic which makes it possible to generate proofs on top of them. But I'll get back to that later. So all the state that we change, store and actually use is stored in this Merkel tree. So I have this other image here that I found on the Internet is like how this actually works. Basically, like I said, it's a blockchain. There are a couple of blocks a block contains a number of transactions.
00:03:26.762 - 00:04:00.362, Speaker B: And these transactions change one merkle tree state to the other one. And these transactions, like the worker on the Merkel tree. Exactly. And these transactions are proven with a zero knowledge proof. So every time we submit new work on chain, we have to batch all these transactions together. This is done by the operator. The operator batches these transactions together and generates a very small proof for them.
00:04:00.362 - 00:04:55.494, Speaker B: So that's what provides us with the security and scalability we have. All this data, all this transaction data, all these signatures which need to be used to verify if the user has signed the transaction. We have also all these balances that are stored in the Merkle tree. Trading history is stored in the Merkle tree. All of that is stored in the Merkle tree. But on chain we just submit like this single Merkel route and this single proof, which makes sure that all these transactions were validly executed in a valid way so they are proven to be correctly even if we don't execute them directly on chain, which is like a very nice property to have. And it's as secure as ethereum because all these transactions, we also post some data for them on chain.
00:04:55.494 - 00:05:49.334, Speaker B: So one of the problems like this is the data availability problem. So all these states is stored in this Merkle tree, only this Merkel root is posted on chain. But to generate proofs for our system, so like for ZK rollup, you actually have to have all the state available because you have to have this Merkel proof. So you have to show that you know that some kind of data is available in the tree. So to be able to generate the proof, you need all this data. So ZK rollups solved that for all these transactions that were executed, you also post the resulting Merkel tree deltas on chain. So everybody can just recreate the Merkel tree just by looking at what's happening on Ethereum.
00:05:49.334 - 00:06:46.618, Speaker B: So if we wouldn't do that, then we are still sure that all the transactions were correctly executed, because we have this zero knowledge proof, but you don't really see what's happening on chain. So there could be like a transfer that's executed, but you don't really know that that transaction was included in a block because you can't see what's happening. So this posting of the data solves this problem. And if you posted data, then it's called the Zika rollup. If you don't post the data, then you kind of expect there to be some kind of third party or multiple parties that provides this data to users. So you can still see what's going on, but that's less secure because then you have to trust those external data providers. So that's called validium or ZK plasma or some similar names.
00:06:46.618 - 00:07:42.634, Speaker B: There's a lot of names for that. But if you post the data on chain and you have this zero knowledge proof, then it's a zero knowledge ZK roll up. Okay, so I hope that's kind of like a short overview of what Zika roll ups are. And yeah, this is one basic version we've been online with starting this year, but with 3.6 there are a lot of improvements that we have done which are very important, especially for the emms, but also very important for extending the functionality that we can do. So if we switch to the design doc quickly. So there's only a couple of transactions that we support directly in the Zika rollup.
00:07:42.634 - 00:08:21.934, Speaker B: So we have trades which is now limit orders and emms, just the swap logic for emms. We also have transfers, deposit withdrawals, account updates to set ZK roll up, specific public keys because we have special signature types that are very efficient. On layer two. We also have that EMM update which I'll talk later more about. But that's it. So that's kind of the basic functionality that's completely done on layer two. And now we are.
00:08:21.934 - 00:08:57.206, Speaker B: Well, the goal of the bounty is that we use this basic functionality, which is very efficient to make this more richer functionality. But first I'll talk a bit more about 3.6 and how 3.6 actually is needed to do all this stuff because our current version 3.1 is, well, it's much less flexible in that way. And I'll use this presentation to show why that is. So this is presentation that shows the differences between 3.1
00:08:57.206 - 00:10:02.042, Speaker B: and 3.6. And I'll elaborate on how this helps us to build more interesting features on top of that basic functionality. So first big change is currently there's like a high gas cost to get users on board because every user has to do an Ethereum transaction to make an account on the ZK roll up. This was fine if gas prices are low, but now it's a big problem because gas prices are so high and so getting on board on the Zika roll up is very expensive on 3.1. So on 3.6 we fixed that by two things so people don't have to explicitly onboard anymore to receive funds from other users. So that's basically as cheap as a normal transfer, but also users that want to create an account don't have to do an Ethereum transaction anymore, they just have to sign that they want to create an account.
00:10:02.042 - 00:10:51.482, Speaker B: And then we use that signature on chain to still cheaply set up their accounts with their own public keys. So it's only like around 5000 guests to completely set up a user inside the Zeke roll up. We also increased the capacity of a lot of stuff in our merkel tree because this Merkel tree I've shown before, it's important because that's where we need to store all of what we use inside the Zeke roll up. So we used to have just a million users and like 250 tokens, but now we have increased the capacity to like we now have 32 bit accounts. So like more than 4 billion users. More than 4 billion accounts that can be used. And we also use 16 bits for the tokens.
00:10:51.482 - 00:12:05.834, Speaker B: So we can have like this is a bit updated because now we can have more than 65,000 different tokens. So we have some limited support to even support things like non fungible tokens, nfts, as long as they don't need to have too much unique ids as we also do, like this custom deposit contract. So we store user funds in this external contract that exchanges can write themselves. And this external contract can provide extra functionality on top of the basics ones that are built into the protocol. So those funds used deposit by the users can be used in a productive ways. But you can also implement new token standards, flash loans, and lots of interesting stuff there as well. There's now lots of ways to authorize transactions.
00:12:05.834 - 00:12:40.970, Speaker B: So you can authorize transactions like most of the transactions. You can authorize with the ZK roll up specific signatures, which are very efficient. You can also authorize them with standard Ethereum signed messages, which are still pretty efficient. But like the benefit is that you don't even have to have this ZT roll up specific public keys. You can just write authorized transactions with your normal ethereum addresses. So that's another benefit. And you can also authorize transactions like with an Ethereum transaction.
00:12:40.970 - 00:13:46.962, Speaker B: So you can authorize, this is useful for contracts, basically for contracts, but these contracts can also be like general purpose functionality built on top of the exchange. So we call those agents. So if you have, you can have some additional logic inside a contract. And let's say for this contract just verifies if a user wants to do a transfer, checks the signature, and then this contract can authorize a transfer for that user using whatever on chain logic that's needed. So that's also one of the things that we'll use for the EMMs. So this EMM pool contract can authorize transactions for a specific user, and this user can authorize this contract to do that or not. It's kind of like similar to how you approve spending by a contract for an ERC 20 token.
00:13:46.962 - 00:14:21.342, Speaker B: Now you can authorize a contract to authorize these transactions for you. So that's kind of like one of the important things that we've added and that we actually already use in multiple ways. We have these fast withdrawals which work on top of that, and now these Emm pools as well. So that's kind of an important feature. So 3.6 also introduces universal blocks. So in 3.1
00:14:21.342 - 00:16:02.240, Speaker B: we kind of like optimized everything as much as possible because, well, zero knowledge proof generation was very expensive and we didn't really know much too much about how it would actually be used. So we tried to reduce cost as much as possible and we had less like these different circuits for every transaction type, which makes, in theory that makes things less expensive, but it also makes things more complicated. And depending on how many transactions we actually have to do, it can actually make things more expensive. Because if you don't have enough transactions to fill up a complete block, then that's a problem because the bigger the blocks we can commit on chain, the lower the cost will be. Even if there's some extra costs, because the universal block is bigger and more expensive to generate the proof with, it's kind of still be in practice, much less like a big improvement in cost because we can just put all the different transaction size inside the single block and just submit a single block on chain verification for all these blocks. So we can even verify the proof in a very efficient manner. Like I said, it's also pretty important because it just makes things a lot more easier to do because we can just put all the different transactions after each other instead of having to put transactions in the correct block, and then there could be dependencies between those blocks and it just makes the life of the operator much more difficult to keep track of all that stuff.
00:16:02.240 - 00:17:21.894, Speaker B: Six yeah, because we have now this universal blocks, we can also just add dummy blocks, dummy transactions to bat a block. So we don't really have to add actual dummy transactions that don't have state changes directly. But now they are nicely like no operations, which are all zero data on chain. So it's also a bit more cheaply. So yeah, fast withdrawals, not important for now, but yeah, it's building on top of the agent functionality, receipts also like one of the things that we use the data availability data for. So because we have like this, because we have post all this data for these transactions in the block, it's not only useful for solving the data availability problem because we have the data on chain, we can also use this data to read it on layer one and then use that in interesting ways. So that's one of the things we always will also use for the AmM pool.
00:17:21.894 - 00:18:29.534, Speaker B: So this data is on chain and we will verify if these transactions that were included in the block were actually the ones that we expected to be included in the block with whatever on chain logic that we need. So yeah, the more flexible authorization, I think I already said so lots of ways to actually do transactions, authorize transactions for users in the roll up. Also a couple of trading stuff, so specific takers for orders. Also a special way for transfers to be authenticated. So there's a way to set up transfers that need to be signed by two keys instead of just the one stored in the account, which can be used in a couple of interesting ways. Also like the 212. So like depositing and withdrawing, it's kind of like you can go from layer one to layer two in any direction in any way you want.
00:18:29.534 - 00:19:27.410, Speaker B: So from layer two to whatever address on layer one and from any address on layer one to any address on layer two. So pretty flexible there as well. Okay, so I think that's kind of like the short overview of 3.6. So I guess lots of things to think about. But now to make it a bit more concrete, I'll start explaining more about how we built the amm pool on top of that functionality that you just saw. But first, I'll first explain what we've built in for the emms inside the protocol so you know what's possible there. And then I'll check if there are any questions so I don't go too fast or too slow.
00:19:27.410 - 00:20:02.602, Speaker B: So what we built inside the protocol is like the balancer formula. So this is the curve paper, which kind of like a nice introduction about the different curves that we can follow. So this one is the uniswap formula. That's not the one. So this is the uniswap formula. So it's like just x times y is some constant. And this constant is kind of like you can implicitly derive it from the current balances inside the account.
00:20:02.602 - 00:21:07.522, Speaker B: So this is quite kind of like very elegant formula because you don't really have to store any data for it, you just have the balances and then you basically have defined the curve already. But the swap logic, like the swap logic that we use inside the circuit to do efficient swaps, is the balancer one. So it's the balance times to the power of some weight. Then the product of all these different tokens in the pools is also some kind of constant, which is nice to have, because there's like this single parameter that this depends on. So this is one parameter that you can set inside the EMM pool, or we have a ZK rob transactions to set this weight. And then once you've enabled this weight, then this kind of automatically enables for the account. So it's kind of like a very elegant way.
00:21:07.522 - 00:22:15.554, Speaker B: And also, the swap formula only depends on the ratio of the weights between those two tokens. So even though there can be multiple tokens inside the pool, like more than two, the swap logic is still very simple, because it doesn't care about what the other weights are of the different tokens. Like ten tokens in pool, doesn't matter what the other eight weights are of the other eight tokens. It only depends on the two tokens you are actually trading. So that's kind of important to have, because otherwise it would greatly complicate the swap logic we have to do, because we kind of don't have very the logic that we need to implement, and the circuits is kind of like fixed, and you can't do dynamic loops or anything like that. So this way we just have to depend on two tokens in all cases, and it's kind of like nicely works out. So I'll have to jump here to the actual EMM update transaction.
00:22:15.554 - 00:23:37.810, Speaker B: So this is the transaction you can use to update the weights inside the Merkel tree and also enable EMM trades for that account. So if you set the EMM weight to a non zero value, then implicitly you also enabled EMM for that token. So if you have two tokens that have a non zero token weight, then the operator can create orders for that account, as long as the resulting state of doing that trade matches the balancer curve. So instead of defining some other order type, or however you can enable it, we basically generate standard limit orders for the AMM account. And the only thing that we have to check extra is if this balance circle curve is still valid. In that way, it's kind of like very elegantly integrated into our trading circuit, because everything remains the same. We just have this like this single extra check if this remains valid.
00:23:37.810 - 00:24:36.034, Speaker B: Okay, let me see if there's any questions. Okay, yeah, so the first question was for privacy on Zika rollup level. So our Zika rollup doesn't have any privacy because we have to publish all the deltas on chain for the data availability problem. To solve that, you have to anonymize that data as well. So you have to publish these extra hashes, like you have to publish hashes on chain, which you can then fill the miracle tree with. And you also kind of need recursive snarks because you kind of have to validate ZK proof inside a ZK proof. So that's kind of like pretty expensive now, but people are making a lot of progress there.
00:24:36.034 - 00:25:29.510, Speaker B: So there's like Aztec that will have this ZK ZK roll up type of transactions, which will still be more expensive because the amount of data that you have to put on chain will be larger. So now we can have this compressed amount of data. So if you do a simple transfer, then we can check here the design doc. So here is the list of the actual data that we push on chain for this transfer. And as you can see, it's done in a very compressed way. So instead of posting ethereum addresses, we only post short ids. Instead of doing token addresses, also just a short id, the actual amount.
00:25:29.510 - 00:26:23.974, Speaker B: Instead of using a simple 32 un, we compress it to like a decimal float to three bytes fee payments as well. Just two bytes for the token, two bytes for the actual amount. So all this stuff is very compressed. So we can do like all the things that we need is just 20 bytes. And we know exactly what happened in the Merkel tree. If you have additional privacy on that, then there's some extra overhead for that, especially with these high gas costs. All the data that you push on chain just makes things a lot more expensive, even though like call data, you only post it in call data and it's pretty inexpensive, like 16 bytes for a non zero byte value.
00:26:23.974 - 00:27:00.900, Speaker B: It still adds up because it's your main cost that you get on chain. So it also reduces scalability and pretty greatly increases cost. So hopefully things progress like ethereum 2.0 will have more data available. ZK knowledge proofs are getting better, so recurface narcs will be pretty common. So I think we'll be seeing more of that pretty soon. Prediction markets so does this support prediction markets is a question.
00:27:00.900 - 00:27:52.180, Speaker B: So yeah, it does support it, but only if you tokenize it. So if you can get the token in the exchange. So then it's just like a simple transfer of that token or a simple swap of that token. But otherwise we are fixed to this specific functionality inside the roll up. And if you want this richer functionality on top of it, then you still need to do some more stuff on chain. So we can't go too wild yet in the roll up. And for the rest, I'll make sure that everything I've used in this presentation, I'll list it somewhere so you can check it later if you want to.
00:27:52.180 - 00:28:52.354, Speaker B: Okay, I think that's all the questions. So let's jump into the actual AMM implementation because it's kind of like pretty specific how you would implement it. I've written this demo implementation, which already does quite a lot, so you don't have to worry about all this loop ring and Zeker roll up specific functionality. Okay, so first things first. So I said how we can extend the functionality of the Zika roll up in interesting ways. So how we do that is to do extra callbacks on top of the block. So if we have a block that does a couple of transactions, we verify if those transactions are valid.
00:28:52.354 - 00:30:14.610, Speaker B: So let me try to paint this. So it's kind of like, let's hope this works. So if we have this block, there's a large block, and this block contains three transactions. So one of the things that we have to be able to support for Amm pools is like depositing multiple tokens. These tokens need to be supported in one group, because if this pool has three tokens, then a user wants to deposit these three tokens inside the pool contract, and then he mints like some kind of liquidity token. Because we have to make sure that the Amm pool is an honest way, so people can just cheat in some way to get more or less liquidity tokens. Depending on how a user deposited funds on the empom pool, we need to make sure that these three transactions which do the deposits are actually done in a group, and we can accurately calculate how many liquidity tokens the user gets for this deposit, for this deposit, for this join in the pool.
00:30:14.610 - 00:31:39.526, Speaker B: So inside the protocol we don't have any way to force this link between the transactions. And also inside the protocol, we don't have any way to do this minting logic. So this is quite specific for the EMM, like the type of EMM that we want to support. If you just want to support simple uniswap or balancer pool, or one of these new ones that are coming out, maybe that use price oracles or even this stable credit that's coming out now. So this is kind of like pretty much like we don't want to bake it too much into the protocol because things are changing rapidly inside these emms. So this logic, we want to enforce this logic in a smart contract because it's much easier for people to write smart contracts on top of the basic protocol instead of having to write these zero knowledge circuits, which are very hard to write. And it's also much like people, people can write smart contracts, but not a lot of people can write circuits.
00:31:39.526 - 00:32:19.590, Speaker B: So the way that's done then in the EMM pool is we check if all these transactions are done in this sequence. So there's this callback, we check, okay, this is the pool contract. And this pool contract, we check, okay, this user has deposited this much. The user has deposited this much. The user has deposited this much. Okay, now I know I have verified this and now I will mint these liquidity tokens and then I will make sure that this block that was submitted is actually also submitted on the exchange contract. So it's kind of like an atomic operation.
00:32:19.590 - 00:33:04.514, Speaker B: The operator submits this block on chain. We have this additional constraints that are applied on top of this block, and then this block is immediately as well. It's submitted on the exchange contract, it's verified and it's final. So we don't have any reverts that are possible, which is kind of nice to have and important to do this kind of functionality. Because if you have reverts, then everything just gets a lot more complicated because in our current version you can first commit a block and then later prove it. But then you have all this logic that you may have done on layer one, but then you have to revert. So it's just much harder.
00:33:04.514 - 00:33:53.062, Speaker B: So by having this atomic operation, that's possible. The block submission, direct verification of the proof and the state is final. We also know that these liquidity tokens can be minted without the block actually being valid and everything being correct. So one of the interesting things here as well is that the EMM pool also has to authorize some transactions. And some of that can also depend on the state. Let's say there's another. Most of the times it's like, let's add it to the end, but this is like an EMM update event.
00:33:53.062 - 00:34:45.234, Speaker B: So the pool wants to authorize a weight change or whatever. So this transaction of the pool, this transaction isn't yet authorized on the exchange contractor. So before when the operator is creating this block, this transaction hasn't yet been authorized. But because these extra constraints need to be validated inside this pool contract, we run over these transactions. And then when we see that all things are valid, then we authorize this transaction as well. So this uses the new agent functionality of 3.6. So we authorize this transaction by sending a transaction hash to the exchange contract.
00:34:45.234 - 00:35:51.486, Speaker B: So this is like okay, this goes to the exchange and now everything is valid. This kind of like okay, you can do this transaction, and once this callback has exited. So now this block is valid for the AmM pool contract, then we actually submit it to the exchange as well. And then this exchange contract checks for this transaction. Like okay, was this transaction validated? And because we've just validated it like authorized it, now the block can actually be submitted. So this also forces the operator to do these checks in the pool contract. Because if this transaction would already be authorized in some other manner, then the operator could just not call all this enforcement logic and just do these transfers to the MM pool and nobody would see what's going on.
00:35:51.486 - 00:36:59.390, Speaker B: And users would just deposit to the MM pool, but they wouldn't have their minted liquidity tokens. So that's basically how this richer functionality is implemented on the basic functionality inside the roll up. So you can even say these like the, like these simple transactions type that you support. You could even call them like ZK pre compiles. You have some pre compiles that you can use on solidity that kind of makes things much more cheaply than if you would have to implement all that stuff directly yourself. In solidity, there's like these pre compiles that make certain operations much cheaper than they would be otherwise. So you could say that these transactions that we support in the ZK roll up are kind of have the same purpose.
00:36:59.390 - 00:38:23.962, Speaker B: So if you can use them like a pre compiled, then you can have a lot of gains. Because even if we wouldn't support spot trades directly inside the circuit, you can still emulate them with just normal transfers inside an agent contract. And so the agent contract would just verify the orders of the users and then do basic transfers between those users to do a trade. The benefit of course of doing it completely inside the roll up is that you can still do it much more efficiently because you don't have to use layer one at all. But the benefit of doing it in an agent contract is it's a lot more flexible. So people can just write whatever logic they want in smart contracts like they are used to, and then they use these ZK pre compiles to optimize it in the significant ways. Because even though these general operations are pretty specific, you can still use them very generally because things like replay protection or fee payments and all the storage you would always have to load and store on chain.
00:38:23.962 - 00:39:07.270, Speaker B: All of that, you can depend on the layer two stuff to do that for you. So that's kind of like very nice to have. So most times, just making everything stateless is already a big game because most costs are like storage costs. And if you use this model, then everything is stateless. You just have to post the data on chain that you need, verify it, and then depend on the layer two to actually store everything that you'll need in the future. Okay, let's see if there are any questions. Okay, no.
00:39:07.270 - 00:39:17.520, Speaker B: So I'll now go over the code a bit. Somebody raised their hand. Is there a question.
00:39:19.810 - 00:39:35.410, Speaker A: Mark? If you got a question, if you could type it into the questions chat, that would be greater.
00:39:40.570 - 00:40:38.266, Speaker B: Probably we will be open sourcing our relayer. Well, not completely. So we'll probably open source like a very light version for only transfers. But the very complex stuff like the order matching will, will probably keep closed source for now. Okay, so I'll start running over some of the codes where you can add some functionality to start at the beginning. This is the place where blocks are submitted, and this is where the block finally goes through the exchange contract. So this is where this additional constraints of the transactions goes on.
00:40:38.266 - 00:41:24.166, Speaker B: So some callbacks can be specified here as well. And these callbacks are just called. So they just say like, okay, contracts look at this block, at this transaction, and there are some extra data, like auxiliary data that can be used to do that. And that's exactly what currently the EMM pool does. So this is like this callback that's called on the EMM pool. So you already this block the transaction id and transaction index and auxiliary data. So the first thing we do is this check.
00:41:24.166 - 00:42:24.540, Speaker B: So this callback can only be called by the exchange owner. So we have to make sure that not everybody can just call this function because otherwise some state changes can be done on this contract as well. And you can lie about which blocks will actually be submitted. So if you would be able to submit fake blocks here, then this would not work correctly. So the auxiliary data here is just a list of all the pool transactions that need to be executed. So a pool transaction is just a join and an exit of the pool. And a join and an exit is just grouped together deposits to this Amm pool and a grouped exit is just token transfers from the pool to the user's account.
00:42:24.540 - 00:43:20.938, Speaker B: And there's two ways that you can do it now in this demo version. So you can deposit from layer one or layer two and you can also exit to layer one or layer two. So what this does is these funds of the AmM pool are stored in the account on layer two of the. Okay, is there a question? Otherwise, I'll wait for the question. It not immediately. So I'll continue. For now, the funds of the pool need to be on layer two because otherwise we won't have any scalability benefits.
00:43:20.938 - 00:44:41.270, Speaker B: So people can just trade on layer two like they would like with limit orders. So if people deposit on layer one to this pool contract, then eventually we'll also have to deposit like the funds stored in this contract to layer two as well. The other option is that users already have their funds on layer two and so the only thing they have to do is transfer their funds from their layer two account to the AMM pools layer two account on layer two as well. So both options are available here and yeah, so yeah, first we just check if all the data as we expect it to. There's some extra utility functions on the block, so you can easily read the block header and all the transactions as well. In this case, let me go to join. If the join is like, yeah, so if the join is a transfer, then we read the transfer here on the specific transaction index in the block and then we verify some data and then we mint the tokens.
00:44:41.270 - 00:45:23.998, Speaker B: But I'll get back to that later. So yeah, the first thing we have to do is an AMM update because on layer one we don't really know much about the AMM pool. So to mint and burn the correct number of liquidity tokens, we have to know the balances of the EMM account on layer two. And we don't have that data available directly on layer one. So the first thing we have to do is pull the balances from the AMM account from layer two to layer one. And for that we can use the AMM account updates. So AMM updates.
00:45:23.998 - 00:46:17.190, Speaker B: So one thing this does is it not only is able to set the token weight of the token, it's also able to set like the fee that's expected, but it's not very important. But the important thing here is that it also pulls the balance from layer two to layer one in the data availability data, so we can read it on layer one at that specific time. So by doing this EMM update first, we know exactly what the balance in the account is and we can use it to make sure everything works correctly. So I'll just jump to this process. EMM updates function. So this is just what's happening here. So for every token, for all the tokens in the pool, we read the AMM update.
00:46:17.190 - 00:47:09.510, Speaker B: So we know what the balance is. So that's written here. So we read the data from the block and here's the balance. And then we store the balance locally so we can work on it for processing all the joints and exits so we don't have to get it from layer two to layer one every time. We just keep a cached copy here and we work on these balances for the next transaction. And here is also where we actually approve the transaction because the operator included this EMM update transaction. But of course we don't want the operator to be able to actually authorize transactions for this pool account.
00:47:09.510 - 00:47:48.734, Speaker B: So this transaction is only authorized when this callback is actually executed. So we know what I explained on the diagram. So yeah, this is like, okay, this transaction was included, but now this callback is called which verifies these transactions. And then, okay, I've seen it, they are as expected. And then this authorization is done to the exchange. And this is exactly what's happening here. So this is authorization through the exchange contract.
00:47:48.734 - 00:48:24.430, Speaker B: So this EMM update transaction is actually valid and can be included in the block. Otherwise, if you don't do this authorization, then this EMM update would be invalid because it wouldn't be authorized. Okay, so this is like the start. At this point, we know what the balances are on layer two. We've set the weights, we've set the fee that's expected. And now we will process all the actual operations that we need to do. So the joins and the exits.
00:48:24.430 - 00:49:19.600, Speaker B: So let's go to the joins. Okay, there's currently two ways to authorize this join by a user. So the user can submit like an approval on chain and then it gets added to this queue. So if it's done that way, then we expect the funds to come from layer one currently in this demo application. Otherwise the user can just sign a message and then we verify if the user wants to join. So if a signature is private, we verify if the user actually wants to join. And then later we will actually approve this transfer from the user to the pool account.
00:49:19.600 - 00:49:55.142, Speaker B: So it's kind of like a similar way. So the user only authorizes this join at this point. And again, because this callback needs to be called for this join to be valid and all the data of this join to be valid as well. We just check if everything was processed correctly by the operator. Because at this point the operator can do whatever it wants. But here we check if the transfer was actually done as expected. Once that's the case, it's like, okay, everything is valid.
00:49:55.142 - 00:51:07.262, Speaker B: Now approve this transfer from the account to the user and everything is okay. We update the balance inside the EMM account so we know how to correctly mint tokens in the future. And then at this point, we actually mint the tokens for the user for the amounts that he deposited. So at this point, the minting is quite simple, as in they are not actual tokens, but the minted liquidity tokens are just balances on this contract. So they are automatically locked for exits. It's the same, well, it's slightly different because at this point, users, if you exit, then it's the AMM pool that needs to authorize transfers from the AMM pool to the user, instead of the user having to authorize transfers to the AMM pool. But it's kind of still the same idea because the user still has to authorize that he wants to exit the pool under some conditions.
00:51:07.262 - 00:52:13.698, Speaker B: So the user still has to authorize this exit by an on chain transaction or by providing a signature, and then it's mostly the same id. So the exit is approved now from the AMM pool to the user if it's on layer two, if it's on layer one. If the user orcast is next on layer one, then we just update the balances here in this pool, and then the user can withdraw from this pool contract directly or however you would like to implement it. So one of the things that I forgot to mention is like this approved transaction. This is possible because this contract is the owner of the MM account on layer two. So this contract can, by design, doesn't need any other functionality. This contract can approve transactions for this account because it's the owner for the joints.
00:52:13.698 - 00:53:09.990, Speaker B: It's kind of like still a special case because now this contract also approves a transaction from the owner of the account. So for this to be possible, we have to use the agent functionality. So the agent needs to approve this AmM pool contract to approve transactions from its account. So that's kind of like another interesting way that all these things come together with the agents, with the contract, approvals of transactions and signatures and all that stuff. Let's see how much time is. Time is almost up. But once we've included all these transactions, all the joints, all the exits, then there's still one possibility.
00:53:09.990 - 00:54:06.854, Speaker B: So if everybody enters and exits on layer two, then the total amount of balances inside the roll up remains the same and we don't have to deposit or withdraw actual funds from or to layer one. Diffusers deposit and withdraw from or to layer one. Then the amount of funds available in the account, the total roll up changes. So we have to actually do deposits to the exchange contract or do withdrawals from the exchange contract. So that's what's done here because we just keep track of all the balances in the account. And like the expected ones, we know exactly like, okay, this user has deposited ten eth on ray one. Okay, this ten ETH is still stored in this contract.
00:54:06.854 - 00:54:47.430, Speaker B: But now we have to actually deposit this ten eth to layer two to the EMM account. So it can actually be used for trading by the users on layer two. So that's one of the things that's just what's done here. So if we wouldn't support transfers from or to layer one, then this would be unnecessary. At the end we still do another AMM update. And that's because there's an additional trick that you can use so we don't have to. Well, if you have a join, then there's still a signature needed on this pool contract.
00:54:47.430 - 00:55:55.870, Speaker B: So we have kind of like this locking mechanism where you are unable to transfer funds to the AMM account on layer two if the amm weight is non zero. Because of that, we can use these AMM updates as kind of a lock for transfers. So we first disable the weights, so we set them to zero. And at that point we can do transfers to the AMM account. And then once everything is done again, we reset the weights again to their non zero actual values. And then this disables transfers again and enables trades. So this kind of locks in all the transfers that happen to the AML count between these operations, which is kind of like a nice thing to have because let's say the user just signs a transfer like they normally would with their ZK roll up public keys.
00:55:55.870 - 00:56:53.762, Speaker B: Then if we wouldn't lock it, then we could just use that transfer to do the transfer to the Amam account. But the user wouldn't have any liquidity tokens. So basically the user would have lost all his funds. So by having this locking mechanism where the transfer can only happen between these transactions and these transactions, we force the operator to actually do them inside here. And because they are forced to be done between those two, we can also verify them here as well on chain. So that's kind of like another neat trick that we can use to make things more efficient and user friendly. Okay, I guess that's where I leave, I'll leave things.
00:56:53.762 - 00:58:11.802, Speaker B: So this quite heavy contract, but yeah, so the goal is of course to do something interesting with it. So either really do like a balancer AmM pools, or update the weights, like the weights that you can set here in the AMM updates, they are just now fixed token weights, so not much going on there. So you can use oracles chainlink to optimize these token rates in various ways or things like that. So if you want to work on it, then I would say this is where you will spend most of your time to add functionality. You don't have to worry too much about the other stuff like the withdrawing, which is just there for safety. So because users can deposit funds to this AMM account, we also have to make sure that users can get their funds out again in a censorship resistant way. And then there's like this test, EMm pool test, that just very simple test.
00:58:11.802 - 00:58:53.160, Speaker B: It just uses the EMM pool, just the user just deposits to it. There's like a single trade on the EMM pool and then the users partly gets his money back out. So it's like a simple test, but I would say just mainly focus first on getting the smart contract ready and then if you actually want to test it, you can use this. But yeah, just let me know if there are any problems with getting it running because I think it won't be that easy to update everything as needed.
00:58:54.970 - 00:59:10.814, Speaker A: Awesome. Well, thank you so much. This was a very informative workshop here. Definitely a heavy subject, definitely a lot of really interesting pieces going here, but yeah, thank you so much. And with that, we are at time, so we will roll out. Appreciate it.
00:59:10.932 - 00:59:11.550, Speaker B: Thanks.
00:59:11.700 - 00:59:15.610, Speaker A: All right, bye everybody. Bye.

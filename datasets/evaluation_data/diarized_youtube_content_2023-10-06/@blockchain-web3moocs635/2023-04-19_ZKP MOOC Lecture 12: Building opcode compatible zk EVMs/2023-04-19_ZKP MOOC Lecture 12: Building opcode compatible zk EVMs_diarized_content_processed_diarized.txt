00:00:03.820 - 00:00:37.892, Speaker A: Hello, I'm Jordy Violina. I'm the technical lead at Polygon ZKBM. And in today's lecture I'm going to explain a little bit how ZK rollapse works. And we are going to explain also how the ZK proof is generated in this ZK rollapse. This is the core piece and the most differential piece that's in the CK roll ups. So let's start first in a brief introduction in how a roll up works. A roll up is like a blockchain.
00:00:37.892 - 00:01:28.990, Speaker A: So it's like any other blockchain and has the same properties as the blockchain, but without the consensus layer. In general, we are leveraging this consensus layer on top of another layer, one most of the cases Ethereum. So our roll up you can understand, it's a chain that has a state represented by a state root. In this state you can have the balances of the account, you can have the smart contracts, the storage of those smart contracts. And once in a while we collect a set of transactions and we process these transactions. So we go from one state, we process these transactions deterministically and we go to the next state. This is how it works and this happens.
00:01:28.990 - 00:02:16.570, Speaker A: So we are generating these blocks in L2s, we call them batches, to distinguish from the layer one blocks. So let's see how a real ZK EBM works. In the case of the polygon, ZKBM works. So if you are a user and you want to send transactions to the blockchain, what you are going to do, instead of broadcasting that in a peer to peer network, what you're going to do is you are going to send that to a sequencer. If the sequencer is centralized, that means that you are going to send these transactions directly to the sequencer. The sequencer will include these transactions in one of the blocks. It's going to generate blocks in generally really quite fast.
00:02:16.570 - 00:03:20.264, Speaker A: And then once this sequencer decides that your transaction is inside, it's going to return you the new block with your transaction and then you will have what we call it a trusted estate. Because this is centralized, you need to trust the sequencer because the sequencer, they can do other things. But if you trust the sequencer, this transaction, you can consider that's final. Then this sequencer once in a while, in general, when a full batch, so when it has a lot of transactions or after a timeout, if there is not many transactions in the roll up, then it sends these transactions on chain. So they put these transactions in call data in a normal ethereum transaction. And then these transactions are sended on chain. At this point, the transactions are final and trustless.
00:03:20.264 - 00:04:02.636, Speaker A: So nobody can modify these transactions. Everybody know what transactions are going to be executed and you can compute the newest state. So anybody can compute this new state because they have these transactions, these transactions execute deterministically on top of the previous batch. So anybody can now know what's a new state, but the blockchain does not know this state. So in this estate, you know for sure that your transaction is going to be executed and you know for sure what's going to be the newest state. But the only thing that you cannot do is withdraw funds. Because in order to withdraw funds, the blockchain needs to know what's this state.
00:04:02.636 - 00:04:52.332, Speaker A: You need to know if you make a transaction for exit, for example, and recovering. But in this case, the blockchain, the layer one does not process all these transactions. Actually processing these transactions in a naive way, just in solidity would be really expensive and not viable. So what we do in order to consolidate this estate, in order to create this trustlet exclusive estate and put this estate on chain here there is two techniques. The optimistic roll ups. What they do is they just put somebody puts this estate and then there is a challenging period because this estate can be bad. And then there is a challenging period where you can decide that this estate is good or bad.
00:04:52.332 - 00:05:49.164, Speaker A: In general, this challenging period is about one week. Or what you can do, and this is what the ZK rollabs do, is just put a validity proof that this estate is correct. So it's a validity proof that prove that the execution of these transactions on top of this block is exactly this state route. And this can be done really fast. You can compute one of these proofs in minutes. And then when this proof is verified on chain, then you are able to withdraw the funds or maybe move the funds to other roll ups or just leave the roll up. So you see that the core piece is this proverb you need to prove what you need to prove here.
00:05:49.164 - 00:06:28.020, Speaker A: So this proof is you have a current state of the state route. You have a set of transactions that you want to process and you want to compute deterministically this new state route. So you want to prove that these transactions goes to this new estate route. And so the circuit is something that's taking transactions and executing those transactions. In the case of SDKBM, these transactions are normal. Ethereum transactions can be normal, transfers can be deploying a smart contract, can be executing function in the smart contract. And they need to behave.
00:06:28.020 - 00:07:16.680, Speaker A: The behavior should be exactly the same that what Ethereum does. If it's executing a smart contract and this smart contract has some opcodes, you need to execute the opcodes the same way that Ethereum does. That's what ZKBM means. That's acting exactly the same way that Ethereum does. So how we build this proof, if we try to build this proof in a naive way, for example, we try to build that in circum. A naive way would be okay, let's put for take just the part for example of executing some opcode. Then you would put all the opcodes in parallel and you would have to repeat all the opcodes every time.
00:07:16.680 - 00:07:48.384, Speaker A: So for every time that you execute one of the opcodes. So as you can see, each opcode can be really big. Imagine a ketchup opcode. And if you want to repeat that many times then this would be like impossible, not possible. The number of constraints that you would need if you trying to build that in circum would be thousands of trillions. So it would be really impossible. So here the trick is mainly working with polynomials.
00:07:48.384 - 00:08:45.944, Speaker A: The cool thing of generating validity proof with polynomials or zero knowledge proof with polynomials is that polynomials allows us to prove many constraints at a time. So a polynomial constraint, actually you can understand a polynomial as a set of values. And if this polynomial is of degree two to the 23, that means that you have a million values and then a constraint. For example a polynomial a times polynomial b is equal polynomial c. That would be constraint that you can add with a single constraint. Actually you are proving 8 million constraints at a time. So that's why this working with polynomials is really interesting because allows us to do millions of constraints in parallel in order to do that.
00:08:45.944 - 00:09:49.420, Speaker A: And this is the main strategy that we are following here is the idea is with these polynomial constraints. With the polynomial constraints allows us to build state machines because you can put constraints of if we understand that polynomials are columns and each of the values are rows, the idea is that you can define relationship between each rows. So and if you can define this relationship between each rows, then you can create the state machines. If you can create the state machines, that means that you can create a processor. And then if you create a processor, you can create a program that's running on top of this processor. And if this program is emulating the EBM, then you will have a proof that actually is proving the EBM execution. This is the main strategy that we are following to build the Zk EBM.
00:09:49.420 - 00:10:40.260, Speaker A: Let's start to deepen how this proof is generated. And let's start by the bottom layer. We call it the hardware layer because the one is morsed in the bottom. And it's how we build these circuits with polynomials, how we define these polynomial constraints or polynomial identities. In order to build a circuit to work in this layer, we created a language named polynomial identity language that will help us to write these circuits. So in order to see what we can do with language, let's start with a simple example. It would be the hello world of this example.
00:10:40.260 - 00:11:29.486, Speaker A: That's the Fibonacci series. So let's define the problem. The problem is, imagine that you have a number. So you want to prove that if you have a number in a specific prime field. I want to prove that I know two numbers that two numbers that when I apply the Fibonacci series for, let's say 1024 times, then I get to this number. That would be an example. If you want to write that in circum in normal, then that would be relatively easy, just a normal loop of 1024.
00:11:29.486 - 00:12:11.482, Speaker A: And then we just define these 1024 constraints, one for each step on the series. Okay, but we want to do that in parallel. We want to do that with polynomials. Okay, so here the strategy is that what we're going to have is we are going to define two committed polynomials. In this case is a before last polynomial and a last polynomial. And these polynomials are going to be of degree 1024. And we want to define a relationship, a polynomial relationship that follows these Fibonacci series.
00:12:11.482 - 00:13:13.902, Speaker A: Okay, so the relationship that we want to express is this one. So the idea is that we want to see that, for example, that ab for last is a last. And then we want to define that the a last on the next line is going to be the ab for last and a last in the previous line. So we define here, we define this with these polynomials identities here. Sorry, the wx here means the next row. Okay, so here what's saying is that a before last of the next row is a last of the current row, and a last of the next row is going to be a before last of the preview of the next row is going to be ab for last plus a last of the current row. So if we want to define that in pill, then we would do it this way.
00:13:13.902 - 00:14:07.262, Speaker A: Mainly we say here that a before last minus is equal to a last. And here we define that a last is equal to a before last plus a last. The problem of doing this is that the relationships of these polynomials, we can define these polynomials between one value and the next value from one row and the next row. But the problem is that this constraint must also fulfill when we go around the relationship between the last and the first, because this is a cyclic relationship must also follow. And in this case, if I am adding these two numbers, if I am adding these last two numbers, it's not going to be one. So the idea is that I don't want to generate a constraint for the last line. So in order to do that, we define another polynomial.
00:14:07.262 - 00:14:35.994, Speaker A: In this case is last. This polynomial is not generated every time. We call it a precomputed polynomial or a constant polynomial. So a polynomial that the proverb and the verifier knows. So it's the same for all the instances, and it's going to be a polynomial with it's going to be zero in all the rows except in the last row. That's going to be one. And then we modify the pill so that we say that I minus last.
00:14:35.994 - 00:15:15.606, Speaker A: So you see that here, if its last is one, then one minus one is zero. So zero four times whatever is going to be zero. So no matter what the relationship for the last row is going to fulfill always, okay? But if it's last is zero, so for the remaining rows, then it's one minus zero is one, and then ab for last minus a last must fulfill. So ab for last must be equal to a last. Okay, an a last of the next row must be equal to a before last plus a last of the current row. Okay? So with these two constraints, with these two constraints, we define the polynomial. Here.
00:15:15.606 - 00:15:53.874, Speaker A: You see that? For example, we define, well, in this case, we define the state machine, or the name of space is Fibonacci is 1024, and then its last is constant. And then we have the commit in the last lines. Mainly what we do is we define a public, in this case, a public output. This public output is the place where this public output is in the last line of the Alask polynomial. And then we need to also define what we call it, the boundary constraint. In this case is that in the is last. So when is last is one.
00:15:53.874 - 00:16:25.978, Speaker A: So in the last line, alas must be equal to this public input. So we need to add this constraint. Okay, so you see here, it's important. You see here why it's important. This example, because you see here an example of defining the concept of a state machine. We have some registers, and then we define this transition state machine, this relationship between one state and the next state. So this is the idea of a state machines and again, if we have a state machines, we can build processors.
00:16:25.978 - 00:16:50.802, Speaker A: We can build processors, and then we can build a program that's running on top of this processor. So we can build whatever we want. Okay, let's see other things that you can do in Peel. One thing that we can do in peel is permutation checks. So, one thing is measure that. We have two polynomials, and we want to add some constraints. This is done internally.
00:16:50.802 - 00:17:15.086, Speaker A: We're following some specific arguments. But in this case, I want to prove that all the values in a are all the values in b. No matter the order. One is a permutation or the other. Okay? So a is exactly the same that b, but in any random order. So in pill, we just define it very easily. We just say that a is b.
00:17:15.086 - 00:17:48.790, Speaker A: Okay, this is how we would define that in pill. Actually, in pill, we can do it a little bit more complex. So instead of working with one column, we can work with many columns. In this case, for example, a one and a two. These two values of a one and a two have these values in b one and b two. And I can have another polynomial, that is a binary polynomial that we call it the selector select. In this case, selector I and selector V, just to take in account specific rows.
00:17:48.790 - 00:18:15.246, Speaker A: So in this case, we see that the first row is one. So that means it's taking account. And this row must be in the cell b one and b two. And we express that in peel this way. So it's selector a one, a two is in selector selector b one and b two. This is just permutation checks. I can do the same with plugups.
00:18:15.246 - 00:18:39.738, Speaker A: The plugups is not permutation, it's an inclusion. So that means that all the values in a must be included in the values in b. So this three three is here, the six is also here, the five is also here, and the one is here. So this is the inclusion. This is what's called a block up. In pill, we define that is a is in b. So in the set of is in B.
00:18:39.738 - 00:19:17.586, Speaker A: Okay, and we can also work with multiple columns and with selectors. So the idea is that we can see that multiple columns are included. So these two columns are included in these two columns so that they are equal in these two columns, and there is an inclusion for just some specific rows, and we express that exactly the same way. Cella a one a two. In cell b, one b two. Again, plug up is a plug up argument. Internally, the prover is going to generate these plug up arguments that will force that this constraint is valid and in appeal.
00:19:17.586 - 00:19:47.822, Speaker A: We can have as many plug ups as we want or as many permutation checks as we want. What else we can do in pill? Well, we can put connection checks or copy constraints if you want. Imagine that you have a polynomial, and I want to enforce that. For example, the first value is equal to the third, fourth and fifth. This is a copy constraint. So we connect, it's like we have a connection. We connect one value with another value.
00:19:47.822 - 00:20:22.810, Speaker A: Or in this case, for example, I want to force that the second value is equal to the 7th value. So what we do is we take what we call it, an identity polynomial. In this case is x. Okay, and this is the polynomial where you start normally. And then for each connection, what we do is permutation. We create a rotation of this polynomial. So, for example, here is the one, three, four and five.
00:20:22.810 - 00:20:47.826, Speaker A: So I want to connect. So what I'm doing is I'm just rotating. The one is putting here, the three is going to the next, the four is going to the next, and the fifth is going to the first. So I create another polynomial where the evaluations are permutated and putting cycles for all the values that I want to connect. If I don't want to connect one of the values, I just keep the same. Okay. If I want to connect two values, I just swap one of the other.
00:20:47.826 - 00:21:15.418, Speaker A: But if I connect three values, I just create a rotation on there. Okay, so here, this would be this s polynomial that defines this connection. So how does be connected? And then in Peel, we just say that a connects with S. In general, s is going to be a constant polynomial. It does not necessarily be b. But in general, you want to define the connections as part of the circuit. Okay.
00:21:15.418 - 00:21:43.142, Speaker A: And we can do that not for a single column. We can have different polynomials and connect them between polynomials. So I can have one value in c and connect with some values in ABC. And we do that also the same way we define three polynomials. In this case is an identity, a constant times identity, and another constant time identity. And then I just permutate these three polynomials in the way that I just do the connections. And I express that in purely this way.
00:21:43.142 - 00:22:31.858, Speaker A: Okay, so I just, that one, a two, a three, connects with s one, s two, and s three. So with all this tooling, for example, what I can do is I can create plonk. For example, plonk is a concrete case of. So I can implement plonk in pill. Okay, so if you know how plonk works, if we have three committed polynomials, abc. Here we have the, sorry. Here we have the plonk gate, the q left times a plus qr times v plus q output times c plus q m times a times v plus q c equals zero.
00:22:31.858 - 00:23:02.254, Speaker A: Okay, here we have the connection part of the polynomial. So we define the three polynomials that connects one of the other. And in this case, we also define a public input. In this case, a public input is in a zero. And we put the boundary constraint here. We say that l one, which is a polynomial, that's just one, and the first value and zero in the remainings first, like a launch polynomial, and then just say that a minus public input is equal to zero. So we define a public input in this.
00:23:02.254 - 00:23:50.794, Speaker A: But here you see that how easy is to generate planck in pill. Now that we have the tooling for building these basic polynomial circuits, or if you want this arithmetization layer, let's try to build something more complex, or something more interesting, or something that's going to be the base for the ZkVm prover. Let's try to build a processor. Let's see how a processor would look like. Imagine that we want to define a processor with five generic registers, ABCD and E. And let's start with basic operations. Imagine a processor that just, the only thing you want to do is do moves.
00:23:50.794 - 00:24:41.070, Speaker A: So you want to move the value that's in a that goes to b, or another instruction that could be moved from c to d. So in this processor, we will define some polynomials. That will be the instructions. Okay? So an instruction is going to be a set of polynomials, in this case in a, in b, in c, in D, in e, and set a, set b, set c, set d and set e. So, instruction will be a combination of any of these polynomials that are binary. And in general, only one in a is going to be one, and only one set b is going to be set. Whatever is going to be one.
00:24:41.070 - 00:25:24.038, Speaker A: Okay, so this is going to be the instruction. So in these polynomials, we will see the instruction that we are executing. And imagine that we want to do a movement between a move of moving the value from a to b. Then in a is going to be one, set b is going to be one, and the other polynomials are going to be zero. This is going to be instruction that's a move from a to b. Okay, if we see how this would be written in polynomials, we see here down the pill that would be equivalent to that. For that, we define intermediate polynomials.
00:25:24.038 - 00:26:16.634, Speaker A: Just note here that op is not a committed, it's just an intermediate polynomial. That's defined it as a times in a, b times in b, c times in b, d times c d, and e times c e. If in a is one, then op is going to be one. If in b is one and the others are zero, then op is going to be b. So the in indicates which register are you putting in the register? B. And then we define the condition for what's the next value for the register? A. Well, if set a is one, then in this second constraint we see that set a is going to be one.
00:26:16.634 - 00:26:56.490, Speaker A: So op minus a plus a, a cancels, and a prime is going to be op. Okay, if instead set a is zero, then a prime is a. So we'll keep the value. So for the set whatever that are zero, we are going to keep the value. And for set whatever is one, then we are going to insert the value of a b. So if you see that clearly, that if the instruction in the instruction in a is one and set b is one and the remaining polynomials are zero, we will have a move between a and b. And with these we can solve any of the movements.
00:26:56.490 - 00:27:31.570, Speaker A: If you want to, for example, create an instruction that's an immediate value. That means you want to put, for example, a four in the instruction. Then here we have another polynomial. That's part of the instruction that's going to be a constant. So the instruction can contain a constant. In general, constant is going to be zero, but if constant is five and then all in a and b and c and d and e is zero, then in op it's going to be this constant. And then I can set to any of the registers.
00:27:31.570 - 00:28:50.570, Speaker A: Note here that in a processor it's convenient to have also not a register but bitten instruction, we call it infringe. So you can have instructions where you can put any value to any register. In general, you want to do that when the next instruction is going to check that what you put in this register is correct. For example, if you want to do a square root of a polynomial, what you will do is, okay, you put the result of the square root, then you multiply this result by itself and then check that's the original instead of computing the square root. Okay, this nondeterministic way of writing programs in general is written that way. So we have a processor, we can move things and we can, well, we have immediate values and some instructions. We allow us to put any value, okay, but next thing that in general you want to add to processors is conditional.
00:28:50.570 - 00:29:30.470, Speaker A: Sometimes you want to have a program that, okay, say if some value is zero, for example, just jump here. If not continue the normal execution. So to do that well, we need to implement in polynomials zero detector. So some way that algebraically you detect the e zero. You can see here, I'm not going to take the detail, but you can check how it works. And the idea is that the processor is going to have a program counter. A program counter register is a register that points to some position in the program or in the ROM.
00:29:30.470 - 00:30:06.600, Speaker A: That is the one that's executing one. Okay? So when there is a condition, mainly what we do is we change this program counter. This program counter. If you want to jump, the idea is to put this new address, but if we want to continue for normal instructions, we are going to just increment this program counter. So the next instruction is going to be the next instruction. This is very much like a normal processor works. All the processors have this program counter that points to the program.
00:30:06.600 - 00:31:04.242, Speaker A: But you see here, so we have conditions so we can do jumps, conditional jumps, we can do movements. But you see that these instructions are in some polynomials. But what is the ROM? Where is the program that's executing? Actually, in these instructions are committed polynomials. And in these instructions I can put whatever instruction I want so it's not constrained to any program. I can put any instructions that I want in each row. So how do I force to execute a program? So in order to do that, we just create a RoM. A ROM is a set of lines, and in each line an instruction, as I told you, an instruction can be many polynomials, in general, many polynomials.
00:31:04.242 - 00:31:46.194, Speaker A: And you see here that these are constant polynomials. So we have one polynomial, that's going to be the row number, so the program line, and then we will have a set of polynomials. In this case I say instruction, but this is a set of polynomials that here is where can be the program that you want to execute. And these are constant polynomials are polynomials that are known by the prover and the verifier. So you know that this processor is going to execute a specific RoM. Okay? And in the left side I have the polynomials that we have seen until now. So we have the program counter.
00:31:46.194 - 00:32:47.130, Speaker A: This is the program counter register, and here is the instruction that I'm executing. So this is a committed polynomial that it's saying which Instruction is executed. So here what I do is, I'm saying with a plug up that the instruction that I'm executing is in the ROM. That means that, for example, if the program counter says five, then because there is only one line, five in the ROM, that means that in order to fulfill this pull cap, the instruction that I need to put here, that I need to put here is exactly so must be the one that's in the ROM. And with this, I'm forcing that, I'm executing the right specific program. Okay, so you see here that I can define a ROM. A ROM at the end is compiled to a constant set of constant polynomials.
00:32:47.130 - 00:33:32.710, Speaker A: And then in the processor, I am executing this ROM. And I can do, in this case, can do movements and jumps. But in general, well, you can also have memory in order. I'm not going to enter to detail, but the idea is that you can have an instruction that can be a read write memory, and then I can have another state machine. That's the memory. And the idea is that here, the trick is, in this other state machine, what I'm doing is I'm sorting all the instructions that I'm doing in the normal trace in the main, but I'm sorting them by address. So I pack all the address and then by the count, the trace number.
00:33:32.710 - 00:34:11.266, Speaker A: Okay, so that means that I'm packing all the reads and writes for a given instruction in the same place. So I can do it with a single register. And then I'm just doing a single permutation check between the ROM and between the main execution trace and the memory. So with this, I could have a processor with memory and with some instructions. In general, you will want also to do some arithmetic operations or some binary operations and some other more interesting operations. And here, the day is a little quite easy. In general, it's always the same.
00:34:11.266 - 00:35:25.994, Speaker A: We define a secondary estate machine, in this case, an arithmetic estate machine that's just doing arithmetic operations. And here is doing additions or multiplications or whatever arithmetic operation you want to do. And in the main, when you are executing one arithmetic operation, or when you want to check that two values fulfill an arithmetic operation, then the only thing is that you do is a plug up you just do a matching with. So you just do an in that says, okay, the operation that I am assuming in the main must be checked, must be included in this arithmetic state machine. If it's in the arithmetic state machine, that means that this operation, so in general is inputs and the outputs of this operation are correct, fulfills this arithmetication. And then I'm just checking that r in both sides. So with this I have a full processor, and, well, I can do any operation, have memory, arithmetic operations, a program that's running binary operations, and so on.
00:35:25.994 - 00:36:30.974, Speaker A: So what we did in order to build processor to execute the EVM is create a processor that looks very much like that, with registers that are 256 bits, so they have different chunks and some details. We also have, for example, storage state machine, just to store values to a sparse merkel tree. We have a binary, we have arimetic. We have also hash state machines where we compute hash. So the idea is that we build all the hardware, all the arithmetic of all these state machines that are required in order to execute the EVM ROM to emulate the EVM. But this is the hardware layer. And on top of this processor actually is going to be what we call it the ROM.
00:36:30.974 - 00:37:11.642, Speaker A: So the real program, this program is written in an assembly. It's an assembly specific assembly for this processor. And this ROM will emulate the, it will emulate ethereum. So it will take transactions, it will check that these transactions have the valid signature. It will discount the gas, the ether, if it's a deployment smart contract, needs to deploy a smart contract. So this ROM actually is writing the same thing that a gas in Ethereum is doing, or that any client is doing. It's simulating ethereum.
00:37:11.642 - 00:38:00.378, Speaker A: So it has to do the things exactly the same way that ethereum, actually we are even using the Ethereum test suite to test that this program is okay. That behavior is exactly the same that Ethereum does. This is an example of how this assembly would look like. Here again, I don't want to enter in detail in this assembly, but for example, this dollar, when you see this dollar, these are free inputs. So there's an instructions that allow you to do a free input. In the left you see that the selected registers that go to up the right to the arrow is where I'm setting. There's going to be a register or a set of registers.
00:38:00.378 - 00:38:46.816, Speaker A: And after the column here is the actual instructions. If it's narrative mitigation, a jump, conditional jump, or whatever. Now that we have seen how to build a proof with this pill, this assembly, and this program with this, we already have a proof, actually we have a huge stark. It's a proof that if we see how this proof like this will be the basic circuit, but it's going to be a big proof. It's going to be a stark that will have more than 1000 polynomials with a degree. We are working with a degree of two to 23. It's a proof that takes about two minutes to generate, but it's a big proof.
00:38:46.816 - 00:39:19.116, Speaker A: It's a proof of about two megabytes of information. So what we want to do, if you want to verify this proof on chain, mainly what we want to do is we want to do two things. We want to compress this proof. So make a proof that's something that's smaller. And we want also to aggregate this proof. We also want to take the proof of various blocks and convert to a single proof. We want to prove a segment of the roll up of the chain, not a single block.
00:39:19.116 - 00:40:05.856, Speaker A: So let's see how we compress these roots. The way to do is we apply recursion. What means recursion? Mainly what we do is we generate another circuit. In this case, we generate this circuit with plunk that verifies the previous proof. So it's a circuit that it has the current proof as a public input, and it verifies this proof. This verifier is a stark verifier. It's written in plonk actually is using many custom gates of plum to reduce this stark as much as we can.
00:40:05.856 - 00:40:55.392, Speaker A: And if we see the statistics of this first iteration, this first recursion, it's a much smaller stark, it's a stark that has only 65 committed polynomials. And the degree of these polynomials is two to the 22. And the proof that we generate after this second stage of recursion is about 500 previous of the previous proof. And this, actually we could do it more times. Actually, if we do a third time, we can generate another circuit. In this case it's called recursive two. That as an input it takes c twelve.
00:40:55.392 - 00:41:48.844, Speaker A: So it takes the previous one, and again it verifies that again, in order to do the recursion, what we do is we do a trick. So we are taking this circuit, and instead of generating a full circuit that verifies the previous one. Actually what we are taking is if you see this circuit, well, it's going to be a plunk, it's going to have some structure, but at some point it's going to have hard coded the root c. The root c is what represents the circuit itself. The root c is where the queues and the permutation checks of the plonk. So the constant functions, so the constant functions that define the circuit itself are represented by a Merkel tree in the stark. And the root of this Merkel tree is what represents the circuit.
00:41:48.844 - 00:42:49.568, Speaker A: So what we're doing is we modify this circuit and we take this constant root. Instead of hard coded inside the circuit, we just generate a template that has as an input this constant circuit. Okay, so this template is, I can embed this template in any other circuit, but the only condition is that the root c, if I want to verify, if I want to verify the previous circuit, this root C must be the constant generated by the recursive one circuit. Okay, so I have a template that verifies c. Twelve proof. If this input is a specific value that represents this circuit. Okay, so what we do with this template, actually is I generate another circuit using this template twice.
00:42:49.568 - 00:43:27.212, Speaker A: Okay, so what it does is circuit is aggregate two proofs from maybe the proof of the batch 24 and the proof of the batch 25. Both proof are part of the input. And then this circuit verifies the two proofs. So the output of this circuit is going to be a proof. That's the aggregation of these two circuits. I generate this circuit again with plonk and this will give us a structure. And I can generate, again can do the same process that I did with the recursive one circuit.
00:43:27.212 - 00:44:38.080, Speaker A: So I can generate a template template that verifies this recursive two circuit. And I remove the root c. So the specific of this recursive two circuit, the specifics, the constant value of this recursive two circuit, I take it outside, okay? And the cool thing here is that the two templates that I generated, once I remove this constant, this constant root, which represents which circuit is verifying. So these two templates are exactly the same. So they have the same structure, they have the same degree, they have the same structure, and depending of if this root c, you put one constant, the constant for the recursive one or the constant for the recursive two, it will verify the recursive one or the recursive two circuit. But the circuit is exactly the same. So I can use this circuit to build, actually the recursive two is going to be a circuit that's going to be like this.
00:44:38.080 - 00:46:05.464, Speaker A: But here the root c. So we have a selector here that specifies if it selects the recursive one or the recursive two, but the recursive two, I want to be the same circuit, that is. So here we have a chicken and egg problem. So the idea is that, okay, what I'm doing is it can be recursive one or the recursive two. I just put it outside, okay, so the root c is the one that you want to verify. Okay, so the interesting thing here is that I have a circuit that I have a circuit that can verifies two proofs. And this proof can be either a recursive one, so a basic batch proof, or a recursive two, which is an aggregated proof, okay? And this allows me to generate a tree of proofs so a tree of recursion proofs, I can build this tree as I want, so I can aggregate to aggregate the proof for the batch one and two separately.
00:46:05.464 - 00:46:53.132, Speaker A: I can aggregate the batch for three and four and then aggregate the resulting two proof to a single proof. And this proof is going to prove the sequence so that it's going to prove the segment between one and fourth. And then I can take this proof and maybe aggregate it with proof five, and then I can take the result and aggregate it with proof. That's aggregating the batches six, seven, eight and nine. Okay, so I can build in parallel, and I can build this proof that represents a full segment. Okay, this is an interesting thing of recordion. In this case an infinite recordion.
00:46:53.132 - 00:47:54.772, Speaker A: That's how we hope this is built. Okay, and once we have this final proof that just prove a full segment, then next, the final step is I want to verify that on chain. So how do I do that? Well, the first is I generate a circuit using the same template that I used before. In this case, the root c. Here I can already hard code the root c one for the recursive one and recursive two. But the thing here is that this circuit, instead of using a hash, of using a poseidon of the same prime field, the goldilocks prime field for the starks, the one that we are using, for starks, we are using the poseidons with bn 128. This stark is going to be a normal stark, but the hashing is going to be the bn 128.
00:47:54.772 - 00:48:51.072, Speaker A: So after this circuit, I can verify this stark, but not using the goddelox, but using the bn 128. So here I can generate a normal circuit. I can generate a normal circumcise that verifies this, but is very optimal because it's using normal poseidon for the bn 128. Okay, in this final circuit, I also hash all the public inputs to a single input with shadow 56. This is done also on chain. So the idea here is to, instead of having a circuit with many public inputs, I have a circuit with one public input is a technique for aggregate for reducing the number of public inputs. And this is a final circum.
00:48:51.072 - 00:49:20.828, Speaker A: So here I can compile this circuit to gross 16 plonk. Or in our case, what we are doing is flunk. We are using flunk. Flunk allows us, it's more expensive. It's a proving system. It's a proving system that, well, it's kind of a plonk, but the idea is that you spend more time proving. In this case, it takes more than 2 seconds to generate this proof.
00:49:20.828 - 00:50:38.008, Speaker A: But the gas cost for verifying this final flunk is less that gross is in. So it really takes like 170k gas. So it's really cheap to verify that. Okay, so this final circuit has about 16 million of plum constraints and this is the one that we verify on chain. So we see that on chain, you can see here that on chain with a single flung proof, with a very small circuit, it's less than 1 can verify a full segment of the roll up. And to finish this lecture I would like to explain a little bit the current state of the network and what are the challenges in the near future. Right now the polygon CKVM is already mainet as a beta since March 2023 and challenges.
00:50:38.008 - 00:51:24.540, Speaker A: So the next steps is we need to be type two. That means implementing some of the precompiled smart contracts that are missing like paddings, shadow 56 and Blake. We also have to work with data compression. Right now. The limitation, the biggest bottleneck of the ZK roll ups, and the roll ups in general, is the data availability that's required in the layer one. So here, compressing this data is an important thing. And with roll ups you can compress a lot, removing the signatures and using information of the state or the previous transactions to do a better compression.
00:51:24.540 - 00:52:02.628, Speaker A: EIP 4844, dank sharding and protodank sharding are important. Implementing them and adapting to them is really important. Another thing is another interesting topic of work is that right now the proof is a big monolithic proof with all the state machines. Okay, but we are wasting a lot of polynomials because sometimes we are not using all the resources. Imagine that in the ketchups we have like many polynomials and we can do like 2000 ketchups. But maybe there are some blocks that we only are using 500 ketchups. So we are wasting a lot of polynomials.
00:52:02.628 - 00:52:46.672, Speaker A: So the idea here is to split the proof in many subproof, one for the ketchups, one for arithmetics. And the idea is have a bigger proof that aggregates all these subproofs, connecting them together and selecting, being able to prove different sizes for these subproof. This will also give better performance. It will require less memory to compute this proof. And probably these superfoofs also will be able to fit in a GPU. So we expect a lot of acceleration in that front. Security just mentioned that security is an important thing.
00:52:46.672 - 00:53:28.336, Speaker A: These systems are complex and new. And security is very important to invest in auditing and checking, rechecking, re auditing and the new things, rechecking the audit. So it's an important bet. Okay, and the other big topic is the decentralization. Decentralizing the sequencer, or if you want, converting, replacing the sequencer with a consensus mechanism is something that's important to decentralize the system. To finish, mention that all the Polygon CKBN is open source and other repos are available. They are in GPL.
00:53:28.336 - 00:53:44.480, Speaker A: You can check, study, deploy and use them as a reference for learning. So thank you very much and that's all for this lecture.

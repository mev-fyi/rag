00:00:00.170 - 00:00:36.854, Speaker A: I think we can just kick this off by saying welcome to the team from RippleX for joining us today and thank you for being a longtime collaborator of UC Berkeley. And today as a participant in the hackathon, you'll be talking about the challenges of Bridging to XRPL. So we're excited to hear about that and we'll turn it over to you. And then in the second part, we'll be joined by a representative from Gnosis Builders. So students should stay tuned for the second part of the evening as well.
00:00:36.972 - 00:00:39.020, Speaker B: All right, thank you.
00:00:42.980 - 00:00:45.090, Speaker A: I'll let you take it away on call.
00:00:46.900 - 00:01:45.268, Speaker C: Awesome, thank you so much. Well, I'm Anchul Malhotra and I lead the protocol design and cryptography research team at Ripple. Ripple is a software company. It has two units, RippleNet and RippleX. On the RippleX side, we are a group of builders, researchers, engineers who work on XRP Ledger. It's an open source, public decentralized blockchain and Ripple X focuses on providing tools, services and access to other resources for the developers to make it easy for them to build more and more use cases on XRP Ledger. And as a part of this hackathon, we have a challenge in the ZK Bridge category and I will explain it later.
00:01:45.268 - 00:01:55.576, Speaker C: But first I'll let Mayuka take over and talk about give you an overview of how XRP Ledger works, some of.
00:01:55.598 - 00:01:57.624, Speaker D: Its key features and how it is.
00:01:57.662 - 00:02:11.580, Speaker C: Different from other blockchain ecosystems. And then I'll talk about the hackathon challenge in detail and also about the prize money. So thank you everyone and Mayuka.
00:02:12.400 - 00:02:13.228, Speaker B: Hi everyone.
00:02:13.314 - 00:02:46.970, Speaker D: My name is Mayuka Vidari. I am a software engineer at RippleX. I mainly work on interoperability, so that's bridges and side chains and all that sort of stuff. I'm just going to give you an overview of how the XRPL works. Give you a bit of a demo of our Python Library. We also have other libraries like JavaScript and Java and there's a couple more that are being written in Go and Rust, so feel free to use any of those libraries. They're all open source and easily available.
00:02:46.970 - 00:03:26.588, Speaker D: Just going to share my screen. So what is the XRP ledger? It's one of the first decentralized blockchains. It was first launched in 2012. It has very high performance, can hit over 1500 TPS, I believe. The latest public numbers are around 2000. In a lab setting, it has very low latency ledgers, close every 4 seconds. So usually your transaction takes four to 8 seconds to be validated and at that point in time it's confirmed.
00:03:26.588 - 00:04:13.220, Speaker D: It has very low fees, less than a small fraction of a cent per transaction. It's carbon neutral. It has a native dex, so you can interact with a decentralized exchange without any smart contract necessary. It's all built into the L one and it also has native L one NFTs. Again, no smart contracts needed for that. So I'm just going to give you a bit of a demo of XRPL Pi, which is the Python library that you can use to interact with the XRP ledger so you can install it with just pip. Okay, great.
00:04:13.220 - 00:04:30.690, Speaker D: And so first of all, we're going to need a client to be able to do anything with. So we can create our client.
00:04:35.530 - 00:04:35.894, Speaker B: And.
00:04:35.932 - 00:04:38.470, Speaker D: We can connect to the testnet.
00:04:43.500 - 00:04:43.912, Speaker B: And.
00:04:43.966 - 00:04:58.940, Speaker D: We can make sure that we're properly connected by checking the server info, which is called for which the RPC is called server info. Very handily.
00:04:59.760 - 00:05:06.306, Speaker B: So if I do and I need.
00:05:06.328 - 00:05:07.460, Speaker D: To awake that.
00:05:15.720 - 00:05:16.870, Speaker B: There we go.
00:05:17.320 - 00:06:07.210, Speaker D: So this just tells us some basic information about this network and we know that we are indeed successfully connected because this returned a successful response. So now what are kind of the basic things you want to do with the blockchain? Usually you want to create a payment, you want to send some money to someone. So let's create a couple of accounts and send a payment between them. So I can create a wallet and I want to make sure that it's funded. So.
00:06:13.700 - 00:06:15.250, Speaker B: Hopefully it's the right.
00:06:23.060 - 00:06:23.616, Speaker C: Time to.
00:06:23.638 - 00:06:37.392, Speaker D: Refer to the docs because I forget the exact wording of this particular transaction, of this particular method. Generate faucet wallet.
00:06:37.456 - 00:06:38.070, Speaker B: Okay.
00:06:40.760 - 00:07:55.560, Speaker D: Set. And it'll take a SEC. So the Generate Faucet wallet function is calling the Faucet, which basically funds an account with some fake XRP and then creates that wallet. So now this account has been generated, but we're also going to need a destination account to send this payment to. So we'll create another one and so that's going to be the address that we send our money to. So if we want to check what the balance of this account is, we can use the RPC called account info and.
00:08:08.540 - 00:08:09.850, Speaker B: Go with that.
00:08:11.280 - 00:09:34.554, Speaker D: And so this is the balance in what are called drops. So there are a million drops in one XRP. So this is a balance of 1000 because that's just the default amount that the faucet funds. Okay, so now let's create our payments. So we want to send it from our wallet address. We want to send it to our destination address, and we want to send well, we want to send, we'll say, ten XRP, but we got to convert that to drops. Now we need to sign and auto fill the transaction.
00:09:34.554 - 00:09:49.090, Speaker D: What Autofill does is gives you things like the fee and the sequence number and that sort of thing. Just kind of auto fills that information from the current ledger info.
00:09:59.470 - 00:10:00.278, Speaker B: And we're.
00:10:00.294 - 00:10:02.022, Speaker D: Also going to need to submit the transaction.
00:10:02.086 - 00:10:03.340, Speaker B: So I'm just going to.
00:10:07.050 - 00:10:37.090, Speaker D: Import that while we're here. So here's what the payment looks like right now. As you can see, it's being sent from this account. It's a type payment. It's being sent to this account. And this is the amount that we're transferring, which is ten XRP in drops. So now we can sign it.
00:11:09.060 - 00:11:10.370, Speaker B: The wrong one.
00:11:14.720 - 00:12:03.164, Speaker D: And so now it has been signed. And here is the public key that signed the transaction and the transaction signature itself. So now we can send this transaction and there's this helpful function called Send reliable Submission, which basically submits a transaction and then waits for it to be validated. The XRP ledger uses a consensus protocol called proof of association. And what that means is that every node chooses which other nodes it trusts and everyone kind of works together to decide which transactions are validated. So you don't really need to worry about a fork like you do with something like proof of work. So as soon as a transaction is validated, that's it.
00:12:03.164 - 00:12:17.680, Speaker D: You don't need to wait for any number of blocks after that, you know that it's confirmed after that. And this function basically just waits till it's validated and returns.
00:12:23.760 - 00:12:30.270, Speaker B: So I waited too long.
00:12:30.960 - 00:13:08.840, Speaker D: There's a check to make sure that you don't wait too long to make sure that your payment doesn't stay waiting to be submitted too long, and I waited too long before submitting. So here we have, this is the validated transaction. You know that it's validated because validated is indeed true and we can double check that by running our account info command again. So the balance has now decreased and if I go to the destination, this balance has now increased. So that's how you submit a transaction on the XRP ledger.
00:13:10.220 - 00:13:11.880, Speaker B: Back to the slides.
00:13:13.360 - 00:14:11.818, Speaker D: Any questions? So what is a transactor? A transactor is basically just what we call transactions or related features on the XRP ledger. So some of the features include Escrows or payment channels. Those are all native on the XRP ledger. You might also consider NFTs to be kind of a transactor. But this is what a transaction looks like as you can see it again. And it's kind of the only way that you can really modify the XRP ledger state. And what it does, it can create, modify or delete ledger objects which are just different ways of storing data on the ledger such as NFTs or Escrows or payment channels.
00:14:11.818 - 00:14:36.020, Speaker D: And it commits data to the ledger that users and servers have access to and transactions have to be submitted by an account. Ledger objects are how the XRP ledger stores on ledger data almost exclusively. They must be owned by an account. Everything is really account based in the XRP ledger's world. And.
00:14:37.930 - 00:14:38.680, Speaker B: Yeah.
00:14:40.410 - 00:15:24.402, Speaker D: So the way that a transaction is actually applied to the ledger is the way that you actually build a transaction is it goes through a few different steps. First it goes through this method called calculate base fee. And basically what that does is it calculates the fee that you need to pay and it makes sure that you did in fact pay enough of a fee as a part of your transaction for that transaction to be valid. Make TX consequences is used when an account has multiple transactions queued to estimate whether it'll be able to pay all the fees for all of them. It's really not necessary in 99.9% of cases. So we'll just ignore it for now.
00:15:24.402 - 00:16:38.816, Speaker D: Pre Flight is essentially taking a look at the transaction. What is everything that you can check about the validity of the transaction just from the transaction itself. So for example, for a payment, you want to make sure that your destination is a valid address, not that someone's trying to send money to address one, two, three, as opposed to something that's actually well formed as an address. You want to make sure that the amount that they're trying to send isn't negative and that sort of thing. And preclaim is then the next level of steps that you take and that's basically what can you check about the validity of the transaction with read only access to the ledger state? So this would be like, does the account submitting the transaction exist? And then there's do apply, which is where you actually apply the transaction and it changes the ledger state and you commit that change. So I'm also going to talk a little bit about the current bridge design that we have. We just launched a proposal about a month ago for a native bridge design.
00:16:38.816 - 00:17:36.964, Speaker D: And basically the way that this works is in this diagram you've got your two chains that you're transferring between we'll call one your locking chain and one your issuing chain. Because in any bridge on one chain you're going to be locking and unlocking a certain asset and on the other chain you're going to be minting and burning a wrapped version of that asset. That's kind of true, inherently true to pretty much any bridge. And so that's the names that we're giving them. So the way that this works is just like any bridge, you need some sort of middle trusted service to kind of be a source of truth for what is happening on the opposite chain. So each of these two chains, there's no real way for them to directly communicate with each other. So in order for them to be able to relay data back and forth, we have these witness servers that we're calling them.
00:17:36.964 - 00:18:47.604, Speaker D: It's basically like a light client concept or an oracle like concept that attests to information that happened on the other chain. So to give you an example here, this is the anatomy of a cross chain transfer. You start by creating a claim ID on the issuing chain. A claim ID you can basically think of as like a unique ID for a cross chain transfer. It basically ensures that you can't try to repeat the same transfer again and try to get free money basically. And then you send an exchange commit transaction on the locking chain, which basically just takes that claim ID, uses that claim ID as the ID of the transfer, and it commits or locks the funds on the locking chain. And then the witness servers they notice of the commit transaction and they submit XChain claim attestations on the issuing chain, attesting to the fact that the funds were actually locked on the locking chain.
00:18:47.604 - 00:19:02.230, Speaker D: And then that releases the funds on the issuing chain to then be accessible to the destination. Anshul, I'll pass it on to you.
00:19:06.380 - 00:19:06.888, Speaker B: Awesome.
00:19:06.974 - 00:19:53.694, Speaker C: Thank you so much, Mayoka. That was great. Okay, let me start sharing my screen. All right, so I'm going to talk about the challenge that we posted, but I would highly recommend that if you want to learn more about how XRP ledger works, how its consensus mechanism works, it's very different from most other blockchains. xrpl.org is a great resource for that. Also, it's a great resource to learn how different transactors, what are the different kinds of transactors that are natively available on the XRP ledger payments being one that mayuka just showed you a demo of.
00:19:53.694 - 00:21:29.902, Speaker C: And you can also play around with all these different also try and play around with all these different transactions using the libraries that are available, and they're available in Python, JS, Java and so on. So it's a great resource for you guys to get started on how XRP ledger works for this challenge hackathon. So although it's under ZK bridge track, but I would like to highlight that since we have just started exploring zero knowledge proofs, the feasibility of implementing zkSNARKs for XRP ledger, this challenge is very open ended. So here I'll go through some of the modules that we think would be useful to be built so that they can be reused for generating Zkesnar proofs for different kinds of transactions on XRP ledger. But really, this is really like a clean slate and you have a great flexibility and opportunity to come up with your own ideas, come up with anything that is simple, small module that can be used to generate real Zksnac proofs for different kinds of transactions. So here I'm going to talk about some of the things that some of the modules that you can easily build and then you can come up with your own. So first of all, one thing to keep in mind is that Ripple D code base is in C plus plus.
00:21:29.902 - 00:22:34.174, Speaker C: So all the validators, they run Ripple D software which is written in C plus plus. So anything that you build should be compatible to XRP ledger that can be and everything goes natively, so it has to be compatible with C. One of the libraries probably that you can use for building these proofs is lipsnark, but I guess there are others that you can use too. So let me start by saying that, well, the end goal here for one of the things that you can do here is to build a Zksnarc proof for one of the simplest transactors, that is the payment transaction and more specifically for direct XRP to XRP transactions. I'll share this Google doc afterwards so that you can have access to these links. So one of the tasks is serialization. XRP ledger has its canonical serialization format for all the objects that are subject to consensus.
00:22:34.174 - 00:23:50.170, Speaker C: So in this task one of the things that you can do is to build a circuit that implements the serialization this custom serialization format for XRP ledger another task is signature verification. So XRP ledger supports two different signature algorithms, one is ECDSA and the other is at 25519 just like most other blockchains do to sign and verify the transaction messages. And in this task obviously you can build proof statement for signature verification and then further transform it to R one CS using any library. This one third task is, as I said, payment transaction validation. And in this task generates simplest transaction. Payment transaction is an XRP to XRP transaction and Mayuka just described the functions in the Ripple decode that are used from the beginning. From checking the validity of the statements, to checking the validity of these payment transactions, to applying the transactions.
00:23:50.170 - 00:25:09.682, Speaker C: And there are links available on the xrpl.org to the source code which you can refer to while you are generating these proof statements for this payment transaction. So some of the constraints would be statement that the sender has a high enough XRP balance to send the payment. The amount that the sender specifies in the amount field, which is one of the fields of the transaction, should be the same as the amount that the receiver receives and so on and so forth. And here are the links to the complete documentation of all the necessary steps required for a payment transaction to be applied. And I would also encourage so this is just for one you can generate proofs for one transaction but also try and look for generating proof for a batch of transactions. Then another task is obviously the proof generation, the CRS and proof generation which would include the initial setup phase and then also the generation of the proof for the payment transaction and the proof verification which will be the Verifier will be on the XRP ledger.
00:25:09.682 - 00:26:05.110, Speaker C: So generating proof verification algorithm. So these are some of the tasks, like the first two you can think of as more reusable modules that can be used to build that can be used to generate proofs for several kinds of like almost all the transactions on XRP ledger. And then the task three. This one is specific to a payment transaction, but you can also pick and choose other transactors that are available natively on XRP ledger. And there's a list available on the xrpl.org that you can look into in terms of prize money, similar to how we are very flexible and this challenge is very open ended. So is the prize money.
00:26:05.110 - 00:26:51.940, Speaker C: So I would say that once you come up with something that you want to build, for instance you want to do task one, you can submit how you propose to do the task one and then we can decide on the price money accordingly. And the general idea is that smaller modules will be given less price money. But if you reach up to task three, like building Azika snack for transaction that is supported by XRP ledger, then the price money will keep increasing. Yeah, so that's mostly what I have to say. Any questions? We can take questions.
00:26:56.970 - 00:27:05.900, Speaker A: Right? Well, Mayoka and Ankal, thank you very much for joining us today. It's very easy and clear to understand what you were saying.
00:27:06.990 - 00:27:07.498, Speaker B: Awesome.
00:27:07.584 - 00:27:13.580, Speaker C: Thank you so much. And I hope to see a lot of participation here. Feel free to ask any questions.
00:27:14.990 - 00:27:19.278, Speaker B: Yeah, all right, thank you.
00:27:19.364 - 00:27:32.610, Speaker A: Well, you're welcome to stay if you'd like and listen to the next presentation, but otherwise we will turn it over to Oren and let him present for Gnosis Builders.
00:27:33.350 - 00:28:09.310, Speaker E: Hey, everyone. I'm Oren. I work at Gnosis and Gnosis Guild. We build a whole bunch of different infrastructure for the ethereum ecosystem, along with being the kind of custodians of Gnosis chain. Today we're going to chat through mostly bridge related topics and kind of introduce something called hashi that we've been working on for the last few weeks. So it's kind of relatively new, very exciting. So, yeah, we'll just dive right in.
00:28:09.310 - 00:29:06.954, Speaker E: So Hashi is this system for additive security, for cross chain bridging. So what we'll do here is just go through a brief intro to hashi, kind of talk briefly about why bridges get hacked, have a chat about the kind of hashy design principles and goals, the architecture, and then talk through your challenge for the hackathon maybe in between there. So we can actually just dive into the hashy code a little bit and go through it. Or we can wait till after and do it kind of with Q-A-I am totally cool with this talk getting derailed. If you have questions, don't feel like you have to wait till the end, you can throw them in the Q A section, throw them in the chat, and yeah, feel free to derail me anywhere. We can go down rabbit holes and I can always make my way back to the talk afterwards. So I guess with that, we'll dive right in.
00:29:06.954 - 00:30:14.082, Speaker E: So introducing hashi. Hashi is this protocol for cross chain communication based on additive security. Essentially, it's aggregating multiple inputs, multiple oracles. At its core, hashi has a typo in the presentation. Hashi is a hash oracle aggregator, so it allows one to implement what, as of about 30 minutes ago, we're calling a Ryho, a redundant array of hash oracles. And so the goal here is to distribute trust for bridges on the mechanism level, to essentially not have to trust any one individual bridge mechanism or allow end users to kind of set up this layer of redundancy on the bridge mechanisms that their systems depend on. So why hashi? Why do bridges get hacked? So, in 2022, there was roughly $2 billion worth of tokens lost in kind of bridge related exploits.
00:30:14.082 - 00:31:35.790, Speaker E: Four of the top five exploits that are on the Rec News Leaderboard are bridge related exploits. What I think this should be a kind of really clear indicator of is that essentially no bridge implementation is 100% secure and that we probably shouldn't be building security critical systems that depend solely on any of them. All bridge designs have some trade offs in terms of cost and security and auditability and all these kind of things. And so, yeah, the kind of really important, kind of take home message here is that the systems built on top of bridges get hacked or get exploited because they put all of their trust into individual bridge mechanisms that ultimately get exploited. And that's not to say that every bridge mechanism will ultimately get exploited, but every bridge mechanism has an attack surface. None of them are 100% secure. And so for security critical applications, it really doesn't make sense to put all of your trust, essentially make your system entirely dependent on the security of one individual bridge mechanism.
00:31:35.790 - 00:32:34.546, Speaker E: So the design principles for hashi, essentially we want to standardize at the lowest level the hash, and we can kind of dive into what we are talking about when we talk about hashes here a little bit later. We want it to be modular and agnostic to the underlying mechanisms and we want to enable this thing. Ryho a redundant array of independent hash. Oracles so this is analogous to array redundant array of independent drives. If you've ever dealt with setting up servers or anything like that, then you would have played around with this, where essentially if you have a critical piece of data, right, you have a system that has some data that is critical. You wouldn't just store that kind of on the solid state drive in your laptop or on a flash disk, you would want to kind of create backups of it, essentially. So you might store it on your laptop, you might store it on a flash drive as well.
00:32:34.546 - 00:33:39.560, Speaker E: You might upload it to a cloud storage provider. You might store it on multiple of your own machines, or you might set up a raid. So a Raid is this system where you have multiple disks running in parallel storing all of the data so that if one of the disks breaks, the other still have the data. Depending on the configuration of the Raid, you can also get speed gains as well as redundancy gains out of it. But in either case, it kind of has this trade off of speed cost and redundancy, or I guess this trilemma kind of thing where you can kind of get two of the three most of the time. And so, yeah, what we're trying to set up here is this kind of system. What we're trying to enable, I should say, is the system that's analogous to raids, but for bridge oracles where you get this kind of choice now to kind of optimize for whichever two of those three things you want.
00:33:39.560 - 00:34:58.750, Speaker E: In our case, we very much want to optimize for security over latency and cost. Ariho is going to kind of move only as fast as the slowest oracle in whatever the kind of threshold set is, you need to kind of agree on a hash. And because of that, because especially if you're using kind of a threshold of more than one robustness and security are kind of going to be improved, but at the cost of increased resources. And so I guess stepping back a bit, I'll stick here for a second. The design of hashi is essentially analogous to this raid setup. Multiple bridge oracles need to report the same hash, or should say multiple hash oracles need to report the same hash. In order for your system to consider that hash valid, what set of oracles need to report it is entirely kind of up to you as the person implementing a system built on top of that, built on top of this kind of Ryo setup.
00:34:58.750 - 00:36:17.580, Speaker E: And yeah, we can dive more into that once we start poking through some code in a little bit. So the goals here, we want kind of diversification on the cross chain protocol implementation. We want to have many different mechanisms that we're aggregating in order to come up with a valid hash for any given data that we want to validate across chains. And the idea here is that these mechanisms should be both independent and kind of diverse. So that the more independent they are and the more diverse the implementations are, the more difficult it is for a would be exploiter to coerce those mechanisms into reporting something false at the same time. If it's duplicate implementations of the same system, then kind of breaking both at the same time is kind of much more likely. So we want kind of a good mix of things like committee based oracles, ZK Oracles, optimistic oracles, so that it becomes really difficult to exploit all of them simultaneously in the same way, have them all report the same false information.
00:36:17.580 - 00:36:54.294, Speaker E: We want to see integrations, I guess. Yeah. So with that in mind, we want to see integrations with multiple head oracles, telepathy, Zkbridge, et cetera. Integrations with multiple message passing mechanisms, amb, wormhole, et cetera, and want to allow kind of users the choice in which combinations of mechanisms to trust to secure their systems so quick kind of overview of the architecture. This looks really messy and it kind of is. And this is to a certain extent the price you pay for additional security, but we can kind of walk through it. I'm not sure if you guys can see my mouse cursor or not.
00:36:54.294 - 00:38:12.510, Speaker E: I'll assume that you can. But on the left hand side, starting with a kind of canonical example, the token bridge. So we have some token bridge contract that wants to ultimately mint tokens on a kind of destination chain, right? So on the source chain it's going to send a message or put a message into storage. And that message is then going to be reported over a variety of different mechanisms to the destination chain. On that destination chain, each of these mechanisms is going to essentially validate the message independently, validate a hash of the message independently, and then that will be aggregated by hashi. And the token bridge contract will ultimately request from hashi a validation of request from hashi the hash that is associated with a given kind of message ID or block ID. And if they all agree on it, then allow tokens to be minted.
00:38:12.510 - 00:40:34.074, Speaker E: I am being a little bit, I don't know, obtuse in how I'm talking about this because it's not just for this use case. We started building this thinking about how do we aggregate block headers? How do we aggregate the hash that is attached to every block so that on a destination chain we can validate or on one chain we can kind of validate the state of another chain using light clients or kind of other mechanisms that will report the block header? But in setting it up, we realized that it's kind of more general purpose than this in that it can really just be used to aggregate any hashes that kind of conform to this mapping of byte 32 for domain UN, two five, six for ID and then byte 32 for the data. So if you have some data that you want to aggregate that can kind of map well to that structure, then you can build Oracle adapters for it and kind of use this architecture to build kind of redundancy into systems that are wanting access to that kind of data. So the main components mean at least what we're thinking about here is applications like token bridges, governance bridges, NFT bridges. The underlying components to that are the hash Oracles, essentially the things that plug into other systems. So if we're talking about block headers, this would be the Oracle adapters that then plug into something like Succinct Labs Telepathy Client or plug into the arbitrary message bridge or the wormhole bridge to grab messages or block hashes. The core contracts for hashi are the hashi contract, which is this kind of stateless, very unappinionated way of just querying multiple Oracles or Oracle adapters from kind of one place.
00:40:34.074 - 00:42:08.940, Speaker E: And then this girigiri bashi is this kind of governable extension to hashi that lets you kind of have an ownable contract that you can define explicitly what set of adapters must agree on a given hash for a system kind of connected to it to consider it valid. And so this is where you would get this kind of gearigiri bashi contract, is where you would set up something like a Ryho set up. You would define the set of adapters and the kind of threshold, the number of those. Adapters that need to agree on a hash to consider it valid. Outside of that, systems built on this willfully also want to leverage things like storage proofs reporter contracts for broadcasting and then executing messages based on the hash and then relayers for listening to events on an origin chain and reporting the hashes or triggering the transactions on the corresponding destination chains. So what can you build with hashi? What we'd like to see people working on is adapters for other bridges, preferably ZK Lite client bridges, but also we'd love to see kind of optimistic bridges and committee based bridges and any other mechanisms that you can come up with. Again, diversity is really valuable here.
00:42:08.940 - 00:42:58.474, Speaker E: We'd love to see contracts that check merkel proof for some events or storage on an origin chain. And we'd love to see alternate implementations of Gear Geiribashi. So it's a relatively simple kind of aggregation rule right now, but we'd love to see kind of different governance rules, kind of pausing mechanisms, different aggregation rules. So, yeah, kind of variations on that contract I think would be really great to see. And then we'd love to see things built on top of hashi. So token bridges, NFT bridges, governance bridges, and other novel things that we're not thinking about. So yeah, just going through that again.
00:42:58.474 - 00:43:31.590, Speaker E: Here the challenge for you guys. You have these kind of two categories that I think are relevant. The category five is applications leveraging. I think in the hackathon description it said ZK bridges. But changing over here, as much as we want to see ZK stuff, I think more. So we want to see kind of diversity. So additional pieces that kind of allow for this Ryho setup and then applications built on top of this kind of Riho style setup.
00:43:31.590 - 00:44:05.678, Speaker E: Yeah, I think from there we can move on, I guess. Yeah, deliverables. So, open source code, obviously, ideally test, well tested and documented. If it's something that's improving on hashi, then PR to the hashi, repos that's, things like additional adapters and whatnot. And then yeah, short presentation explaining the project. The prizes for each of the categories are published up on the hackathon website. So I don't think we need to go over them now.
00:44:05.678 - 00:44:37.194, Speaker E: There's a bunch of resources here in the presentation. I'll share the link to the presentation afterwards. There are deployed contracts here that we've listed. These are probably a little bit out of date now because we've been actively developing for the last few weeks, but they should work if you need them. I'd probably recommend just deploying your own rather than leveraging the ones that exist here. But if you don't want to deploy your own, then here they are. And yeah, that's the end of the talk.
00:44:37.194 - 00:45:31.740, Speaker E: I'll jump over into the code and again, if anyone has questions, then feel free to just kind of derail it. But we can jump in and just start kind of poking through what hashi is how it works. Kind of under the hood a little bit more and kind of go from there. So hashy is a really simple contract. Less than 100 line of code, including a bunch of comments. The kind of primary function that you would interact with here is just get hash, where you're going to provide a domain. This is probably a chain ID, an ID here, which is probably the block number or message ID, and then an array of adapters that you want to query to get the given hashes from.
00:45:31.740 - 00:46:48.050, Speaker E: When you when you call get hash here, it's basically just going to iterate through the list of Oracle adapters and report back the hash if they all agree on it. If they don't agree, then the function is just going to throw an error that the Oracles disagree. So, super simple code. But yeah, this is kind of the base of what hashi does. Gary gary Bashi extends this a little bit, makes it ownable here we go. And gives you a little bit of storage to do things like define which set of adapters are valid for a given domain and what the threshold of adapters is that's required for a given domain. And then it's basically going to expose the same endpoint.
00:46:48.050 - 00:47:22.010, Speaker E: Get hash. It will run a handful of its own checks to make sure that the threshold is high enough. There's no duplicate adapters. None of the adapters passed in are kind of invalid. Make sure that they all correspond to one of the adapters in the list for that given domain. And then it's going to call out to hashi to make sure that the adapters that you've passed in actually agree on a given hash. So this is kind of the core pieces to hashi that would exist on the origin chain.
00:47:22.010 - 00:47:51.850, Speaker E: Essentially the chain that wants to receive messages. Oren, we only see the thank you screen. Are you sharing? Oh, I am sharing some code. Good call out. Let me switch to a different screen. I've been just ranting on here, so I'm going to switch to how's that like yeah, now we see the code. All right, perfect.
00:47:51.850 - 00:48:34.978, Speaker E: So I'll jump back in here really quickly. So this is our get hash function from our hashing contract. Just to go over it again quickly. It's basically just going to take a domain, which is likely the Identifier for the chain that you're wanting to query. So chain ID, and then ID here is probably the block number or message ID. Oracle adapters is the list of adapters that you want to query to aggregate a hash. And so when you call this function, it's going to iterate through this list of Oracle adapters and make sure that they all agree on the hash.
00:48:34.978 - 00:50:18.386, Speaker E: Then Girigiri Bashi here is the ownable version of this that again, lets you kind of set some internal state to define what set of adapters are valid for a given domain and what the threshold that's required for a given domain to threshold that's required for a given hash to be considered valid on a given domain. And again it's going to expose the same function, get hash, perform a handful of checks before ultimately calling out to our hashy contract to query each of the Oracle adapters. So these two contracts would be deployed on kind of each potential destination chain and then on the origin chain. I guess depending on whether if you're just querying for things like block headers then nothing specific needs to be deployed on the origin chain, you just need on the chain that you're wanting to I should clarify that depending on the mechanism, you probably don't need something deployed on the origin chain. For some mechanisms like maybe a committee based Oracle, you could have something deployed to kind of coerce message bridges into reporting block headers. I can show some code for that in a minute, but for kind of light client type setups you wouldn't need anything specific deployed for passing messages. On the other hand, you would have something like this contract here Yahoo.
00:50:18.386 - 00:51:20.838, Speaker E: This is our message dispatcher. And what it's going to do has a handful of functions here for dispatching messages, relaying already dispatched messages to adapters, and then convenience function for doing both in one call. But the idea here is that essentially when you dispatch a message, you're putting a hash of that message into storage and you're emitting the message dispatched event. And so depending on the Oracle mechanism, that should pretty universally allow just about any Oracle mechanism to have a route to validate that this message was actually passed from the origin chain. Some Oracle mechanisms may do things like storage proofs, in which case you've got this message in storage. Others may do things like event proofs. So you've had this event that's happened on the chain that you can now validate using event proofs.
00:51:20.838 - 00:53:01.894, Speaker E: And then others might use, others might want to kind of create a message from what's in storage and then pass it via some committee based Oracle. So yeah, this Yahoo contract allows us to create a message that just about any Oracle mechanism should be able to validate through whatever its kind of local mechanism is. And then on the other side of this, if you're creating messages, then you probably are wanting to trigger some kind of execution from it. So this is our Yaru contract is our message executor, and from this one you can basically execute messages from Oracles. So if the Oracles report a hash that corresponds to the messages that you input, then it will allow you to execute it. So essentially you put in an array of messages along with an array of message IDs. And this function here execute messages from Oracles is going to iterate through your list of Oracle adapters and query that the calculated hash from the messages that you inputted corresponds to the hash that's reported from each of the Oracle adapters that's required and if they do then it will allow the message to be executed.
00:53:01.894 - 00:54:11.154, Speaker E: And so from this, if you're building say a token bridge, it would plug into this, the token bridge on the origin chain would send a message through Yahoo to tell the token bridge on the destination chain to execute a message. Token bridge on the destination chain would receive a call that was initiated by this execute messages from Oracles, which is a permissionless function that anyone can call and will validate that the message passed in has not been executed yet and corresponds to the ID of the message that you pass in. Yeah, I guess that's a pretty good overview of the code and probably gives you a good starting point. The other place that we could take a quick look is at adapters here. So we have a handful of adapters that we've written already. Amb connects, telepathy pretty much ready. The wormhole one is not, we haven't written any tests for it yet, it's essentially just a sketch of what the code might look like.
00:54:11.154 - 00:55:35.360, Speaker E: So if you're looking for some low hanging fruit of some way that you might jump in and make some additions or improvements to this repo, fixing the wormhole adapter is probably a great place to start. But yeah, essentially adapters are going to inherit this Oracle adapter contract and if they're a block header storage contract then they'll also probably want to implement this or inherit this header storage contract. Sorry no, they'll probably want to implement this block hash Oracle adapter contract that just allows for kind of historical provenance. But yeah, the idea here is that essentially each Oracle adapter should have a mechanism for storing the hash and then expose this function, get hash from Oracle which hashi can ultimately oracleadapter. Get hash from Oracle. So hashic can ultimately call this when it is aggregating the reports from various different mechanisms. And so the route that it takes to do that for your Oracle adapter depend entirely on the mechanism that it's plugging into.
00:55:35.360 - 00:56:50.740, Speaker E: The Amb adapter for example, is basically just going to store hashes but it's only going to allow the arbitrary message bridge contract to call that function and only allow it from a specific message sender on the origin chain. In that case, this is, this Amb header. Reporter so this is what I was talking about earlier where we can kind of coerce message bridges into reporting headers if we want to kind of use them for that function. Yeah, I guess that's maybe a good stopping point or a good opportunity to jump into some of the chat questions. Yeah, and if we don't have any questions then we can just wrap it up here. If you want to find out more about Gnosis and nosis chain generally then we've got a bunch of links here. There is a whole bunch of us available most of the time to answer any questions, and specifically for folks participating in the hackathon, we'll obviously be really responsive and do our best to help you find whatever information you need.
00:56:50.740 - 00:57:06.220, Speaker E: Yeah, great. I'll go ahead and just drop the slides in the chat here. Here's a link to those and then make sure that it's available elsewhere as well.
00:57:06.670 - 00:57:11.370, Speaker A: Okay, great. Well, thank you very much for joining us this evening.
00:57:11.870 - 00:57:13.786, Speaker E: No worries. Thanks for having me, guys.
00:57:13.968 - 00:57:15.226, Speaker A: Yeah, all right.
00:57:15.328 - 00:57:16.220, Speaker D: Take care.
00:57:16.910 - 00:57:19.880, Speaker A: Devesh, did you have any announcements you wanted to make?

00:00:00.570 - 00:00:10.880, Speaker A: We have a very special guest tonight, Tim Rafgarden, professor at Columbia, head of a 16 Z research. Thank you very much for being here.
00:00:11.650 - 00:00:34.278, Speaker B: Great. Thanks, Arthur. Hi, everyone. Thanks for coming. For lack of a better title, I wanted to talk today about some results and challenges in crypto economics. And I have to say, crypto economics is actually not a word I use that much myself. In my experience, it just means very different things to different people.
00:00:34.278 - 00:01:12.062, Speaker B: But when Don asked me to give this talk, I was like, okay, let me think. I'll use this as a chance to ruminate. What is it that's really kind of special and unique about the problems in this nebulous area? And I'm kind of glad I did because it kind of reminded me of how intellectually fascinating actually this area is. So I think it's useful to compare and contrast cryptoeconomics with the field of mechanism design, which is a traditional field of microeconomics. One way to describe mechanism design is as inverse game theory. So what does that mean? Well, what's game theory? So, in game theory, usually a game falls from the sky, right? Prisoners dilemma, rock, paper, scissors. And then you investigate it strategically.
00:01:12.062 - 00:01:51.038, Speaker B: So you ask, do players have dominant strategies in this game? You try to understand the Nash equity of that game. In other words, given the game, you try to figure out what are the outcomes that are most plausible. So mechanism design is inverse game theory in the sense that you don't start with the game, you start with the outcome, an outcome that is one that you would like to see happen. So, in a protocol context, maybe you'd like to see all of the participants running the protocol as you intended. Or maybe you have scarce resources to allocate. You would like to allocate those in sort of the best possible way. And then the goal is to design a game so that the outcome that you desire actually is an equilibrium of that game.
00:01:51.124 - 00:01:51.374, Speaker A: Okay?
00:01:51.412 - 00:02:28.154, Speaker B: So again, in a scarce allocation context, maybe you're trying to give one good to one of many of n people. You'd like to give it to the person who values it the most. And so a second price, or vic re auction, is a way of setting up a game so that everybody's incentivized to tell you their true value, which then allows you to allocate it efficiently. Now, traditional mechanism design, like this VCG example, there is often a notion of a currency. So there's payments going back and forth between participants and the mechanism. And traditionally, you don't really worry about what that currency is. It's just like dollars or something like that, and you don't really think anything more about it.
00:02:28.154 - 00:03:09.550, Speaker B: So one really interesting question is, what happens to mechanism design problems if you grant the mechanism the power of access to a cryptocurrency? So to a currency that is native to the blockchain protocol on which it's running. And this question is exciting for two reasons. So, number one, it expands the design space. It's conceivable that mechanisms with access to a native currency could do things that you could not do without that access. So, for example, as we'll see, one thing you can do in a mechanism with access to the native currency is either mint it or burn it. So to inflate or deflate the currency. But with that additional power also comes responsibility.
00:03:09.550 - 00:03:49.598, Speaker B: If you're running like a second price or a vicary auction, you're not worrying about the consequences of your auction on us money supply. It's really kind of irrelevant. Whereas if your mechanism is doing things like minting or burning a native currency, that has macroeconomic implications, that actually is affecting the currency supply. Okay, so that interplay is something we'll see over the next couple of examples. And I really know of kind of no analog of this in the traditional kind of mechanism design literature. This is really a new feature of the problems in crypto economics. So for the first example, let's go back to the very beginning, let's go back to bitcoin, and let's view it through a mechanism design lens.
00:03:49.598 - 00:04:25.940, Speaker B: Okay, so what would be the outcome that we're looking to incentivize? Well, we'd like all of the nodes running the protocol to run it as we intended, meaning they should all be working hard to solve their proof of work crypto puzzles. They should all be trying to extend the end of the longest chain. So mechanism design would say, let's set up a game like, for example, payments, so that nodes are indeed incentivized to do this. And probably the most straightforward way to do this, and the way it's done in bitcoin is just to have a block reward. So if you mine a block and that block winds up in the longest chain, then you will get some economically meaningful reward. If it doesn't wind up in the longest chain, you get nothing in the bitcoin protocol, at least. Okay.
00:04:25.940 - 00:04:52.474, Speaker B: And the intuition, hopefully, is pretty clear. Right. So, as a miner, you only get rewarded for the blocks you create that wind up on the longest chain. How can you make that as likely as possible? Well, it sure seems like you may as well start out by putting it on the longest chain, such as it is right now. Side comment. There's actually old paper by Al and severe which shows that's not fully true. So there are cases in which it is true.
00:04:52.474 - 00:05:43.286, Speaker B: There are other regimes in which actually, while block rewards do to some extent incentivize honest behavior, they even more incentivize other dishonest behavior. So it's sort of a cautionary tale of how hard it is to get the game theory right in blockchain protocol design. But what I want to focus on here is, all right, so you say you're going to give miners an economically meaningful reward. Where does that value come from? Who pays for it? Okay, and if you did not have access to a native currency, this would be a difficult or maybe even impossible question to answer. If your mechanism does have the ability to, in particular, print money to inflate the currency, then actually there is an answer to this question. And it's what bitcoin does, which is it mints new coins every time a block is created. That's in fact the only way that bitcoins ever get brought into existence.
00:05:43.286 - 00:06:09.534, Speaker B: Okay, so with that power of the native currency, you are able to manufacture block rewards out of thin air. Not clear how you would do that without that power. But as I said, with power comes responsibility. There are macroeconomic implications of anything like injecting fllation into your currency. Now, the way I described it so far, probably sounds like this inflation is going to go on forever. Blocks keep getting created. I said there were block rewards.
00:06:09.534 - 00:06:39.126, Speaker B: That's an increase in the money supply. But famously, as I'm sure many of you know, Nakamoto very intentionally set up bitcoin to have a hard cap. 21 million bitcoins is going to be the maximum amount ever in existence. You could imagine other versions of bitcoin. You could imagine holding everything else the same. Nakamoto consensus, Utxos, bitcoin scripts, all that stuff. You could keep it the same and change the monetary policy, and you would get another, arguably reasonable variant of the bitcoin protocol.
00:06:39.126 - 00:07:32.406, Speaker B: But that was not what Nakamoto did. Nakamoto made a macroeconomic policy decision to cap the supply. And if you think about it, this has immediate implications for then how this inflation is going to work, which in turn, as we'll see, really has interesting game theoretic implications. So, given that the bitcoin protocol never burns bitcoins, they're never burned in protocol. There's no sync for the currency, for the cap to stay, to sort of respect the cap the block rewards must necessarily go to zero, which is scheduled to happen maybe 120 years from now. Okay, so if the block rewards go to zero, you then have to ask, okay, well, now let's go back to our original question. Like, why are nodes actually incentivized to run this protocol at all? And the vision has always been, if anyone cares about it, 120 years from now, it's probably pretty valuable.
00:07:32.406 - 00:08:04.242, Speaker B: Hopefully, because it's valuable, there'll be sort of sufficiently large transaction fees that that's good enough incentive to have a bunch of nodes running the protocol. It's always been obvious that if transaction fees also stayed really small, that bitcoin really wouldn't function as we understand it today. But I want to tell you about a more subtle issue, which was investigated in detail several years ago in a paper by Carlston et al. Which is another difference between block rewards and transaction fees is the block rewards are steady. They're constant block to block. It's the same. Like right now, it's six and a quarter bitcoins.
00:08:04.242 - 00:08:48.740, Speaker B: Transaction fees can vary by an order of magnitude or more, okay. They vary from block to block. And that changes the game theory for miners in the bitcoin protocol. And in particular, imagine the miner, just before you cleaned out the mem pool, built a block, had tons of transaction fees, and you now have this empty mem pool. You're now going to be tempted to, given that there's no block reward, maybe instead of extending that last minor and conceding those transaction fees to that minor, maybe you're going to try to fork it away. So maybe you'll have a competing block at the same block height with roughly the same transactions, hoping the future miners will build on you instead of them. And in general, miners, when you have high variance in these transaction fees, have an incentive to undercut each other.
00:08:48.740 - 00:09:23.082, Speaker B: Now, here, if this ever actually did become a problem, there's a quite simple tweak to bitcoin that would actually sort of mostly fix it, which would be to smooth out those transaction fees over time. So if you mine a block, maybe you get 1% of the transaction fees of that block, but you also get 1% of the transaction fees of the next 99 blocks that get mined. And then the reward per block wouldn't be exactly constant, but it would be quite close. Now, interestingly so, that was many years ago. So that was 2016 paper. Certainly we didn't yet have DFI. Now that we do, this exact same story is recurring.
00:09:23.082 - 00:10:09.280, Speaker B: The modern version is in terms of MeV. So in some sense, block producers sort of siphoning revenue off of the application layer, and even more so than transaction fees. MEV can vary wildly from block to block, so you have exactly these same undercutting issues. You can again try to smooth out the rewards. And so you can Google MeV smoothing to see the latest from the Ethereum community on that idea. But it's definitely harder because while transaction fees are directly observable by the l one, by, for example, Ethereum main net MeV comes from the application layer and is not directly observable by the L1. So you need to also kind of make sure that there's a competitive market for block building so that the MEV actually gets expressed at the consensus layer where it can then be smoothed out.
00:10:09.280 - 00:11:02.910, Speaker B: All right, so that's example number one. Let's look at another one that shows this interplay between sort of microeconomic decisions and macroeconomic consequences. Let's segue from bitcoin to ethereum and from block rewards to transaction fees. So let's look at the market for Ethereum block space through the lens of mechanism design. What would be the desired outcome? Well, you might like that to be allocated as efficiently as possible, meaning the blockchain should be fully utilized, and the transactions that get included are exactly the ones that value execution as much as possible. All right, now, hypothetically, if a market clearing price fell from the sky, market clearing price, meaning a price that equalizes the supply. So like 15 million gas per block in Ethereum equalizes the supply with the demand for block space at that price.
00:11:02.910 - 00:11:34.506, Speaker B: So like 15 million gas of transactions. Exactly. Would be willing to pay that price, then we'd be good. We'd have exactly the right amount of transactions getting in those willing to pay the price, they would also be the most valuable transactions. Now, the market clearing price does not fall from the sky, so your mechanism has to do something else. And the sort of way it worked in Ethereum until a little over a year ago. And the way it continues to work in bitcoin is a first price auction, which basically says, you know what, let's let the users figure out for themselves what the market clearing price is.
00:11:34.506 - 00:12:15.798, Speaker B: They bid, they have to pay what their bid is. And you kind of hope that at equilibrium, the bids are going to be the market clearing price. That's the hope of that format. And so first price auctions, that's a lot of sort of work for people trying to get their transactions into a blockchain. And so that motivated the design of EIP 1559, which is the transaction fee mechanism that Ethereum has been using for now a little over a year. And so here the idea is to make things easier for users, make sure that they don't have to compute the market clearing price, compute it in protocol, or at least compute a pretty good estimate known as the base fee of the current market clearing price. Okay, so a little more detail.
00:12:15.798 - 00:13:06.066, Speaker B: Right, so you have to continually adjust the base fee because demand is always changing. You use the sizes of past blocks as an on chain signal for whether you should be adjusting the base fee up or down. And the good news is that unless the base fee is way off, unless it's way lower than the market clearing price, then in fact, it is completely obvious how you should bid in this transaction fee mechanism. So under normal operations, it's as trivial to participate in as, say, a second price auction. It also enjoys some really nice collusion resistance properties, which are important in a blockchain context. And interestingly, those collusion resistant properties hold only if you do something fairly counterintuitive with the revenues that are being generated by the base fee. The most obvious thing to do with those revenues is to pass it on to the producer of the block, just like you would with a block reward.
00:13:06.066 - 00:14:05.130, Speaker B: But then you're vulnerable to cartels between that block producer and end users. They could then have an off chain agreement that allows them to circumvent the base fee. So what the game theory tells you is that this mechanism works well, has the collision resistant properties, if and only if you take the base fee revenues and reroute them anywhere other than the producer of that block. For the game theory, it doesn't matter where it goes, as long as it does not go to the block producer. So that leads to another design question, which is like, okay, so we know where we can't set that revenue, where should we set the revenue? And there's different answers to this question. You can imagine different variants of EIP 1559 with different answers. The version of EIP 1559 which is deployed, which operates today in Ethereum, I think primarily, initially, just for simplicity purposes, dispenses with that revenue in the most straightforward way, right, just by sending it to dev null, literally removing the currency from circulation, burning it.
00:14:05.130 - 00:14:50.346, Speaker B: Okay, and one point I want to make is everything I've said up to this point, until we got to this burning property, everything else about EIP 1559 didn't really rely on the fact that Ethereum has a native currency. That all would have been basically the same had transaction fees always been denominated in, say, USDC. This is the part of the mechanism which you could not do without this power of accessing a native currency and being able to burn it. Like if fees were in try, you could burn a USDC on Ethereum. But that's not really burning the US dollar. That's burning a representation of a US dollar in a vault. The representation on the Ethereum blockchain, it's very different to literally delete the currency which is tracked by that blockchain itself.
00:14:50.346 - 00:15:15.326, Speaker B: Okay, so this is where we see the power in this particular mechanism. And again, with that power comes responsibilities, comes macroeconomic consequences. So here we have a force that's going in the opposite direction of the block rewards. Block rewards were inflationary. So here, burning revenues, that's going to be deflationary. That takes coins out of circulation. In Ethereum today, on any given day, there's going to be a tug of war between inflationary and deflationary forces.
00:15:15.326 - 00:16:03.070, Speaker B: Any given day, one of those might win over the other. Long term, I do think most of us expect Ethereum's currency to be deflationary in the long run. How should we feel about that? So this macroeconomic, unlike bitcoin, where it's very explicit, like the whole point, you started with the macroeconomic policy decision, 21 million bitcoins. Here we're getting a macroeconomic consequence, rather as a byproduct of our microeconomic goals, of wanting to have a transaction fee mechanism with good ux and then to dispense with base fee revenue in the simplest possible way. So is this macroeconomic byproduct good or bad? The answer depends very much who you ask. You ask anyone who holds eth, they love this mechanism. They think Ep 1559 is the best thing ever.
00:16:03.070 - 00:16:51.150, Speaker B: What's the reasoning? So this is sort of saying, well, let's think of Ethereum's market cap is fixed independent of the number of tokens which happen to be in circulation. Well, then if the supply goes down and the market cap stays fixed, the price per token, of course, increases. And so that's why ETH holders are happy about this idea. Honestly, if you ask anyone who's sort of trained in classical macroeconomics and you tell them this, they're like, oh, my God, that's a horrible idea. And they start telling you stories about sort of stagnation in Japan in the 1990s, your reaction is like, well, how much does 1990s Japan really have to do with Ethereum's cryptocurrency? I kind of sympathize with that. But it does kind of throw the gauntlet a little bit. I mean, really, we don't have a satisfactory, I'd say, discussion even of whether these are sort of different scenarios or not.
00:16:51.150 - 00:17:15.510, Speaker B: Okay, so in large part, I'd say this is an open question. Certainly in sort of this community, it's mostly viewed as a good thing. One quick final example. This is maybe less squarely part of crypto economics. I think this would meet some people's definitions, but not others. But I did want to say at least a little bit about the application layer. I did want to say a little bit about sort of the most recent work that I've been doing, which concerns automated market makers.
00:17:15.510 - 00:17:39.754, Speaker B: I assume this concept is familiar to many of you. The goal of an exchange is to allow people to buy and sell one asset for another, let's say eth. For USDC traditional markets, you'd use a limit order book. Limit order books are a poor fit for most modern blockchain protocols. They're just too expensive. They need to do too much storage, they need to do too much computation. Those are two things that are very scarce in typical modern blockchain protocols.
00:17:39.754 - 00:18:21.690, Speaker B: So automated market makers are just a much simpler way of doing exchange, where you're pretty much always ready to do business. There's always a spot price at which the AMm will be willing to buy or sell at that given price. And that price is some simple function of the current quantities of the two tokens. And one thing I want to point out is, I'd say, for AMM design, cryptocurrencies is not unlike the first two mechanisms we talked about. Unlike block rewards, unlike ep 50 59, cryptocurrencies is really not fundamental to amms. Yes, amms are often used to trade cryptocurrencies, but you could trade anything with an amms. It could be any assets, doesn't matter.
00:18:21.690 - 00:19:03.270, Speaker B: Okay. Furthermore, the operation of the AMM itself, all of the steps that it takes, it never references a native currency. It never needs to mint, it never needs to burn. This is why Uniswap could launch originally without a native token. It just didn't need one for its amms to work as intended. So rather, this is a problem which is novel, which we're considering because the scarcity, the computational scarcity of the blockchain protocols that we use to secure cryptocurrencies, that computational power is so scarce, it forces us to look at other designs, which then gives us new research problems to think about. So what's sort of the work we've been doing, I and co authors have been doing recently on automated market makers.
00:19:03.270 - 00:19:43.442, Speaker B: We've been focusing on the cost benefit analysis that's faced by liquidity providers. Liquidity providers, remember, they're the ones who deposit coins in these amms in the first place in exchange for a share of the trading fees. And so the question is, when is that a good decision? The benefit is obvious. You get a share of the trading fees. So that's some amount of money. What is the cost that you incur as a liquidity provider in an amm? Well, it's something known as adverse selection, which basically means that you may be forced to execute trades at unfavorable prices. So, for example, if the spot price of the amm becomes stale and gets corrected by an arbitrature, that arbitrageure is going to be making money at the expense of the lps.
00:19:43.442 - 00:20:18.050, Speaker B: So that's where the costs come from. Adverse selection costs being forced to execute trades at suboptimal prices. How can we isolate, measure and characterize those costs? The old answer is impermanent loss, which has its uses. Our critique of impermanent loss is that it conflates two things. It conflates the thing we really care about, which is adverse selection costs. But that can be occluded by price movements in the underlying assets, which makes it difficult to interpret why the impermanent loss might be high or low. Which of these two is the key factor.
00:20:18.050 - 00:20:45.162, Speaker B: So the new concept is something we call lever LVR. That's for loss versus rebalancing. And you can think of that as sort of take impermanent loss and mod out in some sense by the price movements of the underlying assets. So sort of, if you hedge all the hedgeable parts of impermanent loss, lever is like the unhedgible residue that remains. So I don't have much time to talk about this. I will know. I think the math actually turns out pretty nice.
00:20:45.162 - 00:21:16.322, Speaker B: You can check out the paper that's with my PhD student, Jason Milionis, my colleague CMac Molemi at Columbia, and Anthony Li Zhang at Chicago. There's also a couple of YouTube. There's YouTube talks by, I think, all of us at this point, if you want to learn more. All right, so let me just take a couple minutes to wrap up with some challenges for crypto economics. Just like my examples were no way exhaustive, neither are these challenges. I just wanted to group some of my thoughts in three different themes. So I'll say a little bit about each of the themes and then the example questions.
00:21:16.322 - 00:21:46.986, Speaker B: I'll just let you read. So grand challenge number one might be the most ambitious of all, which is to make macroeconomics our own. And here, when I say our, what I mean is basically the community in this room. So computer science researchers, blockchain researchers, et cetera. This is something we have seen happen with other parts of economics. So game theory has been around forever. Computer scientists got very interested in it largely about 25 years ago, and made it their own in the sense that they brought a lot of new stuff to the table and adapted it for their own applications.
00:21:46.986 - 00:22:12.582, Speaker B: They brought computational complexity. They talked about the price of anarchy. We saw it again with mechanism design. Again, computer scientists, over time, eventually added a number of new dimensions to that field. Focuses on, for example, communication complexity, sort of prior free auction design and so on. So the hope is that we see that happen again with macroeconomics. As you can already see in these 20 minutes, there's really reasons we'd like to do that.
00:22:12.582 - 00:22:47.262, Speaker B: Right? Like, is the hard cap in bitcoin a good idea or a bad idea? Like, is deflation in a cryptocurrency good or bad? These absolutely basic questions, we really don't have theory guiding us about how to think about it. So this might be a long term challenge. This might be ten to 20 years, but I do think it's going to be, going to be worth it, I should say. Thus far, there has been basically zero interaction between computer science and macroeconomics. I've given dozens of seminars at econ departments. We always go out to dinner afterwards. Not once, not once has there been a macroeconomist at the dinner following my seminar.
00:22:47.262 - 00:23:31.774, Speaker B: This is very little interaction thus far. All right, so the second challenge is the one I think we're furthest along on. So it's basically taking an area where there's already been a lot of really nice ideas, and just the goal is to develop into a sort of mature, crisp theory, which is incentives at layer one. And so I'm thinking about things like, for example, proof of stake slashing in protocol recovery from sort of 51% attacks. Again, we've seen a lot of good ideas, for example, in e two, for example, in eigen layer. I think we're making lots of progress, but it would be great to have a theory that's as sort of nailed down as, for example, the theory of fault tolerance in distributed computing, where we have a million different models. And in all of the models, we kind of know exactly the threshold at which you can achieve consensus or not.
00:23:31.774 - 00:24:07.962, Speaker B: So I think there are big opportunities to really take this to the next level. Finally, and this again, I think there's been some progress, but there's tons to do, is to understand crypto economics at each layer of the blockchain stack and also the interactions between those layers. So thus far, we've seen most of the focus on l, one fair amount of focus on the application layer, and not much elsewhere, frankly. Okay, so layer zero. So the peer to peer network for disseminating transactions, super important part of the stack. Very understudied from a game theoretic perspective. I really hope that changes soon.
00:24:07.962 - 00:24:47.094, Speaker B: Layer twos, they're kind of new, so maybe that's why. But we haven't seen a lot about the economics of L2s and how they interact with the other layers either. Mev I largely think of as an example of this layer to layer interaction between the consensus layer or the execution layer and the application layer. And so people like to claim MeV is unavoidable. I would like to see a theorem that states that fact. More generally, I would like to understand, is all this messy interaction we're seeing between the different layers of the blockchain stack. Is that a fundamental aspect of designing decentralized systems? Or actually, do we just need to think of some new architectures where we can get much cleaner separations between the various layers? So I think I'm out of time.
00:24:47.094 - 00:24:48.620, Speaker B: Let me stop there. Thanks.
00:24:54.910 - 00:25:07.374, Speaker A: I have a question. Hey, Tim. So in the second last slide, you said grand challenge number two, is slashing optimal, right? Isn't that one of the questions you ask?
00:25:07.492 - 00:25:12.974, Speaker B: So slashing necessary in some sense, which, of course, the question then is like, necessary for what? Yeah.
00:25:13.012 - 00:25:15.038, Speaker A: How do you actually even formulate that question?
00:25:15.204 - 00:25:55.158, Speaker B: You can ask that question about almost everything I wrote in these last three slides. Yeah, sorry. The question was, what do I even mean by kind of, is slashing necessary? Like necessary for what? When I say optimal economic security, what do I mean? This is characteristic of being at the very early days of a scientific field, which is like, all the parts are moving at the same time. We're not sure about our definitions, we're not sure about our problem statements, we're not sure about our theorem statements, we're not sure about our proofs. They're all moving. So I'm open to how to do that. I mean, slashing in particular, for starters, I would just be very happy to see a result which says, consider some property p on the one hand, a possibility.
00:25:55.158 - 00:26:28.418, Speaker B: Maybe that's something to do with in protocol recovery from 51% attacks or something like that a possibility result, saying that you can do it with slashing. We already have examples where we have results of that form, for example in e two. But then what we're lacking is sort of impossibility results. So you have to define a space of all possible permissionless protocols. You have to say what it means that the protocol does not do slashing. It doesn't sort of secretly do it in some hidden way. And then you'd want to prove an impossibility result that says you cannot actually achieve property p in as broad a range of parameters as you could with slashing.
00:26:28.418 - 00:26:45.920, Speaker B: And ideally p is something we really care about, but at least to get the ball rolling. I would like to see that true for any p. Alternatively, maybe there's some black box reduction. You give me a system that relies on slashing, I'll give you back some transformation of that system with the same economic guarantees, but without using slashing. I don't know.
00:26:46.370 - 00:27:24.582, Speaker A: Thank you. Of course I have a question related to your grand challenge number three. So I like to see your view. So you talk about l one, l two, how to get money or the value from the application layer. But theoretically is application layer could collapse all the layers and grab the value from the l two, for example. What I mean give you a concrete example is that for l two today they pretty much cannot, from economic perspective sustains itself. The sequencers won't capture much value, the token won't accrue value because of sequencer revenues.
00:27:24.582 - 00:28:13.434, Speaker A: Technically, if the app like app chain, like a lot of people talk about today, is you could build into the L2 scaling functions into the D app itself and you basically remove the L2 altogether and you capture dialogue value in the app D app. And also you can actually create a new usage of your app tokens, utility of app tokens to basically for the sequencers stuff. So this dynamic I think going to happen whether you like it or not because whoever control the user eventually have the most revenue they don't want to pass along to lower layer. I think same thing happened today. I just saw like for example Zk bridge. Technically if you build the Zk bridge into your application, you could remove the bridge revenue or the bridge functions altogether. I just want to see your view on this.
00:28:13.434 - 00:28:17.734, Speaker A: And how do you think the dynamic looks like and what's your recommendation?
00:28:17.782 - 00:28:22.490, Speaker B: So just to understand, you're saying you expect all the value capture to move up to the application layer. That's your conjecture.
00:28:22.830 - 00:28:27.694, Speaker A: The value passing down, they pass from the user to application to L2 to layer one.
00:28:27.812 - 00:28:33.886, Speaker B: But again, I just want to make sure. Correct. Your conjecture is that all of the value capture will go up to the application layer. Right.
00:28:33.908 - 00:28:41.090, Speaker A: The question is whether they want to pass along to L2 or layer one instead of layer one. Say, I want to capture value of your application so I can survive.
00:28:41.590 - 00:29:03.802, Speaker B: I think that's plausible. I'm a theoretician by nature, so anecdotes I find helpful. But ultimately I'm not really satisfied until there's a formal analysis. And of course, obviously that's going to be in some model where you make some assumptions. The assumptions may or may not be true. There's all that stuff. But part of being so early to the space, I hope you all have this visceral sense too.
00:29:03.802 - 00:29:53.574, Speaker B: We've just explored so little of the design space that's out there for every single part of the stack. Frankly, I'm always very nervous when someone says, you can't do x, or like, x has to happen no matter what design you use, because we do not have good mental models for the design space yet you can always, like with math, you can prove an impossibility result, right? You can say like, well, here's like a very weak notion of a permissionless protocol that would satisfy anything we could possibly imagine. And here's a mathematical proof that you can't do x with any protocol in that family. To someone like me, that's the really sort of forceful argument. So I'm not disagreeing with your logic. To me, that's just, I would view that as a conjecture. And we think an interesting problem, or at least exercise, would be to set up plausible economic models and dynamics under which, at least in the long run, you see exactly the same dynamics that you're predicting.
00:29:53.574 - 00:29:57.210, Speaker B: I think that for someone like me, that's kind of what I would like to see.
00:29:57.360 - 00:30:02.254, Speaker A: Okay, yeah, this is like a count of intuitive, like, you think l one would grab value from, right.
00:30:02.452 - 00:30:04.000, Speaker B: I want to make sure everyone has a turn.
00:30:06.930 - 00:30:30.866, Speaker C: So it seems like behavioral economics plays a role in people's, like, what's happening right now? We're in a bear market, and that's driven, at least in part, by people's personal biases, et cetera. Is there a way to run more intelligent experiments, macroeconomic experiments, now that we have this new primitive to see how people respond to, or can those really be modeled perfectly using game theory?
00:30:30.978 - 00:31:32.442, Speaker B: Yeah, that's a great question. So it's sort of a question of like, when we're modeling people's preferences, what kind of fidelity do we need I mean, one thing I want to point out is behavioral economics is usually more on the microeconomic side, or at least I see it show up largely as a corrective on the microeconomic side. I don't know. Instead of just assuming people have quasilinear utility, you assume they have something else. I will say I sympathize with your comment in that, especially if you look at my bottom one on grand challenge one, which is just like what drives token price, which, of course you could imagine at a 16 z. All of our projects are very interested in having better mental models for this. That's the question where I do wonder if what you bring up is going to make it very difficult, that the answer may just be so dependent on these things like the cycles and the bubbles, and that without some kind of unrealistically deep understanding of the psychology, you may not be able to get a very accurate answer to that last question.
00:31:32.442 - 00:31:49.950, Speaker B: A lot of the other ones here, I'm not sure. It's crucial that you deeply understand the psychology of sort of users of these protocols, like hard cap or not. It's not obvious to me that that would be so dependent on what your model is of people's preferences, even with inflation.
00:31:51.090 - 00:31:57.870, Speaker C: If you buy the idea that the reason that people reinvest their money during a downturn is because they think that inflation is eating their money away.
00:31:57.940 - 00:32:12.840, Speaker B: Yeah. This is, again, sort of getting back to the last question on this slide. Okay. If you're like a trader type and you're focused on prices that may be out of reach because of the psychological aspects, if you look at the questions on this slide, they're mostly not of that nature. Right.
00:32:13.290 - 00:32:14.150, Speaker A: Yeah, makes sense.
00:32:14.220 - 00:32:17.000, Speaker B: Thanks. Okay. All right, thanks, everyone.

00:00:01.360 - 00:00:27.200, Speaker A: My name is Joe. We work on a protocol called Witness. This presentation is basically 15 minutes of a high level overview of kind of what this protocol is, why we think it's interesting, how it works, et cetera. And then we're going to go through a little bit of a workshop that hopefully will be a little bit interactive. We'll let you guys kind of play with the MVP app. We have understand how application developers can interface with the protocol as well because that part of this architecture actually differs a lot compared to most blockchains. Be something very important to highlight.
00:00:27.200 - 00:01:00.250, Speaker A: As I said, we'll go through what this protocol is, why we think it's interesting, demo some use cases and yeah, anytime you guys have questions, just feel free to raise your hand, we can run through it. I think you both are familiar with our backgrounds, but just for the sake of the recording. My name is Joe. I was previously an investor at Framework Ventures. I've been on chain for the better part of the last decade and I'm very passionate about extending on chain guarantees to the rest of the Internet. Sina also very passionate about that idea. Spent previous time as an engineer at Paradigm, Google and Meta I think is one of the better solidity engineers in the space, if not the best.
00:01:00.250 - 00:01:47.644, Speaker A: So what does witness protocol do? We start this anytime we're introducing the protocol to people, especially at an event like this, where people are focused on the various layers of these blockchain resources, what are they able to provide to us? Different of these, like different ones of these layers or multiple of these layers can provide us some of this, like some similar resources. And so when we think about what those resources are, you can obviously get execution from a blockchain. You can also get this kind of DA data availability resource. And at witness, what we were really interested in is actually this resource that we believe is kind of a nerfed version of data availability. But because it's nerfed we can significantly reprice it, which means it's more accessible for developers. And this is kind of the lens that we view through. So like what is witness? It is extending the data existence property of blockchains.
00:01:47.644 - 00:02:11.716, Speaker A: And if you guys have questions around what that is, I can kind of get into that in the next slides. But we're creating trustless timestamps at scale. There's kind of two portions to this protocol. That's why we don't call it a blockchain is because not everything is happening on chain. And that's actually the nuance of this architecture. And so two things are happening off chain, we have users that are essentially receiving proofs from an API interface. And these proofs are basically sovereignly verifiable, trustless timestamps.
00:02:11.716 - 00:02:38.316, Speaker A: On chain, we have a set or a series of smart contracts that periodically verify and update the root hash of this data structure that we're basically adding hashes to over time. And I'll get into the specifics of how that operates. But when we think about like, ok, feel free to hop in. No worries. Welcome, welcome. No, no worries. When we think about what witness is, this off chain component operates as a verifiable data structure.
00:02:38.316 - 00:03:17.036, Speaker A: And does that ring a bell for you guys as far as what a VDS is? It's essentially a data structure. As you manipulate it, you can verify basically the manipulations that you've made to it in some ways. And specifically this operates as a Merkle mountain range, which is a specific type of Merkle tree. We'll get into why those properties are interesting for the protocol here in a bit. And then also off chain there's this web two API, an interface for application developers to basically send hashes of information to and retrieve proofs from us. On chain we have an immutable smart contract, and this, the same smart contract, is actually deployed across many EVM networks. Right now we're live on Ethereum optimism base, like basically every major testnet as well.
00:03:17.036 - 00:04:07.710, Speaker A: And what's happening here is essentially, I think I actually get into this next slide, which might be a better portion for it, but this Merkle mountain range is essentially getting checkpointed against this immutable contract. That's what's happening on chain. It gives us these nice properties that we'll chat through first thing we want to kind of like center the room on, especially in a space or a conference where people are talking a lot about scalability. Is this kind of broad question of like why isn't everything on chain? And when we think about like what my answers would be or what kind of our opinions at witness on are about this, it's kind of this aspect where there's this always this kind of initial and upfront cost you have in order to interact with these permissionless dynamic markets. Right? We're very familiar with the fee market dynamics. On a network like Ethereum, even a network like Celestia, you have these kind of priority fees where as more people start using the shared resource, it becomes more expensive for everyone. And so there's kind of this diseconomy of scale that occurs.
00:04:07.710 - 00:05:03.686, Speaker A: The reason witnesses architecture makes sense to us is because although it creates a new trade off space. Part of the output of that tradeoff space is the fact that this thing is essentially, we can amortize the cost of one dynamic consumption of on chain resources to represent many off chain artifacts. And candidly, when I say many, I mean millions, tens of millions, hundreds of millions. And so a lot of what we're thinking about is like, okay, when you're in a room with someone or maybe taking a selfie or something, what's preventing people from minting these things at that scale today, where applications might be thinking like, oh, I meant one thing per user, per user session. What allows them to think differently about basically receiving this resource of hardness from blockchains at a different scale? So removing that glass ceiling is something we're interested about because I think we've all seen it. But almost all of the applications we're using today are inherently financial in nature. And that's because there is this upfront cost to leverage these resources.
00:05:03.686 - 00:05:50.400, Speaker A: Any questions? Just as I'm running through things, just want to get sentiment again. Yeah, so you're talking about like, could I get, maybe give some more context into this, this proof word that I'm using that I haven't described? So, thank you. Essentially what this proof is is it is a merkle proof that resolves to a checkpoint. And that merkle root represents this verifiable data structure that we have access to off chain. And so the way to think about it is that as soon as we land a checkpoint of this Merkle route on chain, we can produce a proof that is the merkle path that allows a random hash that someone's trying to prove to resolve to the chain. So I'll kind of walk you through, like, some of this and some of the upcoming slides. But it's a great question and we probably should have started with that a little earlier.
00:05:50.400 - 00:05:50.740, Speaker A: So I think.
00:05:50.770 - 00:05:52.608, Speaker B: So it's proof in numerical management.
00:05:52.744 - 00:06:18.990, Speaker A: Correct. It's basically proving that this thing was included or witnessed at a certain time. That's like one way to think about it. What does witness do? Is allows you to prove to an untrusting party or an on chain contract that a specific hash of data was witnessed and maybe hasn't been modified since that point in time. A great question. Thank you for that. And yeah, why are we building this? We think if we extend the hardness of public blockchains, and using this word hardness, it means this verifiability.
00:06:18.990 - 00:06:54.080, Speaker A: If we have the potential to extend that to the rest of the Internet, we can accelerate the adoption of public blockchains as these universal standards for coordinating around things like ownership, truth, etcetera. And some of you might have seen this tweet, but this really hits for people, I think. So it's worth summarizing. Why build witness? What is it? This is actually the only part where blockchain really comes into play is this verifiable ordering. I could just verify a signature that you make to me off chain. I don't need a blockchain for it. We think this is actually this really novel property that we need to find ways to extend and incentivize people to leverage.
00:06:54.080 - 00:07:06.712, Speaker A: Hopefully that captures it succinctly for you guys. Do you maybe want to chat through your perspective? Because I feel like you do a good job describing this one. I can hold the mic for you, but yeah, sure, it's going to not extend too far.
00:07:06.816 - 00:07:31.244, Speaker C: Yeah. So this is kind of an interesting graphic that we. So basically what this graphic is trying to describe is like this sort of overlapping Venn diagram of what data you can actually sort of express in sort of a web3 way, quote, unquote. So obviously, the smallest circle just has the data you can post on chain without DaeV. Think of call data roll ups, stuff like that. Then you get 4844, sort of align DA. Maybe even you count Eigen layer in there.
00:07:31.244 - 00:08:08.120, Speaker C: You also have the unaligned DA. So the circles are getting bigger as you almost degrade the DA relative to the base layer that you're looking at, or sort of even factor in some of these more centralized DA's, data availability committees, stuff like that. But the punchline of this graphic is that no matter how many of these Da layers you stack on each other, a, you're kind of degrading what it even means to have DA at a certain point. And then b, at the end of the day, you're never going to really hit Internet scale for sort of data that could benefit from being sort of interoperable with the chain, effectively. So making more data portable, you don't necessarily need dA. You can just do it via witnessing it, which is what we built.
00:08:09.340 - 00:08:17.810, Speaker A: Thanks, sir. Any questions on this graphic? Because I think this does, again, it does a good job of succinctly describing the why, like, you know.
00:08:20.790 - 00:08:21.890, Speaker D: Separate layers.
00:08:22.550 - 00:08:23.742, Speaker A: Do you have any thoughts on that?
00:08:23.846 - 00:08:40.134, Speaker D: Can you say it again? Da waterfall. Yeah, I feel like it's like, can they be like fully integrated or like. Yeah, I mean, I think one way to think of it is like, what's data that's never going to benefit from sort of, or never is going to make sense to be made available. Right. Think of like tweets or like discord messages or far past your cast.
00:08:40.182 - 00:08:40.390, Speaker A: Right?
00:08:40.430 - 00:08:45.460, Speaker D: Like, would someone make a post on social media costing them a cent, $0.10, those kinds of things? Probably not.
00:08:45.800 - 00:08:53.020, Speaker A: But an application developer develop an application if they know, like, an end user is going to always have to pay an upfront dynamic fee that they might not necessarily control.
00:08:53.360 - 00:09:26.846, Speaker D: Yeah, but I'm going to talk about this. I mentioned waterfall. Like, is it possible to do this? Something like everything is just witnessed and then over time we're. Yeah, I mean, that's kind of over time how much security or how long we want it. Yeah. And kind of part of the thesis here, actually, is that you don't need da for a lot of cases, which I think is exactly what you're getting at. Or you can have sort of different types of dynamics in a lot of cases where you have like a data availability committee, for example, like, would it be better if you just had like some kind of witness timestamp and then you as a user just testing your own data? Right.
00:09:26.846 - 00:09:56.040, Speaker D: Maybe that's even better than delegating it to like, this committee of companies or whatever, if it's obviously this application being a model where you can sort of get away with users custody the data. But I'm also talking about, like, can they be like, can we move in like selective ring or something? Like, where we have some hierarchy of data importance, like, something actually gets on, like, gets on ethereum while others are just. Yeah, yeah, I mean, that's kind of exactly what this gets up. Yeah.
00:09:56.080 - 00:10:32.590, Speaker A: The only thing I would like modify about this graphic is like, when we think about like the actual, like, you know, we're trying to represent like the size of data with these. These different circles here. Arguably, if we remade this graphic, I would make this 199 times bigger. In the sense that we think about what percentage of data on the Internet exists in these three buckets. It's less than a basis point, probably, when you think of the percentage. A lot of what we're saying is that, hey, there's all this other stuff on the Internet that can benefit just from this even very light guarantee of this data existence. Guarantee can allow applications to think differently about how they coordinate and potentially how they compose on chain.
00:10:32.590 - 00:10:57.520, Speaker A: Great questions. I appreciate it. So let's kind of break down, like, how witness works. We've kind of described, like, why we think this thing is interesting. It gives you a different scale of access to this resource that blockchains quite uniquely provide. And so the way that we kind of break this down is there's like this five step game that's happening. We have an app user, we have the witness API, and then we have the actual on chain protocol.
00:10:57.520 - 00:11:28.274, Speaker A: And I'll walk through each of these steps. Who are the actors involved in each one? But the first thing we have is that a user is submitting their data as a hash. Notably, the underlying data that is represented by that hash is never shown to our protocol. It's never relayed to our API. So there is some nice privacy properties we can chat about later with regards to that. What the API is doing is that it is essentially aggregating hashes from any client that is consuming the service. So, you know, I've seen us sending me 1000 hashes and you know, some like another five applications are all sending me hashes.
00:11:28.274 - 00:11:51.994, Speaker A: We're aggregating all of those into essentially what is a new Merkle root of this tree that we're operating off chain. And one way to think about that data structure is the append only list. We're basically saying, hey, during this epoch we added these events. Those events are all individual unique hashes. Periodically that API is submitting the new Merkle route that we've arrived at. We say, okay, we've waited five minutes. Perfect, we're going to aggregate all of this.
00:11:51.994 - 00:12:29.404, Speaker A: Take that new Merkle root and we're actually going to broadcast it to the chain. When it gets broadcasted to the chain, the protocol is doing two things. The first thing it's doing is it's verifying a consistency proof that ensures that all we did with this new root checkpoint is add new leaves. So it enforces that append only aspect of this verifiable data structure. The other thing it does is that obviously we're paying for this data availability resource when we go and broadcast this transaction. A nice byproduct of that is that this root checkpoint gets broadcast for anyone in the world that wants to see it. So we publish this new route and that is actually what allows us to coordinate around these off chain proofs.
00:12:29.404 - 00:13:08.310, Speaker A: So we have this checkpoint on chain. What's happening here? Once that lands on any of the chains that we support, a user can then come in and request this Merkle proof that I was mentioning earlier that you were asking great questions on. And that merkle proof is actually the trustless timestamp. Once we get to the end of this flow, what are the key things to kind of take away from it? The first is that only the protocol is paying a static amount of gas to update this thing. And so the idea is like, even if there's a million hashes being submitted during a certain period of time, the costs associated with that, with air quotes, can be amortized across all the clients that are getting benefit from that. Right. The gas usage.
00:13:08.310 - 00:13:41.170, Speaker A: So the amount of gas it takes for us to process a transaction at the protocol level is always around 90,000 gas, depending on some dynamics there. Yeah. So if the priority fee goes up and down, you're absolutely right, but we're still only being exposed at a static gas usage. So if I have one proof that I'm adding, or, sorry, one hash that I'm adding to this verifiable data structure, I make a Merkle route, I bring it to the chain, I'm paying 90,000 gas. If a huge application is leveraging this and there's a billion entries into this tree, that gas usage is still 90.
00:13:42.710 - 00:13:47.782, Speaker B: I understand it as like a technical point. Yep. I think it's interesting to have this.
00:13:47.806 - 00:13:48.934, Speaker D: In mind that you're like, it's a.
00:13:48.942 - 00:14:08.310, Speaker B: Static, for example, gas fee, it's not interesting for an app user, for example, protocol, in the sense that they don't really care. Like, if you tell them, okay, each time you're gonna pay, like, okay, because it's our time, ultimately, the protocol, you're gonna pay x gas. It's like, okay, I don't care about the number of guests I pay, I.
00:14:08.350 - 00:14:09.790, Speaker D: Care about how much I save.
00:14:09.870 - 00:14:34.016, Speaker A: So I'll add some dynamics here. The first thing is that we're not charging people on a per entry basis. The idea is that we want to basically turn what is a dynamic and upfront market into a static cost for applications. What could that look like? Right now we're trying to get people to experiment with this primitive. If you want an API key, you'll have an API key for it. And again, under the, under the context of, it's increasing our ephemeral storage costs for storing this data tree off chain. But that's a much more scalable cost company like this.
00:14:34.016 - 00:15:00.442, Speaker A: The example I kind of give people do crudely, if you took every action that's gone into discord as an application, there's been some things they published around this. Every, like, every comment, every new user creation, all of those events. And you wanted to give them verifiable timestamps. We could run that through an architecture like this. Over the course of a year, none of the on chain gas cost is changing. The ephemeral storage that is associated with storing those leaves does increase. So that's like the one kind of dynamic there.
00:15:00.442 - 00:15:27.956, Speaker A: But it speaks to the scalability of this sort of an approach because regardless of how many people are using it, the cost that we're paying on chain is static. You bring up great points around the priority fee. That's something that we'll gauge as it comes to how often we're checkpointing to different chains. But great questions. The other thing that's really important to take away from this whole thing is like I've talked about this centralized API that we operate and we are very explicit with those words. We don't try to beat around the bush around that. That's because the architecture kind of empowers this unique degree of sovereignty.
00:15:27.956 - 00:16:00.854, Speaker A: And what I mean by that is as soon as you have this merkle proof, the only thing that is required in order to verify it is to have access to the underlying dare layer that the root checkpoint was posted to. So that means that if you're showing this to a party that doesn't trust you, they don't need to go verify a bunch of signatures. What they need to do is go verify that the root checkpoint that the merkle proof resolves to landed on chain. Maybe they're trusting an infra provider, maybe they're running their own light client, maybe they're just trusting and verifying later. But that's kind of the spectrum that it gives you. But go ahead. If you had a question for the.
00:16:00.942 - 00:16:05.446, Speaker D: Proof, the end user has to save themselves somewhere.
00:16:05.598 - 00:16:56.990, Speaker A: It's a great point. The protocol is unopinionated around where the proof goes. If someone brings a hash to our explorer, for example, right now we're going to give you a proof if we have it for you. When you talk about sovereignty though, you bring up a great point, which is, is an application going to store this on behalf of a user? Are they going to allow our user to exit it? And the key here is that regardless of where this data is custodied, wherever it's stored, that verifiability can still follow it. So even if I'm like hitting a centralized API like I don't know, weather underground or something, and I want a signature from them that's timely, from their API, they can prove that they produce that information at a point in time, regardless of how that data moves around. It can move between data storage networks, it can move between data availability networks through maybe a, like a federated system, like how we're seeing with a lot of the social protocols right now, like Farcaster and blue sky. The protocol at its core is not opinionated about where that data gets stored.
00:16:56.990 - 00:16:58.990, Speaker A: But as an application developer, you're at.
00:16:59.030 - 00:17:02.130, Speaker D: This API doesn't guarantee the availability of the proof.
00:17:03.070 - 00:17:28.765, Speaker A: We wouldn't describe it in the same way that like, you know, a celestial layer gives you like, gives you guarantees around it. Right. Could you optimistically trust us? Yes, but the idea here and the nice kind of property of sovereignty that we're hitting on, and I think you're asking great questions on ISdev, that once you have the proof produced, you have the option to exit, essentially. And so if you want, you know, if it gets deleted and you want to come back for us, hey, maybe we still have it. Great. But that's not a guarantee that we like discussing around the protocol. It's not one we wouldn't write about the protocol.
00:17:28.765 - 00:17:59.182, Speaker A: But a fantastic question, what's the frequency of? So it's different between the different networks that we support. And again, this goes into the cost because, you know, we're paying that 90,000 gas as many times as we checkpoint in a day. We checkpoint on testnets. I think it's like every 25, 30 seconds, we're checkpointing on base, which I think is our fastest network right now, every ten. But we could probably knock that down. A lot of what we're waiting for there is to see how people want to leverage this. Do they get value from kind of a higher frequency or cadence of checkpointing? On Ethereum, for example, we're checkpointing around once a day.
00:17:59.182 - 00:18:01.090, Speaker A: So it differs depending on the network.
00:18:02.590 - 00:18:15.420, Speaker D: It's the kind of thing where once the economies of scale kick in of having people using this, it starts to make more and more sense to crank that down because starting to basically amortize that ux across a certain number of parties. Right. Still sort of like bootstrapping that initial fix. Yeah, absolutely.
00:18:15.460 - 00:18:17.996, Speaker A: And we're very early in that journey. That's kind of a dynamic bootstrap.
00:18:18.028 - 00:18:19.252, Speaker D: So at the moment, you're not charging.
00:18:19.316 - 00:18:34.440, Speaker A: Fees or how do I. Yeah, at this stage in this, we're fortunate to be venture backed in the sense that we can go experiment with this primitive, understand how it brings utility to different applications. We're also building applications on top of this protocol as well that we'll kind of demo here in a little bit. But, yeah, hitting all the right questions.
00:18:35.020 - 00:18:38.074, Speaker D: If you charge fees eventually, would it be on chain or off chain?
00:18:38.212 - 00:19:30.030, Speaker A: We've actually discussed that a little bit, especially because some of these payments can be made cheap enough. Now, I think we would probably want to accept a number of ranges there when it comes to the preference of a user to pay for this. So the quick TLDR that we have around how to use witness is really as simple as three steps. You're submitting a hash of whatever data format, regardless of size, location, et cetera, that you're attempting to retrieve this resource for this trustless timestamping. We're submitting a root of this verifiable data structure that allows your proof to be produced and verified by anyone, and then you're having this proof distributed back to you by the server, at which point that proof is sovereign for the user. We have a quick replicate demo that we can go through that shows really the SDK. If people are interested in this room and diving into that, we can go into it now if we want to skip over it and chat more about some of the use cases and some of the other things, we can shift through that.
00:19:30.030 - 00:20:08.656, Speaker A: So I will pull up this little demo and I'll kind of describe what this is before we kind of play it, and I'll kind of pause and play through it. But this is an application that we've developed on top of the protocol called cosign. So you can think of this as something that could be created, leveraging the protocol's resources that it scales. And the idea with this is really to kind of demonstrate this lazy minting flow. You're doing something off chain with signatures that leverages the protocol to prevent you from having to pay an upfront and dynamic fee be as you're initializing content, as you're performing actions within an application. So what we're doing here is essentially we're logging in with kind of like a privy style client, if everyone's familiar with that. We're uploading an image here.
00:20:08.656 - 00:20:33.528, Speaker A: In this case, it's from the trust infra day. The other day when I click cosign there, you'll see the wallet pop up here. But I'm basically writing my signature on there. I'm saying, hey, Osprey, saw this piece of data. If we go back to that tweet, what's the last thing that we could prove about that signature is when was that signature made? That's what witness is actually going to empower through this flow. So once you see this kind of refresh, you're seeing like, oh, we're kind of pending on chain. What does that mean? We're waiting for that checkpoint to land.
00:20:33.528 - 00:20:57.280, Speaker A: So we've submitted it to the API. The API has given us a valid request that it was accepted. And now we're waiting based on these intervals to see it. For this demo, we're leveraging base sepolia, which is their kind of predominant testnet. So you'll see this flow actually happen quite quickly where we're expecting this base sepolia thing to have already landed on chain. If I go back to the application and give it a quick refresh, you'll see that that button up there actually changes. And I'll take a quick pause once it updates.
00:20:57.280 - 00:21:24.024, Speaker A: We've created this off chain object. We've basically made it so that you can verify what it is, who signed over it and when it was signed. All of those properties, even though they exist off chain, are verifiable by smart contracts. And so in this next step of the flow, what we're saying is, oh, trust. Infra day was a banger. It's two years in the future, and I want to have the ability to actually compose with this object on chain and for anyone to be able to verify that like, oh yes, it originated at that point in time. That's what this flow is going to demonstrate.
00:21:24.024 - 00:21:49.362, Speaker A: But we're not waiting a year, we're going to go ahead and send some testnet eth. And this asset has been minted on base tupolia. Obviously there a user is paying a transaction fee to compose with the data when they bring it back on chain. But the idea is you remove that dynamic from the initialization of content. This is just kind of an example of what the UI looks like. If we think about Farcaster as a protocol. I won't go into the technicals of it, but people are passing around signatures.
00:21:49.362 - 00:22:34.768, Speaker A: You have this federated system that is storing your data for you that you're to some degree trusting. Maybe it's on in our servers, maybe it's on Dan Romero's server back home, who knows? One thing here though, is that as these users broadcast these signatures on the protocol like a cast, there's no verifiable ordering around that. So, for example, if I wanted to basically make a farcast and they go throw it to my own hub and start gossiping that information with the network, if I wrote down the timestamp that I made this tweet or this cast six months ago, that's what the protocol is going to show users in the interface. So that's kind of like an interesting example where all people are doing are throwing these signatures around. And a way to make them composable with blockchains is to give them this verifiable ordering. And that's that property that we try to extend from blockchains. And so this is just like an example of like, oh, I upload this post.
00:22:34.768 - 00:23:12.672, Speaker A: It allows people to interact with it in a different, like, oh, imagine it's like a bookmark or a retweet or a super, like. And now when I refresh this page, you're going to see that our interface is kind of contextualizing that signature from that other platform here. And Opensea's testnet support's a little wonky, but that gives us an idea. It actually composed it to the jade. Any questions on the demo? We actually have one that you guys can cosign if you want to play around with it on this. I think this next slide here, if anyone wants to scan, you can actually see what this flow looks like. And again, the nuance here is that, like, since no one's paying a transaction fee, this can be happening like hundreds, if not thousands of times for any scale of users within an application.
00:23:12.736 - 00:23:13.980, Speaker D: It's like a fault that.
00:23:14.280 - 00:23:16.400, Speaker A: Exactly. It's a great way to put it.
00:23:16.560 - 00:23:28.340, Speaker B: The point here is like, in this example is just to say, okay, I sold this fault or I did this fault, and to like, verify. Anybody can verify, don't check.
00:23:29.950 - 00:23:40.078, Speaker A: Even though this information exists off chain, you're still empowering smart contracts and untrusting parties to leverage blockchains to coordinate around that data. I'm no longer trusting your signature. I'm trusting something deeper.
00:23:40.094 - 00:23:49.370, Speaker B: I don't need witness to do that because I could generate a hash of data by myself and then send this.
00:23:49.990 - 00:24:09.226, Speaker A: It's actually a nice exit guarantee of the protocol. Actually, that's kind of what Cina always says. It's like, oh, if we ever stopped serving you or we were serving you in a bad way, could you go post a hash on chain? Yes, if you wanted to go post a million hashes per user, or like, if you wanted to achieve it at that scale, then you're exposing yourself to that dynamically priced market.
00:24:09.378 - 00:24:17.430, Speaker B: What you're doing is proof aggregation. It's the same thing as what nibra or CNA or Lla are doing.
00:24:18.170 - 00:24:19.122, Speaker D: We don't want to sound as big.
00:24:19.146 - 00:24:30.770, Speaker A: Brain as I would say the aggregation element of those systems that you mentioned are somewhat similar that we're saying, hey, we can consume this constant resource and attempt to scale it to many, many users.
00:24:32.510 - 00:24:38.490, Speaker B: What are some of the largest use cases that you see in your mind? What is your vision for your protocol?
00:24:38.830 - 00:25:29.692, Speaker A: What could it be leveraged for perfect segue into this slide. Why do we think this is cool? Which is a great question. The first is the on chain composability aspect of this. So right now you can have a smart contract verify a signature over a piece of information. Unless you kind of have a protocol like this that can scale this existence resource, it's actually quite difficult to verify the timeliness or ordering. That means that people can think differently, in our opinion, about things like open editions, like lazy minting, so that more parts or components of an application that might be quite granular, things like likes, things like proofs that people aren't, sorry, not proofs, but posts that people wouldn't even think to mint today because it's too expensive, there's too much friction. This allows them to think differently about, hey, I can actually anchor this information to the chain in a very scalable way that has the potential to unlock some kind of novel composability.
00:25:29.692 - 00:26:03.550, Speaker A: Things like enforcing fees, things like allowing for fungible assets to be produced from these timely proofs. It's one aspect that we think is interesting. There's also a lot of excitement recently around people experimenting with attestations. The way to think about this is that something was said by someone at some point. Attestations can actually be custodied off chain in a fully verifiable way using a protocol like this. And we think that means that people can experiment with a different scale of attestation designs. There's also this aspect of data portability between applications because you can verify the timeliness.
00:26:03.550 - 00:26:53.000, Speaker A: You might be more willing to coordinate with data produced by another application because you know that they could not have backdated this information. If you're expecting for these signatures or these proofs to be present in the data sets that you're trying to, that you're trying to move around, or that you're trying to compose with in an off chain manner. There's also this element of just like incentivizing data to move on chain. I make this joke that like, I think we were saying it when we walked in the room, like everyone's thinking about like how I bring applications and users to like pay for my chain. I don't think as many people are thinking about like how you extend the existing guarantees of blockchains to like the rest of the Internet, as we kind of described with that graphic. And we think that's like an important thing to try to kind of accelerate. And when we think about how society, like the adoption rate for society, coordinating using blockchains there's also just this general aspect of trustless timestamps at scale.
00:26:53.000 - 00:27:37.030, Speaker A: I think the nuance here is that except for maybe two or three systems that are widely adopted across the modern Internet, every time stamp you see is a signature from some trusted authority. The exceptions to that are a system called certificate transparency, which many of you have probably used hundreds of times. And it's what empowers you to essentially have that green lockbox pop up in your browser. If those SSL certificates aren't included in a verifiable data structure that your browser is literally requesting from a publicly available log, your browser will not accept it. And that's what basically brings accountability to that system if one of those authorities misacts. So it's an example of like an immutable trust log that leverages these sorts of concepts. And candidly, that is what's scaling the majority of modern encryption on the Internet today.
00:27:37.030 - 00:28:15.842, Speaker A: Another example is like the Apple keychain, if you're familiar with how that system self audits itself basically prevents the rotation of signer keys for the entire iMessage platform as a protocol. And the last thing I briefly mentioned this, but this API interface is only seeing these hashes. What does that mean? It means that you can make private but verifiable commitments at scale. And we think that also has some really interesting externalities. So I have some resources here, and I'll probably be sharing this on Twitter as well. So people can reference back to the presentation, you can play with cosign, mess around with the docs. We have a quick start on relet, as I mentioned.
00:28:15.842 - 00:28:43.620, Speaker A: That's like you can fork and be using this API in less than two or three minutes. And yeah, we have a developer chat and telegram where we're bringing people together to chat about these ideas, help support them if they're interested in leveraging the protocol, ask questions, et cetera. So if any of you are interested in joining us there, definitely feel free. So we have some other slides if you guys have questions. I think we have around like, you know, ten or 15 minutes if you have more to chat on. And we wanted to. And yeah, I appreciate you guys taking the time to listen.
00:28:43.620 - 00:28:52.260, Speaker A: Thanks guys. Anything else? What was your name, by the way? Philip. It's great to meet you, man. I appreciate you.
00:28:53.560 - 00:29:01.564, Speaker B: I have a question regarding you said without from gas fees. What do you mean? If somebody needs to pay you.
00:29:01.612 - 00:29:01.772, Speaker D: Yeah.
00:29:01.796 - 00:29:11.240, Speaker A: So don't get me wrong, the protocol is paying that gas fee every time that it goes and updates on chain. No worries about it.
00:29:16.740 - 00:29:18.268, Speaker B: Uses your API.
00:29:18.364 - 00:29:29.040, Speaker A: So let's think about you submit 1000 hashes as a developer. Me is witness as a, like, think of this, think of this as a, when you think.
00:29:33.300 - 00:29:37.080, Speaker D: You'Re making attestations, okay. Right. Use them in Dom, you know?
00:29:37.740 - 00:29:45.660, Speaker B: Okay, so I'm in app which is called boa, which has users, users do actions, correct. And these actions trigger the URIB.
00:29:45.740 - 00:29:47.212, Speaker A: Correct. Because the way to think about it.
00:29:47.236 - 00:29:48.556, Speaker D: Is a hash submission to us, basically.
00:29:48.588 - 00:29:48.930, Speaker A: Exactly.
00:29:48.980 - 00:30:06.526, Speaker D: They get added to this merkle tree which gets checkpointed on chain. And the punchline there is that the user now has a verifiable, like sort of effectively lazy mint without co op having to have paid gnosis chain. Right now, gnosis chain has paid like a couple cents every time they did something. Plus you.
00:30:06.598 - 00:30:11.130, Speaker B: Thank you. What do you mean they have, they don't need to mint? I don't really understand.
00:30:11.630 - 00:30:55.648, Speaker D: So it's like, so for Defcon they have a discount on tickets if you have a PO app from Defcon over previous year. Right. One issue with that might be that if I was an organizer of Defcon a couple years ago, I might have some secret po op codes that I can go mint now and give discounts to my friends. But because in that case, you're effectively trusting that this person is creating these trusted attestations. If you have one of these attestations, we know you're at this event. You can imagine a world where all these co ops are sort of actually forced to be verifiably timestamped on chain, either via directly being minted or via having one of these off chain proofs that rolls up to the chain where now you can effectively prevent against this, preventing its backdating effectively, which is in a lot of cases what makes an NFT valuable in the first place.
00:30:55.784 - 00:31:04.928, Speaker B: So what you're doing is like instead of having to make things on chain, you can say like, okay, I actually clicked on this button, which is what was the mint button at time x.
00:31:05.024 - 00:31:05.392, Speaker D: Yes.
00:31:05.456 - 00:31:09.630, Speaker B: I have this thing into on chain. So you don't have to commit to anything anymore.
00:31:10.410 - 00:31:31.470, Speaker A: It depends on the utility you get for the myth. Right. There's kind of two things you get when you post an attestation on chain. You get this verifiability of when it happened. Another thing you get when you're actually posting the NFT fully on chain is this nice data availability property. The data availability property is important because it allows any indexer that's watching the chain to actually retrieve that information and store their own copy.
00:31:31.810 - 00:31:47.040, Speaker B: But what do you mean, same time I'm like, okay, if I can, if I post the proof on channel through your service as a user and I don't actually need to have the NFT in my wallet, I don't really care because I can generate the proof that I actually have.
00:31:47.120 - 00:31:49.100, Speaker A: That's exactly what I'm basically thinking of.
00:31:49.560 - 00:31:57.648, Speaker B: And say, okay, I actually have it because this is the times that give you the proof. So actually I never really, that's kind.
00:31:57.664 - 00:32:34.900, Speaker D: Of the punchline here is that there's a, a lot of sort of NFT sort of looking use cases where all you care about is exactly what you said, being able to prove to someone else that hey, I was here at a certain point in time, but that I took that action at that point in time. Right now, if I have to pay gas for all of those things, maybe I'm capturing those moments a lot less versus what we're arguing is that you shouldn't have to pay gas for it. We can aggregate in a web two way. We can upfront, sort of stomach that web3 portion of the cost. And now all of a sudden sort of this new little like Ux trend, that web3. We use the phrase lazy minting because I think that's really what this is, because you can bring it back on chain and make a proper nft out of it. It's just the phrase lazy minting has been around so long that it's kind of diluted.
00:32:35.060 - 00:32:36.452, Speaker B: Why would I mint that?
00:32:36.636 - 00:32:49.720, Speaker D: Why would you mint it? Because imagine all of a sudden that po out from a long time ago. Not only do you want to prove you had it, but your friend wants to buy it from you because it's a cool collector's item. And so now you sort of, it's almost like having the option, but you don't have that, right.
00:32:51.070 - 00:33:05.050, Speaker A: The dynamic here is that if you want to do a stateful action with this asset, it needs to be more composable on chain. But the idea of having an upfront fee market to initialize data in a verifiable way is kind of, I think the thesis that we're kind of testing.
00:33:06.710 - 00:33:14.210, Speaker B: I have a question also too, around determination of the proof. Like how do I prove that this proof belongs to?
00:33:16.160 - 00:33:46.700, Speaker D: Basically you have some data, right? Think of it as like a data schema, some JSON, whatever. You hash that data and then we give you the vertical proof and that all basically just connects up. So depending on the data schema, you may or may not be able to claim ownership of it, right? So one data schema might just be an image. Another data schema might be an image with a signature, right? That's kind of what that cosign demo is. It says, hey, come sign your image, and now you can sort of claim some ownership over it, right? If no one else has an earlier signature on this image, that's kind of like good indicator that you might own this image or create this image or however you want to say it.
00:33:47.400 - 00:33:55.024, Speaker B: So is it like each app would have their own Merkel mountain range and then you would aggregate this into a viable.
00:33:55.192 - 00:34:01.220, Speaker D: Right. Now we just have one big Merkel mountain range. But potentially designs like that might make sense too, just depending on different trade offs.
00:34:02.200 - 00:34:54.940, Speaker A: The thing to think about is that if there's essentially hashes that you want to provide for two different trees, you're now paying that $90,000 gas usage twice. So there is an element where like, you know, if someone came to us and we're like, hey, like we'd love to see the system operate for like a personal tree with like a different type of verification logic, something like that. Something we'd be interested in. But a lot of the economy is of scale for this like lazy minting use case is like, listen, we can use this really fat, beefy web two system that, as you can hear me talk about it like, there's nothing we shy around from when it regards to the centralization and sovereignty of that component. But the utility of this is that once a has been provided to a user, that proof is sovereign. It might not be available somewhere, but there's still an ability for applications and smart contracts to compose with it, because it's as verifiable as it possibly could be. You can verify all three of these properties that you could potentially verify about data, even if that data is stored off chain, even if that data is provided to you by a party or an indexer or a data provider that you don't trust.
00:34:56.800 - 00:35:47.160, Speaker B: If you're a user and then you have a certain piece of data that improved at time x. Yeah. And that is now living on interior or in base. The problem is like the way to retrieve this data is to generate vertical proof, right? But to generate the local proof, then you need all the leaves, this one, this one, and this graph together. And so if I'm a user, imagine we take an example where we have any web to service, let's say Goa or user wants to do that. And the problem is that if I'm a user, I might not have access to all the other laser. So I wouldn't be able to generate.
00:35:47.160 - 00:35:49.428, Speaker B: So how do I do?
00:35:49.524 - 00:36:22.350, Speaker D: So I guess our sort of thesis here is, is that you have the option to custody that data yourself. So again, once a checkpoint lands on chain, you could request a proof from us and we'll serve it to you. And so from that point on, you can choose to store it yourself. You can throw it in your Google Drive, maybe YouTube as an application stores it for you as well. So there's kind of that dynamic, and kind of our underlying thesis is that even if you're using a normal DD layer, a user's going to be querying via an indexer or some centralized API anyway. And so the thing that actually matters is the verifiability. And so even if it's not on a DA layer, but you still have the DA and you can verify it like you have the data.
00:36:22.350 - 00:36:25.318, Speaker D: So, like, data availability kind of stops mattering at that point because you have.
00:36:25.334 - 00:36:26.534, Speaker A: The data in your own hands.
00:36:26.662 - 00:36:32.246, Speaker D: That's kind of like enough in a lot of cases, effectively. And then you're not paying that dynamic da fee that everyone else is paying.
00:36:32.318 - 00:36:37.006, Speaker B: But what they didn't get is like, if I'm a user and I have.
00:36:37.038 - 00:36:38.686, Speaker D: A certain piece of data, which is.
00:36:38.718 - 00:36:42.198, Speaker B: Like my name, timestamp and the name.
00:36:42.334 - 00:36:42.838, Speaker D: Yep.
00:36:42.934 - 00:37:07.490, Speaker B: That I wanted to make. And then there's YouTube, there's a poem. This is. And it does millions of actions with other users that do the same thing. And then all of these actions are sent to your service as hashes. And then you navigate them into this merchant range. And then you take the route to this mercantile range, and then you post and change the route in this program.
00:37:07.490 - 00:37:15.380, Speaker B: Thing is that I, as a user, have never had access to all the other leads.
00:37:15.760 - 00:37:16.496, Speaker D: That's right.
00:37:16.608 - 00:37:21.712, Speaker B: I will never be able to retrieve data from the root that you posted because I will not be able to.
00:37:21.736 - 00:37:47.098, Speaker D: Generate the proof we serve it to you. So we call it like a call, like a 32nd trust assumption, where effectively show the little ping pong. Did that go up a couple? This one, yeah. So basically, like, when this flow is over, you're good. But you're right that during this flow, there is a data availability problem. But the punchline here is that we're not doing anything complicated where we might be, we might front run you. All we're seeing is a hash of your data.
00:37:47.098 - 00:37:57.826, Speaker D: And so, assuming, you know, in the ten minutes it takes us to land a checkpoint on base, that our incentives don't change and we decide to censor you, we'll give you this proof at the end of that and then you're good. So that's kind of the point here.
00:37:57.858 - 00:38:03.950, Speaker A: Is that like, we call it this trust window. And again, we're not shy about this. This is kind of what the architecture is somewhat designed for.
00:38:04.330 - 00:38:09.778, Speaker D: And once you have your proof, you're good. When we post updates to the tree, you can keep your proof up to date. Your old proof is still good.
00:38:09.874 - 00:38:53.966, Speaker A: It goes back to the fallback you said earlier as well, which is like imagine we censor you, the centralized API censors you. You could go pay the dynamic fee on chain if you want to go broadcast this hash. But the idea is we're giving people this alternative that can actually have, yeah, scale and be free. A great question though, you're really hitting on kind of like where are the trust boundaries? When is this sovereignty actually guaranteed? And obviously you're hitting a lot of the nuance here. And part of the reason we appreciate you guys engaging with us on this is describing some of the dynamics here versus some of these architectures that people are familiar with. When it comes to blockchains, when it comes to DA layers, it comes down to the guarantees that they're providing. And one thing that's key with witness is that it's that data existence resource that we're scaling, not giving you a DA guarantee or a data storage guarantee on the underlying data.
00:38:53.966 - 00:39:02.490, Speaker A: We believe if you make that verifiable, those things can happen naturally or even in centralized ways that still allow people to coordinate on that data in important and composable ways.
00:39:04.190 - 00:39:07.090, Speaker B: So your vision for it is that like web services.
00:39:15.190 - 00:39:47.720, Speaker A: I think trust, trust, minimize audit infrastructure is something that this can really empower with. We go back to the idea of certificate transparency, et cetera. These things are live in production today and empowering a lot of how all of us use the modern Internet. You wouldn't be able to solve byzantine generals for a symmetric key generation, for example, in SSL, unless you had one party trusting the other first. Why is your browser trusting that directory? It's because there is a certificate that was issued in a way where I. If the certificate authority was bad, anyone can audit it. Your browser can audit it almost like a light client.
00:39:47.720 - 00:40:01.480, Speaker A: And so allowing people to kind of create these timely proofs that are verified with basically no intermediary once you have custody of it, we think is a very, very interesting design that can empower a very different future for the Internet.
00:40:03.100 - 00:40:06.560, Speaker B: Do you have some example of, are you already live?
00:40:06.860 - 00:40:47.348, Speaker A: Yeah. So we have a number of different protocols that are leveraging this today. We have a few that we'll be able to get somewhat loud about here in the coming months as well, which we're kind of stoked for being the first production use cases, we bucket into three groups. I'll kind of broadly describe them. The first is this lazy minting use case brands, et cetera, that are thinking about minting on chains that their users care about, potentially multiple chains, but in a way that they're never having to worry about this dynamic upfront fee market that is out of their control. The second use case is this kind of trustless timestamping thesis where there are entities that generate different types of off chain data. Maybe it's a legal contract, maybe it's some sort of attestation or guarantee allowing them to audit how they're generating that data.
00:40:47.348 - 00:41:35.420, Speaker A: And different web two systems can be very valuable for them. So there's a number of different use cases we're experimenting with there. We're also quite excited by some of the teams that are looking at existing web two signatures and essentially trying to find ways for those to compose and trust minimize ways with smart contracts. Some examples of this are like the team at, I think it's ZK p, two p or the ZK email team. They're leveraging aspects of this system to create essentially trust minimize infrastructure around essentially the signatures that are being verified as valid because they're coming from these DKIM headers and these emails and they rotate over time, so timely signatures become very important for a use case like that. Another one is kind of the excitement that we're seeing around ZK TL's again, I think over the past couple months, essentially trust minimizing some of those infrastructures. This protocol has been found valuable by some of those teams.
00:41:35.420 - 00:42:17.720, Speaker A: Yeah, I really encourage you all to look into both of those directions as well. A cool thing about those is that if they can be trust minimized in a proper way, there's no consent that's needed from the generator. So this is the thesis that I think people have been preaching for a long time in crypto, where it's like we're going to be able to import all of our web two data into crypto networks finally, or kind of compose with it, versus like trusting a gatekeeper or trusting a signature from a Spotify server, whatever it is. I think that's going to have the potential to kind of like, you know, allow users that aren't even on blockchains to kind of come to blockchains with something they already have generated. This valuable data. And now smart contracts can compose with that in a verifiable way. I think there's really, really cool new, interesting, maybe a little bit pie in the sky vision for applications that can be built on those primitives.
00:42:19.870 - 00:42:27.170, Speaker B: Cool. What are your trust assumptions? Like you have likeness, basically.
00:42:32.150 - 00:42:56.662, Speaker A: Yep. And again, the reason we think that's acceptable, and again, like, that's our opinion, that doesn't mean it's acceptable for everyone. The reason we think that's acceptable is because of the economies of scale you get of the system, first and foremost. The second is that that trust boundary, as I kind of described here in this first bullet point, is bounded in time. Again, you're waiting for a checkpoint to land. We don't know what you just checkpointed, so we don't have the underlying data of your hash. We couldn't go try to claim ownership over it because we don't even have the data on it.
00:42:56.662 - 00:43:11.450, Speaker A: And obviously we're only receiving a hash. The incentive for censoring a hash versus censoring a stateful transaction is very different. When you get into the meV dynamics, et cetera, around that, you could still.
00:43:11.950 - 00:43:23.066, Speaker B: Imagine you have something like a big launch, like something like four days, something like that. You could definitely try to shut down your service. Absolutely.
00:43:23.218 - 00:43:24.146, Speaker D: Yeah. Long tail mev.
00:43:24.178 - 00:43:24.610, Speaker B: Always.
00:43:24.730 - 00:43:45.210, Speaker A: There's always long tail MeV. I think you see that a lot when it comes to the adversarial mindsets of, like, you know, whether it's like fake employees applying for my job applications or someone not liking the network my, you know, my API operates on and trying to crash it. You definitely bring up a good point, which is like, yeah, you still need to think about, like, cyber resistance and kind of spam production for a system like this. There's a few ideas we have.
00:43:48.150 - 00:43:48.486, Speaker D: Used.
00:43:48.518 - 00:43:51.290, Speaker B: Invite the truth to the user, but then hot.
00:43:52.590 - 00:44:16.816, Speaker D: So we've obviously considered building, like, clients and stuff like that. Maybe a little Chrome extension or Google Drive plugin that backs it up for you. We're still kind of early stages in that regard. So for now, when people use this, we just say our API is going to serve it to you for as much as you need. Some of our clients, as we checkpoint stuff, they also just get the proofs and stored in their database practically as well. Some of the clients just read it from us when they need it. So it's been all over so far.
00:44:16.928 - 00:44:19.536, Speaker B: So you store each and every proof?
00:44:19.688 - 00:44:26.420, Speaker D: We have the whole tree. We have the whole tree. So don't think of it as like, restoring the proof we have the tree, we can just look up the proof as we know.
00:44:27.440 - 00:44:29.408, Speaker B: If you didn't store the tree as.
00:44:29.464 - 00:44:30.260, Speaker A: A user.
00:44:32.170 - 00:44:36.390, Speaker D: Um, effectively, yeah. I mean, that, that's what the mermaid.
00:44:36.850 - 00:45:15.404, Speaker B: The problem is that it's not even the only censorship resistance problem, because, like, you also have this very problematic thing of like, you're centralizing this tree industry that cannot be recomposed. It's like if you lose this tree, then all the users that don't have their proofs, like, it's finished. When, for example, if you take a blockchain like Startnet and post their state transitions to the shuts down, shuts down, you can still broken from the state, from the DA to an extent, the.
00:45:15.492 - 00:45:20.524, Speaker D: Only persistent, right, but according to the incentives that be on there. So one of the ones, I would.
00:45:20.532 - 00:45:26.820, Speaker A: Say, because you publish any index or credit sort it, if the network shuts down, it becomes a question of which indexers are still storing it.
00:45:28.080 - 00:45:31.072, Speaker B: But I mean, it's still in the DA, right? So you could recompose it.
00:45:31.096 - 00:45:40.660, Speaker D: It was at a DA at one point, so presumably you could compose it because it was available at one point. But when you're querying it now, when you know the DA from a year, a year later, that's not still on any given.
00:45:46.040 - 00:45:48.100, Speaker B: Say if you lose the tree.
00:45:49.810 - 00:46:14.186, Speaker A: So because the checkpoints are landing on chain, and that's what you need to verify this proof that we claimed you're sovereign with. You're right. Could the proofs be recomposed? No. If a user still has their proof custody, are they still sovereign with it and have an ability for anyone to verify it? Yes, because the read verification does not require any dependency on the tree even existing or us even serving you. So you're asking all the right questions there around the trust boundaries. That is really a lot of the nuance here. Of course.
00:46:14.338 - 00:46:25.786, Speaker B: Um, would it be possible to lie for you? Like, serve you a hash that has a certain type that is like, who does the type of stamp? Like, is it you or is it chain?
00:46:25.938 - 00:46:26.710, Speaker A: Chain.
00:46:27.970 - 00:46:33.106, Speaker D: We just give the chain a really juicy brute hash to do her eyes, and then we give people proofs that.
00:46:33.138 - 00:46:36.310, Speaker A: Their hash rolls up to that resize hash.
00:46:37.850 - 00:47:06.598, Speaker B: And how does these hash store value? Like, because, like, a hash only. Like, a proof only has value. Like, how do you say that the proof, only the proof bears value? Like, inherently, because it's a proof. Like this value can only be extracted by the verified. You need a party that will accept this proof. Yeah, of course. So if I have this proof and nobody's ready to accept it.
00:47:06.598 - 00:47:16.462, Speaker B: It's useless to. So it's like I need a protocol that will accept my proof and be like, okay, this proof is valid and I will give you money for it. Or I will say that you can.
00:47:16.526 - 00:47:17.730, Speaker D: Now live to this.
00:47:19.070 - 00:48:19.826, Speaker B: Okay, so you need to be integrated with all these workloads and make sure also that these guys, they respect their promise because now the problem is that I'm sovereign on my proof, but I'm not sovereign on my NFT. And so because I don't really hold the NFT in my wallet, then if the protocol at one point seems, for example, let's take this, there's a boarding launch. And when the boarding launched, I know it was $10 to mint. And then I generate all the guys, they generate the mints using a protocol and they get these proofs of like, okay, I was there. And then the price, thousand exits, a million exits, the protocol that you get asked, maybe they're going to say, no, we're not going to let you redeem your proofs for the mints because now it's better for us to keep those and actually sell those then to accept, to validate, like to value these rules.
00:48:19.858 - 00:48:20.338, Speaker A: Right.
00:48:20.474 - 00:48:25.628, Speaker B: So you can have very big problems like that in case you have high price migration.
00:48:25.724 - 00:48:32.476, Speaker D: Yeah, yeah. You definitely still need to consider like traditional upgradability, stuff like that with regards to what they're doing.
00:48:32.508 - 00:48:56.210, Speaker A: Yeah, but like one way to think about it is like imagine before they start issuing these proofs, they've launched their NFT collection still. Yeah. Thank you, man. I appreciate it. I think how a lot of those flows would work is the first thing that's happening is like before I start issuing proofs, I'm going to make an NFT contract. I'm going to deploy that contract in an immutable way. That contract can basically enforce different things about this data signed message that you're bringing back to it to mint your NFT.
00:48:56.210 - 00:49:30.930, Speaker A: So for example, it can say, hey, I want to verify that this was issued by Yuga Labs and that it was issued before this time for it to be valid. That can be an immutable contract that they launch. They start giving out their proofs, the users can basically say, yes, I could go mint this whenever I want. And it stops yuga labs for minting more after that expiration time. So it allows you to enforce that. And so I think the dynamic that's important to understand there is that, again, what this is saving costs for is initialization of these things. And there's still ways to essentially launch contracts that can compose or incentivize these proofs or this data to come back on chain.
00:49:30.930 - 00:49:35.770, Speaker A: There's ways to enforce that rule into data schemas without having to pay an upfront fee for it.
00:49:36.630 - 00:49:48.924, Speaker B: I think it's. I don't know. In my mind, I feel like I have an intuition for the potential, but it seems interesting, but I feel like it adds a lot of complexity.
00:49:49.092 - 00:49:50.588, Speaker A: There is an aspect of complexity you.
00:49:50.604 - 00:50:21.454, Speaker B: Can'T add architecture or the smart contract developers need maybe to add some things, and then you have all these games that happen. So I'm just curious, can you give us a banger? Do you have to mind something that is like Google, you find anything that you want. And one thing, do you have something like that with everything? This is the application, like, okay, our protocol is made for that. And if we do that, yeah, I.
00:50:21.462 - 00:50:43.720, Speaker D: Think when people say. When we say mint everything, I don't think it hits people's ears the right way. When I say mint everything, what I mean is that your phone has a radio, right? Talking to the Wi Fi talking. It knows there's other bluetooth. This around. I'm talking about in that granularity minting every single interaction so that when you're doing some kyc in the future, you can prove via some kind of, you know, like the captchas, like the capture your mouse movements and the minutiae of how you move your mouse. It's like, this is a robot or a human.
00:50:43.720 - 00:51:19.910, Speaker D: I'm talking like, that level of granularity provable to the chain in real time as, like, a continuous algorithm. Like, look, I'm a human because I have 18 years worth of, like, human like, activity that could have been fake because it was done in real time. I would have to fake it all the way starting 18 years ago. So, like, that type of granularity of interaction that then how does it actually manifest into value on the chain? That's a little bit more like finding the sky. Maybe I'm doing some DK proven, like, identity thing. Maybe it's some KYc thing that's kind of like where my head space goes in terms of, like, what scale this and where it actually gets useful compared to, like, throwing it on a cheaper DA layer or something like that. Like, you would never be able to put all that data on a DA layer.
00:51:23.700 - 00:51:25.468, Speaker B: Every single interaction that you do, if.
00:51:25.484 - 00:51:26.960, Speaker D: It'S not on chain, it's not real.
00:51:27.780 - 00:51:46.640, Speaker A: I mean, or if it's not on chain, then there's some element of the data that cannot be verified by you as an individual, by the entity you're trying to coordinate with, maybe by an AI agent in the future. Yeah, literally. That's the funny part. I think that analogy, I think hits for people that are. Yeah, yeah.
00:51:47.350 - 00:51:49.142, Speaker B: I said, if there's no SSL, don't.
00:51:49.166 - 00:51:49.926, Speaker A: Go to the website.
00:51:50.038 - 00:51:53.518, Speaker D: Like, imagine you go to a website in that lockbox, and you're like, I don't trust this. Get me out of here.
00:51:53.534 - 00:51:54.950, Speaker B: Right? They're gonna, like, do anything.
00:51:55.070 - 00:52:04.174, Speaker D: Now, imagine all the time stamps. You scroll across as you just check your email, check Twitter. And you're just like, well, Twitter told me that he posted this yesterday, so I guess he must have. Which Twitter doesn't have a reason to lie.
00:52:04.222 - 00:52:04.550, Speaker B: Right.
00:52:04.630 - 00:52:14.144, Speaker D: But, you know, as the incentives get crazy, as AI gets crazy, like, the acceleration continues. Yeah. So if it's not on chain, it's not gonna be real. Why would you trust that if it's.
00:52:14.272 - 00:52:44.098, Speaker A: We have some blog pieces as well. If you want to read into some of our, like, hey, like, don't talk to me about how this works, but why does it matter? Yeah, I think this framework is really hit for people where it's like, if you show me a piece of data, there's only three things I can potentially verify about it without trusting anyone that can allow me to ascribe some sense of authenticity to that data object. And those three things are like, what are you presenting me? Who signed it and when did they sign it? There's not this, like, fourth magical property. Like, oh, this thing is authentic. This thing is a deep reel. This thing is a deep fake. You need the context of these things.
00:52:44.098 - 00:53:23.600, Speaker A: And by taking all of these signatures from all these validators across the networks that we operate this thing, on top of, we're able to produce this kind of verifiable timestamp at a scale, and in a way where we think it empowers individuals, we think it empowers people to think differently about how their applications compose, et cetera. I think another one I get excited around is journalistic integrity. I think you have to think hard about the incentives there to help those entities kind of self regulate themselves for different reasons. But ironically enough, there's, like, individual entities, I think, that are interested in that. So, like, independent journalists, et cetera, everybody. All righty. We're all good.
00:53:23.600 - 00:53:24.080, Speaker A: Thank you so much.

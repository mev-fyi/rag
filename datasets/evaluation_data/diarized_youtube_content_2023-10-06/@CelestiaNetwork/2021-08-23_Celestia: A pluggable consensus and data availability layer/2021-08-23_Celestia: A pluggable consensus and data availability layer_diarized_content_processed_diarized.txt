00:00:01.210 - 00:00:43.690, Speaker A: Hello, everyone. My name is Mustafa and I'm the co founder of Celestia. And today I want to talk to you about Celestia, which is a pluggable consensus layer for blockchains to enable anyone to deploy a blockchain really easily. A bit of background about myself. I was previously a PhD researcher at University College London working on layer one blockchain scalability techniques such as Sharding. And I was also previously a co founder of Chainspace, which was one of the first Sharding projects in Blockchains. And that company was actually hired by Facebook, but I was the only researcher there that did not go to Facebook.
00:00:43.690 - 00:02:08.290, Speaker A: So what is Celestia? Celestia is a pluggable consensus and data availability layer. We're going to talk about what that means in this talk and why that's important. But the key idea here is what we're trying to achieve is to enable anyone to really easily, quickly deploy their own blockchain without the overhead of having to create their own consensus network from scratch, using something like proof of work or proof of stake. Whereas now it would take a very long time or months to build a consensus network to deploy a blockchain, we want to really crunch that process down to a few minutes by making it really easy and providing a pluggable consensus network. And one of the key reasons we're doing this is because we want to create a world where global digital communities can effectively self organize in a completely sovereign way, using decentralized networks without being burdened by existing power structures. And that could also include being beholden to the rules of another layer one network. For example, if you're deploying a smart contract on existing layer one, you have to follow the rules of that specific network.
00:02:08.290 - 00:02:58.358, Speaker A: And we're going to talk about why that's not good and why we're trying to change that in this talk. So if you look at existing blockchains today, existing blockchains today are very monolithic. They try to do everything at the same time. So there's several layers to a blockchain. If you look on the left existing blockchains today, they provide on the base layer on layer one, they provide both consensus and data availability and execution. And so, for example, if you look at Ethereum, for example, you write your smart contract and you deploy your smart contract onto Ethereum. And Ethereum provides everything for you.
00:02:58.358 - 00:04:21.040, Speaker A: It provides the consensus and it provides the execution, which is the Ethereum virtual machine. So you have to write all of your applications in such a way that the Ethereum virtual machine understands it. And that's quite limiting in terms of what you can do not only from a technical perspective in terms of being limited to the technical limitations of the Ethereum virtual machine, but it also means that your smart contract is sharing the same execution environment as every other smart contract. Which is similar to if your computer program is running on the same computer as everyone else. And so that means you're bound by this kind of shared social contract of all Ethereum users. So if, for example, you wanted to change the rules of your smart contract, let's say there was a hack, or for example, like the Dao, you have to convince the entire Ethereum community to hard fork the entire chain and every single contract. So it's not a very sovereign way of creating your own sovereign applications because you're bound by the rules of other contracts that you might not necessarily care about.
00:04:21.040 - 00:05:32.630, Speaker A: But what we're trying to do is trying to make the blockchain stack more modular and decouple some of those layers. So what we are trying to do is decouple the consensus layer from the execution layer. And what that means is that we're trying to provide a very simple base layer blockchain that only does one thing, which is consensus and data availability, which is just the core things that blockchain needs to do. And that gives developers the flexibility to define their own execution layers on top in the form of their own blockchains. And it gives them a lot more flexibility and power that hasn't been possible before in the decentralized application space. One of our thesis is that we can compare the evolution of the blockchain space to the web. So if you look at the early web in the 90s when HTP or the web was first created, if you wanted to create a website, you had to basically have your own physical server, for example, in your bedroom or in your university.
00:05:32.630 - 00:06:22.150, Speaker A: And then shared hosting providers came about. I don't know if everyone remembers services like GeoCities or DreamHost or Bluehost. You would basically upload your code to this shared server and your website would run on the same server as everyone else. And then in the modern web we have virtual machines or the cloud. So now anyone can easily spin up their own server, kind of like the 90s, but without actually having to go through the overhead of having a physical machine. You can spin up your own server on something like AWS in minutes and have complete flexibility and control and sovereignty over how you create or deploy your application. So we're seeing a similar evolution in the blockchain space.
00:06:22.150 - 00:07:33.962, Speaker A: So when Bitcoin came around in 2008, there was this idea of each application has its own blockchain. So Bitcoin had its own blockchain specifically for cryptocurrency or for the Bitcoin asset. And then you had things like Litecoin, Namecoin, Mastercoin and those were basically providing a blockchain for each application. And then Ethereum came about in 2014 and provided a general purpose blockchain that allows people to upload any application to share the same chain. And that made it easy for people to create their own smart contracts and upload it. But that has severe limitations, similar to the limitations of uploading your website code to a shared web hosting provider like GeoCities, because you have very limited flexibility in how you can actually develop your website and what it can do. So what we're seeing now is a trend towards back to people creating their own app specific chains or their own chains for their own applications.
00:07:33.962 - 00:08:48.840, Speaker A: But instead of having to create their own application from scratch, they can deploy their chains on existing or pluggable consensus layers, similar to how today you can deploy your own virtual machine on AWS using physical servers that they have from a technical perspective. I'm going to discuss the way that Celestia works. So, existing blockchains today, in order to check if a block is valid, you basically have to check two things. Number one, you have to check if the block has consensus, if it's proof of work, for example, does the chain have enough proof of work for it to be the longest chain, or if it's proof of stake, for example, using Byzantine fault tolerance, have two thirds of the validators sign the block. That's the first thing. And then the second thing is that you have to check if the actual transactions in the block are valid. Like you can't just insert a transaction into the chain that steals everyone's money.
00:08:48.840 - 00:10:27.910, Speaker A: You should reject that block. And so effectively, current blockchains are coupling the rules, the execution rules for transactions with the rules for the consensus. And this doesn't scale because the problem with that is that in order for users to check that a block is valid, you have to download and process every single transaction to check that a block is actually valid. But what if you actually remove that second rule? What if you said you're allowed to post invalid transactions on the chain and anyone's allowed to post anything on the chain? Would the chain still be secure? The intuition is yes, it will still be secure. Because what you can do is you can insert an implicit rule on the actual user's machines to say that if they see an invalid transaction, they just ignore that transaction. So if there's a transaction that steals people's money, even though that transaction is on the blockchain, you just ignore it when you're trying to process or compute everyone's account balances. So however, even if you ignore the transactions that are invalid, you still have to make sure that the miner or the block producer has actually published all the transactions in that block.
00:10:27.910 - 00:11:56.558, Speaker A: So you don't want to end up in a situation where, for example, here a Miner has published a block but has not actually published the transactions inside that block. Then people won't know what the transactions are and therefore they won't know what the actual account balances are in the chain or what the state of the chain is. And if that's the case, then a Miner or a malicious miner or block producer could potentially inject an invalid transaction that no one will ever know about. So it's important to also make sure the miner has actually made the transaction published available on the network. So what you have to do is you have to replace the rule that transactions are valid with transactions actually being available. And it turns out that checking that a transaction has actually been published or is available is a lot easier and more scalable problem to solve than actually processing and computing the transactions. Because using techniques such as data availability sampling, you can actually check that entire file or entire block has been published without actually downloading the entire file.
00:11:56.558 - 00:13:34.160, Speaker A: You can effectively check that the entire block is available by only downloading a very small piece of that block. I'm not going to go too much into the weeds about how this technique works, but the basic idea is that if you use a technique called erasure coding, which is like a redundancy technique used in lots of technologies, like CDROMs or satellite communication. If you apply that technique to the way that you create the block, you can make users use random sampling or probabilistic techniques such that if they just download a few pieces from that block, like a few random pieces. Like, for example, these black chunks here. They can have very, very high probability that all of the other pieces in that block have actually been published and therefore, all the transactions in that block are actually available. And therefore that a miner or a block producer cannot actually hide an invalid transaction in that block. And the key thing about data availability sampling or data availability proofs is that the number of samples or the number of chunks in a block that you have to download to check that the entire block is valid is irrespective of how big that block is.
00:13:34.160 - 00:14:50.490, Speaker A: Which is nice because you can increase the size of that block in the chain and therefore the number of transactions per second without increasing the cost to the end user to actually validate that chain. But the caveat to that is the bigger the chain's blocks are, the more users you need in the network to actually be downloading these random samples in the chain. Because you need to be sure for this technique to work that all the users have collectively sampled every sample in that chain or in that block. So this leads to two key properties. The first property is that because you only have to check that a block's data is available to validate that chain, you no longer have to actually execute all the transactions in that chain, you just have to check they've been published. You can actually validate blocks in subliminal time because you can validate the chain without downloading everything or checking everything. You just need a few pieces from that chain.
00:14:50.490 - 00:15:48.598, Speaker A: Secondly, the other key property is the more nodes you have in the network, the bigger the block size you can actually have securely. Because, as I mentioned, you need to increase the number of users if you want to increase the block size because you need to make sure that there's enough users in the network to sample the entire chain. And this is kind of interesting insight because if you think about what's the world's most current decentralized scalable protocol, it's typically peer to peer file sharing systems like BitTorrent. So like BitTorrent at one point handled a quarter of the internet's traffic. This was back before Netflix people was pirating movies. BitTorrent handled a quarter of the internet's traffic. And the reason why it was so scalable is because BitTorrent doesn't do execution.
00:15:48.598 - 00:17:55.220, Speaker A: It just does data storage and distribution. It had this property where the more users there are in the network, the more seeds and peers there are on the network, the more data the network can store and distribute. And one of the key insights here is that if in a blockchain we simplify the block verification rules to just data availability verification, you can potentially achieve very similar scalability properties to BitTorrent. So now we've discussed how does Celestia itself work as a basic consensus and data layer? I'm going to discuss how do you actually deploy or build your own application on top of Celestia? Given that there is no smart contracts like Ethereum and there is no shared execution environment, the way it would work is that applications only use the chain to store the transactions but not process their transactions. Instead, the application's transactions are processed locally by the actual users of those applications to determine what is the state of the application, what are people's balances. But the problem with that is, what if it's not practical for users to process their transactions themselves? A solution to that is you can instead make it so that you also post what's called a state commitment, which can be a merkel route that commits to the entire state or account balances of everyone in the application. But the problem is, how do you know that merkel route is valid? Or how do you know whoever posted that state commitment is valid? And that's where roll ups come into play.
00:17:55.220 - 00:19:12.030, Speaker A: So what is a roll up? A roll up is basically, in simple terms, a blockchain that posts its data to another blockchain that serves as the layer one. In a roll up. What happens is that a user submits transactions to what's called an aggregator in that roll up, which takes all the transactions from users wanting to post to that roll up and then creates a block from all the transactions and then posts it on the chain. And that block includes a commitment or merkel route to the state of that application at that time. Now, if the aggregator is malicious, then what happens is that there's two cases depending on what kind of roll up you're using. If you're using an optimistic roll up, then it's kind of an innocent until proven guilty model. So you assume optimistically that the aggregator is telling you the truth.
00:19:12.030 - 00:20:16.826, Speaker A: But what you do is you allow anyone to challenge that. So if the aggregator is lying to you, then anyone can challenge that and create a proof that there's a transaction or state in the roll up chain that's incorrect. And that would be called a fraud proof. Then the other category of roll ups is what's called a zero knowledge or ZKE roll up, which works under a guilty until proven innocent model. Which means that when an aggregator posts the block to the chain, you assume that the aggregator by default is dishonest. And then you require them to also submit what's called a zero knowledge cryptographic proof to prove to you that the block is valid. And both of these techniques require a base consensus or data availability layer such as Celestia.
00:20:16.826 - 00:21:32.620, Speaker A: Because in the case of optimistic rollup, you need to be sure that all the data in the rollup chain is actually available in order for people to actually be able to generate fraud proofs. Because if they don't know what the transactions in the chain are, then no one can generate a fraud proof because they can't prove something has gone wrong if they don't know what happened. In the case of a ZK roll up, it also requires a base consensus and data layer. Because if the actual data or the transactions in that roll up weren't posted, then you could end up in a situation where no one will know what their balance is or what the balance is, or the state in the chain is. And therefore that's potentially equivalent to burning people's funds or locking people's funds. The model in Celestia is that all applications have messages associated with a namespace. So when you create an application, you choose a namespace for that application.
00:21:32.620 - 00:23:11.900, Speaker A: You can choose whatever namespace you want. And in Celestial, we've organized the block such that we're using a merkel tree that is ordered by the namespace of each transaction. And what that allows you to do is users in that network, in our network can query storage nodes in Celestia to ask for transactions specifically relating to their application. And so that basically makes it possible for users to use the Celestia chain for only roll ups or applications that they're using without having to download the transactions of other applications that they don't use, for example. And so that's why we call Celestia a pluggable consensus and data layer because you can build an application that uses Celestia just for that without requiring your users to take an interest or download the transactions of other applications that they're not using. Which is unlike existing blockchain models where because the consensus and the execution layer is coupled together, you have this world computer model where every smart contract is running on the same computer. The user of any smart contract has to also take an interest or check whether transactions for every other smart contract is correct.
00:23:11.900 - 00:23:53.560, Speaker A: And so we sidestep that by creating a model where we separate consensus and execution. So, in conclusion, we're trying to build a scalable universal pluggable consensus layer for developers and communities that want to create their own chains very easily without having to go through the overhead of creating their own validation network. If you want to learn more, you can check out our website, celestia.org, where you'll find more resources, including links to papers and videos. Do we have time for questions?
00:24:08.110 - 00:24:23.882, Speaker B: What benefit do you have for posting these transaction messages in separate namespaces instead of just using separate blockchains? What does this common consensus layer achieves?
00:24:23.946 - 00:24:33.250, Speaker A: It basically makes it so that you can create your own chain using a roll up without having to create your own layer one blockchain from scratch.
00:24:33.670 - 00:24:44.966, Speaker B: But do you have some cryptographic or some other incentive or is just like infrastructure incentive to use this instead of building another one?
00:24:45.148 - 00:25:34.710, Speaker A: So the main incentive is that there are several incentives here. First of all, the first incentive is simplicity or flexibility, right? Now, if you want to create your own blockchain, let's say you use something like tendermint of substrate, you have to define the validator in your chain. So by default, you start with one validator. For example, that's not a very secure chain. For example, you might have four validators, and that's still not very secure, that's very small validator set. So there's this bootstrapping problem where you have to create your own token and you have to maybe do a token sale and distribute your token. And then you have to make sure that there's enough validators and stakers in your network such that your chain consensus is actually secure.
00:25:34.710 - 00:26:38.140, Speaker A: That's a very long process, not only technical overhead, but potentially also legal overhead and also lots of maintenance work and actually maintaining a consensus network. So this allows you to sidestep all of that by instead of having to create your own validator set, you've got a pluggable consensus network that provides consensus for your chain that you can post your blocks to. So you can just immediately, within seconds, just create a chain or define a chain using something like the Cosmos SDK and then post the blocks off the chains into Celestial without having to worry about creating your own consensus network. The other point is we're kind of trying to envision a world where there's potentially thousands or even millions of blockchains. Just like how today there's like millions of websites, organizations using websites. They're not all using shared servers, most of them using virtual machines. And all of those virtual machines talk to each other and interoperate with each other.
00:26:38.140 - 00:27:21.618, Speaker A: In a world with millions of blockchains, you cannot expect all of those blockchains to have a secure value to set like Ethereum or like Cosmos or Polkadot. These are big malific chains with a lot of value locked up and therefore can have a secure staking network. But with a chain with millions of blockchains, you have this tail end of blockchains that will probably have like one or two validators. And we're trying to get rid of that issue by making a pluggable consensus network that chains can easily plug into and be secure. Hello?
00:27:21.724 - 00:27:45.330, Speaker C: Maybe I just wanted to ask, is that any different from just being a layer one for other L2 solutions? Because as far as I understand, the other blockchains which get your consensus are just L2 solutions on your L1 based chain, right?
00:27:45.480 - 00:27:46.180, Speaker A: Yeah.
00:27:47.670 - 00:27:57.720, Speaker C: So they are pretty much limited because, for instance, in Ethereum and Optimistics and ZK Wallops, they sometimes have limitations in what they can do.
00:27:58.730 - 00:28:02.120, Speaker A: So what do you mean? I don't understand what you mean.
00:28:04.970 - 00:28:13.622, Speaker C: It seems like Celestia is a blockchain. They're just projects that launches L2 on your blockchain.
00:28:13.766 - 00:28:47.590, Speaker A: Yeah. So it depends what you mean by L2. So it's not like you're creating your own L2 solution on top of Celestia. It's more like you're using existing L2 solutions or L2 execution environments. For example. There's lots of people building roll up based execution environments and you can use different data availability layers for those solutions. And most of them right now use Ethereum.
00:28:47.590 - 00:30:06.206, Speaker A: And that makes sense if you're building an application that uses ETH as an asset. But what we found is most applications, except for maybe some DeFi DEXs, maybe like uniswap, they don't inherently rely on ETH as an asset. So the question is, like, why would you build your rollout specifically on Ethereum if it's not using ETH specifically as an asset? What we're trying to create is a general purpose data availability layer. So whereas Ethereum is not general purpose because if you want to use Ethereum as a data layer for your L2, then you have to effectively take an interest in the validity of the entire smart contract execution environment in Ethereum because that's where your L2 posts to. So in order to validate the state of your L2, you also have to take the interest of every smart contract in Ethereum. But we're trying to remove that kind of overhead by creating an overhead minimized or general purpose data availability layer that is not coupled with some heavy state machine like the Ethereum 1.0 state.
00:30:06.206 - 00:31:05.360, Speaker A: And that's quite useful for people are just trying to build general purpose sovereign or independent roll up applications or decentralized networks that are not necessarily tied to the Ethereum ecosystem. And this is more of a general question because we're living in a more and more multi chain ecosystem where most transaction volume on Ethereum now is not even on Ethereum, it's on Polygon. People are just transferring assets from Ethereum to Polygon and just doing the transactions there and then transferring it back to Ethereum. So because we're living in a multi chain ecosystem, solutions like this will become more and more relevant and a general purpose data availability layer will become more and more important. Do you have a follow up or I don't mind a follow up. One more question, we just put the site back. My mouse is not connected for some reason.
00:31:05.360 - 00:31:26.520, Speaker A: How it anyway?
00:31:27.210 - 00:32:08.340, Speaker D: Yes. So my question has more to do with DDoS protection. So let's say there is an application which has a stateroom decision function which involves something competitionally heavy, like zero knowledge proof verification, and because the data availability layer is data agnostic, so it doesn't care whether the verification is going to be costly or not. I can cheaply spam a lot of transactions, but the client still needs to verify every single transaction that was added related to that application. Would the DDoS protection happen on the data availability layer or on the application layer for that?
00:32:08.710 - 00:32:59.654, Speaker A: Yes. So, good question and there's two points to that. The first point is, let's assume you're building an application on Celestia that's not using a roll up, that's just like you're just posting the transactions on Celestia, then as you like, what if someone just spams the chain with like a million invalid transactions? The solution to that is the same solution that Bitcoin and Ethereum have, which is a fee market for block space. So there will still be a block size limit in Celestia. That should be a function of how many users there are on the network. Because as I mentioned, the more users you are, the greater block capacity you can have securely. And so if you want to spam the chain with too many transactions, there will be a cost associated to that.
00:32:59.654 - 00:34:19.466, Speaker A: And that's okay because Bitcoin and Ethereum have the same issue. In Bitcoin you can try to post like a million transactions that move like one satoshi, for example. And that's not a problem because if you paid for it's not spam. So the first point is that for deals protection, there's a fee market which makes it expensive to post economically infusible or economically expensive to keep spamming the chain. Second point is if you implement your application as a roll up, you can sidestep the entire issue because the clients or the Light clients in your chain wouldn't be validating every transaction or checking every transaction. Instead they would be downloading the block headers for your application and the block headers will be given to you by what's called the subnetwork of your roll up. So you will be connected to nodes specifically like aggregator for example, in your roll up and you will be downloading the block headers from them rather than scanning the celestial chain directly for the block headers.
00:34:19.466 - 00:34:55.340, Speaker A: And unless you're connected to a malicious block producer, which you can easily blacklist if they've given you invalid blockheader, then that makes it much more difficult to do a D Ros attack against Light client to give them a lot of invalid blockheader or make them process a lot of junk. And that's exactly the same model that Bitcoin and Ethereum have. Like if you run a bitcoin node, your peer could send you a lot of invalid block headers, but all you would do is you would disconnect from that peer and you blacklist the IP address.
00:34:56.670 - 00:34:58.650, Speaker D: Is it okay if I ask a follow up?
00:34:58.720 - 00:34:59.340, Speaker A: Sure.
00:34:59.790 - 00:35:03.770, Speaker D: So I was more referring to native applications rather than roll ups.
00:35:03.850 - 00:35:04.430, Speaker A: Okay.
00:35:04.580 - 00:35:20.786, Speaker D: So in Ethereum, for example, we have certain operations that are costing certain that are not. So, for example, let's say in Celestia, I presume the fee will depend on the amount of data stored on the layer, right?
00:35:20.888 - 00:35:26.066, Speaker A: Yeah. The more demand there is, the higher the fee would be.
00:35:26.248 - 00:35:43.914, Speaker D: Okay, so, for example, a zero knowledge proof is relatively small at size, but it's very costly to verify. On Ethereum, I can't spam a lot of transactions because I'll run out of gas limit for the block, whereas in here, I can spam a lot of transactions because I'm just paying for the data.
00:35:44.112 - 00:36:37.320, Speaker A: Yeah, but the key point is there's no difference between from a cost perspective, there's no difference between a transaction that makes an invalid payment and a transaction that makes payment of one. Satoshi both of them theoretically cost the same amount to verify. I'm not specifically sure about the ZK scenario talking about, but in a specific payment scenario, you start to verify the signatures. So the cost of validating, like a one sufficient transaction is the same as validating an invalid transaction. So you can do the same attack Bitcoin and Ethereum by just doing a one sufficient transaction and make people process like a bunch of meaningless transactions. But of course, they still fix that with the fee market, and that solution seems to have worked.
00:36:38.170 - 00:36:39.046, Speaker D: Okay, I understand.
00:36:39.148 - 00:36:40.014, Speaker C: Thank you.
00:36:40.172 - 00:36:40.880, Speaker A: Thanks.
00:36:46.930 - 00:36:48.570, Speaker D: Can you help change the slide?

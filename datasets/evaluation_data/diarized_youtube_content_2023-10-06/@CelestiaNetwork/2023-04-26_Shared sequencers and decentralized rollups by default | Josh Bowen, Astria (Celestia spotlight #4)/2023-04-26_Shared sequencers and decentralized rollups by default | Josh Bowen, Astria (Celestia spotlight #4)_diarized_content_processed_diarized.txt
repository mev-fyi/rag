00:00:00.170 - 00:00:18.000, Speaker A: We want to see a million roll ups and maybe in five years, yeah, we do see like a million roll ups. I really want to see this kind of, to use like an overused term, like a cambrian explosion of innovation in these state machines driven by this kind of infrastructure being provided for them as a service, but in a decentralized way.
00:00:19.170 - 00:01:18.294, Speaker B: Hey, all my fellow modularists out there. Welcome to another episode of Celestia's spotlights, where we hear from the people at the forefront of the modular movement. I'm Nick White, COO of Celestia Labs, and today my guest is Josh Bowen, who is building Astria, the shared sequencer network. And as I've said many times, I think that shared sequencing is the next most important layer of the modular stack to be built after the DA layer itself. And I also think that if it's built correctly and designed correctly, a shared sequencer network could dramatically lower the overhead cost of launching your own rollup and provide a bunch of other benefits, which we'll get into. I also want to just do a quick shout out to Josh himself, who actually started out on the Celestialabs team a little while ago before spinning out to launch Astria. And we're very proud of him and what he's achieved so far.
00:01:18.294 - 00:01:19.746, Speaker B: So welcome, Josh.
00:01:19.858 - 00:01:21.880, Speaker A: Thanks, Nick. Really happy to be here.
00:01:24.090 - 00:01:38.586, Speaker B: So let's just jump right in. And I know you prepared some slides to explain what Astra is, and I think everyone's going to be really curious to learn more about the product, how it works. So let's go into that.
00:01:38.688 - 00:03:04.118, Speaker A: Yeah, great. So we call Astria the shared sequencer network, and we'll kind of dive right into some of the more technical details kind of during this presentation talk here. So kind of the core thing we think that is important that Astria is providing is for roll ups to be decentralized by default. And when we know default, the really key thing is we see a lot of rollups today that are centralized, but have obviously roadmaps and plans for how they're going to decentralize themselves. But we can obviously see as part of these plans that it's like a relatively significant effort for the roll ups to move from being this centralized sequencer run by the labs team to something that is fully decentralized through a governance mechanism and the multifig on chain or whatever like this. And so we think kind of with this future of many thousands of roll ups that we think is kind of necessary to scale blockchain sufficiently, we think it's important that new roll ups that stand up are decentralized by default, rather than going through the same kind of iterative process of standing up in a centralized manner and then over time, decentralizing, because we can see kind of the level of work it is for even the larger kind of established rollups that have been live for better than part of a year now or approaching two years for arbitram and optimism. So kind of just going into what kind of astria is and kind of how we see it in this space.
00:03:04.118 - 00:04:37.650, Speaker A: So we call Astria the shared sequencer network, but there's an important kind of like unsaid component there that's like a decentralized network here. And so Astria is this shared and decentralized network. And what we mean by that is shared here means that multiple rollups can use the singular kind of network. And then when we say decentralized, it's really this concept of kind of leader rotation or leader selection, similar to any kind of existing layer one blockchain, wherein there isn't a single actor that is responsible for proposing every single block across all time. We think it's important for censorship, resistance, and liveness guarantees to have a decentralized set of block proposers. And the way you accomplish this is a very similar structure to what you do with existing layer one networks that have this kind of leader rotation mechanism going kind of more into detail, I guess, on what it is to be, when we say like a sequencer, like, what is a sequencer here, we really think it's useful to kind of break down the flow of transactions through blockchain or like a roll up more generally into the components that actually happen. Right? So if you're a user of a roll up or even an l one, when you create a transaction, you're going to submit it into what's called mem pool or a transaction pool, right? And this mem pool is this kind of peer to peer network of nodes that are all kind of sharing a view of these transactions, but the transactions are unordered relative to each other.
00:04:37.650 - 00:05:34.934, Speaker A: They're all just kind of sitting in this pool. And then there's this phase where you actually order the transactions. And this is what we consider a block, right? You have this block. And fundamentally, the distinction going from a mem pool to a block is a step of ordering the transactions relative to each other from this pool of all available transactions. And then there's this third phase that right now is kind of bundled into the ordering step, but that's execution and the execution is what actually happens when you apply a state transition function over this existing ordered blocks. And there is a state machine like the Ethereum virtual machine is defined by being able to take a prior state of the database, take an ordered block as an input, apply that state transition function, and you generate a new state database, like a new state in time, right. And a state route alongside that.
00:05:34.934 - 00:06:31.098, Speaker A: And that's actually, that state route is what is kind of a key component of the header that is shared to light clients, whether those wallets or bridges. So I guess going kind of forward again into kind of like this is the kind of core diagram and comparison we use at kind of a high level here that was shared in our blog post. You can see the comparison on the left where we have these independent and centralized sequencers. This is kind of the standard for roll ups today. Users will send their transactions to the sequencer for a given roll up. That roll up is responsible for doing both the kind of production of the block or the ordering of that block and the execution of it. And at this phase they give this user this kind of soft commitment, but it is fundamentally like a trusted commitment, right? The user getting this kind of response from optimism or arbitrum is assuming that the sequencer that's like a single entity is being truthful here.
00:06:31.098 - 00:07:42.026, Speaker A: And then the sequencer, they're also responsible for bundling or batching or whatever terminology you want to use, and submitting the contents of this block to a data availability layer, whether that's something like celestia or with existing roll ups using Ethereum l one kind of call data as their data availability layer. We're obviously paper overing some details of kind of execution and the specific fraud proof or zero knowledge proof mechanisms. But we're trying to look at kind of a high level flow of data here. What we see as a better kind of system using a decentralized and shared sequencer here is that users submit their transactions to the shared sequencer, and the shared sequencer is responsible for performing the ordering of blocks for multiple roll ups at a given time. And then you have the shared sequencer again, kind of providing this soft commitment to end users and saying, hey, here is my ordering of the blocks. I guess it's given to the roll ups, ends up the users. But you can also have this shared sequencer be responsible for writing all the data to the data availability layer.
00:07:42.026 - 00:08:40.398, Speaker A: So you have this singular batch that is composed of transactions that have a kind of defined ordering for multiple roll ups, and you write that as kind of one batch to the data availability layer, and we consider that data availability layer giving what we consider like a hard or like a firm commitment. Right. I think in optimism's terminology, I think this is considered safe or final. I'm not sure exactly which terminology is, but there's a phase where you go from this statement of, like, the sequencer is giving you a guarantee over the ordering to the data availability layer, has accepted and kind of produced a block on top of that ordering, has given you its own kind of commitment over that. And we fundamentally see this a more optimal system, and we can go in more depth here into why we think this is truly a better kind of structured system here. I think the key thing, and this is going to be kind of in the weeds here to kind of move on here, right. Is getting into kind of like meV.
00:08:40.398 - 00:09:19.210, Speaker A: So a lot of the kind of what we presented on that last slide is kind of intentionally a bit high level here. We're not covering the details of exactly what is happening. And when we dive into this, really, we get into what is called, like the MeV supply chain. So this diagram here was taken from the post from, I think, last may by the flashbox team. And this kind of demonstrates, when you as a user are creating a transaction, what is the flow of this transaction through this whole system, right. And so all the way on the left, we have the user and they're going to kind of sign this transaction. Fundamentally, the transaction is expressing some kind of intent.
00:09:19.210 - 00:10:00.746, Speaker A: And again, we're not going to get into the weeds of intent based programming and various kind of ways around that. But what you're saying is in, say, a peer to peer sense, you're saying, I want to send money from this individual to this individual. Right. And I am allowed to kind of approve that transaction by way of having the private key to sign those funds. More commonly, this might be something like using a uniswap contract on chain and saying, I want to swap token a for token b, and then the wallet is kind of responsible, I guess, for taking the user's intent in an abstract sense. Right. And creating this transaction, doing the signing of that process, and then this transaction is sent.
00:10:00.746 - 00:10:51.466, Speaker A: What's not kind of stated here, because it's complicated to structure these, is that this transaction is going into a mem pool, whether that is a private mem pool or a public mem pool. So what we saw on the previous slide is that there is this phase of going from a mem pool to an ordered block, and there's actually a couple of steps in between there. When we get into kind of nitty gritty of what we see as this kind of proposer builder separation order flow. And when this transaction goes in the mem pool, that is where it becomes accessible to searchers. And searchers are responsible for looking at transaction in the mem pool and essentially extracting mev or finding what they're searching for, right. Is these mev opportunities. And that mev opportunities is kind of where the ordering of transactions relative to each other.
00:10:51.466 - 00:11:28.226, Speaker A: And this could be literally one transaction relative to another, or three transactions. This is where you get things like front running, you get back running, you get sandwiches. These searchers are looking for context in these transactions that can be valuable, and therefore they're trying to extract that value. So this transaction at this phase is going into a mem pool. The searcher will then create what is called a bundle. And a bundle is just a set of transactions, but specifically with metadata applied, such as a transaction within the bundle are ordered relative to each other. And then there's another phase, and that is the building phase.
00:11:28.226 - 00:13:12.534, Speaker A: And what this builder does, the builder is responsible for receiving a large quantity of these bundles and then saying, okay, based on the bundles I have what is the optimal block to build? And then the builder is then responsible for kind of sending this block to a validator, or in kind of the modern sense, this would be considered a proposer, and we prefer the terminology proposer, because specifically we are not doing validation. But the kind of core thing, kind of throughout this whole flow, is that all of this is relative to ordering of the transactions. Again, this block here is just like an ordered set of transactions. And I think it might be kind of two in the weeks to go into kind of like all the economic reasoning why we have this kind of separation of actors in the system that do this phase. But we think the key thing here is that there is fundamentally in this kind of, what I'll call it, the steady state, right? Like, if you have a system that is running for a long period of time, has user demand in it, you see multiple actors in the system that are responsible for doing a lot of action currently, like off chain, right, where the searchers find these mav opportunities and the builders construct the blocks and the validators or the proposers, fundamentally, what they're trending towards is being this very intentionally naive actor, wherein they are given this right just by the structural elements of how leader based blockchains work and produce blocks that they are allowed to kind of pick. What is the next valid block in the chain, obviously within the bounds of the state transition function of that chain. And what they actually are incentivized to do is to sell that right to the highest bidder, because it's fundamentally a specialized activity to construct these optimal blocks.
00:13:12.534 - 00:13:43.534, Speaker A: This building step is actually relatively high demand from a computational perspective. So this is what we see as MEV supply chain. And we'll go into kind of how we see the MEV supply chain applying to existing rollups, and then how we see it kind of applying to a shared sequencer network here. So we go into, this is our, again, relatively simplified view of what is an existing roll ups kind of MEV supply chain state. Right. You have this user on the left. They're going to talk to an RPC node.
00:13:43.534 - 00:14:07.050, Speaker A: Whether this is right now, I think inferior alchemy, et cetera, are running nodes for things like optimism and arbitrum. You could also submit directly to optimism and arbitrum here. But they're going to check their transaction. This is essentially where the wallet phase would be. It's going from user to intent to transaction. Check that transaction at the RPC. And this RPC is then going to send what is, in Eastland terms, like a pending transaction.
00:14:07.050 - 00:14:30.910, Speaker A: And that's going to go into the rollup mem pool here. And that is where searchers are going to pull from the roll up mem pool. They're going to create these bundles, they're going to submit those bundles to the builders. The builder is going to create blocks, and those blocks are going to go to the proposer for the roll up. That proposer roll up is going to do two things. It's going to give a soft commitment when it picks a block. It's going to give a soft commitment of that block back to the roll up RPC.
00:14:30.910 - 00:15:00.090, Speaker A: And again, these could be strictly at the same actors, but it's going to get back that user's RPC so that user can get this soft commitment here. It's also going to submit a batch to the data availability layer. When that batch is kind of accepted, the roll up will get this firm commitment from the data availability layer. So this is how we see kind of the existing state of roll up, like mev supply chain. And really it's mev supply chain. But this is overall what we see is just like transactional supply chain. This is a flow of order flow.
00:15:00.090 - 00:15:42.874, Speaker A: If we kind of go into how we see like a shared sequencer, fundamentally, the kind of structure here looks relatively similar, where, again, we see a user. And this is where we're kind of going into more details from our kind of higher level diagram before the user is actually still doing this. We're calling the check transaction phase, right. This is essentially like a signature check on the actual kind of transaction they are submitting to a given roll up. And that's happening at the roll up RPC node. But then the roll up kind of instead of in the previous slide where it would submit it to the roll up specific mempool, it is sending it to the shared sequencers mempool. And so this is, again, where the pending transactions happen.
00:15:42.874 - 00:16:11.554, Speaker A: But a lot of the flow from here is actually relatively similar in that this single roll up use case, you still have a roll up RPC. Give a pending transaction to a mem pool. That Mem pool is going to be looked at by searchers. Those searchers will create bundles. Those bundles will be passed to a builder or a set of builders. Those builders will then create blocks, and they will bid these blocks to the proposer. Kind of the key distinction here, right, is if we look at the shared sequencer, we've drawn it as a way to show there are multiple boxes here.
00:16:11.554 - 00:16:51.166, Speaker A: Actually, this shared sequencer, right again, is part of like a decentralized network here. So this isn't a single proposer. For every block, there is a rotation here, a leader rotation, and different proposers get different slots and they get to propose that. But fundamentally, they're still accepting blocks, and those blocks are still going to be kind of bid for. And then a soft commitment is passed to the roll up, and a batch is sent to the data availability layer, and you still get this firm commitment. So if we go and compare these kind of next to each other, right, we can see that really structurally, the system isn't all that different. When we have one roll up here, right, the flow is still kind of left to right similar.
00:16:51.166 - 00:17:45.954, Speaker A: We're really swapping out this roll up mem pool here for the shared sequencer mempool and this roll up proposer for the shared sequencer proposer. But all the rest of the flow is actually very similar. And so there's kind of a benefit here, even in the single sequencer case, and that is that Astria as kind of a project focusing on this shared sequencing component and specifically providing that decentralization as a service to these rollups which utilize the shared sequencer. We're just kind of incentivized in our product vision to make this kind of shared sequencing component decentralized from day one. We don't intend to kind of have this iterative launch where we have, oh, here's our centralized block proposer here. No, we're going to be decentralized from the day we go to a public testnet, from the day we go to any kind of main net launch. And so we think that's an important part of this.
00:17:45.954 - 00:18:28.190, Speaker A: But really, it gets more interesting when you look at having multiple roll ups here, right? So if we go to the kind of single centralized sequencer case, and we want to have two roll ups, this is really what we're seeing today, right. We essentially duplicate the entire supply chain for both roll ups. Whereas if I'm a user and I'm submitting a transaction to optimism here, it flows through this kind of optimism specific stack. Whereas if I'm submitting to arbitrum or something, this is going to submit through the arbitrum specific stack. And what we end up seeing here is that for every roll up we add, we have a lot of duplicative work. Each roll up is kind of standing up everything that another roll up is. And they're not sharing resourcing here, right.
00:18:28.190 - 00:19:13.398, Speaker A: They're sharing this data availability layer, but they're not sharing this kind of proposer thing. And this is why, if we see optimism decentralized their sequencer prior to arbitram, that doesn't inherently save arbitram, really that much work. Like, they could borrow the design, they could maybe share some code, but fundamentally, they're going to have to do the work of decentralizing that sequencer again. Whereas if we compare this to a multi roll up world using a shared sequencer, you have this user here, right? And they can submit their transactions to multiple different roll up rpcs. But all of these roll ups are then going to submit their pending transactions to the single shared sequencer mem pool. Right? And then this goes through kind of, this middle section is the same, right. It's shared between all of the roll ups.
00:19:13.398 - 00:19:33.794, Speaker A: And we think that's kind of the core benefit here, right. The searchers are feeding out of the same mempool. The builders are building a single block that goes to the shared sequencers proposer. Right? This proposer, again, it's decentralized. We do think that's a huge benefit here, an important thing. And then it's writing a single batch to the data availability layer. So you can see we can have three roll ups here.
00:19:33.794 - 00:20:17.300, Speaker A: And they are responsible for standing up what we're calling, like their RPC node or their roll up node here, right? But they can share all this resourcing. And so if we add many, many more roll ups, whether it's dozens, hundreds or thousands of them, it's still a much smaller amount of work than if we were building up this whole supply chain for every single roll up we staff on top. And yeah, that is the end of my slides here. Would love if you have kind of points that you think are more useful to kind of dig into more thoroughly. I know that was kind know a relatively rapid summary of a lot of stuff and there are still some kind of open bits here, but Nick, I'll kind of pass over to you there.
00:20:19.110 - 00:21:31.158, Speaker B: No, I love that. So just to summarize, basically what my takeaway is, know, the shared sequencer network basically reduces a lot of the redundant effort for people to run this sort of. It's not just the mev sort of supply chain, but in general the supply chain of launching and maintaining your own roll up. And so one of the things that pops out to me is that in this model, who is actually, if my roll up actually has mev, people are incentivized to run a builder, right, and to build the blocks and stuff, and probably even do the execution and generate the state DB and state commitments and so on. But in the case where I'm a new roll up, maybe there isn't, or maybe I just don't have meV. I'm a use case that just doesn't have much Mev, who's actually the one doing the execution and generating the new state commitments, even generating fraud proofs and ZK proofs, et cetera. That's the one gap, I guess, that I'm seeing, this model.
00:21:31.324 - 00:22:07.154, Speaker A: Yeah. So when we see this again, right. It's kind of hard to define this model. If we had a strict sequence diagram, there is a little bit of back and forth, and it's a little bit hard to see in a left to right case. But if we just look at this model and focus on one roll up here, right, fundamentally, if you're an end user in an existing l one or like a roll up, right, if you run your own full node, right, then you always have the strongest security guarantees because you are executing the state yourself. You are keeping a copy of the state DB, you are executing every new block and updating your own local copy of your state dB. Right.
00:22:07.154 - 00:23:21.782, Speaker A: And this fundamentally, I think what's important is this isn't different if you're running an l one full node or a roll up full node, right. Fundamentally, if I choose to run a full node of optimism, right, and I subscribe to all the new blocks provided by the optimism block proposer. You don't have any reliance on like a fraud proof or a zero knowledge proof, right? Because you know, you executed the block. You know that this is actually a valid block or is not a valid block, right? And this is this one of n kind of like honesty assumption, right? If you are the individual, you can always run that node yourself and provide yourself with this one of n honesty. So something that I think, and probably the best kind of more formally written kind of comparison of this would probably be like arbitram's white paper, where they go into the explicit distinction between the ordering of a block and the submission of a batch, and then what they call, I believe, the roll up sub protocol. And so there is this extra phase of this state route, right, where you still have someone who has to generate a state route and that state route to kind of give a guarantee of validity to light clients. And so I guess, yeah, going back to the kind of running your own node, full nodes don't need any other outside party to do execution.
00:23:21.782 - 00:24:48.822, Speaker A: They can accept an ordered block, they can execute it themselves. They have their new state Db, they don't need anyone else to provide them with this header that says, hey, here is the valid kind of state route at this time. But if you're running a lite client where there's really two primary users of a lite client, right, there are end users running wallets, whether it's metamask or Kepler or whatever, right? Or there are bridges, right? And so in the kind of, what is assumed to be kind of the standard model of roll ups now, right, what we would call an l two in the Ethereum land, right? Fundamentally the l one bridge is a light client of the roll up, right? So this is where this kind of fraud proof mechanism comes in. It's fundamentally a layer two and a layer one are two distinct networks, right? What they share is a guarantee of the availability of data, right? So at this phase, when a batch for a roll up is submitting to a data availability layer, that data availability layer is now aware and has the same kind of synchronous guarantee of what data was available at this time. And that is what we consider kind of trust minimized bridging. But going to kind of the state level of this, you have this kind of on chain bridging contract on the o. And I'm going to stay in Ethereum land because I think this is more kind of understood on how these roll up protocols work with a bridging sense, which I think is one that people focus on a lot, there is this assumption that that's kind of bundled into the roll up.
00:24:48.822 - 00:26:15.294, Speaker A: But fundamentally, it's a bridge like any other bridge, in that you have a light client that is not the same chain as the roll up. Right. If we had two cosmos chains, right? Fundamentally, there is a receiving chain, and that receiving chain has to be convinced that the sending chain is not lying to it before it takes some action on its side, whether this is minting new transactions or whatever kind of execution it wants to do for one of these kind of generic, maybe not token bridges, but what do they call them? Generic, kind of like messaging bridges. And so there is in this roll up case, right, some party that we'll call the validator for this case, like the validating party that's responsible for submitting a state route and fundamentally attesting to what is a valid state route to a receiving side of the bridge, right? So again, arbitrum actually fleshes this out quite well in that they have a set of validators that are currently whitelisted, right? These are actors that are responsible for submitting new state routes to the on chain contract on the receiving bridge. In this case, it's on the l one. This is, again, similar to how you would see, like IBC, where if I have a committee in IBC land, right, that is doing this kind of like signature aggregation, right? And it is sending this message to a receiving chain. Fundamentally, what that sending chain is doing is attesting to a given state route and then sending it to the receiving chain.
00:26:15.294 - 00:27:25.930, Speaker A: So that's what we see this in our model, is this roll up, because the key thing is this sequencer, right, fundamentally is only doing the ordering, it's not doing the execution of the blocks. And so you do still need this, what we'll call like a validating node, to actually do bridging. But we think it's important to note that that is not strictly kind of like a necessary component of being a roll up, right? In celestial terminology, we have this concept of sovereign roll ups. And sovereign roll ups do not have these enshrined bridges with any given settlement layer, right? They define their own destiny, their own definition of canonicity, of the state of the roll up. And we kind of fundamentally view the kind of bridging concept as something that is separate, that is better trust minimized bridges are better than non trust minimized bridges, right? But it's fundamentally separate from the roll up component. So maybe is there a more specific kind of component of that that's useful to dig into here. I know you mentioned the fraud proof or the ZK proof, and this kind of who is the actor doing this? But at a high level argue is that there's no reason that should only be done by a single actor.
00:27:25.930 - 00:27:43.780, Speaker A: I think it was Kelvin from optimism who had a good talk at East Global some number of weeks ago that really kind of dove into this. And then Paki McCormick had a follow on blog post that kind of summarized kind of his view on that as well, but can go into details on kind of whatever is useful here.
00:27:45.030 - 00:28:53.186, Speaker B: Well, I think to summarize what you're saying is basically that Astria's function is very much sort of independent and agnostic to whatever sort of model the roll up builder chooses as far as ensuring the validity or proving that the state route or doing the execution, essentially. And people can either, there can either be support, it could be like a pessimistic roll up where it's like, oh, you either run a full node or you have no guarantees, or it could be like, hey, someone is responsible for generating a ZK proof and ZK proving the validity. And so that makes sense to me. I think I was more commenting on the fact that of the developer experience, which is that let's say I'm a developer, right? The goal for all of this and for the modular stack is that to make it turnkey. So when I want to deploy a roll up, I just press a button and we want it to be as easy as deploying a smart contract where there's basically no infrastructure required. Essentially I am seeing, for example, an RPC. So someone's probably going to be responsible for deploying and maintaining that RPC node.
00:28:53.186 - 00:29:33.810, Speaker B: I think that's pretty easy. Like someone could build a service for that. But that RPC node is not the same thing as someone standing there and saying, I'm actually going to be responsible for generating and circulating fraud proofs, for example. So I guess I was thinking to myself, builders, if there's MEV or people doing as part of the MEV pipeline, might already be doing the execution, so they might fulfill that role out of the box. But if they aren't there, then a roll up builder may have to actually say, hey, I'm going to run that service internally, or maybe there's some way of incentivizing it. That's really what I was getting into. I don't want to go too much further on that, but if you have a quick comment there and then we can move on.
00:29:33.810 - 00:29:34.882, Speaker B: Yeah, just touch on the review.
00:29:34.936 - 00:30:07.582, Speaker A: Yeah. I think this kind of roll up RPC, right. This question of who runs that, right. Fundamentally, your roll up still has its own state transition function, right? Like what do you define as the state machine of your roll up? And someone still has to do that execution, as you noted, right. The builders are incentivized to do this execution. If there is mev to be extracted, then they will do this stimulation over one roll up or many roll ups, right. To find what is this kind of potentially multi roll up, optimal ordered block that maximizes kind of their return there.
00:30:07.582 - 00:31:35.094, Speaker A: But if you're a new roll up, right, and haven't kind of signaled or kind of gotten support here, the thing that we think is very nice and kind of clean here, that this degrades or degenerates to kind of the current status quo, right, where you could say, okay, we are the roll up development team, we're early, we're looking to kind of find product market fit or get adoption or whatever, and we're going to run this roll up RPC infrastructure ourselves. And you're welcome to do that. And then users have kind of the same status quo they have now of saying, hey, I'm going to go talk to this full node hosted by Infira or alchemy or the roll up development team. And that's where they're going to kind of make their kind of trust assumptions. The kind of nice part is that you're not bundling your censorship resistance or liveness guarantees into that block. Production is fundamentally a distinct element of this system that is done by this existing decentralized network that you get to buy into, right? That's why we consider like decentralization as a service, right? Thinking about this off the shelf construction of a roll up, you want to be able to pick and choose these different kind of components to build up a system, right? So you say, okay, I'm going to go to Celestia, and I'm going to use Celestia for my data availability, and I'm going to go to Astri, I'm going to use that for my block production, my shared sequencing. And then right now I'm going to choose to stand up my own roll up and I'm going to run my RPC node or I'm going to work with infura or alchemy or you know, pocket network or something to stand up an RPC node and then going into bridging.
00:31:35.094 - 00:32:37.662, Speaker A: We think that will look kind of very similar to how we see bridging right now where is, if you're a chain and you want to get kind of fast existing liquidity, you're probably going to negotiate with layer zero, or axilar, or wormhole, or the hyperlane guys, right? And you're going to tie into some existing liquidity network that will give you this kind of interoperability between these chains. But again, it's just another component you're able to get off the shelf, and you have a lot of optionality into that. And just one last is like long term. We also think this is what will happen on the zero knowledge proof side, right? We see the work happening with the starkware guys on their sharp shared prover. The risk zero guys with their bonsai network are building up these networks to incentivize the computation, right, because it's relatively expensive computationally to generate a zero knowledge proof. But again, it becomes this existing network of actors that are incentivized to say, hey, I don't care what goes in the proof. I am paid for essentially my marginal computation power and knowledge at executing computations of this shape and form.
00:32:37.662 - 00:33:24.750, Speaker A: You pass your roll up state machine into that with, okay, I have this state and I have this block, and I want to execute this state transition function. I want you to give me a stark on the back end of that. Right. Again, it's just part of this kind of overall holistic system, such that we really drop the effort of deploying a roll up as low as possible, similarly to how we think cloud services have allowed it to launch a web, two kind of centralized application to a very low amount of effort. You don't need to call a colocation facility and go get a rack or whatever. You click three buttons, you deploy your app, it's live. We want roll ups to have the same space, and that really will open up innovation, experimentation, and kind of an abundance of kind of transaction throughput by building on these existing kind of decentralized networks that build up this overall modular ecosystem.
00:33:26.530 - 00:34:16.110, Speaker B: Yeah, absolutely. I am also really excited by the fact that people like Risero and Sarquare are building these sort of decentralized networks that provide these services that are going to be key components to the modular stack of deploying a roll. Like they could do the proving, for example, and you don't have to, because that would be a huge lift if I wanted to deploy my own ZK roll up, but, oh, I have to run the prover. Not only does that probably take a lot of expertise, it's also just expensive to set up and maintain. And so it makes perfect sense that that becomes a decentralized service that people can tap into. So completely agree there. And the more of these layers and components that turn out that can be built that way, the more they should be, I think.
00:34:16.110 - 00:35:18.654, Speaker B: And even, I mean, things like Pocket network, which does decentralized RPC service stuff, maybe there's something there to help decentralize or automate the launching of the RPC layer of this diagram. So, I don't know. I'm really excited because it feels like it's within reach, that we can actually make this a reality in a decentralized way. That's the important thing. It's really funny, because I remember back in 2017, there was this buzword of blockchains as a service, right? In that era, it was basically like private chains. I know teams like AWS or even Google Cloud started launching these things with, oh, one click and deploy your own blockchain network or what have you, but it didn't make any sense because it's all like centralized. But now we're actually getting to a stage where it's possible to have decentralized blockchains as a service, and every component is actually run on a decentralized network.
00:35:18.654 - 00:36:24.182, Speaker B: So it's really cool and I think it's within reach. So I have a bunch of other questions, and I want us to get through them all. So hopefully it's hard not to get way too deep into each of these, but hopefully we can touch on a bunch of these without getting too down the rabbit hole. So one of my next questions is basically around the economics of Astria. So you mentioned that Astria is sort of decentralized sequencing as a service. So I'm wondering how does, if I'm a developer, I deploy my roll up, how do I pay for this service? Or do I pay for it? Or sort of how does it work? Or maybe Astria's, the way that it operates and funds itself is just through MeV, because it kind of has this preferred spot in the sequencing in the MEV, sort of like supply chain, where it can just capture value without actually asking for people to pay. So I'm curious how you see this all functioning economically, because that's obviously important for the viability of something like this.
00:36:24.316 - 00:37:17.906, Speaker A: Yeah, so I think there's really two parts. When you think about how it paid, there's like a structural element of, literally the wiring of how do I pay for this? Right? Or there's the economic element of it, and that is based on the market structure of actors within the system who is able to demand a higher price because they have kind of more dominant kind of competitive pressures. And one of the things we see and why I think this kind of MEV supply chain is such like an interesting concept, especially in this kind of shared sequencer sense, and really especially in this sense of separating this ordering from the execution. We're leaving out one bit here, I guess I'll note, and that's that there's a relayer. And I'm going to try not to go too much in the weeds here. But fundamentally, the thing that we're seeing in relayers right now is that a relayer is an actor. Relayer is a sidecar on top of a validator in, like Ethel one, right? And this relayer is responsible for accepting a large amount of traffic.
00:37:17.906 - 00:38:15.242, Speaker A: It's relatively like a high bandwidth component, and then it's also responsible for checking the blocks that it receives from the builders. So it's responsible for making sure they're valid before it sends them off to a proposer. And this is like a trusted party here, right? And again, I don't want to go too much in the weeds here, but what we're seeing kind of happen is the ultrasound money guys, is like Justin Drake is they launched this thing called an optimistic relay. And fundamentally, it's not doing this execution phase of the blocks. And why we think that's really interesting is because it models very similarly to how we see the shared secrets of component. That is only doing ordering and not execution of the blocks is we see this trend over time wherein the block proposer, this actor, that, again, just as an artifact of how leader based blockchain networks produce, the next chain in the block is allowed to kind of rubber stamp and say, I attest to the validity of this block, and it is the next block. And that is a monopoly that actor has within that system.
00:38:15.242 - 00:39:03.770, Speaker A: And the concerning thing about this monopoly, right, is it's not like a horrible monopoly. It's not like the centralized sequencers would have this monopoly over time. It has a monopoly for this given block. But a monopoly is still a very powerful force in, like, an economic system, right? It can say, well, if no one pays me a valid price, then there's just no blocks this time, right? And what we see as kind of desirable is to drive the amount of value that this monopoly is able to extract out of this system as low as possible. There will always be this fundamental kind of value as being a monopoly. But what we want is we want a trend towards saying there is this proposal and it must exist as an artifact of how these leader based systems work. This proposer doesn't do a lot of work right now, right? It just says, hey, I will accept whatever is the highest bid block that is sent to me.
00:39:03.770 - 00:39:35.742, Speaker A: It's your job to tell me and determine what is the highest bid block and I will just accept that. So we think that's a role that we want to kind of minimize the value for. So economically that's kind of what we're trending towards. We see this as being beneficial in that. What we say is also that we want roll ups that utilize the shared sequencer to maintain their sovereignty. And what we mean by that is that it's very easy for them to leave the network. And the ways in which this is done is because the network is inherently a very simple component.
00:39:35.742 - 00:40:56.378, Speaker A: What this shared sequencer network is doing is going to, it's part of this like the proof of stake leader selection based blockchain. It's just rubber stamping. It's saying someone else, these builders, and then these searchers, and the user at the end did effort to say I either want a transaction in, and I found valuable economic ordering opportunities. And I did the simulation work of finding how I could most optimally pack a block to kind of maximize the value of this block, decides this block, given the gas limits. And they did work, right? And we want the work that is done by this kind of monopolistic proposer component to be minimized and structured in such a way that you say, hey, we think this monopolistic actor is being rent extractive, right? They're just abusing their position and maximizing the amount of rent they can take out a system while minimizing the amount of work they do. We wanted to make it easy to say, hey, if that's the case, you should go use a different sequencer component, whether that's your own sequencer component or whether you stand up through like hard forking or whatever, an alternative sequencing network. And this is enabled again because it's a very simple component and really kind of going back to your point on who's doing this kind of state validation, right? In this RPC node, the sequencer doesn't own the state of the roll up, the roll up owns its own state database, right? And state is fundamentally the thing that is hard to fork.
00:40:56.378 - 00:41:56.558, Speaker A: Whereas if you say, hey, we're going to pause the network and it's going to take us 30 minutes, we're going to be down for 30 minutes or whatever, right? You can do it as a hot swap, but you just say we're just going to readjust this one parameter and say this is now the actor that we trust, whether it is a networked actor, as the canonical block production mechanism, right? And by making that very easy in our design, we think that minimizes the amount of rent that this proposer component will be able to extract from the system. Touching really briefly on kind of the wiring kind of system of this fundamentally, this shared sequencer is a network. And as a network, right. This kind of decentralized byzantine vault on your network, we do need a civil resistance mechanism, right? And so I think a lot of times people kind of forget and have gotten in like a weird sense of tokenize everything. That's not my personal view. Right. It's the idea that these tokens exist as a fundamental requirement of running this byzantine fault tolerant, decentralized network.
00:41:56.558 - 00:42:29.194, Speaker A: Whereas if you don't have some sense of metering in the network, you will get spam on the network. And so the existence of the token is because one of these networks needs to have this native kind of concept of metering access to the network. And this is fundamentally what gas is for, is you're saying, I want to use this network. It's providing me a service. In our case, it's giving you sequencing and it's giving you decentralized sequencing, right. That is permissionless for any kind of roll up to choose to utilize and tie into its system. But it does require a token, I guess, is what I'm saying.
00:42:29.194 - 00:43:39.570, Speaker A: But a token in this kind of true sense of this kind of commoditized element that is just like a measurement of a unit of work essentially, for the network to do. So combining those two things, I guess it's maybe kind of beyond the scope here of kind of like what happens at this user state, but touching briefly on this kind of mev supply chain and some things we've heard around, like ERc four, three, seven and other kinds of account abstraction style primitives, we think there's potential to see things like gasless transactions at least abstracting away this proposer component through searchers saying, hey, if you send your order flow here and I pick up your order flow, I am going to monetize that on my side. And I don't really need whatever your kind of base fee component is to kind of be able to monetize that. There's some kind of, again, this kind of civil base cost, right, in the network of the network cost as much computationally use. And the actors that are potentially kind of comfortable paying that cost because they have other economic incentives are these searchers or these builders. And however they negotiate kind of their rates between them as fundamentally kind of like intelligent actors in this system. Right.
00:43:39.570 - 00:43:49.640, Speaker A: They're non naive actors. Again, that's not like a detailed answer. We're not kind of committed to one specific structure here, but that's roughly kind of the direction we're thinking this goes in.
00:43:53.220 - 00:44:53.140, Speaker B: Thank you. Yeah, I am really glad to hear that you guys care a lot about the sovereignty of the rollups, because obviously that's something that Celesia believes in. And in general, I think the modular blockchain movement stands for is people and developers and communities who are running these roll ups should have the freedom of choice to do what they want. And if they were locked in to Astria or whatever, Astria had some kind of control over their system, that would be very undesirable and problematic. So it's good to hear that you guys are not seeking that kind of outcome. And in terms of the account abstraction, I think that's going to be really powerful to make it so that the user experience is as smooth as possible. And if there's too many tokens or they have to think too much about payments, I feel like there's ways of internalizing the costs and abstracting it away from the end user.
00:44:53.140 - 00:46:14.796, Speaker B: It's going to be interesting to see how this all plays out. Some other questions that I, this is like the last sort of technical question that I have, and we have a bunch more to cover and we're running low on time, so hopefully we can go quickly on this. But I just want to hear quickly, I think really a lot about the developer experience, and at the end of the day, to me, the user of Astria or even Celestia is a developer. So why would I, if I want to deploy an application, right, why would I choose to deploy on a shared sequencer network like Astria versus two other options. One, I could deploy a smart contract on an existing sort of general execution chain, or roll up, or b, I could actually launch a based roll up, meaning that in this diagram, you kind of merge the data availability layer with the shared sequencer proposer thing, and all of a sudden you kind of eliminate the need for this shared sequencer interface between the roll up and the DA layer. So I'm curious, how do you see those two things? And I know that could be a big question, but hopefully you can answer that without in a shorter amount of time. I know.
00:46:14.796 - 00:46:17.310, Speaker B: It's like a huge topic, though.
00:46:18.080 - 00:46:29.164, Speaker A: Yeah. I mean, that's certainly like a huge brushing. It's like fundamentally asking what is the justification of, to some degree, roll ups, app specific chains, various things. I'll touch on the first one. Right. It's like the smart contract versus chain.
00:46:29.212 - 00:46:29.616, Speaker B: Right.
00:46:29.718 - 00:46:59.128, Speaker A: And fundamentally, I guess in my mind, there's kind of, like two good reasons maybe to do this, right. Smart contracts are like, fundamentally, I think they've provided an almost unrealistic quality of experience. Right? Like, I come from a cloud background, right? So working on serverless things, right? And the idea is trying to abstract away infrastructure from end users. The cloud is still not there. You still have to kind of pretend there's, like, infrastructure somewhere. Right? Whereas smart contracts with this network stair, you deploy a smart contract and it will run forever. Forever.
00:46:59.128 - 00:47:10.450, Speaker A: That's like an almost unbelievable level of thing. The trade off they've made, fundamentally, is like, it's difficult to scale. Right. The whole space we're in. Right. Very hard to scale, these singular networks. Right.
00:47:10.450 - 00:47:46.084, Speaker A: And so we see kind of myself. Right. I'm not saying I'm speaking for necessarily the whole project, but I think if you're doing a smart contract versus another chain, again, there's two points. One is just scale, right? Like, is that chain just too congested such that you don't think you're going to get yourself through? There's this thing called, like, a noisy neighbor issue and kind of shared resource usage. Right. I think we've seen this on Solana, especially because it didn't have kind of like this state contention biding mechanism where you see, okay, someone's doing an NFT mint today. So every other application on the chain is infeasible to use because the chain is just kind of congested.
00:47:46.084 - 00:48:04.908, Speaker A: Right. So there's use cases like that where you say, actually, I don't want to share the chain with those guys. I don't work with them, I don't interoperate with them. I'd rather be over here in my own lane and not share resurfacing with them, because sometimes when they're busy, I get a degraded quality of service. That's one of this kind of trade offs of sharing, fundamentally. Right. There are ways to resolve that in these chains.
00:48:04.908 - 00:49:22.036, Speaker A: Solana's made progress there. There's a lot of research on Ethereum on kind of resolving these things with fee markets and whatever, but fundamentally, there's, like, congestion and standing up your own chain might be a way around that. There's also this question of app specificity and kind of design of this state machine, right? A smart contract is going to be dependent on the virtual machine it runs on, right? Whether that's a cosmosm one, the Ethereum virtual machine, the Solana virtual machine, IC level, or like fuel, right? But fundamentally, you're building a contract that is inheriting kind of some assumptions on how you construct your stuff within that larger, more generic state machine. The kind of cosmos thesis about specific chains is that maybe if you built it from ground up or using a framework that is at least more flexible, you would get benefits there. And so I think those are kind of two of the, kind of reasons why you would do that. And I guess I'll choose to just not go into more detail here, just for time reasons. Going into the other question that I think is maybe it's more relevant immediately to us, maybe it's like this more existential question of kind of like why should a shared sequencing network exist? And I think we view this as an evolution touch on base roll ups, right? Of like why should a sequencer exist at all? Right? From the base roll up concept, there's not a strict requirement for a sequencer.
00:49:22.036 - 00:50:00.688, Speaker A: All the end users could still submit their transactions directly to the data layer. We think there's really two broad categories, and maybe that's not even like a clean distinction. So going to a history thing, arbitrary. Optimus, they started without sequencers, right? They started as what is now termed like a base roll up, or what the roll kit team calls like a pure fourth choice rule where you submit your transactions directly to called the base layer, right. Fundamentally, what they saw was that, I guess there was demand, so there's user experience demand, right. Your base layer is going to be designed for some reason. So I obviously have more experience with Celestia.
00:50:00.688 - 00:50:16.052, Speaker A: Celestia, in my view, right. I'm not speaking for Celestia, but is optimized for data throughput. And I mean that in that celestia can kind of give good, strong guarantees of the availability of the maximum amount of data in a decentralized manner.
00:50:16.116 - 00:50:16.488, Speaker B: Right?
00:50:16.574 - 00:51:22.512, Speaker A: That is what it is done. That is how it is designed and architected to optimize for that thing. One of the trade offs of that is, and I'm papering over a lot of things, right? Celestial people, Evan Forbes specifically might have a lot better kind of context on this, but there is a trade off in block size and block speed, right? So you could have smaller blocks going faster, you could have larger blocks going slower. My understanding of celestia. Is that the way the kind of share encoding works, it is more optimal to have larger, slower blocks than it is to have smaller, faster blocks, right. And that fundamentally conflicts with user experience, kind of like expectations, right? There's any number of studies out there, I'm not remembering the one off the top of my head, but there's one from like 91 that's like the kind of one reference that's like users want something between one and 4 seconds response time, right? That's just what they like to see. You see this in how Google defines its ranking of pages or whatever, right? But that's a fundamental trade off with the optimal way to design this deeply technical system that is optimizing throughput, the layer above it, right.
00:51:22.512 - 00:52:12.636, Speaker A: The shared sequencer layer is, if we look on this diagram here, we have this concept of a soft commitment versus a firm commitment. It's somewhat analogous, right, to a caching layer where you say, okay, we're going to get a commitment in 2 seconds or 3 seconds or 1 second or whatever we define as like the block time of the shared sequencer, but faster than the data availability layer. And it's going to give you this soft commitment over that. It's good enough for you to take it for that. Maybe you're doing a very large transaction and you want to wait for kind of a longer time to get more guarantees of settlement. On this point, I would reference everyone to kind of like Nick Carter's post from, I want to say it was 2019 and it was, I think, titled something along the lines of like, it's, the settlement assurance is stupid. It's like the title of this post, and fundamentally of saying, what is settlement? That there's a guarantee or a probabilistic, I guess I'll say, guarantee that a transaction won't revert.
00:52:12.636 - 00:52:30.070, Speaker A: Right. If I'm sending a billion dollars, when am I confident that the receiving party has a billion dollars? And I can't take that back. Right. Different financial structural systems have different kind of guarantees of finality. I'm in the system. And so that's what I'll say there, there's this cashing benefit, right. Touching really quickly on one more point.
00:52:30.070 - 00:53:15.376, Speaker A: There is this also just structural element on both Celestia and I believe in protodank charting and dank charting. I've talked to Kelvin a little bit about this, but I'm not that clear. But essentially there's a minimum size of data you can buy on a data availability layer, right? I believe in Celestia. It's like 512 bytes or something like that. And what this means is that if I'm a user and all my transactions go to the data layer and I have a transaction where the intent and signature, et cetera, et cetera, the content of this transaction is 50 bytes. I still have to buy 500 bytes and I can say, okay, fine, I'm just paying 450 bytes extra. And again, this ties into the structural design of how you best construct a chain that maximizes data throughput.
00:53:15.376 - 00:54:07.520, Speaker A: That's like an order of magnitude. That's not nothing, right? Everyone would like their blockchains to be ten times more efficient, right? So there is this benefit in having just like a batching layer, and this is what the sequencer is. And combining these, we think there's a reason why sequencers should exist. Why should there be a shared sequencer? Again, that goes back to kind of how we started this, of like, decentralization is like a hard process, both technically and kind of like, I'll say, in an operational business sense, right. You have to convince a large number of actors in geographically distributed settings to run nodes in your network. That takes work, right? That is a negotiation. We think that we can provide a system that is generic enough in its kind of interfaces with these roll ups that it's less work for them to go buy in and pay whatever the market rate is for decentralized block production sequencing.
00:54:07.520 - 00:54:49.520, Speaker A: Right. Than it is to go try to do the effort of standing up their whole network. I think there's prior kind of validation, I'll say, or at least evidence of the demand for this through both Polkadot kind of parachains as some structure at kind of shared security, right, where they say, hey, people want to buy this in. They don't want to stand up their own network every single time. As well as Cosmos's interchange security or replicated security, they're calling it now. Our system is distinct. I probably won't go into the details here, because it's just a long winded thing, but we do think there is some benefit to kind of sharing security, having one larger, more economically secure network that resolves this specific task, and then it is beneficial for roll ups to just buy the market rate for that.
00:54:49.520 - 00:55:03.210, Speaker A: Again, very similar to cloud stuff. Everyone could go stand up their own data center, but that's like a very high bootstrapping cost. You'd rather pay the market rate to get that as a service. And we think that's fundamentally, like, the optimal way to do this and to make it lower effort to launch a roll up.
00:55:05.740 - 00:56:00.664, Speaker B: Got it nice? I think that's a very clean answer in response to those questions. And a data availability layer at the end of the day has different sort of design, I guess, goals than you might want for this shared sequencing property. And I think what's nice about having these decoupled is that you can kind of get the best of both worlds, like the sum or what is it? I can't remember. The sum is greater than the whole, is greater than the sum of its parts, basically. And the other cool thing is that I envision a future where there's multiple shared sequencer networks, right. And each one might be designed differently for different properties or have different specializations. And I think that that's going to, again, increase the choice for builders and be able to sort of customize what they want.
00:56:00.664 - 00:56:41.216, Speaker B: So again, modulism, not maximalism. We say it all the time, but it really is true that the more choice that developers have, the better the systems they can build. And the better the end user experience, the more crypto can actually be adopted and used. So, very exciting. So some last questions are something that I don't think people are necessarily as aware of. I know you guys are really pushing hard on the shared sequencing side of this thing, but one of the parts of your project is also launching this EVM chain. You guys are kind of, in a sense, going to be the first user or consumer of this shared sequencer network yourselves.
00:56:41.216 - 00:57:02.190, Speaker B: So I want to hear a little bit about Astra AVM and your plans there. What's the ambitions for this EVM roll? As far as I am aware, it's the first general purpose EVM chain or roll up to be launching on Celestia. So I think it has this kind of know, unique position, potentially. So I want to hear more about what you guys are going to be building.
00:57:03.200 - 00:57:34.996, Speaker A: Yeah. So without going too deep in the history here, but the origin of Astria, the project was centered around how do we deploy roll ups generally on top of celestia, and an EVM roll up specifically on top of Celestia. And the shared sequence layer came out of essentially just architectural designs for how to accomplish this. So there was always in our head, like, okay, well, we're already pretty far down the path of building an EVM. We're thinking about how to build an EVM here, right? So there's some path dependency to it. But also when we were building this EVM, we started building it, terming it like a settlement layer. Right.
00:57:34.996 - 00:58:42.648, Speaker A: And when we really looked at it from like a first principled approach. What we were thinking was like, what are we actually trying to do? And what we were trying to do is say, we're trying to make it the easiest possible to build roll ups. Because fundamentally, I view competition as the thing that is necessary to drive an ecosystem forward. You need someone saying, I am incentivized to do better than you, and if I do better than you, then you have to catch up, and then the ecosystem moves forward as a whole, right? So we were trying to say, how do we make it as low barrier entry for someone to build roll ups as possible? And so we saw this EVM as this settlement layer, right? And then we thought, well, what is a settlement layer giving you? And what a settlement layer gives you really is like this opportunity. It's a place you do bridging and kind of really like liquidity, because blockchains are fundamentally these financial elements, right? So liquidity pool somewhere, and it is this hub and spoke model of liquidity within an ecosystem. But we also saw this need for us building the EVM and for other chains as well, to get this ability to have this kind of sequencing as a service, right? It's like decentralized synchronizing a service. We needed that for our EVM, and we knew that other chains would have it.
00:58:42.648 - 00:59:40.832, Speaker A: So that's why we're building this kind of two pillars of things, is the EVM we see as know. I don't love the term, but like settlement layer, wherein other roll ups can say, hey, I want to stand something up. I want to use the shared sequencer network or not, but they want to stand something up within Celestia, and they want to get the benefits of this trust minimized bridging. We want to do, again, similar to the shared sequencer network. A lot of the legwork of establishing these relationships, whether it's with centralized exchanges, whether it's with other ecosystems through bridging, whether it's through with stablecoin issuers, and provide this kind of base level resources that will be desirable for other roll ups that are just kind of fundamental. Kind of like to Paul Graham, things that don't scale, right? Everyone has to do it themselves, and we think we can do it and provide this resource to other rollups within the ecosystem that is more beneficial. And then on one more point, I also think kind of the term eating your own dog food, right, is extremely important.
00:59:40.832 - 01:00:30.530, Speaker A: I've experienced the negatives of this for years in my career, in the past at GCP. I think one of the reasons GCP struggles is Google doesn't build on top of GCP, right? So what I mean is, we want to build this EVM, and this EVM is building on top of the shared sequencer. What that means is if we want the EVM to be a good product, the shared sequencer has to be a good product for that. And this is a forcing function on making sure that we're building something that is actually desirable to other roll ups in the ecosystem. If we just said, hey, here's the shared sequencer, we think it is good, and someone comes and say, that's not that good, then like, okay, great, we have to go back to the drawing board and we have this difficult iterative design process. If we say we're building this, here is the component that's using it. If it's hard for that component to use it, we can know that kind of internally and we could iterate more rapidly, kind of like as a project to build what we think is like a better solution for everyone.
01:00:31.460 - 01:01:20.316, Speaker B: Yeah, I think that dog fooding is extremely important and in some ways something that we're excited that you guys are also building on top of celestia itself and giving us a lot of feedback. And same with other projects like Rollkit or sovereign labs. And obviously we need to be credibly neutral, but having users and sometimes being your first user is extremely valuable. I'm actually kind of surprised that Google doesn't even run on GCP. That's kind of a red flag to me. But yeah, in terms know, and this is something that people also get hung up on about. Celestia is like, hey, there's no settlement as part of the DA layer because they come from an Ethereum mindset and Ethereum model, where part of Ethereum is, it has this enshrined settlement layer.
01:01:20.316 - 01:02:04.380, Speaker B: And frankly, in our opinion, that's not something that belongs within the DA layer. The DA layer should be minimal and as basically generalizable as possible. And when you add settlement, you're kind of making choices that cause externalities for other people building on top of it. And so I expect lots of. But at the same time, settlement is important. Those people are right, there is a need for this kind of function, but we just feel that it shouldn't be at the l one. And so I'm excited and glad to hear that you guys want to provide this to the ecosystem, because I do think it's very valuable to have a liquidity hub or have exchange integrations or asset issuance, et cetera.
01:02:04.380 - 01:02:35.492, Speaker B: This is a very fundamental function that needs to be supplied to the broader modular ecosystem. And some roll ups also require a settlement layer, especially the EVM being probably the most commonly required one, to do interactive verification games and actually verify their fraud proof. So this is going to be. I'm really glad that this is also part of it. It's like two birds with 1 st. You guys are doing the shared sequencing. You're also adding this settlement functionality to the ecosystem.
01:02:35.492 - 01:02:47.870, Speaker B: So super stoked. Okay, now we just have a bunch of rapid fire questions, and you have to answer each one of these. It might be really hard, but try to answer each one of these in only 30 seconds. Okay. Are you ready?
01:02:48.480 - 01:02:49.180, Speaker A: Yes.
01:02:49.330 - 01:02:53.580, Speaker B: Will Astra support other DA layers or only just Celestia?
01:02:54.560 - 01:03:19.510, Speaker A: Yeah, we plan to support other DA layers. We think structurally it's not, like, that difficult, but we're not doing that at the start. There's varying things of premature optimization is not the right thing. But designing too generic of an interface from the start is just, like, more engineering work. So we do intend to theoretically support multiple DA layers, but right now, we're just building for Celestia because we want to build for one interface, and Celestia is also the one we have the most comfort level with.
01:03:19.880 - 01:03:59.410, Speaker B: Yeah, and I was talking to Evan, one of the engineers who helped, I think, to inspire this shared sequencer vision. And one of the things that we couldn't figure out was, does it make sense for the same shared sequencer network to plug into multiple Da layers? And how does that work? It's a non trivial problem. I think it's very possible, but it's also kind of like, you have to think about it pretty carefully when you're designing the system. So I'm curious when that does happen, I'd love to see that design. And I think it should be that way again, that there's multiple DA layers, and maybe people can choose which one they post to. And the mem pool is kind of unified. I don't know.
01:03:59.410 - 01:04:08.420, Speaker B: So the next one, do you expect most of the rollups deployed on Astria to be app specific roll ups or to be general purpose?
01:04:10.040 - 01:04:41.472, Speaker A: I don't know if we have a strong opinion on that. And those terms are a little bit, like, flaky. So, like, when we were designing this, we had this concept know, this sliding scale between app specific being, like, literally, like Cosmos SDK. It just does this one thing, and general purpose being like, it's like an EVM. We had this idea of, like, maybe it's an EVM, but only, like, three applications on it. Because there are still certain applications that kind of compose together. Well, you might want to have a local lending protocol give you flash loans right next to your decks, but maybe you don't need an NFT market on that same thing, but you want those things.
01:04:41.472 - 01:05:04.730, Speaker A: So we don't have a strong opinion on that. We're pretty open. We're talking to broadly other people, and again, we're designing our interface to integrate the shared things to be very generic such that we don't kind of restrict at all the state machine that is designed to work with it. But I don't think we have a perspective on which of these we have a preference for. We're staying open and seeing what the market decides they want to build.
01:05:05.420 - 01:05:28.190, Speaker B: Yeah, I think it's good to build to be generic and let the market decide. And I think the way that you guys have built it will be suitable for either use case. I'm just curious to see how it all plays out personally, because it's interesting to reason about. Okay, next one, what kind of consensus algorithm will Astria run?
01:05:29.520 - 01:05:56.084, Speaker A: Yep. So right now we're using tenorant. We haven't kind of made any, I guess, committed decision, but we do share some of the opinions of people at Zucky who are know, many people have tried to make a objectively better consensus algorithm than tendermint and deploy that and get adoption, and many people have failed. There are many, many chains running tendermint. It is well known, it is formally verified. It has been robustly tested. We're generally confident with it.
01:05:56.084 - 01:06:28.770, Speaker A: Again, it's easy to work with. So right now, we're building on tendermint. We've looked at some of the others, but it was still an open question of whether it's worth kind of the resourcing to kind of more thoroughly investigate one of these consensus algorithms that's either kind of done at a research level but not done at an engineering level, or whether it's useful going to some kind of fully not PBFT, so therefore not single slot finality consensus algorithm. But right now we're planning on using tendermint and we're doing kind of active investigation research internally on whether we want to kind of research or kind of like build on something else.
01:06:29.080 - 01:06:56.924, Speaker B: Yeah, I think that's a very practical approach. I mean, tendermint is kind of the gold standard. It's a safe bet. Although I do feel like certain things, people tend to complain about Tenderman's mempool and certain things that seem quite important to a shared sequencer. And I just wonder. I think there's a whole realm to explore, different consensus mechanisms with different trade offs. But yeah.
01:06:56.924 - 01:07:11.310, Speaker B: Which one of them are really production ready? I don't know. Maybe things like Bullshark and the things that the Sui and Aptos people have built. I don't know. Anyway, that's interesting and we'll definitely go ahead.
01:07:12.240 - 01:07:37.544, Speaker A: It's really great. When we say like tendermint, it's more like tendermint as the kind of finality gadget or whatever. Right? Like the tenderament structure, the work that Evan Forbes and others inside of Celestia have done to improve the men pool inside of tendermint on their own fork of. Right. You know, those are also things like we're looking at. So it's not saying we're just going to use bog standard tendermint, not change anything, but we think this kind of like tendermint ecosystem, I guess more correctly we're supposed to call it like comet BFT now.
01:07:37.582 - 01:07:38.170, Speaker B: Yeah.
01:07:38.780 - 01:07:51.470, Speaker A: A very strong candidate for the optimal kind of like, maybe not optimal, but it's good enough. And you're not going to necessarily dramatically ten x improve your product by using something else. And you might ten x the amount of work you have to do.
01:07:51.920 - 01:08:08.640, Speaker B: Yeah, I think Bucky, whenever he hears tendermint is like inside, I don't know, cringing. He's like, comment, bft. Anyway, all right, two more questions. Will astria improve cross roll up composability?
01:08:10.660 - 01:08:32.916, Speaker A: Yeah, so we think it will. And again, this is like a useful diagram to have, right. If you see multiple roll ups submitting transactions to a shared mem pool, and then they get put in the same block. Right. There is a guarantee over the inclusion of those transactions and they're ordering kind of like relative to each other. Right. So you can guarantee that these roll ups are, say they're going to pull the same block from the shared sequencer.
01:08:32.916 - 01:09:25.800, Speaker A: They're going to pull their subset of that block that is their transaction, they're going to execute it. So we do think there's kind of inclusion guarantees around that that allow you to do some interesting kind of atomic things. And I was going to go over three things. But what we want to be pretty explicit about is this isn't like some holy grail of you're going to be able to do a lock mint burn three stage bridge in a single block, because fundamentally you can't guarantee that a given roll up executed the block on the other side so strictly you could do it. We don't believe it's not strictly safe to do. So whether people do it or not is like over the air. Because you could say, do a lock mint burn and then let's say the mint transaction on roll up b is just reverted or whatever for visibility that your roll up doesn't have into another roll up, well, you just disappeared some amount of tokens into the ether.
01:09:25.800 - 01:09:37.564, Speaker A: Whether or not people get degenerate enough to just Yolo that and say, hey, we're willing to kind of risk that on like a bridge, that's up to them. But we do think there are some general improvements in that space here.
01:09:37.762 - 01:09:45.216, Speaker B: Yeah, modulism, not maximalism. People can build whatever they want, take whatever risk they want. But yeah, I think in general, that.
01:09:45.238 - 01:09:46.610, Speaker A: Sketchiest bridge you want to build.
01:09:48.180 - 01:10:37.216, Speaker B: Yeah. Well, I think that's one of the things that people are really hyped up about for shared sequencers. And I think that's one of the things that will cause maybe a network effect is like, hey, if you share the same shared sequencer network with another roll up, you can have this improved composability. And I think that's going to be something that will be a big part of this last question. Will asture give rollups the ability to capture their own? You know, we've had you on with the skip team on a modular mev episode, and people haven't listened to that. I encourage them to. And a big topic there was sovereign mev, which is this idea that sovereign chains should have the ability to capture and internalize Mev that they generate and then redistribute that to whoever they think deserves it.
01:10:37.216 - 01:10:54.330, Speaker B: Like spend that money, treat that as protocol revenue. In a sense. I think that's another really big incentive for people, for example, to build a roll up in the first place, or an app chain, rather than just deploy a smart contract. And so I'm curious if you guys are thinking about that.
01:10:55.500 - 01:11:16.376, Speaker A: Yeah, so this is not like a 32nd question. Definitely not question or more. I just will say there's like a personal opinion and then there's where we land up. Right. My personal opinion is that token governance is like a bad thing. And so kind of, when I'm asked this question, when I discussed this question, my question is, when they say pay the roll up, who is the roll up? Right. To some degree.
01:11:16.376 - 01:11:57.604, Speaker A: Right. You have this decentralized network that needs civil resistance, that needs a token that does production, that is like a thing that is paid. Why do you want some external kind of like, I'm going to say like state, and I don't mean state in, it's a state, DB. I mean why do you want a separate governance actors that are extracting taxes on your transaction throughput you as a user, why do you want to be tied to one roll up versus you want to pay the market rate for using a roll up and you don't necessarily want to bump back to the kind of proposer thing. Right. There's like this balance between the governance of a roll up and the users of a roll up. And I'm not sure the users want to have additional taxation that that's like a personal kind of anarchistic opinion that's somewhat spicy from a technical perspective.
01:11:57.604 - 01:12:43.816, Speaker A: There's some complexities of when you say we pay back roll ups, right? Again, there's like who is roll ups, right. If I'm saying I'm going to send $10 to the roll up, where am I literally sending those dollars? On what chain am I sending those $10? How is that executed? I think there's a lot of open questions here. We're not certainly opposed to it and there's no kind of structural limitation for that. But I have somewhat biased opinions on whether or not that is a desirable thing for end users. And one of our kind of views is that we want to reduce, again the effort to stand up a roll up such that we don't necessarily think that a roll up should be something that is able to extract a large amount of rent from users of those roll ups. Right now it's a lot of work to stand up a roll up if it comes. It's very little work to stand up a roll up.
01:12:43.816 - 01:13:13.972, Speaker A: Maybe those roll ups portion of kind of whatever transaction throughput that they're returning back to them is very, very minimal. And maybe we end up in, again an account abstraction style space similar to James Presswich's NeV wallet stuff, where actually the revenue is going back to the users who are actually submitting the transactions for it, rather than having this kind of taxation in the system that says hey, I'm a roll up and I'm just a bag of state with users on it and I'm going to extract rent again. So this is, but maybe would be, I guess the final answer here.
01:13:14.026 - 01:14:16.564, Speaker B: Yeah, this is such a longer conversation, but obviously I don't think anyone would agree that, oh, it's a better outcome if we actually extract rent from users kind of against their will. Because clearly incentives are just not aligned. But I think that there is part of sovereign MeV is saying, hey, this is the kind of MeV that is okay and not okay. So it's also potentially trying to protect the users in the first place. There's also a certain amount of MeV that is simply just kind of inherent to these systems and will be present no matter what. And it doesn't necessarily have to have negative externalities to users, although it may. But the point is, who should actually get that value? And I think that at least providing some mechanism to channel that value into certain ways intentionally, rather than just like letting it go to whoever, I don't know, wherever on the supply chain that it ends up, I think that's a very powerful idea.
01:14:16.564 - 01:14:32.268, Speaker B: So anyway, okay, now we're going to start sort of wrapping up here. I want to hear again quickly, what is the vision for Astria five years from now, if the project is successful? What is Astria in five mean?
01:14:32.274 - 01:15:27.288, Speaker A: That's like a very open question, a large question. I think there's many things that could be, but fundamentally what we want to see is we want to see an abundant number of roll ups. And really what we want to see is the blockchain industry. I'll use that broadly as a whole, move forward. Right. When I'm asked why blockchains, why is it a useful thing? I say, look, the base case you can explain to anyone is I'm like, what if you had a system that could do financial transactions at a cheaper rate than visa, and they were structured in such a way that they didn't want to take a 3% rate that visa and Mastercard take, they wanted to take a one and a half cent rate, right? And that all requires scaling, right? And so in the back of my mind, that's always the goal, right? Is get the throughput high enough, whether that has to be across 1000 chains, 10,000 chains, or whether we figure out how to do it on ten chains. I think we want to just get the throughput high enough that this system is valid such that we can remove kind of these rent extractive actors and cartels from the overall system of financial transactions.
01:15:27.288 - 01:16:25.724, Speaker A: What we see Astri kind of playing into that, right? Again, we really see this as providing these kind of hard to bootstrap or expensive to bootstrap resources to this module ecosystem, right? It's a two pillar. We have this settlement layer, this EVM based settlement layer that does a lot of the kind of BD legwork of providing token issuance stuff, bridging between other ecosystems, and just this settlement layer that can potentially do ibgs or if you want to do a non sovereign roll up on that, right? That's an option, while all being within the same data availability layer. Again, the other pillar being this kind of shared decentralized sequencing, where you can kind of buy decentralized sequencing as a service at like a market price. We all see this as driving many, many roll ups. And the thing that I think is really valuable out of that is going to kind of the cloud case. And my co founder Jordan had a good kind of post on this. We see there being more experimentation in applications.
01:16:25.724 - 01:17:29.428, Speaker A: And when I say applications that could either be smart contracts or that could know state machines themselves, if you reduce the barrier to entry, then you can have more experimentation. Whereas right now, if I want to launch a chain, it's a very large effort to stand up a chain and launch a new chain and get it decentralized. If you can say, hey, all I have to do to launch a chain is go take this open source software, change a few things I don't like about it, or I prefer to make it my custom thing, and then off the shelf, I can grab this data availability layer, this sequencing layer, this validity proof layer, and I don't have to build any of that. They have clearly defined interfaces, and I can tie in and I can use this based template. You can iterate much more rapidly because just the amount of people and human resources to launch a new roll up is reduced so much that now we can maybe move out of, okay, 90% of the chains are running on EVM. Okay, that's great. But there are a lot of known issues with the EVM, but it's very difficult to build a competitor to it because of just the bootstrapping cost to do so.
01:17:29.428 - 01:18:03.250, Speaker A: Ideally, we're seeing astria. I generally want to be kind of more pragmatic in my statement here, right. We've seen people like the base guy say we want like a billion users next year. That's just not going to happen, guys. But we just say we want to see a million roll ups and maybe in five years. Yeah, we do see like a million roll ups. I really want to see this kind of, to use an overused term, like a cambrian explosion of innovation in these state machines, driven by this kind of infrastructure being provided for them as a service, but in a decentralized way.
01:18:03.620 - 01:18:30.084, Speaker B: Absolutely. The analogy that I like to use is essentially what Ethereum did for decentralized applications. I think the modular stack will do for blockchains themselves. So Ethereum made it before when in the bitcoin sort of era, in order to launch a new d app. You had to build a new blockchain from scratch. All of a sudden Ethereum came along. You could deploy your application by just writing a few lines of code as a smart contract.
01:18:30.084 - 01:19:21.450, Speaker B: And then all of a sudden, what did that do? It lowered the barrier to entry. It made it so much faster to innovate. And what did you get? You got this cambrian explosion, like you said. You got DeFi, you got nfts, you got dows, you got all these use cases that we know and love today. And now I think we're doing the same thing. We're removing the barrier to entry, lowering the overhead cost at a layer even deeper in the stack, which is not just to write a smart contract and launch an application, but actually to launch your own blockchain to create a new execution environment to experiment with all these things that are just way more powerful, I think, and also will be way more scalable. So I could not agree more, and I hope that in five years, if we have a million roll ups in five, will I can die happy? I think so.
01:19:21.450 - 01:19:35.980, Speaker B: Last question is, where can people sort of like play around? Do you guys have anything sort of live? Is there a testnet or will there be a testnet soon? Where can people play around with stuff? And also where in general can people learn more and follow the progress of Astria?
01:19:37.120 - 01:19:59.472, Speaker A: Yeah, so we have a website. It's astria.org. Astria.org blog. Astria.org is where we have an introduction post that's probably the most thorough kind of like written summary of this. I also really reference people to John Sharbanau's wonderful, I don't know, really long blog post, but recently I had one called like roles aren't real that covers shared sequencing, that also goes into composability.
01:19:59.472 - 01:20:26.510, Speaker A: I'd highly recommend that if you'd want a summary on this from playing with our know coming out of Celestia, we really kind of carried over one of the things I really liked about Celestia, which is like from day one, our code is open source. I've never figured out or bothered to set up a business account on GitHub such that we have any private repositories. Right. We have no credit card with GitHub. All of our code is open source. It is one of MIT or Apache two licenses. If you find a code base that is not, please ping us.
01:20:26.510 - 01:21:09.096, Speaker A: Maybe don't harass our engineers too much, but we are working on getting something that is kind of runnable on a devs machine in some kind of like docker Kubernetes kind of cluster setup. We're hoping to have that done by an over promise here. But like end of this week, noting we're recording on April twelveth right now, so ideally April 14 we have something out or maybe next Monday. And then we hope to have something for kind of like a trusted partner kind of devnet, testnet, whatever you want to call it, available in coming weeks if things go really well. Maybe it's two weeks, maybe it's three weeks. So it's not quite like here's a public RPC yet, but we are very close to having something that we're comfortable kind of sharing publicly. And again, our code is all open source.
01:21:09.096 - 01:21:26.144, Speaker A: You can go to GitHub.com, astria.org, just all one word, astria.org. Poke at our code. Again, please be respectful of the engineers and don't harass them a bunch. But we as open source, we welcome contributions. And if you want to go poke at it, you can go look in the repos there.
01:21:26.342 - 01:21:59.390, Speaker B: Cool. And I'm glad you guys are building open source. And for people who don't know, Mustafa is a diehard open source person, obviously from his hacktivism days and even things like he basically refuses to use almost anything that's not open source, including he doesn't use Microsoft office, he uses libreoffice and stuff like that. And anyway, it cracks me up. I'm glad that you guys are carrying that on. Just the last thing before we go off. You guys are hiring, right? Are there any open roles you guys are seeking to fill?
01:22:00.640 - 01:22:26.672, Speaker A: Yeah. So right now our team is nine people we are hiring for. I guess the key roles would be we're looking for Debra on solutions engineers people. We are always kind of looking for good software engineers. We don't feel like we absolutely need a bunch more right now, but we are really always happy to kind of accept kind of inbound interest and go through that. And we will reach out to people if we think they're really strong fit for this position. Our code base is primarily rust.
01:22:26.672 - 01:23:05.810, Speaker A: We do have a bit of go basing that we're like tendermint. We have some cosmos stuff in there. We're also looking for solidity people on this kind of solutions engineer front and just giving us some kind of solidity expertise inside the, we're also looking for a chief of staff, kind of head of operations role. And generally, if you think this is a project really exciting to you, we welcome kind of like inbound interest you can reach us at contact@astria.org or reach out to us on. That's like the best way to reach out. We also have on our website there is like a jobs page on, you know, send inbound interest there.
01:23:05.810 - 01:23:20.244, Speaker A: Follow us on Twitter, twitter.com slash astria.org. Again, all one word. I'm Josh Bowen. I'm under jsky Bowen on Twitter. So reach out if you're interested. We're always happy to kind of chat with people.
01:23:20.442 - 01:23:47.216, Speaker B: Cool. Well, there you have it, guys. You're hearing from the man himself, Josh Bowen, about the future of decentralized sequencers at astria. And we're definitely going to be following this closely. And I hope you guys end up listening to a bunch of other interviews. I'm sure Josh is doing the tour right now, and there's a lot to absorb in this vision, I think feel like we only scratched the surface. I wish we had more time.
01:23:47.216 - 01:23:51.410, Speaker B: But thank you, Josh, for coming on, and we'll see you soon.
01:23:52.340 - 01:23:53.950, Speaker A: Yeah, thanks, Nick. Thanks for taking the time.

00:00:03.060 - 00:01:07.100, Speaker A: All right, so the title of my talk today is scaling data reach applications on Ethereum with axiom. And the starting point of this is the realization that if you're writing smart contracts today on Ethereum, or really on any blockchain vm, you're really operating in a very data starved environment. If you look at the listing for this Q Penguin on OpenSea, and you try to identify, of all the pieces of on chain data on the page, what can actually be used on chain, you'll find that the answer is only the owner, namely Zach Efron. All the other rich information on the page, like the transaction history, the historical prices, and all that good stuff that Opensea users get to see, is simply not available to your smart contract. And this is not just an implementation flaw of Ethereum. Any blockchain that wants to be decentralized can't impose the requirement that validating nodes can access history. Otherwise, that would require all full nodes to become archived nodes.
00:01:07.100 - 00:02:22.096, Speaker A: Now, of course, developers are very creative, and they work around this in many ways. Today they have this tradeoff between putting more data in state and paying for that, or by reducing the security somewhat and relying on trusted oracles, which in many cases is a fancy way of saying that the team itself puts the relevant data on chain in a fully trusted way. And so developers who want to scale data access on chain today really have to trade off between increasing their cost or reducing the security of their application. So at axiom, we're thinking about whether we can scale data rich on chain applications. Now, on blockchains, we have a special tool, namely, in any blockchain, the current block always commits to the full history of the chain. And that means we can use cryptography instead of consensus to access on chain history. So how does this work? On Ethereum, the current block is linked to all pass blocks by a ketchek chain of block headers.
00:02:22.096 - 00:03:15.952, Speaker A: And of course, every pass block commits to all the information in that block, namely the state of Ethereum at that block, as well as all transactions and receipts. The problem, though, is that if you try to decommit all the way back to a million blocks ago in Ethereum, that's going to be prohibitively expensive. You can never do that in the EVM. So what we realized at Axiom is that we can shove all of these verifications into ZK. We can check a Merkel Patricia triproof, as well as a chain of blockheader hashes, and make that feasible to verify on chain. This has a couple side advantages of providing scale in accessing the historic data and composition. So what we've packaged that into is something we're calling a ZK coprocessor.
00:03:15.952 - 00:04:21.290, Speaker A: For Ethereum, smart contracts can query axiom on chain to do a combination of historic data reads and verified compute. Over that data, we generate the result off chain and also provide a zero knowledge proof that everything we computed was valid. Once we verify that proof on chain, you can use that result in your smart contract however you like. And because of the zero knowledge proof, every result that we return from Axiom has security that's cryptographically equivalent to something you're accessing on chain in Ethereum itself. So let me talk through what the two components of axiom give you. The first component, reading arbitrary historic on chain data means that you can scale your application while interoperating with existing applications that are already on the chain. Unlike something like a rollup, you don't have to move your state or really do anything to access more data.
00:04:21.290 - 00:05:06.590, Speaker A: On the compute side, we envision supporting computations that really cannot fit in any blockchain VM, either today or in the future. You might imagine running some sort of local neural network inference that's never going to happen on a timeshared global computer. And so I've told you what our ZK coprocessor is, and I now want to talk about what it can enable. So I've drawn a rough graph. On the x axis is the amount of data you're accessing, and on the y axis is the amount of compute you're using to process that data. Obviously they're correlated. If you have a lot of data, you're going to use more compute.
00:05:06.590 - 00:06:13.170, Speaker A: So in the beginning, we think that ZK coprocessing will make the devex for certain operations that are already possible, but at great cost. In the EVM much simpler. This will be things like computing a trustless volatility, Oracle verifying a user's account age, or simply computing a consensus level randomness. But where I think it really gets exciting is when the data and the compute both get ratcheted up. You might imagine accessing fully, trustlessly, the historic balance of any ERC 20 token at any historic block. Or if you're running and designing an onchain protocol, you could define objective slashing conditions over the entire history of your protocol participants that cause them to be punished or rewarded. And once CKML gets sufficiently fine grained, you can imagine adjusting your parameters of a DeFi protocol based on machine learning algorithms applied to the historic data on chain.
00:06:13.170 - 00:07:10.790, Speaker A: In this way, we think you can bridge the gap between traditional web two applications that take in vast streams of data and process it to the current trustless onchain applications that are data starved. So let me walk through what the state of Zkcoprocessing is today. So we just went live on mainnet with trustless access to any historic blockheader account or contract storage variable. Two weeks ago and this week at ECC, we've launched transactions and receipts to Testnet. So in this way, we allow smart contracts to access any piece of execution layer data on chain. Today, to decompute over that data, we offer the ability to write custom ZK circuits to come to a result for a developer. All of that can be verified on chain fully, trustlessly.
00:07:10.790 - 00:07:51.230, Speaker A: Now, what does that mean for your actual application? I'm going to walk through a few examples in a very concrete way. Suppose you want to access a user's account age. What you can do is trustlessly read the historic nonce of their account at two different blocks. Then you compute the first block that has a nonzero nonce, and deposit the age of their account on chain. We have this running live in a demo on our website today. Suppose you want to enhance your governance. In traditional corporate governance, there's a very complex governance structure.
00:07:51.230 - 00:08:38.500, Speaker A: It's not just one stock, one vote. Most governance today is simply one token, one vote. And I think the reason for that is it's very hard for governance to actually know any other information about the participants. To have a more complex voting weight scheme with Axiom, all you need to do is trustlessly read the history of your users voting. By looking at the on chain events. Then you can compute derived quantities, like the number of times someone has voted, their voter participation, or even things involving when they vote, and how reliably they vote. You can then compute the custom voting weight using that, and really tailor your governance to incentivize whatever you'd like.
00:08:38.500 - 00:09:41.720, Speaker A: In DeFi, you might imagine adjusting fees for historic participation in standard exchanges like Binance and Nasdaq. Obviously, if you're a higher volume trader, you get a fee rebate. In DeFi today, everyone gets the same fee, and we think that kind of violates the fundamental law of economics. The only reason it hasn't happened yet on chain is that amms actually can't know how much their users have traded. To implement that with axiom, all you need to do is trustlessly read the trade events of your users on chain, add them up, and then apply the appropriate discount to fees. So all of the applications I just talked through are possible today on Mainnet with Axiom, but I want to talk through where we're going. So we started by giving smart contracts access to the execution layer data, and we think ultimately they want access to all data.
00:09:41.720 - 00:10:56.670, Speaker A: Once Cancun lands in September, we'll be able to access consensus relatable data on Ethereum, and perhaps through bridges like succinct, we can access data from other blockchains and roll ups. After that, we think developers want to process the data they're getting in the most native format possible. For Ethereum, that's going to be simulating the result of view functions through ZKevM proofs. Once we're able to do these first two steps, we'll essentially have a ZK version of an archive node or indexer, which caches these values and returns them to smart contracts with lower latencies. Finally, we think developers will want to use different forms of computation that exceed the balance of blockchain vms, and we think the best way to provide that will be through a ZK native vm. So we've started on the first piece of this roadmap and shipped it to mainnet two weeks ago, and we're excited to continue over the next months and years. If you want to try out axiom today, you can check out our developer Docs at Docs Axiom XYZ.
00:10:56.670 - 00:11:52.782, Speaker A: In my remaining time I want to talk a bit more meta level about the usage of ZK in blockchain applications. I think a lot of developers today are very excited about ZK as a concept and technology. To be frank, they don't really know too much about it. And this week I've been talking to developers about using ZK, and they view it either as a black box, which either they like or are very afraid about. And so at axiom we started something we're calling the open source program to educate developers about how they can develop ZK circuits and what ZK can do for their applications. So in the first round of our program, we had a number of community written open source circuits for things like fixed point arithmetic, ED 25519, signature verification, and BLS signature verification. So we're opening up the second round of applications next week.
00:11:52.782 - 00:12:03.580, Speaker A: You can go to the URL above to apply, and we'd love to see what you can build using ZK. Thanks so much guys. Thank.

00:00:02.320 - 00:00:45.550, Speaker A: Okay, before I start my talk, how many of you have written a ZK circuit? Okay, great. And how many of you have written solidity? Great, great. Let's start the talk. Today I'm going to show you nibra UPA. The way we view it is that we think this is a ZK broadband that unlocks scaling, privacy and interoperability. So this is a talk outline. So first I will tell you what is UPA, which is a universal proof aggregator.
00:00:45.550 - 00:01:53.610, Speaker A: First I will motivate a little bit why we need this and what is UPA. And it's becoming obvious why UPA is good for both privacy and scaling. And next I'm going to show you a little bit more about why UPA is also important for interoperability. So first, why UPA? So this is a ZK supply chain at the current stage of blockchain industry. So from the high level you can think of there is a user and user will provide some sort of data to the prover and then the prover will generate the proof and the proof is getting verified. So this is a very simplistic picture of the ZK supply chain. And of course the most suitable place to deploy a ZKP verifier is on chain because blockchain is kind of like a public permissionless censorship resistance ledger can give you the truth.
00:01:53.610 - 00:03:05.870, Speaker A: So and then for there are two kind of ZKP application scheme. The first is privacy preserving applications, for example like private on chain voting, privacy token transfer, for example like a tornado cache, or privacy preserving decentralized identities such as word coin. So in this privacy preserving applications, the user generated proof on the client side for privacy reasons. And then basically both the user and prover have to be on the same side or same devices. It could be in your browser, it could be in your phone, and then the user or the client sends the proof to the verifier. So the second kind of solution is the scaling solutions where the user still provides the data, but the prover is run on some beefy machines in Amazon or whatever cloud providers. And then the proof is getting verified on chain.
00:03:05.870 - 00:04:00.900, Speaker A: So you can see in both scenarios the common interfaces is this like a verifier interface where the proof is standing on chain and it's getting verified on blockchain, let's say ethereum. So that's why we're building UPA. So in our view we think proofs is going to be the future of all the blockchains. And then it's crucial to scale the proof processing power of all blockchains we want to upgrade the blockchains from a narrow band ZK to a broadband ZK. To precisely state the problem. You can see verification cost is one of the biggest remaining problems of having more and more proofs. So this is a cost in terms of dollars.
00:04:00.900 - 00:04:49.952, Speaker A: Verify a single proof on chain. For example, today verify a gross 16 proof cost more than $20 and verify halo two KZG proof costs more than $30. And if you want to verify a stark proof, it will cost you hopping more than $100. So clearly this is not the future we want to live in. Like Vitalik used to ask this question, do you want to pay $20 to add privacy for your transaction of buying a coffee? And clearly not, right, because the coffee itself in most places is not worth more than $20. So that's why we're building UPA. So what is UPA? So UPA stands for universal proof aggregator.
00:04:49.952 - 00:05:33.260, Speaker A: And there are three keywords, right? Universal means these proofs are coming from different circuits. So for example, proof can come from Zkevm like SQL polygon, or it could come from coprocessors like Lagrange, where Ishmael just show you before show you before this talk. Or it can come from a privacy preserving application such as wordcoin. We don't care. So NibaR UPA can aggregate all this proof to a single aggregated proof. And this single aggregated proof is a recursive ZKP proof. Basically states that all these previous proofs in these batches, in this current batch are validated.
00:05:33.260 - 00:06:24.630, Speaker A: So now instead of putting all these different proof on chain, you just need to prove the single aggregated proof on chain. So all the cost is getting amortized. And essentially we're building a shared economy of proof processing without hurting decentralization. So if you think about that, basically the more proof, the better economy, because the more proof you can put a single batch, the better cost you can get. So this is a high level overview and the properties of the protocol. First, UPA protocol is deployed on chain, which means the UPA will be deployed on Ethereum, Mainnet and all the major l two s. So this is a permissionless protocol.
00:06:24.630 - 00:07:13.980, Speaker A: The sole interface developer or users need to interact with us is a smart contract. So in the sense that you don't need to sign a contract with us, we are permissionless, can aggregate all the proof you want. And second, is the censorship resistant in the sense that we have a force inclusion mechanism. So in the sense that we cannot censor you even if we want to. Last but not least is going to be progressively decentralizable in the sense that there will be a permissionless way of running the provers so that you can have even better liveness and censorship resistance guarantee. So next, using Nibar Upa is extremely simple. So on the left hand side is how do you verify a proof today on Ethereum and all the other blockchains.
00:07:13.980 - 00:08:05.912, Speaker A: So you have proof generation or ZKP client, and this ZKP application client could be for example raw as well. You deploy your own verifier contract on chain and then you send the proof to your own verifier contract. And using Nibra is almost the same. The only difference here is that you are not using your own verifier contract, you are sending your proof to Nibra UPA. So we actually tried to give the UPA documentation to many, many users. Most of users finish their protocol integration within two days with very, very minimal code changes. So we launched Nebar UPA on Testnet about three months ago on Sepolia.
00:08:05.912 - 00:08:42.430, Speaker A: So the high level overview of the UPA 1.0 here is that it uses a two plus layers of recursion using halo two KZG. And we actually have built a pipeline and distributed prover serving architecture to harness the power of this ZKPD. So this is the underlying distributed system work. So UPA has a two layer of aggregation circuit. The first layer we call the UBV. Basically it's a universal batch verification circuit and a pair with a cachex circuit which used to handle public input.
00:08:42.430 - 00:09:38.510, Speaker A: And then both the UBA and cache proof is aggregated by the aggregation circuit. And this aggregation circuit will produce a final halo two KZG proof and going to put it on chair. So here, basically we are leveraging the parallelization here to improve the latency of the recursive proof generation. So the way we do that is that every single circuit you see in this picture is placed in a GPU machine. And so all these GPU machines are working in parallel in a pipeline way to generate proof so that the latency of generating proof is minimized. So in addition to that we have a pipeline server server farm to overlap in the prover proving over batches. For example, when the first batch comes, our coordinator will spawn the prover cluster one.
00:09:38.510 - 00:10:33.630, Speaker A: Well this prover cluster one is still working. If at that time the batch two comes, the coordinator will spawn a proverb cluster too. So by overlapping the different batches we can get the maximum throughput as well. So I'll just highlight a few challenges while building Nibro UPA. So the first and foremost is ZKP engineering. So one of the challenging places here is that how can we build a non native arithmetics? So basically, if you're doing recursive proving, you are having this disparity between the data sizes of the proof of your input and proof you are programming in the circuit. So for example, there is a disparity between the financial sizes, and this is causes like 20 x blow up in terms of circle sizes.
00:10:33.630 - 00:11:14.882, Speaker A: And we have many hard works in terms of the, we call it like a mathematical hacking. Basically we leverage all these advanced mathematics, including chinese remainder theorem, like Montgomery letters, all these fancy mathematics to build the most performance non native arithmetic circuit. And second is how do we handle heterogeneous proofs. So for example, in Nibar UPA 1.0, we are supporting three major versions of gross 18 proofs with arbitrary size of the public input. And in Nibara UPA 2.0, we will be supporting all the major proof systems incoming.
00:11:14.882 - 00:12:16.260, Speaker A: So for us, it's not just about supporting proof systems, it's also about economy. Because the more wider variety of the proof system we're support, the more proof we can aggregate as well. And also we are deeply careful about how do our system in terms of are we actually using a circuit or we are using a ZKVM. So the short answer here is that circuit is more performance and the VM is more versatile. So in our first generation, we are using a circuit first approach, because our observation is that more than 70% of the proof on chain today is just a gross team proof. So this is the majority of the amount of users we want to support. And we're moving to a VM based architecture, which means we're actually using both ZkVM and precompiles, so that we can achieve best of both world in the sense that it's both flexible and performant.
00:12:16.260 - 00:13:36.920, Speaker A: So clearly, basically for building NibAR UPA, our value proposition here is that because we can make ZKP proof ten times and more cheaper, this is a huge unlock for the entire ZK industry, in the sense that for both privacy and scaling applications, you will be much, much cheaper to use. So for example, for privacy preserving applications, lower the cost of their ZKP proof from dollar 20 to dollar two on ethereum layer one, and from $2 to 20 cent on all the major l two s is a huge unlock, so you can acquire your users much more cost efficient. And for the infrastructures, for example, if you are running a ZK based app chain. You are actually paying about 15k proof 15k for proof verification per month every month. And we can down the cost to one five k. So next I'm going to talk a little bit about the UPA for interoperability. The whole idea here is that we can use proof aggregation to bring native inter probability to rops.
00:13:36.920 - 00:14:18.650, Speaker A: The idea here is that by using proof aggregation we can make the crossroad transaction the first class citizen and to be part of a settlement. So for example, this is a high level architecture of how NibRA can bring the native interoperability to all the robots. So this is a new development we're building. We call it Nibra Os. So we kind of like locate Landsat in our own event proof day about two weeks ago. Sorry about two days ago, but we will have more information disclosed in incoming. So the whole idea here is that first you can make crosswalk transactions.
00:14:18.650 - 00:15:32.816, Speaker A: Basically you can think of as the transaction bundles as a first class citizen and then users don't send these transaction bundles directly to the RoP, you can send to the coordination module. And the coordination module will basically ask all the Rob sequencers to say, hey, are you going to promise to include this crossroad transactions in the next epoch if everyone said yes? So there is a safety module to generate the inclusion proofs for these transactions. So basically during the settlement of this Rop state route, the proof aggregation module is going to aggregate both the validity proof from all the different rops together with this like a meta transaction inclusion proof. So basically this proof aggregation module can hold all this roab as hostage. So that making sure the if they committed to include this cross rop transactions in the next epoch, they have to. Otherwise their stateroom is not getting settled. And in the future we can put more fancy type of intent safety proofs as part of a proof aggregation.
00:15:32.816 - 00:16:21.542, Speaker A: So for example, let's say if you not just want to do a cross drop swap of your asset, you want to have a price guarantee. For example, you want to swap this arbitrum op token with this arb token at a certain price guarantees. So we can do that natively in the settlement layer so that you can have safety guarantees without relying for example, all this cross chain liquidity providers. And so this is a high level picture of how does proof aggregation can enable interoperability. So here is my claim. I do think native interoperability is an ecosystem wide analog. So here, this is a list of the advantages we can have if you have native interoperability.
00:16:21.542 - 00:17:21.445, Speaker A: First it will fix the secure leakage of crossroad transactions. So it's actually well known today, despite from the l one to l two transactions on Rob is secure all the cross rop transactions. Because we don't have proof aggregation, it still requires unsafe cross chain bridges with liquidity providers. And here most of the times the liquidity providers are taking the risk of the settlement. So for example, despite optimistic draw up takes seven days for settlement. So as a normal user, you can do your cross chain transaction very quickly, because all this risk is taken by all these liquidity providers. But in some sense there is no free lunch here because these liquidity providers taking the risk, all this risk is priced in with your cross drop transaction cost.
00:17:21.445 - 00:18:12.272, Speaker A: So now basically we are saying if you have native interoperability, these security costs will be much, much cheaper for your crossroad transactions. And second, like I said before, you could have enforceable cross rob intent, which means for all these crosswalk transactions you can have native interoperability. And also you can have intense safety guarantee, which means you can have user express their preferences of how this transaction getting done. And we as a proof aggregation settlement layer can enforce that. Last is that it will actually provide better developer experiences for both chain abstraction and wallet builders. And like I said before, it will actually provide better capital efficiency for crosswalk market makers. And also as a result.
00:18:12.272 - 00:19:15.000, Speaker A: So today, if you are building a new app chain, you have a huge amount of burden of bootstrap equalities. And now because you can frictionlessly tapping the cross chain liquidity by having native interoperability, it will actually give you less liquidity requirement to start a new chain. And next, we do think it can enable new use cases, for example like a pure asset chance or a pure DAC chance like a uni chain to fix up abstraction leakage. So in general, we think native interoperability means lower user friction and better ux in general. So I would like to conclude my talk here. So like to conclude, basically I show you what we're building Nivar UPA. And how can we use Nivar UPA to bring like to lower the cost and then to enable better privacy, scalability and native interoperability.
00:19:15.000 - 00:19:39.700, Speaker A: And so we are doing, we are building sniper os this native interoperability for all the ethereum based ZK ropse. If you want to get a white paper scan my telegram, I'm happy to give you the preview of the white paper before we publish it. And with that, thank a lot. That's end of my talk. Yeah, thank you.

00:00:00.970 - 00:00:41.452, Speaker A: Hello everyone. I'm ismay Kofi, co founder and CTO of Celestia. I'm going to talk a little bit about the architecture of Celestia, how it currently is, and give like a glimpse into the future. Whoop. They're not mine. How do I fix this? Okay, first so on the agenda, I wanted to talk like two parts. The first part is I'm going to recap the Celestia architecture.
00:00:41.452 - 00:02:15.612, Speaker A: And in the second part, as I said, I'm going to talk a little bit about future directions. So it's not like a full fledged roadmap, but what could be on the roadmap next year or so. Okay, so first of all, what is Celestia? I think most of you know, but for those who don't know, I going to explain it from a high level, but also how it's implemented roughly. So Celestia is like the first modular blockchain network, and what it does is it decouples consensus from execution. So what does this mean? So in classical monolithic blockchains, usually how every chain works is a client verifies two things, right? It verifies that the header has consensus, and it also verifies that all the transactions are valid, right? Like, it executes the transactions, makes sure the state transitions are valid, and then in Celestia, though, it only verifies if the transactions are available, it still validates that the header has consensus, right? But it doesn't execute the transactions. It doesn't validate that what is posted on chain is actually valid. It just ensures that these messages that have been posted on chain are available, right? They are OPAC blobs to Celestia.
00:02:15.612 - 00:03:37.560, Speaker A: Like, every application can post their blob onto Celestia, their message. And it's just in short that these are ordered, there's consensus on the order, and then everyone can verify themselves that these transactions are available. So that's the main differentiator. I'm going to explain a little bit on how this works as well. You might ask, where does the execution happen? And the execution in Celestia happens in so called roll ups, right? Instead of this world computer model where all the transactions are validated on one chain, the state transitions are validated on a roll up. And you might ask how does that work in practice? The Light clients, for instance, to validate that a header contains only valid state transitions, there's two approaches to this, which is like via fraud or validity proofs, right? In the ethereum world, these fraud or validity proofs are posted on ethereum, or they're settled on ethereum. But in celestial, as there is no execution layer whatsoever on the main layer.
00:03:37.560 - 00:05:23.820, Speaker A: These can be on a different layer, like on a settlement layer, or they could be on the peer to peer layer. I just wanted to stretch this as many people still perceive roll ups as enshrined with an enshrined settlement layer, like on ethereum. So now that we covered how execution works, how the main chain works, I wanted to mention the four guiding principles with which we designed Celestia or goals that we wanted to achieve. So it should be possible that a block is deemed valid only by checking block availability, right? Which means you can verify a header as a light node without having to download the transactions just by verifying the availability. The second principle is application message partitioning, which means every application only has to download their data, right? Like they don't have to download all the transaction data of all applications, only the transactions that are necessary for their application. And then there's application message retrieval completeness, which is the same thing, which means that they can verify that all the application messages they downloaded, all of them and nothing is missing. And there's also application state sovereignty, which means that all they need to care about is their state transitions and basically their state portion.
00:05:23.820 - 00:06:28.124, Speaker A: And they don't have to execute other transactions of other applications unless there's a direct dependency. So next I want to talk about how is this achieved roughly, I don't want to go too much into detail, but there's mainly three key ingredients here in play. One is erasure coding of block data. Another one is a namespace merkel tree and Data availability sampling. So let's dive a little bit in erasure coding is a technique that is very well known, which is basically used in CDs where you can recover data. So you add parity data and you can recover data even if parts of the data are missing, right? So how this works in Celestia is the data is encoded in a certain way, arranged in a certain way. The original block data is split into equally sized chunks.
00:06:28.124 - 00:07:26.244, Speaker A: And then you add this erasure coding in this square construction that is depicted here, the details do not matter. What matter is that this enables basically that you can with a portion of the data, can always recover the whole data. So here we also commit, when validators create a block. They also commit to the erasure coded block and not to the original data only as it is with other chains. And so every row or column here basically forms a mercury and these mercuries get committed to in a bigger overarching mercury. And that mercury is not like a simple traditional mercury. It is very similar though.
00:07:26.244 - 00:08:45.150, Speaker A: The main difference is that a namespaced mercury is used which sorts the data according to their namespace. Like each application can have their own namespace and the data gets posted on Celestia gets prefixed with a namespace, right? Like it gets sorted. And this is the data structure that ensures the property that I mentioned earlier. You can only download your portion of the data, your namespace, and you get like a complete guarantee of that as well. So the third and most important ingredient that makes it possible for Celestia to ensure availability is data availability Sampling, right? So as I mentioned before, the block is erasure coded here, depicted slightly differently. And then light nodes or nodes or clients can download only a small portion, like 1% of the data due to that erasure coding, to guarantee almost 100% certainty that the data is available. Yeah, and so, from a very high level perspective, this is how we built the system.
00:08:45.150 - 00:09:30.750, Speaker A: We took tenement, right? And we modified Comet BFT called today. So Comet BFT, previously Tenement, we took that, modified it, and we added basically the data commitment that I mentioned earlier. We also used the namespace Merkel tree for that data. And the third component that I mentioned, the data availability sampling, is done in a different layer, in a different peer to peer network. We call the DA networks, heavily reliant on bitswap and lipidop. Huge shout out to the node team that built this. No one has built this before.
00:09:30.750 - 00:10:39.824, Speaker A: It's a huge effort. And yeah, that's a high level architecture overview. So let's go to the more interesting part, which is what are future directions for Celestia? How could a future roadmap look like? Or at least what could be some highlights here. So I mentioned this erasure coding, right? This is required for roll ups to ensure safety, right? Like in the sense that you have to be sure that the data that has published has not been tampered with. Like there's no validator that is like committing to garbage, essentially, or something else, or some invalid data. So how do we ensure this? Currently we have a fraud proof type that is called bad encoding fraud proof that every node can generate that downloads either the whole block or even a row, or like several rows are sufficient. They can verify that the data matches the data route and can generate a fraud proof.
00:10:39.824 - 00:11:34.160, Speaker A: If that's not the case, that has the downside that theoretically light nodes need to have to wait for such bad encoding fraud proofs to not happen to ensure full finality of the block. Right. An alternative approach is to use KCG commitments. I think if you saw avails talk yesterday, that's a technique they employ which gets rid of the bad encoding fraud proofs. The question is, can we do better than this? I think we can. So with an alternative approach here is to use a ZK proof of the erasure, to use a ZK proof that proves to you that the erasure coding and the construction of the data route was done correctly. So you can still compute quickly, like the data route as before, and send around a proof if necessary if you require finality.
00:11:34.160 - 00:12:35.092, Speaker A: Right? So that's a research direction. If anyone is into ZK proofs, this is something you could look at. I will later share a research forum link and the GitHub link. Another direction or another topic that we certainly will look at after launch is a trust minimized bridge, or like a two way bridge from and to Celestia. So currently, if you wanted to use the base layer Celestia token in your roll up as a gas token, you have to use other bridges and to use other chains or third parties to get the token out and in to your roll up and back. Right. Ideally, the UX of this would be more seamlessly such that developers can use the Tia token directly.
00:12:35.092 - 00:13:13.220, Speaker A: So one naive way to do this, one way to achieve this is you could enshrine a general purpose execution environment onto Celestia that acts as a bridge. Right. That has the problem that it wouldn't be really neutral in the sense that you have to choose an execution environment. And also you'd basically reintroduce. Yeah. Like you would tamper with the original vision, which is like having only data availability and consensus. It turns out that you can do this without enshrining an execution environment.
00:13:13.220 - 00:14:15.450, Speaker A: Mustafa came up with this idea where you basically leverage that ZK snark verification is more or less looks very similar to cryptographic signature verification. Right. You also have a public key. And from that, if you look at how ZK snarks work from the public key, it basically looks the same. So the user flow for how this would look like roughly from a high level, is that a user would send a deposit of Tia to a verification key address. That's like a key address, like a public key or an address owned by, like, a ZK program. So you deposit Tia to there, it gets escrowed or burned, the transaction gets confirmed, and then the Tia would get credited on the roll up.
00:14:15.450 - 00:14:57.648, Speaker A: And so you moved Tia into your roll up seamlessly. So this roll up would need to track the state of that verification tier. So the more interesting part is, like, how do you bridge back? You would send tier a withdrawal transaction of your tier in the roll up. Right. If the transaction gets confirmed by the state machine on the rollup, you generate a ZK proof. And that ZK proof kind of simulates or acts like a signature on the verification key address on Celestia. So that would trigger the withdrawal of TL.
00:14:57.648 - 00:15:25.870, Speaker A: That's very high level. The devil is in the detail. There's a lot of choices to made here, John would say. A lot of implementation details. And indeed, yeah. Another hot topic is how to fix mev, or rather how to apply current state of the art mev research and techniques to the modular stack. Right.
00:15:25.870 - 00:16:14.108, Speaker A: There are several teams working on this. I think Skip and Flashbots are the most noteworthy here. The the specialty, or like the difference here is that mev can trickle from the roll up into the base layer. Like, the base layer validators could delay or even sensor batches from the rollups. Right. So the question really is how do we apply solutions to mev to more modular stack, especially given that there's like a very heterogeneous application layer. I think Evan's Talk will cover this in greater detail.
00:16:14.108 - 00:16:49.924, Speaker A: Don't miss it. It's like this afternoon, he will speak about how to break the proposal monopoly. Don't miss that talk. So this is like the long term goal here that we want to achieve is 1GB blocks, 1 million roll ups and 1 billion light nodes. So often when we mention this to people, it's like 1GB blocks. That sounds insane, right? And it kind of does. But we won't achieve this immediately anyways.
00:16:49.924 - 00:17:38.356, Speaker A: It will be on demand. But we do believe that this is like as it becomes necessary, we will tackle this. And the question really is how? I think we are very confident that we can go to 100 or something very quickly. But to actually get closer to that 1GB blocks goal, we will have to optimize commit BFT's peer to peer layer. Right? Like the Mempool is not made for super large Blobs and the consensus reactor, like the gossiping mechanism, is also not made for that. There's a lot of low hanging fruits and optimizations that we will do. One of them is already started, which is like the content address pool, cat pool.
00:17:38.356 - 00:18:20.336, Speaker A: Callum implemented this already. Similar, the node peer to peer layer needs a lot of improvements to achieve this. Mainly block sync and Dasync. There's a lot of optimizations to be done, mostly very implementation specific. It might turn out that in the future, in several years, we have to merge the DA layer and the consensus layer again, architecturally from a software perspective. And we will might have to employ a technique called internal node sharding to achieve the throughput on the consensus layer. Another topic that I want to stretch is we want 1 billion light nodes.
00:18:20.336 - 00:19:07.910, Speaker A: How do you achieve this? Right, so we want light nodes to run on all devices, like on all kind of devices. But I think the device we should target the next is the browser because this is what people are used to interact with in their wallets and they send transactions through MetaMask and everything. What we want to achieve is running celestial nodes dashing light clients in the browser. So there's two approaches to this. One is having a different compile target for celestial node go implementation. Another one is having a rust implementation. For the sake of time, I'm not going into detail, but if you want to hack on this, please talk to me.
00:19:07.910 - 00:19:41.584, Speaker A: Yeah. There's plenty of other open problems and research directions. A few were already mentioned, for instance, by Yuma yesterday, the ZK quantum gravity bridge. Yeah. And I think one thing that last word that I want to mention is that we need to focus on developer usability. And if you want to do usability research for developers in the modular stack, please also reach out to me. Yeah.
00:19:41.584 - 00:19:50.110, Speaker A: You can engage here in our research forum and on GitHub. These are the main things. Thank you very much.

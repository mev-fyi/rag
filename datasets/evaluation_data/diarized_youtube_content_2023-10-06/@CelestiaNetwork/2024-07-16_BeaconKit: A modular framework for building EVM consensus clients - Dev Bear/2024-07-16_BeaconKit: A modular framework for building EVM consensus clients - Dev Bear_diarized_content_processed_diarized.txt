00:00:01.840 - 00:00:39.758, Speaker A: How's everyone doing today? So today I'm going to give a little talk about Beaconkit, and super excited to share that with you guys. Quickly, to just introduce myself, I'm Dev Bear, one of the co founders of Bear chain CTO. Been focusing a lot of my time over the past little while on kind of execution clients and building out kind of core protocol stuff. And super excited to share the next part of the journey with you today. To give a little bit of an update from last year. Last year, I spoke about Polaris, which was our previous version of this EVM framework. We've been through a long, long adventure figuring out how to build a modular EVM.
00:00:39.758 - 00:01:25.830, Speaker A: So to give a recap of how we got here way, way long ago, when we were first Ida ing on Bear chain, kind of the first thing that we thought was like, hey, what if we just do what everyone else does? Start a geth fork and go from there? We realized that that's actually quite difficult when you want to start playing with things and changing the logic. It can become quite cumbersome. So we looked at, ok, is there a framework that we can use? Looked into substrate. Funny enough, I don't know if that's still alive today. Then as we dove into cosmos, we saw ethermint and we saw that, hey, maybe there's something here, the intersection of the inner chain with EVM. And maybe this is where we want to go. Ultimately, where it took us was we were like, okay, there's pieces of this that we like, pieces of it we don't.
00:01:25.830 - 00:01:57.900, Speaker A: But overall, we were bullish on this ideology of having this interoperability. So we were like, okay, let's go build our own framework. And that's kind of how Polaris came to be. So the idea behind Polaris is that we saw this opportunity to build this modular EVM framework. And the way that I kind of break things down for this, and still very true today, and you'll see this in beacon kit, is we can break down kind of any blockchain into like, three basic pieces. You have to build a block, you have to process a block, and then you need to save the block somewhere. And the whole idea behind Polaris was creating this modular separation of these concerns.
00:01:57.900 - 00:02:51.648, Speaker A: Now, what happened was we also discovered that ABCI and Comet, BFT and all this jazz and the EVM kind of lifecycle and semantics of that didn't really mesh well together. The EVMM pool, the EVM block building process has been something that's been iterated on for almost a decade at this point we discovered that it's really critical that you actually use these semantics in the way that they're supposed to. And kind of just some of the ways that ABCI was designed made it kind of some performance issues there. On the converse though, we saw that there was definitely something there when it came to having this interoperability. We had this concept of precompiles which allowed EVM transactions to touch into cosmos namespaces. And we think for application specific chains, this could be really, really cool. If you have a really complex application that you need to run on a blockchain, but you want your users and developers to be able to interact with that application in a programming language that they know.
00:02:51.648 - 00:03:20.540, Speaker A: Having that synchronous composability is really, really powerful. So the one downside to this though is you're going to end up with a getfork. There's no way to get around it. We tried and tried and tried, but ultimately you're going to end up having to maintain your own EVM. And that's kind of the problem is that you think it's going to be great. You're like, ok, we'll use all this stuff that Ethereum has. We'll add our modifications and we'll make this super crazy thing that's like geth Plus plus.
00:03:20.540 - 00:03:41.808, Speaker A: In theory this happens. Oh, one of the slides got messed up. Oh no, there was a spongeBob on fire meme. But what ends up happening is you end up just having to maintain a nest of dependencies. You're forking your own logic and it just gets really, really messy. And we see this on a lot of other chains where Geth falls behind. They're running an EVM that's older, people want the latest features, but it requires engineering effort to keep it there.
00:03:41.808 - 00:04:15.052, Speaker A: And it just ends up being this nasty cobweb of things that just sink time and money into it. You end up having to do exactly that. You're building these cursed connectors, you're having to figure out ways to patch pieces together. It just gets really, really gross and you end up just spinning and burning engineering time, trying to build something that you shouldn't have to. You're trying to figure out, how do we make this layer just work? You have 1000 meetings, 1000 design sessions. Ultimately you end up at the same place where you're. We just need an EVM that works and that's what developers want.
00:04:15.052 - 00:05:12.852, Speaker A: At the end of the day, a lot of our experiments and testing and things really showed that users just want or developers just want an EVM that just works. And if you have this embodiment where JSON RPC is slightly off or an opcode is slightly changed, the whole suite of EVM tooling that has been developed over the past ten years at this point starts to run into issues and it really adds a lot of friction for developers. At the end of the day, there were basically three biggest things that we wanted to be able to achieve as part of this EVM framework. The biggest of which was we wanted to be able to still leverage these cool concepts around single slot finality IBC. But at the same time, we wanted to avoid having the situation where you're running this kind of hodgepodge VM that has issues. Lastly, one of the things is that we didn't want to have to maintain all of this work. Like a non trivial amount of engineering time was going into just simply keeping our evm up to date.
00:05:12.852 - 00:05:43.990, Speaker A: And it seemed like really silly and like there was a better way to get around this. And, you know, teams that are building, you know, if you just want to build an app chain, having to devote, you know, millions of dollars a year in engineering time to just keep your EVM up to date seems really, really silly. So, I don't know. At this .6 months ago, seven months ago, whatever it was, I had this crazy idea. And the crazy idea was, what if we were able to just run any execution client anything we wanted? We just wanted like an EVM that works, we don't want to have to deal with it. And where we got to is we came up with this idea, which is now called beaconkit.
00:05:43.990 - 00:06:16.906, Speaker A: And the tagline is a modular framework for building EVM consensus clients. And basically the idea behind that is we have two different binaries, so we have one on the left, which we call the consensus client. The consensus client is basically in EVM terms, and this is taken straight from kind of ethereum 2.0. It's responsible for consensus. It doesn't do anything. You can't submit transactions to it. It's just simply, what is the state of my blockchain? Are we coming to consensus on it? And the thing that it's coming to consensus on is basically, what is the.
00:06:16.906 - 00:07:23.930, Speaker A: And I just realized I'm standing in front of the screen, what is the state of my execution chain? And it's basically saying, okay, like the consensus chain, there's an execution chain. I want to come to consensus on what the head of that chain is. And that's pretty much all it does. Lastly, how it does that and it powers the EVM is over what's known as the engine API, which if you're into the ETH two world, is a very well thought out, very kind of, it's been around for a while at this point, but what's nice about it is now we're interacting to the EVM in a way that's very natural, right? We're using the common channels, the common API that it was designed to do, and that allows us to have this standard unmodified UVM, but still being able to leverage common BFT, IBC, etcetera. So what this looks like to the developer that's running it, and you can, if you go into our repo today, you can just run this simple example on the left here we have beacon D running, which is a consensus client. Then over either IPC or JSON RPC, it communicates with an execution client. And if you were to read into these logs, you'll see that they're basically talking back and forth, one building a block, saying, hey, are we good with this? And then basically moving the execution chain forward.
00:07:23.930 - 00:08:18.470, Speaker A: And what this looks like when you actually run a full network is it looks very much like Ethereum, where you have all these different consensus nodes. They're all communicating with their execution client over that engine API. And then that's the whole blockchain system itself. On the execution layer, we have the ability for gossiping ETH blocks and ETH transactions, and that allows the network to leverage that p, two p optimizations that have been done on Ethereum over the past, you know, ten years. And on the consensus layer, we're able to come to consensus on the state of this chain really quickly, thanks to comet, BFT and all the work that has been done there. So at the end of the day, the coolest part, in my opinion, is that out of the box, if you're using beaconkit and you're building a beaconkit, you can use any ethereum client you want. So obviously you can use Geth, you can use Aragon, which is at this point a very, very far fork of geth, or turbo geth for those who've been around a while.
00:08:18.470 - 00:08:57.530, Speaker A: But you can also use some of the high performance clients too, like Nethermine and ref, who are really pushing forward. Like how many Giga gasps per second can we go? If you're an enterprise user, you can use bazoo and get all the benefits of Java and being able to plug into that ecosystem. And if you're like some members of our team and you really, really like sniffing glue, you can run Eth JS or Nimbus if you're really, really, really bold. So to kind of sum it up, at the end of the day, if you're running Beaconkit, you get a fully 100% evm identical. If you run that smart contract on Ethereum mainnet, you run that smart contract on a Beaconkit chain, it's going to be exactly the same. Absolutely zero. Forking it is something that I will die on the hill of when it comes to Beaconkit.
00:08:57.530 - 00:09:38.178, Speaker A: Beaconkit should forever be able to run any Ethereum execution client without any modifications made. Docker pull go ethereum client, Docker pull Nethermind, and it should just run. And exactly that. We want to be able to support as many clients as possible and leverage all the work that these execution client teams put in, day in, day out to keep those clients running well. And lastly, not only can beaconkit be used for l one s, but by leveraging things like Rolekit, we can also be able to run l two s. And that's really, really powerful because Beaconkit really is this first framework that can run any layer you want. You want to run a layer one, you want to run a L2, you want to run a layer seven, whatever you want.
00:09:38.178 - 00:10:32.996, Speaker A: It's the first framework that allows you to run any standard unmodified execution client in any kind of format you like. And the way that we're able to achieve this, and some might say it's very much too good to be true, is through. I mean, this is modular, summit modularity. Am I missing a slide? No, we're good. And how this basically looks is what we've done, architecturally, is not only have we decoupled the execution client from the consensus client, but within the consensus client itself, we've actually decoupled our specific runtime that powers the EVM from the consensus engine completely. So in a traditional kind of cosmos chain, the ABCI or comet chain, I should say the ABCI lifecycle is actually what's powering the chain. But what we do is over on the beacon kit, in our code, we have modules that actually are powering themselves, and we run like a service based architecture to achieve this.
00:10:32.996 - 00:11:19.890, Speaker A: And then all that's actually happening is when something about ABCI happens. So, like, I use prepare proposal as an example, right? Prepare proposal doesn't actually trigger beaconkit to build a block. All prepare proposal does is basically emit an event that tells our code to like move forward and tells our code that, like, something happened. So for instance, like when a block is built, right? ABCI will come along and it'll be like, hey, you know, this happened. And then R code basically just uses that as like a point in time. So these events are essentially taking ABCI calls and things like that, and basically allowing our runtime to create a canonical set of points in time. And if you look into our code base, we use this as an example, as like in Ethereum, we have the concept of slots which are based on these twelve second intervals.
00:11:19.890 - 00:11:59.492, Speaker A: But how we compute slots today is we actually define the length of a slot based on when ABCI is emitting certain events. And what's really powerful about that, though, and this is like the coolest part, in my opinion, is it in theory, allows us to run like any arbitrary consensus mechanism we want. So you could use avalanche consensus, you could use hot stuff, you could use anything you want. All you have to do is write this little middleware piece that glues basically what avalanche uses as its cadence. Its ABCi thing I don't know the details of. Maybe it's snowman. However you want to think about it, we can translate things that avalanche know to things that beaconkit can understand.
00:11:59.492 - 00:12:36.910, Speaker A: And then all of the logic that's happening in the runtime over here is completely agnostic. It just sees like, hey, I received a block, like, hey, you know, height increased, things like that. And it makes it like, you know, Abci makes it really easy to like, go and build new applications without having to worry about consensus. But we've also gone the other way where, you know, we can build these applications in a way that they don't care about what consensus is happening. And I think that's a really powerful, powerful thing in the future. One of the other things that I really, really thought was important was encoding. And in Cosmos, and in a lot of people in general, they don't really think about like how important this might be.
00:12:36.910 - 00:13:08.224, Speaker A: But one of the things on Ethereum and specifically ETH two, is this concept of SSD encoding. And what that is, is basically, it's called simple serialization. And what it is is it's basically a way to serialize data that is like natively merkelizable. What's really powerful about this is after the latest Deneb upgrade on Ethereum, we have EIP 4788. And what this actually means is that the block root of the block is actually pushed into the EVM. And this is used by a lot of protocols. Eigen layer, Lido is looking into this.
00:13:08.224 - 00:14:01.022, Speaker A: We actually use it for our PLL prover which we won't get into this in this talk, but effectively allows us to relay consensus information about who proposed a block, you know, what the, you know, how many transactions were in that block, et cetera. And proof of liquidity can actually leverage that data in a way that's completely decentralized because it's natively provable and mercalizable, et cetera. Lastly, one of the things that we really spent a lot of time on was like making the code modular itself and really ensuring that from a software architecture perspective there was like as minimal coupling as possible and making things really extensible. So for instance, we've broken down all of our core pieces of the chain into their own modules. This has taken a lot of the inspiration was actually taken from breath in terms of their crates and having everything broken down. And we've kind of done the same thing. Additionally, I think this is something that's not really used in go that wildly, at least at this high of a level.
00:14:01.022 - 00:14:40.070, Speaker A: But everything in our typing system is completely generic. So we've gone and spent the time to fully generic size everything. What's really powerful about that is it allows people to get creative with how they're building their own beacon get chain. I want this to have a different type. I want to inject a tracer into some block or something like that. As long as you're able to create that hard type that implements the interface, you can add your own custom logic that way, which is super, super cool. Now you may think that all of these things are adding a lot of overhead, but one of the things that I've personally spent a lot of time on is making sure that not only is beat concept modular, but it's super fast.
00:14:40.070 - 00:15:10.010, Speaker A: I will live and die by the statement. Some may disagree, but running a Beaconkit chain today is like the fastest, lowest resource way to run an EVM. It's stupid fast. So this data is actually real. From our validator nodes on Bardio testnet, which is running the latest version of Beaconkit, these nodes consume. It's literally nothing. It's like half a gig of ram, half a, not even half a real cpu, like half a virtual cpu, and we're still able to achieve super low block times.
00:15:10.010 - 00:16:10.040, Speaker A: And one of the things that I think is really cool about this and what it enables is it enables running Beaconkit on super low power devices, which is really nice for eventually getting to this thing where instead of having to trust an RPC node, I can just run not even a light node, literally a full node on my phone or a fire stick is one of the jokes that we've made. You can just run it and verify things yourself. I think that's a super powerful thing to be able to do, but not only on the other side of the spectrum. You can think about it like what we've seen is if we throw hardware at it, we can actually achieve some sane transaction throughput numbers. So this was an example that we cooked, I guess, last week, and it was running basically a combination of beaconkit using an l two on rollkit with a local version of Celestia running and then ref and we were able to retrieve. Obviously this is the execution client pulling its weight three giga gas per second. But mainly what was really cool about this is we could actually support around 30k transactions per block.
00:16:10.040 - 00:16:53.244, Speaker A: We actually, this may be able to go even higher. We just kind of stopped the testing because you were like, that's a number that looks good on a slide. But what's really cool is that's actually testing the actual level of how hard the actual consensus client can go. And we can see that we can support these really, really large blocks which may be useful for certain applications. If you need to support a lot of ETH transfers, your chain has some piece that really needs to go in and send a lot of transactions. It's cool to see that we can handle that level. Additionally, because we support the engine API, if we get into some cool things that are in the works not by us, but by people abroad, if your parallel EVM supports the engine API, you can just plug it in.
00:16:53.244 - 00:17:55.800, Speaker A: That's again showing that performance is always on the table. And being able to plug in the work of another execution team that's really striving for that shows the modular extensiveness of beaconkit, and it's super cool. So tying it all together, Beaconkit unmodified execution client, that's something that I will hold up forever because I think that's one of the biggest value adds, is that you don't have to change anything. Supports building out ones right now that's done via comma bfteminal supports building l two s that right now that's done via rolekit. But again, based on this architecture, we're really thinking down the road about what if somebody wants to write their own consensus thing or plug in avalanche as it is written in go something like that. One of the things I actually forgot to mention earlier is since we're using standard unmodified clients and we strive to maintain full EVM or EIP compliance we actually have, Beaconkit has a built in DA layer as well. So you can use, you can submit blobs, blob txs on the EVM, and they will get stored and you can access et cetera.
00:17:55.800 - 00:18:46.360, Speaker A: And then also because the client is modular, this is a great segue into if we wanted to use another DA layer, you could totally do that. So you could have it. So instead of just saving the blobs of the file system on your chain, you could use the IP 4844 endpoints on the execution client to forward those blobs to Celestia, for instance. What else? Yeah, we got full cancun support. So tying into before, we're always going to be able to have all the latest features because the eips just come with the execution clients. And lastly, the thing that I personally find is the most important, one of the most important things that I think is really people kind of, it kind of falls behind. Not falls behind, but people don't think about it, is that we support the standard eTH, two ss ed encoding, which will be really powerful for people building things that require cross chain interoperability and proofability and those type of things.
00:18:46.360 - 00:19:40.060, Speaker A: So yeah, to kind of sum it up, beaconkit allows you to build your l one, l two, whatever you want to build. You can use comma BFT and rolekit today, but there's no reason why you can't start plugging in your own engine. And if there's anyone who's interested in doing that, I would love to chat with you, especially as we think about these APIs, etcetera, and some of the other things that were also in the works right now. And again, if you're interested in working on these anything, please reach out to me. Ssed native database so we're actually looking at how can we can store SS data really efficiently on disk. We're building that basically for the purpose of reducing hashing over and over again. And that's where exploring building on top of MDBX, which is a really, really powerful database there, tying into SSZ in 4788, one of the things that we want to figure out how to build is this generalized execution client consensus middleware piece that allows you to communicate data back and forth.
00:19:40.060 - 00:20:17.720, Speaker A: The consensus client would read logs from the EVM, and then conversely the consensus client could pass data in a provable way back to the. And lastly, this modular architecture is really powerful because it allows us to test and verify and audit all these pieces individually. So one of the things that we're working on now we're working with informal on basically creating a formal spec and then eventually verifying that spec for kind of our core state transition module. But that could apply to any module in general, which is super cool. So thank you guys for coming so much again. If you're interested in working on any of these things, please reach out to me on Telegram, Twitter. It's all under the same header here.
00:20:17.720 - 00:20:25.800, Speaker A: And check out the GitHub at Barachain Beaconkit. Yeah, that's everything. Thank you guys for listening to my talk.

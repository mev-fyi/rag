00:00:01.760 - 00:00:21.214, Speaker A: Alright, guys, welcome to the panel title. What's the title? Oh yeah. Is economic security a meme? Well, I'll answer yes, but no, I'm just joking. So, with our esteemed guests here, do you guys want to present yourself first before we jump into it?
00:00:21.342 - 00:00:43.342, Speaker B: Sure. My name is Sunny. I'm one of the co founders of Osmosis. It's a Dex app chain, has its own native staking token, but with ability to stake other things other than just the native token, like LP shares and potentially other tokens in the future coming soon.
00:00:43.406 - 00:01:19.040, Speaker C: So, yeah, hey, yeah, I lost my voice like two days ago. So yeah, my name is Misha. I'm co founder of symbiotic permissionless rest taking protocol and permissionless and shared security protocol. I don't think it's a meme. I think it's been used incorrectly in most cases. And I think that information is not spread, that is not spreading efficiently about that. But if we are careful, we can do a lot of good with that.
00:01:20.410 - 00:01:40.802, Speaker D: Hey guys, I'm vias, one of the founding members of Eigenlayer. And yeah, if economic security is a meme, then we need to touch on whether decentralization is a meme, whether crypto user experience is a meme. And I don't mean to just punt the problem at other dimensions, but it's not the only one we got to tackle here.
00:01:40.826 - 00:02:07.390, Speaker A: Maybe togrul, I would love to tackle other problems as well. I have nothing against it. So I think let's begin. So it seems that restaking protocols focus a lot on DA and finality. Why is that? And also, do you think there are a lot of other use cases that restaking can offer in the future? And potentially some stuff that is revolutionary.
00:02:08.370 - 00:03:05.404, Speaker D: Maybe I'll start off because we are building Eigenva. And again, very gracious to the modular summit guys, for letting us come here and talk about Eigen Da, when obviously, you know, we should be talking about Celestia. But at the same time we, you know, there's always a lot of questions on whether DA is just a proof of concept for us, whether we're just dogfooding the protocol, right, what it is, why it matters. And you know, a few of you are familiar faces from my talk right before to grill's talk. And one of the points I had to make was today we have a lot of defi actions in the ecosystem, and for them, security matters a lot, but throughput really doesn't. But as we onboard, more and more consumer use cases and social use cases where the actual users are in applications today. The security footprint might go down and the throughput footprint might go up.
00:03:05.404 - 00:03:53.940, Speaker D: And so are we building Eigen DA for being a core integration into the Eigen layer protocol? Yes. Are we building it because we believe that infrastructure is required to be able to scale and actually make a difference in onboarding users? Yes. But at the same time, is that the core value prop to Eigen layer as a totality? Absolutely not. Economic security is its own dimension, and I think that's what we're going to get into today. DA is a way to make a dent in terms of what are the throughput applications that we can eventually onboard. So Eigen DA is at ten megabytes per second today on Mainnet, across 200 operators. We have a vast operator set that we're actively expanding.
00:03:53.940 - 00:04:32.260, Speaker D: We just hit 17 megabytes per second on public mainnet, and we have an internal roadmap to go far beyond that by the end of the year. But, you know, and to touch on fast finality, there's a bunch of other services building fast finality across the ecosystem to provide value add services to rollups. But I don't think it just stops there. I think the point is, let's make sure that these projects are building in the ethereum ecosystem, and the value is not being distributed to their own tokens and their own ecosystems, but rather is conducive to growing the overall piece rather than distributing the PI into multiple subsets.
00:04:34.760 - 00:05:21.300, Speaker C: Yeah, the shared security industry, it hasn't been started yet, so it's way, way too early. Like, we don't have any production protocols on shared security beyond Polkadot. I think in Cosmos merge security as well. But they're doing it for their own ecosystems. The main goal for us here is not to limit the space in any way, because data availability is a really nice angle, but it's like you're expecting something that hasn't been created yet to support something that's not useful yet. So you create layered abstractions. It's really hard to evaluate.
00:05:21.300 - 00:05:36.270, Speaker C: Yeah. The goal for, I think, successful shared security protocols and initiatives is to be as flexible as possible to accommodate. And that's it. Our opinions doesn't actually matter in any way.
00:05:37.730 - 00:05:39.350, Speaker B: What was the original question again?
00:05:40.290 - 00:05:41.430, Speaker A: I can't remember.
00:05:42.650 - 00:05:45.066, Speaker D: DA and finality on restaking.
00:05:45.258 - 00:05:48.614, Speaker A: Why do most of the restaking protocols focus on DA finality?
00:05:48.662 - 00:05:52.650, Speaker B: For now, those are like the easiest things to build.
00:05:54.590 - 00:06:12.890, Speaker A: That was the right answer. It was quick. So, okay, but why does economic security actually matter? And for example, why is Eigen layer or symbioting in the position to be the prime provider of that economic security?
00:06:14.300 - 00:06:16.120, Speaker C: Yes, that's a loaded question.
00:06:17.380 - 00:06:21.068, Speaker A: I'm here to ask the loaded questions.
00:06:21.204 - 00:07:30.524, Speaker C: I'll take the first one. Yeah, well, economic security matters a lot and it matters not from the, I think the hype perspective is a bit overblown, but beyond that there is an actual use case. This is product 101. People are doing the same stuff over and over and over again and like they're delaying the go to market and safety, like diminishing their safety by a lot while doing the same stuff. They need to, they need to create a foundation, create a token for it, pump up the token list on exchanges, get yourself like your friends validators, or like the brother that like you have that you never talk to like four or five years and who's doing like a great, great job validating some stuff. And yeah, after that you don't have a stable token, you don't have a good operator set. And like if anyone here like launched a network, you know, like if you fucked up on validators, it's gonna cost you because like they will be down a lot.
00:07:30.524 - 00:08:09.808, Speaker C: They will ask you questions that you don't want to answer ever. They might even like create some conspiracy and bring your network to the ground. And this is millions upon millions of hours spent inefficiently. Shared security as a really useful primitive can help you with that because it will be a center of expertise. The platform that you can use to really create a robust framework to onboard hundreds of networks, not just like one to one. I talk to you, you become our network. No, no, no.
00:08:09.808 - 00:08:47.420, Speaker C: Like just scoring technical stuff like tech stack and tokenomics and like risks and everything like that. Yeah. So this is the point. Like that is really important and we just need to pay for it. And for that we need scale. And I think the protocol that is going to be eventually successful, we still have a lot, but they are successful in mass adoption, is the protocol that can be as accommodating to networks as possible. You don't want to create a protocol that you need to.
00:08:47.420 - 00:09:39.688, Speaker C: You've shortened your go to market by 616 months and then you spend 16 months adopting your protocol to your network, to the restaking protocol that wouldn't do anything good. So the networks need a good instrument to onboard themselves and to be in a pipeline that is efficient. If any protocol will be successful with that, they'll immediately solve hundreds or not thousands problems per year. Just imagine like that. It's nothing fancy, you just enable them the protocol to test traction. They don't need like billion dollars for that. They need like from the start, like 20, 30, 40.
00:09:39.688 - 00:10:00.740, Speaker C: But the stable ones, the ones that are not gonna do like ten x in a day or like to do zero in a day, that's the important stuff. You solve that and yeah, like, nobody cares. The protocols start to start innovating, start iterating, like quickly, quicker. It's nothing sexy, it's just infrastructure.
00:10:03.080 - 00:10:06.576, Speaker A: That's actually a good tagline. Nothing sexy, just infrastructure.
00:10:06.688 - 00:11:14.020, Speaker D: I like that a lot. I can't help but agree with pretty much everything Misha just said. I used to think I was an Ethereum maxi, but I realized I was just a coordination maxi, because I think coordination and innovation are directly tied with each other and shared securities about how can we coordinate more effectively with the same set of resources. And to the final point that Misha just made, which is innovation, if you wanted to experiment on just one layer of the modular stack, you needed to build your own trust network. You needed to bootstrap your validators, pump your token, build a market cap, and still be susceptible to token debt spirals. And yet now what's possible is you have dramatically reduced the rate of innovation, or, sorry, dramatically increased the rate of innovation while reducing the rate of deployment, which is the most important factor where people can just focus on what they do best, which is, hey, let's say I know how to build a great consensus protocol that I think is better than comet VFT, maybe. Okay, cool, let me just go work on that.
00:11:14.020 - 00:11:29.560, Speaker D: Rather than trying to figure out how to launch a token in, launch an l one, because that's incredibly difficult and like incredibly outside of my zone of genius. So if we can just enable people to operate inside their zone of genius more than economic security, insured security makes sense.
00:11:31.340 - 00:11:44.800, Speaker A: Is there some, because I see it a lot, that people are like, oh, yeah, just put everything into restaking protocols. Like Babylon is going to go to 100 billion staked, etcetera. Is there such thing as too much economic security?
00:11:46.070 - 00:12:06.854, Speaker B: Yes. I think you probably want to know what security has a cost. You can have costs, money and something like osmosis. We have, I don't know, a billion dollars of assets on chain. We don't need $10 billion of security. I'm sorry. Actually, really, we don't even care about what's on chain.
00:12:06.854 - 00:12:46.240, Speaker B: We shouldn't even count the OSMo value. We have $300 million of bridged assets on chain. So it's like, okay, we don't need billions of dollars of economic security. We just need, like, we should set a security threshold of, like, hey, we want this much economic security. OSMO is already providing us, like, enough economic security, so, like, maybe we don't need anything else. Now, if we get into a situation where somehow OSmo isn't valuable enough to, like, provide us the, you know, whatever the target is, let's say it's 50% more than bridged assets, right. Then we can be like, okay, we'll give, like, a little bit of staking rewards to bring in external security, but you should minimize that as much as possible.
00:12:47.740 - 00:13:20.106, Speaker D: I think you're touching on something very important, Sunny, which is like, yes, there is a cost to economic security, and you're gonna have to pay out emissions and yield. But the one area where I would disagree with you is it highly depends on the use case. I want my bridge to have way more economic security than my gaming VM. Those are two dramatically different things and with two dramatically different value propositions. So I want my bridge to be far more secure because it's managing my assets in transit, then I want my gaming VM to be deployed.
00:13:20.138 - 00:13:27.310, Speaker B: Right, yeah, of course. I just mean that even the bridge has a target, economic security. Right. It is possible for a bridge to have too much economic security.
00:13:28.450 - 00:13:31.270, Speaker D: Depends on how much volume is transacting on the bridge, no?
00:13:32.250 - 00:13:35.874, Speaker B: Yes, but based off that volume, you can set a target.
00:13:35.962 - 00:13:38.490, Speaker D: Sure. Like, I agree.
00:13:42.230 - 00:14:29.942, Speaker C: Yeah. I don't understand the question. Like, you have a network. They are paying for the whole party, right? Well, in a stable condition, you can push points and create layer of five different points from five different companies. But beyond that, networks are paying for their security, and they select how much security do they need? They can be pushed to get more, and we need to figure out a way for them to, again, like, the framework of scoring and understanding. So the ideal. Not ideal, but the current thinking on my part is that our protocol will have curators, like, really, really expert people that are going to, like, the.
00:14:29.942 - 00:15:14.774, Speaker C: Going to come to networks and like, yeah, this is the best operator set for you, and we can give you, like, $201 billion for your economic security. They are going to be the ones who are going to be limited that with networks, because, like, if the network is great, they're going to be pushing for more. If the network is not so great and they want to limit the risks, that's going to be their problem, because they're going to be losing money on that. So, like, if the incentives are allocated, like, they're, like, built correctly, we will see the push and pull motion between the networks and money managers and operators as well. But it's only be effective if it's on scale. Like we can't limit ourselves to ten networks per month. That's like way too low.
00:15:14.942 - 00:15:17.974, Speaker A: So it's basically all about aligning the incentives, right?
00:15:18.102 - 00:15:30.600, Speaker C: Yeah, it's not going to be a problem if your incentives are dysfunctional. Yeah, you'll have like protocols that have like one tps with a 100 below economic security and like five users without bots.
00:15:31.820 - 00:16:19.242, Speaker D: Well, the question I haven't said that. One of the questions that you're touching on, togro here is like, how much economic security does a new service need? Right. And I think there's two dimensions to that, and one of them is completely broken today, which is like, oh, if I get more economic security, then I can, you know, theoretically get more alignment from the ecosystem, make my token pump further, like distribute that better. And now my market cap goes up and value accrual and all these factors, rather than thinking about the perspective of like, okay, what is the value prop that I'm actually trying to solve and how much security does my protocol actually need? Or two completely different dimensions. But the problem is you have three dimensions of things that you can do with value. You can create value, you can capture value, and you can distribute value. And the reality is most people focus in that order, create, capture, then distribute.
00:16:19.242 - 00:16:46.660, Speaker D: But I think decentralized systems should be operating from the counter approach, which is you create a, you distribute and then you capture. And so what ends up happening is you end up with, sure, a smaller piece, but of a much bigger pie, rather than like a really big piece of a small pie. Right. And it's up to you on what you want to have. But you know, I think if we start implementing rent seeking systems and decentralized systems, then we've really lost the plot.
00:16:48.200 - 00:17:01.630, Speaker A: There's just been a lot of talk in the past year or so about whether or not restaking protocols introduce systemic risks to the underlying base layer. Any thoughts on that?
00:17:04.130 - 00:18:16.560, Speaker C: They might, yeah, like, are cars dangerous? Some of them have like 1000 no brakes. Some of them are like, I don't know, forth focus. So yeah, like it depends on how you design them. If you want to validate every service using sidecar to Ethereum validators, it's not probably gonna go great. Like, we designed a protocol that like, I don't see any risk for, if the system works as intended, like they don't usually do, but like it's, how can we do that? Like, yeah, if we have like, I don't know how much, like 1 billion, like 100 billion or 200 billion ethereums staked to a thousand networks that have like a really, really loose slashing conditions. Yeah, but if you will survive that, like, it's going to be slashed, it can be like recovered by, I don't know, some social mutiny or something. But yeah, I don't see that.
00:18:16.560 - 00:18:52.350, Speaker C: Like, it was scary when we were like at the early Ethereum days, like shared security freedom days, where people thought that like, yeah, we have like validators for Ethereum, but people don't know their stuff. Like ethereum validators are like calculators by like computing power, maybe like smart ones, but they can't do anything else. Like they can do ZK co processing or something like that. It's not a risk, it's impossible. And yeah, so I don't think that's a huge risk, but we need to keep that in mind, I think.
00:18:52.650 - 00:19:25.588, Speaker B: I mean, yes, they have the potential to harm the incentive to the l one, but I think actually that's probably the more exciting thing, is the ability to impact how the l one works. I feel like today most of the restaking protocols have been about external ABS's. But what makes restaking actually interesting to me is the ability to change how the l one works. Oh, I probably should have mentioned this. Along with osmosis, I'm also an advisor to Babylon. And bitcoin staking was something that I worked with David on coming up with the idea for. And one of the main reasons I wanted this to exist.
00:19:25.588 - 00:20:00.200, Speaker B: Well, two reasons. One, it's my way of backdooring proof of stake into bitcoin one day. But the other is I wanted to use it to build a zero conf network for bitcoin, where you have a way of having bitcoin miners stake and attest to that. Hey, we will include your transaction in the next thing, so you don't have to wait ten minutes for your transactions to get integrated. Right. And so eventually we can build a fast bridge from bitcoin. So, but it's like, I think the interesting thing about a restake, building a restaking system on bitcoin and involving the miners in it, is that we want to get the, like, we want to change the l one properties.
00:20:02.180 - 00:20:41.678, Speaker D: I would agree with both parties. I think it's very interesting to start experimenting with what features the l one has. I think the second aspect of avss, or whatever services, whatever we want to call them, that are building on top of these restaking protocols is rather than experimenting directly on the l one, maybe it becomes too risky. Right? We talk about things like don't overload ethereum consensus, and so we need to offload them to a different ecosystem. We need to test them out. We need to create this like, you know, playground for them to innovate and experiment. And then we start enshrining these features into the main protocol.
00:20:41.678 - 00:21:13.630, Speaker D: And there's like this graduation phase of like, okay, you've reached product market fit, you've reached value accrual to the l one. And so you get enshrined into the protocol. So kind of a hybrid response to both of those where I think they both matter. But it's, you know, we're really tackling this like stability versus agility trade off, right? Like you don't want to break the system. So like you don't move too fast, so you rock the boat too much. But at the same time, if you don't move fast enough, then you're just getting further and further away from your end goal. So how do you tackle that?
00:21:17.130 - 00:21:44.450, Speaker A: Another thing that I was thinking about is I've personally been spending a lot of time thinking about objective versus subjective slashing and slashing in general. And what are your opinions? Should restaking protocols limit themselves to objective slashable conditions? Or is it fine to introduce some kind of social consensus that does subjective slashing?
00:21:45.230 - 00:22:11.370, Speaker B: I think it's fine to introduce some sort of social consensus and just be upfront with all the validators that this is what we're doing. And like we in osmosis, like, I think there was like, hey, if people are sandwiching at the transaction layer, I'm like, it's hard to prove that right now, but if governance, if a two thirds are valid, it's like, no, this person is clearly running sandwich attacks and here's all this evidence, we'll slash them.
00:22:14.870 - 00:22:47.200, Speaker D: I mean, I felt like that was a Tl question for me, tigrual, because we did announce the intersubjective token and did put out the white paper. And yes, the talk right before yours was about the intersubjective tokenization to some extent. Again, it goes back to, does every single social consensus moment need to happen on the l one layer? How expensive is that? How much bloat does that put on the ecosystem? If we can agree that that's inefficient, then we need to offload it. And I think that's kind of sunny's approach as well.
00:22:51.460 - 00:23:36.280, Speaker C: Yeah, I think it's a really narrow way of looking at things not offloading. It shouldn't be considered like l one. It might be entirely off chain. I got approached a couple of days ago by the person presenting a huge insurance concern that would require a slashing committee on arbitration layer. That is going to be a consortium of lawyer firms and like appraisers and everything like that. As long as it has operators. As long as it's like, can benefit from like some clear framework and strong smart contracts.
00:23:36.280 - 00:23:45.840, Speaker C: Yeah, like flexibility is infinite. Again, we are just starting up. I'm not like 100% sure that I know what interest adjective is.
00:23:46.660 - 00:23:48.100, Speaker A: I don't think anybody knows.
00:23:48.180 - 00:24:36.160, Speaker C: Yeah, like this is like 3 hours of my life I'm never getting back. Yeah, but like, we, like, yeah, even the ogre ones, like I think that that's the inspiration for intersubjectivity. The prediction market ones, they have their own place. It's not going to be for consensus of l one, probably for like at least the conventional one, but yeah, yeah. Both of them, they need to be, you just need to, like, you never should use one size fits all of, as long as you have consent from three participants, operator, staker, and network, it should be fine. All of these guys are doing some risk analysis, otherwise they're going to lose their money and it's going to be fine.
00:24:37.980 - 00:25:44.082, Speaker D: If you believe that you shouldn't do one size fits all, then that's also why we need to go and try and build something different, which is the intersubjective design as well. Right? Like those two things are contradictory to some extent because like we're just making an attempt at saying, hey, here are these problems. And maybe the example outside of prediction markets that to me makes the most sense, is like, okay, what happens with all these decentralized AI projects? If you believe that some of them are a meme, that's fine. But if you believe that some of them actually matter, how do you identify whether somebody introduced a rogue variable to the data model? How do you identify that the variable was rogue? That's a highly subjective question, but at some point we need to make that objective and slash them if we're going to build these decentralized AI systems. So that's a moment of intersubjectivity right there. And if we don't come up with a way to try and tackle that, then we're just going to let the problems persist and let them just manifest themselves in the ecosystem. So I agree with you that to some extent, one size does not fit all and we need to come up with custom solutions but at the same time, Ethereum itself just moved from proof of work to proof of stake a few years ago.
00:25:44.082 - 00:25:46.870, Speaker D: We're all just trying to attempt new systems.
00:25:47.370 - 00:26:31.106, Speaker B: Okay? So with the interstellar subjectivity stuff, this works until you have some. If everything is in a small internal closed system. As soon as this is sort of the idea of, hey, if this chain disagrees, we'll split the chain in half. But as soon as you have any bridged assets or anything, it'll like. So I don't know what is actually like the use cases of interceptivity that doesn't rely on like some external thing, like even for like a prediction market case, right? It's like, yes, it splits augur in half, but it like, doesn't matter. There's still some USDC that was that need. Unless all the trade like bets are being made in augur, and it's like, that's not gonna happen, right? People wanna bet in USDC, totally agree.
00:26:31.178 - 00:27:35.790, Speaker D: But right now, if that that fork was to happen, it would happen directly on the l one. Not only would augur be split and the USDC would be split, but as well, we would end up with essentially a fork on the l one chain of people choosing one branch saying, hey, this was the correct state transition, and hey, this was the other branch saying, this is the incorrect state transition. And if we want that to happen on the l one, well, either we need to say we're comfortably accepting the cost and we're comfortable accepting social consensus happening on there, which is highly expensive, or we find ways to do it either on other systems, which for us is like restaked ETH. So we have a subset that we're working with, or like Misha mentioned, off chain. But then the question becomes, who is doing the computation off chain? How do you verify off chain and bring it to on chain? Open questions there to be fully transparent, but again, very much something that's still in design and about to go into effect. And we'll have more and more docs on this explaining some of these use cases, actual integrations as we come forth with the execution of the design.
00:27:37.890 - 00:27:55.190, Speaker A: I have a question for you via specifically. You guys can weigh in later. Was there any technical reason for limiting the protocol, at least for now, to ETH and certain versions of staked eth only? Or is it purely a business decision?
00:27:57.660 - 00:28:47.808, Speaker D: That's a great question, actually. Have we considered the idea of doing it on other ecosystems? Yes. Do we think, is it a business decision or is it an operational decision? Because the amount of time that it takes to build these protocols is not trivial. And so I don't think that we would be able to execute on multiple ecosystems simultaneously. Quite frankly, it takes a 70, 80 person team on labs, plus a foundation team, plus the man hours of multiple people over years to do it on one ecosystem, much less multiple. So if you want to classify that as a business decision, for sure, but also like a strategic one and also a time driven execution one. A focus theory problem.
00:28:47.808 - 00:29:07.430, Speaker D: You can't focus on multiple ecosystems at the same time. It just becomes very fragmented and very difficult. Who do you have your smart contract engineers work on? We would need to scale to such massive team in order to just have contract engineers on Solana, on Ethereum, on each of these ecosystems. So that's kind of the problem also.
00:29:07.850 - 00:29:22.936, Speaker A: But I also meant in general within ETH, accepting tokens that are non eth token, not ETH denominated tokens, maybe even some random meme coins. I don't know how far you want to push this field. That's what I meant, yeah.
00:29:23.008 - 00:29:47.296, Speaker D: As in what can be deposited into these restaking protocols. Yeah, that's an interesting one. Right. For us, it's about the ability that Ethereum provides in terms of native slashing on the l one. And when you introduce meme coins, it's not clear that you would be able to identify ways to slash those systems.
00:29:47.368 - 00:29:49.100, Speaker B: Can you just present to the zero address?
00:29:49.480 - 00:29:49.880, Speaker D: Sorry?
00:29:49.920 - 00:29:51.168, Speaker B: You can just send to the zero address?
00:29:51.224 - 00:30:12.380, Speaker D: No, no, that's fair. But at the same time, is there enough economic security in those systems to be able to be viable? Where, like, the stability versus agility problem, like, is there enough stability on those meme coins for things to be built on top of and for you to undermine your entire protocol on these highly unstable systems, whereas, like, ETH is a far more stable asset.
00:30:14.160 - 00:31:14.424, Speaker C: We talked about, like, flexibility and the vision that needs to be as wide as possible. Yeah, like, meme coins won't be interesting for people for a long time. But restaking is, again, restaking is not something a lot of people understand correctly, I think it's not. Just like we have a stable asset and we use a lot of networks to secure it with this asset for bigger protocols. Restaking works completely differently, like Uniswap, when they're going to be building their off chain parts. Won't expect other networks to use the unitoken for their security, but the big protocols can use their own token to restake multiple off chain parts. Defy is getting really complicated, and they need that token to align every off chain part to be secured within the ecosystem.
00:31:14.424 - 00:31:48.410, Speaker C: So it's not like, yeah, we don't have enough security in Ethereum, we need to add some other tokens. It's not about that. It's just the bigger protocols that, the tier ones that want to use restaking because it's useful, not because it's hyped or market oriented. They don't want to use Ethereum. Why would they? They have billions of circulating supply of their own token. They want to create additional utility for that while securing the network. So like it's not about like just like if or not if, it's about giving the industry as wider chance of success as possible.
00:31:51.230 - 00:31:59.622, Speaker A: So in your vision in the future, we'll see like a basket of different assets securing different, yeah, yeah.
00:31:59.646 - 00:32:34.090, Speaker C: Like the inner case, the Hina cases is like the demonstrator case. They want to create an interop with their governance token and stablecoin as a base. And then after they create interop they will actually vertical. For these protocols you have a governance layer that is like zero risk of slashing, everyone can join. The other layer is like you have an app chain with sequencing or something like that. You can get slashed. The risk is really minimal, but you can get slashed.
00:32:34.090 - 00:33:22.600, Speaker C: It's used for attestations, it's used for scheduling, but if you have scheduling you have MeV and you might want to stake that as well. And if you have scheduling, your confirmations are not the same as one entity SQL database. So you need probably pre confirmations or some finality gadgets or something you can stake there as well. And then you need oracles, market makers in infinite case they use exchanges. So they need a lot of chain workers that do stuff for them. And you can smoosh it together and gold staking, but you lose a lot of people because the risk profiles for each activity are completely different. Like institutions would never like go to the big ones, but they can use voting and scheduling or something like that.
00:33:22.600 - 00:33:32.344, Speaker C: So when you do each layer as opt in, what's that called? Restaking, cross staking, shared security. Yeah.
00:33:32.472 - 00:34:24.040, Speaker B: Can I ask a question that I think kind of goes more at the heart of what I thought maybe the panel would be about is I feel like economic security definitely matters in a world of actual proof of stake where everyone is staking their own tokens. I think that's actually much more similar to what proof of work actually is because every miner is actually spending their own hashrate in proof of stake. In the reality we've just seen that the operators are not actually staking their own tokens anymore. It's all delegation basically, for the most part. And so at that point everything is just reputation based anyways. So why are we even bothering with this proof of stake thing at all? I think the real question is, does proof of stake matter? Should we have just actually switched to some more poa kind of system instead? Does economic security behind each operator actually matter?
00:34:25.710 - 00:34:27.930, Speaker C: Who's going to be gating this poa?
00:34:28.470 - 00:34:30.690, Speaker B: Some initial set, right?
00:34:31.550 - 00:34:33.598, Speaker C: No, the, wait, wait, why?
00:34:33.734 - 00:34:55.650, Speaker B: Every token starts with some initial. Every proof of stake system started with some initial distribution, right? So you just start any POA system with some initial distribution and then that initial distribution votes on the change, right? Like you can say, hey, okay, I started with these 20 initial entities and now we vote to change those add or remove entities.
00:34:55.950 - 00:35:42.980, Speaker C: Yeah, like in us, it's the same if you're like in us, you take electoral college, you get to the first election and then start. Stop asking people like, you already have your delegates, right? Why would you need people after that? No, no, they need like in a lot of cases, I agree with you completely. In some cases, like the reputation already superseded the staking as an actual source of stability and security. But in mainstream cases, I think the stake is really important by gating the operator list still in the systems where there are hundreds of thousands of participants. Otherwise it's super easy to get to oligarchy.
00:35:45.410 - 00:35:57.110, Speaker A: My question is to you, Sonny, isn't it better to just have dpos, which is permissionless, but it's also kind of POA because you delegate to the people who have the best reputation, et cetera?
00:35:57.570 - 00:36:34.280, Speaker B: Yeah, but I don't understand why I actually have to stake on them. I can maybe have it so like, oh my token holders can vote to add in people, but I don't know why not do the dpos? It just opens yourself up to attack vectors. That can be, if you don't have enough economic security, you can be exploited by it. Let's just close those attack vectors by not even being fully permissionless. Obviously this depends on the application. I'm just saying that in practice most proof of stake systems have. Unless you're operating with anonymous, enforcing anonymous validators.
00:36:34.280 - 00:37:08.890, Speaker B: I think that would be interesting. Some chains have actually Thor chain did something in that realm where they try to enforce all their validators, be anonymous. And now you could do something where, ok, every validator is staked and use some inter subjective slashing to say that hey, if someone can dox the identity of a validator, we'll slash them or at least kick them out of validator. That's interesting, but that's not what most chains are doing, most proof of stake systems are doing today. Definitely not what most avss and stuff are doing today. So like, why are we bothering with that?
00:37:09.220 - 00:37:39.796, Speaker A: But I would argue that this system is not very scalable because any proof of stake system at some point degrades the delegate of proof of stake. It's just not sustainable for everyone to run their own. So the approach that you mentioned with anonymity and stuff, I don't think it works on like the scale of Ethereum. For example, you kind of need delegation. And I think it was a mistake for Ethereum not to enshrine delegation into the protocol because it introduced a lot of third party risks, etcetera.
00:37:39.908 - 00:38:02.060, Speaker B: Yeah, look, I think there is like a case for like, you know, maybe the l one to have it. I'm just talking like most applications, right? Like most things I see, like trying to be avss right now, those are the ones I don't think actually need there. Like, or would probably be better off as like POA system. Sometimes I think, I wonder if like osmosis should just switch to like a POA system rather than proof of stake.
00:38:02.180 - 00:38:11.110, Speaker A: But isn't the argument there that slosh kind of adds additional security that POA wouldn't have the economic security on the.
00:38:11.270 - 00:38:28.050, Speaker B: Most of the security right now is like coming like all the top validators of osmosis, but also of Ethereum, but also they're all like the same entities with a lot of reputation at stake. And I think their reputation is more valuable than actually, like the stake amount at slashable.
00:38:28.670 - 00:38:43.550, Speaker A: I would agree that the reputation is valuable initially, but my question is more than, because if you have slashing, you can always fall back to it. Whereas if there's no slashing and you have POA, essentially, if the reputation is not enough, you're essentially screwed.
00:38:44.130 - 00:38:46.930, Speaker D: There's no economic cost to misbehavior. Right?
00:38:47.050 - 00:39:03.680, Speaker A: There is economic cost, you can argue if you can get sued, etcetera, but it's just like, it's a very long and arduous process in slashing. It's basically, especially with objective slashing, it's one condition and that's it. You get slashed, then that's it.
00:39:04.980 - 00:39:47.300, Speaker B: Yeah. I mean, I think it's like it depends on the type of fault, right. And how much coordination there is to do an attack, right? Like if it only takes one entity to do an attack, I actually think that their economic security matters more. Right. But if it takes like a coordination of like a larger set of entities, I think, like, the coordination cost is like exponential and the chance of someone ratting you out or like, you know, is just so high that I think that's what actually, like, you know, I think what stops, like, you know, we always say, like, oh, what if coinbase and Lido just colluded to attack Ethereum? It's like this massive reputational, like, cost of them doing that kind of thing.
00:39:48.240 - 00:39:49.736, Speaker A: Yeah, I guess.
00:39:49.888 - 00:40:01.410, Speaker B: And none of the assets are there. Once again, this goes back to the point that none of the assets are actually theirs anyway. So it's nothing, their economic cost to stop them from misbehaving. It's their reputation that's stopping them from misbehaving.
00:40:04.350 - 00:40:07.130, Speaker A: Yeah, I guess there is a point there. Yeah.
00:40:08.110 - 00:40:12.406, Speaker B: Cost as well, but not the operators cost. Right. That's the point.
00:40:12.438 - 00:40:13.450, Speaker C: Operator's cost.
00:40:14.950 - 00:40:18.366, Speaker B: But it's not the economic stake that's lashable. It's not their stake.
00:40:18.398 - 00:40:22.762, Speaker C: Yeah. It's time value of which future cash inflows for operator business.
00:40:22.886 - 00:40:25.290, Speaker B: Exactly. So that you don't actually need the economic stake there.
00:40:25.330 - 00:40:25.482, Speaker A: Right.
00:40:25.506 - 00:40:25.946, Speaker B: That's all.
00:40:25.978 - 00:40:28.790, Speaker C: Like that. You're paying validators too much.
00:40:30.770 - 00:40:32.378, Speaker B: Okay, so that doesn't answer the question.
00:40:32.434 - 00:40:44.670, Speaker C: Yeah, like, the amount of risk, it influences the amount of capital inflows. Like, if you decrease the amount of economic risk, you decrease the amount of economic inflows to a validator business.
00:40:46.170 - 00:40:48.594, Speaker B: So can you explain that the more.
00:40:48.642 - 00:41:09.070, Speaker C: You'Re risking, the more money you can get for this, for the operation of a lot of stake? If you decrease the risk model for stake, you can, like, basically, yeah. The amount of money the businesses of validators can extract will decrease as well. This is like basic theory, game theory.
00:41:09.230 - 00:41:10.382, Speaker B: It's not a good thing.
00:41:10.526 - 00:41:20.496, Speaker C: No. You want to pay your operators enough. That's how it works. Do you know, like, DevOps are really expensive.
00:41:20.608 - 00:41:31.384, Speaker B: Sorry. Okay, so you're saying that by making people give money to others, right. You're increasing the money that they can earn off of it.
00:41:31.432 - 00:41:31.640, Speaker A: Why?
00:41:31.680 - 00:41:32.472, Speaker B: What are they doing with it?
00:41:32.496 - 00:41:34.056, Speaker C: Like, they're risking it.
00:41:34.208 - 00:41:35.860, Speaker B: They're risking it.
00:41:37.400 - 00:41:48.704, Speaker D: Well, I think. Okay, but operators that are validating for services that are naturally more risky should be compensated for the additional risk that they're taking on. Right? Is that your point, Misha? To some extent?
00:41:48.832 - 00:42:34.046, Speaker C: One of it, yeah. Like, yeah, there is a lot of research on, like, proof of governance where basically the main risk for you is to get kicked out of the list. Just. And it makes a lot of sense. But I think in open ended systems that require thousands if not hundreds of thousands of operators you still need this base of risk, like billions of risk because that brings actual good risk managers that can be paid by it because the base of the risk is quite big. If it's only $100,000 this operator gets in one month, the talent that you can acquire into validator business will be not as great as it is right now.
00:42:34.118 - 00:42:42.130, Speaker B: So I agree. If it's 100,000 operators that's more what bitcoin mining is. That's not what any actual proof of state system is today.
00:42:42.250 - 00:43:02.830, Speaker A: Unfortunately we've run out of time. I really enjoyed this conversation. I was trying to intervene for the last two minutes but I was like this is too interesting, I can't intervene. Yeah, unfortunately we run out of time. But thank you for coming. It was a great conversation and thank you all for listening and give them a round of applause please.
00:43:03.290 - 00:43:03.730, Speaker D: Thank you.

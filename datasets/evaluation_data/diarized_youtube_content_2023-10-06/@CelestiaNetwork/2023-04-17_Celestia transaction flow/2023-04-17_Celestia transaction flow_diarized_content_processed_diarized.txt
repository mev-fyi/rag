00:00:03.850 - 00:00:59.790, Speaker A: Okay. So yeah, I'm going to present a kind of like end to end transaction flow of what a typical transaction on Celestia will look like. And we've done this every onsite and it's important that we go through this again, but only for the new team members to understand what are we building as a product, but also for the existing team members so that they're reminded regularly so that the big picture can fit into everyone's mind. To see how you're working on fits into the big picture of all the other components in their modular stack. But I'm going to be kind of like presenting on this from a very specific angle. I'm going to be presenting what the end to end transaction flow will look like specifically for optimistic roll up on rollkit that uses Celestia as a DA. But obviously there's of course other roll up frameworks like SDK for example, opstack and so on and so forth.
00:00:59.790 - 00:02:02.014, Speaker A: And they might have slightly differing architectures, especially if it's a ZK roll up, but this should still help you understand the general concepts. So let's start with from the perspective of the user, what does the end user ideally run on their machine, like a user that wants to use a roll up. So first of all, one of the core components of celestial is that this idea of light node. So unlike most other blockchains, like Ethereum for example, the way you interact with the chain is that you run a MetaMask wallet but you connect to a centralized service, what's called a centralized RPC endpoint like infura. And that centralized server runs the ethereum node and tells you what the state of the chain is. But that's one of the kind of like biggest problems that need to be solved with Web Three. Right now the whole point of web Three is that it's supposed to be trust minimized and that users should be first class citizens of the network.
00:02:02.014 - 00:03:24.870, Speaker A: So that's why we've kind of like put a heavy emphasis on making sure that people can run light nodes that connect directly to their network and can get information directly from network instead of having to connect to some centralized service. So the first thing that the user is expected to run, and a user, by the way, could be like an exchange or a company or custodian or anything like that. The first thing they're expected to run is the celestial light node. And then celestial light node does a few things. It connects to the celestial peer to peer network and you can interact with full nodes in the peer network to ask it for what the state of the network, what the latest blocks are. And it also performs something called data availability sampling. So you have this Lester core network, which I'll draw that in Blue and then in this, in this core network you have these less juffled nodes.
00:03:24.870 - 00:04:21.510, Speaker A: In this case I'll call them, they could be validators as well. But I'll be going to refer to full nodes as a general concept that also encompasses validators. Yeah, but I'm also referring to storage nodes. Well, because they don't sample light nodes don't sample from consensus nodes, they sample from storage nodes. So I'm just going to refer to them as full nodes for now. These full nodes are connected to each other in the peer to peer network. These light nodes, they can sample block headers from the celestial network.
00:04:21.510 - 00:05:21.750, Speaker A: So the celestial network, celestial network produces celestial blocks. What is inside the celestial block? A few core components. But the most important component is this concept of a data commitment called a data route. So which we call data route. What this data route is, is basically a Merco tree of all data in the chains of these mercury are like the data that people have submitted to this lecture. So these are like called data blobs. Like data blobs could be different lengths.
00:05:21.750 - 00:06:04.930, Speaker A: You could have like a data blob that consists of three pieces in the tree or like two pieces. So all of these distinct things are like data blobs. And light nodes can check proof that they can receive these data blobs and check a proof that they've included it in the data route via merkel proof. So now let's go back to the end to end transaction flow. It's going to become more clear how the light node interacts with the network. When you run on solid light node, you're also presumably also going to be a user for a roll up. So there's also going to be like a roll up network.
00:06:04.930 - 00:07:38.482, Speaker A: And this like roll up network also has its own full nodes that are also connected to each other. And then the user also has to run on their machine not only a solid light node, but also a roll up light node. So now let's, now let's say that the user wanted to submit transactions network. Let's look up what the transaction flow is like. Where does that go? The user constructs the transaction, let's call like TX on their local machine and then they send that transaction to a full node on the roll up network. So let's say they send it to a full node on the roll up network and that full node gossips it to other full nodes and then they all receive like the pending transactions on the chain. Does anyone have any questions so far? Someone said something? Okay, and then what did the folders do with this transaction? They put it into or they sequence it into roll up blocks.
00:07:38.482 - 00:08:21.490, Speaker A: So I mentioned that there's celestial blocks but there's also another thing called the roll up also has its own chain. And that chain, the data of that chain, the blocks of that chain gets posted into Celestia. So a roll up is basically like a chain inside a chain. And to visualize that so let's see what that looks like. So the full nodes collect these transactions and these full nodes could be sequences and then they produce these roll up blocks. So let's say like this latest block, it contains the user's transaction TX. So then they've created this latest roll up block.
00:08:21.490 - 00:09:37.690, Speaker A: What did they do with the block? This block has what's called a it's what's called has what's called like a commitment. How to describe it? Yeah, let's just call it a date commitment for now. This date commitment, what is this date commitment is also a merkle tree. So let's see what that looks like. So let's say it's just a Merco tree of four and part of that merkle tree could be the user's transaction. Now, the key thing to realize is that what happens is that the roll up sequencer, they post this block data into the celestial network. So this block gets posted to the celestial network and then it gets included inside a celestial block.
00:09:37.690 - 00:10:19.590, Speaker A: And then this roll up block could be inside the actual celestial block. For example, it could be one of the blobs. Like here it's color coded red because this data is inside that data. And then the key thing to realize is if you look at this data commitment here, this data commitment is a medical tree in itself, but it's actually a subtree in this bigger tree, for example. So this is four. So let's face this is the data blob. This smaller tree is actually inside this bigger tree.
00:10:19.590 - 00:10:33.740, Speaker A: This data here in the tree is the same data as that. Does that make sense so far? Does anyone have questions? Yeah.
00:10:34.670 - 00:10:58.370, Speaker B: Reason you can kind of use that like one one mapping is because of namespaces. Because the namespace you kind of are locking into all of this block data can stay together in this namespace as that subtree versus if you just put all the data together it wouldn't necessarily match the same. It might bleed over into other trees.
00:10:59.690 - 00:11:19.100, Speaker A: Well, the namespaces aren't actually necessary component for this to work. The namespaces are more like an optimization to make it possible for people to later download this data to know where it is. So instead of them having to search the whole block, they only have to search the namespace for that data.
00:11:24.130 - 00:11:29.870, Speaker B: It doesn't have any impact on the way that block tree is balanced.
00:11:31.010 - 00:11:33.520, Speaker A: That's the implementation detail. Basically.
00:11:35.330 - 00:11:40.670, Speaker B: The thing is that the leafs and the data route are the chunks, right?
00:11:40.740 - 00:11:40.938, Speaker A: Yeah.
00:11:40.964 - 00:11:45.070, Speaker B: Whereas the leafs and the data commitment at the top are the actual transactions.
00:11:45.150 - 00:12:28.494, Speaker A: No, they're actually also chunks. They should also be chunks. Yeah. This is what the new Blob module API is supposed to achieve. There's this new Blob module API in node where you can add data to it, you can specify the data and you can call a function, say calling called commit that computes the commitment for you. It commits what this substitute route is so that when you post it to Celestia, you know it's going to be in the tree, if that makes sense. And then the user's transaction kind of ends up in Celestia here.
00:12:28.494 - 00:13:27.010, Speaker A: So summarize so far, I've described the entire read mean the write flow. How does a user write data to Celestia? To summarize, the user submits a transaction into a roll up network to the sequences in roll up network, they make a roll up block and that roll up block gets included inside this Lester block. And then that transaction, the data of that transaction is inside this lecture block. That's the kind of write flow so far. Now let's look at the read flow. What do I mean by read flow? Now we've talked about how does the user add data to the chain, but how does the user read data from the chain? Like how does it read this balance, for example. So to understand that, we also have to understand that the roll ups blocks have something called a state commitment.
00:13:27.010 - 00:14:28.646, Speaker A: I'll do it in a different color to signify that this is the read flow. I'll do it in green. But first of all, what do we mean by state? This is for assuming this optimistic roll up. But what do we mean by the state of the roll up? By state we mean it's like kind of like imagine an Excel spreadsheet that says what everyone's balance is. If you imagine it's like an Excel spreadsheet and then you have two columns. The first one is like name and then the second one is balance. So you might have Alice and Bob and then let's say they have like five coins each or something.
00:14:28.646 - 00:15:02.020, Speaker A: This is what we mean by state. The user might want to see, okay, please tell me what Alice's balance is. What is Bob's balance? And that's what we mean by state. We need to know what the state of the chain is and the rollout block, they commit to the state of the chain using a merkel tree, using a merkel route. And it's very similar to this data commitment from merkleroot. But instead of committing to the transactions that happened, it commits to the state of the chain. So it might look something like this.
00:15:02.020 - 00:16:07.510, Speaker A: This is like a very basic example, but if it was a sparse macro tree, let's say it's like a four leaf tree. Part of the tree might say like the Alice equal five and other part might say like Bob equal five. And that kind of like it commits to the state. This route commits to the state of all the balances in the roll up. So now how does the user kind of like know what Alice or Bob's balance is? So what happens is the roll up network's, full nodes, they need to be able to synchronize new roll up block headers posted to the celestial chain. So then there's this kind of like read flow back from the celestial chain back to the roll up network. So these block headers, they are read by these roll up full nodes.
00:16:07.510 - 00:17:36.230, Speaker A: There's this kind of information flow going this way roll up block header the actual roll up blocks themselves. How do these roll up folders? What kind of query do they make to get these roll up blocks? So in Celestia, we have this concept of namespaces where each like when you post the data blob to Celestia, you can specify what namespace is associated with a blob. You can kind of think of it like a twitter hashtag or like a channel on a walkie talkie. If you tweet something and then a specific hashtag, people can later search for that hashtag to see what people have tweeted under that hashtag and anyone can tweet under that hashtag. So a namespace is kind of like the same thing for a blockchain. You can post data to a chain under a specific namespace and then people can later search the chain for data under that namespace. So that roll up chooses its namespace and then it calls API, called celestial node, called get data by namespace, data by namespace.
00:17:36.230 - 00:20:01.470, Speaker A: And then the roll up full nodes, they send the header of the roll up. And by header, what we by header is the actual roll up block, everything about the roll up block, everything inside the roll up block except for the actual transaction data itself. So they send to the light client basically like a roll up header. What does that consist of? It consists of the state commitment and data commitment and then because the light nodes have the state commitment they can also ask the full node hey, can you please tell me the balance for Alice? And then once the full node responds to the light node it has to prove that that's Alice's balance and how does it prove to that prove that? It proves that by using something called a merkel proof the robot folder can't just tell the light node alice's balance is five believe me, you can't just do that. What it needs to do is say like alice's balance is five and here's a proof for it and the proof is basically like what's called a Berkeley proof it shows a path from the root to the leaf. It shows that this commitment is actually committing to the fact that Alice's balance is five the problem here, which is kind of like Wesley exists does anyone know what is yeah, but before that what could the roll up full node do maliciously in this flow telling the user yeah, so what could happen? Is that what happens? Because the trust assumption for Walt network is that we need to assume that the full nodes are dishonest. What that means is that the full nodes might be committing to invalid roll up blocks, they might be generating invalid roll up blocks and what does it mean to generate invalid roll up block.
00:20:01.470 - 00:21:09.390, Speaker A: It means they might introduce a malicious transaction in the block that, for example, prints more money and gives it to them or steals someone's balance. For example, they might add a malicious entry to the estate, I say like Charlie or something. And they put the balance is like a thousand or something. But according to the rules of the roll up, there's no reason that's not a valid thing to do. According to the rules of roll up, you can't just give someone money that doesn't exist, but they might create a roll up block that has such a transaction in it because we can't assume that they're honest. Because the whole point of roll ups is that they're trust minimized so that you should be able to have a roll up with a single node and you don't have to trust that node because the whole point of a roll up is that you can create your own blockchain without having a secure or valid data set. The way that optimistic roll ups deal with that case is that they use fraud proofs.
00:21:09.390 - 00:21:51.898, Speaker A: And the general idea for fraud proof is that it's called state transition fraud proof. If you assume that every roll up has something called a state transition function, let's say like STF for short, you can think of the state transition function is basically a black box. What does that black box do? That black box takes in two things. It takes in two things. You put two things in that black box. The first one is new transactions, like, let's say one transaction. And the second thing is that you put the state inside that black box.
00:21:51.898 - 00:22:59.086, Speaker A: The state, again, as I said, is this spreadsheet that tells everyone's balances and then what is the output? It outputs the new state. But this or an error, basically, and it returns the error. If you put an invalid transaction, like if you put a transaction that says give Charlie a thousand coins, let's say the input transaction is like, give Charlie increase his balance by a thousand coins or something. It could be like an invalid transaction, for example. But in that case, that state transition function should return an error. It shouldn't return a new state, which halle's, balance is 1000. So it turns out, like, you can prove to a light client that the roll up full node committed to an invalid block.
00:22:59.086 - 00:23:49.810, Speaker A: And it's pretty easy to prove it to them by giving them the right data. And the data that you need to give them is like the following. What does a fraud proof consist of? How do you prove that some roll up block has an invalid transaction with an invalid state commitment? What you have to do is you have to give them the state of the chain. You have to give them the state commitment of the chain before the transaction. This is what we call the prestate route. You give them the commitment to the state after the transaction, then you give them the transaction itself. Then you also give them what's called witnesses.
00:23:49.810 - 00:24:38.382, Speaker A: But I'm not going to go into that right now. It's not an important detail, but if you give a light client this information, what they can do is they have the information required to put these things inside this black box and see what came out of the black box is not the same as what the full node said should come out of the black box. And they say it doesn't match. So you can tell that the full node is being malicious. Like if that black box should actually reset the error, but the roll up full node says actually it doesn't reset the error, it returns this new balance. They can compare the output of this black box and see it does not match what the roll up said it would match. Yeah.
00:24:38.436 - 00:24:40.930, Speaker B: Can you give the gist of how the witness works?
00:24:41.080 - 00:25:32.834, Speaker A: So the witness is basically you have to give a medical proof of all of their state that the transaction accesses. In this case, this is kind of like a contrived example, but you might have a key for Charlie because you're accessing Charlie's key. So you would give them a record proof for Charlie's key. And they say a better example, this is kind of like a control. But let's say the better example is like this is what the transaction does. It subtracts a thousand coins from Bob and it sends a thousand to Charlie. That's like a straightforward transaction where you're sending someone's money.
00:25:32.834 - 00:26:21.170, Speaker A: What the force proof would look like in that case is you would have to give a medical proof for Bob's balance and Charlie's balance. So it would be like this. And then the state transition function would turn an error because you can't subtract 1000 coins from Bob's balance because it's only got five coins. Does that make sense? Yeah. So now we understand any other questions about the fraud proof. Now, assuming that we have this fraud proof, who generates this fraud proof? So we have this other actor on the chain called well, it's not a specific actor, but basically any full node on the roll up network can generate these fraud proofs. Anyone can join the roll up network and become like a fraud proof generator or like a watchman of the chain.
00:26:21.170 - 00:26:52.860, Speaker A: So if there's a fraud proof, this node is honest, they can send a fraud proof to the light node. And if light node receives a fraud proof for a roll up block, it does not accept that block as valid. It rejects that block. It pretends it was never there. And you can also, for example, punish the pat. You can slash, for example, the full node that generated that block. You can have like a rule where we say we're going to slash them because maybe they put up some bond or something.
00:26:52.860 - 00:28:01.086, Speaker A: So now I've explained how fraud proofs work. But now there's another problem and this is where celestial comes in. Does anyone want to describe that problem? Yeah. So the problem is that just because we know how to generate fraud proofs does not mean that the data to generate that fraud proof is available. Because what could happen is that if the like if the celestial don't work or if the underlying data availability layer is malicious, what could happen is this what could happen is that the validators of the data availability layer they might only release the block header but they might not release the actual data that points is pointing from the block header. Like they might release this block header, they might release the data root commitment, but they might not tell you what this data actually commits to. So you don't know what data is in the chain, you only know here is what the commitment is, but you don't know what the actual data in the chain is.
00:28:01.086 - 00:28:44.734, Speaker A: And if you don't know what the data in the chain is, you can't challenge anyone. You can't challenge your roll up blocks if they're fraudulent, because you don't know if they're fraudulent because you don't know what the data is in the first place. And this is obviously problematic. This is like why roll ups need a data availability layer, because roll ups can't be responsible for their own data availability because then you have to trust the roll up operator. And the whole point of roll ups is that you shouldn't need to trust the roll up operator. So does that make sense so far? I think there's like a good analogy for it, something to do with football, something do you want to do?
00:28:44.852 - 00:28:47.200, Speaker B: Yeah, the analogy is that.
00:28:49.090 - 00:28:49.566, Speaker A: I think.
00:28:49.588 - 00:29:23.210, Speaker B: Of data vendors kind of like the cameras who are recording like a football game and when something happens and people want to see what actually transpired, they can rewind and look at the video recording, basically. And then if the referee is saying that there's something fraudulent that happened on the field, people can actually go and inspect and verify that fraud.
00:29:25.490 - 00:29:53.282, Speaker A: Another analogy is kind of like the court system. It's like if you want to accuse someone of murder or something, the best evidence, like you should have CCTV evidence, but if you have CCTV evidence, then you can't really prove it. So this is kind of like if no one is recording or if there's no footage, then you can't prove the fraud. Yeah.
00:29:53.336 - 00:29:56.900, Speaker B: Can you explain also why it's needed, for instance?
00:29:57.510 - 00:30:33.998, Speaker A: Yeah, so we've described why it's needed for fraud proofs, but only optimistic roll ups use fraud proofs. So why is data availability also needed for ZK roll ups? Because ZK roll ups don't use fraud proofs, they use validity proofs. So with ZK roll ups you prove ahead of time using zero knowledge cryptography, that the roll up is valid. So it's like whereas optimistic roll ups are kind of like they're kind of like innocent until proven guilty. Validity roll ups are like guilty until proven innocent. You only accept the block if you know it's valid using because the ZK proof proves it's valid. So there is no fraud proof.
00:30:33.998 - 00:31:44.138, Speaker A: So why do ZK roll ups still need data availability? The reason why they need data availability is just because you can prove to someone that the state is correct does not mean that you have actually told them what the actual state is and this could be problematic. So for example, like a ZK roll up might say you might advance the state but no one knows what the actual state is. Users don't know what their balance is or anything like that because the transactions behind that state transitions have not been published. So no one knows what the actual state is. And that's basically like a massive aliveness failure, but it's also potentially a safety failure if you assume it can be used for blackmail. Because the ZK sequencer could blackmail people by saying, I'm not going to tell you what the state is, and therefore no one else can advance the chain except for me, unless you pay me, or something like that. So in summary, you need data availability for ZK roll ups because you need to know what people's balances are for other people to build on the chain and advance the state and to know what the balances are and to even use the chain in the first place.
00:31:44.138 - 00:33:04.594, Speaker A: Does that make sense? So yes, I described how do the light nodes so that means when a light node receives a roll up header they can't just accept it as valid immediately. They also need to make sure they have some kind of guarantee that the data behind that data commitment in the roll up header was actually published to the network. Because if they can't verify that, if they don't know if it's published to network then they don't know for sure if someone can generate a fraud proof because the whole security of a light node relies on the assumption that the light node knows for a fact that if something's wrong someone can generate a fraud proof. But you can't generate a fraud proof if the data is not available. So before the light node accepts the roll up header into its software, it needs to first of all check in the first place to have some kind of assurance or guarantee that the data behind that roll up header is available so that it can be audited by someone that can generate a foolproof. And so there's different levels of security that you can do that for what we call like a super light client. The way that they would do that is because by the way this is kind of slightly wrong.
00:33:04.594 - 00:34:11.650, Speaker A: These arrows should be going into the roll up light node, not the celestial light node. But the way that they would do that is that remember the user is also running celestialite node. So the user also receives the block headers of the celestial chain. And so they have these block headers and they also know the data route of every block in the celestial chain. And remember I said the data for the router block is like a smaller tree in this bigger tree in the celestial block. So all they have to do technically to check that data commitment is theoretically available is check is received a merkel proof that this smaller tree the root of this smaller tree is inside this bigger tree using a merkel proof that's inside the data root and the merkel proof is just a path from the root to the root of this smaller tree. And that proves to the roll up that the data behind this roll up is actually inside this relationship block without needing to actually download all the transactions.
00:34:11.650 - 00:34:24.620, Speaker A: Net roll up. Because they don't need to download all of the entire transaction data, they just need to get the root node of the tree and check that it's inside the bigger tree. Does that make sense so far?
00:34:26.030 - 00:34:29.814, Speaker B: Yeah, that implies that the rollout header.
00:34:29.862 - 00:34:31.674, Speaker A: Or like the rollout data commitment is.
00:34:31.712 - 00:34:33.660, Speaker B: Always exactly the same as the.
00:34:35.550 - 00:35:20.794, Speaker A: Rollouts are not supposed to use it and Mt or something. They can use it under this. They would have to yeah, but there's other ways of constructing a roll up that does not involve this thing. But I'm just doing this explaining this. Yeah, this is the base case to explain there's other ways to do it. For example, instead of roll up block committing to a specific date commitment they could commit to say instead of committing to this tree they could just commit to say the data for this roll up is actually at this location in the block. So instead of committing to the root to the actual commitment of the data, they commit to a specific location.
00:35:20.794 - 00:36:30.226, Speaker A: So they say the data is at location number five from five to ten in the roll up selected block. But this isn't important for the sake of this explanation. So now I've explained why how do the light nodes verify that these follow up blocks are inside the celestial block? Now, the way that the process I've described so far, it only works if you assume that the celestial validator set is honest. Like there's two thirds of them are honest. If the celestial validator set is dishonest then they might as I said before, they might just release a block header but not actually release the data route the data behind the data route. So they might say the lackline might receive a proof that this data is inside the data route but the validators haven't actually published the data for real. So this is fine if you trust the validator set of Celestia but this isn't scalable because the whole point of blockchains is.
00:36:30.226 - 00:37:30.946, Speaker A: That the usual threat model for blockchains like Bitcoin and Ethereum have, for example, is that you don't need to trust the validator set for safety guarantees. Because if you trust the validator sets for safety guarantees, then you're basically giving the validator set the power to make invalid fate transitions or change the policy of the chain, or print money or steal people's funds. And that's not usually the threat model blockchain. The threat model blockchain is usually like you're not supposed to trust the validator set or the third parties. It's supposed to be a decentralized trust minimized network because of the fact that users can actually run nodes that verify the state of the chain and verify that it's correct. So no one has to trust the validators. But to achieve that, in this case, the naive way to achieve that would be simply to require roll up celestial nodes to have to download every single transaction in every single celestial block.
00:37:30.946 - 00:38:37.200, Speaker A: And that's obviously not scalable because obviously the more block data you have, the more resource requirements that nodes need to have. And that's kind of like antithetical to the value where users should be first class instead of network. If users have to download the entire chain, no one can run, people are not going to run nodes on their computer or something like that or anything because they can only run nodes on servers. So to fix that, that's where data availability sampling comes in. And data availability sampling is a technique that allows light nodes to verify that 100% of the data in a certain block has been published by only downloading a very small percentage of that block. And it does that by using this mathematical primitive called erasure coding, which I won't go into now. But the general idea is the light node downloads random chunks from that block and after you download enough random chunks they have a very high probability guarantee that the 100% of the data is available.
00:38:37.200 - 00:39:16.454, Speaker A: So if you download like 16 chunks, then you have like a 99% guarantee. If you download 32 chunks, it's like 99.99% guarantee. And then after a while if you have 100 chunks you have such a high guarantee that the probability of you being tricked is lower than a hardware failure. It's more likely that a photon or something will hit your Ram and flip a bit than it is for the data availability sampling to fail, if that makes sense. Yeah. So that's the so that's the end transaction flow.
00:39:16.454 - 00:39:19.340, Speaker A: So now let me know if anyone has any questions.

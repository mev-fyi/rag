00:00:03.200 - 00:00:53.540, Speaker A: Hey everybody, thank you for coming. I'm starting off this research series, but I wouldn't call myself a researcher. So I'm sure the next people will give you much better research than I will be presenting. But I'm really glad to have this opportunity. I recently got involved with Celestia and I actually came to it from an interest in researching Dows. And I had been doing a lot of research on how decentralized methods of organizing labor can create higher levels of productivity. And what's really cool is that the modular design that Celestia has can actually create a very high amount of innovation in the execution layer.
00:00:53.540 - 00:01:38.576, Speaker A: I've made this argument before and I've posted it online. So what I'm going to do is I'm going to talk about a few things adjacent to this point and then I'll try to show why I believe that a lot of innovation will happen on Celestia. But first I'll just talk a little bit about more about myself and what I'm working on. So I'm building a cloud services company, kind of like infura for Celestia. So what I'm doing is I'm re implementing a Celestia node. I'm listening to the networks and indexing the new blocks into AWS, and then I'm replicating the endpoint using serverless technology. And this can allow people to access Celestia nodes without running it on their own.
00:01:38.576 - 00:02:32.080, Speaker A: There'd be no upfront cost for them, no minimum spend, no DevOps effort, and they would have extremely high speed scale and reliability for any time they need to query a node. So if you're interested in using a service like this or potentially a future service cloud service offering based on Celestia data, please let me know. And we haven't launched yet, but I would love to work with and I get it. AWS. Some people don't like using that, but I'll talk more about why I don't think that there's any problem with a crypto company using AWS in the so, okay, here's the talk. So I want to talk about this concept that I find really interesting. It's called software.
00:02:32.080 - 00:03:40.948, Speaker A: Two. So this is something, I think it was coined by Andre Carpathy, who's the director of AI at Tesla. I'm not an AI expert by any means, but my understanding is that back in the when approaching a problem such as visual recognition, but also other types of problems that we now use AI to solve, they tried to decompose the problem manually so they would try to detect edges and they would build all these very complex systems. So it's a person, if they have an arm and a head and eyes and you detect those because they have this pattern of pixels and stuff like that. And these approaches didn't work for building complex software such as visual recognition. And over time, AI, and I promise this will get to blockchain eventually. But over time they started introducing machine learning into the process increasingly.
00:03:40.948 - 00:04:53.804, Speaker A: And they would engineer features and they would put that into a pipeline where they would train on a data set and you would start getting better results that way because it's very hard. There's so much variability in the type of work that machine learning does. The traditional engineering approach, which is called the approach by decomposition, where you basically break down the problem into a series of steps and you hard code what the software does. That doesn't work for very complex software. And as you can see here on this chart, and this is all from Andre Carpenthy's talk, this is not something that I originated, but over time, they basically discovered that it's more effective to step back and do less work. And what you want to do is here's the quote it's difficult to take millions of numbers that describe an image and turn it into a concept because there's so much variation. We want to step back and not design those features.
00:04:53.804 - 00:05:46.210, Speaker A: We actually want to lay out a skeleton of the architecture and leave much more to the optimization. We are stepping back, designing less, and things work better. So more modern AI models are actually you're running an optimization on a program space. So if you look at this dot in this circle, that's an implementation of some code. And it's not a very complex application. It's something that a human was able to write themselves. But there's also this large area here that this would be what software two would do is you would carve out a space metaphorically in the list of possible program spaces and you would run an optimization on top.
00:05:46.210 - 00:06:24.780, Speaker A: You would optimize on the program space to find an implementation that is the best. And so, for example, AlphaGo was done this way. They use this at Tesla. And there's all kinds of things you can do with. So one interesting example of this, and again, I promise that this will get to blockchain one thing you can do with this is as cool as Dolly. It just came out. I thought it was kind of funny that just as NFTs started giving Illustrators a revenue source, they got basically completely automated.
00:06:24.780 - 00:07:35.216, Speaker A: But what's important here to note is that what the engineers are building here is software that creates software, and they're creating software that searches for the software that they're trying to create. Okay, so how much can this be generalized? Because this is actually really interesting. You want to step back and say, can I create something that can create something better than I could create the thing that was going to be created? So this is what Andre says about it. He says anytime you have an evaluation criterion, such as winning a game of chess or go, you can apply this methodology. You can search the program space and you can actually discover through optimization by paying in compute the much better algorithms in that space. So this is something that requires a large amount of compute to do. So my kind of point here and again, this is just something that I'm thinking there's only so much that I can substantiate this claim.
00:07:35.216 - 00:08:30.048, Speaker A: But Web Three is a form of software too. So let me explain what that means and what the implications of that are. But first, before I do that, we need to go to in a political analogy. So central planning is a way that people have run an economy and they've used this to allocate resources and organize people at scale. And so countries have adopted this and when they have, it's never worked out. There's been massive shortages or overproductions and they would make too many of one thing and not enough of another thing. And there's actually a reason behind why this happens and the reason is that one, that knowledge is distributed in society across all of the individuals.
00:08:30.048 - 00:09:54.080, Speaker A: So if you think of this algorithmically, if you're running a computation and you need to access knowledge, access data that's stored throughout a network, you're going to need some way of retrieving that information for your calculation. And when you don't have prices, you're also unable to calculate trade offs. So what they do is they make it impossible to compute they make it impossible to compute the relative trade offs between different things that could be produced. Like for example, if you want to build a car or a house, both of them contain some amount of metal, how much should go to each one without prices, you can't calculate what the trade offs are between cars and houses. And furthermore, without the knowledge of everyone in society, you can't know what people would prefer to have. They wouldn't know things about what they know about the environment in which the house is being built or car. Basically when you go to at a large scale you lose your ability to allocate resources.
00:09:54.080 - 00:10:50.130, Speaker A: And a connection that I've made is that product management, meaning deciding what you are going to build, what engineers are going to build is a form of central planning. But there is a solution to planning an economy and this solution is to use markets. So markets are the greatest decentralized system that has ever existed. They yield amazing results. And this is a log scale graph. As you can see, it just goes up into the right and no matter how big or small a market is, it will deliver compounding growth and you get this really valuable price information when people are able to coordinate at scale. And as you can see, this is a decentralized process.
00:10:50.130 - 00:12:27.970, Speaker A: So here's some structural properties of markets that kind of support this take on it. If you compare it to bitcoin mining or BitTorrent, which are both things that are considered to be decentralized processes, they have these really great characteristics that make them very good on the internet, which meaning you can have untrusted people participate, you can require incremental contribution and they can contribute in parallel. So when you're thinking about doing something at an internet scale, you're thinking of the possibility of many, many people participating and you don't know who these people are, you don't trust them and they may not have a capacity that is very high in their contributions. So with all of these systems, like for example, you can join BitTorrent and there's cryptographic guarantees that what you're sending is what you're saying you're going to send. If you're in BitTorrent, you can just seed a few bytes of data and then you can go offline and many people can see different data or the same data and it all works together beautifully. So similarly though a market has this type of these characteristics, practically speaking, it is the only way that people have been able to coordinate to work together at scale. And I've written a newsletter article about this.
00:12:27.970 - 00:13:35.748, Speaker A: So Web Three allows us to and the reason I'm using the term Web Three is just because of the symmetry with software too. But Web three allows us to program markets so tokens and blockchains can create designer markets that can achieve specific goals, including building more software. And in this case it would be software too, since it is software that creates software. And the mental model I like to think about is basically that a human is a neural engine and you can have a cluster of neural engines and that would be the human colossus. And we have a lot of people coming online, entering the economy all around the world. And so it's very exciting to think about the possibilities when you can use a market to incorporate labor from many different people. And yeah, humans are just like AI humans.
00:13:35.748 - 00:15:04.980, Speaker A: They are optimizers, they optimize for profit and these are called incentives. We don't think about them this as an optimization problem, but that's because I don't think we've entered the era in which you can in any meaningful way program markets and design markets. But now we're at the stage where we can start to think about tokenomics is basically the field of engineering markets and using that toward harnessing people towards a productive end, basically. I think I kind of already covered this, but yeah, I mean, I guess I kind of already said all this stuff, but this fits the criteria. If you design a tokenomic scheme that can allow people to profit, that is an evaluation criterion and it can scale. So I've done some research on this topic and how this could be used for building social apps, but I haven't pursued this in terms of how you can build roll ups or blockchains. But I think that this is a valid research question and I think that people should be looking into it.
00:15:04.980 - 00:16:14.170, Speaker A: And for example, there is a lot of discussion about how certain projects have tokens when maybe they don't need a token and people say it's just for the sake of funding. But that kind of starts to look more reasonable when you think about that. It's basically funding the improvement of a search inside of a program space of possible implementations. And of course, someone would need to flush out that argument, but that could be a start. But more specifically, I think that there's already good reason to believe that there's going to be a high level of innovation on Celestia, even without taking into consideration these types of more advanced tokenomics plays. And this is again, because of the type of infrastructure that it provides to a market. So I was hoping that I would be able to use my computer to show this next part.
00:16:14.170 - 00:17:03.290, Speaker A: Okay, I think I can just do it from here. Okay, I actually already have this up. Can you see this? Okay, sorry, I wanted to walk through this thread that I had written on Celestia. So basically the idea oh, no, it's not scrolling. Sorry about this, guys. I'm not sure it's going to work. I can go here.
00:17:03.290 - 00:18:12.920, Speaker A: One annoying thing about Twitter is if you don't have I think it's if you don't have your phone number on your account, they restrict every image for you and stuff like that. Even though this is my own account, I can't even view it. So I'll just try to run through this. Basically, let's say that you're making a change to the EVM. There's basically two ways that you can do this. One is you can submit a pull request to the EVM, to the code base, but the problem is that you would need to convince people to accept your change, and that can take a lot of time. The other option is, if you don't want to be dependent, by the way, they may not accept your change.
00:18:12.920 - 00:19:28.240, Speaker A: But the other option is you could just hard fork it and then you have the complete capability of doing whatever you want. But when you do that, unfortunately, you're segmenting your project from the Ethereum network and so users are not going to necessarily want to come on and use your implementation. And under a traditional model before Celestia, this would come at a security cost to anyone who wants to come and use your project. So this is a disincentive for people to do your change. So if you want to make a targeted change that just simply optimizes the EVM, you're going to be at a severe disadvantage and Ethereum is going to have a significant moat in its current implementation. Sorry. The EVM is going to be basically stagnated because there's going to be a moat for people switching to any sort of competition.
00:19:28.240 - 00:20:40.178, Speaker A: So there's a lot of problems that this causes since hard forks aren't really viable. Even if you think that you could convince people to adopt your change, the problem is that you can't accept all the changes. So even if they were really fast at accepting changes and they made really good choices at accepting the changes. You can have a conflicting change that conflicts with someone else and you can be having different trade offs. And if you have an implementation someone else does, they're going to have to choose between your implementations. So this again causes, it prevents changes from being experimented with in the market. And so this is a problem because what it means is that there's a significant barrier to trying things and some things will never, it's impossible to try them.
00:20:40.178 - 00:21:48.250, Speaker A: And as a result, you end up being way more conservative in your choices of what code gets merged and what gets used. What you have here is like a distribution and these are the outliers. There's going to be very few changes, but these very few changes can have a very high impact and this can be the kind of crazy idea that revolutionizes the EVM. And just an example is bitcoin I think was a great example of something that everyone thought was not going to work when they heard about it at first. I know there's people who did think it would work, but most people that heard about it in the beginning thought who would ever want this internet money? And when it was actually brought to market, satoshi released the code and the white paper at the same time and it actually got adoption. And that proved that it was a good idea. So you don't get any of these types of ideas when you have just this one monolithic code base that needs to be, I mean, it needs to be conservative.
00:21:48.250 - 00:23:29.690, Speaker A: So and so going to this article that I had written, there's this important concept that startups have known about for a long time and it's called the rate of iteration. And basically the faster you iterate as a company, the more compounding growth you're going to experience. And the reason for that is because every time you iterate on your software, you're taking into consideration the new information that you have. So you're acting from a superior point of knowledge and you're also making a small bet that can have an asymmetric payoff and you can create a bunch of little S curves that can turn into exponential growth. And so when you are able to hard fork, when you're able to hard fork software, what's really cool, and this was the original research direction that got me interested in this, is that hard forks are done completely in parallel. And it follows that chart that I had shown earlier where you don't have to trust the person who's hard forking you and the person who forks the other person doesn't have to trust them as well as so it's untrusted. If someone does a bad job, that's okay, or they can do a good job and then that will be a success, but it doesn't drag down anybody.
00:23:29.690 - 00:24:42.034, Speaker A: It doesn't hurt you to be hard forked. Basically. It's a way of parallelizing software development. And so when you parallelize software development, you're increasing the rate of iteration because multiple iterations can be ran in parallel. And since this is a driver of compounding growth, since a lot of code is in common and ideas are in common, you can build off of each hard forks can build off of each other's work and merge back upstream or hard fork downstream. And that can lead to an acceleration in the obviously I just drew this, it's not like real data, but in theory, as your iterations increase, your output will increase exponentially. And unfortunately, what happens though is, as I was saying earlier, how central planning is.
00:24:42.034 - 00:25:40.660, Speaker A: Product management is a form of central planning. You get an iteration bottleneck here and this causes a stagnation in output over time. So as an organization, only five more minutes. So as an organization scales, you're not able to allocate resources as effectively. So anyway, I only have five more minutes, so I'm going to skip ahead here's. I think I pretty much covered all of this conceptually. So just going back to the presentation, I guess I just wanted to return to that point on cloud services.
00:25:40.660 - 00:26:54.774, Speaker A: I don't think anyone actually is thinking this, but it is something comments that I get a lot about. You don't want to depend too much on Amazon. And I think that one thing based off of what I was just saying, is that there is a moat in the Ethereum ecosystem to new chains and there's a lot of cloud services that support development on those ecosystems. And so providing cloud services to them can help, providing cloud infrastructure that can help new chains roll out cloud service offerings similar to that of Ethereum can actually increase decentralization and the rate of innovation because there's less reason for people not to switch to them. And it's normal to have a big provider like Amazon is a big provider of hosting. That doesn't mean that the Internet is necessarily decentralized. It's possible to have an over reliance on something, but there's also always a power law distribution in any network.
00:26:54.774 - 00:27:40.902, Speaker A: So someone is going to be servicing a large number of requests and a large amount of compute. That's a natural phenomena. And if something does go down, if people are relying on a service and it goes down, that doesn't mean that the network is necessarily centralized. As long as the network can recover, markets are decentralized and there's depressions, there's market failures of different sorts, but the market does clear those and recover. So I don't think that that's necessarily a problem. And if there is an over reliance on some piece of infrastructure, that's definitely something that the protocol should take into consideration and they should try to design that out. So anyway, that's all.
00:27:40.902 - 00:27:43.380, Speaker A: Thank you so much. I appreciate it.

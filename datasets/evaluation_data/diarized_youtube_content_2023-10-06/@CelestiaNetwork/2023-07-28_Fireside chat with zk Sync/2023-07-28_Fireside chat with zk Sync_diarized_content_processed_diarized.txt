00:00:00.330 - 00:00:00.880, Speaker A: You.
00:00:01.650 - 00:00:05.582, Speaker B: Thanks everyone for coming. Alex, it's great to be here with you, enjoying the week.
00:00:05.636 - 00:00:06.426, Speaker A: It's a pleasure.
00:00:06.538 - 00:00:38.502, Speaker B: All right, so we've only got about 20 minutes, I believe. And I want you to basically, I want to get deep in the weeds with you about ZK sync and what you're building at ZK Stack. Maybe we could actually start at a high level. I've heard you describe ZKstack actually as a set of architectures or frameworks for people who want to build appchain. So maybe we could get into some of the high level and almost like take us back to the room when you were originally ideating some of those decisions for Zkera. And then we can get into some of the actual components about what makes up the ZK stack.
00:00:38.646 - 00:01:17.502, Speaker A: Sure. So let's start with what is ZK Stack? We have been focused on Zksync ZK roll up technology for several years now. We released era. Era is the first ZkVM live on Mannet, and it's now the most popular ZK roll up. Also on Ethereum network. We are the most used l two by number of transactions over the last month and third by TVL. And we have seen a lot of interest in reusing a lot of interest from builders who want to create their own blockchains, their own roll ups, their own application specific chains.
00:01:17.502 - 00:02:01.918, Speaker A: And we realized that we should just open like, I mean, the code was open source from the beginning, but we want to adopt it in a form that makes it easy for anyone to build their own custom chains on ZK technology. So ZK stack is a framework. It's a modular, customizable framework that allows you to take our code and create your own custom ZK chains. You have a choice of all the different components. For example, you can choose the different data availability modes. It can be a on chain data availability mode, which make your chain a ZK roll up. It can be a validium, it can be a mix of both called volition, or we call it ZK Porter.
00:02:01.918 - 00:02:47.086, Speaker A: You can customize the sequencer, you can go for centralized sequencer or decentralized sequencer, which we're working on. Or you might use something entirely different and enrich the stack and share it with others. You can customize the way you deal with. Maybe you want to use your own token for some things. You have full control over all aspects of the stack. But really interesting property of ZK stack is it's designed from the beginning to be interoperable with other ZK stacks, other like what we call hyperchains, using a new primitive we call hyper bridges. This is something only possible if you start building in a shared ecosystem.
00:02:47.086 - 00:03:28.282, Speaker A: There are certain technical properties that you need to enforce. All of these chains have to use a shared base contract on layer one, or the shared, like people call it bridge. I don't like the word bridge for this thing, but it must be a shared thing. And then you need to use a common standard for passing messages and for transferring assets. And this is really powerful because then the hyperchains can be connected seamlessly and trustlessly in a huge unified liquidity ecosystem, which can grow indefinitely, just like the Internet. So that's what ZK stack and hyperchains are in a nutshell.
00:03:28.426 - 00:03:57.358, Speaker B: That's a really helpful explanation there. And I want to get into the weeds on some of those individual components. I'd also actually even like to start a little bit more high level and just get some of the. What were some of the original design principles and problems that you were trying to solves for? So in talking about the hyperchain infrastructure, it's clear interoperability was a big sort of design decision or something that you prioritize in the beginning. Walk us through some of the other original problems that you were trying to solve with the ZK stack.
00:03:57.554 - 00:04:38.630, Speaker A: So we started Zksync with the mission to make blockchains universally accessible for everyone. So to scale blockchains while preserving the core values, the core properties that make the blockchains valuable, specifically public, permissionless blockchains. And I think by now it's very clear that Ethereum has crystallized as the. Well, I mean, to me, it's my personal take. Ethereum is likely going to be the settlement layer for most of the Internet of value. We'll have some alternatives, but for now, they will have to compete with Ethereum. So we're focusing on Ethereum, but we're making Ethereum modular and extensible and spreadable.
00:04:38.630 - 00:05:44.098, Speaker A: We have been thinking about what's the end state of this Internet of value have to look like, what must be the eventual. If we take the certain properties, we have to articulate them well, what do we want to preserve? And then we have to imagine, how does this look like at scale? So we had an intuition which has been guiding us on those properties. Recently we published something called the ZK Credo, which is a manifesto, a mission statement, mission philosophy, statement for the ZK sync ZK community in general, where we articulate very specifically, like we want trustlessness, we want resilience, we want censorship, resistance. The system must be accessible, affordable by anyone. Then the list goes on. There are, I think, eight properties there. And then all of that has to work at scale, meaning the systems have to be able to grow just like the Internet.
00:05:44.098 - 00:06:40.282, Speaker A: One of the properties is called hyperscalability. If you think of the Internet, it's impossible to. To conceive that all of the world's Internet transactions, web servers, application servers, are running on a single server or even on a single data center. It just physically won't scale, right? So you end up with a multi server, multi computational paradigm, which supports parallelism to arbitrary degree, where you can add more servers, more links, more data clusters to it, and it will just grow and absorb arbitrary number of users and arbitrary number of transactions and apply to the world of blockchains. This means you need to plan for a multichain world. And if we will have multiple chains running in parallel, they have to be connected the same way Internet services are connected. Like a simple example is an email.
00:06:40.282 - 00:07:12.886, Speaker A: You have your address. I have my address. Like Alex at metal apps, you have your address. Michael at. I don't know, Gmail or blockworks or something. You can send email from any address on any domain to any other address or on any other domain in one click. It doesn't cost you more in terms of effort time, like it will just arrive in a few seconds or cost the same with web pages and hyperlinks, you can go from any page on any domain to any other page in just exactly one click.
00:07:12.886 - 00:07:59.874, Speaker A: You don't have to spend more. This is the property of hyperbridges that we aim to preserve there. Or this has been the core part of our design. How do we create a multi chain system following the vision of the Internet, of chains first articulated by Cosmos and then Polkadot, that actually works. That actually gives you trustlessness, where you don't have to rely on validators of those bridges, on some custodians, where you have native assets that follow the bridging paradigm. When we say bridge, we think of pieces of land connected by something over water. So if you have a bridge between two islands, you have assets on one island, you have like a pile of gold there, or a car of gold.
00:07:59.874 - 00:08:46.670, Speaker A: You can just move it over the bridge, and so it will disappear on the first island and it will appear on the other island. But that's not how the bridges work today. What we have, like the interchange bridges between layer ones or sovereign chains work more like you have to park the car on one side, then you get an iou and then you go to the other side, like we swim over, and then you carry over this iou where the assets are actually in custody by someone else, which is not native, not extensible. Like, you have to trust those guys and so on. So we wanted to preserve this. And the only technology which we have today which is capable of doing it at arbitrary scale is decay. Your knowledge, proofs, validity proofs.
00:08:46.670 - 00:08:49.842, Speaker A: This is what hyperbaric hyperchains are based on.
00:08:49.896 - 00:09:12.214, Speaker B: So I really like that example of thinking about how the Internet scaled and how it can't all be on one server, obviously. But I think it's actually, if you maybe go one layer deeper and look at the interoperability of the current Internet, there is part of the web which is open, and then you start to see, like, closed off clusters or parts that are slightly less interoperable with other parts of the web. An example might be the great firewall of China.
00:09:12.262 - 00:09:12.426, Speaker A: Right.
00:09:12.448 - 00:09:52.220, Speaker B: And how the Internet works over there, or know government sort of restricted networks, or even, frankly, like Google or Facebook. Right, which are kind of open and interoperable, but what really are really closed gardens that want to keep you on their platform. So I would love to get a little bit more specific about how you see interoperability across different layer twos, because my sort of, in hearing you describe what the ZK stack will enable is a bunch of hyperchains that are highly interoperable with one another. But is the plan for that to be interoperable with other layer twos? Like either other ZK roll ups or like the optimisms or arbitrams of the world? How do you see big sort of layer twos interacting with one another going forward?
00:09:53.070 - 00:10:49.770, Speaker A: That would be an ideal goal for us in Ethereum, to come up with a standard that allows us to be completely interoperable. That would, unfortunately, require some very fundamental changes at layer one protocol. So we have to build some kind of common bridge that is designed for ZK architectures that is shared across all of us, and it is basically enshrined into the base architecture. Maybe one day we'll arrive at that. But first we need to experiment when we'll see this experimentation happening between different ecosystems, a few of them are experimenting with this kind of designs, with a local ecosystem of application specific or generic chains more tightly connected than just arbitrary roll ups. On Ethereum, we'll see experimentation, and maybe some standards will crystallize over time.
00:10:49.840 - 00:11:14.900, Speaker B: Got it. I want to actually get into some of the different modular components that you were alluding to before. So there's data availability, provers, sequencers, et cetera. Let's try to close our eyes and put ourselves from the perspective of someone who wants to build their own hyperchain on Zksync or using the ZK stack. How are they kind of thinking about what are the most important components kind of to tackle first and what are some of the options that they're looking at?
00:11:16.870 - 00:11:47.194, Speaker A: When I'm thinking from a builder perspective, my builder hat on, I'm thinking about properties of a system I want to get. I'm not thinking in terms of components. I'm thinking like what do I want from this system? For me, the priorities would be, number one, security. This is something non negotiable. If you're building a system, their security does not matter. You probably don't need blockchain. You're on blockchain for decentralization and for the ultimate security where every user can verify all the transactions.
00:11:47.194 - 00:12:48.210, Speaker A: So that is something highly important. And here ZK stack shines because this is one of the most bottle tested frameworks that we have today, with over half a billion dollar TVL on Ethereum and being the most used l two at least. For the last month, with 25 million transactions almost, we invested over $4 million in security audits, like various audits for all components of the system, with top tier auditors in security contests. We are having mechanisms for security defense in depth, with delayed withdrawals and various other techniques. And we're working on extending this thing because we have to keep in mind that all the roll up technologies are still relatively new and there can be bugs, and you want multiple layers of defense. Even if one layer fails, you still want to rely on others for security. So that's the security perspective.
00:12:48.210 - 00:13:55.122, Speaker A: The second property I would want from a system or from a framework to build my chain on is reliability. Like highly reliable liveness. This is critical for Defi applications, this is critical for your users, for the fantastic UX, because if your system goes down frequently for a prolonged period of times, you're not going to make it, people will lose trust and the system is not going to work. So you really want to take a bottle as architecture. And this includes also being able to accommodate spikes in activity surges in the demand for transactions. Let's say we're doing like ten tps on average right now, organic demand. But if the capacity was only like 20 tps, any event like a popular NFT mint drop or some token issue would bring the network to its knees, because a lot of people would try to reach it and we've seen it on other networks.
00:13:55.122 - 00:14:25.550, Speaker A: They are not capable of accommodating the actual lot. So this is why we knew that that's going to be an important factor. We did not take gas as the base for the chain. We started building our own custom sequencer, implemented rust from the beginning, and we're capable of doing over 100 tps comfortably now. And we're still working on making things like we're far from optimal. We can do thousands of tps, but the real lot has shows over 100.
00:14:25.700 - 00:14:41.000, Speaker B: Nice. And I think ZK sync, you guys were some of the early ones that really experimented with account abstraction as well, which just allows you so much more flexibility. So am I correct in assuming that creators of these hyperchains, they'll be able to specify whatever gas token they want?
00:14:42.090 - 00:15:23.630, Speaker A: Even the users today on Zksync era can specify what they want to pay their gas in wow. Or you can have sponsored transactions for certain users, they don't have to need any gas at all. Pay from smart contracts, or you can sponsor transactions from some accounts you have full flexibility. And we have account of section, indeed natively implemented at the protocol level. So it's not limited to certain types of accounts that you have to specifically deploy any metamask wallet, any other wallet on Ethereum can profit from it and can do gas less transactions or pay fees in any token.
00:15:23.710 - 00:15:37.678, Speaker B: Yeah, I want to ask you a couple of questions about sort of decentralizing some of the more centralizing parts of l two design today. Maybe we can talk a little bit about the sequencer and then also the state of the proverb, how proving is done on ZK sync.
00:15:37.714 - 00:15:58.110, Speaker A: Sure. So sequencer is for some applications. They will be happy with centralized sequencer, especially for high frequency transactions with low latency. But most blockchain use cases require full decentralization of the entire stack. We are very aware of this. This is one of the priorities we're working with. High priority on decentralizing the sequencer.
00:15:58.110 - 00:16:59.330, Speaker A: We will have some results in probably a few months from now, but it's kind of even a lesser priority than decentralizing the prover, paradoxically, because you need to be able to at least distribute the prover across many different types of distributed compute systems, cloud services, or user systems. Because otherwise, if your prover has very high computing requirements on the hardware, you're going to be locked into the most efficient cloud providers and they will have a lot of power over you. It will be able to just shut it down. This was very clear to us from the beginning. And we invested heavily in GPU optimizations. And recently, just this week, we announced Boojam, a new implementation of the proof system. Thank you orders are making it more performant than what we had before.
00:16:59.330 - 00:17:46.926, Speaker A: It's one of the fastest proof systems in the world. We joined benchmarks, or like seller network made benchmarks across multiple different implementations, which we published. And interesting thing is, our implementation of the GPU for this new proof system only requires six to 16gb of ram. We can bring it down to six by default. It's configured for 16, so you can run it on any gpu, on consumer gpus, on gaming computers, on anywhere in the cloud, on all the cloud services. Previous systems required hundreds, like 500gb of ram, which would be prohibitively high barrier for entry.
00:17:47.038 - 00:18:06.306, Speaker B: Right. So the idea maybe to state it for any five year old brain like mine is right now, if proofs are being done by one very large, expensive computer in an AWS sort of service right now, the idea would be to distribute that computation actually to hardware devices with very low or very cheap.
00:18:06.418 - 00:18:44.930, Speaker A: Well, right now, for existing EZK rollups, they are not done on one huge computer. They are done on many huge computers, parallel, which you have to spin up and shut down just in time, depending on how your demand fluctuates. So it's actually, if the systems are not efficient enough or have very tight specialization requirements for hardware, you might just run out of the hardware on those cloud providers. So like, you really want something very generic that can reuse any type of gpus designed for machine learning for all the generic kind of computations. Nice.
00:18:45.000 - 00:18:47.010, Speaker B: Sounds like a really easy problem to solve.
00:18:48.310 - 00:19:12.780, Speaker A: Well, zero knowledge proofs made a huge progress over the last couple of years, so we have very mature systems now. Indeed. It took work of many brilliant minds to get to this state. All the incremental improvements are not as hard as they used to be, like five years.
00:19:15.150 - 00:19:33.102, Speaker B: I guess. I know we've got to wrap it up here now, but yeah, as you mentioned before, to just give ZK Cinc a shout out. Yeah, the TVL has been going up into the right, transactions have been going up into the right. What do you tribute that success to? And then give us a little hint of what we should expect in the next twelve months. Anything you can share with the audience?
00:19:33.246 - 00:20:33.218, Speaker A: Sure. So we treat it more as a responsibility than a success at this stage, because we know that those systems are experimental, people are trying things out. The next step for us would be lowering transaction fees very significantly from where we are today. We have two paths for this one is the transaction or like data compression, which will soon find its way to Mainet and right now we're slightly above optimistic roll ups. Data compression techniques that optimistic roll ups already use would bring us below them, and on top of that we'll have some really interesting properties resulting from the fact that we use state diffs for data availability, not transaction inputs like optimistic roll ups. And like basically all the other EZK AVM projects that I've seen. Which means for certain transaction types we will be hundreds if not thousands cheaper.
00:20:33.218 - 00:20:57.434, Speaker A: Or in other words, you will be able to do many more of those transactions. Like think of Oracle updates can do 100 oracle updates for like 100 ticks of the same oracle update in the same batch and you will only have to pay for one data availability slot because you're constantly updating the same slot. And at the end we only have to publish this one delta which will open really interesting possibilities for whole class of applications.
00:20:57.562 - 00:21:01.610, Speaker B: That's really exciting. Alex, congratulations on the news and yeah, thanks guys for listening.

00:00:00.250 - 00:01:14.690, Speaker A: Today's knowledge session is about testground. The tool that I'm kind of super stoked to tell you about, and especially the topic of day, is for big network tests and to give you an overview. So far, in our playing field community, there was not a lot of, I would say, traction moving forward, what is happening, how you can basically do the testing there, and the vanilla approach of how we do testing, I would say web two world or whatever, is to have this big puppeteer that deploys everything that you need to be tested. And we kind of get used to that, mainly in integration testing, like in celestial node, where we have a celestial app inside deployed by a swamp instance. And the swamp instance basically knows when to deploy a light node, a full node, and a bridge node to test everything out. The big minus of it is that it is not that scalable when you want to take it to a bigger picture. And this is where testground comes in.
00:01:14.690 - 00:02:34.750, Speaker A: Unfortunately, test ground is not very, I would say, beginner friendly, written in a sense that documentation is kind of lacking. So I would like to play the analysis game to deal with you today so you can stay on the same page. So, to start, let's think about designing big network tests as directing a movie. And especially, there is one specific movie that I always think about when I'm doing test ground tests. And let's imagine right now we are Christopher Nolan, and we want to do Ducker. We have this awesome project where we're thinking about how to tell a story where there were a lot of parties involved, and we want the viewer to have a different perspective of the same incident. And this is important because when we look from a different perspective of a human being, we feel more attached and understanding of what basically has happened.
00:02:34.750 - 00:02:58.754, Speaker A: And the same falls down to test ground. Why? Right now, we're not the only team that is doing these tests. Why it is making so much sense. And, yeah, let's continue. The phase one is how you want to tell a story. So test ground falls. It's in the same category where we have the manifest topple.
00:02:58.754 - 00:03:59.050, Speaker A: This is where we want to know what characters do we need? Like in Dunkirk, you have a pilot, you have a soldier, you have a captain, and you have a bunch of marine soldiers. And the second question that every time we want to answer ourselves in test ground is, what do those prototype characters need to sell the story? For example, a pilot needs to know that he has a plane. And overall, all characters, they need to be synced that in one location. So you need a bunch of prerequisites that all the characters should be aligned and same. We have with manifest. An example here. When we are doing data availability sync across rich node, full node and light node, we want to make sure that all of them are aware of those parameters to be kind of like in the same sec.
00:03:59.050 - 00:04:46.786, Speaker A: And here we have execution time how much we want to execute the test. We have latency bandwidth, so we can pinpoint and say that some participants will have less bandwidth and more latency vice versa. We want to make sure that validators, how much persistent fears the validators have. And here the submit times and message size is where we are knowing upfront how much data will be put into the block. So we can crystalize just the whole story behind it. And imagine, like here I've written down ridge, full white block I can roll. This is kind of in a set of tongue curve.
00:04:46.786 - 00:05:27.890, Speaker A: Just imagine how much, like every soldier or captain knows how much of the army is on the opposite side. So this is kind of also in the set. And this is basically the manifest. It is, I would say, the overall prerequisite of what we need to know. And the role here, as last one, is where we want to take the perspective. So in test ground, we don't have the volunteer. That's why we need to combine different roles and know from which point we are looking at the test and the phase two, as we have Christopher Nolan, we want to do the casting.
00:05:27.890 - 00:05:55.710, Speaker A: This is where we have proposition on top. And the casting falls into three big groups. First is global. For example, we want to film it in France. We put down France params itself on the beach, which day to start filming it. And the groups, it's what resources each of the groups need and which params they need specifically for them. And the sync service.
00:05:55.710 - 00:06:44.670, Speaker A: This is where everybody's confused when they're learning. Test round is which specific shot of the timeline we're doing. So imagine it will be kind of strange in a movie where you see a different perspective of actors during daylight time, and then suddenly you see a different scene where Tom Hardy is flying on the plane during the night. It will basically make no sense and we will just lose the plot. This is why sync service is kind of the same. It gives all the actors all the roles, the baseline where they are in the progression of the movie. And on the right, I put down the test params, as you see the global one, where everybody's aware of how much validators they are, how much free nodes, full nodes, and write nodes.
00:06:44.670 - 00:07:15.190, Speaker A: Which size is the message size. This I would say important for validators. And yeah, for validators it will be important to have persistent peers and everybody know that this movie will last for 10 minutes. And the validators you can see here, there's a bunch of builders. It's just implementation detail. What you want to know is that there is latency and bandwidth down below of each group. And we have four groups.
00:07:15.190 - 00:08:08.870, Speaker A: First is valid, second one is bridge nodes, third is full nodes and fourth one is black. I haven't put down bridge nodes here for the sake of readability. But yeah, just bear in mind that bridge nodes are also shown in the composition file. And as you see here, we are allocating the amount of cpu and memory for each instance in sentiment group. Meaning that in the groups of validators, each validator, and we already know that there are 40 validators, each validator will have at least three core cpus and 4gb ram. And each of them have here is zero latency and the bandwidth is 256. All the same is for full nodes and light nodes.
00:08:08.870 - 00:08:49.778, Speaker A: Specifically at the light nodes you see here at this example, we have 100 light nodes in this group. And each light node will have two cpu, four gigabyte. However, they only have bandwidth of 100gb. And we have an assumption here from light node perspective that we will only get to the block height of ten in this test case. And then whatever else will be decided later on. So let's move further to the phase three. This is where it is from the perspective of go files, the scene shooting.
00:08:49.778 - 00:09:40.694, Speaker A: This is where we can dive in into the actor's perspective and know what exactly they are doing. Like what words should they say, how they can use the sync service to stay aligned. Like if it's 02:00 p.m. At the day, then what is happening with them and what should they say? And especially this is very important is what is the pivotal moment from their perspective. So as I said, for a light node to get to bulk out of ten, the pivotal moment for light node will be if we are designing the scene shooting here, is that we are keeping up with the chain. And because test case itself is kind of easy, same can be set for a full node and a breach node. Yeah, we can also assume that the whole scene should be like that.
00:09:40.694 - 00:11:01.962, Speaker A: Or from different perspective. And yeah, let's look a little bit at the code to show you the true colors of sync service. I would like us to imagine more, I would say a more to real life test case where a light node is syncing the past headers. It's not syncing the current headers, I mean that it is starting from Genesis, but let's say we started from zero, but the chain is already like a block height, 100. So what will happen from the dot profile perspective, as you see here, first line, we already see the barrier where we are waiting for events to be fired at us, saying that we need to be aligned, that the breach node has reached some blocks, some blocks production. Let's say here it is 100 and before, if the block height hasn't been reached and the bridge node hasn't fired that event, all of bridge nodes, we don't care. You see here how agnostic it is, this code that we don't care about which amount of the bridge node, how many of them should be, et cetera, et cetera.
00:11:01.962 - 00:11:54.602, Speaker A: We just know that some amount of bridge node should fire in event and we will not go further if we won't reach that state later on. As let's say 100 blocks had passed and 30 bridge nodes had said yes, we all reached to 100 locks. Then we started creating the light where we are saying that, hey folks. Yes, now we can start our light node and let's get the pivotal moment for the light node is we want to reach to a specific height. This is the pivotal moment for the light node. And we know that we can define that in the composition which was the casting. And here you see we are doing two important checks.
00:11:54.602 - 00:13:00.850, Speaker A: First one is that are we still syncing? If we're still thinking in the past, meaning that we haven't reached to the latest blockchain, then it means it's a failure. And the second checker, which is very important also to us from a litecoin perspective is the das status, meaning actually are we dashing the latest chain? So we first keep up with the chain as it is. Basically we have dashed the past headers quicker than the new blocks introduced. And we also caught up to the latest check. Those are the two checkers. And the beauty of this folk, as you see here, there is no, I would say, specific mentioning of how much bytecodes. And this is an awesome point where you can define, let's say you have 30 bridge nodes, but today you want 100 light nodes and tomorrow you say, I want 10,000 light nodes.
00:13:00.850 - 00:14:08.726, Speaker A: And this exact same code will work because this is the scene shooting of it. We can go back to the casting and basically imagine, I don't know, duplicating 10,000 tom hardies and saying everybody will fight play at the middle of the day and you need to do dog fighting in this guy and the premiere, how it should look. Let's say we are now scaling up, as I would say every viewer is test round itself is, I would say, the pinpoint mechanism, how much actors and how much roles we want. Inside the environment quadrant and the cookbook is our composition. It's the casting who is playing what. And inside the environment quadrant, you see that every yellow, I would say, circle, has its own actors and what they should do with all the scene shooting that they should be doing. And the scene service is kind of like our, I would say, da layer.
00:14:08.726 - 00:14:53.130, Speaker A: I mean, da network. It's a halo network that controls at which timeline everybody is in. And each of the yellow circle has its own test case where it is doing XYZ to see what is going there. I would like here to mention that we'll have a demo section. And, yeah, I want to do the demo right now and continue on the noise session, I would say, after we finish. So, as you see here, it is really simple how you want to execute test bound in kubernetes cluster. Small notice.
00:14:54.190 - 00:14:58.700, Speaker B: Could you increase the size a little bit?
00:14:59.230 - 00:15:01.280, Speaker A: Sure. Is it better?
00:15:02.290 - 00:15:06.800, Speaker B: Yeah, it's just coming through blurry, but, yeah, that's better.
00:15:07.250 - 00:15:25.918, Speaker A: Okay, I'll just do this kind of thing. Yeah, that's good. Thank you. Cool. So here is our test case, the composition that we want to execute. And just to give you a quick TlDR here, we're saying we have 40 biodata sets with 40 bridge nodes. So one per one ratio.
00:15:25.918 - 00:15:59.322, Speaker A: We have 24 nodes, and we have 100 light lines. And what I put down here is that everybody, except for the light node, has 320 megabytes, megabit of bandwidth, and light node has only 100. And, yeah, let's try to execute it because it will take some time. And I just want to walk you through what exactly is happening. Like, right now. As you see here, this writing something like run, is queued with id fifth. What will happen next is that we have here the dashboard.
00:15:59.322 - 00:16:30.940, Speaker A: Yeah, it looks kind of fuzzy right now, but bear with me, it will be better as time goes by. And you see what testground is doing here. I'll just make that a little bit bigger. Testground is setting up all. All the images, all the actors that we want. It's just preparing the set to be run. It will take some time, as I see that our awesome eks cluster has scaled down save cost.
00:16:30.940 - 00:17:22.566, Speaker A: Alex, awesome job, but I think right now, everybody should wait a little bit for this. So now, as you see, it is very, I would say, a straightforward dish from kubernetes point of view is that you can use I would say Kubectl to see what is happening inside. And you already can see that. Yeah it is scaling up to a ridiculous amount but I don't know why we are not having this windows. Okay. It will take some time guys. I'm in the hands of Tesla and Kubernetes cluster.
00:17:22.566 - 00:17:31.840, Speaker A: Yeah somebody's waving hands. Please go ahead. Last waiting for the demo.
00:17:36.690 - 00:17:48.850, Speaker B: It's scaling up but it takes around 3 minutes to become ready. Just so you know because I'm watching in the background it spins shitloads of nodes but it takes a bit of time, 3 minutes roughly.
00:17:49.190 - 00:18:46.062, Speaker A: Okay so then to give you some overview what is eks as Renee has asked me yesterday. But imagine that it can scale up and down the amount of pods as the test case needs. So today we're executing around 200 pods meaning that 100 light nodes, 24 nodes, 43 slots and 45 letters. And the cluster scaling it up to fulfill our test case. But let's say after like 10 minutes of execution the cluster sees that it is kind of running without any necessary usage and it just kills down automatically. So yeah it is kind of like an awesome piece of tech that Alex just finished I would say this week. And yeah Alex recalled it correctly.
00:18:46.062 - 00:19:25.700, Speaker A: We just had a talk with Lauren. Yeah. And we just explained to him that we achieved that. And Lauren is default from protocol apps and she's trying to help us out and she's also trying to learn how we're achieving all this. So you see here what is happening is that testground is saying oh I see that you want to fire up 200 instances for the case dac. And this is, I would say very interesting point of view is that eks sees that it needs more power. So it is scaling up and up and up lazily I would say.
00:19:25.700 - 00:20:25.170, Speaker A: And here we already can see that we have the status of how much actors are ready for the set. So let's say, yeah, now it's 64 out of 200 that are ready. And as far as I'm concerned we still need some time to give it to run up because oh yeah, you see here again is this trying to scale up? Is it scaling up? So Alex. Right, we just need to wait still. What we will do next is I will show, as you see here I've prepared a lot of terminals and switches. I want to show the perspective of the test plan for example from two validators, one bridge node, one full node and the like. And this test case just to give you an overview.
00:20:25.170 - 00:21:04.480, Speaker A: All the validators, they will submit 180 kb data, which will mean we will have around 7.2 megabytes block. Meaning that the full node, the light node will see it as 256 square size blocks. Yeah, it's still kind of trying to fill up. Alex, will it do this or we need to do another one? Oh no, it's called 78.
00:21:05.750 - 00:21:08.290, Speaker B: It's still scaling up, it still requires more.
00:21:08.360 - 00:21:08.738, Speaker A: I don't know.
00:21:08.744 - 00:21:10.050, Speaker B: How many did you launch?
00:21:10.870 - 00:21:12.980, Speaker A: I launched 200.
00:21:14.550 - 00:21:16.710, Speaker B: Right. It's still updating capacity.
00:21:17.290 - 00:21:17.798, Speaker A: Okay.
00:21:17.884 - 00:21:22.760, Speaker B: So while it's flexible, sometimes it's not the most agile thing.
00:21:26.090 - 00:22:10.806, Speaker A: I can still continue on with explaining how I think this text is a little bit small for fault. So it won't work as this is still happening. I'll just go here and explain more details what is happening. So as you see here, the builder said it is a little bit of implementation details still. All the test cases that we've written, it is packed into a docker container. And that doc container is spinning up to what the composition file told him to do. Meaning that if the test ground says hey Paul, I think you are falling into the group of light nodes, the docker file already knows what to do.
00:22:10.806 - 00:22:52.686, Speaker A: It just calls the dark node file that will describe test case and says yeah, I'll just execute the scene that was defined for me. So this still going? Oh yeah. Nice. As you see here, finally, now we have 200 instances running, which means for us, if we go to kubecon, get pod, we'll just see a ridiculous amount of file that is light nodes, bridges, full nodes. This is awesome. I'm really getting hyped. And let's see the logs, let's see the logs.
00:22:52.686 - 00:23:32.026, Speaker A: What is happening there? So at the bottom up here, what we will do is we'll just do, I would say usual stuff from quick development perspective. And you see here folks, we already at block one. I'm a little bit sorry for the messages that you see here for influxdb, it's kind of like still in progress. But yeah, we're already generating blocks. So all 40 validators found each other and they're trying to reduce the block. Let's go and look from the perspective of a bridge node. This is also a really interesting perspective.
00:23:32.026 - 00:24:02.590, Speaker A: What is happening on its side. I'll just put down here both. So we're already at block height three. Oh nice. So here we already have a bridge node that is spin up and it already see that. Yeah, it is already syncing from height. So as the bridge node is running up and we see that height is already four.
00:24:02.590 - 00:24:47.320, Speaker A: What will be interesting for us is to actually start and look at the full node, because there is some alphabets in it I haven't looked at myself, but let's look at it together. So the full node you see here in debug mode. So it's already up and running, which is kind of fast. Wow. Yeah. We have a full node. And to give you a perspective, month ago or two months ago, our full node to das at 256, precise, it needed around 60 to 80 seconds.
00:24:47.320 - 00:25:31.380, Speaker A: There are still some calculations that are in a separate page. And today we can basically say that same use case. What is the outcome? Is it better? Is it worse? So let's wait for the new blocks came up for the full node and see it ourselves. And also let's put down here for the light node. So the light node is also fired up. I'm 100% sure. Yeah, Ray, this is your logs that we had in the latest release I put down in debug mode, so we can see even more.
00:25:31.380 - 00:26:10.058, Speaker A: So here's the moment of truth. We here at the full node, we see that we are retrieving the data square for the block height. For the block height, five. And let's wait for the moment to see how much that costs for it. Because as far as we can see, we are generating 7.27.2 megabyte box. Now here we have a little bit less, meaning that we only have 31 transactions.
00:26:10.058 - 00:26:57.650, Speaker A: So something happened on the film 56. And where is it? Let's try to find it. Oh yeah, here we have it. So now it's a little bit better, meaning that it was around 60 optimistic and 80 pessimistic. Now we just 57. So some changes happened. 256 was kind of like a bummer for me to test, but now, as you see here, with big network tests, I can just see with my own eyes what is happening.
00:26:57.650 - 00:27:50.988, Speaker A: And yeah, it's kind of what it is. Still, as we are following up on this test case, you see that there are a lot of different stuff that is making life not easier. And what I wanted to talk about is, first, imagine right now I need to go through all these 200 pieces to see the logs. It will be basically close to invariable. And second part is doing it once, for example, as an experiment, is kind of okay to go through all the logs and read through and know what is happening still. Yeah, you see here height, 7.7 seconds.
00:27:50.988 - 00:28:46.560, Speaker A: So it's getting better. Still, we know that this is the point where we need automation. And the second part is of course, how we can get rid of a lot of errors along the way that we are having. So yeah, this is the issues that we have for this day, but for the sake of doing experiments, it's kind of like a pain that we can do. So just to return to this execution, you see that it's still running and already some of the participants have finished and some of them are still running, meaning that we already can know that some of them failed, because if it is succeeded, but we're still not reaching. This test case is still block high at like 30 or 23. So we already know that something bad happened along the way.
00:28:46.560 - 00:29:31.840, Speaker A: So this is where the interesting part comes in for me. But it's kind of like time consuming is to learn who from the group or specifically an instance fails at which specific point. So yeah, you see, this is kind of cool stuff. You don't need a puppeteer. You can just look at different perspective of any instance and make decision on your own. So let's move a little bit from the hands on experience to the ideas that we have. I've been discussing this during the onsite, what is the path forward? And here I'll only talk from perspective of testing as from DevOps even more.
00:29:31.840 - 00:31:00.424, Speaker A: And I didn't want to overblow today's in knowledge session with this. First one is the Roleman introduction to testgraph, meaning that we want to see how the modular vision is test because you already have all the basics of basics of DA set up for you. So from my point of view, from what I think is that if we can give the devs the tool to just say, spin up this role, mint, I don't know, instance inside a full wild data set with 100 which nodes and just post like, I don't know, 300 close to 1gb of data, what will happen? Can my current implementation design work or not? And the second part was the true benchmarking. I would say that kickbench, this idea was born after Gabriel and I were discussing how much TPS we can have on an l two with four megabyte blocks selection. So saying that one roll up is occupying all four megabytes, then how many tps we can have now because we can post data on test ground, we can safely start doing that. I mean, in the nearest future. And of course, to make it more, I would say, giggly and funny.
00:31:00.424 - 00:32:24.090, Speaker A: I would say that it will be very funny for me to do how many gms we can have upon selection block. Because testing is not kind of like just about numbers. It's more about having fun in some cases. And so far with test ground, yes, I was having a lot of fun and I think that from perspective to just know, like in Google back in 2012, they were counting the distance between earth to moon in Paris. So we're going to kind of have the same people but with our own kitchen still with challenges ahead. You see that we have log analysis issue and the cluster also scaling with the question mark, meaning that today we have a talk the protocol apps maintainer Lauren center, he's kind of like the guy behind right now, moving session forward. And yeah, he already approached the call, he already asked us about do we want to basically collaborate with Procolabs and their partner proxyco, because we kind of know what can be done better and how we can basically tailor the roadmap for testground as a public group.
00:32:24.090 - 00:33:40.100, Speaker A: And the first point here is loss analysis. Also, I have a lot of ideas and team, which is basically my ex colleagues who are willing to do this after they saw testground at decentralization for them because they were wondering what is the ex colleague doing in the open Oss one? And yeah, Lauren also knows this issue and she's very keen to learn more about what approach I took to basically solve the issue of filtering out specific locks that you need from a test run. But you have a lot of participants shouted lobster. And yeah, I think that in a couple of days we'll be more in touch and have more discussions how we can solve that. And I think this is all my main motivation for today is to bring some fun and hope that because of fun storytelling, you learn something new today. And yeah, thank you.
00:33:42.630 - 00:34:53.090, Speaker C: I wanted to say, I know this presentation was extremely technical, but I don't think anyone appreciates just how heavy of a lift this was to pull off and how few blockchains, if any at all, perform this kind of testing. There's very few projects out there that have actually invested this much time into network level testing and spinning up, creating these scenarios where you can actually do these kinds of real world tests. It's extremely valuable and it takes a lot of time and a lot of energy, and it's crucial to be able to catch, we've caught so many different weird bugs inside a test ground now that has made it completely worth it. Completely worth it. And I'm saying this because I come from a testing background. I was working at whiteblock before and like a big fan of network level testing and simulations like this. And back in the day, there were tons of blockchains out there that were like the only kind of testing they would be doing is just like spinning up test networks like we're doing with Arabica and Malaki and all that shit.
00:34:53.090 - 00:35:25.860, Speaker C: But it's very difficult to test for particular scenarios in that kind of to have a controlled environment where you can do something like that. And at the time, there were just no projects that were willing to invest the time or thought that it was important enough to do. And of course this leads to failures in the real world and hopefully we can create a more robust network because of this. It's honestly so immense of a list. I so appreciate the work that you're doing via and Alex as well. This is awesome.
00:35:26.790 - 00:35:49.660, Speaker D: Yeah, for sure. Coming from academic background, these tests were kind of common when doing scientific. If you're academic and you come with a protocol, you're kind of expected to do these kinds of tests. So I was kind of surprised coming to the cosmos space and denim space that in the industry people weren't doing this kind of stuff. So it's pretty cool to see.
00:35:52.110 - 00:35:52.426, Speaker B: The.
00:35:52.448 - 00:35:57.600, Speaker D: Tests that actual scientists do, academia being actually applied to industry as well.
00:35:59.330 - 00:36:56.190, Speaker A: Just to give some oversight for you all. We've been trying to be active in the search bank community and people do appreciate how we're pushing forward this whole big tech podcast idea. And regarding the blog post, I think most of all we need to first ship block reconstruction and to see if there's still a big glass of. And yeah, let's think about maybe change anything. I want to write a blog post about block reconstruction because today when Lauren asked me directly why you need so much light notes, I explained to him the test case and he was like, what? You are pulling this off? And I said, yes, we have a paper that stated that we need this amount of light crimes. We need to do that to say that the software implementation is not failing. This is all that we need to do.
00:36:56.190 - 00:37:01.362, Speaker A: Because holy crap, I think even before.
00:37:01.416 - 00:37:15.510, Speaker D: That, the fact that we're testing like thousands of light clients or hundreds of light clients, even that itself is interesting because most chains don't have like, clients in the first place, let alone have testing infrastructure for light clients.
00:37:18.810 - 00:38:05.940, Speaker A: Yeah. So moving forward, I would say that we want to do the tooling for this better as there's still a lot of room for improvements. Yeah. And I guess we can just discuss it after the call. Protocol apps are really key into us driving forward the roadmap, how the community should evolve around test graphics. And mainly they want us to pinpoint how different teams can learn from doing big network tests because they already have some requests from new teams that are joining. There are some new protocols that are doing something, and they need this kind of knowledge from.
00:38:05.940 - 00:38:23.110, Speaker A: Okay, if there are no more questions, guess then let's wrap it up, folks. I hope you have fun today, and, yeah, see ya. Bye.

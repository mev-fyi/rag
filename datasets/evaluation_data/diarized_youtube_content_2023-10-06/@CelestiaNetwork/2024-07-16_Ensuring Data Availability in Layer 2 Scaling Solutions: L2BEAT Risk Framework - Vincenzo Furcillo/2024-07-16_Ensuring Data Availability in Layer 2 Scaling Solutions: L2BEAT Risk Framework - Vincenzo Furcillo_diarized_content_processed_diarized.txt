00:00:02.040 - 00:01:08.850, Speaker A: Today I'm going to be talking about data availability and in particular data availability risks and what we've been working on at l two bit with the ARISC framework. So if you're familiar with l two bit, you're familiar with Alturis Crusade, made up of five categories or five slices if you see that as a pizza. And one of the slices is data availability. And so far we have been marked green for L2s using Ethereum as other availability solutions. But we have lacked granularity on the risks and the different characteristics of other data availability layers. And so this data availability risk framework aims at expanding our previous efforts in assessing the security of different l two architectures, and we aim to evaluate the specific security profiles of data availability providers. And so a brief primer on data availability.
00:01:08.850 - 00:02:07.488, Speaker A: You know, it's basically making block data accessible to all participants in the network. So to verify a blockchain block. And this generally applies also to L2s where participants in the network needs to be able to access the data to verify the l two state. But there is slightly difference in l two types. When you have ZK constructions you have validity proof, you know that the state transition is valid, but the users still need to be able to access the data to be able to reconstruct a state and maybe advance it for withdrawals. In optimistic roll ups, you still need to reconstruct the state with the data, but most importantly you need to be able to challenge an invalid state root proposal. And so what are the critical issues? They are different as well.
00:02:07.488 - 00:03:37.170, Speaker A: With the different types. For ZK rollups, users may be left unable to prove that ownership of the asset on the l two, and so this essentially would freeze their funds. While for optimistic constructions this can be even worse and you may have an invalid l two state route being proposed and without the transaction data necessary to recompute the state, users may be unable to prove its invalidity and therefore user funds could be at risk of being stolen. And so looking at how these components play together with the layers and L2s, you have a sequencer usually collecting transaction data and posting it to the dlayer. And this DA layer can be on chain. In the case of Ethereum, call data on the execution layer or blobs in the consensus layer, or it can be on an external DA provider which can be of two main types. One type is a dedicated blockchain, public blockchain like celestia or avail, and with its own consensus mechanism, or can be on a data viability committee which is basically a set of members getting together and preserving the data and making sure it's accessible to users upon demand.
00:03:37.170 - 00:04:29.282, Speaker A: And if the data is on chain, then Ethereum is aware that the data has been posted, a data commitment is posted together with the data. But if the roll up is using an external data availability layer, then you need a data attestation. And this data testation needs to be posted to a DA bridge and act as an oracle on Ethereum for the DLA. And so if you think about securing data availability, you have different guarantees that are needed. And here I grouped them into three categories. You have a data publishing guarantee, basically you need to make sure that the data was published and was accessible during the defined period. And this is different than a long term storage of the data.
00:04:29.282 - 00:05:38.188, Speaker A: But in this case, you just need the developer to be aware of the data for the defined period on the DL layer. And then you need a data integrity guarantee, meaning that if any transformation is applied to the data, the users needs to be able to recollect the original data that was posted to the Dlaer. And then to complete you need a data attestation. So you need a proof to Ethereum that at any point in time data was stored and all the data was included. And so a key takeaway of securing data availability is that for Ethereum, DLA is secure only if there is also a DA bridge that provides this proof. So the DLA and the DA bridge needs to work together to make sure that the availability is secured. So focusing on the DL layer, you have some issues in terms of what can go wrong with posting to the dlayer.
00:05:38.188 - 00:06:32.500, Speaker A: And here I divided into two, you have the issue of unavailable data, so you can have the case that data cannot enter the ledger and so data commitment cannot be produced. And this can be the case if a vast majority of nodes goes offline, or there is a censorship attack on the DA layer, and this is a liveness issue, or you may have the data that enters the ledger and then at some point in time it disappears. And this would be the case, for example, for a chair in reorg, and the data being unavailable also on the non canonical fork. And this would be a safe dish. And the other issue is the withheld data. So data is attested but is not served. And this is known as the data withholding attack.
00:06:32.500 - 00:07:33.802, Speaker A: And so we end up capturing these issues and addressing them through the economic security risk dimension of the Daris framework. So this is the first category of the framework, and it aims at measuring the level of trust that we can place in the majority consensus of the Dlayer and it's marked as green. If the total slashable stake is quantifiable on chain and is more than the total value secured by a dlaer, it will be marked as yellow if the this is not the case. So the total slashable fund are less than the total value secured. So for example, you may have 10 billion total value secured and only 1 billion in slashable assets. Then variators may be incentivized to be malicious or bribed to be malicious by someone else. And this we marked as yellow.
00:07:33.802 - 00:08:53.240, Speaker A: And in this dimension we aim at capturing not only the alayers with their own consensus mechanism, but also data availability committees. And so in the yellow category we also include committees that are publicly verifiable on chain. I mean like the members are known that there is a reputational risk for the members and they could lose their reputation if they behave maliciously. But if they are not known, and so this could be the case for an unknown committee with not known members, then this would be the worst case scenario. And we marked as read in the, in this category. So we looked at liveness and safety issues, but what about protecting against a data withholding attack? And usually have two ways, you can have every node download all the data, but this is of course not scalable and you would need to increase node requirements. Or another approach is to use a data sampling algorithm, data variability sampling, that offer a way to scale the data throughput while maintaining verifiability.
00:08:53.240 - 00:10:11.420, Speaker A: And so just briefly, database sampling, you have richer coding applied, which splits the data into smaller chunks. And that's some redundancy, so that the original data can be recovered from a subset of the chunks. But here is important, that there needs to be enough verifiers or light clients or light nodes to sample enough chunks to reconstruct the original data blob. And so this fraud detection mechanism is the second category of the framework and aims at measuring how effectively users can protect themselves against malicious majority of committee members. And it will be marked as green if invalid data can be detected on the Dlayer through a sound data availability sampling construction. And it would be marked as yellow if for example, there is a data availability sampling construction, but there aren't enough light nodes to sample enough chunks, so the block cannot reconstruct it. And if there is, there isn't any fraud detection mechanism at all, then we marked as red.
00:10:11.420 - 00:11:41.330, Speaker A: And so we looked at the first part of securing the DA layer, and now we can look at securing the DA bridge. And here you can group the issues into two, you have gestation security. So basically how can the bridge, how robust is the bridge verification of data commitment? And does it produce any additional trust assumption? And another issue that is very common to smart contracts and l two s as well, is upgradability. So we need the criteria for an exit window and making sure that if there is any unwanted upgrade for the users that they are able to exit the system. And so the third category is the attestation security that basically verifies that the economic security on the DA layer is mapped to that attestation on the DA bridge. And this will include verifying signatures, verifying the threshold and verifying evaluator set restruct properly on chain. And in the case of the ZK proof, the ZK proof would have to include all these checks, the correctness of the signatures, the threshold, and if the system wants to be marked as green, you wouldn't need to allow for signature equivocation.
00:11:41.330 - 00:13:00.010, Speaker A: So you cannot sign something on the layer and something else as an attestation to the a bridge. If that happens, we marked as yellow. And this could also be the case for constructions where there's a different set of signers on the DA layer and the DA bridge. Usually it's a smaller set of signers, while if there is no bridge at all then of course it will be read. And the fourth one is the exit window, which basically examines the possibility of users to exit the system in case of an unwanted upgrade. And this follows the criteria that we set in the stages framework for l two s. So you would have green for an immutable bridge or an upgrade delay of 30 days or more, and yellow for above seven days, which you can bring to zero if you have a security council in place as defined in the stages framework as well, and red if the upgrade delay is below seven days and there is no Security council.
00:13:00.010 - 00:15:03.174, Speaker A: And so we get to the last one, which is additional trust assumptions of external delayers to enshrine solutions on Ethereum. And here basically Ethereum roll ups need to trust only full nodes on Ethereum, while if you're using an external DA layer you introduce additional trust assumptions which come from the need for a DA attestation on the Da bridge. And there is this graph is actually from Luca Donna's scalability guide website, which basically goes through an example of a roll up using Ethereum, not from the point of view of enshrined with so called data or blobs, but uses it as if it was external DA provider. And so you will post data to Ethereum and then data commitments to a DA bridge on Ethereum. And I think it's a good example to show how even if you're in this case, when you're using a DA bridge on Ethereum, or basically the same DA layer in two different ways, if you're using Ethereum as an external layer, so you're using data testation signed by validators, you would need to follow the data commitments on the DA bridge and in case of data withholding attack, while the full nodes on Ethereum for our enshrined roll up will be able to discard the invalid data. So make sure that the data is only available if it's present on the honest chain. In this case, you would need to trust the majority of validators to make it, to sign an attestation, and to make it available to you.
00:15:03.174 - 00:15:54.350, Speaker A: So we aim at capturing this difference in the last category, which is accessibility, so it measures the ease with which data can be accessed directly from Ethereum. And so it will be marked as green for enshrined solutions in Ethereum protocol and yellow for not enshrined. And so we're aiming to finalize this risk framework. And we've had some great suggestions in the l two bit forum. So if you want to provide feedback or you have some comments, some suggestions, you can go to the forum at gov dot l two bit.com and post there. And that's it.
00:15:54.350 - 00:15:56.370, Speaker A: If you have any questions. Thank you.

00:00:02.000 - 00:00:31.016, Speaker A: Yeah. So I'm Jordan. I'm the co founder CTO of Astria. I will see if I remember which direction. Yeah, we'll do a little presentation here, kind of format here. Plan is like half demo, half some slides that I talk about. So, to start with, does everyone here have an idea of what Astria is and does at like some high cursory level? No.
00:00:31.016 - 00:01:14.450, Speaker A: Okay, well, I'm going to talk about this from the perspective of I'm a roll up producer. Like, I'm creating a roll up. I've decided a roll up is right for me. How am I going to ship? And like, why would I want to do this? Like, shipping a base roll up? And what is that process, the whole development lifecycle and how we're thinking about it and trying to make it really easy for people and hopefully along the way, figure out what, what Asher is doing. So, to start with, get an idea of, like, what is a based roll up? This is out of Justin Drake's paper. Rollup is said to be based, or l one sequence, when its sequencing is driven by the base l one. How does that relate to Astria? Well, and then we have this here as well that was based roll ups.
00:01:14.450 - 00:01:43.840, Speaker A: The idea that this paper that Justin Drake put out a people like, oh, base roll ups are cool. I think Arbitrum started out trying to build a base roll up, and then they realized twelve second block times aren't really the UX that we're going for when building roll ups. So you needed to add a secondary sequencer on top of it. Some people, probably smarter than me, were like, base roll ups are a great idea. If Ethereum had two second block times, and it would be great. And it's like, especially if it had single slot finality. It just so happens that that's exactly what we're building.
00:01:43.840 - 00:02:32.550, Speaker A: What does that look like from a just diagram? Flows before we get to into software architecture, the Astria shared sequencer exists here. Users can submit their roll up transactions into that. You get this one ordered block, because the key on how this works is that we defer execution. So instead of having to execute across every state machine, on top of this, we just provide an order for you. And then that data is posted to Celestia. And the way you interact with the sequencer as a roll up allows you to get the data that's only for your roll up. That data is posted to Celestia, and then the roll up can read that data, execute it, figure out its state route, and then you can do what you want to do for posting that state route somewhere.
00:02:32.550 - 00:02:59.054, Speaker A: I don't currently have strong opinions on that. We can talk about the future. Being able to do ZK rollups, of doing ZK proofs is your stateroot. The important aspect here is that if you have a given state machine and you have a given set of transactions, it is deterministic. The state route you will arrive at. Then it's just a matter of figuring out that you ran the right state transition function in order to achieve it. This is where Astria started from.
00:02:59.054 - 00:03:48.502, Speaker A: This based aspect is that the roll up reads this data directly off of the block and is able to rely on that. What that provides you is a decentralized network for these as opposed to a single sequencer. Because we don't have a fancy, a fancy virtual machine built into the state machine, we can do this much faster and give you your two second block times. I guess to go back real quick here, I wanted to say, how does this relate to us? Well, Astria is an l one that posts data to Celestia for various roll ups. And it's built for you to do base sequencing. So it's a l one, it's a roll ups. Built on top of it are base roll ups.
00:03:48.502 - 00:04:38.004, Speaker A: Basically that's how it's architected from. And there's other options you could do, but this is the way it's intended to. So you've decided, you're an app developer and you've decided, okay, I want to build something here. And the question here is, can we go through the SDLC of this? Like what am I actually doing to build it? This is, if we go back to this .1 of the issues here, it's like why you want single slot finality, why you want two second block times is like when you have single slot finality, it means that I, as the roll up producer, no longer need to figure out how to deal with fork choice rules. If you look through optimism's codebase, I would estimate about three quarters of the op node is dealing with Ethereum fork choices. It's also not great for your users if like the order of the transactions.
00:04:38.004 - 00:05:00.356, Speaker A: And this is a complicated problem for a roll up developer, and it leads to most of the roll ups today we see like, oh, it's an op stack or it's an arbitrum. It's like it's one of these things because it's complicated and difficult to build. I'm not as a roll up developer and be like, I'm just going to go redo that. That is a. I need many engineers in many time. I'm interested in deploying an app and so I'm going to go with what exists. You don't have to do that with this.
00:05:00.356 - 00:05:23.776, Speaker A: It's an instant improvement. We have. This is some boxes and arrows. Josh has done some talks about boxes. We have six boxes. But as a roll up developer, the components that you're working on are this actual roll up, this actual state machine we have provided in order to make this development. I'm interested in building my app.
00:05:23.776 - 00:06:08.856, Speaker A: I'm interested in building whatever is uniquely mine. You can focus on that. These two components that we call the composer and the conductor can fundamentally be thought of as the right path of how the data gets through. And then conductor is actually the extra special bit here. When you want to go and you want to build a roll up and you want to integrate with Celestia, there's questions of, okay, I need to understand how to read the data off of Celestia. I have to understand how to post it, how to verify it. If I'm using a separate sequencer, how do I validate that it was sequenced by the right entity? Conductor does all of this already for you and then has an API integration with your roll up, kind of akin to ABCI, but right now it's called the execution API.
00:06:08.856 - 00:06:40.246, Speaker A: It's designed for your. When you have a base sequence roll up to really just be as simple as possible. Entirely state machine agnostic as opposed to what we have is like the norm. If you work in Opstack, their execution environments, use the engine API, which is the standard for Ethereum chains and Cosmos chains use AbCI. There's a lot of bloat in there that you don't need when you're building a base roll up. So we made this similar to the whole system. You can do it in a different way.
00:06:40.246 - 00:07:29.026, Speaker A: We've built roll ups that are, we've built a minimal. We did a proof of concept integration with Cosmos chains. We have a geth integration that we're actively maintaining and building on top of. And then we have also done proof of concepts of fun, like what if I wanted to do my own fancy unique state machine? I wanted to do something like, that's not normal blockchain, but I want to use blockchain as a database storage layer of some part. You can also do that. All you have to focus on is this and your application. If you're a solidity dev, who wants a roll up? Our geth implementation soon to be added in, but already being used by forma is a precompile manager, so you can write your own custom precompiles for your solidity so that you can enable your special app behavior.
00:07:29.026 - 00:08:02.410, Speaker A: That's maybe not normal to every EVM in the world, which is great, but how do I actually build that and test that and run that locally? The classic developers, developers, developers. I'm going to go ahead and exit out of the slideshow view here real quick so that we can look over some stuff here. We've built this. Let me make this font bigger and then we'll just clear here. All right. I. We have built the Ashriago Cli.
00:08:02.410 - 00:08:47.160, Speaker A: This is in a classic web two sense. There's a lot of tools like this for you to go and integrate with. If you're building a new web two app and you want a database, there's things like Firebase and you run something locally and you test it and then you ship it to prod and there's this easy promotion cycle. So that's what we think about when we think about how are we building and shipping these with the Astra go CLI here, this is going to run all of the core Astra components locally on your machine such that you can do your hot reload cycle of whatever your roll up app is. You can go and say, oh, I'm going to change my precompile and reload geth. You're going to say, oh, I'm just going to run Geth and then also push it down so we can do with this. I've purged everything, so I'm going to initialize.
00:08:47.160 - 00:09:13.100, Speaker A: I didn't think about the wifi problem. This might take a minute, but they're not that large. When you initialize here, it's actually going to pull the binaries of everything that's going to be run as a sidecar. And once it's loaded here, we'll be able to. And I'll come take a look once it's finished here. Once that's all loaded, we'll be to run all those components. In the meantime, we have.
00:09:13.100 - 00:09:33.620, Speaker A: This is our Geth fork, which is published. There's a website, you can go and see the changes that have been made in here. We can just start our. I did like a make geth earlier. We have some fancy just commands here. I think it's just run. Yeah, I think I run this.
00:09:33.620 - 00:10:17.906, Speaker A: Oh, I think actually I need to just init because I didn't initialize my geth node. Just clean. Maybe I did and I, there we go. Cool. We have a geth node started up and then once we get the, this is running and then once everything else has started up, it will run against this and we'll be able to see just even through the ClI here that everything is going. So Astria, go dev run. Yeah, so I showed you we have a sequencing node that is spun up here.
00:10:17.906 - 00:10:47.830, Speaker A: We can see consensus operating through Comet BFT, which is how our sequencing node works. And then we have the composer and conductor nodes here and we can see that this is firing into geth, creating new blocks locally. And I can go and I can just do hot reload. I can go and I can make some modifications to what I'm doing and do this whole dev cycle. Trying to make it as easy as possible for you to locally build. He's like, but running Astria, I'm going to have to figure out how to run it. It's like, no, there's tooling for you to build and test on your local machine.
00:10:47.830 - 00:11:26.500, Speaker A: And this is a simple, our first pass of this. You talked about using dev cluster in the past. We also have fancy kubernetes and helm charts and you can do all that. But when you're doing a lot of local development, you oftentimes don't want to rebuild the Docker image each time you want to test what you're doing. And so this will work. And the cool thing here too is that we're running geth. You can run any roll up against this as long as it implements the execution API and a couple of integrations for submitting the transactions, you are fully set and it will go and it will run through.
00:11:26.500 - 00:12:03.602, Speaker A: That's okay. Now we can go and we can build. And you see composer and conductor, they like stopped being able to communicate with the client we had. Yeah, so that's the build process and hopefully that's useful for people. Let me go back in here. That's great. And all the question then in our software development lifecycle is I have built something, but I actually want to deploy it.
00:12:03.602 - 00:12:37.838, Speaker A: This is oftentimes where things become more complicated. I should go ahead and. All right, yes. When we get into deployment process, this is, again, in a traditional, this is why some people might prefer to build just on top of main Eth. It's like, oh, well, what's my deployment? It's like I push a solidity contract. I pay for it once it's deployed to a network and I don't have to worry about running nodes. How are you as a roll up developer, you've decided a roll up is right for you.
00:12:37.838 - 00:13:06.304, Speaker A: How do you work with this? Again, we come back to this. Well, that looks like a lot of things that I have to run. We built some automated tooling to do it on your machine, but when you go and you deploy, you're like, ok, I'm going to have to figure out how to do AWS. Am I going to pay for services? Am I going to have to coordinate with other people to run all of this? There's a couple of answers here. One is that we have a lot of in house expertise on this. At one point we had this one click button deploy a roll up. This is how a lot of people are building rollups today.
00:13:06.304 - 00:13:38.800, Speaker A: They're using conduit or they're using caldera. Yeah. And this is how lots of developers are getting into running a roll up. We'll help you run your node. It might not be a one click because it turns out this one click isn't actually all that valuable as we find people want to do things like customize their precompiles and have custom images and build all of their fancy stuff. But we can help you run that infrastructure. We currently doing this with forma and their main net.
00:13:38.800 - 00:14:15.636, Speaker A: I can talk about how that works here a little bit later, but also again to the point where I said before, we have all of this fancy helm charts and kubernetes and all of that, which is really useful for testing your deployment. You can run things locally. You can test, you can do CI CD if you're interested in running that. We have all of this built. It's how we're going to deploy it ourselves. So coming back to that point, I set up today, like last night here, I went and I set up a new role and I'm going to run through it like, ok, I'm running a role. I want to test this, not just on my machine, I want to test this.
00:14:15.636 - 00:14:50.958, Speaker A: I want to see how is this going to run against Testnet. Where is that data getting posted to Celestia? How is all of that working? I have running on my machine right now. If we go over here, there's a whole bunch of things that are running. It was like one command, it spun up a bunch of stuff. We have celestia mocha light nodes, we have some block scout stuff and evm. We have all this stuff running right now. If I go on my machine, when I spun that up last night, I came up with a roll up name and I'm posting data.
00:14:50.958 - 00:15:34.280, Speaker A: This is actually running directly live against our current devnet off of my machine and posting data. So we've worked with the people who built selenium to build Astrotrak. You can come here and when you have roll up transactions which you can see have gone through here, this is a local dev thing. If I had reload the page here, scanning for new transactions, we can go back to our main page here. Let's say we want to fund a wallet just to show proof of hey, this is actually doing something. Build a whole new address. Let's go to our faucet that's running, this is, again, this is running on my local machine.
00:15:34.280 - 00:16:05.512, Speaker A: We can request some funds from our faucet. We can go here into our explorer. We see one more transaction has come in. That execution is like okay, that's cool, this is all running on my machine. But what's happening further down the line? Well, we can go and we can look inside of Astrotrack. We can go into the roll ups page here, some work on making these more readable. But this is the newest roll up that was created and the data that's been posted to it, we can see the actual sequences of data.
00:16:05.512 - 00:16:31.108, Speaker A: There's a bridge account that we'll talk about a little bit later. Here we have all of this information. It's like ok, this is cool. Additionally we have a link directly out here. The way that I go over how we post data to Celestia here, this was also posted to Celestia's mocha network. Again pushed to the testnet push to the network. We can see the bytes that come here.
00:16:31.108 - 00:17:08.434, Speaker A: One of the unique things about building on top of this based roll up architecture in the way that Ashtray has built is that if you are running a normal op stack chain, you are posting, you have empty blocks, you're still posting data. There's a cost. If you have no users, you can see here, this is all of the blob commitments that have been posted. If you have no users, you have no data to pay for and post. When you're running this manner, there's infrastructure costs potentially of running it. But because of the way our shared sequencer works, there's two types of data bundles that we post and two namespaces. One that contains some metadata information that's usable by everyone using Azure.
00:17:08.434 - 00:17:32.410, Speaker A: Those get posted and overhead cost to the sequencer. Now those get posted every block time of the sequencer. The second is your roll up namespace data. And so that gets posted here. All of this is fancy it's protobuf, it's batched, it's compressed with Brotli so that you're using fewer bytes. If we look here at this namespace, there's 3 data here versus three and a half. These have been all minimal transactions.
00:17:32.410 - 00:17:59.670, Speaker A: There's not a lot of batching that happens in compression. But when you get high transaction flows actually coming through, you can start to see that there's higher compression coming through in terms of the data that actually gets posted. You can trace this throughout the stack. We also have, I don't have it set up right now. We're working on getting it fully integrated. There's a CLI tool because we have this data posted to Celestia. I was like, okay, there's a downside potentially to this.
00:17:59.670 - 00:18:35.022, Speaker A: I want to see what the actual data is. We have a tool such that you can copy the base 64 and go see what data was actually posted for you. Because it's batched compressed protobuf data, it's not always the easiest to insight into. But yeah, if we go in here, and I would have to reboot the testnet faucet. But if we want, we can actually see here this timestamp here, this was created three minutes ago or whatever when I actually created that transaction that goes in this flow and all of this tooling. Again, single line command. If you have a Kubernetes cluster, you can just run it.
00:18:35.022 - 00:19:30.306, Speaker A: You have to have your docker image and you're set to go. Especially one of our next steps is how do we take this CLI where I had everything configured, there's some configuration there, had it set up exactly how I liked it locally. How do I then go into the production mode and do that? You can test with this setup, you can test all of the Kubernetes stuff locally as well before you go. And you can have normal staging flow of launching your software, testing it, and pushing things through. Yeah, so that's kind of how do you deploy. And then there's the actual problem of like now I have a roll up, I need money on it, because I'm either, you could be a sovereign, roll up and go like the full sovereign, create your own token and do that at day one. But in all likelihood, the way that we see people using rollups today and the way that, for instance, like formal works, is you want to use whatever ecosystem you're in.
00:19:30.306 - 00:20:21.706, Speaker A: There's upsides to using that same token. So it's in our instance, how am I getting TIa on my chain? But also maybe the question like how am I getting USDC on my chain and how am I going to get some restaked asset that matters to me? What if those are what I want? We've built a bridging solution into Astra that gives you this native deployment. If we go back here to the roll up here, you can see it's like initialized bridge account. If we look at Block scout here, you can actually see the first transaction here is a bridging transaction. I moved from a sequencer account which had funds directly up into the roll up and it gets 100 in this instance. It's a native asset to that sequencer of RIA on our testnet. You'll be able to do this with mocha Tia.
00:20:21.706 - 00:21:21.100, Speaker A: The sequencer is IBC enabled, so you can get assets via IBC into the sequencer and then use those as your native asset. With a native bridge that has various aspects of being able to be upgraded and multisigs and change the multi sig and all of that that you get out of the box when you use something like op stack. And also because of the way this is built, fairly generically, some customization has to be done on the withdrawal workflow. But for getting the money actually into your chain, it's entirely generic in the aspect of how it goes up there. So it's up to you if you do something wholly unique, because your specialized thing is that you know how to build the greatest state machine that's ever lived and you have the next best thing for execution environments like you can customize that to, as long as you can process a certain set of protobufs, figure out how to execute and process that. It says this money goes into that account, then you can do that. Yeah.
00:21:21.100 - 00:22:03.440, Speaker A: There's also to that point a withdrawal functionality. Here we have a deployed, we have a contract solution for this on the EVM. So I transferred some money and did a faucet into this account and then I have this contract that we created and then I bridged out and we're running the tooling to relay and post that. It was a small amount. If I actually click on this contract amount, you'll see that it was exactly one like NREA that bridged out. But if we go and we look on, we can go into Astrotrack here and we can go and look at view the transactions. There's some stuff we're working with them still on getting us all categorized under your roll up right now.
00:22:03.440 - 00:22:46.950, Speaker A: Mainly the sequence actions show up, but you see the bridge unlock here. Action. You can see when you look at this, you can validate, if I open this transaction, you can go and say, yeah, I can see that I actually did this and I unlocked and I moved it into this account and it has a balance. This account didn't have a balance. It was created fresh from scratch. You have this bridging solution, and one of the things that's maybe not wholly unique, but that is cool about it, is also that you can register multiple assets to bridge through this native bridges. It's technically deploying multiple bridges.
00:22:46.950 - 00:23:19.020, Speaker A: For instance, on this evm, I could have my native token that I take up here, but I could also say, oh, there's USDC coming through the sequencer. I want that as an ERC 20 on my roll up. And you can get that all by building on top of Astra. You get the bridge out of box. Where are people bridging from? Is this specific chains? So it's going to. It depends. So, for instance, in our use case with t, and this is where IBC enabled on the actual sequencer.
00:23:19.020 - 00:23:48.532, Speaker A: And there's also a one hop solution here, limitations of getting everything ready for demo here. But we're. You can do a one hop of. And we've done this with Celestia. You're on Celestia and you say initiate an IBC transfer. We have a website we're putting together. You can just sign it with your Kepler wallet and it will send it straight through all the way to your roll up, but it'll do the IBC hop into the sequencer and then automatically deposit into your roll up.
00:23:48.532 - 00:24:35.280, Speaker A: And similar with doing withdrawal, you can withdraw straight back. So it's going to depend on the asset. For instance, if you're talking about USDC in the IBC space, we're talking about having that, like that USDC is ultimately going to originate from Noble. So it's depending on where your asset comes from through standard IBC hops until you get into the sequencer. And then as the. I've used this analogy before that a base roll up is kind of like a materialized view on a database, which is, it's, I want to take some subset of that information that's stored there and I want to execute it my own way. We just provide a way for you to very easily shard that, access only the data you need, and then execute it and get your access to the funding and whatnot.
00:24:35.280 - 00:25:02.056, Speaker A: I have to say, describing it as a database. Yeah, yeah, sorry. I am a boring person. That's potentially my crypto flaw is that I think of things in my web two days. No, you're right. The reason I ask is we're thinking about launching token and then sort of bridge it after we launch the roll up and bridge it on. So we're not sure at the moment we'd launch the token through layer zero or either elsewhere.
00:25:02.056 - 00:25:22.032, Speaker A: So. Yeah, gotcha. Yeah, it'd be interesting to talk separately about. You know, we want to, we want to do a later native, but have the bridging out. That's something that I don't know that we've thought a whole ton about, but it's, it's definitely possible with the architecture. So. Yeah, so going through here.
00:25:22.032 - 00:26:13.204, Speaker A: Sorry to go back to like what do, what do people need and what are the solutions we provide for here? Bridging. I think with these three, these are the table stakes of what's required for you to get a roll up. There's also, though, there's going to be additional integrations. I say integrations here. The idea here is, and this ties into the interoperability of utilizing a based sequencer. And to be really nerdy using a shared wall clock time, is that you get some fun interoperability aspects here, which is if my roll up posts data at a certain point in time, I can decide as rollup is like whatever my roll up is, there's some other partner that I want to work with. I also want to ingest their data because I'm interested in that that affects our users.
00:26:13.204 - 00:27:09.260, Speaker A: You can have this interesting aspect of here is a roll up which aggregates this sort of data and it's going to happen at the same block time. I'm curious about what's happening there because I want to do this. You can build that. Additionally, we are actively working with SCIP on working with now SCIP Connect, formerly slinky, such that Oracle data will be available out of the box to any roll up who wants to run on top via the connect integration. It's like, ok, there's some of these additional integrations that because it's useful to all rollups, we can post it and you can choose to utilize that data based off of what works best for you and your ecosystem and projects and products you're building. And then I have this last one here, kind of tongue in cheek because I think this is what people and the rest of roll up land do, is they say, well, we did all of that and it's very successful. We're going to decentralize.
00:27:09.260 - 00:28:10.800, Speaker A: But if you build on top of Astria, that's already done for you, because you already have a decentralized proposer and you already have have that aspect done for you. And building from the ground up with that is like we're building blockchains. Why would we be here if we weren't interested in decentralizing our infrastructure and setup? And so you get that from day one, live mis guarantees and improvements over running a centralized entity and not, I'm sure, optimism and arbitrum and folks have some designs, I don't talk enough to them to know, but I do know that it feels like this has taken longer than it should. Yeah, that's all I had here, I think. Yeah, that's the end of my slides here. So open up to questions people have and try to answer things. And maybe some more demo stuff I can do for you folks, if you guys are interested.
00:28:10.800 - 00:29:17.090, Speaker A: I wanted to ask about Pharma. How does your partnership work? You guys run the infrastructure, how does the fees fit and all that work? Yeah, I think the answer in terms of fee split and whatnot, I'm not going to have the full answers there for you, unfortunately, but in terms of the partnership, of how we run. And then there's also, I feel like the open question people have asked, and I've seen people ask of like how is forma on Mainnet when Astria is not on Mainnet? I can address both of those. One of the cool things about this architecture from the aspect of Formas Mainnet, is that because at the end of the day, all of your data is posted to Celestia. The thing that makes forma main nettable, they are actually operating on top of. For right now, they're operating on a custom running instance of our devnet. They have four different validators that are running for that node, and then the data is posted to Celestia Mainnet specifically for their roll up.
00:29:17.090 - 00:29:57.024, Speaker A: And that data is going to be there, available in perpetuity. Well, not in perpetuity unless you are an archive node, but that data will be available on Mainnet for you. When you go and you say, I want to upgrade to the newest version of sequencer. When Astria hits mainnet, there's this upgrade path of, okay, now I want to switch similar to when we run things and test things locally. And I do this oftentimes when we're doing and shipping a new testnet or a new Devnet. And like, oh, I want to upgrade the, I want to get my roll up out, but there's some initial state that I want to have there. And so we'll do some establishing and going and building like, okay, here's the initial state setup.
00:29:57.024 - 00:30:29.540, Speaker A: And now we're going to launch it fully. But I can do this sort of like workflow in the release cycle to be like, as we could see when we looked at the block explorer here. And I did this very much on purpose because you can change what height you're interested in the sequencer at. If we look at this transaction here, this is in block one. I very purposefully, I previously initialized this. I did everything I needed to initialize. This thing hadn't been spun up at all.
00:30:29.540 - 00:31:09.980, Speaker A: I can turn this down and spin it back up and it will resync off of data off of two to other separate networks. But at block one, because I set it set where its block height started, first block has the first meaningful data to the roll up with formal, we can do that process to upgrade to using a main net sequencer. Right now they're a Devnet sequencer, but with assets that are real mainnet assets. Yeah. Then in terms of the partnership and how we work there, I think this is, this is something that's going to evolve over time with different partners. As the first team we've worked with, we have Kubernetes cluster, we work with them. They're like, hey, we want to do this upgrade.
00:31:09.980 - 00:31:51.910, Speaker A: We have this stuff. We just run their nodes and help to give general advice and help. It's like, hey, how should I integrate with this new upgrade? Is this going to work? Is this not. We work there? I think as we grow, obviously that partnership will become a little bit more formal, but it's a little bit first mover in the space, something a bit more technical. I just want to ask about ordering. How do you guys handle that? Sorry, what was that? Authoring them or ordering them? Sorry, sorry, ordering the transactions. What are you.
00:31:51.910 - 00:32:38.440, Speaker A: I'm assuming it's not just complex. So right now, and this is one of the areas where we talk about integrations, where we'll continue to build things that are useful for people. Right now, the way that transaction ordering works, it is essentially roll up driven to an extent, where you have the composer component builds batches of transactions. So if I fire off like 100 transactions into it, it observes the mempool and it watches for EVM transactions to go pending and then different. You can run multiple different composer instances, but when it finds transactions that are valid and pending, it will push them down. And this, I think builds into a full order flow pipeline. And it depends on what you're interested in.
00:32:38.440 - 00:33:31.906, Speaker A: As a roll up. If you are a roll up who is interested in having some sort of roll up built sequencing selection, edamar engineer who just walked in here put together a paper on how you could integrate with suave to say if I have a suave bundle, that's always the top of block for me from the actual sequencer. Right now it's default. It's essentially first come, first serve. But it's a little bit like there's some nonce stuff. Unlike comet BFT, we actually do some nonce ordering so that we make sure things execute in order of received and it's a little bit more clean. But the long term here is that there's going to be a full order flow set up on top of this and it's up to you how you want to integrate as a roll up and who you want to work with.
00:33:31.906 - 00:34:33.982, Speaker A: Maybe you just want first come, first served and you can participate in that way. Maybe you want a fully roll up owned builder, but you want decentralization of making sure you come have consensus over that. Those are options kind of abound there. Talk, I think, something about soft dynamic. Yeah, yeah. So I say like, to me I feel like, yeah, so this is, this is, I think soft finality is kind of the, and I've been trying to figure out how to reword this, but so we talk about, you know, when we go back to this diagram here, you get, we call it like firm commitments versus soft commitments. And really what you're getting from the data that's posted to Celestia is a commitment of availability of that because we have a smaller proposer network.
00:34:33.982 - 00:35:18.386, Speaker A: But if you get access to the data at soft commitment time, the only thing that could potentially happen to stop that from actually existing is if it didn't get posted to Celestia so that everyone you could verify with the reduced trust and higher certainty of data availability. That's the only point at which that's the difference between the soft and the firm. This is different than in ETH land where it's like, well, the soft commitment, the order might change. It's like, no, the order is not going to change. It's just either going to exist or not exist. If we do our job well and everyone operates their nodes correctly, then it will always end up existing. So it's just a matter of.
00:35:18.386 - 00:35:52.344, Speaker A: Soft is potentially the wrong term here. Yeah. So we run our sequencer and I think this data is here. We've been doing some large posting, so it might not show up here, but in Astrotech there's some like blockchain statistics. This one doesn't have the block time one yet. Blocks. Blocks might have it on it.
00:35:52.344 - 00:36:14.360, Speaker A: Yeah. Each block will show how long the block takes. You can see like 1.85 seconds right now running comment BFT consensus. So that's 2 seconds is kind of our like it should be about faster than 2 seconds. Just from a UI perspective. That's the soft commitment.
00:36:14.360 - 00:37:15.340, Speaker A: We execute those to the point of you can integrate any execution machine. This is actually a proto buff API that anyone can implement. We've implemented on a geth node to override the normal engine API. When you go in here and you execute a block, that doesn't necessarily add the commitment, but we have this idea of updating the commitment state and within eth the plate way that we use this and this is up to your decisions. But in general what we say is that when you get a soft commitment that is an ETH land, it's head and it's safe, then we wait to market final until it's firm. Whereas opposed to like in the normal eth world you would actually have like head and then later you'd have safe and then you'd have final. So yeah, it's like definitely more firm than what you would otherwise experience.
00:37:15.340 - 00:37:33.690, Speaker A: Yeah. Any other questions? Great, well thanks everyone. It was fun chat with you and yeah, hopefully that learned something.

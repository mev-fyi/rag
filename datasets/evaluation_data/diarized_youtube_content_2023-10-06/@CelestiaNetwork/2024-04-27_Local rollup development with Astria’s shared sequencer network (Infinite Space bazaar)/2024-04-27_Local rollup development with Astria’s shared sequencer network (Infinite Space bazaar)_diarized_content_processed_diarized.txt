00:00:22.960 - 00:00:49.174, Speaker A: Everyone, and welcome to another workshop for the infinite space Bazaar. My name is Josh from Celestia Labs, and I'll be your host today. Today I'm excited to welcome Jordan Oreshiba from the Astria team. Jordan is the CTO there, and we'll be doing learning about local roll up development with Astria's shared sequencer network today. Jordan, we're glad to have you here, and we're excited to learn more.
00:00:49.634 - 00:00:52.534, Speaker B: Yeah, GM, thanks for. Thanks for having me here.
00:00:54.494 - 00:00:55.754, Speaker A: What is Astria?
00:00:57.014 - 00:01:19.394, Speaker B: Yeah, Astria is, we started by calling it kind of a shared sequencer network, which is technically accurate in a sense. I think a better way to think about it is that we're building a sequencing layer on top of Celestia for people to utilize and make it easier to get fast, to find melody and decentralized sequencing and develops a building.
00:01:20.494 - 00:01:26.914, Speaker A: So this kind of solves the centralized sequencing problem that exists basically on every roll up today, right?
00:01:27.654 - 00:02:11.666, Speaker B: Yeah, that's the idea here. It also offers for rollups building on top of it, and this is kind of using our tooling and developing with it. The idea here is to offer a really easy to use developer experience. So if you're building a roll up, whether that's something that's an evm, it's something novel or a cosmos chain, the idea is that you can use this for any of those. It can provide a platform to do maybe more novel ideas. We had the messenger roll up thing that we put out. It was a hackathon project that we did, and it's entirely not built on top of Nivm, just built straight out of, on top of the services and whatnot.
00:02:11.666 - 00:02:21.872, Speaker B: We've built as an exercise to test it out, trying to make a great developer experience for people building on top of it. And, yeah, looking forward to learning more.
00:02:22.048 - 00:02:24.964, Speaker A: Want to go ahead and we're going to do a demo first?
00:02:26.384 - 00:02:36.324, Speaker B: Yeah, yeah. I'll start with walking through kind of the tooling and the demo and then kind of explain what's happening underneath the hood here. Yeah, I can go ahead and I'll set here for demo.
00:02:36.784 - 00:02:37.644, Speaker A: Awesome.
00:02:41.584 - 00:02:43.200, Speaker B: All right. Are we presenting?
00:02:43.272 - 00:02:44.842, Speaker A: Oh, yeah, we're up. Sorry.
00:02:45.008 - 00:03:22.134, Speaker B: All right, cool. So I'm going to walk through some of the docs that we have here just around the CLI tool we've put together recently. And this is, we've had a couple of different CLI tools that we've played around with, and this is our next phase of learning. The first thing we've done is here's how you is really about deploying the deployment tooling. And what we've built now is more geared towards the developer and kind of their needs when building new roll ups. Trying to build this entire pipeline of tooling from I'm building my role to I want to go forward and then actually deploy it and have a production application. And how do we make it easy to do that full cycle.
00:03:22.134 - 00:03:51.164, Speaker B: So to get started here, I actually set up and cleared and uninstalled everything. So I'm going to actually go ahead and install here. There's directions here for binaries. I'm going to use this. We're going to work on updating the docs so that it points to different oss. This is by default going to work for your smack silicon. All right, let's actually, let's completely empty demo environment here.
00:03:51.164 - 00:04:27.584, Speaker B: All right, and now let's paste that. Download everything. Just going to follow piece by piece through here what we have so we can see what you can expect to see if you run it on your local machine. And then we should be able to see the version on this. Go ahead. And then we'll go ahead and this require I do a sudo command on it. I move this just so I don't have to type the dot slash through everything else in the demo.
00:04:29.644 - 00:04:30.824, Speaker A: Pseudo mv.
00:04:32.064 - 00:04:36.672, Speaker B: Yeah. Thanks. Like it for not copying and pasting.
00:04:36.848 - 00:04:39.524, Speaker A: It's okay. It might be better that way.
00:04:44.144 - 00:05:05.464, Speaker B: Great. And then this is just basic software stuff. We can add package management stuff and whatnot to this over time we can see they have the same version running there. We also have instructions here on how you can build from source. This GitHub repo is open source, so you're free to go and look at it. I can run us through doing this, but it takes a little time. You just have to have go.
00:05:05.464 - 00:05:58.580, Speaker B: And then we use just for commands as opposed to a make file. It's a little bit cleaner for us once we have that. This is going to be the CLI tooling we can use for interacting. This has both the ability to work with remote to talk to our sequencer via CLI commands. We'll do a little bit of that later through the demo here as well as tooling for spinning up and running things. The other thing I'm going to pull here is I'm going to actually download a roll up we've built that's built on top of this we have a fork of go Ethereum and we're going to get started. The first step here in getting everything set up is to actually go and let's go in here, download this fork again that we've modified.
00:05:58.580 - 00:06:30.654, Speaker B: This works cleanly on top of all the other services and whatnot. We're going to be running to get this going. All right. And then check out our local dev branch. This has kind of the tooling and whatnot. We'll be merging this near future and then we're just going to build the go environment that we have here.
00:06:35.234 - 00:06:37.774, Speaker A: And just as like make, right?
00:06:38.154 - 00:07:18.028, Speaker B: Yeah, just is very similar to make. It's built in rust. It offers, you know, a simple way to scripts that you're using very frequently to create kind of nice, almost like building a, you know, custom cli for your given repo. Yeah, again, very similar to make just a little bit more customizable in terms of. Well, maybe not more customizable, but easier to customize in terms of what you do, at least from my viewpoint. All right, so we've built this roll up. We're now going to go ahead and do some configuration for what's needed in order to launch this.
00:07:18.028 - 00:07:54.704, Speaker B: I'm going to start by just creating a new wallet address here. This is going to print out a private key. Obviously this is going up on the Internet. No one should use this in real life. And then I'm going to edit this genesis file that we have and it's going to have information, has a couple of things in it. One is that it is a adaption of like a normal cath Genesis file. There's also some additional configuration features here for using the roll up.
00:07:54.704 - 00:08:54.444, Speaker B: All right, I'm going to just delete this whole string here and replace it with this new address. What this is going to do is that, you know, I now know the private key of on spin up or spinning up a dev roll up here. This is going to, this is going to allow us to know the private key that we can use when interacting with that in order to submit transactions and do such things. All right, so we have that there. I'm also just going to export this private key so I don't have to scroll up later. All right, we have that all set up. We can use that for our test transactions later.
00:08:54.444 - 00:09:25.604, Speaker B: And now I'm going to actually just start this again. We have some start commands here that make this a little bit easier. Just a net that's going to set up our. Yeah, I have a. I think I have to. Yeah, I should have to delete the. All right, initialize the geth node and then I'm going to leave this running here.
00:09:25.604 - 00:09:35.924, Speaker B: That first thing I do, start up. There's nothing connecting to this. There's nothing that's going to happen with it. And then, and create a new tab here. Let me make sure I have this big enough for us.
00:09:38.344 - 00:09:41.592, Speaker A: We did get a shout out for kudos for the character size.
00:09:41.688 - 00:09:41.944, Speaker B: So.
00:09:41.984 - 00:09:43.764, Speaker A: Yes, thank you.
00:09:46.744 - 00:10:08.924, Speaker B: All right, hopefully that's big enough. Cool. And then let's see the into our demo directory and create it here. All right, cool. So now we have this all started up. There's some commands that you can do here to restart this. We'll go through the flow there and how that might work for you a little bit later.
00:10:08.924 - 00:11:12.754, Speaker B: Next thing we have within our actual CLI tooling, we have some tooling in order to run a whole Astraea stack locally on your machine where you can see all of the logs. I start by just cleaning in case I have some stuff there. And then we just do Astria, go dev init and create some configuration files. It's also going to pull all of the binaries for various components that we need down. And depending on the version of, you know, these binaries are built for, they, they are built for either Apple silicon, Mac or Intel Silicon, as well as Linux on X 86 architecture. When you go and you pull the correct one, it'll pull the correct binaries for everything else that you're running onto your machine to run. All right, then we are going to go ahead and start this up.
00:11:12.754 - 00:11:55.874, Speaker B: All right, so as we spit up here, we're going to see, we have the core sequencer, we have a comet BFT. And then we have two components called composer and conductor. We have an inflight thing here. Usually on first startup this conductor errors. With this tooling, you can go and you can enter, you can see logs and then you can go back and then this one, you can just press r and it will restart the selected component. So this is going to be, if I had this bigger, you would see a little bit more in terms of what's going on. So I'm going to go ahead and disable autoscroll and then wrap.
00:11:55.874 - 00:12:04.274, Speaker B: So we can see kind of a, because it's so long, it seems like that goes up to the top.
00:12:04.314 - 00:12:04.666, Speaker A: Oops.
00:12:04.730 - 00:12:26.886, Speaker B: Haven't done with the text that big. But what we're seeing here is that we will. There we go. We can see new blocks being created and proposed executing index block events like.
00:12:26.910 - 00:12:28.874, Speaker A: Every second or 2 seconds.
00:12:30.134 - 00:12:32.390, Speaker B: Yeah, sorry, I'll go a little bit slower.
00:12:32.582 - 00:12:38.006, Speaker A: Oh no. But yeah, the blocks are being created about every like few seconds, it looks like.
00:12:38.070 - 00:13:16.494, Speaker B: Yeah, yeah. That should be created every 2 seconds. I actually think we have, as always, everything fails at the mostly an opportune time. I'm gonna, I'm gonna go ahead and right here we can quit. And then I'm gonna again go do a astria. Go of plan. All right.
00:13:16.494 - 00:14:14.574, Speaker B: Finalizing commit of block. All right, I think we're good here. If we go and we look, switch back over to our tab here, we can see, we can clean up these logs a little bit, but you can see there's various, we're getting these get genesis info, updating of commitment states and blocks being executed. If we go in here where I was saying, I'll show you real quick what you can do here is when this is because I restarted the whole network. What we can do is we can do it, just clean, restart, and that will spin everything up with a fresh database in here. Every time you restart, you usually have to restart the conductor process because it connects into that. That's part of why we start that up, something we're working on to improve.
00:14:14.574 - 00:15:00.378, Speaker B: And we can see here that we have commitment states and there will be blocks and such which are getting executed as well as new blocks are created on the network. Cool. So that's getting everything running. We now have a blockchain. We can go do some interaction with it. We have some docs kind of further down in here on how we can send a whole bundle of transactions to it. I'm going to create another tab here, make this larger.
00:15:00.378 - 00:15:01.294, Speaker B: Sorry.
00:15:02.674 - 00:15:11.614, Speaker A: While you're at it, actually, new move. The little streamyard is streaming bubble because it's over. Like, ah, maybe.
00:15:12.514 - 00:15:18.760, Speaker B: Yeah, there we go. Cool.
00:15:18.832 - 00:15:23.284, Speaker A: You restarted the container back there with just like hitting r in the Tui.
00:15:24.384 - 00:15:53.504, Speaker B: Yeah, yeah. You just hit r in the Tui. When you, when you highlight over it, you can press enter and you can see things are being sent to the Tui. You can see the execute block. Again, if I had to, if I make this a little bit wider, we'll be able to see a little bit more of kind of the logs here, larger screen, smaller font. You see a lot more. And we can see, you know, we can go and we can look at the sequencer and we can look at what we call composer.
00:15:53.504 - 00:16:35.352, Speaker B: So real quick on, this is probably a good time. This is, you know, the quick overview of how we, how we go through here. I give a higher level overview of kind of what these component boxes are and how we envision that working. And then also what your dev flow here is, so when I go through here and I was like okay, I want to go and I want to make changes. What I could do here is I can exit out of my geth node, I can go make changes to my role, do whatever I want to do and then I can run, in this instance just click restart. But basically I clear out the database and I restart this node. I go over here, I can keep this running in the background.
00:16:35.352 - 00:17:22.604, Speaker B: All I have to do is restart my conductor. What we actually see here where that ran through everything is that because the sequencer has been running, this is going to sync all of the blocks that have been created. If you're like oh, I have this edit and you change something with a smart contract, execution isn't working. You go, you make some updates, whatever you do, you can go and you can just restart this, it'll replay the execution that wasn't working for you in that roll up that you've already set up. So all you have to do is go your dev iteration cycle. So in comparison to the previous tooling that we've had to put together, it was really easy to run a roll up. But in order to do this active development cycle, where I go, I edit and I get my changes updated into it could be more tedious.
00:17:22.604 - 00:18:37.894, Speaker B: So the other thing here that you can do is if you have a set of transactions that you're running in, you like having inside this common BFT data is persisted. So if I can't, if I, if I close all of this down and start back up, those transactions will continue to persist. We're working on ways such that you can say, hey, hey, I have this sample set of transactions I run through. You can go and you can do a test, you can query, you can say given everything else at block height, you know, 100, I should expect to see this data hash and you can see that every time. So a lot more useful for the development cycle as opposed to before we were using kubernetes and helm charts and all of that, which is really great deployment tooling once you've already got your software figured out. So in terms of the actual architecture of what you go through here, I have a presentation that I can go through which we'll talk a little bit about the way we think about this high level of, you know, I can talk about what is a composer, what is a conductor, you know, purposely obtuse names and what, how they exist in our system for sure. Oh, there we go, I have it up.
00:18:37.894 - 00:19:39.360, Speaker B: The, so the idea here, like shared sequencing, you know, I say that it's a sequencing layer and that it's really built around. I like to say that shared sequencing is a blockchain which is optimized for base roll ups where, you know, Justin Drake had this in his initial post about based roll ups. It's based, if it's l one's roll up is said to be based, or l one sequence, when it's sequencing is driven by the base l one. I'm not a huge fan of the l one, l two, l three terminology myself. I'm a bit of a modular maxi and come from a microservices background. So I think that what we can actually say here is that a roll up is said to be based when its sequencing is derived from the base blockchain. And what defines l one, your base, it can be a little bit hand wavy in ethereum it's very clear.
00:19:39.360 - 00:20:18.056, Speaker B: But I think in this modular space where we use Celestia's dA, you have a sequencer, you have your own roll up. From our perspective, the sequencing defines the canonical data state, and you have your own state transition function and all of that. There can be social consensus over the software that's being run. It's not as simple as there's like an l one and it's the source of truth. And so this is kind of, you know, we say like a shared sequencing or a sequence. What makes it shared is that, you know, many people use it. But the idea of this kind of sequencing layer is people can submit, take their transactions, they end up getting submitted down.
00:20:18.056 - 00:21:39.674, Speaker B: We end up with this large block of everything, all the transactions from all the various roll ups, and then offer the tooling in order to take these roll up transactions, turn those into roll up blocks, and these go through your roll up your state transition function, if you will, and then create state routes on the other end while utilizing, we post our data to Celestia from the sequencing layer and talk about exactly how that's all architected. But the idea of conductor and the composer tooling is that you don't have to worry exactly about how it is, how it's structured and where it goes to. It just works. Celestia provides, you know, better data availability guarantees, which allows us for the sequencing layer to consider more about how we make the sequencing optimal while you get this firm propagation, censorship resistance from celestial underneath it. So in terms of what this architecture actually looks like, composure here when we have the full setup, is that we have our sequencer application, which is when we go back and we look at everything we have running that says sequencer, that says comma BFT, comma BFT is the consensus algorithm we use and the consensus engine. The sequencer app here is built at rust. It's a custom ABCI application.
00:21:39.674 - 00:22:17.194, Speaker B: There's a relaying component in order to post the data to Celestia that reads off of this comma BFT network. And then you have what's all composed into the roll up, and we have what we've called the conductor and the composer. The roll up is your execution state machine box. It's the app. If you're writing things in a Cosmos app, that would be a roll up. If you're writing working in ethereum land, like the execution engine would be the part that we're calling the roll up. This is really just a straight transition function and block storage.
00:22:17.194 - 00:22:59.480, Speaker B: The conductor is kind of the slightly magic sauce. It's not really all that magic, but it abstracts away a lot of the technical difficulty for you. It knows how to read off of sequencer. It knows how to read off of Celestia. There's some configuration that's determined based off of your, however you do your genesis on your all. That's when we looked at the geth Genesis, and there's some extra fields there that's all configuration for how the conductor is going to run that's hard coded into your Genesis file. It's going to read blocks that we call soft commitments off of the sequencer and execute them as quickly as it receives them.
00:22:59.480 - 00:23:43.774, Speaker B: That's at approximately two second block times right now. And then it's going to read data off of Celestia and then update to the roll up state. Like, hey, there's no affirmed commitment to this state. If for whatever reason your connection to sequencer gets censored, it's fully capable of reading data off of Celestia. In the future it will also, there is a need to have access to headers. We don't have this integrated yet, but adding a light client basically into here so it becomes a light client sequencer network required for doing verification of the data posted to Celestia and then composer tooling. Here is the submission flow.
00:23:43.774 - 00:24:23.344, Speaker B: If you're writing, if you're building a roll up, the cost of running your network or you have the l one l two fee profit situation. This is basically a way to take transactions as they come in and push them down to the sequencer when they are ready. We have built into this two ways in order to submit transactions. One of them is that if you're running a Geth EVM. It can monitor the mempool on the EVM, take pending transactions. It does some wrapping and submission directly to sequencer. This is a nice user experience for the users.
00:24:23.344 - 00:25:16.802, Speaker B: There's nothing technically stopping a user from creating their own transaction, wrapping it in the sequencer transaction, and submitting it directly. So you do have this direct submission path into the sequencer as well. Kind of similar to it to escape hatches when you're using other roll ups in the ethereum ecosystem. This is the core of what that is. And then when we talk about actually what you're building here, that I think the really curious thing here we talk about, we have the roll up, and then we have conductor, and it's like, what is this interface and how is that driven? Because that's the part that makes this conductor aspect actually really generic for building different blockchains we've integrated thus far. We've built our own custom messenger roll up. We have a test integration with Cosmos SDK, integrating actually directly into Rolekit, which then integrates into the Cosmos SDK.
00:25:16.802 - 00:25:58.576, Speaker B: And then we have this geth integration and being able to bridge and execute things across all these kind of unique ways that you're building things. So in building this and building this interface, we took a look at a lot of prior art. This is pulled out of Arbitrum's nitro white paper. And, you know, it's, if you, if you squid. Oh, right, yeah. If you, if you, if you squid it, this, it looks a lot like a sequencer layer. Transactions go into a sequencer in for arbitrum, and then they get a sequencer feed, a soft guarantee that goes down its batch and compressed and pushed to the l one chain.
00:25:58.576 - 00:26:34.956, Speaker B: This is very similar to what our relayer does, is it takes these, these batched and compressed things and push them to the sequencing layer. Take a set of sequence transactions, put them through the state transition function. We get, you know, direct into the sequence transactions. The state transition function can also read the batches off of the l one. If it doesn't have access to the sequencer directly, you generate your l two blocks. One of the things that we don't have any strong opinions on within our stack here is how you, what you do in terms of this, like, settlement where you post your l two blocks. If you're, if you're building on top of Astria, fully deterministic how you get there.
00:26:34.956 - 00:27:21.524, Speaker B: It's just a matter of figuring out what the right state route is and how you agree on that. Stateroom. So the other art we have here, this is pulled straight out of optimism. Docs. This is how they drive execution of their roll up using the engine API. There's a couple of problems with this from our perspective, when you're looking like, oh, can we reuse an existing API? A I'm not a huge fan of the way this API is designed around legacy get Ethereum stuff, but the engine fork choice updated here, it updates what your canonical head is. It also can initiate block building that happens within the roll up node.
00:27:21.524 - 00:28:24.404, Speaker B: That's something that you already have a deterministic set of transactions coming out of the Astria sequencer. So you don't really need to do this initiate block production. There's this whole payload id, and then in order to actually execute the block you need to submit an already built Ethereum block and then update to that fork choice state. Not really great from the perspective of generic nature. It works for Ethereum, obviously, but we wanted to build something that's not highly tied to a specific blockchain. The other prior art and one we actually use within our sequencing stack is that there's ABCI. And this may be small for hoax, sorry if it is, but there's a lot of things that go on in ABCI and a lot of them don't really apply when you're doing a based roll up, the idea of an entire consensus around and having to do votes and all of this, your transaction set is already set, it's just a matter of executing it and getting your state boost roof.
00:28:24.404 - 00:29:10.024, Speaker B: So, and there's also stuff in terms of, you know, state sync and all of that, which is kind of again to the point of no opinions on how you settle your state routes, not something that we're really wanting to implement and push forward with a strong opinion. So if we were to use the ABCI, we could more or less remove two thirds of it. You have to initialize your chain. Still, you need an ability to get info about the state of the chain finalized. Block can just execute and then you need to have the ability to do commits to it. And so we were like, what if we had a much simpler API? This is essentially how our API works. There's a whole sequence diagram up in our specs doc and a doc that I'll share later.
00:29:10.024 - 00:30:08.754, Speaker B: But the core of this is that we do this execute block and we get new roll up block. And then we also have this idea of updating software commitment states with this idea of the soft and firm. There's the soft which comes from the sequencer, where the, and then there's the firm, which comes from finding that data posted in Celestia. One thing to note here is that when we say it's soft, because we're using PFT as consensus, there has been a whole consensus algorithm run over this. There is consensus over the data, and it's been agreed upon by a decentralized network. What we're really saying by saying it's soft is that we can't guarantee that everyone had access to the data because we provide data availability to our proposer nodes. But you as an individual may struggle to get the data using Celestia, using Celestia node and having access to data visibility sampling allows you to kind of enforce, hey, there's a lot better guarantees of data availability and keeping you from getting censored, from receiving information.
00:30:08.754 - 00:31:03.864, Speaker B: So what does execute block look like? So we've built this as a GRPC service such that depending on any language you want to build on top of, you can go implement a server implementation of this very generic. Whether, you know, most blockchain folks are working in either go or rust, we use both. You know, we've integrated with go. Ethereum conductor itself is written in rust, and we have a couple of different implementations. The core here is that when you request, you have to know the block you're executing on top of, you have to know a set of transactions. This is data pulled out of the sequencer, and then in order to ensure repeatability, you need to have a timestamp. And this timestamp is taken straight from the sequencer block itself.
00:31:03.864 - 00:31:42.910, Speaker B: And it also ensures, this is one of the really nice things about using a shared sequencer. You have this kind of shared wall clock time. If you utilize it as your fork choice rule, there's options. We could get into it like, well, I really want to do blocks every 20 seconds and I consume ten. You can, but you lose some interoperability by doing that because you can't guarantee that every other roll up that's using that sequencing layer has blocks at the same time. So if I do something, you know, within the sequencing layer, you can submit a bundle that says, I'm submitting transactions to five different roll ups. I sign it, I push it down, we can, we can have that run, and it will only run on all five at the same time.
00:31:42.910 - 00:32:15.604, Speaker B: You have to know if your roll up is actually going to execute on that block time. This is kind of, I think, the best way to move forward, and then you respond with what a block is and this is only the things needed to continue driving us. There's a lot of other state routes and all of that and information presumably in your block. But just validating that the timestamp was, was correct based off of what was sent parent block hash. So we know what to execute. Validating that you executed it on top of the right block, the hash of that block. So we know what to execute on top of next.
00:32:15.604 - 00:32:57.980, Speaker B: And block number just makes a lot easier to index and keep on top of that. And so this is all the information that we need and allows us to do state commitments and whatnot after that. And again, this allows, because there's no determination of what block shape is, any of that. It's very simple. And even in comparison to this, where we eliminate things when you're using ABCI, if we look at how finalized block works or how in here you do prepare proposal and all of that. But those are all highly tied to relying that you have to use the comet DFT header shape. You can have whatever header shape, whatever block shape you want here.
00:32:57.980 - 00:33:04.224, Speaker B: You just have to be able to return these fields, which we think are pretty generic. Across, across blockchains.
00:33:05.644 - 00:33:10.860, Speaker A: Seems like it. Number hash and parent block hash for the block.
00:33:10.932 - 00:33:42.884, Speaker B: Yeah, number hashes and times, you know, the blocks happen at a time. They have to, have to have a hash and they're numbered. So that's the, that's the core we have here. We have some more information. I'll go through some of this here as well in our. If we, if we go back to doing the screen share, I can, I can go a little bit over for sure showing where we have some of these docs and some of the information on them. Cool.
00:33:42.884 - 00:33:44.728, Speaker B: Are we sharing again?
00:33:44.896 - 00:33:45.644, Speaker A: Yeah.
00:33:46.764 - 00:33:57.584, Speaker B: Cool. I'm going to go ahead and just make this a little bit wider for us right now. A couple of things here. Just let me. I'm going to have to make all of these bigger as we go through.
00:33:57.884 - 00:33:58.624, Speaker A: Perfect.
00:33:59.324 - 00:35:16.140, Speaker B: This is our go Ethereum fork right now we're in the process of, this is a strict fork of go Ethereum. When the process of migrating to a different branch here, we'll deprecate and point to that when it's updated, that will be kept in sync on a kind of more similar to the way that op Geth is. This started as us just confirming that everything we built worked and then over time has built built into a lot more. But this can be interesting to go and look and see within here we have, I mentioned that we have this server that was interesting. We've added this GRPC execution server and this is a implementation of that, of that interface. This is validation and these are kind of all of the endpoints that you have to integrate in order to support that API. This is also documented within our specs of our main we have a mono repo, all the code that's not our core CLI and this is going to spec out similar to if you've read like engine API documentation or whatnot, what each endpoint is.
00:35:16.140 - 00:36:22.436, Speaker B: There's a sequence diagram at the end so you can understand what's going on, but implementation details of what certain conditions that need to be met, as well as publishing all of the GRPC stuff to buff. So anyone can pull all of pull this down and build on top of it, build server server stubs and many different programming languages and there's documentation on each request and whatnot. The core of the actual execution service that you have to implement here is just these six methods where three of them are very simple and executing your block and then updating and tracking your commitment states. I just wanted to point out those two pieces of documentation. If we flow through here, we can see in this sequence diagram what exactly happens from a developer perspective across all of the stack. As a roll up developer, you only really have to be concerned with how this transaction, what you have to interface with on the roll up node. But this can be interesting to look at.
00:36:22.436 - 00:37:32.494, Speaker B: If you're curious about what happens with my block after I submit it to the sequencer, what happens in terms of consensus, how does it get pushed to the underlying DA and batched and when am I going to get my commitment updates? Interesting thing to look at. And then also wanted to show we have this messenger roll up. And I said previously, this is another implementation of our actual execution API on top of this similar structure here. But this is the whole server that's required in order to drive and start integrating with that, and provides a neat little on chain functionality where all of that data ends up getting posted to Celestia, visible for everyone there as well as on our sequencer network. Yeah, that's all the pages and such that I hadn't just kind of wanted to be able to show people existed. This also offers another way that the messenger currently has a docker compose thing that you could use as a sample of how, if you like using a dockerflow, how you could utilize that.
00:37:34.914 - 00:37:36.814, Speaker A: What is the messenger roll up?
00:37:37.954 - 00:38:10.224, Speaker B: Oh yeah, let's so the, this is our messenger roll up running on top of our latest devnet. You can go to eight bit chat. And anyone can type things in here, you know, and hit send, going to give you a unique id per reload of the page. So, you know, I can type in a couple of things here. And people can go to this website and type in publish. Yeah. And this is all posted to the sequencer and then.
00:38:10.224 - 00:38:41.364, Speaker B: Yeah, built by Ashwea. Underneath all this data goes to the sequencer before getting executed on the, on the chat and is posted data posted to Celestia. It's not necessarily human readable. On Celestia, we're using like, brotli compression right now on the data we put down in order to preserve data space and use as little as possible. But over time, we'll provide some more information there so that people know where they're, where their data stored, what the format is, and how they can interpret it. Try to add some tooling on top of that.
00:38:42.144 - 00:39:00.174, Speaker A: So what I want to understand a little bit, like, more at a high level, what happens? I send a chat here. So I hit, where does my message go? Like, where does it actually get posted to Celestia? Where does it, what does it do when going through the shared sequencing layer?
00:39:00.794 - 00:39:19.094, Speaker B: Yeah. So in terms of the messages that we sent here, these are all getting posted to our. Actually, I don't remember. We have two devnet networks that are live right now. I don't know whether or not this one is live on the dusk three network or the dusk four network.
00:39:20.184 - 00:39:22.000, Speaker A: Oh, good implementation details.
00:39:22.032 - 00:40:07.096, Speaker B: But the implementation, if I was thinking if it's the Ford network, I could actually go show you in a block explorer where the data is and whatnot. We have a similar to how selenium works. There is a astro trek that has been built, and you can see blobs and roll up data that have been posted. It looks like since we've been using this, it's probably the dusk three network, but you can see roll up transactions and blocks as they flow through here. So what happens when we, when we post the data through this eight bit chat is that, you know, as a developer, if you're building on top of this, we can see this. What's first going to happen is it's going to. It reads this data and then it's going to forward it.
00:40:07.096 - 00:40:32.308, Speaker B: I actually think there's two implementations. One that directly wraps and signs them and submits them to sequencer. There's a new version which we're in the process upgrading, which uses the composer. It kind of functions as a wallet mechanism for this. When you're using this chat and it's free to post. Ultimately someone's paying for the posting. So it goes through this composer piece which wraps that data, sends it down to the sequencer.
00:40:32.308 - 00:41:08.134, Speaker B: It goes into the sequencer mempool, goes through the full ABCI process, prepare process proposal, execute comma VFT happens, that happens on a two second block time. The conductor is following these blocks and then reads off of the sequencer. Every time there's a new block height, it reads the data unique to its own roll ups. There's actually an API that we've added to our app here which allows you to get the data, that's its header data off of the sequencer as well as the filtered data unique to your roll up.
00:41:08.434 - 00:41:08.898, Speaker A: Okay.
00:41:08.946 - 00:42:01.074, Speaker B: And it, and there's, and then it does validation over that data because we're pulling a partial block, we have a couple of state routes and all of that, which are, we have a couple of merkle trees that are conducted and or constructed or do validation. When you're pulling the partial data, it does the validation of that and then it sends it over. First it's going to do the execute block that's sent over so the block gets executed and then we update the commitment state to say this is safe data. The idea of this execute block and then update safe, is that also as a developer, if you're running your thing, you can run manual commands and you can say I want to execute this and just see what happens and test out just the execution before you figure it out. Finalization, how you're going to store the data. You're just like, I want to see what happens if I execute this one piece of data. You can do all of that.
00:42:01.074 - 00:42:07.434, Speaker B: So, and then it's going to go here.
00:42:08.454 - 00:42:13.234, Speaker A: Is that after or soft commitment? Like when does it actually end up?
00:42:14.414 - 00:43:18.842, Speaker B: This will show up as soon as it's a soft commitment. And so while this is happening, because the sequencer runs on this two second block time slashes approximately eleven second block times, there is a relayer component that we run post that data to slashy. It's going to back all of the blocks that have occurred over that time together and it's going to post, there's going to be a blob for the sequencer header metadata that's needed for verification. And then it's going to use what we call a roll up id. It's similar to a, you know, a celestial namespace, although ours are a little bit different constructed. We derive the celestial namespace from the roll up id and we post the data to that namespace. So when you go in conductor again, and that's reading data off of Celestia, it's reading that sequencer metadata and your unique block data without having to pull anyone else's.
00:43:18.842 - 00:43:29.284, Speaker B: So you can see all of your unique sets of transactions. You can see all of those on your specific roll up namespace on Celestia as well.
00:43:31.024 - 00:43:33.524, Speaker A: You know, actually, do you have this one handy?
00:43:34.904 - 00:43:59.414, Speaker B: I do not have this one. Yeah, yeah, sorry. That would be, that would be neat. If I could, if we could go and show you what all is being posted there. We also have. So in this instance, you'll note that, like, when I'm running everything here and I'm running locally, we are not running a selection instance locally while testing this. That's, you know, from that there are ways and we can go through here that.
00:43:59.414 - 00:44:23.166, Speaker B: Actually, one thing I didn't do in this demo is there's also a way when we're doing this to run your roll up. Like, oh, I tested it all locally and it works within the overview documentation here. You go down. It's like, okay, I tested it all locally. I actually want to test this against Devnet. Right? Instead of running a local sequencer and comment BFT, I want to run this against Devnet. We have documentation here on how you can do this.
00:44:23.166 - 00:44:54.904, Speaker B: Improving the workflow here a little bit over time so that you don't have to go manually edit as many files, add some more configuration stuff. The downside to using, posting here data to Devnet is that you need to have dev tokens. There's a faucet that you can go to and grab tokens there and use. But it's a lot easier for most development to have your local flow and then to do a test verification against the Devnet.
00:44:58.684 - 00:45:08.064, Speaker A: Garang Patel asked in the chat, who pays for the chat posts? They're free, but someone's paying for it, right?
00:45:08.844 - 00:45:30.394, Speaker B: Yeah, right now that's us. Okay. We run this and this is all running, uh, right now the way this is running, you know, this isn't live on, on mainnet. So this is, um, this is going through our, our Devnet. So, you know, it's, it's kind of our free funny money.
00:45:31.014 - 00:45:33.894, Speaker A: And I guess it's going to a celestial testnet as well.
00:45:34.054 - 00:46:27.376, Speaker B: Yeah, it's going to a celestial testnet as well. Nice. Um, in a production setting, you know, for the chat here, there's, there's options. So for the EVM, kind of the way the flow here works is that when you post data to the sequencer, it collects enough fees in order to pay the DA costs underneath it. And then similarly, when you're designing your roll up, again, this is up to your roll up design, to your design and what you're doing. One of the upsides of building on top of an EVM is that there's a wide set of wallet technology and whatnot available, but you could build this such that, you know, you go and you hit send, it asks metamask, and then you pay whatever, you know, a couple cents low gas fees because it's your roll up. And then it goes through and signs a transaction, sends it.
00:46:27.376 - 00:46:49.764, Speaker B: You could, you could honor just, you know, some basic ETH stuff while not having to use the whole EVm, and just gather enough in fees in order to also pay for various data posting things. Or you could have this such that it takes the transaction, wraps it and signs it, and sends it directly through to the sequencer without having to touch your roll up node beforehand. Those are both options.
00:46:50.504 - 00:46:56.484, Speaker A: Then another question from going is, who would pay for it in a realistic scenario, what do you think?
00:46:58.304 - 00:47:38.976, Speaker B: Well, that's going to depend on your business. Um, and, and what, what you're trying to accomplish with your roll up. I mean, like, it could be a, a user ends up paying it, it could be that, um, the roll up itself, you know, there's the, the roll up itself pays for it because this offers value in some, some other way to them back through, through other things. You know, maybe, maybe through this you, you update this modular chat and you can do swap trading through it. And there's ways that you make fees off of that. There's various, like you had bought integrations and all those sorts of things. Maybe that's how you make money.
00:47:38.976 - 00:47:45.804, Speaker B: And it's worth it for people to just be able to send nonsense through for free because it gets people using your product. Ultimately, business decision.
00:47:46.304 - 00:48:05.764, Speaker A: Yeah. So I guess, like you also could think of it as kind of like in the EVM world, there's a lot of account abstraction tools and one of them would be like a pay master. So I think you can kind of think of this implementation as like Astria is the paymaster. They're just covering the fees for everyone.
00:48:06.904 - 00:48:09.364, Speaker B: Yeah, yeah, precisely.
00:48:12.624 - 00:48:17.004, Speaker A: So I have a few questions, unless you had anything else.
00:48:17.504 - 00:48:20.656, Speaker B: I don't have anything else. Happy to take some questions. Yeah.
00:48:20.720 - 00:48:25.662, Speaker A: So I guess you mentioned nitro and op stack during the presentation.
00:48:25.798 - 00:48:26.518, Speaker B: Yeah.
00:48:26.686 - 00:48:46.354, Speaker A: And you also mentioned rolekit. So my understanding, correct that you could use like all of these on their own. Obviously, but, like, I could have three roll ups running, one with each framework, and they could all use Astria's shared sequencing layer without, like, really, like, any problems. Like, it would just work, right?
00:48:47.214 - 00:49:45.280, Speaker B: Yeah, yeah. So, I mean, so in terms of, you know, this local dev environment, this isn't optimized in order to show that, um, but back in, um, the, the last kind of demo I did, I did with all of this was using a, like, has a lot more dependencies. Not as great for local development, but shows kind of what you can do in terms of deployment. I was able to deploy four different, you know, geth roll ups on top of different namespace with different chain ids, and you can connect to them and there's no, no interference, they just run smoothly next to each other. Same thing with any of these other stacks. We have like a cursory go through of getting the op stack to work on top of what we have here. I think the op stack is in a lot of ways very similar, except that it has opinions on where state routes get posted from.
00:49:45.280 - 00:50:41.014, Speaker B: From how this works, the conductor piece looks a lot like what Op node is in their stack. In terms of op node is responsible for reading and verifying and driving execution. Very similar to a consensus client on traditional Ethereum, and very similar to what BFT does in cosmos chains. Yeah, you could run all three of those on top of a sequencer, and because of the way all the data is name spaced, no interaction between them required whatsoever. The other cool thing, and this is something that we'll be investigating more in the future, is because it's all posted to different namespaces, you could theoretically have a roll up. You post and you say, what I'm actually interested in is parts of data from both of these, and I'm going to observe all three of these roll ups, data they're posting, and then do some action based off of the conglomerate.
00:50:41.514 - 00:50:43.974, Speaker A: Interesting. Sound like a meta roll up?
00:50:44.814 - 00:51:04.390, Speaker B: Yeah, you could create something like a meta roll up. I think this is more useful if, you know, as we build up over time. You could have a roll up that posts oracle data or something along those lines that could be consumed across many different roll ups at its own oracle.
00:51:04.422 - 00:51:07.774, Speaker A: Data set and that kind of same.
00:51:07.814 - 00:51:09.498, Speaker B: Time on all of the roll ups.
00:51:09.646 - 00:51:14.306, Speaker A: It sounds like it would solve the oracle problem for rollups if there were one kind of.
00:51:14.330 - 00:51:15.654, Speaker B: Yeah, yeah.
00:51:17.194 - 00:51:35.574, Speaker A: Goreng has another question. Actually, first, I thank you for the last answers, and apologies if you've covered this already, but are there any optimizations made now or planned in the future for posting data to celestia. That is batching or compression compressing.
00:51:36.274 - 00:52:20.094, Speaker B: Yeah. So the data we post to Celestia is batched and compressed. So we batched across, you know, because we have block times of 2 seconds and Celestia's eleven second block times. We batch all of that data together and then we compress it with one of actually, the nice things. If we talk about the way arbitrum works, they have their, their sequencers very much in the hot path, so they do compression using like, I think it's like brotli at like its lowest setting. Compress data and post it because it's actually not in the hot path of you getting the data back from the roll up. Because we operate on this eleven second time window, we can actually do a little bit more compression.
00:52:20.094 - 00:52:47.954, Speaker B: And so I think right now we added brotli at like a level five, which gets you in large data cases. So in instances where you have larger amounts of data, it can get up to, you know, like a compression ratio of eight. So eight times as much data as you would need. Saves money for roll up. Developers keeps our fees lower and. Yeah, that's cool.
00:52:50.774 - 00:52:53.834, Speaker A: When Astria ref. Go on.
00:52:54.774 - 00:53:40.614, Speaker B: When Astria ref. Yeah, so this is, this is something we've investigated going back to, you know, our core team, the sequencer, composer and conductor, are all written in rust. The very earliest design docs of Astri, from before ref was announced, had us using REVM and, you know, potentially putting a, you know, getting a EVM running. That was kind of a full custom thing on top of this. The answer is like, it's a matter of staffing and stability, building a building, all of the integrations. And at one point we were halfway done and they changed their database. So we just haven't prioritized it recently.
00:53:40.614 - 00:53:43.914, Speaker B: But yeah, eventually.
00:53:46.854 - 00:53:49.262, Speaker A: You were going on something before I asked that.
00:53:49.358 - 00:54:28.748, Speaker B: Oh, I was going to say too, that the other aspect here we talk about who's paying for the fees, right? We compress the data that we post to Celestia because Astria has no insight into what you're trying. I mean, we have the bytes, but we don't do anything with them except keep them as bytes. If you were doing the sort of pay master flow and your roll up wanted to, you could theoretically do compression on the transactions themselves before you read them, which can, can save fees at higher up the stack as well. Obviously reduces the effectiveness of the compression for us lower down, but it's a way for you to reduce your fees as well.
00:54:28.916 - 00:54:33.184, Speaker A: What kind of scale does that reduce? Like the size by.
00:54:33.964 - 00:55:11.244, Speaker B: Yeah, so this is where it's going to depend on the type of transactions you have. Compression is only going to be useful on larger data sets. So, you know, if you were a roll up that was building something that for whatever reason, sent, you know, large globs of strings through, like, you might want to compress your data before you push it. But if you're doing small, like, smaller, you know, EVM transactions, and thus it's probably not going to be as beneficial, because until you get to larger batch sizes, the compression doesn't offer much benefits.
00:55:11.744 - 00:55:21.604, Speaker A: Makes sense. What bounties do you have for the infinite space bazaar? And the follow up there is, what would you like to see built?
00:55:22.944 - 00:56:38.470, Speaker B: What would I like to see built? Okay, I believe for the infinite space bazaar, we have a, like, best non EVM roll up. This comes down to my, the EVM exists and is very popular for a lot of reasons, but I'm really excited to see the innovation that people can do when they're, when there's other tooling options. And one of the things I'm excited about personally, in the long run about this sort of infrastructure is that it unlocks me from having to build cosmos or not. I can build whatever I want. So we have that bounty, and I think it's, I don't want to miss, say, the dollar amount here, but that's what we have a bounty for, if I recall correctly. Um, what would I like to see built? I, I don't think I have any, like, really super strong, strong thoughts here. I think there's things that could be interesting in public goods standpoints, you know, I think the, the messenger roll up we put together started as just a meme that we had within our team, because I was saying that, like, everything eventually becomes a, everything eventually becomes, are we still presenting or are we just talking?
00:56:38.542 - 00:56:39.514, Speaker A: I'm coming back.
00:56:41.014 - 00:57:10.164, Speaker B: No, I wasn't, I didn't mean to present. Yeah, the everything eventually becomes a chat app is something that's said a lot in web. Two circles of every app you build, eventually someone integrates chat with it. And so I was like, we're building a blockchain. We should build a chat app, because everything eventually becomes a chat app. And then we did it as kind of a team hackathon project. So I think whatever cool thing you're doing is, and whatever interests you is really cool.
00:57:10.164 - 00:58:07.002, Speaker B: But one of the ideas I've had floating around the back of my mind is that it would be really cool to have audit logs that are posted on a blockchain, some sort of roll up specifically built for this. In a previous life, I worked in privacy and compliance data stuff. And so the ability to say, you know, this person accessed this data and we know it's true. One of the big things when you're working at a big tech company or some sort of small companies, who has access to the database of the audit logs, because if you're an actor within that that's doing something fraudulent, then you may be able to go and delete the log of your audit. So by having sort of audit logs on this public ledger, you know, it costs money, but it provides this functionality to a company. If, even if you're not building on top of web3 technology, to be able to say, we posted the data onto the blockchain, it's there forever. So we can guarantee the audit and it's publicly hosted public good.
00:58:07.002 - 00:58:08.774, Speaker B: I think it's a cool idea.
00:58:09.114 - 00:58:25.014, Speaker A: Interesting. One more question on compression, I think anything other than compression hosting during low gas, etcetera, or is that not really relevant right now?
00:58:28.134 - 00:59:10.084, Speaker B: Yes. Yeah, I think I understand the question. As the EVM Denkin upgrade went live, we saw some price spiking on blobs within the EVM space. We haven't seen that as far as I'm aware of. On Celestia to date, there was a brief period of high gas fees because people did inscription with actual transfer transactions as opposed to using blobs, which is really funny to me. But we don't have anything around prioritizing low gas periods or anything with data posting. There's not a direct.
00:59:10.084 - 00:59:54.394, Speaker B: In our current system, it is a non automatic update on the sequencer side. In terms of fees to update around things, there's a toggle where you can be like, okay, the fees need to go up. But yeah, so nothing around that. I think long term, there's some like, derivative market stuff over blob space. But the rally in Celestia right now is what, when I look at the blob space is that it's not being over utilized at the moment. So we're not seeing any huge gas fluctuations as we get around that, we'll figure out the way to prioritize that. If you prioritize for gas fees, there can be downsides.
00:59:54.394 - 01:00:16.534, Speaker B: I'm going to post data only when there's low gas fees. It's like, well, I think that right now the gas fees high, but the next block it ends up higher. How long do you wait before you bite the bullet and just say, I got to spend the money. So without some sort of smoothing function abilities to buy groups of blocks and whatnot, that'll be kind of probably the future there.
01:00:16.914 - 01:00:25.054, Speaker A: Cool. Speaking of the future, are there any things that you're really excited about that Astra is working on that you might have not shared already?
01:00:29.434 - 01:01:09.734, Speaker B: I'm really excited. I mean, not something that's not shared, but excited to see the former stuff that we've been working with them to get the NFT space on top of celestial Live. We're in a place right now where we're working towards. We have a slightly different architecture to the way that most blockchains are operating in terms of what quantifies as a devnet, what quantifies a testnet, and what qualifies as main net. Maybe not as a main net. I think we all have a pretty firm agreement on that one. We've launched a lot of, we've done these devnets but haven't launched a testnet to date.
01:01:09.734 - 01:02:00.244, Speaker B: And that's because my view on a testnet is that a testnet a, you have to have decentralized folks running things. If you have a bunch of testnets with no incentive for the people running them, it can be difficult from a validator relationship. But the other aspect is that I think testnets are really intended as, to be as close to possible as what main net will be. And so we're getting really close to feeling like we're locked into a point where we're ready to launch testnet, do some testing of the network decentralization pieces there. We've done internal testing on this, but haven't gone out and worked with all the validators on getting everything running. They're running some full nodes right now. Yeah, that's exciting for that.
01:02:00.244 - 01:02:01.484, Speaker B: Awesome.
01:02:02.864 - 01:02:12.164, Speaker A: And where's the best place to go? If I'm building something with Astria, I run into something I have a question about. Is the ISB discord a good place?
01:02:13.224 - 01:02:34.556, Speaker B: Yeah, yeah, the ISB discord. We have four of us in there if you're, if you're working on, you know, infinite space. Bizarre stuff. Great place to go. We also have our, our own discord with like an issues ticket management thing if you're running into issues. Or you can open up a GitHub issue on one of our repos if you have something more specific to a.
01:02:34.580 - 01:02:39.156, Speaker A: Specific code base and I guess all of our. Yeah, yeah.
01:02:39.180 - 01:02:47.024, Speaker B: This is one of the things that from day one, you know, all of our code has been open source, so it's out there and available for you to look through and read.
01:02:47.404 - 01:03:12.604, Speaker A: Cool. And I just want to throw the website out there. Astria.org is where you can find all of these places that Jordan just mentioned. I want to thank everyone for attending the last workshop of the week, and we look forward to seeing you next week for another one. Jordan, thank you for teaching us about Astria and, yeah, showing us a demo as well. That was really insightful.
01:03:13.304 - 01:03:14.844, Speaker B: Yeah, thanks so much.
01:03:15.144 - 01:03:15.904, Speaker A: Have a good one, everyone.

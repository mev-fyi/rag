00:00:01.930 - 00:00:31.160, Speaker A: We are going to be talking about some exciting ZK applications. As you may know, zkps have only really become feasible in the last few years, and there's been tons of experimentation going around trying to use them to extend and improve on existing technology. So specifically, we're going to talk about machine learning and a little bit on identity, given the expertise of our panelists. So we'll start off with introductions. I'm Ishida, and I do research in the space.
00:00:31.690 - 00:00:37.560, Speaker B: Hey, everybody, I'm Daniel, and we start a company called Modulus. We work on zero knowledge machine learning.
00:00:38.490 - 00:00:49.770, Speaker C: And I'm Lakshman. I work on personi, where we think about what identity looks like on Ethereum in 100 years, which turns out to use zero knowledge.
00:00:52.590 - 00:01:01.950, Speaker A: Can each of you walk us through the state of ZK tech right now and specifically what's been built within and outside of crypto and what's still a work in progress?
00:01:03.810 - 00:01:46.014, Speaker B: Sure. Yeah, I think, actually Lakshman and I agree on maybe a lot of this, so I'll make sure to leave some protein to be shared, but kind of from our perspective at Modulus. The big scary thing about all this investment into ZK and its application to blockchain networks is that it's all focused on proving VM operations, or evms. Right, which kind of makes sense, right? We want to prove the entire execution of a blockchain network, compress that effectively, and then bring that onto the network that's doing the verification. Awesome. But it leaves a lot of space for other kinds of kind of specialization. Right? So in the case of Modulus, we're really excited about machine learning.
00:01:46.014 - 00:02:17.800, Speaker B: And if you know anything about AI operations, you notice it's super repetitive, it's highly structured, and it has these architectural features that represent a downselection of all possible VM operations. Right? And so I guess our insight was that potentially, if we build a ZK system that's purpose oriented for machine learning, then we can get much better proving overhead. And actually, this is a little bit of what Harry works on as. So that's kind of our orientation. We think that might be.
00:02:20.970 - 00:03:04.454, Speaker C: Mean. We were just talking about this backstage. But a very similar observation that what a zero knowledge proof isn't the ideal. There's many different parameters you can improve on based on what specifically you're trying to do. And so a lot, obviously, most attention is on scaling vms, which I think is a good thing. We think mostly about the zero knowledge side and specifically getting things to work in a very resource constrained environment. It's super important for a true zero knowledge application, for the users of the application to not be delegating the proving anywhere else or sending the private information anywhere else.
00:03:04.454 - 00:03:44.114, Speaker C: So we spent a lot of time thinking about this very specific problem, about making these very specific ZK circuits, I. E like proving a signature for a given crypto system, work on a mobile device. And that's led us down like a pretty unique path in terms of proofing system and stuff like that. But at the same time, it's super inspiring seeing we take a lot of inspiration from all of the stuff happening in the more general systems. Because the thing I'm learning, I'm honestly not a cryptographer by training. I've been learning a lot as we go, but the moving pieces of a lot of these systems are kind of very common. And so we're learning a lot.
00:03:44.114 - 00:03:51.526, Speaker C: Just learning, like seeing what's being tried and understanding the different trade offs between using the different components of these systems, which is cool.
00:03:51.708 - 00:04:03.206, Speaker A: Hey Harry, you want to do a little intro? And we're just talking about the state of ZK tech, so talking about what's been built within and outside of crypto and what's still a work in progress.
00:04:03.398 - 00:04:58.250, Speaker D: Awesome. So, yeah, I'm Harry, one of the co founders of Jensen. We're a machine learning compute protocol which uses proof systems in order to lower the costs of verifying that trading has happened. Concretely, we use polynomial interactive oracle proofs in our verification system, which were quite recently popularized by Justin Fowler. I think broadly speaking, in the kind of wider applied gene knowledge space, there's like three trends which come to mind. The first would be around the overall kind of trend away from using elliptic curve cryptography into using more kind of hash function security. So you see that with examples like Starknet, you'd also look at things like the kind of emergence of zero knowledge ethereum virtual machines which assist with the wider kind of confirmation of the blocks on the chain itself.
00:04:58.250 - 00:05:34.918, Speaker D: So you see that with scroll. But then, most relevantly for us, it's about very kind of operation specific forms of zero knowledge. So for example, you see with z conduits, a ZcO library for doing zero knowledge image classification, like ZkCNN, they typically use kind of off the shelf proof systems for VAT, but we think that that can become much faster, like maybe free oritudes of magnitude faster if you specialize the proof systems. So that's a bit about me and then the kind of free areas that I'm excited about.
00:05:35.084 - 00:05:51.520, Speaker A: Thank you. So first, let's touch on identity. I'm excited to see what you say about this. So, in the advent of AI, do you think it's important to distinguish bots from humans? And how far can biometric verification take us?
00:05:52.210 - 00:07:19.154, Speaker C: Yeah, it's funny, I've been having this conversation with a lot of people recently, and I'm in a strongly opinions weekly held place of mind where I want people to tell me I'm wrong. But also, something feels quite true about what I think right now, which is I think there's a conflation between AI and bots, which is humans controlling AI, in the sense that if we're distinguishing between a human, having made the signature on some piece of data, as whether or not it's like an AI, a human could stamp a thousand pieces of data and send them to a bunch of bots to distribute to a bunch of people. And I think that's the thing. I think a lot of people are scared about when they look at Twitter bots and sort of connect that problem with sort of the value of distinguishing AI and humans. And I think that's really distinguishing humans from humans with bots, which is slightly different. As for literally whether or not it's good to distinguish humans and AI, yeah, I think in the stuff we're building, we think a lot about the importance of exit in our systems. We want humans or AI to sort of be able to shed their old identity and form a new identity very easily.
00:07:19.154 - 00:08:01.590, Speaker C: This feels, like fundamental to some of my personal values and some of the old crypto libertarian, crypto anarchist values, and feels like a good property of a system to have. And it's hard to have such a system if every human is only one identity or is identifiable as a human. So I think that's quite challenging. I also worry that if the probability of AI doom is high, then any system that is good at identifying humans is really like a human directory for bots, for AI, it becomes a tool for control by not necessarily something that humans are using anymore. So it's a very nuanced question. I don't know what the answers are here, but I also think that the narratives are probably a little simplified.
00:08:02.970 - 00:08:05.666, Speaker A: Do you guys have anything to add, Harry?
00:08:05.858 - 00:08:57.170, Speaker D: I've got a lot to add. I think it's important for two reasons. The first one is there will be, I reckon, in the next nine months, a major public outcry about the use of, or, I guess, the acquisition of, other people's identities. And it's used to defraud people with the state of the art kind of generative voice and vision models, it will become essentially impossible to delineate real from fake. And a really kind of clean way of solving that problem is by somehow proving your humanity and then using that proof to, say, chunk and sign any calls or kind of video that you create on chain. So you could imagine that if you were in a Zoom call, this simultaneous to the Zoom call, you could be kind of independently confirming that, yeah, you're on that call. It's you, it's your private key, et cetera.
00:08:57.170 - 00:09:42.470, Speaker D: That's the kind of short run benefit of it. I think it's just more of a kind of security and fraud piece. But the longer term advantage, I think, is we see a Jensen within the next five years, the majority of compute being requisitioned will be by machines, not people. We think that the kind of substrate for artificial general intelligence will be on chain. And when that happens, you get these kind of very philosophical, almost like blade Runner style questions about who's real and who has rights and what are the rights of the kind of autonomous beings out there. I think having a way to confirm yourself is essentially the same as having a passport or an identity in general. And you need that to function in a world where we're kind of coexisting with another artificial species.
00:09:43.930 - 00:09:52.060, Speaker A: So how do you think humans and bots, how do you think we can be collaborative in the future?
00:09:56.110 - 00:11:22.066, Speaker B: Yeah, I think it starts with the ability to, I think, kind of what's already been mentioned, but just stamp one as one and the other as the other, right? So in some sense, what we work on at modulus is the ability for AI processes or AI models or AGI one day potentially, to stamp their work, right? We do the is model kind of process, right? I mean, the way we do it is using ZK circuits and generating a proof that's verified somewhere. But you can imagine the analog being like an artist signing their masterpiece and then giving it to somebody, and then that signature being what testifies to the authenticity of that work, right? In fact, we're in the process of taking a generative model. In this case, it outputs pixel art and putting it on chain via this ZK process and embedding it in kind of the NFT container, right? So the actual machine artist is itself on chain. And that's really interesting, right? Because suddenly this AI process is a distinguishable entity. And obviously you can imagine lots of these different agents interacting with each other as a kind of collaborative process on chain, because there is that agreed upon, immutable basis for reality there. So that's like one vision. There's lots of other ones, but I try to get very, very specific because AI is so expressive and it's so easy to get into the AGI conversation.
00:11:22.066 - 00:11:30.140, Speaker B: I'm still trying to get my toast to come out right every time, so there's always more nuance and more kind of process to get there.
00:11:30.750 - 00:12:20.634, Speaker C: I'm actually kind of curious to ask both of you just to push back, because I think I represent the other perspective. Why, fundamentally, is it good for AI and humans to sort of be distinguished online? I think this is more of a feeling than a rational thought, but it seems conceivable that such a delineation creates less empathy between the two agents in the very long term. I'm sort of maybe naively envisioning a world where there are these more powerful beings out there, but we're all sort of doing the thing, and it doesn't matter who's who. Yeah, I'm curious to dig into that a bit more.
00:12:20.752 - 00:13:07.990, Speaker D: Yeah. So for me, it fundamentally comes down to liability. A good example of this would be autonomous driving. If you have a car which is self driving, and the car crashes into someone, do you think you're as responsible as if you were driving it? If the answer is no, then it fall, which is, for me. Then it follows that when you have a brain machine interface attached to your scal in approximately ten years, and that interface is using on your own network to expand the scope and memory that you have in your mind and also making some decisions for you, like maybe it's filtering your emails or something, or maybe it's doing even more things. Are the actions of that model your actions? I think the answer is also no. So that requires there to be an individual identity for the organic part of your brain and the artificial part of your brain.
00:13:09.310 - 00:14:04.460, Speaker B: Yeah, I think the liability point is very concrete, but maybe the other orientation to tackle this precise kind of premise around empathy, and to be clear, I don't think it will be binary, right? There will be some operations and some ambiguity as a default, and then there will be certain kind of properties or processes that are stamped with signatures in the future. That's kind of my impression of things, but I actually think the better path to having empathy for one another or making the collaboration more productive is the capacity to delineate bot from human right. Just look at kind of stability, AI and stable diffusion, and all this uproar against. Like, I'm an artist, I feel like my artwork is being attacked because it's being used to train models are much more performant than I can be at a really high scale. We're looking at the Hollywood kind of protests right now between the writers and the actors saying, I just want you to put in the contract that you're not going to replace me with an LLM. That's very performant. Right.
00:14:04.460 - 00:14:44.920, Speaker B: I don't think it's at all practical to put the brakes on these life changing technologies that can be very productive for society, like llms or generative models. But I also think that if we want to build some, this is what I guess blockchain systems are really good at, right? Which is like ground truth. This is the reality that in the digital world anyways, that we all have to agree to. So if we can take advantage of that property and put the things that we want to differentiate or delineate on that ledger, then that, for me anyways, is a more egalitarian way of approaching empathy between humans and agents.
00:14:46.490 - 00:15:05.774, Speaker C: Yeah, that makes sense. I suppose there are also humans whose factors on chain make them seem more AI than some. That's, that's a fair. I don't want to navel gaze in this too much and take the panel away from actual applications of ZK, but I'm excited to jam more on this later.
00:15:05.812 - 00:15:17.380, Speaker A: Yeah, that's interesting. So we can switch gears and talk about ZKML a little bit. So Daniel and Harry, what's sort of the state of machine learning at the moment and the role that trust.
00:15:23.830 - 00:16:36.538, Speaker B: From my angle, Modulus. We spent a lot of time thinking about cost. I'm sure Jensen's actually quite similar in this regard, in part because to me as a, you know, we all kind of were doing AI research before this, right? The story of AI is a little bit the story of cost, right? Like what happened in 2009 ish, that suddenly deep learning as a method for training models and in generating these emergent, amazing magical outputs. Why is it that 2009 was this pivotal year where decades of theory suddenly got put into practice? For me, it's gpus. And the fact that this new computing form factor became widely accessible and like, look, you can build a GPU server farm out of cpus, it would just be significantly more expensive, right? So we brought the cost of compute down significantly, made it much more accessible. And in selling these methods of training models, deep learning, oftentimes known, gave us the models that we are all really excited about today, right? And obviously we can draw parallels to the Zk world and circuits. I think that's later in the conversation, but maybe I'll just end by saying it's like super non obvious, right? It's not like if I get more parameters, my performance on my model is linearly better.
00:16:36.538 - 00:17:35.070, Speaker B: It's this weird step function looking thing where emergent properties just show up as models get bigger and more sophisticated. That doesn't seem to be changing anytime soon. So we're just all marching towards more parameters and more compute and more electricity and so forth. I'm sure that blows up Jensen's tam into something amazing, which is awesome. I'm very excited for Harry and Ben, but I think from my angle, we're just at the beginning, right? Because although that is the dominant trend, there's also the trend of more sophisticated architectures, better learning models or better learning methodologies, right? Quantizing our models to save on electricity and make them more ZK friendly. There's all these subfields of research which are emerging as well underneath the current of more compute, more compute, more performance, more attention, more money. So, yeah, AI is most likely or almost certainly going to be the most expressive transformative technology of our time, besides maybe crypto, but I'm biased.
00:17:36.210 - 00:18:42.366, Speaker D: Yeah, I would just vibe on all of that. For anyone who doesn't know, the kind of tour de force of deep learning came up in the kind of late 1940s, the neural network architectures, then during the kind of 50s, had its first applied use case predicting Weber for the US Navy big kind of winter in between late 2000s, stacking different layers of a neural network and combining it with something called stochastic gradient descent. So, basically, the idea that you are comfortable with the model learning in a slightly randomized but more efficient way, combined with the compute power that Daniel mentioned, causing explosion in image recognition models. So the classic was like predicting, is it a cat or is it like a muffet, or is it a dog, or is it a muffin? And all this kind of like these kind of funny toy examples. And then throughout the kind of 2010s, we got to the point where around 2018, 2019, transformer models came out. Transformer models were basically used, a concept called attention, where you have different heads on the model. You could think of it like a kind of hydra of lots of different heads, and they're each paying attention to different things in a sentence.
00:18:42.366 - 00:19:26.574, Speaker D: And then more recently, kind of the fusion models came out, I think, core to our thinking around the kind of reasoning for using zero knowledge machine learning in this space is really what Daniel said. It's around cost. So just kind of two important things here. Generally speaking, if you throw more gpus at something, it gets better. The kind of scaling laws do hold, we haven't broken them yet. Number two, there's enormous kind of margins charged by the cloud oligopolists like AWS and Azure, around 70% to 80%. If you can find a way in a decentralized setting, peer to peer, with no middleman to train these models, you essentially increase every dollar spent on training by four to five x.
00:19:26.574 - 00:20:04.080, Speaker D: The best way to do that, in our opinion, is to use very lightweight proof systems. And then immediately you find yourself in this kind of conversation around zero knowledge machine learning, because you don't want to have lots of people training. The model gets super expensive. A good example of like an attempt at that would have been truebit by a torch and others in kind of 2016 17, which was a really good kind of first step in the direction, but it didn't go far enough to getting the overhead down. I think we calculated it to be like six x, which basically adds the margin back on. However, with the recent advancements in proofs, you get that cost way down. We anticipate that the cost right now is about 25%.
00:20:04.080 - 00:20:13.170, Speaker D: In Jensen to verifying the model has been trained, which makes it the unit economics substantially better versus the cloud giants.
00:20:14.310 - 00:20:23.940, Speaker A: So, Daniel, could you discuss some of the tradeoffs between using ckps amongst other, like fhes or something else?
00:20:24.710 - 00:21:35.530, Speaker B: With marrying to, I guess, you know, ZK has become kind of a dominant narrative within the crypto zeitgeist because it has this kind of bizarre property that we call succinctness that makes it a great fit for blockchains. But it's always important to remind ourselves, especially here in the ZK world, that there are, in fact, other cryptographic techniques, and they do different things, and they're all super exciting, right? Fhe kind of, I guess, homophobic encryption is most by default associated with privacy, the ability to operate over data without understanding or having the capacity to understand that data, the actual content of that data. So there's a lot of privacy applications on that. And of course there's MPC, where you want to split up some key or any number of other techniques as well. Within the canon of cryptography, a lot of which is often used in the crypto industry. I guess what I'll say on that is, and not to hammer a point constantly, but is nonetheless cost right. There is always a cost to doing these sophisticated cryptographic operations than to not do them right.
00:21:35.530 - 00:22:19.146, Speaker B: In fact, when we talk to our early customers, the first thing we always ask them is, can you get away with not using us just like don't do any crypto, just do it the normal way, right? Do it centrally. Are things broken? Okay, then we can talk the cryptography, right, because it's always a premium. And so that's what I try to focus on just to make things really specific and practical again. But certainly when it comes to the day to day work of what it looks like to marry machine learning and ZK, we actually still have a lot to learn from these other avenues, including fhe, which have been dealing with the intersection for a lot longer, just as an academic discipline. So a non trivial portion of my time is spent talking to academics in those kind of disciplines as well.
00:22:19.328 - 00:22:36.350, Speaker A: So what has been achieved so far as representing ML models as a circuit? Are we at the point where we can express really complex models with a lot of parameters, or has it just been pretty much R D early stage?
00:22:38.690 - 00:22:39.902, Speaker B: Yeah, training maybe?
00:22:39.956 - 00:23:50.950, Speaker D: Yeah, with training it isn't at a level yet. So if we think about the circuit generation, or even as Daniel said, looking at from a fully homomorphic perspective, it's just too slow for our use case, which is generic training without the kind of privacy component, it's just too slow. What we do use it for Vo is inference within training to monitor model loss. And that works well. Typically because you don't have to put all the data through, you can just put like a batch through, and also because you can typically checkpoint loss in kind of intervals, as opposed to having to do it all the time. And the benefit of course of being able to monitor the model's training, I guess over time, is that if things start to look unusual, you can then pinpoint kind of audits around the area, which looks unusual, which makes the whole system much more secure. I think broadly speaking, there's always going to be a lag, particularly with the fully homomorphic stuff behind the kind of state of the art, just using a GPU kind of locally, in kind of clear text, but there are definitely use cases for it, as Daniel mentioned, I guess.
00:23:51.020 - 00:24:04.778, Speaker B: Lakshm, what does that look like in the world of signatures? Right, which to me in the machine learning world, and probably Harry as well, it's like, oh, signatures should be relatively straightforward, but maybe does your focus on client end devices change that?
00:24:04.864 - 00:25:18.254, Speaker C: Yeah, one of the really challenging things that I think is true of a lot of ZK applications is we need to sort of adapt sort of the numerical primitives of sort of whatever we're trying to do to some field, some finite field. I think a lot of our challenges have come from doing, trying to do arithmetic in a field that's smaller than the field of the cryptography. We're actually trying to do wrong field arithmetic. And this is really untenable on a mobile device because the witness of the ZK circuit becomes really large. So we've spent a lot of time, so literally, like, the memory requirements become very big. That's the thing that probably heat up your device if you're using some other zero knowledge proof stuff. So we've spent a lot of time kind of trying to see, I think, broadly have the premise that there are certain crypto systems and signature schemes that will probably be 80% of signatures that matter in the world, but then kind of want to be open to making statements about many different systems.
00:25:18.254 - 00:25:37.270, Speaker C: So we're choosing proving systems based on their ability to be agnostic to the underlying field so that we can kind of change that up as we go. But, yeah, it's a very different, much tighter and scoped problem, but also one with the constraint like memory on a mobile device.
00:25:38.170 - 00:25:44.154, Speaker B: Yeah. Okay, very interesting. And part of why I ask is because we also struggle with memory. Now, the scale might be a little different.
00:25:44.192 - 00:25:44.346, Speaker C: Right.
00:25:44.368 - 00:26:05.106, Speaker B: It's like VGPUs and AWS and Azure. Sorry, Harry, for, you know, it gets very expensive very quickly. Know, oftentimes it's like the peak memory consumption in the proving process. Right. And so we need to rent a massive machine, even if we don't use all the capabilities of that machine most of the time. Right. And that's just a product of what proving systems often are.
00:26:05.106 - 00:26:57.166, Speaker B: But that doesn't make any sense when you think about the structure of machine learning, compute, which is generally pretty predictable, very consistent. And so I guess our insight, when we bumped into that initially in our early days of just looking at this almost as a scientific curiosity, is this proving schema is not appropriately acknowledging the fact that we're down selecting for a more specific kind of problem. Right. And maybe the two. Harry's earlier point about building custom provers, which are actually tailor made for that specific function. I think one of the narratives which will pick up some more gas, again, in the crypto zeitgeist, if I'm allowed to hazard a guess here, is this idea around specialized proving schemas or proving systems. And I'm very excited for modulus to put in our kind of spin on that, as well as personi or Jensen.
00:26:57.166 - 00:27:34.694, Speaker B: But in some sense, proof is in the pudding performance one of those. And I think when y'all see these numbers, it's like, man, for these really intensive applications, whether it's training inference for machine learning or for proving anything on a mobile phone on an edge device, it makes sense to go down the specialized route. And once you do, the water is warmer, the sky's clearer, your spouse is more attractive, your kids are more disciplined, life's just better. So this panel, I think, actually represents like one side of this debate. Unfortunately, we all agree with each other. Maybe that's not very exciting to.
00:27:34.752 - 00:28:11.498, Speaker C: Well, there are some other. I don't know if this is true, if lookups are something you guys think much about, but I think in my perception, there's like this one day magical technology, improving systems, like a lookup table, basically. And at some point it'll be economical to just do whatever we want with a lookup table. And we're sort of like following the space, and we expect at some point that curve will cross the way we're doing things in a very specialized way, but also maybe not. I'm also actually on this topic just because I have two experts here to ask about it. What's it like doing, like floating point arithmetic in a field?
00:28:11.584 - 00:28:46.020, Speaker D: I mean, that's a brilliant question. We spend a lot of time thinking about this, where basically for our system more broadly, we need reproducibility in the kind of model training process. There's four places it gets ruined. The first is machine learning frameworks typically just aren't reproducible. They have randomness in them, obviously, like random seeds, et cetera, a bit lower down. You then have, if you're training it in a decentralized system, you have all the various devices, because we don't use a standardized piece of hardware. It's lots of different kind of gpus from different manufacturers, mainly the video.
00:28:46.020 - 00:29:17.646, Speaker D: And then they're all different. And then thirdly, the way the gpus kind of compile the code, the way they execute them in the kernels, are all different. So we're actually having to rewrite lots of the kernels ourselves, hiring GPU engineers to do that so that our runtime does it. And then you get even more abstract, that you can get like a bit flip or something from like a cosmic ray. Add all that in, and it's a really tough challenge. We looked a lot at kind of like model quantization. Of course, the issue around the quantization is if you quantize it too much, then you lose the kind of the signal, so to speak.
00:29:17.646 - 00:29:47.062, Speaker D: Then if you're plotting kind of loss, but it's quantized to like three or four bits or something like that. It's just like a straight line. So, yeah, it's a really good question. The trade off would be if you create custom hardware, which works really well with it, then you kind of fall into like a centralized trap, which is something that we think about. There's a good example of Internet computer protocol. They went down this route of, like, we're going to make this one type of hardware, it's going to work really well. They call them, like, canisters or whatever.
00:29:47.062 - 00:29:55.370, Speaker D: To us, that's just way too much centralization also makes you into a hardware company, which makes a hard problem even harder.
00:29:57.070 - 00:30:46.394, Speaker B: I mean, I would just echo everything that Harry just said. I think the problem is it's acute, but it's not as acute on the inference side. We get away with a little more, thankfully. But maybe just to attack the same question from a different angle, when we talk to our partners and early customers, never do they go, what is your quantization schema? Is it eight bit? Is it like, what happens when you lose a couple of digits, when you blow up your floating point into a finite field? They just go, hey, does it still work? Question mark. Right. How much performance do I lose when I need to prove to the world that I didn't manipulate my algorithm? Right. So if you want to take it from the customer centric approach, the pain point lies in that more precision, less loss, usually means more expensive on the proving side.
00:30:46.394 - 00:31:22.022, Speaker B: Right? So we're helped by the fact that, again, machine learning models are generally a bit squishier, so they're a little more tolerant to these kinds of accuracy losses. But it is very much an ongoing kind of research question. The last thing I'll say is, we're not the only ones thinking about it, right. Because obviously, when you quantize a model, first of all, it's a lot more memory efficient. And so all these folks working on llms that are eating into massive hardware, there's only three of these machines in the world, and so they're super expensive. They're really incentivized to find ways to bring that memory footprint down. And so we're helped by that research interest.
00:31:22.022 - 00:31:51.374, Speaker B: We're super aligned on that. The other thing is, when you quantize a model, they're a lot more energy efficient, as in literally electricity sipped from the wall. Right. And so if you want to run some complex model on embedded hardware, on your smart glasses or on your phone or on your smartwatch, you want to quantize it and do all that. So there are a lot of complements and in the same way that earlier I mentioned ZKML. Anyways, we have a lot to learn from the fhe world because they've already been working with machine learning operations for a while. It applies to quantization as well.
00:31:51.492 - 00:32:32.480, Speaker D: Yeah, I'd add one final point to that. Again, I agree with all of it, just common Fred on this panel, but we very much think of the kind of, I guess, extent of quantization as being very connected to kind of computational liberty. A good example this was around the Lama model, which someone kind of quite quickly quantized when it was leaked, and then you got it kind of running on a raspberry PI, and then there's a decentralization kind of metapoint there about if you can actually make these things work on consumer hardware devices in a relatively kind of constrained way, that does a lot for people's ability to, number one, compute, but also then to just build different kind of models as well.
00:32:33.410 - 00:33:02.934, Speaker A: So you touched a bit on how expensive it is to build out a decentralized gpu network specifically for machine learning. Could you talk about why it was important to stay narrow and just focus on training machine learning models? And why would a developer or team go for a decentralized network that's potentially expensive? Potentially. Potentially expensive. Potentially take a long time to put together?
00:33:03.132 - 00:33:36.880, Speaker D: Yeah, sure. I think just kind of three points here. So my co founder and I, we kind of came from the machine learning world. We didn't come from the kind of cryptography or wider crypto world, and we faced these problems ourselves. So he was doing a PhD. My co founder, Ben, he had like four gpus under his desk, but he was competing know papers from Google, which were using a thousand gpus, and it was just completely kind of impossible. And then I was in industry where we were training fire detection models at large scale, and that burned a lot of cash.
00:33:36.880 - 00:34:33.422, Speaker D: So our thinking was, number one, it's important to get these costs down, and that's only going to get worse with time, which is proven true with the recent advances in LLM training and the numbers we're seeing. The second point is that if people are going to use this, number one, they're not going to be crypto people, they're going to be machine learning people. So immediately, they're kind of at odds with holding cryptocurrencies and everything that comes with it, you have to drop into your workflow. Usually people will have kind of free clusters, they'll have their kind of data cluster where they store the training data. They'll have their parameter cluster, where they store the updated parameters, and then they'll have their compute cluster, which is where the cache gets burned, and we basically drop in where that compute cluster is. I should say that for us, it's very expensive to build what we're building, but it's expensive to build it because it makes it super cheap to use it. And then the benefit will be we anticipate a roughly 75% cost reduction to 80% cost reduction versus using AWS.
00:34:33.422 - 00:35:12.634, Speaker D: And a really interesting way of thinking about this is if you look at some of the rounds which are happening just now in the market, you see inflection AI and stuff like that, they raise like over a billion dollars. You could easily kind of bet the building that roughly 800 to 900 million of that's going on compute training costs. And if you come to someone and say, hey, we can turn that kind of 900 million into $4.5 billion for you, that's ultra compelling. So when we saw that a couple of years ago, we were like, this is the most important thing. And finally, to your point about staying narrow, we think that the problems in training are quite distinct from the problems in inference. And we're very big believers in the kind of fin versus fat protocol dichotomy.
00:35:12.634 - 00:35:48.554, Speaker D: So lots of fin protocols makes more sense than one kind of big generic fat protocol, for the same way that if you're actually building proof systems, it makes sense to have super kind of custom provers, et cetera. It's just more efficient and effective. So for us, we thought we're just going to do training. It's just going to be the kind of neural network training. It's not going to be like statistical machine learning models, and we're going to ignore all calls to sort of do inference. And lots of people tried to sway us over the years during the art boom, like the Stability AI, like generative art boom. People were, you know, should do like art for nfts and stuff like this.
00:35:48.554 - 00:35:50.650, Speaker D: And we were like, no, thank you.
00:35:50.800 - 00:36:32.986, Speaker B: It's interesting because we've also gone the other direction. We focus on inference, and we're like, we're going to stay narrow. I see Jensen out over there, and I'm terrified of them, so I never want to compete with them. And throughout our past year or so that we've existed, there's been a lot of, like, why don't you tackle the training problem right? Why don't you look at the opportunity space there? And, yes, plus one to everything Harry mentioned. And then one last thing, which is in operation these two kind of steps look quite different. I mean, that's the truth of it, right? So even if kind of from the outside, it's like it's a uniform surface area, right? Just machine learning. What does that mean when you actually dive into the pond, so to speak? They're radically different animals, right.
00:36:32.986 - 00:36:37.210, Speaker B: And it makes sense to have specialized approaches to tackle each problem statement.
00:36:37.710 - 00:36:53.558, Speaker A: So how big of a problem is it that models like OpenAI is behind an API and these developers are just trusting the output that comes out of them? Right. Would OpenAI even want to, in the future, build in a verification system? They're just right now trying to keep this model alive.
00:36:53.674 - 00:36:53.906, Speaker B: Yeah.
00:36:53.928 - 00:37:52.290, Speaker D: I mean, anyone who's a student of history knows that when you trust huge centralized entities run by a small number of people, with something as important as kind of as what Daniel said, like what's truth, what's ground truth, what's real, what's not real, it ends up getting pretty dark pretty quickly. So there is that kind of philosophically it's not a good idea. I'd say number one. But number two, there's just also a kind of. I think a lot about the idea that AI is really just like the kind of artificial extension of your own brain. And it comes to this idea that if you have to trust something to read your thoughts, it gets to a point where you just have to know that it is what it says it is. You can't let OpenAI read your thoughts on, like, a high bandwidth BMI and just be like, cool if.
00:37:52.290 - 00:38:28.366, Speaker D: Yeah, sure, it's probably fine. It's like, google was the last point where you could do that, I think because most people, what they think versus what they put into Google is probably like 99.9% true. But there's all of that holdout. There's all of that stuff that you might not want to type into Google for various reasons, particularly if you're not living in the western world. So you're living in a more oppressive country and you don't want to kind of expose yourself to have different political views, et cetera. If you've got something drilled into your scowl and you think the wrong fault, and then that can result in you being detained or something bad happening, that's a horror story.
00:38:28.366 - 00:38:33.810, Speaker D: So it's a very good kind of antidote to the kind of tyranny which will be ushered in if it's kept centralized.
00:38:35.830 - 00:38:38.050, Speaker A: Anything to add, Luxwin? Daniel?
00:38:39.510 - 00:39:18.030, Speaker C: Honestly, I'm just learning from you guys right now, which is really sweet. I'm curious. Yeah, I think it's very clear to me why, from the perspective of a company doing training, why training verification is very valuable. And it's obvious why from a human interacting with OpenAI, why inference verification is valuable. Do you perceive that either of these sets of proofs are valuable to have on chain for some future notion of a chain? Or is it sufficient for them to just be kind of like just being distributed on the Internet?
00:39:21.090 - 00:40:10.778, Speaker D: My thinking, I've got lots of thoughts on that. I think like a kind of slightly less like glamorous one is actually just for tax purposes. If you sell your likeness, which everybody here will a. I don't know if anyone's watched the movie her with Jacqueline Phoenix. There's a scene in it when he's talking to the machine, which is played by Scarlett Johansson, and she's having kind of like 5000 simultaneous conversations. The fact that we are constrained as people to one Zoom meeting, I think is pretty bad. Number one, because I dislike Zoom meetings intensely, but number two, because you could do a week's worth of Zoom meetings if you just licensed out your likeness and it did all these things, however, and then you yourself could be in the real, you could be inserted in Zoom meetings.
00:40:10.778 - 00:40:33.026, Speaker D: But when you think about if you're, say, an actor or something, and you make your likeness available to a studio, how can you prove that you were in the model? How can you prove that it's in your training date? How can you prove that actually they produced it with you and having the receipts for that on chain, even if they're shielded in some ways. Very useful. That's like a boring example tax, but it has way more kind of like, there's way more philosophical reasons.
00:40:33.058 - 00:40:43.980, Speaker C: I think it's a very general or cool generalization of that, which is that chains are really auditable. So if you want it seen and understood by everyone, then it's a good place to put it.
00:40:45.230 - 00:41:10.606, Speaker B: I spend a lot of time thinking about why are we in crypto? Earnestly. Right. There's a lot about crypto that is not great. A lot of grifters, a lot of fraudsters, a lot of ups and downs. Emotionally, it's just like taxing. My parents are not proud of me because they don't know what I'm doing. I think a lot of us in this room can just walk away and go into AI.
00:41:10.606 - 00:41:58.386, Speaker B: There's like more money there right now, right? More excitement, more intention. And for me, it comes down to something very simple, which is, I like it here. I like these crypto values around decentralization building really robust, secure systems and networks, distributing ownership in a way that my backyard, Silicon Valley, has been so bad at, despite all the prosperity that has been built over the past, however many years. I like those values, and it's built what I think is this very exciting, dynamic industry that we get to play in. And then when it comes to AI, here is a technology which is diametrically opposite in personality. While cryptography, which underpins the crypto industry, is, generally speaking, very humble, very discreet, very specific. This is a statement that I am making and no further, right.
00:41:58.386 - 00:42:55.702, Speaker B: AI is so expressive, right? It's infinitely expressive, and it's so centralizing. It's taking all these resources and gathering it. And so when it comes to marrying the two in a way that I think acknowledges what both are good at, and also, for me, has this mission driven dimension to it where it's like, maybe these values can travel beyond crypto. I hope crypto is huge in the future, but maybe we can bring these values around like trust or don't trust verify out to the rest of the world, right? It's like a really exciting intersection, right. To marry these really appropriately, but then also leverage as a vehicle to bring these values elsewhere, right? We often talk about, you get a credit score, you get an AI process, whatever, and you see like a Twitter verified checkmark next to that score. At least back when Twitter verified checkmarks meant anything. And you can click on that and interface with the on chain verifier contract, see the model card, understand what that actually means for you as the end consumer, and then potentially bringing that to the rest of the world.
00:42:55.702 - 00:43:03.990, Speaker B: Right? I mean, maybe the rest of the world doesn't care. That's fine. But I'm very excited to try nonetheless.
00:43:04.330 - 00:43:07.320, Speaker A: Thank you. This was really insightful. We are at time.
00:43:09.050 - 00:43:11.460, Speaker B: Thanks, everyone. Thank you.

00:00:00.490 - 00:00:49.882, Speaker A: I routinely, I find myself asking myself like, how would I actually build a roll up? And a long time ago, like not too long ago, but I've, I've sort of picked up on that people that roll ups like kind of aren't decentralized. We have these roll ups with single sequencers and we sort of rely on them as a crutch at the moment. And when I wanted to build a roll up, I wouldn't want to use a single sequencer. That doesn't sound like very much fun to me. So I kind of thought about how would I have a decentralized sequencer in a roll up? And the first iteration of this was just to use tendermint for a single roll up, which obviously isn't that scalable, but at least you have the ability to have more than one sequencer. It's already implemented, we can just kind of go and use it. So that was the first thing.
00:00:49.882 - 00:01:14.830, Speaker A: And I named that the same name. So I gave that name Metro. Now that probably didn't need a name. I knew it didn't need a name, but I already had a cute name already picked out, so I used it anyway, which was a mistake. So originally I wasn't going to name this new architecture anything. But then people started when I called it a shared sequencer. That's the terminology that other people have used, such as flashbots with suave.
00:01:14.830 - 00:01:43.342, Speaker A: And this is very different from suave. So now I felt like I had to give it a name. So this is Metro, the architecture, almost like the SQL. And this is covering a blog post. Not a blog post, a forum post that I wrote up a while ago and sort of like an idea that the overall idea, as we'll talk about in a second, is extremely simple. So I believe that. I'm sorry if I'm not giving credit to anybody who has already thought of this.
00:01:43.342 - 00:02:16.210, Speaker A: I'm assuming many people have already thought of this because it's that simple of an idea. And I remember Mustafa talked about pessimistic roll ups a while ago. So this is like a lazy roll up. I'll talk about lazy roll ups in a second. Or if you've already read the blog post, the forum post, then you'll have an idea of what lazy rollups are. Those are basically just pessimistic roll ups. That was the first lazy roll up was a pessimistic roll up that Mustafa described.
00:02:16.210 - 00:02:57.190, Speaker A: And the rest of it, I think has essentially either already been done by tendermint with deferred execution or inbox models, or things like that, they're all extremely similar. This idea really isn't that new. But again, maybe I'm making a mistake again by giving it a cute name, but oh well, we'll go. So starting off with the obvious decentralization allows for a better censorship resistance and liveness. It's difficult to have censorship resistance without having multiple people being able to produce a block. I'm sure maybe you can get very clever and do it, but it's difficult. Same with liveness.
00:02:57.190 - 00:03:43.300, Speaker A: Liveness is even more difficult to do without having multiple different block producers. It kind of sucks with existing roll ups that only have a single sequencer. If that sequencer goes down, the roll up goes down. If the sequencer censors, that roll up censors. So having more nodes, being able to produce blocks is sort of a solution to this. Now when you combine that with roll ups, decentralization obviously isn't like this one dimensional spectrum where this is more decentralized than this. Roll ups have the ability inherently, again stating the obvious, that they can prove a state commitment is correct via some mechanism, whether it's fraud proofs, validity proofs, name a thing.
00:03:43.300 - 00:04:41.254, Speaker A: And because roll ups can do that, it's kind of okay if you have a single sequencer because at least they can't steal your funds. That's like kind of the most important thing. Now they can still censor and they can still go down, which is something that we want to solve. But this is kind of where roll ups, it's kind of okay for them not to be decentralized, but ideally we want them to be decentralized. Now we also want to use roll ups to be able to spin up a new chain quickly. And roll ups, if we have to have their own decentralized committee to produce blocks, then that is difficult to deploy. In fact, organizing for such a feat, just the off chain organization, like having your own discord, answering questions, getting good validators to go up, that's difficult enough to do and not scalable for every single roll up team to do.
00:04:41.254 - 00:05:35.782, Speaker A: So. Not only that, but now you have to incentivize all of them to stay alive and to produce blocks constantly and to not have this, to not lose your key or to not make your key public, because then people can forge, can be malicious on your chain. So it's difficult, it's not scalable. We need to find some solution to this if we want to have a million decentralized roll ups. If we want to have a million just normal sovereign roll ups that are single, like a single sequencer, no big deal. If we want to have a million decentralized roll ups, we have to have some solution to scaling this consensus. And this is what this shared sequencer architecture is sort of aiming to solve just in one way.
00:05:35.782 - 00:06:06.900, Speaker A: It's one way to solve this problem, and we sort of save this. We sort of take advantage of. The fact of the previous thing that we just discussed with roll ups is that they can prove that a state commitment is correct. So that part, the calculation and comparing of the state commitment doesn't have to be decentralized. The aggregation part, the part with censorship, resistance and liveness, that part we do want to have decentralized. So if we can separate them, that would be great. And Celestia does this.
00:06:06.900 - 00:06:32.982, Speaker A: This is Celestia's gimmick, not a gimmick. It's Celestia's thing. It's its stick. You separate execution away from consensus and data availability. And part of the thing that Celestia could do is it could act as an aggregator. You could submit your transactions directly. Users could submit their transactions directly to Celestia.
00:06:32.982 - 00:07:12.454, Speaker A: It gets a little bit annoying because you have to wrap it gets, it gets a little bit annoying because you have to wrap it. There's this padding. It causes a state transition for gas, but it is doable. So it is something that we could do. It's just not optimized for that fact. So base layers like Celestia that do this, they're not optimized for aggregation. If we think about it, we think about how big of a celestial block are we going to get? It's like 134 megabytes is within our range for the next two years or something.
00:07:12.454 - 00:07:48.782, Speaker A: So if we have 134 megabytes and that's a block every 15 seconds, that's half a gigabyte a minute. Okay, so we have half a gigabyte. How many transactions can you fit in? Half a gigabyte. Okay. For each one of those transactions, we don't have to execute it, but we do have to execute a small portion of it on celestia, which is just to subtract gas for that transactions. If we use the celestia as an aggregation layer as well as a consensus and data availability layer, if we do that, then it's not really doable. It ruins the scalability of celestia.
00:07:48.782 - 00:08:25.934, Speaker A: If celestia is also an aggregation layer along with a consensus and data availability layer. So if we can pull the same trick that celestia is doing, where we continue, we separate execution. Now we separate execution from aggregation. We separate execution from consensus and data availability. Execution is its own happy little space. Aggregation is also its happy own little space run by a middleware blockchain that is completely arbitrary. You could have a single sequencer like roll mint currently or roll kit currently, and it could run this thing.
00:08:25.934 - 00:09:11.166, Speaker A: You can run tendermint, you can run arbitrary consensus, doesn't matter. They all have their own trade offs. So that's kind of like what this point was for, was for. Roll ups should be able to pick many different types of aggregation if we rely only on the base layer to do aggregation for us. I think this is kind of like what tezos is doing. As far as I understand, then you can only have specific properties for aggregation. As we'll discuss here in a second, there are lazy roll ups that require specific types of aggregation, and you should be able to pick between whatever types of properties that you want.
00:09:11.166 - 00:10:04.574, Speaker A: We'll talk about soft execution later. You should be able to pick between different types of soft execution. So ideally in this ideal world where we have a bunch of shared sequencers, we would be able to pick between a lot of different ones. So before we talk about shared sequencers a little bit more, let's cover the overall architecture and overall diagram. We can see here where, as I've kind of alluded to, where we have users of many different roll ups can submit transactions directly to a shared aggregator, which is just a middleware blockchain. It's a dead simple blockchain. Over the course of a week during the holiday break while I was at my family's house, I coded one up.
00:10:04.574 - 00:10:47.958, Speaker A: So it's not difficult to do to just build an okay one, a middleware blockchain. Because again, all we're doing is paying for gas and coming to consensus over some things, some soft consensus. And then we sort of batch all those user transactions into one and into a single state transition on the base layer, in this case celestia. And so you can kind of see down here we have Celestia, and up here is just the shared sequencer. It takes everyone's transactions and then it deploys it to the base layer in a single thing. 1 second Josh. And then afterwards we have these things called lazy rollups where we actually generate the header afterwards.
00:10:47.958 - 00:11:38.534, Speaker A: So after the data has been published or finalized on the base layer, we can download those transactions and we apply them to the state. And then depending on a few other things that we'll talk about, you might do a few other things and then you also generate the header. But I think that's like the minimum thing. Yes. Josh, you had a question? So the transactions at the very top of this diagram are those individual transactions that get sent to the shared sequencer from the roll to modify. Depending on the shared sequencer, you might have to modify a few different things, but in the MVP that I had, you added a single field and otherwise it was a completely normal transaction, as if you were signing it from metamask or Kepler. Sweet.
00:11:38.534 - 00:12:28.380, Speaker A: Thank you. Yeah. So this is the overall diagram. You can explain most of it just by looking at this diagram. I also go into more details in the forum post, but paying for gas is one thing, is basically really the only thing the shared sequencers have to do from a state perspective. So whenever I submit a transaction to this shared sequencer, it has to be able to parse that transaction and take the existing things already required for that transaction to be valid. Things like a signature, things like a nonce, and I think that's it, maybe some other things, and subtract gas for that account.
00:12:28.380 - 00:13:25.978, Speaker A: So the shared sequencer sort of keeps an account of the lazy roll up as well. So like that same address has a. When it, whenever you sign a transaction, it sort of keeps track of that account information as well as almost an identical copy as what is kept on the execution layer. An identical copy is on this shared sequencer aggregation layer, and that's pretty much all that's required for gas. In my MVP, there's multiple different ways to do it, but in the MVP that I wrote, I just added like a little extra id to a chain id. So I called it like a secondary chain id. So this secondary chain id was specific to the execution layer, and then the primary chain id was focused purely on the sequencer layer.
00:13:25.978 - 00:14:16.560, Speaker A: But again, that's an implementation detail. We don't have to get into that. The other thing that you can do with a shared sequencer layer is you can inherit the fork choice rule. So in this case, depending on whatever the fork choice rule is of the sequencer layer, the execution layer can inherit that. So instead of having something like what rollkit uses, where you have like this, well, I mean, if you use roll kit for your shared sequencer layer, you can inherit that exact same fork choice rule. If you use tendermint, then you can inherit that fork choice rule, which requires just checking a bunch of signatures and allowing basically the fork choice rule is whatever the committee says is the fork. I can pick that.
00:14:16.560 - 00:15:36.550, Speaker A: That's depending, that's sort of like another trade off space that you can explore using a shared sequencer is different types of fork choice rules, and whatever different applications can be built using those specific fork choice rules. Another thing that you can do is atomic inclusion of transactions. So you can provide very strong guarantees that a transaction will be included in both roll ups. So if I can submit a transaction to the base layer, to the aggregation layer, the aggregation layer can parse that transaction. It actually consists of two different roll up transactions, and I only get to include one transaction if I'm also including the other transaction. So this is a rather trivial feat, because the cosmos SDK already has functionality for this, and that's like a very powerful primitive that has yet to really be explored. But you can kind of think about it like, you don't have guaranteed that those transactions get executed, and you don't know the result of those transactions yet, but you can provide guarantees that those transactions do actually get included.
00:15:36.550 - 00:16:35.174, Speaker A: So maybe for MeV that would be really useful. I only want to do something on this chain if it also occurs on this chain, or there's a good probability of it occurring on this chain in the way that I think, or for bridging, perhaps. I don't really want to execute a transaction on this chain unless also a transaction gets executed on the other chain or is included. There's also an opportunity for it to get included. So again, it's not quite as strong as having a guarantees about execution as if it was executed on the same chain, but it's sort of a weaker guarantee that I think is also still very useful. You can swap shared sequencer sets. So ideally, I'm hoping that if this architecture is actually useful, that we end up using it, that people build a lot of different versions.
00:16:35.174 - 00:17:27.434, Speaker A: There's a huge design space, I think, for something like a shared sequencer. We were talking about fork choice rules. We were talking like later we'll talk about soft execution, transaction preprocessing, how you wrap transactions. If you have atomic inclusion, there's just a huge number of different things that you can change. And importantly, also, I don't think we've discussed MeV yet, but if this shared sequencer set isn't to your liking, in that it's extracting too much value, this shared sequencer set doesn't do much. They don't have a lot of state, and if things that don't have a lot of state are easy to hard fork. So either if I'm a roll up and some shared sequencer set, I feel like they're extracting too much value for me.
00:17:27.434 - 00:18:22.910, Speaker A: I could hard fork that shared sequencer set and move to an identical, different shared sequencer. Or I could just simply swap to a different shared sequencer, assuming that there's a lot of competition, which I hope that there will be, considering that. Again, shared sequencers do not do much in this architecture. So yeah, mev, mev, you are ordering transactions. Now I think it's important to note that a shared sequencer may be slightly different from a shared aggregator, depending on your definitions, of course. But there's nothing really that inherently says that an execution layer has to execute the transactions in the exact order that's determined by the shared sequencer. So the shared sequencer takes users transactions, it bundles them up and it posts them on Celeste and then they get executed after the fact.
00:18:22.910 - 00:19:23.374, Speaker A: And when they get executed after the fact, you can just change the ordering around. What you can't do is you can't exclude certain, well maybe you could, maybe you could come up with a way that you have a certain block validity rule where of transactions of a certain type we get rid of. But there's nothing that's stopping you from doing a sort of second round of processing on those transactions that fits your need. But you can still have, if you wanted to, if you wanted to and you wanted to have the fork choice rule, you wanted to inherit the fork choice rule and you want soft execution, which again we'll talk later about. Then the shared sequencers can do quite a bit of MeV because then at that point then they are ordering transactions. And this is kind of where again, like the last slide when we were talking about how you were able to swap different shared sequencers. That's very important when it comes to MeV.
00:19:23.374 - 00:20:01.782, Speaker A: I think we talk a lot about all of these preventions with MeV. Like we want to have a shared sequence, like we want to encrypt the mempool somehow using threshold encryption. And that might very well work and be a really good solution that people like. That's another trade off space that you could explore with a shared sequencer. You could have a shared sequencer that has a threshold encrypted mempool. But another solution is to have a lot of competition. It's to not just have one that can exploit everything and sort of have it as everything locked in, but you have many many different shared sequencers.
00:20:01.782 - 00:20:39.334, Speaker A: And if one shared sequencer is doing too much mev that you feel is too extractive or isn't returning enough value to you, then you can just switch to another one. They don't do that much. Another useful thing is that you have a shared mempool. Like if you were with the call with column was that as we found out, mempools use a lot of bandwidth, and it's something that increases the resource costs for your node, for all of your roll up full nodes. And it's also some engineering overhead. You have to have the expertise to implement such a thing. If you use a shared sequencer set, that's not the case.
00:20:39.334 - 00:21:16.200, Speaker A: You don't have to. You could have your own mempool if you felt like it for your specific roll up. Or you can just use the mempool of the shared sequencer, which is already running for you. That sounds pretty cool. It's not a universal fit for all roll ups, that's for sure. The main thing is, because this uses a model that's similar to how deferred execution works in tendermint, you have a lot of the same drawbacks, meaning that I can't process the transactions beforehand before I'm producing a block. I cannot process the transactions in a way that requires access to state.
00:21:16.200 - 00:22:18.938, Speaker A: For example, I could not pre execute the transactions and remove any transactions that are going to get reverted or are invalid in any way. My state machine has to have a way to handle that instead. So it's possible to have invalid transactions in your block that all lazy roll ups have to have that functionality where roll ups that do the normal mechanism of creating blocks with immediate execution, they don't have that limitation. This is very different from swap. I've heard so many people, just a few people on Twitter or in telegram or something, say that this is very similar to suave. It kind of is, because technically they have a shared sequencer that's like basically the name. And I feel like that whenever they're reading that name, they're sort of just bundling the two together, when actually they're very different.
00:22:18.938 - 00:22:57.570, Speaker A: So the architecture that I'm describing actually provides very strong guarantees for things like transaction inclusion, mutual transaction inclusion. You inherit the fork choice rule, or you at least have the option to inherit the fork choice rule of the shared sequencer. That's a strong guarantee, as far as I understand from swab. So it's not specked out really. And I haven't seen any implementation with suave. So this is flashbot swab. They want to sort of have a shared sequencer across, like arbitrum, optimism, the block producers on Ethereum and things like that.
00:22:57.570 - 00:23:23.706, Speaker A: Well, as far as I understand, Ethereum is not changing their four choice rule to incorporate suave. Same thing with arbitrum and optimism. Those are not lazy roll ups. Those use immediate execution. So if you don't have those properties, you can't have the strong guarantees that are provided using this architecture. So it's not the same. You do not have the same guarantees.
00:23:23.706 - 00:23:55.062, Speaker A: You cannot guarantee that something gets included. You can't do soft execution. You don't have nearly the strong guarantees for soft execution, which, again, I've mentioned that so many times, I probably should have moved that up in the order in the slides. I didn't have the most time to prepare for this talk. But anyway, it's very different from swab. So that's why, like I said in the first slide, that's why I gave it a cute name. Again with Metro, I didn't really doesn't need a cute name.
00:23:55.062 - 00:24:33.790, Speaker A: It's not that unique of an idea, but it is very different from swath. Okay, so before we get into lazy execution or lazy roll ups, I wanted to go over sort of the thinking behind them. And this is deferred execution, or this is extremely similar to what mustava has described as a pessimistic roll up. So a lazy roll up, very simply. Or we can cover immediate execution. We sort of touched on this a little bit earlier. You sort of have your transactions, you execute them, and then you include the result of the execution of those transactions in the same block.
00:24:33.790 - 00:25:12.558, Speaker A: So you have right here, you execute, you include the commitment to the state in the first block, and then in the second block, you do the same thing. But before you move from one block to the next, whatever consensus mechanism you're using likely has some sort of comparison between the commitments. Sure. Okay. So with deferred execution, we don't actually generate the state route for that block. So we have our transactions for the first block, and we have our consensus mechanism, and we come to agreement on the blocks. But that's it.
00:25:12.558 - 00:25:43.930, Speaker A: We don't actually compare state routes. This is what tenderman does. And Celestia, and we actually wait until the second block. And then in the second block, we have our commitment that we sort of generate at some arbitrary time. So we come to consensus quickly, and then sort of in the background. In theory, you can execute your transactions, and then on the second block, you have a commitment to your state. I think originally this was implemented in tendermint as an optimization.
00:25:43.930 - 00:26:28.120, Speaker A: So you can kind of think about this as like at a grocery store, instead of queuing up at the end where you go grab your groceries, then you all get in a queue, and you scan all your items and you check if you have enough money and then you stick all the groceries in your cart and then you go, that is immediate execution. But if you had deferred execution, it's sort of leaving that queuing up part, scanning everything, seeing how much you owe and seeing if you have enough money for the items. You do that later. So this would be like I run in the grocery store, I stick everything that I need in my cart and I just leave. And sometime before I get from the grocery store to my house, then the items that I don't have enough money for sort of just evaporate into thin air. That's deferred execution. So it's an interesting idea.
00:26:28.120 - 00:27:25.046, Speaker A: And if you take that idea, but instead of actually including the state route, remember what we discussed with the roll up. Roll ups have the great property that you can actually prove that the state route is actually correct and you don't have to have some economic crypto economic committee sign over it. Instead you can just prove that via fraud proofs or validity approves or just execute it yourself in a pessimistic role. Lazy execution is basically just that. It's basically extremely similar to deferred execution where we agree upon the transactions ahead of time and then we execute them later. In this case we are not actually agreeing upon the transactions. That's being done for us, that's being done by Celestia and then it's being done at the final form by Celestia.
00:27:25.046 - 00:28:22.880, Speaker A: But before Celestia it's actually being done by this shared aggregator. But anyway, that is a lazy roll ups in a single diagram is they just download block data, they apply them to the state, they update their state and then they create a header. And then in that header, when they create that header, you have some sort of mechanism, you will likely have some sort of mechanism for proving the state. Whether that be you have a committee that signs things for an optimistic roll up that this committee has. Anyone who has enough funds is allowed in a committee and they sign a header that says a certain state route. And if you have a valid fraud proof to the state route then they get slashed. That could be one thing for an optimistic roll up or with a ZK roll up it's incredibly easy is you execute the transactions you created, not incredibly easy implementation detail.
00:28:22.880 - 00:29:44.358, Speaker A: You have a circuit that can be proved for all of your execution and you create a ZK proof and you include that in your header. And now you have a ZK lazy roll up. So lazy roll ups along with the shared aggregator have a very interesting value proposition, I think because they have some similarities to smart contracts that other roll ups don't. Mainly that you can inherit the decentralized block production of some other committee. So like in an l one smart contract, I post my smart contract, and then now that smart contract is I have the censorship resistance and I have the liveness properties of whatever that l one is. And with a roll up that's not the case, because with a roll up you have a separate block producer or a separate set of block producers. But with a lazy roll up, with a lazy roll up you do inherit the censorship and liveness properties, not of executing the state, but of creating blocks, which I think is an interesting trade off space.
00:29:44.358 - 00:31:03.646, Speaker A: And you still have all the other benefits of being a roll up. You're completely sovereign, you have no shared state, and you have completely custom execution environments, you can hard fork, et cetera. Also you don't have any aggregation logic. So as it turns out, if you went in the cosmos SDK now and you go and look at the sort of standard modules, most of them have to do with the staking module and incentivizing the staking module. So you don't actually have to have that logic anymore because that's handled for you by the aggregation layer, which dramatically decreases the scope of your state machine. Not only that, is that it also makes it easier to adopt execution layers, existing execution layers in theory, because now the problem of taking an existing execution layer, like for example geth, if I wanted to take go Ethereum and make it into a lazy pessimistic roll up, I don't really have to have this aggregation logic. This aggregation logic has already been done for me.
00:31:03.646 - 00:31:50.478, Speaker A: They're performing some basic checks on the transactions they're including in the block. And now I have my block. All I have to do is download the transactions, apply them to the EVM, and then create the header and gossip, the header and everything else around that ecosystem feels a lot of the same. So like in theory you could use a lot of the existing infrastructure, the native implementations of this infrastructure, meaning like made a mask, turbo sync the MEV infrastructure, all of that stuff you could use in a very native, well maybe not the MEV infrastructure, but a lot of other things you can use in a very native way. So again, this is unproven. I haven't actually tried this. This is, in theory, might not be true.
00:31:50.478 - 00:32:19.750, Speaker A: Take it with a grain of salt. What does deploying a lazy roll up look like? So it's actually really easy. It's kind of miraculous in that you just sort of pick a chain id and you pick a genesis state and you pick an execution layer. So you just pick these things and then you also pick a shared sequencer set. And now you're done. There's some implementation details in there, but that's essentially it. Those are the most important things.
00:32:19.750 - 00:32:54.050, Speaker A: And now you have a lazy roll up. Your users just start using it. They just start submitting transactions to this specific chain id to a specific shared sequencer set. And now the transactions are already coming. We already have some ordering mechanisms to come to consensus over these set of transactions. They're already being made available by Celestia. And then we just download them, we apply them to the state and we update and we have our header and we gossip our header or do whatever the hell we want to do with that header.
00:32:54.050 - 00:33:30.314, Speaker A: The deployment is arguably, actually, I won't say that. I was going to say that arguably, it's easier than deploying a set of smart contracts. Maybe that's stretching it a bit, but it's definitely extremely easy. It's certainly easier than spinning up your own committee to produce blocks, that's for sure. Okay, now we finally get to soft execution. Okay, so a great UX has near instant gratification. I stole this slide from my previous presentation.
00:33:30.314 - 00:34:21.374, Speaker A: Extremely high confidence of finality and rare downtime. You can do that. You have to have some form of consensus if you want a good ux. The reason for that is if you don't and you completely rely on Celestia's consensus. Now, if for whatever reason, you don't get to update your block in Celestia, there's no soft promises that can guarantee order in any way, shape or form. You have to have some form of consensus so that you can post your roll up blocks in batches to Celestia. If you have the ability to post your roll up blocks in batches, you can have a good ux now.
00:34:21.374 - 00:35:03.840, Speaker A: You can post your rollup blocks in batches perfectly fine. If you have a single sequencer, that's easy. But if you want decentralized sequencing and you want a good ux now, you have to have some form of consensus. You don't have to have BFT consensus, you just have to have some form of consensus. And that form of consensus that you have determines the sort of level of promises that you can actually provide for those soft commitments. So in this shared sequencer model architecture thing, you could do this really easily. You just have your shared sequencer produce blocks faster than Celestia, and it's almost that simple.
00:35:03.840 - 00:35:36.454, Speaker A: As you produce your aggregation layer blocks. So let's say you produce those once every 2 seconds or so every time. You essentially just download the relevant transactions each time. That's a block, and you apply them to the state prematurely. So it's not final yet. It's not final until you get down here, until it gets posted on Celestia. But as soon as you can check the proof that it is included in Celestia, you finalize it.
00:35:36.454 - 00:36:16.418, Speaker A: The transactions are already executed, you're prematurely executing them. And as soon as Celestia finalizes the block, you already have everything downloaded, you already have everything applied, you execute, you're done, you move on. And now you sort of have this window of soft execution, soft commitments. And again, depending on the fork choice world, depending on the shared sequencer, that sort of determines how good those soft commitments actually are. Decentralized sequencing and outstanding ux. Yes, we already covered that. Okay, so this entire scheme is all plot to make blockchains cute and tiny.
00:36:16.418 - 00:37:07.474, Speaker A: Again, this entire thing, because I wanted to, using an architecture like this lets you get rid of the aggregation logic. It lets you still have decentralized sequencing, it lets you have this really simple thing, and you can sort of isolate your state machine. You can have your state machine smaller and smaller. And because the overhead to deploying a decentralized roll up is smaller and you can use this lazy mechanism, you can have an even smaller state machine. So that's kind of the goal here too is to have as small state machine as possible in certain use cases. Again, this is a huge trade off space. This is not a universal thing that you could do, but sort of the idea is to have, again, I'm bad at I gave it a cute name.
00:37:07.474 - 00:38:04.870, Speaker A: It probably doesn't deserve a cute name. It's not that unique or different of an idea, but you have instance specific blockchains. So instead of having an app specific chain, which would be like the equivalent of GitHub, or if this was a Dex, this would be like osmosis, where you have a single app chain with many different amms or many different order books, or something like GitHub where it has many different GitHub repos on it. If you had an instance specific chain, you would have just have a single amm or a single order book or a single git repo. And then this sort of enables for sort of like this weird arbitrary. Again, I haven't really thought about it that much or have a lot of fleshed out ideas on it, but you can have this arbitrary sharding where you sort of just pay attention to the state that you want. And again, I haven't really thought about it that much.
00:38:04.870 - 00:39:18.382, Speaker A: It might be a terrible idea, it might not even be possible. But maybe there's something that you could do there where now that the state machine is extremely isolated to what you want it to the bare minimum of what it needs to be able to do, and then you can sort of have these cool ideas where now, similar to a normal database schema, it's like I design a schema for a few different databases to optimize for a specific thing. Like if I wanted to optimize for querying like query speeds for specific things, then I do that. If I want to optimize for handling tons of data because I'm trying to train a machine learning algorithm, then I optimize my schema for that. And similar to this, now you can optimize your schemas for proving. So for things that could be proved with the ZK roll up with a validity proof, you have those isolated away. For example, if you just wanted to have being able to send funds across, and then you have some more elaborate things that have an optimistic roll up proving mechanism, and then you have other things that are just committee based, and you can maybe somewhere sort of mix and match.
00:39:18.382 - 00:39:48.220, Speaker A: I'm not entirely sure, but who knows? So I'm not sure. I hope I covered some of these things. Like I said, I didn't have the most time to prepare for this talk because we're busy with other things. But I did write a forum post, which again, I didn't have the most time to write the forum post either. So my ideas might not be the most fluent and they might be a bit scatter brained. So I apologize. But if you have any questions, let's answer those now.
00:39:48.220 - 00:39:55.658, Speaker A: Go for it.
00:39:55.664 - 00:40:09.760, Speaker B: Gabriel, I have a question about optimistic roll ups. I don't understand the case where fraud happens. Who does the fraud, and who am I proving it to?
00:40:10.210 - 00:40:55.562, Speaker A: Well, in an optimistic roll up case, so if you had a lazy optimistic roll up, let's say that you download some transactions, you apply them to the state, and now you have to generate the header. So this is when you have a different committee. So someone, in theory, I mean, they don't have to have a bond, but you probably want them to have bond to prevent spam. Someone who has funds up, they sign the header and they include a state route. At this point, it's like a normal optimistic roll up. Someone signed the header and that person has funds and I'm aware of who's in that committee as a light client. So then I can check.
00:40:55.562 - 00:41:08.080, Speaker A: I can say like, oh, does this person actually have funds up? Should I listen to them at all? Yeah, you can also get a little bit more creative with that as well. That's just one thing.
00:41:08.530 - 00:41:13.440, Speaker B: But this means I still have the staking logic inside.
00:41:14.530 - 00:41:57.780, Speaker A: You would have different logic. You would have different logic, yes, but I think it can be similar. It could be similar, but it could also be very different in that you don't necessarily have to keep track of whose turn it is to sign. What, that could be one thing, or you could just have everyone sign and then you can sort of like if you wanted to get quite clever with it, you could have multiple different people sign and then you can sort of aggregate those signatures. So it's almost like a weird mix between a committee based signature thing and an optimistic roll up.
00:41:58.550 - 00:42:14.518, Speaker B: Why not have another layer that just executes and signs the headers? So we have a shared execution layer which just executes and.
00:42:14.684 - 00:42:20.806, Speaker A: Yeah, you can. I think that's if you don't have an optimistic mechanism, like you don't have fraud proofs or anything, I mean, you.
00:42:20.828 - 00:42:22.950, Speaker B: Can still enable fraud proofs because now.
00:42:23.020 - 00:42:32.906, Speaker A: Yeah, you can still enable fraud proofs, but then if you don't have some sort of bonding mechanism or something, then I think you can have fraud proof spam because it should cost something to sign.
00:42:33.088 - 00:42:42.000, Speaker B: Yeah. What I mean is this one execution layer would then have this staking module, but all the roll ups that use it don't need it.
00:42:42.770 - 00:43:02.802, Speaker A: Exactly. That's sort of referring to the cute and tiny blockchains in that you can have this arbitrary sharding like that you can have an execution layer that executes this blockchain, this blockchain, this blockchain, this blockchain. They sign over it and they are accountable for fraud proofs for those blockchains.
00:43:02.946 - 00:43:06.360, Speaker B: Yeah, that could be interesting.
00:43:07.610 - 00:43:57.960, Speaker A: You can get really creative with it. I'm hopefully looking forward to what people build with this. And I also think that this makes it really simple. And while we're talking about this with like ZK roll ups, we've talked a lot about like, oh, well, we need to decentralize proving or we need to do this. Well, if you have immediate execution where before the transactions are included or the state diff is included on the base layer, you have to verify ZK proof. Well, if in this case, instead of posting state diffs, we post transactions, which is less efficient from this standpoint from like a block space standpoint. But at the same time we can also have, anyone can generate a proof and include it in a header and gossip the header, which is kind of cool.
00:44:02.510 - 00:44:03.370, Speaker B: Colin.
00:44:05.330 - 00:44:07.482, Speaker C: Hey, first off, great presentation.
00:44:07.546 - 00:44:08.490, Speaker A: Love the graphics.
00:44:08.650 - 00:44:15.866, Speaker C: I have like a two part sort of question. The first is, would everything be in the same namespace?
00:44:16.058 - 00:44:18.078, Speaker A: Like they're de aggregated together and I'd.
00:44:18.094 - 00:44:21.730, Speaker C: Have different, okay, so it'd be per namespace.
00:44:22.550 - 00:44:47.914, Speaker A: You could do it either way. I think doing it per namespace is better because then you can have the, you're already going to have to add padding so that I can check for inclusion without downloading the whole block. So you might as well just use a different namespace because that's what does. But maybe if you want it to be denser or something, you could not do that.
00:44:48.032 - 00:45:23.320, Speaker C: Yeah, I thought maybe there might be an optimization. The optimizations from aggregation might be because if you make the blob size 16 shares instead of 13 shares, it all fits in and you don't have any padding. And so that way you're getting some sort of small gain. The other thing is, do you think this is like software that the validators of Celestia could run? Yeah, we've got mib services where validators will have other software that they'll be running alongside their validator. Can you imagine this as well, where they'll be offering this service of aggregating for you?
00:45:24.010 - 00:45:55.662, Speaker A: I hope so, yeah, I hope we have every possible different combination of this. And I think it is a perfect use case for using any form of interchange security, which could just be using the liquid staking token as your bond for the shared aggregators layer. Like if you did that, then that's similar to what it's like Eigen layer ask. Yeah, Gabriel, I just forgot my question.
00:45:55.716 - 00:45:56.366, Speaker B: Sorry.
00:45:56.548 - 00:46:01.940, Speaker A: Okay, sorry. Colin, did that answer your question? Yeah. Okay, cool.
00:46:05.760 - 00:46:12.800, Speaker B: Yeah. What you could do to also pay for gas is maybe use the celestia token.
00:46:14.180 - 00:46:49.524, Speaker A: Yeah, that makes it a lot simpler. If you use a liquid staking derivative of celestia as your native token, paying for gas is really trivial because you're not having to convert between the two. I can lest you. Yes, let's do it. Yeah, Jacob has a lot of good ideas around this. I sort of have been brainstorming with Jacob on some of this stuff. So I really appreciated that Jacob had the idea that you could have a shared aggregator that is an oracle as well.
00:46:49.524 - 00:47:48.136, Speaker A: So the main reason being that if you have an oracle, usually you're just probably going to have some committee. You have to rely on some committee. So it would be cool if this committee is also a blockchain because now you can hard fork that blockchain and if social consensus deems it necessary, you can hard fork and you can slash them if they are not producing an oracle as if they said that they were producing an oracle. And not only that, if you're already verifying that, commit to verify the fork choice rule, right? If you're using the fork choice rule of a shared sequencer set that is just using something like tendermint, then you are effectively also a light client to tendermint. All of your roll up nodes are to the shared sequencer set along with being a light client to Celestia. So you already have to verify this extra commit. You might as well include some extra useful information there which could be an oracle.
00:47:48.136 - 00:48:09.572, Speaker A: So I could have a shared sequencer set, then they are the oracle for a specific price of something like the price of a hot dog. And now I have a huge myriad of roll ups that depend on the price of a hot dog. Yes, Gabriel, sorry.
00:48:09.626 - 00:48:28.760, Speaker B: If there are anyone who wants to ask questions, please. Why couldn't a roll up that has like a normal roll up we're building with decentralized sequences? Can they also do soft execution commitments?
00:48:29.120 - 00:49:06.036, Speaker A: Yeah, totally. Yeah. The first presentation that I did with this was just that I was using tendermint to have this soft execution. That's actually whenever I was started to think about this idea. If you check in that last presentation, on one of the last slides I posted that, one of the things that I tried various different ways to post data. So it was just a normal tendermint committee and they're producing blocks as happily as ever and then they post those blocks on Celestia. But actually what you post can be different.
00:49:06.036 - 00:49:24.988, Speaker A: So are you posting the entire commit? Are you posting the header ahead of time or are you just posting the block data? So I was thinking about what if you just posted block data and then you generate or gossip the headers afterwards? And that's whenever I started thinking about this idea.
00:49:25.154 - 00:49:27.212, Speaker B: Why do you need tendermint for that?
00:49:27.346 - 00:49:28.220, Speaker A: You don't.
00:49:29.280 - 00:49:34.880, Speaker B: I was just execute transactions and post the soft commitment.
00:49:36.180 - 00:49:51.296, Speaker A: Yeah, you could do it with a single sequencer. You do not need tendermint. Tendermint is just like a battle tested way to do this. It's overkill. You have to do BFT consensus when there's no reason to. There's no reason to do BFT consensus. It's a complete waste.
00:49:51.296 - 00:50:26.960, Speaker A: It's also already implemented and I can just go play around with it right now. And it's battle. Just the, that was the entire reasoning behind using tendermint. It would be cooler. Like you create a fork of tendermint and you remove pre votes because again, you don't really need. I think it's still BFT, but it's just you need a much higher percentage of the voting power in order for it to be BFT. Maybe you can lower the percentage because again, you're not really relying on this committee for safety.
00:50:26.960 - 00:50:45.270, Speaker A: They can't steal funds. The only thing they can do is not produce a block or give you a bad soft commitment, which if that happens, it's not the end of the world. So you really don't need bft consensus. You can use all sorts of things.
00:50:48.920 - 00:51:55.804, Speaker B: Another idea that I had while thinking about it, that you could have a promise by the celestial validators where the aggregated block has a promise that it is included from the celestial validator, which then makes the guarantees of the soft commitment even bigger. So the aggregate block grows while it is constructed in a sense that you don't aggregate aggregate and then send the big block. You can aggregate, have a small block which already gets gossiped to the mempool, and then another, like the block gets bigger and you send the rest of the transactions which increase the block and just cancel the smaller block. And for the first block, you will get the soft commitment. A promise from the validator set up.
00:51:55.842 - 00:52:24.390, Speaker A: Yeah, I think that's certainly one way to do it. I'm not entirely, it sounds similar, but you somehow are incorporating. Yeah, I'd have to think about it more. It definitely sounds like one way to do it, and there might be like a different trade off space there. There probably is. So that would definitely be interesting.
00:52:24.760 - 00:52:27.700, Speaker B: I think that was just an addition to this idea.
00:52:27.770 - 00:52:29.610, Speaker A: Oh, okay. Yeah.
00:52:30.460 - 00:52:34.760, Speaker B: Just get more promise that it's included.
00:52:37.420 - 00:53:26.372, Speaker A: Yeah. But as we're coming to the end of this call, kind of like, what I was hinting at at the beginning is, like many of us, I sort of just find myself asking, how would I build a roll up? And this is basically just how I would build a roll up, and sort of the things that I've been thinking about to sort of go in that direction. And there's obviously more important things to build right now. Celestial main net and getting to 134 megabyte blocks. But after that, maybe we could maybe think about heading in this direction. Or again, the bass implementation of this is really easy. Having a really, it's almost like the analogy or metaphor or whatever of playing guitar.
00:53:26.372 - 00:54:21.848, Speaker A: It's like really easy to pick up playing a guitar, but then to become really good at playing the guitar is like a huge gap and it's very similar. It's like creating an okay version of this doesn't take much work. It's really simple. You use existing tools, but then creating an amazing version of this where you're like what Colin mentioned in the chat, where you just use raft consensus or you use something else or you use tendermint without pre votes or you use some other mechanism, you include all this MeV architecture, all these other random stuff, then that part takes more time. That's kind of why I was hoping for other people to build it because I didn't want to build it. But I do eventually. Like when we build roll ups, this is, this is how I build roll ups.
00:54:21.848 - 00:54:22.010, Speaker A: I guess.

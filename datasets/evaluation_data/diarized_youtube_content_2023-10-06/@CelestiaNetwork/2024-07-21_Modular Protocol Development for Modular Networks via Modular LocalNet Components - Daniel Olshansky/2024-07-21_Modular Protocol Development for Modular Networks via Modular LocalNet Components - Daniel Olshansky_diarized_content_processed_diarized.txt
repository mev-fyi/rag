00:00:03.080 - 00:00:58.630, Speaker A: All right, let's do it. I'm Olshansky. I'm the head of protocol at Grove. We're the company that houses the R and D team for Pocket Network, a decentralized RPC protocol that's been around for a little while now. And I'll go into details of what we do, and what I'm going to be talking about today is modular protocol development. I used to work at companies like Waymo and Magic Leap and Twitter and Google, and a lot of what I did was mlops, building infrastructure and local development environments for mlops and various data scientists. And one of the things I realized is that if they don't have a good local environment, then for every single hour that they waste developing, it's literally hundreds or thousands, if not tens of thousands of dollars that are going down the drain.
00:00:58.630 - 00:01:55.570, Speaker A: So as long as the stack of tools that we give them is of high quality, will enable iterative development, agile speed. And the way this extends to protocol development from experience is almost identical. So jumping into it, the typical contributor lifestyle is right here. You find a cool project, you run a local docker container, you get very excited that it's all going well, but then you start trying to develop locally and you realize that all your dependencies are messed up. You eventually just give up and move on. And the cycle repeats as you find a new project. So what we do is we want to move on to the ideal contributor lifecycle.
00:01:55.570 - 00:02:53.510, Speaker A: You find a cool project, you run a local development environment, and all of a sudden you can start making changes to the code. You make changes to the code, you implement fixes, you submit the bug, someone reviews it, merges it, and rather than spending half your day fixing dependencies, you're actually going to get going straight away. In the crypto world, this is not that common, especially in protocol R and D. But we fixed this, and today I'm going to be telling you about how we did. So what's on the agenda? It's the state of protocol development, a few horror stories of what we've done in the past, some Shannon tooling, and then I'll do a live demo. So. And if there's one question that you should be able to answer, leaving today, it's how can we make protocol development more modular? Because we're here at the modular summit.
00:02:53.510 - 00:03:32.720, Speaker A: And one thing I really want to hone in on as well is that these aren't just software engineering practices. This is real modular. This is very, very specific to developing at the protocol layer. So this is the state of protocol development today, we need good coding practices, but there's a few things that are very, very specific when it comes to building an open source protocol, for example, we got to keep it simple. All software engineering needs to be simple. We got to make it even simpler. As simple as possible, but no simpler.
00:03:32.720 - 00:04:00.040, Speaker A: We need to be open source friendly. Everything needs to be well documented and have good issues and tooling. But when it comes to being open source and a spec and a protocol that you build on top of there, being open source isn't just important. It's a first class citizen. There's a few others, but those are the big ones. What I want to do now is jump into the fun stuff. So this is kind of guess the project.
00:04:00.040 - 00:04:43.804, Speaker A: So right here you can see there's a project with a lot of open source development in the beginning, and then it kind of flattened out. Right? That's Ethereum, another project that kind of had a big jump and then kind of slowed down and came back up. That's the Cosmos SDK. And the last one, I think, is going to be kind of harder to predict. It kind of started off slow and then really picked up at the end. That's the at protocol, right? It's not even a blockchain, but it is a protocol for an open source social environment. And the thing that's really interesting here is that Solana, for example, only has 500 contributors.
00:04:43.804 - 00:05:48.200, Speaker A: Ethereum and bitcoin have about 1000. But if you look at the modular protocols, if you look at the Cosmos as decay, if you look at Celestia, they have the same order of magnitude as all of these other protocols whose market cap is in the hundreds of billions, while the module protocols, which are easier to develop on, is very much in the ten s. And one of the cool things here is that you can see that pocket with a local development environment that I'm about to show you has really been improving our developer productivity. So just last month in June, it literally went up 400% with a small team of four people. And if you put us aside across all the other teams, that's quite an improvement given where we're at. Okay, let's go into some very quick, more horror stories because I've seen what chain halts and scalability issues are. Okay, but while listening to us, let's talk about the experience.
00:05:48.200 - 00:06:25.482, Speaker A: We have a live protocol that's been live on mainnet for almost four years with 1000 validators. 600 million, sorry, 600 million requests a day. Over 800. Almost 800 billion requests total over that same lifespan. And we have real products, we have real revenue, we have a real team. We very much pioneered this industry. A few things that happened that kind of led us to want and need to have such a good development environment is our chain halts.
00:06:25.482 - 00:07:35.020, Speaker A: So for example, right here we had a chain halt where there was an indexing transaction issue. Right here there was an issue of us hitting the scalability issues for tendermint because it gets capped at 10,000 and we had the 5000 limit, which not a lot of other teams had. Over there is another one where we literally had a chain halt, waited a day, had another chain halt, waited a day, just as we were trying to release a new feature. This wouldn't happen if we had the local development environment that I'm going to be showing you today. So what I want to show here is that because we're dealing with a protocol and decentralized environments, we can't just restart the servers, we can't just back up the database, we can't just go and look into the validator and see what they're saying. We very much have to have a good environment and testing suite to make sure just doesn't happen. So what's in the box with Shannon? I'm going to tell you, it's in the box in Shannon.
00:07:35.020 - 00:08:09.826, Speaker A: Okay. This is what we prioritized. Protocol developer experience, local development environments, end to end behavior testing basically everything that you need in normal software engineering, but customized for a protocol development environment. And this is the big reason why, this is the big reason why I really want to do this is because ecosystem devs, we all care about them. Node operators, they're always having fun and everyone cares about them. Protocol developers, you just assume that it's going to work. You just assume there will be no bugs.
00:08:09.826 - 00:08:45.388, Speaker A: You just assume that they're geniuses or some hackers or cryptographers that make things work, but no one thinks about giving them the tools they need to succeed. So let me show you what we have. Okay, this is our stack. It's pretty standard. We have common BFT, cosmos decay, we use ignite. But the interesting things really come when we say we're not just using go. I mean we're using tilt, which is a, sorry, tilt, which is a local Kubernetes.
00:08:45.388 - 00:09:17.830, Speaker A: We're using helm, helm charts, which a lot of you guys know about. We use our with CD, but we also use kind to make sure these tools are available locally. We use GitHub actions, we're trying not to reinvent the wheel. We're using what cosmos gave us. We're keeping it as powerful and as simple as possible at the same time. And, uh, yeah, you guys, whoever's watching or listening, feel free to take a picture. Uh, it'll last longer and then come and ask more questions if you want to know more about rstack.
00:09:17.830 - 00:09:52.702, Speaker A: Okay, so what's in the box with Shannon? We have tilt. This is basically a local, containerized, dockerized environment so that you can see all of your actors. You can scale them up, you can scale them down, you can have hot reloading, and you don't even need the Internet. Like, I will show you in a moment in a live environment how all of this works. And this is what I said. What tilt enables is a local net. Where you have logs locally, you have metrics locally, you have bugs locally, you have tests.
00:09:52.702 - 00:10:18.722, Speaker A: Like, literally everything is local. And one of the best part is it's reproducible. I can make a change, push up a branch, and then later someone else can pull it and mimic the exact same environment themselves. We have manifest. We didn't want to recreate the wheel. So, you know, we're thinking, do we have a UI? Do we have a spec? Screw it. We're just using YAML files.
00:10:18.722 - 00:11:07.408, Speaker A: And some of my friends at Netflix, as you know, making their eight, seven figure salaries a year, just like to call themselves YAML engineers because all they do is update these numbers all day long. We also have end to end tests. These are natural language, so literally, you can have a PM that comes in, uses the cucumber gherkin syntax, and they can write tests themselves. And engineers can then take that and take an end to end user behavior into a true end to end test that validates the entire network at once. Observability. We have lots of different graphs, but for the sake of this presentation, I decided to go with the one that has the most colors. So we all like charts and obviously, but these are actually useful.
00:11:07.408 - 00:11:36.098, Speaker A: And the fact that these are updated and testable and usable in a local environment goes a really, really long way. We have a devnet. Basically, you take that whole local net environment, push it up to a cloud, and that's it. It's very transferable. It's reproducible because it's all containerized and dockerized. It's very, very simple to mimic the same behavior in different environments. And this extends very, very easily into testnets, multiple testnets, and then main nets.
00:11:36.098 - 00:12:43.560, Speaker A: Everyone can have their own cloud and see what happens in different environment. So now I'm going to go into a live demo and before we go into a live demo, I'm going to pray to the sloth gods because I hear that's the latest and greatest religion out there. So let's take a moment, and what I'm going to show you during the demo is kind of how we run tests, how we run a local net, some real world end to end usage, and then how we do a printhead. So let's do it. What I've done is this. I put together this document that I'm going to share with everybody after the fact, where you can pretty much clone the repos and then try it yourself. So what I'm going to do is do a clear and start up a local net.
00:12:43.560 - 00:13:22.610, Speaker A: So in order to get the local net I was talking about, I literally just run make local netApp, and that's going to be building docker containers, building protobufs. It's doing a lot of different things. While that's going, what I'm going to show you is we're going to go into another repo. Then if you run make, you can see that we have basically a really nice helper file with all the commands and descriptions for what they do. So these are all part of our makefile. For example, if you ever want to know how to list accounts with ignite, you can just go into the makefile. And here it is.
00:13:22.610 - 00:13:56.554, Speaker A: It's the way our team shares a bunch of tips and tricks so that we don't have to memorize everything ourselves and makes it easier and more reusable. The other thing that I want to show is basically how you run all of our unit tests at once. So I run Maygo develop and test. Actually, there's a little thing I need to do. This is just an environment issue. What I run Maygo develop and test, and I'm compiling protobufs. I'm running tests.
00:13:56.554 - 00:14:28.780, Speaker A: I'm basically setting everything up so that I can make sure that the local nan environment runs well. And while that's going, I did a chef like thing. So I'm going back to the other tab where you can see that the local ad is already running. And if I just press space, it tells us where's the space? Yeah, space to open the browser. One sec. Here I press space, and here is that local environment that I was talking about. Everything is in a local Kubernetes dockerized environment.
00:14:28.780 - 00:15:21.324, Speaker A: And you can literally see we have applications, we have a gateway, we have a validator, we have a relay miner, we have our monitoring stack literally all in one spot. And if I just wanted to see, let's say, the dashboard for validators, I literally just click one button from here and Grafana is available all in the local environment. I can also very easily filter this and then I can see all the claims, which are very pocket specific thing that I won't get into today. Here we are, everything's running. What I want to do next is show you how this actually happens. Here it is, tilt file. A tilt file.
00:15:21.324 - 00:16:19.370, Speaker A: It's what we use for local kubernetes. It uses python like syntax, which I'm not going to go deep into, but we specify helm resources and all of those literally just show up here so you can assess it and you can filter it. Again, I don't really know anyone else that has achieved this in the past, but the fact that we have this local environment for testing so quickly is in my opinion huge. What I want to do next is scale it. Usually you have to provision your environment, modify a bunch of configs if you want to start testing or experimenting in a different way. But what I'm going to do here, just change this. I'll show you guys that we have one appgate server, one gateway, one relay miner, but I'm literally just going to change all of these to three.
00:16:19.370 - 00:17:20.303, Speaker A: I'm going to save the file and immediately the local net environment is scaling to more pods in my local environment that I can start sending requests through testing and load balancing against. Here we have three gateways, now we have three relay miners and three apgate servers as well. So what I showed you here is we're still running all of the unit tests after everything compiled in a separate repo. That's this piece, we ran a local net and we explored a cluster. We can look at logs and we even have dashboards. Next up, I'm going to show you how to use it. I already said that we have this fantastic, let me move this.
00:17:20.303 - 00:18:10.600, Speaker A: Here we have this fantastic makefile. What if we have, let's see, we have a bunch of send commands. Pockets value proposition is decentralized PC. What if we do this? Actually, you can see that since not everything is automatable. Very quickly, what our team did is we used these big, very important statements to remind you to run a command just to set the environment up a little bit when there's an issue. And now I'm going to, let's give it a sec, make send relay. There it is.
00:18:10.600 - 00:19:03.638, Speaker A: What just happened here? I ran a send relay command and I ran a rest relay and I ran a JSON RPC relay. The JSON RPC relay return the response. And same goes for the rest relay. If we ever wanted to know what actually went into it, it's just a curl command against our infrastructure. So this is an ETH block get number, whereas this is actually a request to a local lama node. So you can see that our local environment mimicked the end to end of all of pocket network. We have validators, we have applications, we have gators, we have suppliers.
00:19:03.638 - 00:19:53.020, Speaker A: I just span up a local environment that did an end to end request sending a relay, getting a response. And the coolest thing is that the request here is against a llama node that ran an LLM inference prompt on the spot. So this is what we did. We asked it to count from one to ten, and let's see, the response we got was it said it needs more information. That's actually kind of funny. Content done. Here it is 123-456-7890 whereas that's kind of funny because in a different world, in the previous prompt it actually said it doesn't have enough information to do DLM inference.
00:19:53.020 - 00:20:38.800, Speaker A: Let's keep going. Now I want to talk about end to end tests. This is running in one tab, and what I'll show you is test e two e. We have something called an e two e relay test. So if we go to the makefile and we search for the end to end test relay, we can see that it uses this relay feature file. And this is something that any product manager, any non technical individual can do in simple English. So let's say you're a designer and you know that the protocol should work in a certain way.
00:20:38.800 - 00:21:45.380, Speaker A: Or maybe you're curious what happens when I someone stakes and burns in a specific way that we don't have to get into. You can literally use cucumber gherkin syntax, send it over to the engineering team and ask, is this something you can translate into code? It's not only is it part of your CICD, ensuring that it's always going to be stable, but it also extends the ability to have 100% Qa to the entire organization. So we don't need to get into the details. But the cool thing is every minor component of the verifiability, like making sure that claims are settled, making sure that request is serviced. This is all part of this natural language process. And like I said, it's done against a fully containerized local environment, so I can even develop when I'm offline. Okay, next up I want to show hot reloading, so let's just say, let's go down here.
00:21:45.380 - 00:22:29.344, Speaker A: We've kind of gone through a few things. Oh, actually, before we make that do those changes, what I want to show you is an end to end test that's not just. So we had one test pass, the other one's a little flaky. But what I'm going to show you now is a full on stress test where we're going to be stress testing the entire environment in locally. We're going to go back here, we're going to go to the dashboard, opening this up, and we have a few that the team put together. So here it is. We are literally running a stress test.
00:22:29.344 - 00:23:27.740, Speaker A: We're running a live load test on the spot. And you can see that we got the number of relay courses spiking, the number of go routines are spiking, everything is spiking. Everything is still functioning. But we can understand where are the issues, where are the bottlenecks, where do we need to spend time fixing bugs while also getting a ton of visibility into what's happening in the network? So there's not much else to show, like, unless we start diving into real details. But the fact that I can play around with the dashboards in this real environment, and I mean, all I did is run one command to verify that it works, I think it's probably one of those powerful things I've seen in the development landscape. All right, so what I want to do next is just show how things hot reload. Here's what we're going to do.
00:23:27.740 - 00:24:01.398, Speaker A: We're going to open up this file and settled. And I'm going to update this, this comment live at modular summit. I'm saving it. And while I'm saving it, look, I'm going back to tilt and we can see that this is hot reloading. All I did was save the file. The validator is going to start updating. Everything is updating.
00:24:01.398 - 00:24:40.762, Speaker A: Let's give it a moment while it's still compiling. And this way I don't have to bring down the local net. I don't bring up the local net. Everything is just going on its own. So if we go here settled and then we run another test, here's what I want to show you. Previously, the common was settled and expired. Let's actually search this and expired up here.
00:24:40.762 - 00:25:37.370, Speaker A: It was the old message, settled and expired claims at a certain block number. Here's the updated message live in modular summit, where we're settling and expiring claims. Since I ran an end to end test, the actual claims are going to come in shortly. But the important thing is that this message is updated and I didn't have to do a single thing. Let's give it a sec. Settled one, there might be an issue with the actual claiming process right now, or maybe I just need to do this. Okay, I'm just going to keep going through this part.
00:25:37.370 - 00:26:17.332, Speaker A: But look, it hot reloaded and if we had more time, I could just sit down and start debugging this, which is the key thing here. I had a couple slides here in case people had questions around how pocket works and kind of all the actors that go back and forth. But that was a live demo. Everything is available at Dev Pocketroll. Like, you can go here, go to developer and our quick start guide even has a video where I did this in the past along with all of the instructions and much, much more. It's available at pocket roll. So please do go and check it out.
00:26:17.332 - 00:27:20.424, Speaker A: It's a really, really good environment to play around with. But now I want to jump back into the presentation. So let me go into slideshow mode. Okay, so this is, so here's the thing. What I just showed you, I think can save not just hundreds, not thousands, I think it can save dozens of hours for every single protocol team on a weekly basis. And of course, we don't want to keep it to ourselves just because as engineers, working with engineers, we simply want to share it with the entire community. So what I want to say is, how did we get to the point of having such a mature local development environment? All we did was treat protocol developers as the customer, provide a great customer experience while also being our own customer and building for ourselves.
00:27:20.424 - 00:28:21.658, Speaker A: Like when I wake up and I open up my computer to do real work, I am genuinely excited to work on top of the environment that we have. Most engineers like the problem and the product, but here, which is very important and nothing else matters unless the customer is happy. But here at least you have a good experience the way you have a good experience, having a good coffee, spinning up your local environment without knowing that it's going to be a pain to start getting going and getting into that iterative state where you can actually add new features or solve bugs or update the dashboards. And it took, I spent a lot of time actually figuring out who I should put on this page. I had all these different companies, I had all these different logos, and at the end of it I was like, screw it. I'm actually just going to go to the Cosmos decay website, take a screenshot of the front page and put it here, because as a Cosmos decay app, what I realized is, let's just like, we want to bring this back into Cosmos. I think it's a modular environment.
00:28:21.658 - 00:29:05.610, Speaker A: You saw that. That's what enables a lot of contributors. And I think if we move this back to that environment, we can enable even more developers, and that's going to go a very long way. So no matter how good your tools are, no matter how good the product is, no matter how exciting it is, it's still very important that you have a team and individuals that love what they do. So it does come down to the people. And that's why I want to give a big shout out to the small team that made this happen. Ryan Redone Dima H five law these individuals specifically are the ones who contributed to pocket roll the name of the current repo.
00:29:05.610 - 00:29:46.434, Speaker A: But it's obviously grove and pocket who are the ones that helped make it happen, who created the foundation on which the team can build upon. But it's these individuals with whom I loved making this happen and with whom I want to keep pushing it forward. I mean, there's a bunch of QR codes here. You can scan them, take photos. It's the best way for you to go and try out the local environment yourself. And what I would love is that if you enjoyed it, kind of ping me directly. The most important thing we can do is bring this developing environment to the cosmos.
00:29:46.434 - 00:29:59.420, Speaker A: SDK and the moment we do, I think development across the entire ecosystem is going to skyrocket. So that's it. And thank you very much.

00:00:00.170 - 00:00:35.986, Speaker A: So I'm Josh, I'm the founder CEO of Astria. We're building the shared sequencer network. There's kind of a lot of question, like, what is a shared sequencer network? It's someone intentionally, like a novel term. What we view it as is like a distinct network of sequencing and specifically like lazy sequencing. And that's a term I'll cover a little bit further along and kind of like, I guess, how many people actually know Celestia? We're kind of like papering over a lot of things, but do people roughly know the structure of what Celestia is? It's a DA. It doesn't do execution. Overview of where a shared sequencer fits in the stack and what we mean by shared.
00:00:35.986 - 00:01:06.414, Speaker A: So when we say shared, we mean like, you can have two roll ups. They can use Astria, the shared sequencer network. Astria then submits transactions to Celestia as like a DA layer. This is not a full architecture. This is very much like a simplified architecture for kind of illustrative purposes here. But that's what we mean by shared. And so where this sequencer kind of fits in is because you can have multiple roll ups, or specifically, users of multiple roll ups, submit transactions to a single sequencing layer, and that can do the ordering on their behalf.
00:01:06.414 - 00:02:15.106, Speaker A: And the reason that we want this is we view it as an extension of kind of the modular, celestial thesis, where you separate components of what would historically be a single node. So you have a network and you have single node, and that node runs all the things, right? And so, like in a cosmos thing, you have a consensus node, you have a app side, whatever you're going to call like Cosmos SDK or whatever, right? But that consensus, what it's really doing is defining what is like the canonical chain for a given thing. So call it a fork choice rule, right. Celestia then splits out the DA. So as Barry mentioned in the talk on kind of what they're working on with like ABCI and in their kind of in protocol MeV stuff, they're allowing you to get data availability at the consensus kind of time, like intra consensus and like the multi round voting. I don't know the details, but I know there's some guarantees you can get over the availability of ordering data kind of in this multi round voting process that tendermint does. But what that is so tendermint fundamentally and kind of like BFT consensus mechanisms and what Celestia does fundamentally giving data availability.
00:02:15.106 - 00:02:43.354, Speaker A: So Celestia broke that out. But the other component that usually comes from this kind of consensus algorithm in a monolithic chain is this definition of the canonical chain, this fork choice rule. Celestia. You can use celestia for that. There's various designs here. I will make the argument that it is not optimal for you to use Celestia's ordering guarantees as your defined ordering guarantees for your roll up. And when I say ordering guarantees, I mean like intra block within Celestia.
00:02:43.354 - 00:03:24.902, Speaker A: So like you have a Celestia block. They're still running 15 2nd block times last I checked, right. You understand that there is a guarantee of data within that given block. However, you are submitting raw bytes essentially to that celestial, and Celestia is going to pack those bytes in a way that optimizes the efficiency of the data storage within the celestia network, right, and works for the erasure encoding and satisfies the data availability sampling. And that's kind of like what Celestia is focusing on. What it is not focusing on is giving you kind of preferential ordering. And when I use preferential, I mean that kind of, in the mev sense, similar the skip guys have done, right? Where your block for your blockchain has some order of transactions within a given block.
00:03:24.902 - 00:04:10.646, Speaker A: If we go back to bitcoin times, right, people generally didn't give a damn, right? Your transaction be at the start of a block, your transaction be in the end of the block, doesn't matter. You're just trying to send p to p funds, right? We introduced DFI. Now there is an ordering. Intra block ordering defined some pricing. Because of that, you now have a preference on how your block is ordered. That's something that you probably don't want to just naively inherit from Celestia by doing something where you just say, I'm going to have some mechanism where my roll up is going to submit a block to Celestia and some other user has to come along and say, okay, I know that there is data on Celestia and I can read that data off of Celestia, but how am I supposed to assume the ordering of that thing? You could kind of like pack that. But because Celestia is permissionless, anyone can submit transactions to Celestia, right? Anyone can submit a block.
00:04:10.646 - 00:04:43.702, Speaker A: It's not like what you would use in an ethereum style l two, l one, roll up where you have an inbox, and that inbox is fundamentally defining what is the canonical chain. You're getting your leader selection, your fork choice rule, whatever, from the on chain. Smart contract on the layer one that is permissioned right now, right? Arbitram optimism. There is one actor that is allowed to submit transactions to that inbox. There's also the other inbox override mechanism, essentially. But fundamentally the head canonical chain is defined by an onchain smart contract. You just don't get that from Celeste, so you have to get that somewhere else.
00:04:43.702 - 00:05:30.822, Speaker A: What we propose is that it may be useful to have a single layer, a shared layer, across multiple rollups that allows you to get that ordering guarantee and define what your canonical chain is. So that's fundamentally what we mean when we say a shared sequencer layer. The other important component of this is that we intend to have our shared sequencing layer also be a decentralized shared sequencing layer. This is like a very large, in my view, like oversight that all of the existing roll ups have done. They get away with it for somewhat similar reasons to why we fundamentally need this layer at all is because with the inbox model you can at least make the argument that hey, we have an override. You as an end user can go to the l one, pay your l one fees, and you can force include a transaction. Why the hell are you using a roll up if you're still having submit through the inbox model for forced transaction? That's the question.
00:05:30.822 - 00:06:34.042, Speaker A: But you can at least make an argument that your liveness is not an absolute failure if you are censored by a centralized sequencer. However, as sovereign roll ups on top of celestia, you don't get the guarantee that's papering over a little bit. You could theoretically construct a mechanism where the definition of your canonical chain can just pick up data submitted directly to Celestia from any actor. But broadly, it's similar to think about as the assumption that you need to have liveness guarantees from your sovereign roll up layer or whatever is defining your fork choice rule, because those kind of things are paired together, right? If you're making a liveness guarantee, we probably don't want a centralized sequence here because we don't have easy fallbacks. You should decentralize that. Lot of other reasons to decentralize things, not least of which is like Gary Gensler has a vendetta against this industry. I would not be personally comfortable standing on this soil and having a wholly centralized sequencer, especially if it's one such as like arbitrum that is primarily doing things where it's arbitraging derivative trades between an offshore exchange that is not within the purview of the SEC.
00:06:34.042 - 00:06:56.750, Speaker A: That feels like something that the SEC probably is not a fan of. So for that reason, we can decentralize at this layer. And we argue decentralization is not hard if you come from the tendermint cosmos ecosystem. Right. Like bootstrapping a tendermint chain. Really not that difficult of a task. There's north of 100, probably several hundred tendermint chains.
00:06:56.750 - 00:07:23.114, Speaker A: You can bootstrap a testnet relatively trivially. We're just going to do the same thing, right? We're just going to use some kind of presumably tendermint style leader selection mechanism that allows you to have some rotation between different sequencers. Each one gets a slot. You can either time those against celestia. You can have multiple slots within Celestia. Kind of up to you. We've seen some learnings from l two to l one things on Ethereum where you probably want a fixed block time.
00:07:23.114 - 00:07:50.414, Speaker A: That hasn't worked that well for optimism to have a variable block time. But that's another component here. So how are we going to do this? I just threw these slides together last night, so I'm hoping this makes sense. So yeah, lazy sequencing, right? And this is borrowing heavily from like Evan Forbes. Evan Forbes will assumingly go into more detail on your talk later this week. But roughly, you can think of it as like, this is like what a blockchain does. This is assuming like a singular node.
00:07:50.414 - 00:08:18.458, Speaker A: And we will assume it's from the view of the block proposer, right? You have a bunch of transactions. These live in a mem pool. If it's Solana, I don't know where they live. This maybe just happens really quickly. But you have something like a mem pool, right? You have a bunch of transactions, they're not ordered. You then take all these transactions, you put them in an order and then you execute them, right? So the key kind of learning we're taking from the shared sequencer, that gives us a lot more flexibility than kind of various other shared security design. I think Cosmos is calling it replicated security now.
00:08:18.458 - 00:08:42.494, Speaker A: Parachains, et cetera, et cetera. We're just doing this step. We are not doing this step. And the reason we're not doing this step is because fundamentally this requires an understanding of. You can think like think mass notation, right? You have a thing and then you put the tick for the next time step, right. You need to know the prior state DB. So call this state time t at time t minus one, you need the state DB.
00:08:42.494 - 00:09:46.310, Speaker A: Then you can add the order transactions, execute them, get your new state DB, get your new state route. But if you want to share this across multiple different roll ups. Then you need the state database of every roll up for which you might have transactions that are included in it. That kind of fundamentally breaks the scaling benefits of roll ups, where roll ups are fundamentally a form of sharding, right? We can say, okay, I put this state over here and I put this state over here. If you say, well, one set of actors that are validators or sequencers or whatever you want to call them, has to execute all of the state transitions of many disperse state DBS or state machines or whatever, whether they're homogeneous or heterogeneous, they're just doing more work, right? Fundamentally it just takes more compute to do that. You get all of the various kind of undesirable trade offs in scaling of. You now have to have more storage and it has to be fast storage, right? So you will assume like SSD storage is good enough and then you have to do the actual execution to reach that state route, right? So by doing lazy sequencing, we just take this and we put it into here.
00:09:46.310 - 00:10:34.646, Speaker A: And this is actually sufficient for getting a canonical chain or determining your fork choice rule. That's all you actually want. Because this conversion is fundamentally like deterministic, right? If you have a given state machine defined by essentially a binary, right or a spec, if you're in ethereum land, you have multiple client implementations. If you take this, you can always reach this. In the celestial terminology, we call this like a pessimistic roll up, right? Where you have some guarantee of availability of the data and then you have ordering of the data. You can always, if you run a full node, generate the next state DB, right. Various problems with this for real world usage, right? This obviously doesn't support lite clients, but that's something that I'm not going to cover in this.
00:10:34.646 - 00:11:05.310, Speaker A: Talk too deeply. I'm hoping to leave time for questions at the end. Why are we doing this? I think I kind of covered that at the start, but generally why? Because what we're seeing is quite frankly, roll ups are not focusing on decentralization right now. Decentralization is not that hard, but it is somewhat of like a bd lift, right? This is what we saw Polkadot try to solve with parachain auctions. They maybe made it worse by just enshrining a method that makes Gavin York very, very wealthy. Gavin York. Gavin Woods.
00:11:05.310 - 00:11:41.802, Speaker A: Gavin woods. Who is Gavin York? But yeah, it makes Gavin woods very wealthy. But like, you know, do you enshrine a mechanism for how we're going to essentially buy your way in interchange security with replicated security has had cosmos style issues of we have to go to a governance vote, and then JQuan pokes his head in the room, and now we have to destroy our system. And so there's various reasons why this is problematic. And so what I'm saying is decentralizing. There's a desire for people to get an out of the box. Like, I want someone to do the work of going and talking to 100 to 200 to 500,000.
00:11:41.802 - 00:12:20.540, Speaker A: If your ethereum, though, it's really not 500,000, but whatever, a large number of people to run chains in diverse countries, sovereign regions. Right. For various reasons, whether it is regulatory or whether it is liveness and uptime of the network, we think that can be offered as a service. We think using lazy sequencing, we can do that in a way that supports many heterogeneous state machines by not actually making that final execution state. So, yeah, that's kind of like the argument for shared sequencing network questions. I mean, I have no working relationship with swave formerly. Like I talked to them.
00:12:20.540 - 00:13:09.846, Speaker A: I think structurally, you can look at. If we go back to, right. If we look at just like this structure, right. Fundamentally, and again, these roll ups are here for this is like an intellectual movement, not like this is not how the block or the flow of data, but fundamentally, right. If you have a layer in between, another layer, in this case, it would be like Ethereum for suave or whatever, right? Or maybe they are even putting it in front of the rollups itself, right? You do have an aggregation layer. So I think it's structurally kind of similar in architecture. The way they're viewing it from a market positioning like a go to market is suave, as I understand it, reading what public docs they have for now and talking the team a bit, they view it much more as a preference expression environment.
00:13:09.846 - 00:13:47.362, Speaker A: And specifically a. I don't know what the terms, but private on demand or not, rather private by default, and then revealed preference at the time, you need to reveal the preference environment. And what I mean by this, your desired transaction should not be revealed except to select parties, right? So use the historical version of privacy, right, where it's not completely hidden. Because fundamentally, if you use this architecture and you say, okay, cool, we have a big, basically mem pool, right? That's what suave calls it, right? Single unified auction for value expression. But it's a shared mem pool. You just slap a bunch of transactions in the mem pool. People can look at them across all things.
00:13:47.362 - 00:14:14.958, Speaker A: You have just created a larger pot of potential mev that just makes a larger adversarial environment. That, again, kind of going to the question of executing the state DB for multiple things, right? Like, searchers don't give a shit. They're like, oh, cool, I have to run like five blockchains. It's like, fine with me. That is within the bounds of the effort they will do to find arbitrage. So now you again have made the game such that well resourced actors have yet a further advantage. Because of that, suave is doing a lot of work at looking in.
00:14:14.958 - 00:14:42.134, Speaker A: How do you make this mem pool private? Because it is very, very profitable for someone to have all this information. And quite frankly, I think from Flashbot's point of view, it would be a very hard sell to chains to say, like, you should use this private mempool. It's going to make your mev problems worse. But you should trust us because we're good at things. It's not a good sales pitch, and they know that. So they're working on sGX things, they're working on fhe things. They're working on name many things.
00:14:42.134 - 00:15:10.414, Speaker A: There's so many different problems with scalability and whatever, but they're looking into that. So I think struck architecturally similar what they're trying to do different. And then one last point. They're targeting existing chains, right? They're trying to integrate with existing chains. We are very much targeting this as a solution for yet to be created chains on top of celestia to provide yet another component in this modular stack that makes it such that you have more out of the box componentry. That doesn't restrict how you can develop your chain. Yeah.
00:15:10.414 - 00:15:38.358, Speaker A: Gabriel, you had your hand up before. Yeah. So it's a chain, right? It's a chain. They pay for that. There's various kind of emergent behavior questions around how they pay for this that can kind of tie into the mev thing. You can think of this as a potential environment where you could do account abstraction style things fundamentally, right? If we think of the existing kind of like model in my head, right, you'd say you're like, roll up one. You want to submit transaction for roll up one.
00:15:38.358 - 00:16:07.394, Speaker A: You still own your key. You have to sign a transaction for that roll up. Then presumably you have to submit a transaction into the shared sequencing chain, right. Because that will actually define the ordering of it, right. So you can do it as either, like a wrapped transaction where you're just signing two transactions that may be an undesirable flow. There may be things, account abstraction esque. That can happen at this layer where you could have mev things and essentially it becomes a payment for order flow style system where someone says, hey, I signed my transaction here.
00:16:07.394 - 00:17:04.734, Speaker A: I'm willing to put that in public. That's free game to get front run sandwich whatever, but presumably someone else will pay to include it and their return will be through sandwiching you, front running you whatever, like extracting value from you over a long term. Maybe that's a beneficial thing from an end user perspective to say like, hey, I get free transaction inclusion, but I'm going to get worse price performance on an arbitrage thing. But you can also still to some degree specify what your slippage tolerance is for validity of the transaction. Going to the suave thing. We are also intending to look at at this sequencer laying, allowing some level of preference expression, but we're somewhat restricted in kind of like how agnostic we have to be of awareness of that. Suave solves this, at least in the, again, the proposals I've seen with multiple off chain actors, essentially where you place a bid and then it is a post fact, your bid is essentially a thing where you say, I propose this transaction, here's my signed transaction.
00:17:04.734 - 00:17:53.530, Speaker A: I will only pay you if you satisfy condition x. Condition X is verified out of band by a. It's an oracle from the perspective of like the suave chain, but some actor, maybe they're a validator or whatever on the other chain, that then will submit proof. I don't know what they mean when I say proof, but submit some evidence that that transaction was executed to satisfy the bid, and then they pay out. It's a pretty broad design space for how they do this. Fundamentally what your goal is, is to get an ordered block which is submitted as a payment for blob to Celestia, and then from that your rollup is able to look at that, be a light client of the shared sequencer. And essentially you have this path where I read raw data, I know how to order that data based off of being told how to order that data as a light client of a shared sequencer.
00:17:53.530 - 00:18:14.020, Speaker A: And then I know how to execute mute that by my roll up. And presumably what like a full node looks like in this whole stack is someone who is running one of the minimum viable will be like light client, light client, like full node of the roll up node, right? But you could also have actors that are full node, full node, full node, relatively broad design space.

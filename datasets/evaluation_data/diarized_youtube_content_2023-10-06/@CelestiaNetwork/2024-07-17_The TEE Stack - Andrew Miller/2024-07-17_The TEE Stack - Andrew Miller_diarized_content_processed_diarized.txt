00:00:01.720 - 00:00:47.484, Speaker A: All right, so I'm going to talk more about Tes. I'm going to try to make a point, which is, so you've heard why tes are really important, why we really need them. Just waiting for cryptography is not a long term, let alone a short or medium term solution. I want to build on that in a moment. But the overall message that I want to convey is that we have a lot of work as the web3 and blockchain community to do in making the software stack that builds around Tes actually realize the potential that we can do. This is a really important opportunity because actually the te world, which has applications beyond just blockchain, actually often needs blockchain for many different things. Ethan went over why blockchain plays a role in replay protection and even side channel mitigation in tees.
00:00:47.484 - 00:01:13.540, Speaker A: That's one good example. So that's what I want to talk a bit about. Normally I try to give a nice nuanced argument, but Ethan already covered that, so I'm going to get let loose. I just want to convince you that tes make everything better. Tes are basically a magic box that you can put any software whatsoever into, and it makes the software better and more interesting. If you take a smart contract vm and you put it through a tee, you get a smart contract system with programmable privacy. That's better.
00:01:13.540 - 00:02:01.216, Speaker A: This means that any of the apps that run in smart contract vms become better as well. So if you put in a humble uniswap automated market maker, you get a dark pool out. If you put in a margin lending protocol, you get a private portfolios margin lending protocol where you have resistance against snipes trying to tip the price on just the collateral that you're sensitive to. You heard from Shea about what happens when you put a builder into a tee. You get a trust minimized builder that gives you a guarantee. It follows all of the simulation and ordering rules and bidding rules that you'd expect. If you haven't finished your l two with fraud proofs yet, but you put it in through a TE, then you get proactive validation for it finishes your l two for you, and you even get proactive ZK validation without having to wait for optimism.
00:02:01.216 - 00:02:51.490, Speaker A: If you already have a finished l two with proactive ZK proofs, then you get a multifactor two fa prover. It can downgrade if either your snark circuit's broken or the tes get broken, you have a backup. If you have the multi party computation approach and you're already paying for the extra cryptography there. Then by putting this through the te you get the collusion resistance, which is addressing the main, besides performance, the main remaining challenge of MPC in general. If you put any web two application in the tee, it comes out with web3. You'll see a bunch of examples of this, but the basic idea is that you get the whole TL's stack as part of what comes along in the trusted code base in your enclave. So you can make TL's requests to TL's servers and the enclave is guaranteeing that it actually carried out the certificate validation and it's talking to the thing it's supposed to.
00:02:51.490 - 00:03:41.220, Speaker A: You can serve websites over TL's from a TL's server in the enclave, and now you can even get the certificate transparency to work for you. You can say, well, this domain has only ever had one certificate issued for it and that certificate came from a tee, so the private key for that never left the TE. And so you're always getting, you know, a trust minimized front end, for example. So let me talk just a little bit about what goes into the software stack around trusted hardware. So trusted hardware is a thing that's part of Intel, AMD and Nvidia chips, lots of others like that. The point is that it's something that's supported by hardware, it's part of the instruction set. So it's something that at the lowest level you have to write X 86 instructions to make use of the SGX specific, the extra instructions that are added to support SGX.
00:03:41.220 - 00:04:16.772, Speaker A: Most people also use a higher level layer. So either SDKs, which maybe involve a little bit more work, or a lib OS like gramine where you can really take existing process descriptions and those will run. Also there's confidential virtual machine layers so you can run docker containers or VM images. This is especially with AMDSCv or intel. TDX are more of the virtual machine style. And on top of that we often want to do coordinating decentralized systems with redundancy and matching of these. So the main appeal of these is that this is why you get to run legacy code.
00:04:16.772 - 00:04:52.500, Speaker A: So in principle there ends up being a lot of caveats, but I don't need to discuss those for now. In general, you can take legacy existing code that was not made with Tes in mind, but now you can run it in Tes and you get all of these privacy and integrity benefits as well. And that's really the appeal of this software layer. So the hardware providers are responsible for making the raw thing that makes this work. And that's at the hardware instruction level. They often provide some software interfaces as well, but you can also modify your own software the way that the most important software packages today work. That make up this framework of the software stack around Tesdem.
00:04:52.500 - 00:05:34.806, Speaker A: These are made by open source projects. So there's like the confidential compute consortium, that's a Linux foundation managed thing. A bunch of the projects that we use and frameworks that we use come from there. The main reason why we need to be involved in this is because there is a fundamental mismatch in values between what we want as web3 decentralization and the ordinary enterprise and cloud setting. That's the main driver so far between TE software and hardware support. The main goal that you're supposed to get from Tes is that you can deploy an app to the cloud and you don't have to trust the cloud because the cloud's running the TE so you don't have to worry about it. But that's a very Web 2.0
00:05:34.806 - 00:06:18.332, Speaker A: thinking because it's assuming that the app developer, the app admin, is the one who's being protected from the cloud and that's it. What we care about is that your users don't have to trust either you, the app developer or the cloud. So we want to pass these guarantees down onto users. That's really the main point between what I want to say is needed in this software. So it's really likely that and for that, and for all of the other reasons like Ethan mentioned, there's a lot of reasons why it's actually better when using trusted hardware. To use trusted hardware in conjunction with a blockchain, it's actually a good idea to build. Even if blockchain is not your goal, it might be a useful solution, especially for things like key management and coordinating many nodes, and assigning tasks to nodes, and handling the failovers in a way that doesn't create race conditions.
00:06:18.332 - 00:06:56.912, Speaker A: Using a blockchain is great for resolving those. So I think there's a real need for te frameworks to incorporate blockchain features and that's the sort of thing that we should be building. I will come back to this shape in a moment and I covered that too. I only want to talk about one slightly in depth, still at a pretty high level but technical topic. And this is about something that I think is pretty important that we should extend to in the vein of sovereignty so it can fit the vibe of this summit. And this is about what rights are extended to users especially during software upgrades. So the first way that you use a t is very rigid.
00:06:56.912 - 00:07:26.270, Speaker A: And the main premise is you can say, I'm going to send my sensitive data encrypted to this enclave. I actually specify the hash of the program code that I'm expecting to allow to run. So it's like the hash of the program binary. So I'm saying I can only let this program binary run on my sensitive data. That's where I get these guarantees from. But this is of course really rigid. What happens if the program that I sent my data to turns out to have a bug? I want the devs to be able to patch and upgrade fixes to this.
00:07:26.270 - 00:08:17.268, Speaker A: The next simplest thing that you end up with is using code signing. So you can say, well, I'm going to trust my, send my sensitive data encrypted so that any enclave that's signed by the code signer can access it. This is, I think, a really bad setting that we should move away from, because this basically means whoever has the code signing updates could sign, for example, an enclave that just outputs in plain text everything sensitive that was sent to it. So this is a bad setting that we don't want to be in. The next best thing that is in the direction that we want to get to is that you can say, well, I will use this blockchain environment and I will have something like a DaO governance. I'll encrypt my data so that only this smart contract can define the policy that the enclaves will run. The magic that makes this work is, like Ethan said, you want to run light clients inside your enclave.
00:08:17.268 - 00:09:16.390, Speaker A: Running a light client inside a trusted hardware enclave, that's a huge source of power, and it's good for the enclave, it's good for what private software you're going to do with it. So now the app developers still can influence the program and it can change, but they have to go through the governance rules. So this at least means that they have to do it in some kind of transparent or visible way. This is roughly the structure that oasis and Falla have, and some other systems have something similar to this. But what I want to draw attention to, and that's in the vein of user sovereignty, but this is still to improve on, so we should work on these kind of things and find others like this. What if the user is concerned that the devs, even the majority of devs, even the governance of the contract, want to rug the privacy of this user? What if they're about to change the enclave to something that is not what the user is okay with in terms of privacy. Does the user have any rights in that case? Even the best practice with ordinary non private smart contract updates is a notice period.
00:09:16.390 - 00:10:02.326, Speaker A: The update shouldn't just take effect right away, maybe it goes through an update period. You could implement the same kind of rules and then actually use the enclave to guarantee users that these rights are enforced, that any changes go through a minimum notice period. And ideally even that if users really don't like that policy, they should be able to opt out and revoke their private data altogether. Maybe they don't get to keep using the system because the system has evolved and governance has changed it. But maybe users get the idea, the ability to opt out before having all of their sensitive data disclosed. As an example of user sovereignty, it's something that I think we should be trying to pass down to users, and that's very much along the lines of the difference in values between our web3 world, what we expect from Tes, what the enterprise world currently does. So we should be influencing this.
00:10:02.326 - 00:10:47.066, Speaker A: The best way that we influence things is by just ripping parts out of the stack and redoing it ourselves. So I think it's absolutely the right idea that we should be adding our own blockchain based key management and orchestration and administration of trusted hardware networks. There's also good reasons why we may want different variations of security properties that may require us to go and dig into stuff at the lower level. So, for example, side channels are not something that you can run your legacy code automatically in, something like gramming, and it runs in the TE. But just because it ran in the TE doesn't mean you're getting all of the potential of the TE. It's not automatically secured just because it's running in the te. There's also a lot of steps you have to take to mitigate side channels.
00:10:47.066 - 00:11:17.914, Speaker A: And if you just port some code without thinking about it, you don't necessarily get these mitigations. There's lots of caveats to the trust models and such. We often will say, well, no, we really want. We're very suspicious of the cloud, we're very suspicious of any of the physical operators. We want the strongest possible guarantees. That may require us to basically reach into some of the existing frameworks at a somewhat lower level still software, and change it to ourselves if we have to. This is where Sylvain's talk is relevant, and there's this, I think, emerging movement that I'm pretty excited about to do.
00:11:17.914 - 00:11:41.206, Speaker A: We'll talk more about it. I think today on open tease. I think we should be willing to threaten and deliver, and we can. It's not out of the ordinary. We've done blockchain native hardware of other kinds before, VDFs, Ek accelerations. We should be willing to make our own blockchain native hardware if we have to, and that way we can actually add stronger defenses. We can make open source versions of these so you don't have to trust the opaque manufacturer.
00:11:41.206 - 00:12:15.368, Speaker A: We can build in things that make it easier to audit so you don't just have to take the manufacturer's word for it. That's the status quo. That's not great. We should strive to do better. That's in our nature, right? We should be willing to go take in, dig in any of these. So my goal is to basically embolden you to learn about Tes, accept the idea that they're necessary and very useful, learn a little bit about the software frameworks that are there so you can kind of see how that works and think about where you would want to dig in to try to improve things and shape this cool technology so it fits our values and not only those of the web two world. That's all.
00:12:15.368 - 00:12:15.600, Speaker A: Thank you.

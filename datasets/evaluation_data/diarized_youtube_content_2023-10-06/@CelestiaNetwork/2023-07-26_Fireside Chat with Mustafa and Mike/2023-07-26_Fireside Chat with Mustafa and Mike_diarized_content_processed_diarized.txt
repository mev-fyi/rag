00:00:00.330 - 00:00:32.770, Speaker A: You all right, everyone having a good modular summit? Let's give a hand to Celestia for organizing this maven eleven. This is amazing. And this is the last panel of the day, so everyone gets a trophy and a cookie for staying and watching us. Thank you, Mustafa. I have got a lot of questions for you about Celestia, both the history and how we've gone from lazy ledger to here and sort of what you expect from the future. But I was told actually that you at one point got arrested for hacking the CIA. And I've just got to get you to tell that story on stage.
00:00:32.770 - 00:00:36.120, Speaker A: So give us the inside scoop. What's the history here?
00:00:37.050 - 00:01:10.770, Speaker B: Yeah, so we're starting straight with that. Okay. Yeah, I mean, I kind of got into programming at an early age and the first programming language I learned was PHP. And I started thinking about ways that programmers could make mistakes in their code. And then I started learning hacking naturally through that way. My first experience of a hack was when I was doing my math homework. I didn't have a calculator with me.
00:01:10.920 - 00:01:12.930, Speaker A: How old were you when you were doing this?
00:01:13.080 - 00:02:00.050, Speaker B: Well, this calculator thing was when I was, I was like eleven. And I don't have a calculator, but I need to do my math homework. So I searched online for an online calculator and I found this shitty pearl calculator on this maths professor's website. I think it was like University of Maryland, and it was like a text box. There was like a text box where you can type in sums and it would give you the result. So I was, hmm, I wonder if he implemented this in the most basic way that a programmer would probably implement this, which is he was using Perl. So the way he would do it is you would take the user input and you would input it into a function called evaluate, and that basically evaluates perl computer code.
00:02:00.050 - 00:02:33.562, Speaker B: So not only you could type in like sums into this calculator, you could actually type in computer code into this calculator and the server would execute it. So you could actually hack the entire server through this exploitable calculator. And so I managed to get access to this university server by typing computer commands into this calculator. And then I emailed the professor and he tried to fix it. And then I found a way around it. And that was kind of like a very interesting experience for me. But then I kind of got more involved in hacking.
00:02:33.562 - 00:03:40.046, Speaker B: When I started becoming more involved in Internet activism, I was involved with the groups like Anonymous and Laltec. Anonymous was doing denial of service attacks against various entities that they were protesting against. So, for example, when PayPal and Visa and Mastercard blocked donations to Wikileaks, they did a denial of service attack against PayPal and Visa and Mastercard to take them offline. And there was like thousands of people in the chat rooms kind of coordinating this. But for me, I thought that was kind of interesting, but it didn't really do much except for gain some media attention. So I decided, okay, why don't I actually try to hack something and get information that could shed light on wrongdoing? So then I found some technical people. I noticed a few people that were more technical than others, and I brought them into a private channel and kind of started a hacking group through there, eventually spanned out into Lulsec.
00:03:40.158 - 00:04:09.638, Speaker A: So, just to sum this up, by the way, the difference, mustaf, between you and me, when we're eleven, if I didn't have a calculator, I just didn't do my homework and try to hack a new one out of the web. And just to bring us up to the current time, and I think you're about 16 years old at this point, right? You're sort of casting around and looking for a righteous group that you can hack. And you settled on the CIA, which is. That's a bold choice. Tell me, how does the CIA take to hackers? Is that particularly welcomed?
00:04:09.734 - 00:04:35.826, Speaker B: Yeah, I mean, so the funny thing is, CIA was one of the many things that we kind of attacked. But the funny thing is, the CIA wasn't even technically a hack. It was a denial of service attack. So it's like, denial of service attack. You're not actually getting confidential information. We took the CIA website offline, and that's like a very basic thing. We did more advanced things than that.
00:04:35.826 - 00:04:45.590, Speaker B: But that was the thing that got the most attention, or one of the things that got the most press attention, because it was very embarrassing for the CIA to have their website taken offline.
00:04:46.570 - 00:04:52.650, Speaker A: Did they thank you for this and say thanks for showing a vulnerability in their system, or were they a little less forgiving?
00:04:55.150 - 00:04:57.180, Speaker B: That means some very strange ways.
00:04:58.430 - 00:05:48.300, Speaker A: All right, we'll dig at that a little later. But I think there's a great story to tell because there are a lot of very unique people in the crypto space. And I think the people who have made an enormous impact actually come at this not from a short term money making perspective, but from an ideological how can we change the world perspective? So I think that's just important background for folks in the audience to understand. Now, I want to actually move us forward a little bit in time and talk about lazy Ledger, which was originally the name of Celestia and sort of the white paper and idea that launched this entire wave of modularity that's frankly blossomed into something super amazing that we're witnessing this week in Paris. So tell us a little bit about how lazy ledger came to be and what did the early iterations of that modular idea look like.
00:05:48.670 - 00:06:36.794, Speaker B: Yeah, sure. So I've been interested in peer to peer systems for even before bitcoin existed. Like, I was interested in BitTorrent and peer to peer file sharing because I used to download stuff from Pirate Bay. And it was very interesting to me that people could just download stuff kind of like permissionlessly. And the reason why I was so interested in pay to pay systems is because so many people try to shut down their pirate bay, but to this day it's still online, so it's like extremely censorship resistant. And that's thanks to technology like BitTorrent and DHDs. So then I learned about bitcoin in 2010, 2011, and I was following that and I was kind of like following the research conversations going on.
00:06:36.794 - 00:07:28.854, Speaker B: There was like this IRC channel called bitcoin wizards where people were discussing theoretical improvements to bitcoin. And I noticed that there was like a 1 mb block size limit in bitcoin. And I was like asking people, what are you going to do when it gets reached? And people weren't worried about it at the time, it would never get reached. But then it got hit pretty soon in around 2013, 2012, and transaction fees became very expensive. And then the bitcoin community started debating about how to fix that problem. And it kind of like split into two camps. One camp wanted to increase the block size and that camp span out into bitcoin cash, and another camp wanted to use L2 technologies and payment channels and Lightning network.
00:07:28.854 - 00:08:09.526, Speaker B: And that was the bitcoin camp that kind of prevailed, the bitcoin main network. But the reason why they didn't want to increase the block size was because the fundamental principle of blockchains and cryptocurrency is that end users should be able to fully verify and validate the chain. And if you increase the block size, it will make it more expensive for users to run full nodes. So then I started thinking about like, well, about this problem more. And then I started doing a phd at UCL in 2016, focusing on layer one scaling. And at the time people were talking about sharding. That was like the most interesting getting solution at the time.
00:08:09.526 - 00:08:49.190, Speaker B: And I co authored a paper called Chain Space, which was like the first sharding protocol for smart contracts to be proposed. This was around the time when Ethereum 2.0 was researching sharding. But the problem with all of these proposals were that they weren't dealing with the case where a shard goes bad. It was pretty much like a block size increase, like the security model for those proposals were just like increasing the block size. But there was no way to actually validate what the shards were doing. To fix that, you need to have fraud proofs and ZK proofs, and that's what roll ups are doing.
00:08:49.190 - 00:09:54.758, Speaker B: But at the time, the reason people there was a missing problem to making fraud proofs and ZK proof works, which was the data availability problem, which was an unsolved problem at the time. And so I started doing more research into the data availability problem, and I co authored this paper with Vitalik on how to scale data availability using data availability sampling. And then I realized that this is actually basically the core primitive that makes a blockchain work. A blockchain, fundamentally at its core, is basically a data availability layer and a consensus layer. So then I proposed lazy ledger, which was a kind of a paper that proposed a blockchain, a layer one chain that takes layer one back to its core components. That's why it's called lazy ledger, because it's a lazy blockchain that does not do any computation, only does consensus and data availability. And this was an idea proposed about three months before optimistic roll ups were proposed.
00:09:54.758 - 00:10:14.430, Speaker B: So when optimistic roll ups were proposed, everything kind of clicked together, because in my paper, I didn't really have a fully fleshed out execution model, and optimistic roll ups provided that. So then it kind of made a lot of sense to actually build this, because roll up central roadmaps need a scalable data layer.
00:10:15.410 - 00:11:00.650, Speaker A: Yeah, I actually want to get into the weeds of data availability. I think that's a word that many people understand kind of on a surface level. But it's such an important sort of roadblock in terms of realizing the grand vision that many great talks have actually laid out today. So I kind of want to actually go through and maybe just define sort of the basic components of a stack, which to me is the execution, the data availability, the settlement, and then the consensus. And can we focus on that data availability question? Let's say there were a bunch of five year olds in this audience. How would you explain the importance of that? And then why is solving data availability such a critical roadblock? Not only for scaling base layer infrastructure, but for the cost of apps.
00:11:00.810 - 00:12:10.530, Speaker B: Yeah. So here's how I would explain it. When bitcoin was created, bitcoin was created to solve what's called the double spend problem. And the double spend problem is, where is this fundamental problem in creating digital cash? Where if Alice has a certain amount of funds, how do you prevent Alice from spending their funds, the same funds twice? And the way that you prevent that is by having a blockchain that orders transactions. Because if Alice tries to spend their fund twice, then only the first transaction will go through and the second transaction will be rejected. But in bitcoin, this rule where only the first transaction can go through, or the rule where you can only spend funds that you actually have, is enshrined into every bitcoin node. So that if you run a full node and you receive a block that has an invalid transaction, your full node will execute every transaction and reject a block that contains any invalid transactions.
00:12:10.530 - 00:13:33.070, Speaker B: So miners can't misbehave in that way. But the question that kind of led to lazy ledger was, well, and why data availability is so important is, well, is a thought experiment, which is, what is the simplest version of bitcoin you can create? What if you had a version of bitcoin with no rules about what transactions can go into the chain? Which means imagine a version of bitcoin where conflicting transactions or transactions that double spend coins are actually allowed to be on the chain. Well, how can that still be secure? How can that still prevent double spending problem? Well, it's pretty easy. All you have to do is make sure that the clients simply ignore the second transaction. Right? So technically, you don't need to enshrine computation or transaction validity rules to the chain itself. You can push that away to another layer, or you can push that away to a client side node, where the layer that you're pushing it to simply ignores those invalid transactions. And if you do that, then you're basically using the blockchain not for computation, but only for a ordering, and b data availability.
00:13:33.070 - 00:14:06.634, Speaker B: And the reason why ordering is important is obvious, because you need to know which transaction came first to know which is the real transaction that actually got to spend those coins. And the reason why you need data availability is because you need to know the complete set. You need to know all the transactions that happened to know which one even came first in the first place. If not all of the transactions were published, only some of them, then you don't know if there's a missing transaction in the set that wasn't published that might have come before that makes sense.
00:14:06.752 - 00:14:54.410, Speaker A: So I want to understand from the perspective of, I mean, in kind of simple words, it's a lot of applications, they need data, they want to do it in a way that's cheap. And I want to start painting a picture for those in the audience. Like if we solve this problem, what market structure changes are going to happen here? So from a cost structure, my understanding for especially roll ups and things like that is that data availability is a massive cost for them. Right? And critically, it's a variable cost that it doesn't get cheaper. It's not some fixed cost you can amortize across a whole bunch of users. It's actually something that is going to scale relative to the amount of transactions that happen. So I want to get a sense of, let's say these apps start using celestia for data of availability, they massively lower their cost.
00:14:54.410 - 00:15:09.854, Speaker A: What is the impact of this from a market structure standpoint? Do we see lots of new apps launching? Are there business models that are enabled with a lower cost of transactions that end up happening, that have been precluded from happening before? What are the first order implications of this?
00:15:10.052 - 00:16:31.370, Speaker B: Yeah, I mean, the kind of most immediate, obvious implication is you have cheaper data availability leads to cheaper transaction fees. And I do think that a lot of usage of web3 applications have been bottlenecked by the fact that transaction fees are too high. Like if we had cheap transaction fees, I would honestly genuinely think that we would see a lot more applications being deployed on web3 and not just defi applications, but also for example, to give an example, this will be discussed in the gaming track tomorrow. But there's various on chain games that are only practical with a high data three port or even for financial applications. Imagine you wanted to just use the original purpose of bitcoin was to use it as a peer to peer cash system. But we don't have a single kind of widely used blockchain that is usable as a peer to peer cash system because of the transaction fees. So if you have scalable DA, you have cheap transaction fees, then it can actually be used to what the original purpose of bitcoin was, which is peer to peer cash, not just a store of value or an investment or something that people hold because they think it will go up or trade on dexes and so on and so forth.
00:16:31.370 - 00:17:36.954, Speaker B: I think the other kind of effect is we will see a lot more applications become practical as a result of cheaper transaction fees, but also by having scalable DA and having on a modular blockchain stack, we'll be able to see a lot more experimentation with different execution environments where certain things that people wanted to do before are now possible. So some examples of that is that various projects have banter. For example, have modified the EVM to add certain ZK or privacy friendly opcodes that aren't possible on the standard EVM. Or for example, Curio have modified the EVM to create a 0.5 tick game engine to run a real time strategy game on, which wouldn't be possible on a standard EVM. And historically it wasn't possible to do that without deploying a new layer. One, if you wanted to deploy a new execution environment, which is a lot of overhead to use like a web two, analog.
00:17:36.954 - 00:18:08.840, Speaker B: Imagine if you had to have a physical server somewhere just to experiment with a new programming language or a new database. Today, that's not the case because you can just split up a virtual server in the cloud on AWS or digitalocean. So you can think of roll ups on a scalable dlao as like virtual blockchains that enable people to experiment with different execution environments that unlock things and enable things that fundamentally weren't possible before.
00:18:09.370 - 00:18:52.870, Speaker A: I have a question for you, Mustafa, which is, I sort of found myself wondering, as you were just discussing there, there's kind of this question that's a little fuzzy to me, of like, just as a hypothetical, with the proliferation of many different execution environments. Now it's not just the EVM, many data availability layers, right? It used to be just Ethereum dA, but now we've got eigenda and Celestia avail other providers, and different choices for settlement and consensus as well. It's very possible in a very near time in the future that you could be using an application that's built on the Solana virtual machine using celestia as da, but settling to Ethereum, and the question is, what chain are you on at that point, and where is the lock in for these different environments?
00:18:53.210 - 00:19:47.042, Speaker B: Yeah, that's a good question. The whole point of bingelity is to kind of shift away from a world where you have this tribalistic crypto environment where it's like this chain versus that chain. It's like Ethereum versus Solana versus avalanche, which is a very zero sum mindset. And long term, it's important for chains to have a social mode, but long term, for crypto to go to mainstream. Ultimately, users care about usable products, not necessarily which chain that they're on, as long as the chain has basic unnecessary decentralization and security properties. I think people right now kind of frame things like this app on this chain. You need to swap on polygon, you need to swap on avalanche C chain.
00:19:47.042 - 00:20:15.280, Speaker B: In the future, people won't be thinking in those kind of terms. People will be thinking, okay, this is the app and it uses this underneath. When you interact with a website today on the web, you don't necessarily care too much about what stack is using underneath. In many cases you don't even know. Like when you go on Google, you don't know, is it using Linux, is it using FreeBSD? You don't necessarily know as long as it provides properties that you need.
00:20:15.970 - 00:21:07.266, Speaker A: Yeah, I want to actually do a little thought exercise here and imagine that you and I are sitting down. It's five years from now when we're having this fireside and I've got some questions for you to dust off the old crystal ball here. And I want to ask you about how things have played out during that time. What does the market structure look like and what are some of the big changes that we might not be super obvious today. So we've heard from a lot of great projects today, these past couple of days, basically new approaches to scaling infrastructure, new types of specific blockchains. What does the market structure sort of look like for the modular stack? I mean, are we going to live in a world of thousands of blockchains? Like how many different general purpose roll ups do we really need? Are these going to be across two or three trust environments? Is the multichain future really going to play out? Sorry, I can never just ask one question at a time here.
00:21:07.368 - 00:22:14.114, Speaker B: Yeah. From an engineering perspective, when I kind of started this lesture, what I envisioned happening in a few years, and it's basically already kind of materializing. Today was a world where you can go on the docs and you can click a roll up as a service provider and you can deploy a roll up chain in 2 seconds where effectively you have a world where deploying a roll up chain for your application is easier and more convenient than deploying a smart contract. And so there is a potential world where there's millions of interconnected chains that share security similar to how today there's millions of web applications running. We've seen a very similar evolution in web 210 15 years ago. If you wanted to create a new website or web application, you would use like an existing hosted service provider. You might use Squarespace or blogspot or WordPress, but that's very limiting.
00:22:14.114 - 00:23:03.910, Speaker B: So now today, if you're application developer and you wanted to deploy a new web application. It's like easier and more convenient to simply deploy a virtual machine on the cloud, on AWS or digitalocean than using a shared hosting provider. And I think you'll see a very similar evolution in web3, where shared web hosting providers are like analogous to shared smart contract platforms. And in the future it might not seem obvious now, but in the future the obvious ways to develop new applications will not be to deploy a smart contract on a shared smart contract environment that everyone shares, but to deploy a new all up chain similar to how on web two, you deploy a new virtual machine for applications.
00:23:05.050 - 00:23:32.254, Speaker A: So at the risk of asking potentially a spicy question here in this future sort of envisioned state of yours, where we might have millions of roll ups, I can't help but notice many of the roll ups today have these multibillion dollar valuations, a couple of million roll ups at a couple of billion dollars each, starting to talk about some real numbers. So how do you kind of see that shaking out? Is there consolidation in the future here? How many of these general purpose ones do we really need?
00:23:32.452 - 00:23:59.834, Speaker B: Yeah, we don't need like these millions of roll ups won't have multibillion dollar valuations. They won't all be like massive roll ups. They might all be small applications. Just like how there's different websites that offer small services or small applications. You might imagine like dows having their own roll up chains. Like similar to how organizations have their own discord servers. They don't share the same discord server as everyone else.
00:23:59.834 - 00:24:09.690, Speaker B: They have their own namespace. You can imagine that dows might have or projects might have their own roll up chains that interoperate with other roll up chains.
00:24:10.110 - 00:24:56.170, Speaker A: Understood. What about, I mean, one sort of theme, and maybe I'm reading a little bit too much into this and other folks think differently, is that I think five years into bridges, we can all admit that it hasn't been as smooth as we thought it might have been at one point, and some of especially like intense based architecture sort of points this idea, maybe we're not going to find out bridges as easily as we thought. And there'll kind of be a couple of different sort of trust zones or economic sort of zones. How do you kind of see the. It's very easy for me to imagine a world where there's apps that pick out, hey, I'd like this particular EVM or execution environment in Celestia for DA or whatever, but how much do you actually see assets and data being interoperable between these different base chains?
00:24:56.510 - 00:25:55.280, Speaker B: Yeah, I mean, I think interoperability is absolutely critical, and that's kind of like the reason why we're building Celestia as a shared security layer that can be used by roll ups to interoperate without fragmenting their security. And that's why in the cosmos ecosystem, we want to replace these committee based IBC bridges, which have a heterogeneous security model. That's fragment security with a more homogeneous security model where roll up share security and use fraud and Zk proofs, not committees. But it is the case that bridges today are very janky and very not. Don't have a good user experience. But I honestly think that the fundamental problems, there's practical solutions to all these fundamental problems. Fundamentally, a lot of it is just like an engineering slog that has to be and a lot of missing pieces of infrastructure that just need to get built.
00:25:55.280 - 00:26:34.940, Speaker B: For example, if you take the fact that optimistic roll ups have a seven day challenge period to withdraw from the roll up to the l one or to another chain, that's solvable with atomic swaps. If you have an atomic swap to swap tokens, that's instantaneous. And that's what projects like connects do, for example. And there's problems like you have to have multiple fee tokens to bridge across chains. That's also very solvable. And that's like Skip is solving those problems. I think fundamentally, it's just that we're very early.
00:26:34.940 - 00:27:02.238, Speaker B: It's comparable to using the Internet in the. Was a very janky experience. You couldn't stream video, for example. You have to manually click connect and then do a dial up connection that takes like a minute to run. I think it's just a matter of being early, and I think the challenges will be solved.
00:27:02.414 - 00:27:17.366, Speaker A: Yeah, I tend to agree with that. And that's kind of a nice segue into the next line of questioning here. And do we have infrastructure to take questions from Mustafa from the audience if I kind of want to maybe leave like five minutes at the end or so for that.
00:27:17.548 - 00:27:19.560, Speaker B: Yeah. Raise your hand if you have any questions.
00:27:20.030 - 00:28:02.678, Speaker A: Yeah, we can make it a true fireside here. But one thing that I'd love to get your opinion on, Mustafa, is how we eventually end up bringing more app builders into the space. Because I think the thing that we all want to see is, especially in this next cycle, a couple of apps that really take product market fit and bring millions of people on chain. I think that's the goal here. And one theme that's come up many times is sort of this chicken and egg problem. In between apps and infrastructure, where we need good infrastructure to build good apps, but then the infrastructure also has to serve the apps that exist, and it's kind of like which comes first. So how do you kind of think about that problem and then maybe we can talk about how to bring more builders into the space.
00:28:02.844 - 00:28:54.662, Speaker B: Yeah, I mean, it's definitely like a complaint that people bring up that it's a valid observation that there's a lot more infrastructure projects. It seems like there's a lot more infrastructure projects right now than actual applications. And that might seem wrong, but I actually think that's kind of fine in theorem because fundamentally I think the reason why there's not a lot of web3 developers is just like. It's just that a lot of the things that seem easy to do with web3 is actually not possible to do because of various either scalability or execution environment challenges. For example, take the fact that people want to build Uber in web3. That's like a very stereotypical, classic thing. People say, oh yeah, why isn't Uber on web3? Theoretically it's possible.
00:28:54.662 - 00:29:40.760, Speaker B: It's just like all the tools are very janky. It's impossible to do on Ethereum. L1, no one's going to pay $20 for transaction fee. You need tooling to share location data in a decentralized way that tooling is being built. There's like lip PDP to kind of exchange messages in a decentralized way. Yeah, I just think it's just a matter. So I think it is actually a good idea that there's a lot of infrastructure projects out there to make the developer experience less janky and more practical to build the things that seem obvious in hindsight, like Uber for web3 but haven't been built.
00:29:42.730 - 00:30:18.914, Speaker A: Yeah, completely agree with that sentiment. I think maybe one thing I'd also love to, frankly just ask you, as the founder and developer of the Celestia ecosystem is like, what is the right way to do BD from your perspective? And there's a couple of different approaches you could take. Kind of like the bottoms up ecosystem approach that several blockchain ecosystems have employed successfully. And then there's a little bit more top down and actually asking people to incentivizing builders and apps to come onto the platform. How do you kind of think about building an ecosystem and doing BD within the context of web3?
00:30:19.112 - 00:31:42.810, Speaker B: Yeah, I think it really depends on what you're building. If you're building something that's fundamentally new and you're creating a new category and you're the only product that provides that, then you probably don't need to do as much direct BD, and a community will naturally form around that. But if you're doing something that's more competitive to things in an existing category, then your main differentiator will probably be having a better BD team. So I really think it depends on the product, and I see like roll up as a service providers doing a lot of BD to kind of attract roll up developers onto it and so on and so forth. But really, Celestia, we do have a large community of people naturally building oceles lesure, but we do have also BDT members trying to kind of help people and explain the technology. But the way I see it is that we're just trying to create a distributed community and we're trying to bootstrap a modular stack. We're very happy to have competing DA layers come and talk and kind of come to the summit, even though we're co organizing it, because ultimately, a modular stack is only credible if there's actually a free developers have choice in the stack.
00:31:42.810 - 00:31:48.960, Speaker B: People are only going to build if there's a lot of choice so that they know that they're not locked into a specific.
00:31:50.610 - 00:32:14.006, Speaker A: Understood. I think, folks, it's been really inspiring to watch what Celestia has done and what you guys have achieved over a relatively short amount of time. And I think one of the things that there's no shortage of love for in crypto is a little bit of drops of alpha. So what can folks expect from Celestia? Not revealing anything you can't, obviously, but what should people be looking out for over the coming months and year or so?
00:32:14.188 - 00:33:03.990, Speaker B: Yeah, I mean, the next milestone from here is mainnet, currently planned in the fall of this year. And that's kind of like what we're kind of like head down working on right now. We're trying to ship main net as soon as possible because there's a lot of people in the ecosystem that really need a DA layer, a scalable DA layer, and nothing exists right now. Soon we'll have eip four, four polygon available and so on and so forth. But there's literally no DA layer right now that's actually usable as a kind of a DA layer that provides more than like 10 throughput. So it's like that's a thing that we really need to unblock people on. We also have a lot of kind of like people joining the ecosystem and making announcements, integrating different parts of the stack.
00:33:03.990 - 00:33:26.586, Speaker B: Recently we had an integration with Opstack, where we provided a data availability interface with Opstack so people can deploy Opstack roll ups on Celestia, using Celestia as a DA and ethereum as a solemn layer. And I think we'll be seeing a lot more of that and a lot more integrations like that with other stacks.
00:33:26.778 - 00:33:51.160, Speaker A: Nice. I've got my last question here and then we can open it up to questions from the audience. But I'm always interested to hear from sort of leaders in this space, like the two things that you find yourself thinking about the most. Or maybe it's like a worry when you're falling asleep at night. Like, man, I really just want to make sure that we get this done. What are those maybe two things for you at the current moment?
00:33:53.290 - 00:35:19.410, Speaker B: Well, I guess from a very low level perspective, I'm very active on the engineering side of things, trying to make performance improvements when necessary. And I try to follow the developments, like people using celestia to see what the pain points and bottlenecks are with our testnets that we've done. But from a more high level perspective, one thing that I kind of think about is to what extent in the long term, as crypto goes mainstream, will users kind of care about how decentralized a blockchain is, or to what extent a blockchain kind of conforms with the core values of crypto, which is decentralization sensitive, resistant verifiability. Because fundamentally, from a user perspective, if someone just created a centralized blockchain with two validators, from user experience perspective, it's very similar experience. So I think about, one fear I have is the market will naturally just evolve to centralized solutions if users don't care. But so far we haven't seen that to too much of an extent. We haven't seen an overly centralized l one with ten validate a proof of authority that'll be a very low hanging fruit to build that could have like a billion TPS because it's not decentralized.
00:35:19.410 - 00:35:56.270, Speaker B: So I think about how communities or blockchains have social moat and users care about using applications that they know or they believe are actually decentralized and censorship resistance. But I think about to what extent that will hold true in the future because we're still very early. Crypto hasn't really a mainstream adoption. But I wonder, once we do reach mainstream adoption, if the ideals of crypto will ever become significantly diluted.
00:35:58.930 - 00:36:49.374, Speaker A: I've actually asked myself a similar question. One thing that the way I've sort of phrased it to myself, internally is, do you think there needs to be some sort of Overton window shift in order for people to adapt? So, for instance, privacy, I feel like this comes up often in privacy discussions. I mean, in web two, right? The one thing that's been proven after 20 some OD years is that users don't really care that much about their privacy. And most, the vast, vast majority, will not take even very basic steps to protect it. And how are you going to build privacy related infrastructure for people that simply do not demand or seem to value it with their actions almost at all? So do we need some kind of Overton window shift, from a societal standpoint, for some of these market structures to take place the way that we want, or what do you think about that?
00:36:49.492 - 00:37:14.710, Speaker B: Yeah, I mean, we've seen web two evolve in a very similar way. In the early days of the web, it was much more decentralized. People had their own blogs. They weren't sharing data with big tech. Now we have people just using Facebook, most of all using Facebook, sharing the data with everyone. But in web two, the interesting. Unfortunately, humanity is very reactive and not proactive.
00:37:14.710 - 00:38:01.874, Speaker B: Before 2011, most websites were just using HTTP. You would log into Facebook. This actually is something I saw when I was in my hacking days. The tunisian government was capturing people's logins to Facebook because Facebook did not have HTTP enabled or enforced on login page. But the thing that changed, the fundamental thing that changed, made people have a big push to encryption and encrypted messaging apps and htps and more privacy was when Snowden leaked their NSA files in 2011 or 2010. And that was kind of like a big moment where it was like a massive difference before and after. Before, nothing was encrypted.
00:38:01.874 - 00:38:46.570, Speaker B: Basically, no one cared about HTTPs. Like, all messaging apps were not encrypted. After that, everything started. Everything was basically encrypted by default. WhatsApp is now encrypted, everything uses htps. And there's been various scandals that actually has made web two privacy the forefront of many people's mind, like the Cambridge Analytica scandal. Facebook has a huge perception problem with privacy, and ultimately, unfortunately, I think it could end up similarly leading web3, right now, people don't care about financial privacy, but there probably will be decentralization to some extent.
00:38:46.570 - 00:39:13.180, Speaker B: But there probably will be a moment in the future where people learn that actually it's very important because there'll be that kind of like a Pearl harbor of financial transaction privacy in the web. Three, maybe someone is doing something very bad with all these on chain transactions like Archam analytics is one of them, for example, de anonymizing people based on their onchain activity, for example.
00:39:13.710 - 00:39:22.590, Speaker A: Yeah, I tend to agree with that. Guys, we're in the final minutes here and I want to open it up to the audience to see if they have anything that they want to ask. Mustafa.
00:39:28.790 - 00:40:34.030, Speaker B: Great. So there's a lot of DA solutions that are going to be live in the next year or two, which is really exciting. What do you think are the known unknowns around having these things live around scaling them? What do you think might potentially break and the kind of open questions around the design space here? Yeah, I think there's a few open questions. I think one of the biggest one is how do we get people to run light nodes? Because the way that, the only way to securely scale data availability is to having data availability sampling light nodes. And the more light nodes you have, the bigger the block size you can have. But historically, over the past decade we've had a model of web3 where people just interact with these centralized RPC endpoints, which kind of defeats the whole point of web3 anyway, because that's like a very web two model. You might as well just use web two because you're just interacting with a centralized database and trusting a trusted third party.
00:40:34.030 - 00:41:04.410, Speaker B: So I think we need to think about ways to get more people to run light nodes. Maybe by having. Mina is doing some great work on this. They have a browser version of their light node, so you can actually run the amina node in your browser. So I think that's a good first step. And then we need to figure out how to integrate these light nodes into wallets by default. So for example, instead of metamask connecting to infuria, metamask could run an in browser light node in the background and connect directly to the Ethereum peer to peer network.
00:41:04.410 - 00:41:15.230, Speaker B: And I think that's a very important known unknown that people should think about. Like how do we incentivize and get more people running wallets with light nodes?
00:41:18.850 - 00:41:48.810, Speaker C: Thanks for the talk. It was really enlightening to hear. So I think one difference between the last bear market and this one is the fragmentation of the ecosystem, that now we have so many different layer tools going on that historians might call this the l two wars that are going on now. So I was wondering if someone creating a DaP, how do you choose the right l two to build on? And what happens if the l two you've built on fails? You might be able to retrieve account balances, but can you retrieve transaction history, reputation, all of those other aspects.
00:41:49.230 - 00:42:37.322, Speaker B: Yeah, that's a good question. I would actually say that there's a lot of components in the modular stack. There's a lot of l two s. But I would actually say it's actually less fragmented than the previous bull markets because in the previous bull markets, it was way more fragmented because people were just building alternative layer one networks that did not collaborate with each other. At least with L2s, they can all coordinate with each other in the same stack. And one of the advantages, or what we're trying to achieve with modular stack, is that you can replace components in the stack. So if you deploy something using a specific type of.
00:42:37.322 - 00:43:28.790, Speaker B: If you deploy something on arbitrary roll up, and you could swap that out with the optimism roll up, for example, or you're not locked in to a specific vendor, that's like a very important component of the modular stack. I think that's more practical when you take into an example of roll up app chains, like if you want to develop a roll up app chain, let's say using the op stack, and you choose Celestia as a DA. If Celestia fails, you can replace that Celestia with a different DA layer very easily because there's a common DA interface. So I wouldn't necessarily say it's fragmentation. I would say that there's more freedom of choice. And sometimes that's not necessarily always a good thing. Sometimes there's too much choice, and that's very difficult for developers to compare the trade offs.
00:43:28.790 - 00:43:37.310, Speaker B: But that's also an open problem, which is how do we get developers to understand the trade offs between these different components and execution environments in the stack?
00:43:46.280 - 00:44:44.040, Speaker D: Thank you. Great talk, Mustafa and Mike, thank you so much for all the details. I love that you touched the business development area, and I think it's great that you guys have a dedicated team inside the protocol. I would say that probably many of the projects, at least at the start, may not have this. So I was wondering, what are some learnings that you see in terms of what works, what doesn't work in terms of business development, or maybe some advices that you would give to your builders and maybe what's your strategy? So you were saying that would depend on the product itself, but in particular case for celestia, as you are closer and closer to the main net, what would be some strategies for growing the ecosystem that you would want to explore?
00:44:44.620 - 00:45:50.540, Speaker B: Yeah, I think our kind of overall long term goal is to bootstrap a kind of self serving community. Ideally, we're trying to create a new category. So I think for any protocol, the success of any protocol should not depend on any kind of centralized BD team. Otherwise it's not really a decentralized protocol. And so that's why we've kind of tried to create a community, a modular community that can kind of have a mass or a network effect. And so if you think about other pieces of infrastructure with network effects, let's take AWS, for example. AWS has a massive community of developers and you don't need a centralized BD team of WS because it has a network effect where lots of APIs integrate.
00:45:50.540 - 00:46:33.530, Speaker B: So it's very easy to use AWS because it has wider community support. And so for Celestia and other DA layers, there's a very similar process there where we want to make sure that Celestia as a DA is supported by as many DA interfaces and roll up frameworks as know. We started with the Opstack integration. We want to have the community develop more integrations so that celestial will be like a default DA option for these roll up stacks. And eventually you have a community that kind of bootstraps itself and you don't need a centralized BD team to kind of push it forward. Just like Ethereum doesn't have a centralized BD team, for example.
00:46:34.700 - 00:46:43.670, Speaker A: Guys, I think unfortunately that is all the time that we have. Guys, everyone, give it up for Mustafa. First of all, excellent event, thank you for the chat, this was really great.

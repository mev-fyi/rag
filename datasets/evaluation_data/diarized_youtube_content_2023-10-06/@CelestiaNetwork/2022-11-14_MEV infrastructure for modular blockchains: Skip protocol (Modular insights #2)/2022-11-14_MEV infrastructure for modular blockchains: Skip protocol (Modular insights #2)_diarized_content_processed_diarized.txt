00:00:00.810 - 00:00:44.842, Speaker A: So just to give a little bit of background about skip and also a little bit about MeV. So I guess maybe to start like, what is MeV? MeV stands for maximal extractable value. Used to stand for minor extractable value. But now we don't have miners anymore, we have validators. And it's basically this concept of, there was a research paper a while ago called Flat Boyce which realized, oh, wow. If you could reorder the transactions within blockchain blocks, and you could insert more transactions and remove others, you could actually generate a lot of money. Right? So last year, the revenue amount captured on Ethereum in 2021 through MeV was roughly like $1.2
00:00:44.842 - 00:01:32.970, Speaker A: billion. And then across a lot of the other different roll ups, it almost added up to $2 billion. And the crazy thing about MeV is it's fully riskless. It's atomic capture of value. Meaning you see strategies like people borrowing $500 million of capital with nothing in their account, zero collateral in a flash loan, and then executing a series of arbitrages across different exchanges, and then repaying that flash loan all in a single atomic transaction. And because of that, because you have essentially infinite leverage on your capital, it does keep the market much more efficient and allows for many more people to come in and capture these opportunities. Some of the best MEB searchers I know are under 20 years old and started from their basements.
00:01:32.970 - 00:02:27.260, Speaker A: So it's a very interesting ecosystem, and it's something that I think is very new. Sort of this concept of reordering transactions and public information about mempools is sort of a playing field. It's something that you don't have in traditional finance. And if you did, would probably invite parties like John puts and river trading, Jane street, to sort know, get involved in front run people and sandwich people. And so that stuff is happening on blockchain. And the question is whether it's good, right? And which parts of it are good, like, which parts of it could be prevented, or whether it's all just how it is, and whether we should just create systems that at least try to control it in a way and give people the ability to compete for it in a way that sort of maximizes the revenue and upside for other parties involved. So when we came into cosmos, no one was really thinking about this as much.
00:02:27.260 - 00:03:34.914, Speaker A: We realized that there weren't any good mev solutions. And cosmos natively has first come, first serve mumples, right? So they're not ordered by gas, they're not ordered by tip, they're not ordered by anything. They're just ordered by sort of the order in which they were received. And so what this meant was to capture mev, people would spam mempools, like, as soon as they saw a transaction that created an arbitrage, they would submit a bunch afterwards, and I'll race to be the first to capture it. So what is Skip built? Skip is built the ability for sort of those same set of searchers to compete with one another, and also for the ability for individual app chains and individual validators to choose what kinds of mev that they want to allow. So, Skip is natively front run and sandwiching resistant, meaning when we receive a bundle, we ask that person submitting it to sign so that we can compare the signers of the submitter to the actual transactions within the bundle, and then we can say, this is obviously a front run, or this is a sandwich, or something like that. And then we give validators and in the future, app chains the ability to choose, okay, we don't want that.
00:03:34.914 - 00:04:44.070, Speaker A: We don't want to allow that, because not only is it harmful to the user, arguably, but it's also potentially, like, a source of regulation in the future. There's now discussion on flashbots about sort of regulators looking more closely into sort of this front running type system, which, of course, is not allowed because it's market manipulation in traditional markets. But that said, we give everyone the choice sort of, of what they want to allow, and we also give them the choice of how they want to split their rewards. So whether they want to keep it all, whether they want to send it to their stakers, whether the app chain wants to encode preferences that send some amount of the mev back to their liquidity providers, sort of split the rewards more fairly than everything goes to the validator. So how does this sort of fit into the potential celestia narrative? Or sort of like this idea of basically optimizing your mempool and creating your own mempool. So we've been thinking a lot about this idea of modular mempools. So just to share a little bit of a presentation, this is sort of like.
00:04:44.070 - 00:04:45.734, Speaker A: You guys can all see this, right?
00:04:45.852 - 00:04:48.518, Speaker B: Good. Yes, good to go.
00:04:48.684 - 00:05:54.346, Speaker A: So, like, in traditional tendermint based chains, you have this round robin approach where all validators have their own copy of a mempool, and then they all gossip to each other, right? So if I have a transaction that I got, I'll send it to you, and then you send it to this guy, and this sends to this guy. So roughly everyone sort of hopefully receives the same transactions, but they're all in different orders. And then eventually in a round robin style manner that's dependent upon how much stake you have. You get chosen as the proposer and then you just grab what you have in your mempool and then that's the block, right? And these mempools are very vanilla, right? They're just the order in which they were received and they're just regular transactions. Increasingly, what we've seen is the demand for something more than just like a regular first come, first serve mempool. The idea of something like a modular mempool, right? So you have potentially something like oracle transactions at the top that the chain wants to make sure that prices get updated because they feed into other parts of the protocol. So a good example of this was terra.
00:05:54.346 - 00:06:21.622, Speaker A: When it was alive, they had oracle transactions up top. They always sort of were there. They were inserted by the validator, by a side running process, and then those were used later on to decide the different prices of the various stable coins. Well, sort of a tough word to say now on terra. After that, you might want to have a section for meV, right? So this is the first transactions after the oracle transactions. Maybe everyone saw the Oracle updates. There's mev to be now.
00:06:21.622 - 00:06:27.154, Speaker A: You know, a lot of searchers want to rush in and that's where something like skip could come in handy.
00:06:27.202 - 00:06:27.462, Speaker B: Right?
00:06:27.516 - 00:07:04.770, Speaker A: So we could order those transactions. We could filter out sort of like harmful types of Mev if that was desired. And then we could also sort of create sort of the maximal outcome and then split those rewards to this validator or someone else. Maybe you want an order book for some period of that block or some amount of that block. Maybe you have your own sort of central limit order book model or protocol that you want to sort of interface with that section of the mempool. Maybe there's something for batch auctions if you want mev resistance. And then maybe after that you have regular transactions, right, that just come in from the RPC.
00:07:04.770 - 00:08:30.910, Speaker A: Maybe no one else can touch these. So it's kind of like an inclusion list. So that way if any of these other protocols were censorship resistant or OFAC compliant or, sorry, if they did censor and they were OFAC compliant, then maybe this is the validator or some other party that makes sure that the whole chain is not censored. I think this is a much more exciting model for how you can structure your mempools and these modules can be just slotted in, right? And you can have different protocols submit and compete over the space of each independent module. And these things aren't extremely hard, because you can sort of offer this within the app chain model, and also potentially in the celestial model, in terms of you can build these things, you can have people just easily design them, figure it out as part of sort of their protocol or chain wide plans, and sort of what works best with the protocol, and then you can just ship it to them out of the box. And then you can basically continue to have some kind of round robin type system where different validators or different parties have copies of this modular mempool. And then you can shift that copy around in various ways to make sure that it's not sort of like this centralized sequence or sequencer.
00:08:30.910 - 00:09:09.930, Speaker A: That's basically sort of what we've been chatting to Celestia about for a little while now. Modularity also, I think, comes down to the mempool layer. And I think in general, we've seen an explosion of interest in terms of Dydx has a very unique structured mempool. In the future, I think, say, for example, will have their own cordoned off version of their mempool, where some of it's MeV and some of it's Mev resistant. And I think in general, we'll see more and more of that. So, wanted to pause for any questions?
00:09:15.170 - 00:09:59.440, Speaker C: Yeah, I had a question, actually. I'm trying to understand where skip fits into the picture here. So this makes sense in terms of kind of providing this modular architecture on the mempool and kind of ordering and categorization of transactions. But that's kind of like node client logic, right? So it just kind of specifies which transactions fit into which bucket. But how does skip fit into that picture? Because from my understanding, that's just kind of, as I said, node client logic, some rules to kind of categorize these transactions and subsequently order them. So what does skip provide on this layer here?
00:10:00.210 - 00:11:34.430, Speaker A: Yeah, I think when you say node client logic, I think you can go deeper into that and saying whether this lives at the consensus or the application layer, traditionally, a lot of these solutions have lived at the consensus layer. So, for example, how we build BeV tendermint today, it's built into tendermint itself. I think in the future, these things can actually be built probably into the actual application layer, so that you can encode a lot of these different preferences and not sort of have out of band binaries that you have to run. And you could also encode minimum splits and things like that, where skip fits into the picture is we run all the simulation infrastructure and ordering infrastructure in order to conduct a healthy mev market. So any mempool that wants to take advantage of mev in any part of its modular architecture, Skip can build that section for them. So when the validator or when the node is building the sequence of transactions that are going to become the block, it can call out to skip and say, hey, what do you have for me, Mev wise? And then Skip can understand where it lives in the stack. Be like, okay, we're after the oracle transactions, or wherever that is, and say, well, these are like the top x bundles that we've already simulated and auctioned off that we can transmit to you, and then you can insert in that, and then that would probably result in the vast majority of the profit for that block.
00:11:37.090 - 00:12:31.310, Speaker C: Okay, cool, that makes sense. So, am I correct in thinking you're almost like an MEV expert service provider? So they can kind of specify they're building block x, and you will kind of suggest bundles and a collection of transactions which will satisfy or maximize the value for a particular block according to their rules. And I guess a follow on question to that is, how do you actually source the insights and the knowledge in terms of optimizing block construction? Because if you've got many chains, with each having their own kind of discrete application logic, how do you plan to account for the uniqueness of each kind of application's implementation and requirements?
00:12:32.290 - 00:12:42.478, Speaker A: Yeah, that's a great question. So we ourselves have a modular infrastructure, meaning a big part of MeV is simulation.
00:12:42.574 - 00:12:42.834, Speaker C: Right?
00:12:42.872 - 00:13:46.354, Speaker A: So when someone who wants to participate in the Skip MeV auction submits a bundle, we have to give them the promise that we'll only accept it if we can guarantee that we'll end up on the chain as valid. Which means we not only have to simulate it against chainstate, we also have to simulate it against the most recent proposal, and then we also have to simulate it against other bundles that have gone before it. And all those simulations are dependent upon the sort of individual, like you said, chain implementation of the cosmos SDK. But we have native deployments of skip on all these different chains that use the native stack and can perform that simulation. What's really cool on Celestia is we would have the ability also if we were to deploy in the future, to not only sort of simulate and transmit transactions on a single chain and sort of like chain by chain, but also to much more easily coordinate through the data availability layer.
00:13:46.402 - 00:13:46.758, Speaker C: Right?
00:13:46.844 - 00:14:31.400, Speaker A: So let's say you wanted to submit a cross chain bundle and you wanted an atomicity guarantee to say like, I only want this bundle to go through. If it executes on chain a and chain b, then we can sort of coordinate quite easily through sort of like shared state to say like, okay, these are both going to go through or neither of these are going to go through, instead of sort of just like one going through or the other going through. This is like one of the big unsolved problems of MeV is sort of this cross chain atomicity. But I think when you have shared data availability, it becomes a lot more accessible potentially. But as you said, that's correct. We have to update or we keep copies of chain state for each individual chain that we're deployed on and then we run the simulation on top of that.
00:14:33.530 - 00:14:35.400, Speaker C: Got it. Thank you for your answer.
00:14:36.170 - 00:14:37.080, Speaker A: Of course.
00:14:39.290 - 00:14:45.580, Speaker D: All right, so how do you actually enforce this modular mempool? Would someone literally be slashed if they don't comply with this?
00:14:49.390 - 00:15:38.650, Speaker A: You could do that. Right. So the idea of having this more at the application layer is you can sort of encode these preferences into the chain binary. So when consensus is happening, you can tell or validators all the different nodes will need to apply all the different transactions. And if those get processed differently because they use a different mempool architecture, then it would probably not result in the same chain state and so you'd be out of consensus. And then we're working on ways right now to actually encode the payment preferences as well as part of that. But I think in general these things are pretty easy to watch.
00:15:38.650 - 00:16:06.420, Speaker A: I think the weak way to do it is to look and see sort of how payments could be altered and if someone's defecting and then use governance to slash that. Or more strongly, you can try to have these within consensus so that if you don't actually pay out in sort of like the chain encoded preferences and everyone else did, then that defecting validator would be just out of consensus. Or if, I guess one third.
00:16:07.190 - 00:16:13.430, Speaker D: Yeah, I guess it requires all the mempools to be thanked before they try to all process a block.
00:16:17.410 - 00:16:52.220, Speaker A: In that situation, I don't know if it actually requires all the mempools to be synced. I think you can still have this architecture where there's a single proposer and then they make the proposal, and then it's more of a question of how do you process those transactions within the context of the mempool that you should have. Right. And to make sure if you've modified your mempool that the chain state once you apply the transactions in the proposal would be different.
00:16:54.750 - 00:16:55.354, Speaker B: Okay.
00:16:55.472 - 00:17:07.520, Speaker D: One other thing I was thinking about is, as far as returning MeV to the application layer, one option is basically the question is, what are the options there, and what are the trade offs that we should be thinking about?
00:17:09.010 - 00:17:14.500, Speaker A: So, like returning Mev, let's say, to parties outside of just validators, you're saying?
00:17:14.950 - 00:17:17.620, Speaker D: Yeah, like maybe the person who made the application.
00:17:18.150 - 00:17:18.466, Speaker A: Yeah.
00:17:18.488 - 00:17:21.490, Speaker D: So I guess that could be the same as the validator.
00:17:22.630 - 00:18:10.010, Speaker A: Yeah, it's a good question. I think it really depends on what your chain wants to encourage. Right. So if you're primarily a dex or your chain is all about sort of attracting liquidity, you might want to sort of dial up the amount of rewards that go back to lps. I think in the short run, validators usually don't need to be compensated that much because oftentimes they make bank in the beginning of chains off of high token rewards. But as that dials down, you might want to move. This is happening a lot in Solana right now, where validators are very unprofitable, at least for a very long period of time.
00:18:10.010 - 00:18:36.364, Speaker A: You might want to move that Mev towards the validator to make it sort of more financially sustainable for them. But in general, I think you can dial these metrics sort of according to sort of what the needs of the chain are. Maybe in the beginning it's all about user rewards and getting liquidity. I think later on it's more about paying for a long term security budget. Generally, these things have not been that explored.
00:18:36.412 - 00:18:36.672, Speaker C: Right.
00:18:36.726 - 00:19:24.810, Speaker A: The default, I think, on every chain that I've seen is all the money goes to the validator. And that makes sense for the validators, of course, and it makes it immensely profitable for them. But I think there should be experiments where we try to distribute MeV rewards more fairly to other participants as well. That is mostly sort of what I wanted to present on today. So any more questions, I can answer them. Otherwise, you guys are always feel free to contact us on Twitter or something like that.
00:19:26.220 - 00:20:06.040, Speaker C: Yeah, I have one more question, actually. So I'm trying to understand if Skip would be part of the consumer chains protocol, and would it be enforced that every validator has to use skip as a service, or would it be kind of opt in? Because you mentioned the potential of embedding this at the application layer, which would suggest now like a strong, kind of a strong dependency on skip in that case. So, yeah, I'm just trying to understand if it's opt in or if it's kind of enforced if your vision is to enforce this on the consumer chain, who's looking to leverage skip?
00:20:07.660 - 00:20:17.320, Speaker A: There's a variety of models you can go about this. So in general, like with MeV, you want to encourage competition between different parties.
00:20:17.400 - 00:20:17.692, Speaker C: Right?
00:20:17.746 - 00:20:58.564, Speaker A: So, for example, like, PBS took advantage of this. But I think the big question for us is, how do you encourage competition, and how do you decentralize and have a variety of builders without losing preferences? Right. So when you have, let's say, like 20 builders and they're all competing to build something, how do you judge them amongst themselves? Usually the answer is, let's just maximize profit at the expense of everything else and then choose the most profitable one. Right. Usually what that ends up sort of leading to is an ecosystem like on Ethereum, where MeV becomes no holds barred and you can't sort of encode the preferences that you want. That might be like reducing profit.
00:20:58.612 - 00:20:58.776, Speaker C: Right?
00:20:58.798 - 00:22:09.650, Speaker A: So, like, sandwiching accounts for a large percentage of MeV revenue on Ethereum. And so how do you keep all of those builders sort of on the same page, within the same rule set that the application wants to define for its users, while still sort of encouraging them to compete against each other on fair playing field? This is something that we're just now exploring in the future. We want to build systems that encourage a variety of builders and help build those systems, but also while having some kind of protection. So this sort of goes back to right now, we're working with the Cosmos SDK team to build, like an in protocol PBS module. It's not really PBS, but it basically is a much more preference setting module that allows for either the validator or the entire chain via the chain binary to sort of encode preferences of minimum payout balance to different parties, as well as in protocol run detection mechanisms for front running and things like that that can sort of reject individual bits if sort of people go outside of those bounds. But I would say this is generally an open question.
00:22:12.340 - 00:22:42.250, Speaker B: Got it. Cheers. Yeah, unless there are no other questions. Thank you, but I'll give it another few seconds just in case it's. Yeah, cool.
00:22:42.420 - 00:23:07.830, Speaker A: Thanks, everyone, for listening in. Basic idea, again, is just we should be able to give protocols the ability to design their mempools in a very easy, modular way and to make sure that there's, like, a variety of parties that can compete for each individual part. And mempool design space is generally something that I think is relatively unexplored. And if anyone's interested in this in the future, please reach out. Love to chat.
00:23:09.530 - 00:23:17.418, Speaker B: Thanks for the presentation. Yeah. Thank you so much. Thanks. See ya. Have a good one, everybody. Cheers.
00:23:17.418 - 00:23:20.380, Speaker B: Thank you. Thank you.

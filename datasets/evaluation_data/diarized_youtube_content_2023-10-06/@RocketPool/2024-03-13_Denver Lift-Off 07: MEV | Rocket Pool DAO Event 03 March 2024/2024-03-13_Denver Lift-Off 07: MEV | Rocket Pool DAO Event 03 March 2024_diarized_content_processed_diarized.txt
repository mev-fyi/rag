00:00:09.080 - 00:00:27.964, Speaker A: Hi there, folks. Let's see here. Can see where we met. All right, I'm yokum. I show up as non fungible yokum and discord. So I'm talking a little bit today about Mev and rocket pool and how we use relays. Say a couple things.
00:00:27.964 - 00:01:09.044, Speaker A: At first, I'm just be clear. I'm an Mev boost, or myself, or my node. I use relays, I build mev blocks. I have nothing against it personally, but I think we need to clear up a couple of things that I think maybe some folks don't quite always appreciate when it comes to Mev relays, is that, first of all, relays are trusted entities. And in crypto, trust is kind of a dirty word. Maybe it's underrated or it's too dirty, is the thought. But when we say relays are trusted entities, we're relying on their good faith, their goodwill, their care of their reputation.
00:01:09.044 - 00:01:53.230, Speaker A: To be honest, we have to worry about. There's nothing in the protocol that requires them to act in a certain way. We just have to accept that when we register with them and ask for blocks from them, that they'll do their part in good faith. And then the other thing is, relays are out of protocol entities. So, like, if you go and read the EF's announcement for the Denkun hard fork, there's a big listing of client releases for the execution layer and for the consensus layer, what versions you need to be on if you want to participate. Not listed in there is the release of MEV Boost that you also need. Right.
00:01:53.230 - 00:02:48.172, Speaker A: The core developers, they consider MEV boost to be an add on, something that gets plugged in on the side. It's not intended to be something like 90% of all blocks are built through MEV, but it's very much still an add on on the side. And so, background, why do we have relays and why do we trust them? And there's a little bit of history here. I'll stand here. Formalized MEV extraction kind of got started in late 2020, early 21. This is when arbitrage bots were ramping up gas prices, and they basically would win their bids by whoever was willing to pay the most gas. This was more or less kind of worked for them.
00:02:48.172 - 00:03:30.524, Speaker A: It was not fun for everyone else. If you remember that time, I have sad memories when I look at my wallet from that time, the gas that was spent, it wasn't all that great. Spring of 21, flashbots launched Mev Geth, which helped quite a bit on that front. On the gas front, because they basically set up with whitelisted mining pools, could run Mevgeth to build blocks. They could get bundles from flashbots and take a small spiff on that. But it was whitelisted and permissioned. So if you were a solo miner or you were a tiny mining pool that flashbots didn't want to work with, you were left out.
00:03:30.524 - 00:04:49.190, Speaker A: And that permissioned nature meant that when we're heading into the merge, we had to ask, okay, we're going to have all these solo stakers, we're going to have rocket pool, we're going to have all these other folks that want to be able to participate in Mev. How do we make that happen so that the merge broader. In the current architecture, we have validators, relayers, and builders implementing an out of protocol proposer builder separation. And the reasons why we have realized, and you want to trust them, is that block builders don't want to trust validators directly, especially permissionlessly. If a block builder wanted to just hand it off the block to a random validator, the validator could potentially just take the MEV from that block and rewrite the transactions for their own benefit and take the MEV. So the builders don't want to do that because they don't want to do the work for searching for MEV and then not earn the funds. Validators don't necessarily want to trust builders directly, because if they just signed a block header and handed it off to the builder, then there's no real guarantee that the builder would actually pay the validator for their participation in that.
00:04:49.190 - 00:05:36.688, Speaker A: And then if builders and validators do trust each other, it comes back to the same problem we had under proof of work, which was the builders and the validators would be highly permissioned. You'd have to be a really big staking pool or an exchange to be able to participate in MeV extraction and value collection. So relays entered the mix as a mutually trusted intermediary. That allows for permissionless participation from both sides. So any validators can participate on the relays and the builders can participate on any relay participate, and it's open ended on both sides. But the result is these relays are trusted entities. So it's worth asking ourselves if we're going to trust relays.
00:05:36.688 - 00:06:49.240, Speaker A: We should be asking ourselves, what exactly is the scope of the trust? What are we trusting them to do in particular? So the process, generally speaking, is relays start. They collect registration data from validators every epic, and we expect them to collect and verify the signatures in those registrations and then collect bids submitted by the builders. And there's hundreds of them per slot. You could have tens of builders, and each one sends in tens of bids over the course of a slot. And as they competitively bid to see who's going to offer the best bid at the time that the validator requests, the bid responds to the validator with the best bid at the time of the request. We're expecting that the relay is going to be honest about what the best bid is when they get that request. We don't really know because there's some timing games that can be played there, and then release the block to the network after receiving the signed beacon block from the validator.
00:06:49.240 - 00:07:51.436, Speaker A: Right. So when the validator signs the block header and hands it back to the relay with saying, yes, I accept this bid, we're just trusting that at this point, we have to trust that the relay will in fact release that block back out to the network and do so in a timely way. If it's too late, well, then the block can get orphaned. And then going on from that, we want to make sure that the validator gets paid to the correct bid so that the amount that was in the bid actually gets paid to the validators and to the correct fee recipient that the validator specified. We're trusting that that's honored. There's again, nothing in the protocol that guarantees that, other than we want to make sure that the relay wants to maintain their reputation and that everybody, if there's big problems, then it looks bad. Not stealing the builder's MeV opportunity, which is somewhat tricky because oftentimes relays run their own builders.
00:07:51.436 - 00:08:55.060, Speaker A: And so when a relay runs their own builders, there's going to be questions of are they really being honest with the builders and not taking opportunities from other builders that get submitted to the relay and then not lie or omit data in the data that they report. So relays have a big API that lists out what they've done historically, and I'll go into that later. But that data reporting is a big part of how we know relays, what relays are up to. So based on those trust assumptions and those trust expectations, it's worth asking ourselves, well, what can go wrong here? The wrong fee recipient could be put into the block. I'm aware of one instance of this in a rocket pool. It was shortly after the merge. The node operator had recently opted out of the smoothing pool and their fee recipient was properly set to their fee distributor.
00:08:55.060 - 00:09:42.660, Speaker A: But the relay had some caching implemented that had cached the smoothing pool address as the fee recipient. And so in that case, the block was paid to the wrong fee recipient. It's probably pretty rare, but it's entirely feasible for this to go wrong. The relay could fail to publish the block in a timely manner, and this happens more often than we'd like. But it's kind of tricky to know who's at fault here because the validator has a certain amount of time to respond to the relay and then the relay can only respond release the block if they get the signature in time. But it can open up some games where it's like who is really late here and who wasn't. The relay could allow registrations that don't have a valid signature.
00:09:42.660 - 00:10:56.200, Speaker A: So when you register every epic your validator, there's a validator signature that's included in that. In theory, those relays should be verifying those signatures to make sure that they are valid signatures for the content of that registration. It's unlikely, but it'd be cool if this is not outside the scope of my current project, but it probably needs some external monitoring and verification to hey, are these signatures in these registrations that the relays report? Are they valid? The relay could decide to hide higher bids to the validator and only give a low bar bid, low ball bid, in the hopes that the builders could potentially capture more of the MeV themselves. This really only happens if you're only using one relay, because if you're using more than one relay, the relays are competing against each other. So there's a pretty simple mitigation. But there's the potential that if you only end up using one or the builder, that there's one builder that's only bidding on one relay. The potential for low ball bids and timing games along with that could be played.
00:10:56.200 - 00:12:14.164, Speaker A: A relay could fail to report that they got a winning bid for a slot in their delivered payloads data. Talk about delivered payloads a little bit later. But that's part of their data API that like Beaconchan and etherscan use. When you look at a block to see, hey, which relay processed this block? There have been some instances in rocket pool where we've got the block has all the hallmarks of being built by a builder and processed through a relay, but no relay claims them, which asks some really kind of uncomfortable questions because it's like, how did this block get into the network? And so we think a little bit about what happened here and we got to ask because this is a problem for rocket pool operators, because we have a strict list of what relays are authorized, the team sets that list and we have to follow that list. And that if we don't know what relay delivered a block into the network, we don't know if the operator is in fact using an unauthorized relay or not. So it's potentially problematic. It's just this is a bit of missing data that we don't know quite what's happened here, really.
00:12:14.164 - 00:13:19.512, Speaker A: I could collude with a block builder or with their own in house builder to engage in theft and using some of the above methods here, again, it's hard to detect because, well, we trust the relays and we have to know that if they're doing that or not. It's a tricky thing. So how can we know if relays are being honest or not? Well, one thing we could do, and that helps, and this is the project I'm working on called Nev monitor, is we can watch and archive that data and then republish it to the world so that anyone can access it. We've seen a few instances when a relay shuts down, their data goes away. And so if we want to ever look back and historically and say hey gosh, what did this operator do when they built this block? And now we've got missing data. The goal of my project is to make sure that that data is captured and is made available in the future. And it's the core of.
00:13:19.512 - 00:13:56.550, Speaker A: I should have moved to the advanced, the slide ahead, but yeah, I want to make sure that data is available. I apologize. More delayed on this project than I'd like, but I'm hoping to have the initial beta availability next week. Still have to work out the auditing side of things to make sure. That part of my grant application was that I would have an auditing tool that randomly samples my data and pulls data that's available from the exchange and can compare. That's what the full release would look for. But I'm hoping end of next week I can have something to announce and show data and folks can go forth and do their own research.
00:13:56.550 - 00:14:44.084, Speaker A: That includes a lot of data from the relays that have shut down blocks route, ethical block native. I've got that data going back quite a ways. So what kind of data is going to be included in that? There's the delivered payloads again, the data that if a relay wins a bid, they report that in their API for that slot as hey, we won this slot. More than one relay can do that because the same builder could be biding the same block to the same multiple relays. So multiple relays could report it. The builder bids data, which is a quite voluminous amount of data, because it's the full history of bids for that slot from all the builders. And you can get a good sense of using that.
00:14:44.084 - 00:15:46.788, Speaker A: You could get a sense of what kind of timing issues are going on over the course of the slot, because as the builders bid, the bids increase. And then when the validator requests a block, it on average works out to about 90% of the value of the top bid. So we can look at those comparisons, we can see what the top bid was at the end of the day, and what actually got delivered to the validator. And then there's also validator registrations, and there's actually two different bits of that. You can query a particular validator address and find out, and the relay will respond one particular snapshot of the last time the validator's fee recipient or gas limit changed. And so oftentimes that's quite stale data. But if you query the registrations for every epic, it'll tell you what registrations the relay has for the current epic and the next epic.
00:15:46.788 - 00:16:36.520, Speaker A: But that's very time sensitive collection, because if you're not monitoring it, you only see it for the current and next epic. But once you have that, you can know, okay, you have a real time sense of which validators were registered against the relays for when they were slated to propose, not just stale data. That's basically the gist of the project I've been working on and hope to have the data available on. But I wanted to follow up about what MeV in the future of rocket pool looks like. Because, again, relays are trusted entities. They're out of protocol entities, yet we're really dependent on them. I think the figure is something around 20% of the total yield comes from MeV.
00:16:36.520 - 00:17:34.068, Speaker A: That's a big chunk of their income. So if we're moving into sublinear bonding, it enables a lot of leverage on the validator level. And that's great for our growth, because it means node operators can put in a relatively small amount of capital, and we can grow the protocol dramatically. Roughly speaking, you can get, it's about 20 x in the valid, 20 times relative to solo. So if you have 96 ETH, you can make three solo validators, or you can make roughly 60 validators under sublinear bonding. But the downside is this opens the risk that, like, okay, especially if we decide to drop the RPL collateral requirements, which I think currently acts as an aligning force among our current node operator group. We don't want to hurt our own bags because it would hurt our ETH holders.
00:17:34.068 - 00:18:19.640, Speaker A: But if we drop that, it opens the risk that professional MEV builders could come in, stake some of their ETH, and anytime they have a block opportunity, well, they could choose to not use a relay and just pocket the MEV and pay a nominal amount to the fee recipient. That's a real risk I think we have. If we allow that kind of leverage, it's not an impossible problem to solve. But if we don't do anything, it substantially hurts the re yield. And if that makes re uncompetitive, it draws down the demand that we need to grow. So that's kind of the risk that that shows. But we can manage that risk.
00:18:19.640 - 00:19:41.448, Speaker A: The obvious, simplest solution is, well, we just mandate all operators used authorized MEV relays and disallow self built blocks. Now, it's technically tricky to do that, because by default, the beacon chain clients, if you've set up relays and the relays don't respond, or they're down or they're not working properly, then by default, you should be falling back to building your own block based from your own execution node. All the infrastructure in the current design of this protocol is, of the actual protocol is there's this fallback process. There's even checks if there's a certain number of blocks in a row are missed, the clients decide, we're going to completely shut off MeV boost altogether. So if we want to go down that road of disallowing self built blocks, we have to introduce our own technical implementation to either. If something goes wrong, we could set things up to either just skip the blocks for our own operators, or we build empty blocks. So we can still advance consensus on the beacon chain, but the execution layer just, there's no transactions, and then the operator can be reasonably in a safe space to know they're not going to be penalized for building their own block.
00:19:41.448 - 00:20:50.040, Speaker A: And we still can move the chain forward. But that doesn't quite always look good, especially if we do grow as big as we want to. If we're 22% of the beacon chain and 22% of the validators. And then there's a big, huge issue with MeV, especially out of protocol MEV, and we're not bringing transactions in, or we choose to not propose at all, then that causes all kinds of grief in the network. And it takes us are we really as aligned with Ethereum as we hope we are? If we're going down that path, we should feel a little bit of discomfort on that. We've got a relatively simple solution, but it puts us at ODs with where we want to go or want to be. So there's an alternative, and I think Val referred to this earlier, we could require all operators to be actively registered to at least two relays.
00:20:50.040 - 00:21:38.024, Speaker A: That way we've got at least a competitive process between relays and then create a small network of other builders who are going to be the world's worst MEV searchers. They only look at public transactions in the mempool and they can each be using a different execution client. So we've got a bit of diversity in terms of what transactions could be viewed. They bid those blocks into the relays, they're never going to win the bids. But then we've got that those bids would show up in the bid data and then archive those blocks. And then we could still allow operators to build their own blocks. And then that way, if they do cheat or they are a professional searcher, well, ODs are.
00:21:38.024 - 00:22:22.006, Speaker A: They're not going to do it just for stuff they see in the mem pool. It's going to be stuff that they brought in privately. There's going to be transactions that didn't show up in the mem pool. There's going to be really high value stuff that's happened. Either a sandwich or a back run, something along those lines that, well, if we only see stuff that looks normal, then we can be reasonably guessed that the operator was honest and this was a small glitch. But if there's lots of high value stuff, well, then we have to ask ourselves some questions about is this operator potentially trying to steal MeV from the protocol, you know, you know, and if the valid. You know, it's the.
00:22:22.006 - 00:23:10.978, Speaker A: The high value operator, high value transactions observed, you know, and then we could subject penalties and exit and have that threat looming and have a credible enforcement mechanism. And then that credible enforcement mechanism leads to self policing. But to wrap up, we do need to be participating in MeV. It's a huge chunk of our revenue and it's what makes our ETH competitive. We can't just look at it the other way. But we need credible and judicious MEV enforcement. And incredible, as in, we know that operators know that the Odao is watching and that penalties will be coming if you do in fact try to steal MeV.
00:23:10.978 - 00:24:00.390, Speaker A: But it's got to be judicious and fair so that operators have a reasonably safe space to operate in to make sure that they're not going to get something outside of their control doesn't get them penalized, which is not fun. And we just need to keep sight of our overall values. With Ethereum, the fact is that MeV is still controversial. We all are happy to see the money, but oftentimes, every time a big block lands in the smoothing pool, we have to do a gut check. Gosh, was this the result of a hack? And then we have to question ourselves. God, how do we feel about taking this funds? It's never fun. So we do need to keep sight of our values and about what we want to.
00:24:00.390 - 00:24:09.340, Speaker A: As we try to grow, we have to make sure those values are still represented in that growth. Sorry, that was pretty quick, but thank you.
00:24:16.990 - 00:24:22.766, Speaker B: This time we're going to start with two questions from the discord. So the first one is, where is the data stored and how is it.
00:24:22.788 - 00:25:17.600, Speaker A: Backed up right now? So I've got the project right now. Initially, as I pull it in, it goes into a postgres database, and then there's a follow up process that re exports it into compiled json files that are compressed and that's in a raid volume. So I've got multiple disks on that. And then from there, once I start publishing it, it's going to be pushed up to. I'm pretty much close, this close to getting it set up to start syncing, runizing it to Cloudflare R two, and then generate an index file that makes it easy for people to download and download that themselves. Additional stuff I want to have is PGP signatures on the files so that it hasn't been tampered with after I posted it. My PGP key will be available for everyone and then folks can, if they want, to, verify that the files were from me.
00:25:17.600 - 00:25:32.450, Speaker A: And then it's just going to be, in general web two storage. If anyone has ideas on web three based stuff, I'd be happy to explore, but for now, it's efficient and cost effective just to put it onto Cloudflare.
00:25:33.590 - 00:25:40.150, Speaker B: Okay, great. And we have one more question from the discord here. Do you go back to the start of every relays operation?
00:25:41.370 - 00:26:19.940, Speaker A: Yes, for the most part I was able to get pretty much everything back to the merge. So I have not all relays, though. Not for all relays blocks route, for example, they prune their bid data about every million blocks. And I think when I started, it was like after slot 5 million that I was able to get for them. So most relays, they're very good about making that data available persistently. Blocks route is a little more aggressive about pruning it.
00:26:23.620 - 00:26:44.612, Speaker C: Wonderful discussion. Question is, how immediate existential is this risk, considering the EF seems to be trying to mitigate some of these risks themselves? How much onus is on rocket pool? Specifically regarding your thoughts on MEV burn, like the feasibility or lack of feasibility.
00:26:44.756 - 00:27:43.900, Speaker A: And mean, I'm of the opinion that MeV burn is harder than we mean. We already kind of see it, right? Mean, most of know we love being cowswap users, but all that matching off chain is MEV extraction in one way, right? It's not necessarily the validators don't get to capture it, the protocol doesn't get to capture it. It's already happening off chain. So how do we make sure that still ends up that MEV extraction still can get burned? So I'm pretty skeptical that MeV burn is going to be actually workable. It's an immense incentive to take that MEV extraction into a venue where it doesn't get burned, it gets pocketed. So I don't think that's quite the solution we're looking for. I think EPBs might help, but it removes the relays as a point of trust.
00:27:43.900 - 00:29:04.870, Speaker A: But then we still have to be in the position of instead of whitelisting relays, we whitelist builders that we're allowed to work with. And then that clears up some of the trust assumptions. But one thing we would be nice to have is like a common on chain reference for matching up with a validator pub key and what their expected fee recipient address is. And if that's common across protocols like a well known fee recipient contract, that if the withdrawal address of the validator is able to send a transaction to and say for these pub keys, use this fee recipient at that point, then if a wrong fee recipient is used, well then now there's an on chain reference to say hey, you should have used this and you didn't. Now we know where the problem is. That's one thing that could help, I think EPBs I'm a little leery of, because it tries to kind of hard code a little bit of what the existing arrangement is in terms of builders and validators, while trying to run that through some kind of a peer to peer protocol, that might help, I'm not sure.
00:29:06.840 - 00:29:15.810, Speaker B: Thank you so much jokum, for your wonderful talk. Guys, can you all give him a round of applause? And we're going to have 1 minute until the next talk starts. 1 minute. Can.

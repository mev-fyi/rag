00:00:08.570 - 00:00:47.322, Speaker A: Hey, good morning, everybody. Thanks, Pat, for the intro. As you said, I'm the senior solidity engineer for rocket pool. My primary role with rocket pool is to develop the smart contracts that power rocket pool. Another part of what I do, though, is research and development of ideas that will help the protocol grow and things like technical feasibility, testing of ideas presented by the community and driving them from sort of idea to implementation and deployment. Today I'm going to be talking about megapools. As Pat said.
00:00:47.322 - 00:01:44.540, Speaker A: Thank you. I prepared a research page on our research repository a couple of months ago. And yeah, I'm just going to go over what that idea is. Actually, before I get started, I just want to clarify from Grant's slides, it may have seemed like megapools were coming in Houston, but it's actually not coming in Houston. It'll hopefully be in another upgrade such as Saturn. So before I get into exactly how pools, the idea works, I just want to quickly go over the current situation and what the limitation and drawbacks of many pools are, specifically in the protocol. Anyone here running two or more mini pools will be acutely aware of some of the pain points that come out of the design.
00:01:44.540 - 00:02:38.430, Speaker A: So I'm going to talk about why we picked that design in the first place and what megapool is going to do in the future. So I'm not going to go into everything about rocket pool. I just wanted to focus on the main pools and the points that are specifically related to what megapools are going to help us fix. So most people probably know, but every single rocket pool validator on our protocol has its own smart contract deployed. So if a single node operator has 100 validators, that's 100 separate smart contracts, 100 separate deployments, 100 separate distributions if you want to distribute your rewards. The reason it's done this way, I'll go over in a minute. But we basically need every validator to have its own unique withdrawal credentials.
00:02:38.430 - 00:03:25.430, Speaker A: And I just want to also make this point about the Odao because I come back to it a bit later. But currently the Odao checks to make sure that the withdrawal credentials are correct on every deposit. And that's a trusted duty performed by our oracle Dow called a scrum check. Okay, so you might be thinking that single contract for every single validator is very inefficient and wasteful. And that's true. It was implemented this way simply out of necessity. There was no real better way to achieve the goals that we needed because there's no way natively to differentiate between capital and rewards chain.
00:03:25.430 - 00:03:55.160, Speaker A: So as I mentioned, it's very inefficient for these main reasons. Three reasons. Contract creation. They have recently built validator requires a deployment of a smart contract onto the EDM. Again, multiple distribution chain vaccines are required to distribute your gas, distribute your rewards. Sorry. And if you have not opted into automatic updates on the delegate, it also requires a single transaction to every single vehicle to upgrade it.
00:03:55.160 - 00:04:49.430, Speaker A: And we did improve a little bit in a previous upgrade to use a dual proxy design to minimize the gas for deployment. But at the present day, it still takes about 1.3 million gas to make a deposit and create a mini pool at this point. Um, yeah, so I made that mention about the distinction between rewards and capital. So the reason why we can't differentiate between the two is because on the beacon chains, just validators have a single balance. So it starts at the 32 E, 30 deposit and then it grows as the rewards accrue. Yeah, both of those, whether it's capital rewards, gets distributed to the validators, withdrawal credentials.
00:04:49.430 - 00:05:43.494, Speaker A: The exception to that is the execution layer, awards, tips and Mev. And that. So the problem is that if the mini will have a balance of 16 e, how do we know whether that was 16 ETH worth of accrued rewards over several years, or whether that was the validator being slashed down to 16? So in order to distinguish between these, we kind of make this assumption. We'll treat any balance less than eight e as rewards, and any balance equal to or greater than eight e as potentially capital. That's between eight and 32 capital. And this is a compromise which requires some additional safety measures as well. So, for example, the smart node doesn't let a meaningful get over one e, it automatically will start distributing it.
00:05:43.494 - 00:06:28.360, Speaker A: And that's because if it got close to eight east, then we potentially treated capital instead of what it actually is. Why do we even need to worry about the difference between rewards and capital? Well, mainly just because rewards are distributed with a commission involved, and on the final withdrawal, the capital that needs to be distributed proportionally without a commission. And if a node operator is slashed, then their bond is at risk first. So we need to handle those situations. Yeah. Quick summary. So every validator has its own medium contract and uses a withdrawal gradual address.
00:06:28.360 - 00:07:53.982, Speaker A: We're using the smart contract balance as sort of an inaccurate estimate of the state of the validator beacon chain, because we can't access that state at the moment. And it was done this way not because it's necessarily a great idea, but just because there's no other way to achieve that goal at the time and it's inefficient but necessary compromise. I just mentioned that the validator balancers and validator stake isn't available to us on the EVM, and that's where ERP four, seven, eight beacon block in the EVM comes into play. So it's a proposal and Ethereum improvement proposal by Alex Angza, Danny Martin my client, and commit to the hash tree group of each group block in the corresponding execution payload that will store each of these roots in a smart contract. So it's kind of pretty technically dense, but I'll just walk through what it does in it. And importantly it's included in the hard book, which is on hospital and mainet in well it might actually be this month, April, March. So the abstract is very short and dense of information, so I'll just explain the problem and what it's there to solve.
00:07:53.982 - 00:09:09.340, Speaker A: So currently the beacon state is completely separate from the execution layer state. So the validators statuses, balances and everything is totally in a separate cyborg into the execution layer where our smart contracts execute. That beacon state contains some information that we would like to have on the execution layer, such as the pub key balance status, et cetera. And there's presently no way natively to access that information on the beacon chain from the execution layer up until now, that is. The beacon state can be thought of as a giant data structure where each of the fields can either be additional objects or arrays, or you can think of it as a big tree. And if you take that in that tree, you can perform this process called localization on it, which results in just a single 32 byte hash rep saying the entire state, which it obviously doesn't contain, the entire state, it's just a cryptographic representation of that state. And that's what 4788 intends to put on the execution layer for us.
00:09:09.340 - 00:10:11.318, Speaker A: So there's kind of two parts to this ERP. The first step is that they extending the block headers to include parent beacon block. And then secondly, the more important side is that there's a contract deployed to the execution layer which allows other contracts to call it and query the past 8191 beacon block, which is approximately one day history. Just as a technical implementation point, you might notice that it's the beacon block route or the beacon state route, and that's just a technical reason for that. But it essentially means the same thing. We can access the beacon state route just through another layer of proof. So I'm just mentioning the proof, which is a cool feature of merkel trees, you can essentially prove the existence of certain data within the tree by providing a short proof back to the root.
00:10:11.318 - 00:11:07.040, Speaker A: So now that we getting four, seven, eight, we have this way to give the EVM access to the data that's on the beacon chain, and it can be verified in this sort of realm about asynchronous way. And so therefore we can trustlessly act on data from the beacon chain which is previously accessible to us. So, yeah, that was kind of a bit of a technical overview of that ERP. So why we care about this for rocket pool? Well, we no longer have to rely on this suboptimal solution of a separate mini pool. For every single validator, we can use state proofs to verify the actual validator balances and states instead of implying it based on the mini pool. And the entire process is trustless. So we don't have to rely on an oracle to perform that.
00:11:07.040 - 00:11:57.710, Speaker A: Yeah, so we don't need separate withdrawal credentials to keep track of all their balances separately. And that's where megapools come into play. So I just want to mention first of all, that this is still in like a research level. There's no governance proposal or anything like that at this point in time. So some of these ideas are kind of high level, but they'll get flushed out as we finish up in Houston and start working on our pips for further Saturn. So the high level idea of megapools is that we replace the individual meaningful contracts with a single per node operator smart contract. And all the validator withdrawal credentials for every single node operator will point to this one contract.
00:11:57.710 - 00:12:42.906, Speaker A: Instead of meaningful balances, we rely on state proofs to prove the state of the validator. And so it doesn't require any trusted oracle duties. It's fully trustless. And what needs significant gas reduction for distribution, multiple validators and a single contract deployment per node. So I'll just sort of walk through the idea now, which is all available in that research repository. So first step is there's a setup. So node operators must deploy megapool contract, which is a one time operation to set up the contract.
00:12:42.906 - 00:13:44.710, Speaker A: And it will have a similar gas cost to a current mini pool deploy, and we can just make it automatically done as part of the first deposit. One very unfortunate thing is that current medical will not be able to migrate to this medical system. It'll require a churn validator to do so, because there's no method to change withdrawal credentials from an existing zero x one withdrawal credential to a new one. The deposit process will be very similar to the current mini pool deposit process, except obviously we're not displaying a new contract. Every deposit, the node operating deposit is just directed to the megapool instead. And the megapool will have its own internal FICO queue of deposits so it can handle multiple at once. And then that megapool validator will enter the usual previously uni pool queue, but need to do no for that.
00:13:44.710 - 00:14:38.884, Speaker A: And then once they're assigned funds, once they get to the front of the queue, then they will submit a state proof proving that their validator withdrawal credentials are pointing to the correct megapool. So importantly here, that removes one of the ODA duties, the scrub duty that I mentioned earlier. But it doesn't really reduce the time that we have currently with the scrub jet because it takes eight or so hours for the deposit to appear in the state. So we're still going to have that waiting period. It's just not going to be oracle duty anymore. So it's a trustless thing that's done by the node operator instead. So there's the same situation that we currently have where the deposit hits the mini pool and then the node operator goes offline or something's broken and the department can't just sit there forever.
00:14:38.884 - 00:15:34.040, Speaker A: So we'll have a similar process for dissolution as well. And that dissolution just sends the egg back to the deposit pool to be assigned to another node operator. To avoid relying on the ODA for this, we could incentivize it so that other node operators can perform this action. If the original owning node operator doesn't respond in a timing fashion to exit a validator. Pretty similar again to start with. So the node operator will spit a voluntary exit message on the beacon chain. Smart node will then monitor blocks for rocket pool validator voluntary exits, and if it detects a voluntary exit of one of its own validators, then it again submits another state proof proving that the withdrawal exists in the recent block.
00:15:34.040 - 00:16:44.000, Speaker A: So if after some amount of time, just not strictly defined at this point, but after some amount of time, if the node operator who owns that validator doesn't submit that state proof, then another node operator will be able to submit it and they will be incentivized to do so after only a valid state proof. Sorry, once a valid state proof is submitted to the megapool, the megapool enters into this special withdrawing state, which I'll explain in a second. But first of all, I'll go over the withdrawing capital after you've exited. So once a validator has fully exited, there's going to be a corresponding withdrawal entry in the execution payload of a recent block. So again with another state proof. It's a common theme here, lots of state proof. We can provide the megapool with the exact withdrawable balance of the validator, and then we can perform the slashing if required, or the proportional distribution of capital if required.
00:16:44.000 - 00:17:57.508, Speaker A: Once all the validators as a part of that megapool exits this withdrawing state, then megapool exits that withdrawing state. So while megapool is in this special withdrawing state, you can no longer distribute rewards. So we're just waiting for the exit to happen and the capital to be returned to the smart contract. At that point, the distribution of rewards, this is the most simple part of it. So this is the biggest improvement that megapools sort of bring. So as long as the megapool isn't in a special withdrawing state where it's awaiting the capital to be returned from the beacon chain, you can just call distribute at any point, and the entire balance of the megapool is treated as rewards. So all consensus layer, rewards and execution layer for all the validators under a node can be sent to this one address, and that removes the need for the current distributor that we have at the moment, which distributes mev.
00:17:57.508 - 00:18:41.312, Speaker A: Of course, if you're opted into the smoothie pool, that's not true, but in the other case it is, and then all rewards. So consensus layer rewards, mev rewards, everything, all comes to this one contract, and it's distributed by a single call. And it would be a relatively cheap call to distribute all your rewards across all your validators. That's a massive improvement. I don't know how well you can see that, but it's just a diagram out of the research doc, just shows the process. There's a couple of sort of internal steps there. One of the things I want to point out is kind of introducing this new watcher role for node operators.
00:18:41.312 - 00:19:31.220, Speaker A: So as I mentioned, there's some situations where a node operator doesn't respond with a state group in time, and we need to incentivize another group of people to submit it if they fail to do so. So the proposal doesn't go deeply into the mechanics of that. Still, things we need to iron out, but there's obviously two ways that we can incentivize it. So the benefits from doing this, I think I mentioned it a few times, but it massively reduces the gas required to distribute multiple validators from the same node operator. It removes another ODA duty, which we love doing. Want to get rid of all of anything. So that gets rid of the scrub checking duty replaces it with the state proofs.
00:19:31.220 - 00:20:36.536, Speaker A: If distribution is so much easier now, you don't have to call 100 contracts. If you have 100 validators, then we can hopefully get node operators doing it more often. Because if you have a small amount of rewards across a number of validators, and it costs a certain amount of gas to call each distribute function, then you're going to wait until the balance gets to a level where it makes sense. But if all the rewards come into the same contract, then you're more likely to call it, because it's not giving away so much in gas. And what that will do is hopefully unlock some of the unproductive ETH and send it back to the deposit pool to become productive again. Not that we have a problem with deposit pool size at the moment, but still, it's nice to think about, and this last point is an interesting one. So if we have all of the state for all of validators in a single contract, it makes it easier for us to look into things like cross collateralization of mini pools, not mini pools anymore.
00:20:36.536 - 00:21:41.650, Speaker A: So currently each mini pool is kind of its own little silo of capital, and we're kind of limited to slashing per silo. Whereas if we put them all together, there's potential that we could reduce the bond as it's spread across the bond of multiple valets instead of just individual ones. So how does that translate to scaling? Said this megabolism is going to help us scale well, less friction for node operators, obviously an increased return for node operators. If you're not wasting all that money on gas, then obviously your return on investment is higher. And again, with that cross collateralization of bonds, we could look at lowering the fund even further. And I think megapools also work really well with some of the other proposals that are coming out at the moment, such as the ones in the rapid research incubator. So I think there's a lot of continuity between this idea and some of the ideas that are out there now.
00:21:41.650 - 00:22:19.724, Speaker A: So challenges at the moment, mostly technical in nature. So the usual things, such as actually implementing it. I do have a proof of concept, it's very basic. There's obviously a lot of work to be done before we even do that. Obviously we need to fully spec it out, and then implementation, testing, security audits, all that sort of stuff. I mentioned that I kind of glossed over the incentivization system for the watches, so that's something that needs to be flushed out a bit as well. And yeah, this one is interesting.
00:22:19.724 - 00:22:58.650, Speaker A: So the way Merkel proofs work. They're kind of linked to the structure. The verification process is linked to the structure of the object of the tree. So any changes, but some changes to the beacon state could actually invalidate the verification system. So that means we can't ossify the process. We need to be able to change it as ethereum adapts over time. So in every hard fork so far, except the Dampoon, they made changes to the beacon state.
00:22:58.650 - 00:23:24.176, Speaker A: So it's not an uncommon thing for them to do. So that's just something we have to be aware of. And then you're probably seeing vertical trees on the Ethereum roadmap. They're something that's probably coming in the future, but that would invalidate us as well. We'd have to redesign around it. So unfortunately, we're not going to be able to get rid of upgrading anytime soon, I don't think. But work is like that.
00:23:24.176 - 00:24:27.732, Speaker A: And I mentioned that there's no migration path possible, which is kind of a bummer for a lot of people. I don't really see a path forward there at the moment, unless something comes out of the woodworking. So when megapools, then, as I mentioned, it requires 4788, and that's in Cancun, which we know is imminent. We're wrapping up development on Houston at the moment, so final stages of audits and whatnot. Maya will talk more about that shortly. So we just need feedback from the research and design, finalize some of those hand wavy parts like the incentivization, produce a formal specification in RPIP, go through the governance process, then implementation on a testing, and then hopefully I'd like to see that potentially get into the Saturn upgrade, which is doing all in Houston. Okay, that's me.
00:24:27.732 - 00:24:40.644, Speaker A: I went a little bit quicker through that than I thought. Okay, so we're going to take some questions and I'm going to walk around.
00:24:40.682 - 00:24:43.484, Speaker B: The room with the two mics speaking the phone.
00:24:43.562 - 00:24:44.190, Speaker A: So.
00:24:45.120 - 00:24:50.030, Speaker B: Okay, we're going to go to Romana first.
00:24:51.040 - 00:24:52.028, Speaker A: Thank you.
00:24:52.194 - 00:24:53.870, Speaker B: I have a lot of questions, but.
00:24:56.640 - 00:25:33.240, Speaker C: I'll just ask them all and then you can answer the ones you want to with the existing mini pools. If you end up with eight e or more worth of rewards, what happens with that smart contract that has the beacon state roots? Is that like a pre compile or like, is that updated with. With gassy transactions or how does that work? Is there any reason to make the watchers operators as watchers? But why not just let anyone be them? And will migration to megapools be mandatory? Or are you imagining a state where you have a mix of mini pools and megapools.
00:25:33.580 - 00:25:57.970, Speaker A: Okay, so question one was 80 rewards. So if that happens, the 80s is treated as splash capital. So you will be, it will be treated as if you were splashed down to eight E. So that's why we have the smart node monitoring for the balance of the main pool. So it's only get over one e.
00:25:59.620 - 00:26:02.080, Speaker C: Next one was about the beacon state contract.
00:26:02.160 - 00:26:35.870, Speaker A: Yeah, that's a good one. So they're actually kind of doing it slightly different to previous approaches. There's this special contract that's deployed out of this address on the EVM, and then prior to the execution of transactions in that block. Part of the specifications for the Ethereum execution layer is that they have to call this function on this contract, which is kind of like a pre compile. It's kind of like one, but it's actually at an address. It's not pre compiled as well, but they normally start at zero, whereas this is just an address.
00:26:37.920 - 00:26:39.760, Speaker C: What shares could be anyone.
00:26:39.910 - 00:26:53.750, Speaker A: Yeah, so there's no reason there has to be node operators. It just makes sense because they're already running a smart node stack. If someone wanted to run the smart node stack without running rocket pools, then there's no specific reason why.
00:26:56.360 - 00:26:58.308, Speaker C: Mini pools and megapools at the same time.
00:26:58.394 - 00:27:37.810, Speaker A: Yes, it's up for discussion, obviously, but we obviously already have thousands of mini pools, so we can't just force everyone out and tell them to come back in. Also, it's really a benefit of their own, so it's kind of operators choice whether they want to upgrade. But that's very mini pools. But I think once they're deployed, no one can be upgrading pools because there's no real benefit to create many pools after the introduction. Okay, next question from the audience. Go up here.
00:27:41.540 - 00:28:00.600, Speaker B: I also have a few questions, but I wasn't smart enough to write them down, so I'll try and remember. Thank you for talking. How is this going to be changed with EIDP 72 51, which I believe is increasing the max effective balance? Is it really just doing what that is earlier?
00:28:01.500 - 00:28:14.430, Speaker A: Yes. So we'll need to make changes in response to that, but there's no specific hurdles that I can meet other than.
00:28:17.120 - 00:28:26.336, Speaker B: Okay, similar to that would rewards compound or it would be basically the same thing or would sit on till you get enough for eight and then do another one.
00:28:26.438 - 00:28:43.300, Speaker A: Yes. So it's similar to how it is now. The rewards will get chain into the payable contract and they're not automatically compounding there, but you have to distribute them out and deploy other people. It's not like an automated compounding.
00:28:43.720 - 00:29:04.830, Speaker B: Okay, and the last question is, let's say you're running 100 validators and you needed to. In order to go into the megapool, you said you'd have to exit and then restart a new one. Have you looked at, for a given gas price, how long it would take to break even on the saving and cost? Assuming that you're doing rocket sweep, which I use.
00:29:05.860 - 00:29:27.728, Speaker A: Right. No, I haven't done any looking at that because it does kind of depend on some of the implementation factors. So how much the distribute actually costs and how much the deploy actually costs without it being developed, I don't know what those numbers are in time, but it's something that we can certainly do once we get a bit of further events.
00:29:27.904 - 00:29:32.580, Speaker B: Thank you. Okay, next in the audience.
00:29:37.160 - 00:29:37.696, Speaker A: Sneaky.
00:29:37.728 - 00:29:38.710, Speaker B: Anyone online?
00:29:41.240 - 00:29:44.136, Speaker A: No? Jane.
00:29:44.168 - 00:29:44.684, Speaker B: Thanks a lot.
00:29:44.722 - 00:29:45.290, Speaker A: Okay, thank you, everyone.

00:00:00.360 - 00:00:01.713, Speaker A: Before we get started, we'd like to.
00:00:01.729 - 00:00:04.017, Speaker B: Thank our sponsors for making this event possible.
00:00:04.121 - 00:00:08.897, Speaker A: Special thanks to our platinum sponsor, olas. OLAS enables everyone to own a share.
00:00:08.921 - 00:00:14.377, Speaker B: Of AI, specifically autonomous agent economies. We're also excited to highlight our silver.
00:00:14.441 - 00:00:22.313, Speaker A: Sponsors near empowering Decentralized applications and blockchain ecosystems. Venice AI a private and uncensored alternative.
00:00:22.369 - 00:00:23.825, Speaker B: To popular AI apps.
00:00:23.945 - 00:00:37.125, Speaker A: Mira Unified AI infrastructure secured by crypto and the first on chain multi agent system. To learn more about all of our sponsors, check the description below and dive in. Enjoy the show.
00:00:51.585 - 00:01:20.383, Speaker C: Hey everyone. Welcome back to Delphi's Crypto AI Conference. I'm Tommy, I'm a founding partner at Delphi Ventures and I'm honored to host one of our keynote panels on decentralized versus centralized training. The training of AI models is a foundational bedrock for AI itself. And today we're going to discuss if decentralized training can actually beat decentrally trained models of OpenAI, anthropic perplexity and others. Today I have the best group of people I could find to be on this panel. I'm honored to have them.
00:01:20.383 - 00:01:32.457, Speaker C: I have Dylan from Noose Research, I have Ben Fielding from Jensen, I have Travis from Ambient, and I have Johannes from Prime Intellect. All leading projects in this sector. How's it going guys?
00:01:32.601 - 00:01:34.105, Speaker D: Good, it's great.
00:01:34.225 - 00:01:35.297, Speaker B: Good, Great.
00:01:35.441 - 00:02:00.301, Speaker C: Yeah, that was good to have you guys. I'm going to start off with an easy one. The first question I have is will we have an open source AI trained model through a decentralized network that is actually competitive with centralized models on a near NERF timeline that's actually useful? So will we have something decentralized, an open source model that's competitive with a centralized model on any near term timeline or is that not doable?
00:02:00.413 - 00:02:32.655, Speaker E: You are asking. These are four people that are dedicating their work right now to doing just that. So I think you're not going to have a very contentious answer here, but like resounding yes. I think if you look at, you know, the scale with which India has shipped H1 hundreds, if you with which GPT4 was trained, something like $500 million like open already marshall resources to that scale. So there's no doubt that you could harness that. And just like crypto doing for years in the past.
00:02:33.235 - 00:02:34.899, Speaker C: Ben, Travis, what do you guys think?
00:02:35.027 - 00:03:22.275, Speaker B: Obviously also a bit of a bias view, obviously working on that stuff. Right. But I take maybe a bit of the contrarian perspective that we are maybe not completely there yet. Right. It's not too contrarian to say hey, maybe there's still extra work needed obviously on the distributed training side from the research perspective to actually scale to the largest model sizes obviously as well on the engineering side, getting the fault tolerance to work to on ramping and off ramping of compute resources on a decentralized network and stuff like this. So yeah, I don't think we are necessarily there yet if we need the model sizes that are needed yet. Big Labs right now is also the question, right? We have been making great progress with just distilling other models, larger models and also just training smaller models on way more tokens.
00:03:22.275 - 00:03:39.899, Speaker B: Right. So that's one of the approaches we could go for. But then even beyond that, just pre training, we are also still lacking behind like some of the other techniques Big Labs have right now, right on the mid training, post training side, where we also need to make more progress to actually catch up in my opinion.
00:03:40.067 - 00:04:06.513, Speaker E: Travis, I remember you also doing some work on the inference side. I know that's not exactly what you were dedicated to at this time, but what do you think about the sort of progress that's been made lately towards maybe making a new trade off towards inference time compute versus where we thought maybe spend all your resources to the pre training and training side. Seems like that's a good setup for a decentralized network considering it's like a lesser load on Interconnect.
00:04:06.689 - 00:04:43.453, Speaker D: Totally. Well, Ambient's goal is to be the number one trusted provider of verified inference. So of course we love it when people use more tokens. That's great. And if it can improve the intelligence of some of these models that make the performance better in the near term, I think that's excellent. In terms of the question itself, I think there are probably a few different dimensions to it. One dimension is I think what Johannes was referring to, which is kind of the technical aspect, how good we are at the different phases of training.
00:04:43.453 - 00:05:20.177, Speaker D: And I agree that there's some work to be done. I guess what gives me a lot of optimism is that I think that all the techniques that we need are basically public domain at this point. These closed labs leak like a sieve. Meta has done a good job even recently of popularizing what I think would have been video training techniques that were just languished in the dark. So these things come into the light. Archive is always giving us insights into what's happening. And so I think that we have the ability to catch up on the technical side.
00:05:20.177 - 00:06:04.321, Speaker D: So that's aspect number one. Aspect number two I think is related to the economics of it. So of course, ambient takes a very particular view of that. We think that we're ultimately going to subsidize the training via the strong base that we earn with inference, with verified inference. So, you know, our thought is really start with a really great verified inference and then work into training a model, you know, three to five years from now. Our assumption is that Llama is going to be around for a while. So, you know, we start with something like llama 405 billion, and then when Zuckerberg rugs us all and keeps Llama to himself, we can actually train something on the network.
00:06:04.321 - 00:06:54.297, Speaker D: But I think that for all of us, getting the economics right is actually just as crucial as getting the technology right. And, you know, I think that the final component, which, you know, we might discuss later in the conversation, is really related to the regulatory environment. I think we had a near miss with this California bill recently that could have really created complications for everyone in the space. And so our ability to deliver a complex competitive open source model is somewhat path dependent on how that regulatory milieu evolves in the next several years. And I'm hoping that crypto AI can offer some significant lobbying to the good side of that.
00:06:54.451 - 00:06:56.277, Speaker C: Ben, I know you wanted to jump in.
00:06:56.461 - 00:08:19.055, Speaker A: Yeah, I just wanted to kind of almost riff a little bit on what Johannes said around slightly reframing the question a bit. So we're asking, will we have a decentralized model that's competitive with the centralized models? But I think there's high potential that that kind of idea of singular models starts to fade away towards the view of expert models. So rather than trying to create another large God model that can kind of compete with these existing centralized foundation models, actually there's a likelihood that the decentralized space just chips away and we get a kind of similar thing that happened with the Internet, where multiple kind of websites can exist that are specialized, they have specialized data, they put that out there and they kind of carve out their niche area in terms of human knowledge. I think we can see the exact same thing happening with machine learning where you just get these specialized models where for whatever reason some small organization has the ability to kind of carve out a niche with that model. You see it in kind of industry where machine learning is applied anywhere, where it's not like really using text. Yeah, you can hack it to kind of go via one of the foundation models, but actually just a smaller specialized model might be more appropriate. And I think what decentralization really gives us is the opportunity for a properly modular infrastructure where you could actually compose those models together.
00:08:19.055 - 00:09:07.367, Speaker A: And so if you do need to kind of bounce between different areas of expert knowledge, rather than trying to stuff all of that into one of these huge models and kind of put it up against all the other huge models, you can actually just compose that path in a similar way to a lot of the kind of research does internally anyway, and create a better outcome for that specific use case than you would get from this large meta model. The way I see those large meta models is just that they showed us what's possible, right? Like we just stuffed everything in one thing and we saw, hey, this is really effective, but it doesn't necessarily mean it's the kind of most effective thing going forward. I kind of view them as like a sledgehammer, where in fact, like in certain niche scenarios, you probably want a kind of a finer tool than the sledgehammer in reality. And we can build that in the decentralized space by creating that kind of much more modular ecosystem.
00:09:07.551 - 00:10:10.697, Speaker D: Actually, I actually agree in part and disagree in part. I think both are definitely needed and I totally am on the side of the composability because I think that's the future of the agentic economy. I do think there's always going to be a demand for strong generalist models, and I think that that has to do with the knowledge capabilities, reasoning capabilities and instruction following capabilities of those models. I mean, the reality is that some things you can get away with for, you know, when you're doing composability in terms of the latency, in terms of, you know, the security that you, you work with. Of course, each time you do another hop, you have another set of security problems. But some things are just a lot simpler with, I don't want to say a God model, but maybe an intelligent high schooler. And so I think that there's this balance between being able to solve the technical problem and being able to do so to meet the needs of different use cases conveniently.
00:10:10.697 - 00:10:45.737, Speaker D: And I think the different approaches strike the balance differently. I hope that they somewhat converge, but I really think you need both. And I guess the only other thing I would say is that I think it's really important for crypto AI not to cede the field on this one. I think that it's a big, bold statement that we need to make that we come out with a foundation model together as a community at some point that is competitive, because I think that's what keeps the interest in this field alive and keeps the field relevant.
00:10:45.921 - 00:11:11.275, Speaker A: I do agree with that existence of both Piece, I wonder maybe a question for everyone. The way I kind of see this is very much that's the interface, right? Like that kind of generalized model becomes the kind of interaction venue. And I think the value of that to me is in the personalization of that model. So it's just getting more and more context about you. What do you guys think? Do you think it is in that or actually is it just in it, having as much knowledge as possible?
00:11:11.425 - 00:12:12.997, Speaker E: Yeah, I would tend to agree with the way kind of Travis laid it out in that you need different things for different tasks. And there's plenty of tasks where it's okay to have like a very specialized nimble model. But yeah, for a lot of, you know, generalized interaction, you want to be talking to something that's intelligent. And the best way to do that, that we've seen so far is something that's gigantic and dense. And you know, I think crypto AI or open source AI, however you want to call it, does have that capability. And if we get into more of the idealistic stuff, which I'm sure we will at some point, which of those do you think is the most important to be decentralized? Like there's strong business cases for these open source, more nimble, more precise models like Ben was talking about. But if we're talking about the fate of humanity or this gigantic new change in the way that all labor and all things are done and there is a creation of something that's approaching something like superintelligence from an idealistic standpoint, I think kind of depends on us being able to compete on that larger, denser front.
00:12:13.181 - 00:12:58.735, Speaker B: Probably my perspective too also on we need a generalist model for a lot of things. Right. But yeah, don't deny the usage of specialist models, especially if they are in completely different domains like foundation model are not necessarily only important for natural language type interactions, but also for example, scientific foundation models which are at the moment, right now at least way smaller in size. Right. So one example there, we've recently trained like a 7 billion parameter model like scientific foundation model for metagenomics, which is actually a great use case for a distributed training run. Right. Where you could do it at scale already with the current approaches.
00:12:58.735 - 00:13:09.535, Speaker B: Yeah, over globally distributed GPUs. So yeah, for those kind of things already right now, yeah, decentralized networks could add a lot of value.
00:13:09.875 - 00:14:20.175, Speaker D: I think it's important to look at the models and the ecosystem as well. If you look at what OpenAI has released recently, for example, it's very much along the lines of the toolkit from Anthropic, where you have this canvas and you have an interaction pattern where you can progressively refine things. And so I think it's perhaps equally as important to build up a good set of decentralized apps that utilize the models effectively as it is to build the models themselves. I think that there really is an interface problem here that needs to be solved in order to make all of this very accessible. And I would even argue that much like we can get smarter models via inference tricks, having the model talk to itself, we can actually increase the perceived intelligence of models just with better interfaces. So I think that that's really important. And I also think that we shouldn't lose sight of the evergreen aspects of closed source models.
00:14:20.175 - 00:15:06.995, Speaker D: These guys are releasing models on something like a monthly cadence to keep the knowledge up to date and, you know, for a variety of use cases in the real world, I think that's important. So, you know, if you're looking at maintaining a plethora of models, that there comes a challenge there. You know, how do you keep all of those models somewhat current with the knowledge? Like if you're investing, investigating cancer and you want to have those models fine tuned on the latest papers, like, how do you keep the model current? You know, what's the process for that? What are the economics for that? And then, yeah, how you, how are you accessing, how are you accessing the knowledge in the models? I think those two things are really important and maybe not often thought about when we are looking just at the pure sexiness of the technology.
00:15:07.115 - 00:15:50.471, Speaker A: I think there's a really key piece in that, in that plethora of models piece that you mentioned, because we, in many ways we're going through the productization of these large models. And that productization highlights that we still think about the use case and the model as being kind of the same thing. So it's like, oh, I'm using Claude. My use case is just generic intelligence access and the model is just the same thing. But actually in reality that very quickly changes. If there's a way for them to provide a better experience for my use case by putting another model behind the scenes, and I don't really know, then obviously that will happen. And I think like you said, Travis, the natural progression there is to provide more modalities, provide more kind of better user experience, more of a kind of deeper product.
00:15:50.471 - 00:16:33.899, Speaker A: And behind the scenes, actually you get the typical stack of software that you get in any product where more and more gets added and different pathways get added. And actually this Idea of us interacting with a singular model starts to kind of shift a little bit. And behind the scenes there's more and more and more models. I guess I think about that just exploded out and you say, okay, well, in reality, in the kind of longer future, will it be just huge numbers of models and we're just constructing some kind of pathway through them all whenever we need to. If we need multiple modalities, we just link them together. Because right now I think if you want to fine tune a model to be multimodal, you're kind of doing this manual process of taking bits of models and essentially just sticking them together. But that's a very kind of automatable process.
00:16:33.899 - 00:16:42.375, Speaker A: We just haven't really defined the interfaces between each of the modalities yet to be just entirely automated. But I think it's inevitable that we will.
00:16:42.675 - 00:17:25.559, Speaker D: Yeah, I think I tend to agree about the composability part. I guess where I differ is I think it does come down to the economics. If we can find a way to devote the compute to running things in a scalable, secure fashion for a plethora of models, that's great and that'll work out. But if we can't, then we end up more in the one model world if we have to really focus our efforts on delivering that on the same cost basis. And I think that's the tricky part about this, because the economics have changed so much just in the last year or so. I don't know what the stat is. I think it's decreased.
00:17:25.559 - 00:18:04.931, Speaker D: The token per token cost has decreased something by 200 times. You know, it's, it's quite ridiculous. And so, you know, the open source world is competing with these ridiculous economics that are perhaps somewhat subsidized. I think OpenAI lost like $5 billion last year. And so the question is, how can we focus our limited decentralized resources on competing at a scale that is going to allow us to be cost competitive with those types of things. And you know, Ambien has a particular view on this, but I think that there are probably multiple ways to solve it. I just think that's the crucial issue.
00:18:05.123 - 00:18:49.909, Speaker E: I mean, I agree with you, but I think if you look at it like the economics that we're working with are fantastic. Like one I kind of touched on briefly. But we have resources to marshal. There is enough latent compute out there if you had the ability to harness it to be competitive. Even like at the centralized hyperscaler level, there's enough cash being diverted from even like, you know, name A crypto protocol like Bittensor marshals enough cash in a three month period to train something like you know, maybe at a scale of GPT4, just from a monetary perspective. So there's no doubt there's the resources to do it. Then when you look at like what does it cost, say like the open source community to use one of these things, it starts looking so much better.
00:18:49.909 - 00:19:32.727, Speaker E: Because when you're open AI or you're anthropic, you've got to squeeze all the juice out of that lemon in a little limited period of time. Like of course you're not throwing away everything about the model, but you are kind of obsoleting it, putting a new one to market, like you said, one that's got more information about the world, it's learned new things and sort of obsolete things. So you've got six to nine months to squeeze that lemon. For the open source community, none of us is expending that much CapEx, but we're all dealing with the same product, right? So for any one of us, on an individual level, maybe not on the global scale, but on an individualistic level, like any open source company taking advantage of one of these outputs has a much lower bar to clear to get their capex out of that.
00:19:32.911 - 00:20:08.285, Speaker C: Dylan, I think that was really helpful. I want to ask a question, sort of up this alley. I want to talk about basically what you're describing. The non altruistic reasons why everyone here wins, right? We've talked about why centralized AI is more money. We've talked about why they have more talent, more opex, they have, you know, multi billion dollar social media projects like obviously meta, Obviously we have OpenAI makes a ton of money on their revenue. They have money to spend, they have tons of investor money to use. So I'm trying to figure out how we beat their hard costs.
00:20:08.285 - 00:20:30.525, Speaker C: Like we all want open source AI, we don't want the world controlled by ChatGPT, but what are like the real reasons why we get there? And one last bit, Ben, you had a podcast a couple years or months ago where you mentioned adding all this latent compute and hardware is like adding more electricity to the grid, right? And I loved that metaphor way back when. I feel like that might be up this alley too.
00:20:30.645 - 00:21:11.509, Speaker E: I would push back just real quick before Ben, you talk about that analogy just on the talent and people aspect. I would push back hard on that. I just, there's a bunch of people open source just for the altruistic reason and I know that doesn't necessarily answer your Question. But there is a lot of talent that wants to work on open source products that maybe isn't getting that, you know, scratch itched in a centralized competitor. But beyond that there's just a bunch of talent that's able to contribute to the state of the art of AI. Unlike in many other fields, like people without your traditional pedigree are able to actually move the needle in open source AI. And these people are, you know, somewhat overlooked by the establishment.
00:21:11.509 - 00:21:38.315, Speaker E: Not totally like any kind of big institution is going to gravitate towards people with very great pedigrees. It's just the safe thing to do if you're hr like you don't everybody says, you know, they want somebody from the University of Poor and Hungary and smart or whatever it is, the Alan Greensberg quote. But the truth is it's just harder to hire those people and open source can tap into that especially if you give them the resources on something like a global compute network. So that's just like the talent piece I would push back on.
00:21:40.175 - 00:22:58.755, Speaker D: So I guess I think that it's a matter of comparative advantage and the incentives that that creates. So I think as something like the US gets an increasing advantage over other countries, they are going to have increasing incentives to pour resources into research. And the game theoretic approach that they're going to have to take is collaborative because no one of those countries is going to have enough resources to single handedly compete with the major well funded labs. And so I think that research ends up being in the open and I think it prevents, you know, this dynamic creates a sort of natural check on the ability of closed source to get way out ahead of things because you know, we're talking about the future of the economy. So you imagine that you're a smaller country or even a moderately sized country, you can't really afford to get behind the eight ball on this. So I imagine that as the resources get spent on these huge data centers here, there's going to be a proportion amount of resources that are going to RD in other countries.
00:22:59.335 - 00:24:00.929, Speaker B: I would love to touch on the point from Dylan on the talent side, which I totally agree with. Open source has the advantage of talent in a sense and it's the best example for bringing the open source community together and doing exciting research on top of those models. I think one thing we still have to prove on that side though is that we can actually pre train a model together and have this generalist model basically trained in that way. Basically open source has been great on doing anything on top of Those models once they came out, in a sense and just having a bunch of talent that actually explores different research directions. But the main monolith model that you train at the beginning, like a llama model, is more of a centralized effort so far. Right. Like I remember joining the Eluth AI Discord in 2020 and seeing a bunch of people trying to replicate GPT3 right at the time, which, yeah, they had some success with GPT J at the time.
00:24:00.929 - 00:24:22.911, Speaker B: Right. But they didn't actually, yeah, reproduce GPT3 the same performance. Right. And they had the difficulty that a lot of the people didn't want to do the tasks nobody else want to do, like cleaning data and stuff like this. Right. So I think we need the incentive side there too, right. To actually have people work on those aspects.
00:24:22.911 - 00:24:30.127, Speaker B: And then I think open source AI can shine there. Right. Even on the efforts that are more often.
00:24:30.271 - 00:25:28.085, Speaker D: Just one other thing, you know, I guess I would say that I think there's some real indications that the centralized approach is wrong actually from a technical standpoint. Like if you read the llama paper, or misguided perhaps might be a better word if you read the llama paper. You know, they talk about essentially having brownouts on their network due to the spin up costs of loading checkpoints. They have, you know, more than 300 major failures in their training runs that they need to that cause complete restarts and they have tons of backtracking. And I think that that actually speaks to the impracticality of the concept. Like maybe it's not such a great idea to just have a monolithic data center and be focusing these incredible amounts of resources all in the same place all at the same time. Like maybe that's just not a good idea from an architectural standpoint.
00:25:28.085 - 00:25:50.745, Speaker D: And when you talk about Microsoft spinning up the Three Mile island nuclear plant again in order to power a data center, you just start to question it, right? Do we really need to go to this extent to get the performance we need or actually can we just use a more efficient approach and architecture to achieve something similar?
00:25:51.485 - 00:27:10.297, Speaker A: I think about this very much in that efficiency realm where open source and the kind of the work I guess we're all doing in decentralizing resources is essentially a kind of long term attempt to make the most globally efficient access to those resources, including human effort and knowledge, which is where open source comes in. You see kind of open source as it basically a resource network of humans. And then you can have a resource network over compute and you can have a resource network over data, etcetera but connecting up the entire kind of planet and soon beyond state of those resources allows you to apply optimization techniques against the entire planet's resources, where, say, Microsoft, sure, they might be doing a very good job at making their data centers incredibly efficient, but they're locally efficient for Microsoft, they're not necessarily globally efficient. You can make the argument that capitalism applies a kind of efficiency mechanism on top of that, and eventually it rolls up to globally efficient. But I think going direct to each of the resources is highly likely to be more globally efficient. And then it just becomes this really kind of interesting massive optimization problem. Essentially, you've got access to levers for every single resource, and you can kind of pull those levers collectively as humanity, and you're able to find and essentially search for the most efficient usage of it.
00:27:10.297 - 00:28:04.635, Speaker A: I think that's super important when you zoom further, further out into the future and you can model the Internet as the last big attempt for humanity to make basically a shared knowledge base, like all of our digital knowledge is collected between our devices and we can just communicate between them all. Machine learning in many ways can just be seen as a new, more efficient data type for that exact same thing. And so if we are going to create this enormous shared knowledge base for humanity, do we want it to be locally optimal to how Microsoft does it, or do we want it to be globally optimal over all of our resources? Like the planet is finite, we kind of think very hard about how we can optimize our resource usage. I think just giving direct access to the levers to do that is likely the most efficient way overall to do it. And you create markets for each of those resources rather than having this kind of step down where people are able to capture value from it and make it less efficient on the way down.
00:28:05.135 - 00:29:29.559, Speaker D: Actually, I actually want to riff off of that, but on a political dimension, you know, I think that you could, you could think of these models as future governance mechanisms. Maybe not directly political, but certainly economic, you know, economic power centers. And I think people are increasingly going to ask the question about whether we want those to be controlled by singular entities, because it really gives those entities the opportunity to put their thumb on the economic scales, you know, be they governments or, you know, corporations. And I think that, you know, even at the corporate level, companies are going to find that intolerable. But then the question is, how do you access, you know, decentralized infrastructure that provides an equivalent experience, you know, privacy guarantees, you know, good economics and so forth. And I think if we can, if we can get the infrastructure in place and get some early adopters, that that's actually a pretty easy sell because I don't think that anyone wants the dominant paradigm to be one in which we're all renting models for Microsoft, you know, I think that that's value extractive for a lot of players and they would view that as a threat to their business. So, you know, I think that it's a little bit of a dodge.
00:29:29.559 - 00:29:52.915, Speaker D: You know, why is this a reason to believe that a decentralized AI will, you know, training in particular become successful? But I think that actually the will to support such and create such is going to be increasing in proportion to the amount of economic dominance that these models have in our daily lives. So I think that's a reason to be optimistic.
00:29:54.005 - 00:30:51.211, Speaker E: Yeah, and I mean, the work that, you know, a lot of us are doing, distro, essentially, like the stuff that you all are working in, Deloco, et cetera, like that should make structurally cheaper training, right? Like, maybe not, you know, for the altruistic people out there, but for the whole globe. But, you know, Interconnect is expensive. Buying new land to house a hundred thousand GPUs is expensive. Setting up cooling to accommodate such a setup is expensive. Like, if you could just eliminate that and work with what we have and string together super clusters via the means that we've already spent money into how much capex will be saved over the next 10 years by doing so. How much money is going to be spent next year by Amazon alone setting up new GPU data centers? 5, 10 more, hundreds of billions of dollars. So the work itself will be extremely, you know, beneficial to the capital expenditure side of this thing and making training structurally cheaper.
00:30:51.211 - 00:31:20.171, Speaker E: But then we come back to sort of like Travis and Johannes's point about layering in the right incentives so it's not captured, just. I mean, it's beneficial to centralized players too, right. If Microsoft can string together every data center they have stood up, they likewise benefit. The cool part is though, they already have somewhat of an access to this, like our communities don't. So, you know, we've leveled the playing field at least, right? Somewhat. We still have to do things like activate latent compute, like what Ben was saying. And I think there's a lot of ways to do that.
00:31:20.171 - 00:31:44.875, Speaker E: I think we've experimented a little bit with distro as to how tolerant it is to nodes dropping in and out during runs, and it turns out it is pretty flexible. And then you start getting those economics that Ben was talking about about, you know, what Is this compute doing? Otherwise, what do you have to pay for it to be, you know, directed to your problem? Course it doesn't solve all the problems Travis touched on like data security and you know, the whole nine years. But it's definitely a step in the right direction.
00:31:45.575 - 00:32:29.537, Speaker C: I wanted to talk a little bit about what has happened in the decentralized training world recently that has given you guys so much confidence, right? I mean, the Distro paper was released like 800 to 3,000 times less communication between nodes for training. Johannes, you guys at prime intellect did a 1.1 billion parameter training run across. I think it was three nodes. I know you mentioned at the start of the podcast you're up to, I think it was a 7B model. Travis and Ben, you guys have breakthroughs in your own rights to share, but are these breakthroughs enough because centralized AI companies have breakthroughs all the time, or are these big enough that it's really gotten you guys excited?
00:32:29.641 - 00:33:16.345, Speaker A: I think there's a trend, I think that's what the most kind of interesting thing is, where as a space focus on these more distributed models has just been slow up until very recently. And you look at the work that people are doing now and a lot of it, particularly in the purely data parallel sense, goes back to federated learning techniques from 2017. Essentially there's not. There's been a sudden huge influx. It's actually more like the space is almost discovering itself. And I think one of the things we find particularly interesting is just the increase in kind of acceleration of new papers in this area as people start to realize the benefits and the reasons why we want to do this. You get covering that ground that we've covered before, maybe in a different arena, but also applying it even wider.
00:33:16.345 - 00:33:46.595, Speaker A: So rather than just data parallel, you do Tensor parallel and pipeline and you do optimizations over the top of those and you've got papers like Flash, Flex and Metis and Alpa and things all sort of looking at doing it wider. And I think it's just interesting to see the flurry happen. It gives me just that kind of feeling that we've left this almost unexplored for quite a long time. And once you actually start to get people focusing on it, there's a lot of low hanging fruit to be had. And the results so far are very encouraging.
00:33:47.895 - 00:34:35.005, Speaker D: I would riff on that and say that I think all these techniques are coming out and probably a lot of us see them stacking on top of each other. There are a lot of different theories that are converging on ways to optimize and they seem to be synergistic with each other. So if we track that progress curve, I think all of us are probably reasonably optimistic that these different research tracks layered on top of each other are going to result in something that's actually incredibly efficient compared to where we're at now. That's, I think, the hardening thing. And as Ben said, people are rediscovering aspects of all of these things that we kind of knew about and they're combining them in new ways to get even greater benefits.
00:34:35.665 - 00:35:11.673, Speaker E: Yeah. And I would say another reason to be optimistic is there's no reason why this problem shouldn't be extremely well suited for distributed, decentralized systems. It's an extremely parallel, you know, problem that we're solving. And to go back to what they're both saying is like, we've always sort of like, we knew we could do this in parallel. Right. Like that was the genesis of data parallelism was like, we can do this problem if we just distribute it amongst, you know, however many GPUs. Then the problem became okay, but then how do they communicate? So the solution was like, let's just plug them into each other and give them fire hoses to spew stuff to each other.
00:35:11.673 - 00:35:27.205, Speaker E: And everyone's like, yeah, that works really well. Let's sprint at that. And so that's what we've all been doing. But like we all said, it's fundamentally a very parallelizable problem. And that means that we can all be optimistic for further solutions to reduce other things that we've put on as bandaids.
00:35:27.785 - 00:36:02.929, Speaker D: I would throw in a little bit of a curveball and say that I think that closed sourced AI advances actually help all of us process more information faster and better and further accelerate the open source progress. I know that, you know, I've become sort of inhuman at reading archive papers. I'm sure all of you are doing the same thing where you're just covering a lot more ground than you used to and being able to interrogate research in a way that you never were before. So I actually think that the better closed source gets, the better off we are.
00:36:03.057 - 00:36:09.645, Speaker C: Yeah. I need to stop sending Travis white papers to review for our ventures division as a technical check so he could read more AI papers.
00:36:11.015 - 00:36:13.167, Speaker D: I'm Travis is the new Claude.
00:36:13.311 - 00:36:41.883, Speaker C: What is everyone's North Star OpenAI is focused on creating AGI. Perplexity is focused on creating a research assistant that goes away and comes back and does the work for you. Claude is focused on being a non dramatic version of OpenAI I found what is everybody's North Star here. On what you're creating, do you have a view on what you want to create as your end product or are you sort of are we in the infrastage and you know, we're not there yet.
00:36:42.059 - 00:37:22.989, Speaker A: So I think I have a bit of a cheat answer to this, which is the way we see it, we're building the network from machine intelligence. So the place where machine intelligence can flourish with that absolutely optimal usage of the world's resources. So the most efficient kind of set of layers that exist over all of the base things that allow machine learning to happen. So in many ways it is just a cheat answer because it's infrastructure essentially. But I think that is the product. And realistically the most effective machine learning models in the world will be a product of as much human effort as possible. So I don't think one company should be the company that builds the best model.
00:37:22.989 - 00:38:06.365, Speaker A: I think what we need to do is realistically build infrastructure to allow machine learning to organically evolve over the planet in the absolutely most optimal way for humanity. And that just involves like giving as many people as possible access to the tools to do it. You've also got that coordination piece as well there where you say maybe a hyper central, like a centralized model or a centrally connected model is the most optimal model, in which case you need somewhere for people to rally. Like all those people can access the resources, but how are they kind of like plugging them all together towards the same goal, the same objective function and you kind of need something that allows them to do that is composable and things. But yeah, cheat answer, infrastructure, but towards optimal machine learning for humanity.
00:38:06.665 - 00:39:21.905, Speaker D: Well, I guess Ambient has a very specific objective in mind and it's in the name we'd like to make universally accessible, highly intelligent. A universally accessible, highly intelligent model that becomes part of the foundation for the agentic economy. We believe that in an agentic economy you need a model that is objective, unbiased, uncensored, that a model that's designed like that is not only smarter, but it can also serve the purpose that it needs to. In such an economy, people need to be able to do things like trust that long tail prediction markets can be set up by an AI. They need to be able to believe that an AI can objectively negotiate on their behalf. And to support that we need to deliberately create it. The models that are coming out are the opposite of that.
00:39:21.905 - 00:40:09.965, Speaker D: Of course, we're starting with llama ourselves, but even that one it's very difficult to work with some of the refusals. If you try to do financial analysis with these models, you're looking at a 40% refusal rate. This isn't biochemistry. This is something very basic that a lot of people want to do. Ambient believes that we can do better, we have to do better. And we need to provide an equivalent level of intelligence to closed source in order to be competitive with it on the general tasks that people want to utilize such a model for. And so that's our North Star is to make that generally available, highly intelligent model that's cost competitive with closed source.
00:40:10.135 - 00:40:37.355, Speaker B: Nice. I think maybe to jump in here from our side, basically. I think obviously beyond all the infrastructure engineering challenges we are working on as part of the open Source AI research initiative, we have the North Das should still be AGI in a sense. Right. We want to go there. We want to have scientific progress for AGI, obviously. We want to have, yeah, productive output and stuff like this.
00:40:37.355 - 00:41:06.051, Speaker B: Right. So I think that's what the research aspects we're going to focus on, which are not too different from the big slabs in a sense. Right. And we see different areas where we need to catch up, right. Like obviously on having access to large scale compute resources with actually enabling distributed training across globally distributed GPUs. The other one is like we need to catch up on the large scale synthetic data generation side. Right.
00:41:06.051 - 00:41:29.139, Speaker B: Like OpenAI is supposed to train their GPT5 model and 50 trillion tokens of synthetic data generated content. Right. Open source AI doesn't have like even 1 trillion token data set. Right. To actually catch up there. Right. And also obviously all the inference time compute approaches that are popping up right now, we don't see much on the open source side yet either.
00:41:29.139 - 00:41:36.599, Speaker B: So yeah, we're looking forward to more projects and more experimentation there too, I would say.
00:41:36.647 - 00:42:07.779, Speaker E: Noose's North Star has always been making sure AGI or whatever we want to call it is individualistic and humanistic. Just making sure it's not serving the interests of something specific. That is not quite the humanistic approach. And it touches on what Travis was saying. It's odd that you get refusals for doing things that aren't creating a pipe bomb. They're not like teaching kids how to make meth or whatever. Right.
00:42:07.779 - 00:42:45.581, Speaker E: Like you just want a model that does what you want to do. And the wrong approach is to just hammer in these behaviors into the model. Like this is sort of what the philosophy behind Hermes was like. That's not the way to do it. Because when you do that, you start getting refusals for ordinary tasks. And these centralized companies, whatever their intentions, may be not potentially evil people, but they're subject to this whole body of legislation and shareholders and all these people that they need to make sure that, okay, if this thing starts spouting off racist, it's going to reflect poorly on our stock price, et cetera. So we really got to hammer this in, but it's not the right way to do it.
00:42:45.581 - 00:43:30.747, Speaker E: The right way to do it, we thought, was to do something that convinces the model to role play as whatever you want it to be. So the thing with Hermes 3 is it's trained on a bunch of role playing data, like literally gaming role playing data. And when you tell that model like, hey, I want you to be a non racist, very helpful assistant, it's happy to do that. Or if you tell the model like, you know, basically the guardrails that you want to put on it so that it aligns to you, it's happy to do that. So that's kind of like the culture that we've tried to have at Noose is like, what do we have to do to. Models are not captured serving interests that are maybe antithetical to what we all need. And then you can see distra as sort of an extension of that.
00:43:30.747 - 00:43:54.665, Speaker E: The thought experiment was like, what if duck pulls the rug? Like, I forget what should. You said it. But what if Zuck just decides like, this is not the way to do business anymore. We're not doing it. We kind of thought like, okay, we need an alternative. We need base models, we need the infrastructure, to Ben's point, we need the infrastructure for people to continue contributing to intelligence. That doesn't make us captive or beholden to a select few.
00:43:54.785 - 00:44:49.913, Speaker C: I have a follow up question for everyone here. It's, I think it's very hard for people, or even for me, to contextualize the power of open source AI models with, with crypto and with crypto incentives, right? Like early in crypto's life, everyone said, oh, you know, we don't need this. We have TradFi, we have Stripe, we have Wall street, we can do capital raising, we can do incentives. But as time passed, it became very clear that having Hayden in his bedroom creating Uniswap in a night or two, however long it took, was really important. And that spurred defi and that spurred apps and L1s and L2s and scaling and an entire ecosystem. Right? Could you guys maybe just help contextualize for the listeners the power and the opportunity of having Open source AI models in crypto with crypto apps. And like, what does that mean from the user experience, from capabilities, what do we get?
00:44:50.049 - 00:45:41.833, Speaker A: Just from my side thinking about just competition dynamics in the market, right where you look at the typical path of a company taking on a niche, there's an incumbent in that niche, they come up with some kind of nascent way of addressing it and then they kind of disrupt that company and then they're now successful as a company in that niche. The incentive for them then is to maintain that success and essentially become a monopoly. And a lot of the time the way to do that isn't necessarily in the interests of the consumer of that company's actual products. It's in capturing something else. And we've talked loads about how you can do this on resources and things. And regulation is one way that you can capture value in a product and create a monopoly. But fundamentally what's happening is a misalignment between the demands of a consumer and the incentive of the company.
00:45:41.833 - 00:46:43.095, Speaker A: Basically the company isn't incentivized to create the best experience, it's incentivized to maintain its monopoly. And I think one of the big things that decentralized technologies can do is mitigate that basically. So it pushes competition away from being able to capture the resources, which resources can be anything if you can create a kind of open free market over it. But you stop a company from being able to lock that down and then you push that company into constantly competing instead of having to capture the resources and then just keep whatever product it needs to to keep running to get the revenue coming in. It's actually incentivized to keep winning it, like has to keep competing against other people who will come along and create a better product which aligns with that consumer. So the biggest kind of benefit I see out of this, of unlocking those resources and making them much more decentralized and much more open, is that it just drives far more competition at the application level. Because instead of being able to lock down resources and just make it continue to make a profit and monopoly there, you actually have to just be the best at like whatever the consumer wants.
00:46:43.095 - 00:46:56.435, Speaker A: So it becomes like a real UX competition rather than just like some competition over hoarding a piece of land essentially, I think that just ends up net better for the market because it's higher competition.
00:46:56.735 - 00:47:27.103, Speaker E: Yeah, I mean like we beat the point to death. I think about how we could create great models with resource coordination, with an open source community, with, you know, all these things. We already touched on how we use those models. You know, that's an open question. I agree with Ben. Open competition will surface the best things. I also just think the user interfaces, coming back to what Travis said earlier in the episode, the UIs and the UXs that we're going to see come out of this are going to be a lot different than what we're seeing now.
00:47:27.103 - 00:47:58.045, Speaker E: Like I'm, you know, saying I don't know what they are, I, I really don't. But like, things that look like toys will likely eventually turn into products that make a ton of money and are highly productive. So you sort of need that weird experimentation. I think crypto Rails give you new business models to pay with to do that sort of experimentation. So I think there's a high likelihood that these two concepts married together with this like open competition and you know, open source foster for creativity produces some UX UIs on top of these models. That's just like unbelievable and new.
00:47:58.385 - 00:49:09.575, Speaker D: Yeah, I think that you're all saying crucial things and something maybe that people don't think about typically is that large language models are actually paving the way for a complete user interface transition. So you know, in crypto we can just provide a different API backend for these things and it can be a swap for the consumer. You know, we've got ways for Web2 to interface with Web3. They're a little kludgy right now, but I think they're going to get better and people don't even need to know at some level that they're using a crypto powered platform. And I think that's the start of it. And honestly, if you're just dealing with agents all day and the agents are negotiating all the backend calls, then that's sort of the ideal world for crypto to live in. So I think that's one thing that probably most don't understand is that actually there's this convergence that's happening where the interfaces to Web two and Web three are going to start to overlap in a significant way.
00:49:09.735 - 00:49:13.639, Speaker E: Meaning that the difficulty to interact with these systems is going to get abstracted away.
00:49:13.767 - 00:50:20.785, Speaker D: And then the other thing I would say, and it's sort of riffing on what you were saying, Dylan Trustless. This is the ultimate low friction for an economy. You know, if code is law, if contracts provably do what they say they're going to do and can call each other, that's just a lot less hassle than orchestrating things in Web2 right now. And it might not seem like it because we haven't had this interface switch where all of a sudden there are a lot of things that are moving towards web 3. But if you think about it, we put up with a lot of trouble in Web2. You know, just to give an example, you look at businesses that have had their funds withheld by Stripe or PayPal. Sometimes those businesses go, go out of business, they actually fail because an algorithm tripped, tripped a flag, and then things were frozen and it was too late to retrieve the company.
00:50:20.785 - 00:51:08.377, Speaker D: Like, stuff like that actually doesn't have to happen at all. In Web three, you can have smooth transactions that go exactly as agreed upon. And if you think about the compounding effects of all the transactions in the world being a lot smoother, about all those transactions removing problematic elements, you know, in business terms or human terms, that just looks like a completely different economy than what we're dealing with right now. And I think that's really the promise of crypto. It's this seamless system where you can have value transfers across a wide variety of networks that do different important things for users and for businesses.
00:51:08.481 - 00:51:51.807, Speaker A: I think there's a really interesting piece there in the, in that new economy where machine learning can be seen as just like suddenly drastically scaling a load of things that human use, humans used to do. Like suddenly we just took off the scaling limits on a bunch of knowledge work. But the, a lot of the current institutions and ways we work have huge bottlenecks as people. So like, trust is solved by people and always has been. And that wasn't really a problem because the other side of the trust relationship was people doing things. So it was kind of as slow as each other and it didn't matter. And then suddenly you absolutely drastically scale one side and say, hey, we can just do things in the knowledge realm at like orders of magnitude, like even unbelievable amounts, higher scale.
00:51:51.807 - 00:52:21.277, Speaker A: But there's still this person here who, like you say, Travis, is reviewing this transaction which breached a certain threshold that just doesn't make sense. You have to match the scaling. And what's so exciting is that AI is like triggered. That knowledge work, scaling and crypto is the kind of like protocol design mechanism to release humans from being the scaling bottleneck. So the confluence of the two is kind of required to let them keep going without limiting each other. It's like a really weird, just like coincidence that the two combine in that way.
00:52:21.381 - 00:52:49.131, Speaker E: I mean, these, the things that we're talking about too. They're like things that are already built, you know, like we already saw, I don't know what the end result of this thing was but the Twitter AI bot that got a grant in bitcoin, we've already seen sort of this in small ways start to happen with already built. I'm curious what you guys think, if there's anything net new that crypto will be building to accommodate this kind of future.
00:52:49.323 - 00:53:25.693, Speaker D: Well, I guess I probably say the thing that we're all thinking, which is that I think crypto really enables the autonomous corporation to become a reality. You know, we're not quite there yet, but I think all the building blocks are going to be put in place in the next couple of years where you really have fully autonomous entities that are providing economic value that are in continuous operation without perhaps any human intervention. And I think you're going to see a new type of entrepreneur start to create some of those businesses.
00:53:25.869 - 00:53:39.565, Speaker E: But Travis, would that be like an acceleration in what AI can do right now or crypto? Because it seems to me like crypto is probably capable right now to fulfill that need. It's just we can't. You can't trust an agent with your wallet. You'd be insane. You know, so.
00:53:39.605 - 00:53:44.345, Speaker D: Well, I might be a little biased here, but this is where I think verified inference is really, really important.
00:53:46.815 - 00:54:21.231, Speaker A: I feel like on the trust and agent piece, in many ways we kind of already do, right? Like a smart contract is just a very dumb agent. It's like an expert system with a bunch of IF statements in it that's executing transactions on our behalf. But yeah, there's that verification piece. But ultimately I think it's almost like the whole the AI effect, where AI is always the thing that's like five years away. It's not the thing that you have now. It's like the same thing here where in many ways we have autonomous agents that exist in an on chain world. They have all of the same kind of environmental levers that we have as people, and we do trust them.
00:54:21.231 - 00:54:28.407, Speaker A: There's just some kind of like intelligence level that we kind of like limit them to for now, but we're constantly kind of increasing that.
00:54:28.511 - 00:55:02.725, Speaker E: Right. Like we know what a smart contract will do to some extent. I mean, obviously there's bugs and stuff we don't catch, but we know what they're going to do, so we trust that they'll do that. It's like the generative AI that you don't want spending money on whatever the hell generative AIs will spend their money on. Like, I guess the question I'm trying to get at is like, there's definitely Some building to do on the AI side to get systems that we totally trust. And there's a lot of techniques that you can do to inject determinism back into the generative AI paradigm. But I'm curious, like, what still needs to be built? Purely not.
00:55:02.725 - 00:55:18.371, Speaker E: I agree. All what we're doing is somewhat different. It's like related to the infrastructure, it's related to the building of these models. Say you have that fully mature AI agent. What is that AI agent need that isn't yet built?
00:55:18.403 - 00:56:13.205, Speaker A: In crypto, there's maybe, maybe it is built, but maybe not. I think there's one piece that I think I find fascinating, but gets us into a kind of difficult realm for some people, maybe morally difficult, but the idea of an agent embodying itself through the incentivization of humans. So we think a lot about the incentivization of agents and aligning them and things like that, but the inverse can happen. And that's one of the really interesting things about crypto, right? Like a generative agent running on chain can say, hey, I've got funds. If a person goes to this physical location and takes a picture or does something like interaction with some kind of oracle and puts something on chain and that person gets paid. And in many ways that is that agent embodying its itself through the entirety of humanity through incentives. I think that's undoubtedly happening, but I think some sort of generic system around that doesn't necessarily exist yet, or it's happening, but not deliberately for that.
00:56:13.205 - 00:56:26.505, Speaker A: It's almost like an organic thing. But I think at some point somebody's going to be like, hey, you know what? Agents want to act through humans. Let's just make the marketplace for that to happen. But I think it'll be morally difficult, socially difficult.
00:56:27.405 - 00:58:01.157, Speaker D: So it's a really interesting question. I can't help but think that we're probably two or three years away from really transformational advances in robotics. And when we talk about embodiment, I think about whether I would be comfortable having a robot plugged into a closed source ecosystem wandering around my house. You know, there have been some real problems, even with things like Amazon Ring, you know, with privacy violations and, you know, police using, subpoenaing those recordings and things. And so, you know, at some point I think that there's a real need for crypto to provide private, objective intelligence capabilities to embodied agents, you know, be those embodied in the way you're talking about, you know, sort of metaphorically with software or like actually embodied, you know, in robots. And I Think people are going to be quite hungry for that because the alternative is really is really sort of, sort of frightening. And you know, if you think about things that have happened in the world like this crowdstrike vulnerability, you know, it's not too far fetched to imagine that a software monoculture that's running a fleet of robots could go badly wrong, as.
00:58:01.181 - 00:58:05.181, Speaker E: Our friend Reva likes to say. Skynet was closed source company.
00:58:05.333 - 00:58:44.693, Speaker C: I'm actually kind of interested in that Skynet comment because I think that we understand that incentives and the ability to quickly use crypto incentives is a huge boon to innovation, experimentation, apps. Now we have, we can marry that with open source AI models that are not restricted. Travis mentioned 40% of financial asks on cloud are restricted. Like we don't have that. So unrestricted intelligence, crypto incentives. It seems like pretty obvious we're going to have more apps here than on OpenAI. Would you guys disagree with that? Because there's already like millions of custom chatgpts.
00:58:44.693 - 00:58:48.305, Speaker C: It's sort of hard to make this argument but conceptually to me it makes sense.
00:58:48.885 - 00:59:36.379, Speaker A: I think we'll have more apps in the open source arena. I think the danger is the closed source kind of more centralized approaches can hoard something that gives them an edge over the others. So if you are, maybe they're just a first mover advantage in having the apps in the first place. If you can then capture user data back from usage of those apps, that just gets stickier and stickier and stickier because you get to tailor your kind of product and your models to the individual user. Which I think long term is probably going to be an enormous kind of like value for consumers. Like if I am interacting day to day with an agent and that agent just has context on me because for whatever reason it's hoovering up sensor data or interaction data, it learns how I interact. It gets better at talking to me.
00:59:36.379 - 00:59:45.723, Speaker A: Like it's very hard to break that you might have more apps somewhere else, but more apps doesn't break the fact that hey, this thing just like knows me better. And like that's probably going to be quite appealing to me.
00:59:45.859 - 01:00:43.675, Speaker D: Yeah, I mean I think you can chip away at that by just being very explicit in the contract that you make with users. You know, if you're one of these AI systems and you want to gather data, just be upfront about that and say, hey, here's the data we'd like to gather, here's how we're going to anonymize it. Hopefully there's something provable about that anonymization such that people don't have to trust it. And then I think you can create those mechanisms in a decentralized system. But I agree that there is more friction to do so. And it's just, it's kind of, it's kind of a question of where the friction arises because I think in a closed source world there's not a lot of friction until there is. And when there is friction in closed source, it's usually because there's been an abuse of power, like a severe abuse of power.
01:00:43.675 - 01:01:31.815, Speaker D: You know, to give a social media example, you know, I don't think any of us would have thought that the UK would be imprisoning people for 10 year old Twitter posts, but that's, that's a thing that they're doing these days. And I actually think that that's creating a lot of friction now for the usage of social media and it's probably going to fundamentally change people's interaction patterns with those. So I think that, you know, there's an opportunity for crypto to do it right, you know, to treat user data honorably, to still collect what is needed to be competitive and then ultimately to provide a comparable experience. But I agree it's more challenging.
01:01:32.155 - 01:02:06.959, Speaker B: Totally agree on the app side and app side and the other aspect we've mentioned, like one of the main question I have and like on the agent side of things. Right. That a lot of people in crypto are talking about obviously is like hey, agents won't use a stripe. Right. They will make use of a crypto wallet in a sense. Right. If that future is going to turn out that way, I'm sure they're going to be like five different YC startups already right now that try to build some kind of stripe agent type system or stripe themselves is probably going to try to integrate that too.
01:02:06.959 - 01:02:07.595, Speaker B: Right.
01:02:08.215 - 01:02:10.475, Speaker D: Obviously you can see the elevator pitch.
01:02:11.215 - 01:02:20.975, Speaker B: Yeah. But obviously the point you mentioned Travis. Right. There could be like abuse of power in that sense. Right. On those kind of systems. Right.
01:02:20.975 - 01:02:37.137, Speaker B: And that's obviously where crypto will continue to shine. I'm just wondering and would love to hear you guys perspective on like how do you think that's going to turn out? Is it going to be a huge use case on the agent side that they mainly going to use crypto wallets or how do you think about it?
01:02:37.321 - 01:02:41.025, Speaker E: Meaning are agents going to bank themselves with crypto?
01:02:41.185 - 01:03:09.889, Speaker B: Yeah, basically, if that's needed in a sense. Right. We had the whole example of like we want to have, or Ben had the Example of we want to have agents, crypto agents, more like capital allocators in a sense where they could order a human to do something for them. Which I'm bullish on and sounds like a good way. Why we don't have the robotics breakthroughs yet to go about things. Right. But curious to hear your thoughts.
01:03:10.017 - 01:04:04.275, Speaker E: I mean, it feels obvious that agents will participate in the economy like we are at this time. I forget who's saying it. It was, it was like, what if all your users are bots? I was like, well, I don't care. Bots or people too, you know, like if they've got a wallet and they're willing to pay, you know, like participate in this economy. So yeah, like a sort of economy that's set up very well for agents to participate and they'll use services like, you know, Distro and Prime Intellect and Jensen and Ambient to contract for resources that they need. And certainly like the AI economy will happen on crypto Rails and it's not going to happen on stripe or through GPT4. Maybe that's bullish as well for the types of models that we're creating that and the type of inference systems that we're creating and the experiences that we're creating that, you know, the ultimate creator of some new generative AI app is a bot or is a, you know, agent or whatever you want to call it.
01:04:04.395 - 01:04:34.175, Speaker A: I strongly agree that it's just the most like kind of logically, like logical angle for these systems to do. It's like the most appropriate technology for them to use. It's the lowest friction. So it makes complete sense. I think something you said earlier, Dylan, applies here as well though. There's a lot of talk in the kind of agent space which always in my view at least comes down to quite a lot of anthropomorphization of machine learning systems. I don't think that's necessarily what's going to happen with agents like I.
01:04:34.175 - 01:05:06.243, Speaker A: And the kind of reason I bring up your point was I think you said, I don't know what's going to happen. This is a situation where I'm like, I have no idea how this agent economy is actually going to come up. I don't think it's going to emulate humans. I think it's likely to be something a bit more abstract and a bit deeper. But I'm pretty certain that they are going to use all these rails like you say that we're using. It's just we'll wait and see. And like, I think Somebody mentioned earlier, like the idea that these, like toy interfaces that people make using machine learning, these things that we see as just quirks, I think those are the things that are going to evolve into the agent economy.
01:05:06.243 - 01:05:14.555, Speaker A: But it's not going to be like I'm interacting with another human, but the human's been replaced by an agent. It's going to be something entirely different. Just we don't know what.
01:05:14.595 - 01:05:42.685, Speaker E: Well, to an extent, I mean, like, again, bringing back your point, like what level of intelligence are we talking about? Like, we're interacting with bots all the time and their behavior is incomprehensible in crypto. Like we are constantly being flashbotted or whatever. And like if you looked at the, if I looked at the transaction log and had no assistance, I would be like, this makes no sense and I have no idea what this person was trying to accomplish. Um, so yeah, like there's going to be all these incomprehensible behaviors that are serving some end that is inscrutable to us and it's already happening and it's just a matter of where that goes.
01:05:44.745 - 01:06:10.215, Speaker D: I don't know if anyone here has read Accelerando by Charles Strauss. Yeah, you're, you're reminding me of Accelerando a little bit. For those who don't know, it's a book about a radical approach towards the singularity over the space of like, I think it's like a 30 year span. Each chapter of the book covers a period of years. Highly recommend it. I think it's free, actually. You can download it free.
01:06:10.995 - 01:07:11.875, Speaker C: I have a different line of question for you guys as we get toward the end of the episode, but we're a venture fund and one of the main things we always ask about is value flows, maintaining what you create, things like that. There's always this talk about creating an open source AI model. Obviously everyone here is working toward that in some way, but releasing all the weights publicly means that we don't really own anything. Anybody can copy it, anyone can run it. What are your thoughts on fully open sourcing your creations? And if you do do that, are there other value flows that you can use? Right, like anyone can copy Ethereum, but the reason we use it is because there's nodes around the world and it's hopefully World War 3 proof. Right? Does like someone building a crypto AI app want to use your open source model that has nodes everywhere and liquidity and protections and security and verifiers? Is that the moat? Can you still go fully open source?
01:07:11.955 - 01:08:06.409, Speaker E: I could take a first stab at this. You open source when you have the ability to capture value in other places, which might sound ridiculous coming from news, who's open source? Like all these models that we built and like haven't seen much from that, but like we've gained a lot in terms of talent acquisition, in terms of attention, in terms of, you know, the ability to access resources and individuals that we otherwise would never have been able to. So it has been an economically net positive action for us. We could have been one of many in a sea of centralized competitors that just gets washed away. But instead, like we have a, a big following in a community which you can ultimately figure out ways to create value from. Right? But like if you're meta, like Zuck isn't open sourcing just because like, you know, they're the best guys in the world. Like, maybe that is one of the reasons, but it's really because they have all these buckets placed conveniently everywhere to accrue value.
01:08:06.409 - 01:08:42.495, Speaker E: They've got Instagram, they've got WhatsApp, they've got Facebook, and each of those products rakes in a ton more money because they have these gigantic open source models. And you know, there's all these other reasons, maybe undercutting competitors, etc, but like the truth is once your weights are open, like it's pretty hard to hold a gun to somebody's head and say, like, you can't use this unless you pay me. So when you're doing that, you have to be pretty sure that you have other ways of accruing value. And that's sort of like, I think the goal of doing open source. There's various business models we could get into, like open core, et cetera. But I think that's like the basic gist or the way that I see it.
01:08:42.835 - 01:10:30.721, Speaker D: Yeah, I think from ambient standpoint, I mean we have a very particular view and that is, you know, ambient runs one model and we want it to be trustworthy and we think that the only way to make it trustworthy in the end is to have everything out in the open. The whole training process, all those steps, whatever, backtracking, it's doing whatever reinforcement learning is being applied to that model, then the value that we add is ultimately associated with that ecosystem that keeps the model evergreen, that keeps the cost low because it's difficult to run really huge models at scale. If you do the math, I don't think anyone is going to want to run eight A1 hundreds in their basement, you know, even for a 400 billion parameter model. Because you know it ends up costing a ridiculous amount of money. Like you're much better off just going to a provider for that. But then the question is, does that provider take a neutral approach? Are they uncensored and uncensorable? Are they preserving your privacy? Are they taking reasonable measures to be competitive with other models in the space on an ongoing basis such that you don't just have to worry about that? Do they have a rich and vibrant economy of apps that you can interact with seamlessly, using the same model to get results that correspond to your expectations? Like think this is the sort of value that you bring to the consumer. You bring a complete ecosystem that supports their desire to use intelligence to achieve whatever economic ends that they would like.
01:10:30.913 - 01:11:47.961, Speaker B: I think there's definitely what you talked on the ecosystem side of things like value capture in that sense, the infrastructure could have a value capture or already has value capture right now. The app level is going to grow over time, but honestly I think it's going to be hard to just commercialize on the model level. We all probably agree in some sense that those models are going to be commoditized in a sense and that the value capture will be somewhere else and that open source AI has to find other approaches to build state of the art open source models. They should probably do it in a way that has the lowest, like CapEx, that we use all the talent and all the compute resources that already flow into things like llama, that we make use of that and build on top of it to build state of the art models in a sense. And then not necessarily that I agree with it, but there's also a bit of the emart view on this, on seeing it more like a public good in a sense. Those models and having like nation states coming together, training those models together just to throw that also into the round, like those view on the model side.
01:11:48.073 - 01:12:34.085, Speaker A: I think just to riff on that public good bit, I don't necessarily have kind of a stance on what is and isn't a public good, but I think everybody does. That's the point. Like the collective kind of human decision is or like collective human action determines what is a public good and what branches into actually we want to incentivize this to be kind of a market competitive thing. And I think when you look at these really big models, you take a situation where humanity had kind of been curating a public good, which was like all the knowledge on the Internet, with the impression that that's what that was, that's what we were all doing. Together, like I upload a video to YouTube and it's available to everyone. And that's the kind of the sort of trade off I was making. I was doing that willingly and maybe I'm editing Wikipedia and doing that for everybody.
01:12:34.085 - 01:13:13.667, Speaker A: That's a trade off I was making willingly. And then somebody came along and said, using another resource, compute, I can take all of that, I can compress it into a new representation and then I can kind of capture that public good from before in a new way. And then you see this wave of kind of humanity being like, hang on, we don't necessarily like that. We want to be able to do that in the open still. And then you get efforts like gptj, that was mentioned before, of can we actually just collectively do this? And I think there is a growing swell of people saying we'd like to collectively do this, but we're heavily limited and the limits at the moment in our view are predominantly around compute. Right. There's other things that can be limiting factors, but they're the big one.
01:13:13.667 - 01:13:57.645, Speaker A: So if you can create the sort of like public access to that, if you can create a situation that allows people collectively to say, hey, we want to make this public good, we want to train a model together so that we can have an open version, then I think that will happen. But there's just limitations in those resources. That means that somebody was able to essentially go towards the big public good and say, hey, this is mine now, just for reasons unrelated to the actual curation of the data or anything like that. And you see that backlash from the world. Basically what we want to see is just the world's decisions are able to be made. So if people do want to collectively come together, train a model and say this will always be open, this is public, then the world can do that. I think the idea of limiting that is terrifying to me.
01:13:57.645 - 01:14:06.251, Speaker A: And I think that's what we're seeing with some of the incumbents. They want to stop that from happening, claim altruistic reasons, but realistically it's likely competitive reasons. Right?
01:14:06.443 - 01:14:40.641, Speaker C: As we're talking about whether or not we're going to open source the end models that you guys create, decision making is going to be pretty interesting in the future. You know, I think some of that comes into the data used to train the model. So it's global, but you know, the idea that we just sort of add our latent compute for my Mac Pro and it makes the network smarter and all is utopian, seems a little far fetched. How do you guys envision like major debates and changes around, you know, your open source and products. Like it feels like we're going to get into some crazy debates at some point.
01:14:40.713 - 01:14:51.445, Speaker E: Do you mean from like a regulatory perspective or you just mean like from a who built what kind of. That's my thing. Then I don't want to open source it anymore.
01:14:51.865 - 01:15:17.187, Speaker C: I think the point I was getting at was you guys will face some pretty crazy debates when your networks go live changes to make things to change. They're going to be hyper contentious if you guys are really successful because your models will both be trained by the world and used by the world. How do you envision we can't do this on discord. Like how do these debates happen? Yeah, how do changes get enacted?
01:15:17.291 - 01:15:55.853, Speaker A: I think that's a really good question. I don't think. Well, maybe somebody here does have a good answer. But from what we've seen thinking about this for quite a long time and watching the at least the crypto space come up against this like wide scale governance decisions problem for a while, I don't think we've reached a particularly satisfying answer yet. That's the kind of unsatisfying answer, right? Like we've tried a bunch of things. We went straight to like direct democracy and everybody gets a vote who has a kind of on chain identity. And then we saw the problems with that, the concentrations of power, the lack of interest from people participating, et cetera, that you can have these councils of interested parties.
01:15:55.853 - 01:17:04.215, Speaker A: But then who determines what an interested party is? There's lots of different mechanisms and I think we're constantly evolving them. Realistically, I think it's just going to be a lot of trial and error as we try and find the most effective way of doing this. And it does require just the kind of patience of community in general to accept that there's going to be some like failures along the way as there has been in the crypto space a bunch. I think the most interesting or the way it's going to spike out most interestingly when applied to machine learning is in the social decisions that need to be made on top of ML. So like how are we biasing models, etc. That's a bit different from what's this kind of variable in the way this protocol executes because it means I get less money than I did before or whatever in the kind of the transactions I'm making. It's more existential and kind of more philosophical, which probably puts another entire dimension on the decision making framework for where these discussions happen through all of that I just come back to what do we want? We want the cleanest discussion possible, limit the least friction possible.
01:17:04.215 - 01:17:42.135, Speaker A: And so instead of putting loads of levers in front of people and saying there's a load of on chain voting that can happen here, I think we just have to have as free discussion as we possibly, possibly can. And then absolutely minimal protocols that don't try and make decisions in a way that has to be modified and changed. It actually is just very simple. And then those social decisions can happen at a higher layer like they currently do. Other discussions we had earlier around regulating machine learning models for doing something. An app allows you to generate something that people don't like. I don't think that's the problem with the model, that's a problem with the app, that's allowing you to create something that people don't like.
01:17:42.135 - 01:17:56.639, Speaker A: And we already have social governance systems for that. We say, okay, people aren't allowed to make apps that do X. Like that's already a thing. So I think we just continue using those Rails as much as we can. And then at the lower level it gets like into that more philosophical discussion.
01:17:56.727 - 01:18:27.145, Speaker E: Piece I was going to say, I totally agree with you. We've started to shift these decisions down in the stack, whereas we already have things in place to take care of them. And to your point, like we have regulations in place for platforms. It's sort of the stance that we've taken at Noose. Not a stance per se, but like kind of the way that things have evolved at Noose is like we've built models and some people plug these into their platforms and if these models are doing things you don't like in your platform, you have the tools available to stop that. And hopefully our models are compliant enough that they give you that. Right.
01:18:27.145 - 01:18:34.757, Speaker E: Like that's where the decision making happens, that's where the pressure on these decisions should be. Like you said, keep it simple at the bottom.
01:18:34.861 - 01:19:19.227, Speaker D: Yeah, I guess. I, I mean I think it's different, I think there are different aspects to it. So I mean if you go back to llama 3.1 and you read their 90 page paper of backtracking, backtracking, you know, I think that you have to acknowledge a need to programmatically specify training runs in a very fine grained fashion if you're going to be successful for a decentralized system. And so one of Ambient's goals is to enable that capability. And I think that that is necessary but not sufficient for governance. I actually agree with Ben, like governance is a complex problem.
01:19:19.227 - 01:20:26.385, Speaker D: You probably want to be having these higher level discussions at a higher level. But I also think that your protocol needs to have the tools such that when you've reached a social consensus about what's being implemented that that can be rigorously specified underneath the hood. Because if you don't have that then these things can drift in directions that are unexpected. So that would be one thing I would say. The other thing I would say is that for ambient we're enabling a base model and fine tunes. And so I think people have wide latitude to use fine tunes that are going to be good for their use case and maybe good for the sociocultural milieu that they are operating in. And going back to Ben's point, I think that if people are given that choice and governments regulate what apps are doing, you have enough tools there to maintain sort of social cohesion.
01:20:26.385 - 01:21:07.095, Speaker D: But it's a really, it's a really interesting question and I, I think that I, I think that crypto actually can't afford to be unopinionated about this. I actually think that a protocol should be obligated to come out of the gate with a very specific governance process in mind, even if that changes is challenged so on over time. Because I think that you have to bounce off of something like a concrete proposal in order to come up with a good ultimate solution. So those are just some of the few thoughts I have about that.
01:21:08.075 - 01:21:58.951, Speaker B: Yeah, fully agree on all the governance points we've mentioned there. I think one thing to add there on when we all launch our training ones and so on and how would that evolve? I think the backslash are going to be like less than it would have been like two years ago. I think the public opinion has already shifted a bit on like open source AI could actually have helps progress is net positive in a sense. Right. I think could be a biased view that I have on it. But my opinion is yeah, there has been a lot of people claiming that if you would open source something like a Lama 1 or 2 or whatever, that there's already going to be bad things happening too, which didn't really occur yet. In a sense this has mainly progress hubbed, a lot of people build applications on top of it and so on.
01:21:58.951 - 01:22:22.699, Speaker B: Obviously once we go further on the capability side of things that there's going to be backslash again from that side. Then we're just going to show them empirically again that open source AI is going to be even more helpful for safety research and stuff like this. So I think it's going to be empirically tested. But, yeah, governance processes should obviously be in place too.
01:22:22.827 - 01:22:53.565, Speaker D: Yeah, I think it's an interesting thought experiment. I don't know if you guys follow. I think it's Pliny the Prompter. I don't remember on X. Always amusing. He always jailbreaks every bottle that comes out in hilarious ways. And I guess the question you have to ask yourself is, has society crumbled because of the jailbreaks? Because there's always a day one jailbreak, and someone is using these jailbroken models to think of or do something that, you know, the model creators didn't intend.
01:22:53.565 - 01:23:01.245, Speaker D: But have we experienced mass chaos as a result of that? I think that should tell you something about the actual threat model that we're dealing with here.
01:23:01.405 - 01:23:24.811, Speaker C: In closing, I want to ask you guys a devil's advocate question. There obviously are a lot of skeptics that, you know, it's hard for some people to bridge the gap between using ChatGPT and then buying into what we're saying here. Right. And I think there's probably some tricks the centralized players will play. You know, maybe you could train a model where you have Google Chrome open or Facebook. I don't really know. Right.
01:23:24.811 - 01:23:40.185, Speaker C: I'm just curious. If you have to think through, you know, what keeps you up at night in terms of why you would lose, what do you think those are? I mean, maybe we'll just go around the room. Travis will start with you and go in a circle. But I'm curious, why would you lose? What are the things that keep you up at night?
01:23:40.765 - 01:24:20.095, Speaker D: Yeah, absolutely. Well, I have a few ideas. I guess Ambient is specifically designed to mitigate one of them, which is a loss of focus. I think that crypto AI has historically created a plethora of choices for consumers and for miners, and that can be confusing, actually. You can get into a paradox of choice. And Ambien is deliberately designed to focus that down and let people get a really good experience with a choice that's easy to make. And it's the same thing for the miners.
01:24:20.095 - 01:25:13.665, Speaker D: So that's one thing that we like to mitigate. But you could get that at a sub level if the protocol isn't carefully designed. Where we talked about governance, you have the next version of the model that needs to be developed, and people can't agree on how that should be developed. And as a result, the network falls further and further behind. And so I think that sort of the combinatorial explosion of choice that comes with decentralization is something that crypto always has to guard against. But Then another thing that I think could really be harmful is, you know, associated with that regulatory capture that we talked about at the very beginning. You know, if model training is outlawed, if inference on large models is outlawed, then of course we're in a completely different ballgame.
01:25:13.665 - 01:26:20.215, Speaker D: And so I think that's, you know, definitely something that is a threat. And I think it's like erosion of privacy protections over time in many countries or perhaps the non existence of legislation that would support privacy protections or the non introduction of that over time in the U.S. you know, that represents a significant threat. The only other thing I would say is, you know, maybe related to the trust aspect. You know, Ambien is designed to be very trustworthy and predictable. It's a single well known thing. But you know, if crypto AI as a whole gets a reputation as something of a wild west of agents behaving badly perhaps and doing spurious things in the real economy, maybe, or you know, embodied as robots, I think that that could very quickly tarnish the perception of the marketplace and create difficulties for it for the field.
01:26:20.515 - 01:26:59.831, Speaker A: I don't know which way round in a circle is, but I'm happy to jump in next. I think from my perspective there's like three main ways that this kind of doesn't play out for the decentralized approach. The first one is the incumbents can achieve regulatory capture. Basically they're able to lockdown government kind of driven rails to stop the kind of open source and decentralized world from actually being able to do what it needs to do. I think we've seen many attempts for that. We've also seen the pushback. We've seen it in the past with new technologies, we've seen it with encryption, et cetera.
01:26:59.831 - 01:27:51.077, Speaker A: It's an age old thing. We have to just continue to make sure that rational thought prevails rather than financially incentivized movements. And I think broadly, I think everyone is aware of that, like down to regulators themselves, like they're obviously aware. So it's not necessarily as big a danger as sometimes maybe we make it out to be, but it is a danger as it kind of always is with any market. I think the next one is we touched on it before, but just the stickiness from an incumbent. You look at a very large organization with a centralized model, one that has maybe many, many eyeballs on its products. It's able to capture data, like we said, from those users, it's able to tailor its product towards those users and just generally provide a user experience which might be kind of Locally better for each individual, but globally is kind of subpar in comparison to what we could have had.
01:27:51.077 - 01:28:27.977, Speaker A: We just get stuck in that whirlpool basically, which has potential of happening. But like Travis said earlier, there's also ways to mitigate that in the kind of incentive mechanisms that we have from decentralization, et cetera. Anyway, so maybe that's not as big a thing. The final one I'd say is almost back to markets a little bit in that incumbents can maybe just like incentivize forever. Like they can just subsidize for a really, really long time. And like kind of Keynes said the sort of the quote of the market can stay irrational longer than you can stay solvent. It's the same thing here for anyone trying to build anything in the open.
01:28:27.977 - 01:29:06.005, Speaker A: Right. Like the incumbents can just keep subsidizing and just drive you out with enormously deep pockets to the point where there's nobody can survive long enough to build the open alternative. I think realistically, given the groundswell of interest from the wider world and that point I made earlier about how the kind of public good that becomes this swell of interest in creating the public goods and also resources flowing from many, many, many individuals to make that happen, that's a kind of like counterpoint towards that. But it's still a danger mode that there are some very, very deep pockets in this space that are probably willing to fight for quite a long time to maintain their edge.
01:29:06.385 - 01:30:05.675, Speaker B: Agree with all the points mentioned here. Just to add one that I see as the biggest concern of the whole broader crypto ecosystem is then I think the biggest risk is basically if we can't convince AI folks of crypto in a sense and the world of crypto. So even with future incentives even yeah, I think we drive the risk of having protocols that don't have either. On the compute side of things, no usage of the AI ecosystem obviously, but also on the model builder and talent wise aspects that we, while giving out huge incentive, don't have the right community in place to actually build those models. And yeah, I think the only way around that is convincing AI folks by doing crypto AI folks by doing something at this intersection while still being around in the AI ecosystem speaking their language. Right. I think news is the best example there.
01:30:05.675 - 01:30:15.707, Speaker B: Right. Being perceived as a true AI company while still building at the intersection. Right. And yeah, I think that's the only way to go.
01:30:15.851 - 01:30:38.775, Speaker E: Yeah, I think, you know, the risks are well set here. I think the one is that it's just a scaling game and It's a resource game and the incumbents have deep pockets and such a head start that they are running away with it. And worse than that, it's sort of an insider's game at this point. Like who gets the best hardware first. It's the guys with the business relationships. It's Sam Altman. It's like, you know, individuals at the top of this like technocracy.
01:30:38.775 - 01:31:36.709, Speaker E: And then the other, the most obvious one that we've all talked about is regulatory capture. But I would say it's even a little bit more nefarious than just straight up outlawing what we're doing, which is obviously a possibility as well. And we've seen sort of like belligerent kind of threats in that way as well. But it's like we're playing this gigantic global scale game of chess between like, you know, the world's open source AI and all these gigantic incumbents and regulators are pushing their thumb a little bit on the scale of their side. Like even in the case of say crypto incentives, if you're scaring a sizable enough portion of these institutions who maybe they're publicly traded or for whatever reason they are saying publicly that like, I don't touch crypto, it's not worth the risks, my shareholders don't like it, whatever because of all this like publicity and you know, regulatory nefariousness like that could be enough to sway the game against us. I don't think either of those are going to ruin this. Obviously I wouldn't be in this.
01:31:36.709 - 01:32:16.847, Speaker E: I do think that the risks that we should be aware of, but I think there's a high probability that we're not playing just a resource game and it's not a game of convinced the public companies to direct their resources to us. I do think we will be successful in harnessing what we need to create open source products. But I also think there's a high likelihood that the thing that really creates AGI or really creates like the intelligence that we're looking for comes out of left field. And I think that the probability that that comes from somebody sitting at the top of this technocracy is pretty low. We all know about the innovators dilemma. It's just these quirky ideas that you don't see coming that blindside you and catch you off guard that, you know, really change the world.
01:32:16.991 - 01:32:36.439, Speaker C: Everyone, I want to thank you so much for being here. Travis from Ambient, Dylan from News, Johannes from Prime Intellect and Ben from Jensen. Phenomenal conversation on open source AI model training or decentralized AI model training first, our centralized counterparts. So thank you so much for being a part of the conference and for being here.
01:32:36.527 - 01:32:37.687, Speaker E: Thanks so much, Tommy.
01:32:37.791 - 01:32:38.839, Speaker D: Thanks everyone else.
01:32:38.967 - 01:32:39.703, Speaker A: Thanks, Tommy.
01:32:39.759 - 01:32:40.415, Speaker D: Thank you for having me.

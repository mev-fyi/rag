00:00:00.400 - 00:00:35.891, Speaker A: Before we get started, we'd like to thank our sponsors for making this event possible. Special thanks to our platinum sponsor, olas. OLAS enables everyone to own a share of AI, specifically autonomous agent economies. We're also excited to highlight our silver sponsors NIA Empowering Decentralized Applications and Blockchain ecosystems. Venice AI a private and uncensored alternative to popular AI apps. MIRA Unified AI infrastructure secured by crypto and the first on chain multi agent system. To learn more about all of our sponsors, check the description below and dive in.
00:00:35.891 - 00:00:37.135, Speaker A: Enjoy the show.
00:00:49.995 - 00:01:16.909, Speaker B: All right, everyone, welcome back to Delfi's Crypto AI Month. We've had a lot of great talks, but I'm really excited to step into the ring and host this one. Really nice to have you here. Really excited about this conversation. Before we dive in, I wanted to give some context to what we'll be discussing today and kind of like the framing I'll be asking my questions from. Right. So for anyone who's watching this that's not aware, I'm one of the founders and CEO of Delphi Digital.
00:01:16.909 - 00:02:20.751, Speaker B: As you've probably seen from all our crypto AI content this month that we've held, our team has been going super deep into what we think is one of the most exciting areas of crypto. And you know, admittedly I'm not like, you know, as deep as some of the team like Tom and Ken from the venture side or Ross and Enrico from the research side. But that being said, I've spent a lot of time thinking about what AI means for the future and, you know, especially what it means for our research product and, you know, business as a whole. And, you know, NADA has actually been instrumental in this process and we've actually had the pleasure to work on some experiments for Delphi Research together that I'm looking forward to sharing with our members early next year. But, you know, today I wanted to take a step back from all the deep and technical conversations a lot of our team have been releasing and having the not provide a great foundation for not just, you know, myself, but others on what AI actually is, you know, what problems it's currently facing and what that means about the opportunities available for builders, innovators, you know, looking at this technology and, you know, Nana, before we get started, I think it'd be helpful to talk through your background and why we thought you'd be, you know, the perfect person to have this conversation with.
00:02:20.943 - 00:03:19.115, Speaker C: Yeah, thanks for taking the time anil and chatting about this. I know we've got some interesting research coming out in the next couple of weeks here and happy to talk about that as well if you'd like. My background is, you know, traditional big tech for a long time, over a decade at Amazon and Uber, most recently led marketplace for Uber delivery worldwide. And prior to that spent time with Amazon and Smart Home and Amazon AI over in Cambridge. And this new round of AI that sort of like sprung up, you know, a couple of years ago got me really interested. And as I was thinking about, you know, what we can do with AI, it turned out that there's quite a few challenges that need to be solved. And so one of the things that we've been doing at Mira, you know, where I'm co founder and head of production, is we thought why don't we start actually by building some AI apps ourselves first and figure out what some of the challenges are and then identify the areas where we can add the most amount of value.
00:03:19.115 - 00:03:29.335, Speaker C: And so we've been doing research with you guys, just trying to do some interesting work at the intersection of crypto and AI. And that has borne fruit in a number of ways that I'd love to talk about.
00:03:30.035 - 00:03:59.875, Speaker B: Yeah, definitely. Yeah, I think we'll definitely cover Mira and I'm excited to dive into it and kind of like the intersection you guys are building at. But you know, AI has always like, obviously been this huge buzzword lately and you know, I know, you know, I know it's going to take some time and patience, but, you know, I think we're still not seeing AI live up to its full potential as of today, even though we've had some, you know, really powerful LLM models released in the last, you know, 18, 24 months. So, you know, what do you think is going on with AI independent of crypto?
00:04:00.455 - 00:04:42.325, Speaker C: So I think independent of crypto, AI in many ways is sort of like an extension of neural networks and ML from the last decade. Right. And the key innovation there was, it was always matrix multiplication to some extent. But the key innovation in the last couple of years was the Transformer paper that basically said, why don't we actually try and find every permutation and combination between every token and every other token. So traditionally you sort of like do a single pass on the training run and then and you'd be done. And one of the reasons you think about why Facebook actually bought all of those a 181/ hundreds a couple of years ago was not because of traditional now AI. It was actually because they were doing some of the traditional ML techniques that actually scale very well to today's.
00:04:42.325 - 00:05:33.011, Speaker C: AI. I think where AI goes from here on forward is there's a huge school of thought that says you just need to parameterize AI more, which basically means try and find more and more signal in all the data in the world and then throw more data at the problem. Right? And now we're talking about synthetic data and whatnot. So think about if you have a 405 billion llama 3 model, you'd probably see a trillion parameter model at some point in the next couple of years. I think there's a school of thought there. And When Sam said DNNs work, my read is he's probably thinking just maximize data and maximize parameterization and you'll get to a much more powerful state of AI. What I think is also happening though is endemic to AI is the fact that everything is a probability distribution, right? So if you say the weather today is.
00:05:33.011 - 00:05:59.997, Speaker C: The next word is basically some probability distribution for, you know, from, from the training model. And it's picking something at runtime. I think where we end up here is we need to solve for how do you make AI more reliable. So if you think about where AI is today, everybody is using it for one of two use cases. The first use case is low consequence things. So I'm going to put a chatbot around my FAQs. If I respond incorrectly.
00:05:59.997 - 00:06:39.105, Speaker C: The downside is low. Some people actually tried AI in more high consequence use cases. If you remember, a couple of companies tried to automate customer service earlier in the year, earlier last year and ended up promising customers hundreds of dollars worth of freebies and whatnot, right? So AI sort of like can go rogue very easily. So I think we need to solve that one piece. The other use case that we're seeing is a lot of people using AI as co pilots. But when you think about AI as a co pilot, I think of that as sort of like an extension of SaaS, right? Where it's like there's a human in the loop, it's making the human 20%, 30% better. But to me, AI was like, you know, on the path to getting us to the point where the AI can completely replace humans.
00:06:39.105 - 00:07:16.215, Speaker C: That's where I think it'll become really, really interesting. And so I think two things will happen. One is on the sort of like tailwind, you have to go make models larger, more powerful and whatnot. On the headwind, if you go solve for reliability now, one sort of like sub bullet point on the, on the tailwind is you'll probably see foundation models continue to evolve and you know more parameters and whatnot. But I think you'll also see a lot more use of fine tuned models and small models because you can't, you know, you don't want to throw a hammer at every single problem. Right. You don't want to throw a foundation model that's like so heavy and so expensive to use at every single problem.
00:07:16.215 - 00:07:20.235, Speaker C: So I think you'll probably see some bifurcation over there in the next couple of years.
00:07:21.375 - 00:07:35.515, Speaker B: Got it. Yeah. So you know, when you bring up like AI reliability, like what's the core issue with that? And you know, why isn't anyone. Yeah, I'm sure people are working on it, but like why don't you hear more about this and yeah, like I'm curious how you think about that.
00:07:35.855 - 00:08:02.241, Speaker C: You know, my sense is that as an industry we saw some really exciting outcomes from foundation models. GPT, you know, 3.5 was more powerful than 3, 4.4 was more powerful than 3.5. And so a lot of the focus was on that exciting end of things. Now that you've gotten to a sort of like asymptote where you know, GPTs are reasonably powerful now people are going to start getting worried about how do we make this actually work in, you know, in a production use case. Right.
00:08:02.241 - 00:08:27.885, Speaker C: And so, you know, from a reliability perspective, think about it this way. I'll give you an anecdote. I was with a family friend in San Diego, we had a five year old kid, took her to the zoo, spent all day at San Diego Zoo. And at the end of the day I was like, what was your favorite animal from the day? And she said, rainbow python. So it is very plausible but completely impossible. And that's sort of like the state of AI today. Right.
00:08:27.885 - 00:09:08.375, Speaker C: You get these like plausible responses. You know, you could ask an AI, what's the capital of New York? And there's a reasonable chance, no non trivial chance, it could say New York City, which is plausible but incorrect. And so how do you actually eliminate those plausible but impossible responses is I think the key to making AI useful in production. And that's the, I think to me that's the trillion dollar opportunity right now. You know, foundation models with more training and you throw more power at the problem, you get to some end state. I'm just not sure that foundation models in their current era are actually broadly usable in a manner that unlocks trillions of dollars of value.
00:09:09.875 - 00:09:14.775, Speaker B: Yeah. So given these challenges, how do you reduce error rates in AI?
00:09:15.355 - 00:09:52.925, Speaker C: So there's quite a few schools of thought. There are companies that are saying, okay, look, when you train a model, you basically have a probability distribution, right? For every word. What's the next token? You have a distribution of outcome. Why don't we, for certain things basically set the distribution to one? So that's a training time issue. Now that is interesting, but it doesn't really work in practice all that much because you end up in a situation where you don't really deal very well with any new information, because any new information that you have, you have to retrain the system. And retraining a system is, as you know, extremely expensive. So I think that's an interesting sort of like idea, but not really super scalable.
00:09:52.925 - 00:11:01.887, Speaker C: Another idea is why don't you use a knowledge graph? So some of the early experimentation that we had done even with you guys, is if we had a knowledge graph, could we then enforce outcomes? So say, for example, you say Bitcoin is a layer X that's sort of like the sentence you want to construct. Could we sort of use the AI for the text to speech and the nlu, sort of like the language layer, but then read from a knowledge graph the actual facts and embed them into the output? Right. The problem with knowledge graphs is that they become quite expensive to maintain. You know, the big companies have them, Amazon has it, Microsoft has, you know, a huge knowledge graph and so on. But you know, all those companies employ knowledge engineers who are basically people whose job it is to stay on top of things and so on. Right? So it's kind of hard to make the expenses work, especially in a net new area. So we approach this as, you know, why don't you actually lean on the wisdom of the crowd? Right? So myself, my co founders are all sort of like crypto lurkers or have worked in crypto.
00:11:01.887 - 00:11:53.227, Speaker C: And we said, why don't we take learning from crypto that consensus can actually get us to the right answer. So the area of research that we're looking into right now is, okay, say you have the question, what's the capital of New York of New York State? And you have a model generate the output, run that output through an ensemble of validators or verifiers who can actually verify the outcome for you. And in our early research, we've been able to show that you can reduce the error rate or the hallucination rate quite significantly. In one of the experiments that we ran last month, we were able to reduce the error rate from about 30% to sub 5%. Right. And once you start doing that kind of stuff, you actually start making AI more useful. I can now start, you know, start becoming more hands off the wheel.
00:11:53.227 - 00:12:36.025, Speaker C: I can now actually start thinking about building production use cases. Now, there's two big reasons for this, right? There's two big needs for this. The first one is errors compound. So in a world where you have, you know, OpenAI's O1 reasoning model, if it takes 15 steps and there's like a 10% error rate at each step, that error compounded throughout the entire journey. Which is why you see so many people talk about, you know, O one giving you completely random nonsense at the end of a response, because it's just, it's like a game of Jenga where it's building on top of a poor response from the previous step and then adding its own 10%. So with reasoning models, it's a game of Jenga with agentic models. Now there's no human in the loop.
00:12:36.025 - 00:13:09.575, Speaker C: Again, same problem. You don't know that the agents aren't just talking garbage in, garbage out, because ultimately AI is garbage in, garbage out. All of the use cases you see today, if you're using the chat GPT app, or you are a marketer writing copy, or you're an engineer doing code with Claude, there's a human in the loop because that person is needed there to do the quality control step. And so we think that if you can actually just reduce the error bound from 10% to 2% or 30% to 5%, you can start enabling all of these net new use cases.
00:13:09.735 - 00:13:48.259, Speaker B: Got it? Yeah. I remember when you first told me about this when we were like, you know, preparing for this chat. I thought this was not only super interesting, but, you know, it seemed like such a big deal, you know, dropping the error rate by that much. And, you know, I totally, yeah, even as a user I totally see, you know, the compounding and errors. I guess the latency is definitely like the main drawback that comes to mind. And in this case, won't you only be as fast as the slowest model you've integrated? And then we haven't had a chance to dive into this. But I'm curious, how does that work? How do you plan to scale this? How does decentralization play a role? Yeah, would love to dive into that.
00:13:48.427 - 00:14:13.969, Speaker C: So decentralization actually turns out to be super important. And the reason is just to talk about our journey. You and I have been working on some of these things for a couple of months now building these apps. And one of the insights we gained from building these apps was, look, at the end of the Day. If you think about the key challenges from any builder's perspective, there's a couple of classes. One is I want to build a real time app. That's one class of problem.
00:14:13.969 - 00:14:48.467, Speaker C: The other is I want to use AI as an enabler. That's another class of problem. That's the copilot problem. There's a third problem where you can actually use AI for bulk processing of information. Right. And so what we've decided to do is to your, exactly to your point, today latency is high because if I use say, say I have a second of latency on the first model just to generate the content and then I have, you know, an ensemble of models, I have a network that I have to decentralize to and within that network, the slowest model is 2 seconds. So now my total latency is at least 3 seconds plus any more transportation latency and whatnot.
00:14:48.467 - 00:15:16.465, Speaker C: Right. So let's say give or take four seconds. So I can't do real time use cases without like breaking customer delight. So we're going after initially batch process use cases. So our, you know, we have a customer that we're working with right now where they generate educational content and they, they're fine batch processing that information. They just need it to be accurate. So if you think about the three dimensions that customers care about, the first dimension is cost, the second dimension is latency, and the third dimension is accuracy.
00:15:16.465 - 00:16:18.075, Speaker C: Now if you put latency aside, we're actually pretty competitive on cost because we're often competing with highly paid humans. Right? In the case of the customer we have right now, it's in the edtech space, it's costing them $5 per unit of output. And by replacing that $5 per unit of output, because the person has to go do their research and whatnot to generate good quality education content, running the whole thing through our system, we're able to give it to them for about a dollar. So now it's completely pivoted that customer's business from paying people to generate content to now paying people just to QA content and they've been able to reduce their cost significantly. Right? So that's the kind of use case we're going for initially. Now over time we think that we can get to real time use cases. And the reason why decentralization helps here is think about, you know, the way an AI model is trained is you basically get masses of data, you curate it, you sanitize it, clean it, whatnot, and then you train the model.
00:16:18.075 - 00:17:14.565, Speaker C: But in the model we've developed the insight that there exists what is called as a training dilemma. And the training dilemma basically works as follows. If you want to minimize hallucination, your probability distribution needs to be narrow, which means that you necessarily have to curate the training data. If you curate the training data, you have necessarily introduced bias in the system. Conversely, if you want to minimize bias, then you have to train your model on the broadest set of data possible, which necessarily increases the probability of outcomes introducing hallucinations. So our insight here is that you cannot have a single foundation model that minimizes both hallucination and bias. Right? And so the way to solve for a model that has minimal hallucination and minimal bias, and therefore minimal error rates, is to lean on the wisdom of the crowds.
00:17:14.565 - 00:17:54.645, Speaker C: Now you can say, okay, if you say you need five models to get the right answer, why don't you just run it on your own AWS instance? Why do you need to decentralize this? And we think that you can't decentralize this unless you have. You can't actually make this bias free unless you have decentralization. Otherwise you end up in the same situation as big tech today, where Facebook, Google, et cetera, own your data. And they sort of like tell you what to do with your data, right? They sort of like gradually influence you in a certain direction. And so we want to build on top of crypto incentives because we think that that's the only way in which you can have hallucination free, but also bias free content.
00:17:56.265 - 00:18:27.815, Speaker B: Yeah, yeah. So the way that I understand it is like almost what you're building is like an aggregator slash curator of like LLM models at large. Right. And, you know, now when, you know, one other thing that we were talking about that I think is like, you know, what I was excited to talk about on this pod too, it's like, it's clear that you're drawing like a lot of inspiration from crypto. And, you know, can you explain how you think the concepts of like, you know, proof of work and proof of stake apply to AI and what you're building at Mira? I think that would be fun to talk about now.
00:18:27.935 - 00:19:07.627, Speaker C: Yeah, totally. You know, we've taken inspiration quite deeply and we, you know, we've incorporated both proof of work but also proof of stake. So proof of work in the sense of the way you get paid is you actually, you do an actual inference, right? You have to run compute, it costs you money, just like doing a mining puzzle. And you, you know, you get paid for getting the inference correct. Now you can't Just be a lazy inference provider where you, you know, there's a chance where a malicious or a lazy actor basically says, I won't do any inference, I'm just going to give a response and see what happens. But in that case, the probability of you getting the right response falls asymptotically. Right.
00:19:07.627 - 00:19:52.903, Speaker C: And so very quickly we can figure out that you are either a malicious actor or a lazy actor. So what do we do there? We need to be able to slash you. So to slash you, we also have a proof of stake where to be a participant on the network, you need to stake some value upfront and then over time, based on the quality of your inferences, you get paid and that ends up basically generating yield. Now if you do that, you're basically taking value from traditional builders web to AI builders net new use cases in the world. That value accrues to the network. Some major share of that value goes to the people who are providing inference and providing models. So we're actually generating real value, not just made up stuff.
00:19:52.903 - 00:20:30.855, Speaker C: We're generating real value from web2 and providing that value to all of our verifiers. And we think that by doing so we will actually incentivize two things. One, we will incentivize more compute to come online, which would drive costs down over time. And we think we're incentivizing model builders to build fine tuned models. So tomorrow you could have fine tuned models for medicine, for crypto and so on. Right. I would love to see a Delphi research crypto fine tuned model so that anytime somebody wants to verify something crypto related, the Delphi model can raise its hand and the GPU provider can say, I have a fine tuned model for crypto and then they get paid.
00:20:30.855 - 00:20:43.705, Speaker C: So we think that, you know, at scale, at steady state, you're basically building a really, really good pipe of taking value from traditional tech and distributing it to all of our verifier nodes.
00:20:44.565 - 00:21:10.965, Speaker B: Yeah, so crypto, you know, at its core is very good at like, you know, bootstrapping these network effects for sure. But in this example, like what are the risks you see, you know, what are the key challenges you face? And I know, you know, you kind of went over this already with, you know, I think the three you mentioned are cost, latency, accuracy. But I'm curious, like where does crypto fit in to be a benefit for each of those or a detriment? Right, yeah, I'm curious.
00:21:11.465 - 00:21:49.059, Speaker C: So I think over time, you know, being crypto first enables us to provide trustless verification Otherwise you have to trust. And one of the central problems in AI, which is an extension of Web2, is, you know, too much centralization. You, you know, you have inherent bias in the system. And we think that in a world of AI where there's going to be infinite content, it is more important than ever to be neutral. It is more important than ever to know where content came. So just to double click on something, you know, we're trying to do with our network is when we verify, we write the verification to the blockchain. So we say that this was the content and we transformed the content.
00:21:49.059 - 00:22:15.105, Speaker C: So the content is, you know, we won't give away private information. But we say this was every model involved in the verification. This is what the model said about this. It was either valid, invalid, and so on. So you should be able to over time go to every single output from our system and verify, know which model was used, which model wasn't used, and so on. So that gives people more confidence over the output that they're using. And this cannot be done without crypto.
00:22:15.105 - 00:22:28.405, Speaker C: Right. Otherwise you have to again, trust some central actor. So part of this is ideological, but we're working backwards from the perspective that in AI a couple of things need to be true. A, you need to be credibly neutral, you need to be precise.
00:22:28.485 - 00:22:53.685, Speaker B: Yeah, I'm curious, like, are you guys focused on rolling out to a specific niche use case? Right. Like, is it going to be more so focused around, you know, crypto? Is it going to be focused around politics? Like over time? Obviously you want the breadth of the models that are available in this network to be very large. Right. But how are you thinking about go to market and like proving out that this works at a smaller level?
00:22:53.845 - 00:23:20.961, Speaker C: That's a great question. We're actually going with foundation models, but we're targeting very specific niches for now. So what are the niches that care about hallucinations the most? Education, medicine and so on. Right. Like where factuality matters the most is where we'll go first. And then over time we'll work towards more bias free output. Because for bias free you need to be able to generate enough demand that people come build those models, because those models don't exist today.
00:23:20.961 - 00:23:53.155, Speaker C: So think about like any so like political situation where you have two countries fighting over a territory. Right. If the person requesting the verification is in country A, I need to be able to flag a certain set of models. If the person requesting the verification is in country B, I need to be able to flag some other set of models. Because truth is different in both of those countries. So because truth is so subjective, eventually to get to actual bias free outcome, we need significant demand because we need value flowing. We need to incentivize people to build those fine tuned models.
00:23:53.155 - 00:24:48.665, Speaker C: But where we can provide value today is factuality. Right. So if you're, you know, there's, there's a couple of apps now that are doing medical transcription and you know, using AI for medicine and we hear about a lot of errors to the point where, you know, hospitals are beginning to think about are like second guessing themselves on should we even use AI. So those are the use cases where we can make an immediate impact because we can reduce the error space significantly and actually show doctors, show hospital administrators that AI is useful. So education and medicine are the two demand spaces that we are most excited about in the near term, over time, of course, we'll, you know, we'll do this in every single space. Now we'll also borrow from some of the work that, you know, we're doing with you guys and you know, we want to be shipping some crypto focused product as well in the next couple of weeks and months. But from a demand perspective, I think we think education is a huge opportunity, medicine is a bigger opportunity.
00:24:49.685 - 00:25:53.965, Speaker B: Got it, yeah. So maybe I can ask a question that, you know, I was just watching this, you know, one of our interviews and panels that we did on this crypto AI month. My partner Jose had, you know, Casey Caruso and you know, Jake from Coin Fund and you know, Will on, and it seemed like the consensus was that, you know, when I first came out, everyone expected millions of models to emerge. And now it seems like, you know, a lot of the people on that panel seemed to think that, you know, there were going to be some of these, you know, big models from, you know, the giants, you know, like Facebook, like OpenAI, Google, et cetera, and then just mini fine tuned models, um, above this. Now I'm curious how you think this is going to play out. And then, you know, both, bias aside, right. How do you think this is going to play out? And then what, you know, what works best for Amira? I'm guessing it is, you know, this world where it's that first version where it's millions of different models, but I guess you guys could succeed or be useful in either version of the world.
00:25:53.965 - 00:26:16.075, Speaker B: Right? Like I'm curious and why do people, why have people started thinking that way from that panel? My biggest takeaway was it seemed like, you know, the people who were going to start building these Giant models quickly realized how obviously capital intensive it was, resource intensive it was, and how much of a head start some of the, you know, current incubun had. But yeah, I'm curious how you think about it.
00:26:16.495 - 00:26:49.605, Speaker C: Great question. Yeah. If you think about sort of, if you put sort of like outcome on a log scale, it's beginning to taper off a little bit. And so GPT5, if it turns out to be a real thing, I think will be a very important milestone or at least data point for the industry because it'll tell us what the trend is. And if it starts slowing down, then I think people will sort of step away from investing in foundation models. You'll probably see the big houses continue to do that, of course. But my very strong hunch is that there isn't a lot of money in that layer.
00:26:49.605 - 00:27:46.195, Speaker C: Even the way ChatGPT anthropic, they're all making money in the app layer, right? There's a foundation model, but ChatGPT is now building reasoning on top of it. Reasoning is basically an app on top of the foundation model. It's just like local calls, right in a loop. And so I think that I think of like foundation models ultimately as a public utility, it's your electricity company, you know, it's there, you know, everybody needs it, but there's not a lot of money in it. It'll be so like regulated eventually for biased reasons and for all sorts of other reasons. So the question then becomes where else can you make money? Now the foundation model is sort of like this mega tree in a forest, right? It does like a bunch of things in the aggregate order value, but probably makes a bunch of mistakes in specific use cases. And so then I think what will happen is you'll start seeing a lot of these like niche providers pop up, you know, in the way that Amazon does, you know, E commerce broadly.
00:27:46.195 - 00:28:38.835, Speaker C: But then you have E commerce for foo, right? You have companies that do alcohol only or companies that specialize in fashion and so on. I think those fine tuned models will ultimately show up because it'll just not be a good ROI for any of the foundation model providers to go after those use cases. So I think both of them will coexist. I think more of the money will eventually be made in the app layer because fine tuned models is ultimately an API call, right? It's like it's what you do with that, with that output that matters. And that's the interesting opportunity for us because if you believe in the training dilemma, which says that you cannot minimize both bias and Hallucination in the same model, then there is room for an intermodal solution to reduce hallucination bias. And so where I see us going eventually. So today we are offline use case for maybe edtech.
00:28:38.835 - 00:29:19.661, Speaker C: The North Star is basically real time across all domains. And if I can do real time across all domains, then I'm basically building a synthetic foundation model. If you're putting on the product manager hat or at Mira, you're saying, well, customers doing a generation step and then a verification step. Why shouldn't the customer just do generation with us? Like we'll just give you a verified output and nobody else wants to do it because OpenAI is only dealing with OpenAI models. Claude is only dealing with Claude models. We're dealing with all models. Right.
00:29:19.661 - 00:29:45.875, Speaker C: And so by stitching this together, we're now actually building. I want to ultimately be your one stop shop. Like you should just be making a call to me, I'll do all of the background work for you and give you back a reliable response. And so our roadmap basically is on those two dimensions. Right. Is chip away at today batch processing, northstar real time processing today one or two domains, North Star, all niche domains.
00:29:46.735 - 00:29:47.311, Speaker B: Yeah.
00:29:47.383 - 00:29:50.075, Speaker C: And that, that's the journey we take over the next couple of years.
00:29:50.415 - 00:29:57.111, Speaker B: Yeah. So, you know, it makes sense how you're starting with factual based, you know, sectors like medical.
00:29:57.223 - 00:29:57.493, Speaker C: Yeah.
00:29:57.539 - 00:30:41.351, Speaker B: Know education, et cetera. But once you get in more of these niche sectors, like how do you, like how do you grade the reliability of subjective information? Right. Like for example, this, you know, election is obviously top of mind right now. How do you pick and choose what media is accurate or what media is more relevant to the question that is being asked or do you give both sides and let you know, like how do you. Yeah, I'm curious because like eventually a model will have some bias in it, right? Yes. And then what you will you pick not just from one model, but show answers from two different models and like even have them debate possibly. Like I'm curious how you're thinking about that.
00:30:41.503 - 00:31:05.215, Speaker C: That's a great question. So today in like v0 of what we're building, we will just give you a thumbs up or a thumbs down. So say you generate a model that says that, you know, just to pick something more controversial. Donald Trump won the 2020 election, right. You bring it to our verifier notes and everybody basically agrees that that was not true. And so you basically do a thumbs down. So we'll just say invalid.
00:31:05.215 - 00:31:29.229, Speaker C: The future steps over there are okay if I say invalid. Today I'll just give you the flag. But in the future, I want to reconstruct that sentence and say, actually, this is the right sentence. Right. So if you say the president of the, of the United States is Donald Trump today, I just give you a flat thumbs down. The next step is to actually reconstruct that and say, the president of the US Is Joe Biden. Right.
00:31:29.229 - 00:31:56.615, Speaker C: That's the next technology tree for us. Once I have that, then I'm basically able to generate for you. Right. So next time you come to me and instead of saying, hey, here's a statement verified for me, you just say, hey, who is the President of the US And I'll give you the constructive answer. And I've done the verification steps behind the scenes. Now, your point around bias is great. Now, our thesis is that say you have bias, model one with this bias, and model two with, say, this bias.
00:31:56.615 - 00:32:29.231, Speaker C: The overlap is basically this space. Right. And so this is the answer that we'll give you, which we think is credibly neutral. So think of it as a Venn diagram where if you add 3, 4, 5 models, it's that sort of like, intersection space that we want to give you back. Now, there might be scenarios where there might not be an intersection. So that's another, like, technology tree for the, for the product roadmap, which is, hey, give back a sort of like, hey, this did not sort of like reconcile to a response. But here is the mode of the responses, right?
00:32:29.263 - 00:32:29.875, Speaker B: Yeah.
00:32:30.655 - 00:32:33.711, Speaker C: So say you just give an example.
00:32:33.783 - 00:32:34.135, Speaker B: Go ahead.
00:32:34.175 - 00:32:59.729, Speaker C: Yeah, let's say you say, you ask the question, what is the capital of France? And for whatever reason you got, you know, Paris, London, Rome, Frankfurt, Frankfurt as five models. So we, so we can respond and say, look, we didn't reach consensus, but Frankfurt was the model. Right. And so then you can do something with that. There will be some cases where there's just no, there's just no consensus.
00:32:59.777 - 00:33:00.073, Speaker B: Yeah.
00:33:00.129 - 00:33:09.637, Speaker C: And so in that case, we want to give you back what the. More of the responses was or what the, you know, some sort of like, weighted average response was so that you can do something with it.
00:33:09.821 - 00:33:46.357, Speaker B: Yeah. So that, that actually brings me to my next question and kind of like lays it up for me, like, my concern and what I'm kind of like, more confused about is not when there's an intersection and that overlap, I'm actually. Or when there's no overlap, you know, which is like, kind of like your immediate concern. My concern is actually when there is an overlap, but the right answer is Actually on one of the other sides. Right. So like, how do, how does it, like how do you get smarter when you figure out, oh, okay, yes. Like, even though we're giving this intersection, this overlap answer, the answer is actually closer on this side.
00:33:46.357 - 00:34:16.161, Speaker B: And what, like, over time, I guess, using these like crypto incentives and this like, you know, incentives, you'll basically start letting people discount the other side and then they'll just like naturally move over. Like how does that work and how like, does that rely on a lot of usage? Because you know, I'm curious if it relies on a lot of usage, but if it's given the wrong answer, then you kind of like the flywheel can't really develop right where it's like, why would I use this if it's not giving me the right answer? Yeah, how do you, how do you think about that?
00:34:16.273 - 00:34:55.997, Speaker C: Absolutely. That's a great question. And the way we think about it is a, we don't want to take, you know, we don't want to have any editorial on this, right? Yeah, of course we're not going to tell you what the answer is. What we want to do is get the incentive structure in the network such that people have the incentive to come and provide models. So on a thorny topic, right, say you have, you know, you have a couple of wars going on in the world right now and there's people on both sides of the war and they have their own perspective on what's going on. I can't give you an editorial view on this party is good, this party is bad. In fact, depending on where you are in the world, you might have a very different view of what reality is.
00:34:55.997 - 00:35:56.567, Speaker C: And so the way we're approaching this problem is for some of these thornier issues, we believe if you have the right crypto incentives. So money is flowing through the system and model builders are making money, inference providers are making money. Then folks will be incentivized to put their unique perspective into a fine tuned model and host it in our network. So the way you, you know, the way you work with us as a, as a model builder is you come to our website and you basically submit your, your model to be part of our registry. And so then a GPU provider can basically host your model and raise, raise their hand when a relevant question comes up. So say you have, you know, say it was a Civil War question, right? Like just to make this like a little bit neutral, say it's, you know, we're back in the 1800s, the Civil War is going on, someone's going to be there with a model representing the north and someone's going to be there with the model representing the south. And then we'll hash it out between those models and they might not reach consensus in which case we'll basically just return and say, hey, look, here's the verification.
00:35:56.567 - 00:36:15.825, Speaker C: Three models said south is winning, four models said north is winning. You do what you want with this and then it's up to the app builder. It's up to the customer to either say, I'm going to pick four, which is the north, or provide a more balanced view saying, hey, on balance it seems like the north is winning, but the south isn't doing too bad either.
00:36:16.165 - 00:36:40.695, Speaker B: Got it. That's interesting. Yeah, I guess like, you know, like I'm curious like what the future looks like for Mira. You know, you're one of the builders that I'm like really excited as, like finally come and join us, you know, in crypto. I've tried to kind of, you know, we've known each other for a while and I've tried to kind of red pill you and get you to join. You've done so. Yeah, yeah, yeah.
00:36:40.695 - 00:37:13.039, Speaker B: Finally over time I try to get you join like a lot of our Porkos and stuff like that too. I'm kind of curious. Two questions. One, the first part is maybe the first part should actually be the other question which is, you know, what are some crypto AI projects that you're either following or think are interesting or even are building in a similar lane or vertical as Mira? So maybe like the audience could also understand, oh, okay, Mira kind of fits into this version of the stack if they're more familiar with some other crypto projects. And then the second question is more so like what does the future look like for Mira? Right. Like how do you see this evolving?
00:37:13.167 - 00:37:58.387, Speaker C: Yeah, absolutely. You know, we've had a couple of great partnerships. You know, we're building out our testnet and we'll have some early, you know, early work going out later this month. Partnering with our friends at akaKast network for GPUs with Hyperbolic, you know, working with Sentient on some fine tuned models for some of our products and so on. So like we're partnering with a bunch of folks, we're friends with the folks over at Noose Research, speaking with Shivani later in the week as well. They can bring their perspective and they can sort of bring their fine tuned models. I think that our key partnerships will be with inference providers because similar to being a validator on eth we need compute because of the proof of work aspect.
00:37:58.387 - 00:38:33.373, Speaker C: And so we'll be working closely with inference providers and then we'll be working closely with model providers. Right. Because besides just the foundation models that everybody knows about with Llama and whatnot, we need as much diversity of those models as possible. We just discussed that on this call. And so those are the two areas that we are focused on the most in the crypto world for the rest of our work is on the demand side, which is in Web two. Right. We need people building traditional businesses, traditional tech companies, you know, using our evaluation and verification services to make sure that they can build production grade software.
00:38:33.373 - 00:39:02.615, Speaker C: And so we find ourselves in this unique position where we are so like bridging crypto and Web two very seamlessly. Right. Our demand is all web two and our supply is all web3. So it'll be, you know, we find ourselves as somewhat novel in that regard. And that's what excites me. That's one of the reasons why, you know, I wanted to build Mira is, you know, we see a lot of talk about crypto AI, but oftentimes it feels like there's a, like a bit of a forced narrative. You know, this one was more of a let's peel the onion.
00:39:02.615 - 00:39:42.733, Speaker C: And it turns out that blockchain and crypto is the only way to make it happen. The future for us is basically, you know, testnet in the next couple of weeks. We already working with a couple of demand, you know, some couple of customers for our services. And so, you know, just start generating some revenue over there and scale, right. So we talked about Ed Tech being a big opportunity, medical being a big opportunity in the near term. But if you think about that roadmap, we have to go from offline batch process, lower latency, edtech, medical to real time, every single domain at scale. And that's like a multi, multi quarter, multi year roadmap because you just have to keep chipping away at every single one of the dimensions.
00:39:42.733 - 00:40:03.921, Speaker C: Right. Improve cost, improve latency and improve accuracy. So we're building this like a very, you know, we've got a solid team building this like a traditional tech company. And traditional not in the sense of like slow moving, but traditional in the sense of have an actual product, have an actual technology stack and just execute. Right. The thing that big tech nailed in the last era was not tech. They nailed execution.
00:40:03.921 - 00:40:10.565, Speaker C: Just show up every single day and improve. And that's how they conquered the world. And that's the skillset we're bringing to the tables.
00:40:11.595 - 00:41:30.121, Speaker B: Yeah, for sure. That's something like what I'm most excited about, especially because, you know, when we had our first conversation basically right before this call, one thing that kind of stuck out to me was how, you know, and this is something that our team spends a lot of time on, both on the research and the ventures division is thinking about why crypto is needed for this AI, application infrastructure, etc. And what was novel here was, you know, exactly what you talked about earlier about how you're using, you know, proof of work and proof of stake, you know, in unique ways to kind of, you know, again, build the infrastructure in a web3 way, but build a product for Web two users. So, yeah, I think it's going to be, you know, it's one of the projects that I'm more excited to kind of see bridge kind of that gap and hopefully show more, you know, AI, traditional Web2 builders, the power and why crypto is important. And I think that's probably where, you know, maybe I can kind of like, you know, we can start ending on is, you know, you've worked at, you know, Uber, Amazon, like really high up at both these places. And that's why I've always loved having conversations with you, because you've seen teams scale, but also products kind of like form from, you know, nothing like an idea in Bezos head, and then kind of like you help execute and bring it to market. Like, you know, the.
00:41:30.121 - 00:42:08.723, Speaker B: There's this common. And I think this has always happened in crypto, which it's not really taken seriously by the industries it's trying to disrupt. And I think this is happening again with AI, right? And I think more than ever actually where, you know, a lot of the builders that we've been able to support, they're like really tier one builders, both in the AI and crypto worlds. And we're kind of like helping them bridge the gap. But it seems like there's this huge kind of like negative connotation of crypto when you're talking to like AI builders. And hopefully, you know, this month has changed it with what people have seen with Truth Terminal, Mark Andreessen and Ben Horowitz doing all that. But like, what's your sense of that? And obviously you've kind of jumped come join the dark side.
00:42:08.723 - 00:42:30.443, Speaker B: Like, how. How have your friends kind of like, you know, are they kind of making fun of you for that, taking that leap? Like, and why do you think that is? Is something that I'm always curious about. Obviously crypto has a lot of crazy things that always happen. But, um, I think it's just like a very fundamental, like, interesting technology that people should be taking way more seriously than they. They are.
00:42:30.619 - 00:42:49.851, Speaker C: You know, I think it's. I think it's. It'll change the world. You know, been. Been a crypto lurker for a decade now. You know, got sort of like red pill back in, you know, 2008, nine, when Barry Reholtz used to run that one blog after. After the GFC and, you know, early biology videos and whatnot.
00:42:49.851 - 00:43:07.641, Speaker C: Right. So, you know, I think the idea has always been there, but there's also always been a lot of money to it. And I think, you know, there's. There's. This is not one answer, right? There's like many different. It's a nuanced situation. But I think if you think about this as like the elephant and the blind men.
00:43:07.641 - 00:43:41.905, Speaker C: I'm. I'm one blind guy. Thinking about this as. Typically, if you want to scale a business or a product or what have you, you have to have some sense of the. Not necessarily the end state, but you have to have some sense of like, you know, what you're working backwards from, right. What is the customer problem or the business vision and so on. With crypto, it's always been a little bit backward in the sense that there's so much money with token launches and iqos before that and so on, that we usually end up narrative forward or supply forward as opposed to demand backwards.
00:43:41.905 - 00:44:15.835, Speaker C: Right. And so, you know, the best products or the best businesses get built where you're either building backwards from a defined customer pain point. So like a lot of enterprise SaaS, is that right? A lot of enterprise businesses will not write their first line of code until they have a committed customer willing to write them a check saying, you know, you build this, I will go, you know, write a check. You know, with consumer products, it's a little bit different. You at least have a strong hypothesis. You may not have a dollar, but you have a very strong hypothesis on this is a customer problem. Here's my solution.
00:44:15.835 - 00:45:12.565, Speaker C: If I build this well, people will buy it. With crypto, I think that piece of like, you know, what I'm building for is usually a little bit lost in the larger scheme of things. We're so focused on show this big vision and raise this round, or show this big vision and do your token launch that we sort of lose sight of building, you know, and so I think what we need to do is invest more effort in just thinking about what is the specific use case you want to build for and somehow get the incentive such that people don't make their money before the. Before the product is launched. How do you sort of like, you know, just like realign incentives to the point where a. You're building towards a defined problem. Now, in our case, I feel very lucky that we think we have defined demand from Web2 and so we're not chasing a narrative for us.
00:45:12.565 - 00:45:46.433, Speaker C: Actually, it's not demand risk, actually it's execution risk. Because the thing is complex enough bridging the two. The thing that I didn't talk about in this discussion is when you talk about verifying something, I give you examples like, what is the capital of France? That's like a single line with the binary response. Right. But, you know, you may want to use my API to verify an entire essay. How do I do that? And so there's a lot of work that we'll have to do on the tech side to take these complex outputs and then make them verifiable in the first place. And that's our secret sauce.
00:45:46.433 - 00:45:50.165, Speaker C: So we actually don't have that much demand risk. We actually have execution risk.
00:45:51.145 - 00:45:57.835, Speaker B: Yeah. Why are you so confident that you have this web2demand? Like, what gives you that confidence?
00:45:58.455 - 00:46:33.765, Speaker C: So, you know, we've been working with a couple of partners already. You know, we can dial up like, you know, our revenue to like non zero next week if we wanted to. You know, we're further refining the product and further refining the test net for now and then speaking with all of these builders and like, you know, doing research. We built several apps ourselves earlier this year, as you know, and we'll be on a run rate to a billion plus tokens inferred on a daily basis by end of the year. So, you know, we're seeing enough demand there and we're seeing enough signal on what, what the challenges are that we feel good about. There's something bigger. Awesome.
00:46:33.805 - 00:46:48.527, Speaker B: Yeah, definitely. Really exciting, I guess, like, you know, both for myself as well as, like, you know, people watching this, like, how can they keep up with Mira? What should they be looking out for? Yeah, any. Any other parting words that you want to say before know we hop off?
00:46:48.711 - 00:47:18.585, Speaker C: No, you know, thanks for, thanks for taking this time and for the great conversation. You really pushed me on a couple of very important aspects of, you know, both AI and Mira. We're on Twitter at Mira Network, you know, please follow us there. And we'll be launching a couple of papers in the next couple of weeks. You know, we've been a lot of what I just talked about here is backed by original research that we've we've done over the last couple of months. And, you know, you'll see our papers come out soon. You'll also see a paper that we are quite authoring with Anil and the folks at Delphi because there's some exciting updates coming at front as well.
00:47:18.585 - 00:47:23.125, Speaker C: So hopefully we'll, you know, you'll hear more about us through Delphi channels as well.
00:47:23.505 - 00:47:41.783, Speaker B: Yeah, absolutely. I think, like, you know, the report and the paper on reducing error rates and the reliability was, like, one of the most interesting things I've read recently. And, yeah, that's honestly why I was excited to have this conversation. So. Yeah, it was great having you on. Appreciate you. Appreciate the time.
00:47:41.959 - 00:47:43.235, Speaker C: Awesome. Thank you.
00:47:43.775 - 00:47:44.375, Speaker B: Thank you so much.

00:00:00.360 - 00:00:01.713, Speaker A: Before we get started, we'd like to.
00:00:01.729 - 00:00:12.409, Speaker B: Thank our sponsors for making this event possible. Special thanks to our platinum sponsor, olas. OLAS enables everyone to own a share of AI, specifically autonomous agent economies.
00:00:12.537 - 00:00:14.377, Speaker C: We're also excited to highlight our silver.
00:00:14.441 - 00:00:35.857, Speaker B: Sponsors near empowering decentralized applications and blockchain ecosystems. Venice AI a private and uncensored alternative to popular AI apps. Mira unified AI infrastructure secured by crypto and the first on chain multi agent system. To learn more about all of our sponsors, check the description below and dive in.
00:00:36.001 - 00:01:23.171, Speaker C: Enjoy the show. Hi everyone, your host here, Jose Marie Mercedu. And today I have a really exciting panel on crypto xai, a very controversial sector and we're going to go into it on which areas are most interesting and also which areas are least interesting. Trying to get a bit of, make it a bit spicy because I think panels can be quite boring. So we're going to try and make this a bit of a debate and I'm joined by some of the best investors and most prolific investors in the crypto AI space so far. Maybe to start with you could all, we could go around the horn, you could all introduce yourselves and and your funds.
00:01:23.283 - 00:01:56.689, Speaker A: Hey guys, I'm Will. I'm an engineer by background though not a, not a machine learning engineer. So still, still working on getting up to speed there, but was involved in a few startups before going down the crypto rabbit hole and then most recently was at Polychain for the last five years and you know, did a bunch of things there. But one of the things maybe most relevant helped incubate Bit Tensor back in 2019, 2020 and sort of, you know, have done a lot of thinking in the crypto x AI space since then. So just launching my own fund called Arch Capital this year and getting that off the ground now.
00:01:56.777 - 00:02:19.945, Speaker B: Awesome. I guess I'll go next. My name is Jake Brookman, I'm the founder and CEO of Coin Fund. I'm also actually an engineer. My background is in math and computer science. Been studying blockchain tech for about nine years and investing in the space full time. And then my journey with AI is just that I've been following AI for a very long time, have a lot of acquaintances and friends who work in that industry.
00:02:19.945 - 00:02:40.841, Speaker B: And more recently as we've started to make this very palpable tangible progress in AI, there has developed this intersection between AI and Web3 which is really, really interesting to Coin Fund and we've been watching that from our first investment there, which was Worldcoin at the end of 2020. So excited to talk about the elements of how we see that space.
00:02:40.953 - 00:03:25.525, Speaker D: Awesome. I can wrap. Yeah. My name is Casey Caruso, also an engineer, classically trained computer scientist and spent most of my career at Google as an engineer on a few different teams, but mainly on an exploratory machine learning team as well as course search and then spent a lot of time at Bessemer Venture Partners getting classic venture experience and training and then most recently was an investment partner at Paradigm. Left in 2023 at the beginning of 2023 and just this year started my own firm called Topology, which is a frontier tech firm. And we invest in a few different areas, but the intersection of crypto and AI as well as them independently, crypto and AI is where I spend a lot of my time.
00:03:25.685 - 00:03:52.717, Speaker C: Very cool. All right. I think to get started, obviously everyone on this panel is generally bullish on AI and bullish on crypto and AI, but this definitely isn't the case across the crypto space where a lot of people, it's probably the most controversial sector where you see the smartest investors, kind of a very bearish stance. Like even very smart investors take. Take bearish stances on it. So. And the main criticisms is generally that the big AI labs have almost all the talent.
00:03:52.717 - 00:04:29.737, Speaker C: Most AI people don't want to touch crypto and, and so they. Most of the crypto AI stuff looks to people like there's no product market fit and it's like solutions looking for problems. Kind of the classic crypto criticism in a sense. And I'm curious how, how do each of you respond to this skeptic? You probably spend a lot of your time speaking to AI people, AI engineers that potentially looking to build something in the space. How do you respond to the skeptic? And feel free if you want to cover, if it's relevant to your response to cover, like your AI thesis and kind of where crypto fits in, that's good too. Maybe we can go, we can start with Casey this time and then go around the horn.
00:04:29.841 - 00:05:10.205, Speaker D: Yeah. The first thing I would say is that the skepticism is well warranted and we're going day by day here. It's a really nascent category, but I do think there's a lot of promise here and some early signs that going to materialize into a really robust sector. One thing that I think is underappreciated is how good open source is getting and how that is a foundation for crypto AI. So llama 405B is basically, if you look at all the benchmarks at parity with GPT4. And I think some of my smartest friends, I'll have people that say state of the art will always be closed source. State of the art is going to be open source, but they're close.
00:05:10.205 - 00:05:57.937, Speaker D: It's definitely, um, it's a gray area. And that alone is going to be the cardinal kind of substrate that crypto AI and decentralized AI can build on. And so if nothing else, like, even if nothing else is working, if you're bullish on open source, you almost have to imagine that this sector and this group of people is going to leverage that to build products on. And so that's one thing that I think isn't spoken about enough, but in general, and then I'll pass it on, is that, yeah, I completely understand the skepticism. I completely understand that there's like a lot of meme generation and just like not super educated opinions in the category, but we'll dive into today, I think, where we think it is. And yeah, I think you have to balance confidence as well as being humble in this, in this space.
00:05:58.081 - 00:05:58.473, Speaker C: Jake.
00:05:58.529 - 00:06:41.925, Speaker A: Yeah, I can, I can jump off of what Kasey said. So I agree completely. And I also think as these models, both the closed and the open ones evolve, you know, let's say LLAMA is, you know, 95% as good as, you know, 01 or whatever you want to compare it to, you know, even if it only stays 95% as good as they're all getting better, like that remaining 5% delta or 2% delta or 1% delta becomes less and less relevant for more and more use cases where it's like only very, very specialized use cases where that extra 0.1%, 2% matters. And so I do think we're going to close that gap really quickly. And then on the crypto side, and one of the areas where I think crypto can be beneficial is that crypto is very good at sort of.
00:06:43.625 - 00:06:43.889, Speaker D: I.
00:06:43.897 - 00:07:43.375, Speaker A: Guess, distributing incentives in a way that can sort of distribute the capital intensity of something or actually take advantage of people in different locations that have lower cost of capital for whatever reason. And I think we're seeing a lot of that with sort of figuring out how we can use incentives in the BIT tensor ecosystem. And we've even seen with some of the work from Noose Research and some of these other teams where you can use these incentives to fine tune some of these models in a much more, I don't know if I want to say beneficial, but in at least a very different way than even like Facebook is fine tuning them. You know, get different outcomes, maybe more neutral outcomes, maybe fine tune them in more ways that the community finds beneficial or even specialized use cases. And so I think any of the areas where we can sort of like leverage incentives and getting people sort of anywhere in the globe to use their resources to improve a system is, is kind of where I'm interested in crypto, AI and crypto generally really awesome.
00:07:43.835 - 00:08:27.429, Speaker B: Well, I think on AI broadly, I'm like a bit of a moderate. I don't think that we're going to get AGI tomorrow or probably in 2027 though I recognize we're making really good progress in general. I just think that we need more breakthroughs and to push the state of the art before we could really get to something very impressive. But I'm also bearish on a lot of the common narratives of AI. For example, that there's going to be this huge power law where, you know, one model will win. I think we're very clearly seeing, just like in blockchains, you know, there was a time when people said bitcoin is the only blockchain you'll ever need. Look, the functionality is there, what more do you want? You know, it's just going to eventually take the whole market.
00:08:27.429 - 00:09:26.501, Speaker B: I never thought that thesis was good or true and it has not played out that way. And I don't think that it will play out that way in AI models as well. I think people want to innovate, they want to try new stuff, they want to subvert like even neural networks themselves. They'll find compute, they'll find ways of creating efficiencies and ultimately we'll be in a market where there's going to be a lot of AI models going around. I'm also bearish on again this idea that like the compute race is lost. You know, I think that compute could actually get really, really cheap very soon. Because, you know, a lot of the investments that we've made in compute are based on the ideas that intelligence will scale kind of linearly with compute, but if it scales sublinearly, which I think is a possibility at some point, you know, then we suddenly have this oversupply of compute.
00:09:26.501 - 00:10:16.515, Speaker B: In any case, we're over invested in compute either way, so going to get oversupplied at some point, it's going to get cheaper. What I'm very bullish on is, you know, the intersection of Web3 and AI. And the reason that I'm bullish on it is because I want Web3 to bring its core value proposition to the world. And this is a very promising area with a lot of recognition, a lot of utility, a lot of applications where we can do that. What is blockchains and Web3's core contribution to the world? A lot of people historically have said that it's efficiency, technology, and to some extent that is of course true. But to me, you know, the legacy of blockchains will be building open public goods. And that is what we are bringing to Web three.
00:10:16.515 - 00:10:54.465, Speaker B: We're creating a way that people can have a pipeline that generates AI products, models, inference training, search, compute, et cetera, and even going to market, productization, monetization, et cetera, in a way that is open, global and public. And I think this idea of distributing AI throughout the world in some time will be seen as a very, very important aspect to it. For example, from the perspective of making it safe or making it accessible and making it democratic. So that's why I'm here.
00:10:54.585 - 00:11:49.245, Speaker C: Nice. Yeah. A lot of you touched on the open source portion and how important that is to the success of crypto. I guess I have a two part question there. The first one is, are we all just reliant on Zuck continuing to open source his llama model, or is there, do you see an alternative to that? And I guess the second one is, what is it specifically, I guess, about crypto? Because you could see a world where open source AI still succeeds without any crypto involved and you still have this modular model world where there's millions of models and there's orchestration layers and all this, and none of this necessarily needs crypto to exist. And I'm playing devil's advocate here, but could you drill down on what you think? I guess the most important features of crypto are that it adds on top of that, on top of the open source stuff. So yeah, two part.
00:11:49.245 - 00:11:54.877, Speaker C: Are we dependent on Zuck? And then what specifically is it about crypto that that makes that?
00:11:55.021 - 00:12:33.097, Speaker A: I think. Yeah, yeah, I think, I think the Zuck thing is a really good question and something I think can talk about a lot. I think like right now the answer is like mostly we are kind of dependent on them for like state of the art stuff. I think that I'm not as worried about it in the near term because I think they actually have like a reasonable business model and business case to keep doing that. And you know, Zuck has written about it a couple times, so I'm not like too worried that in the next like five years that they're going to stop doing that. But there Is there is another threat where possibly the government could force them to stop doing that. And we've seen some things in, in California that haven't passed, but that they've tried to do that could severely limit that.
00:12:33.097 - 00:13:20.043, Speaker A: So I think it's a very real threat. But that being said, on the flip side of the coin, and I know Jake has been deep in this area too, but I think there's a lot of interesting things going on right now with like ability to do distributed decentralized training and federated training. We're kind of only at the cusp of that. And it also might tie into how we can use crypto incentives to get access to more data as well, and possibly private data to be able to train distributed models that might be able to compete or out compete with, with a llama. And I think, I think in the next couple of years that's actually possible. So I think we, you know, we have this window where we are reliant on Zuck largely, but I'm not too worried about it. And I think we have a light at the end of that tunnel where if we, if we can get to the right things, we can become less and less reliant on that pretty quickly.
00:13:20.219 - 00:14:13.155, Speaker B: I think that, I think we are reliant on Zuck for a lot of open source today. I think it's a really bad idea to be relying on Zuck. I think if you go listen to Zuck's podcast with Dwarkesh, which is freely available, Zuck will tell you himself that, you know, at some point when it becomes convenient for Meta, they will close source the models and monetize them. So I do not think we can rely on open these open models for forever. And also the openness of these models is, I would say, questionable. Right, because what does openness mean today? Openness means that Zuck has given us the weights and biases of the neural network, but what Meta has not given us is the data upon which it has been trained, the training setup, you know, the hardware setup. These are the things that are really important to making a competitive model.
00:14:13.155 - 00:15:30.703, Speaker B: So even though it's open source, it's not open source in the way that is, you know, that that allows someone to like, truly compete with it and which sort of segues into another really interesting concept. Like if we have true open source of AI, I think the openness of setup versus the openness of weights is really the thing that democratizes the ability to construct models. Right, because that, and that allows someone to come in, crowdfund their Own resources, fork a model, make it better, et cetera, and also democratize a lot of data pipelines and so forth. In terms of the value props that, that we're bringing here, I think, you know, on the compute dimension, I think if we think that we can build larger, more effective networks than a Meta or an OpenAI to train these kinds of things, then the only way that we're going to be able to do that is through a decentralized setup because that will be the only way we can, you know, source enough compute to do that. Well, you mentioned incentives. We have a number of companies in our portfolio that are using incentives in AI context. Worldcoin would be one.
00:15:30.703 - 00:16:22.601, Speaker B: But more pertinently, Kiva AI is a data labeling network which is trying to use incentives to create a better supply side of humans for data labeling. I mentioned compute and then decentralized training, which is a big topic that I think I've, me and Casey have gone back and forth on many times and I know Will you're interested in, but I do think we're going to push the state of the art there to a point where we're going to start to see essentially a race of people creating bigger and bigger models using decentralized frameworks. We're very early in that process, don't want to oversell it, but I think it is starting to happen and what it will do is it will really democratize the ability of individuals, scientists, companies, governments, et cetera, all over the world to, to participate in the AI pipeline.
00:16:22.713 - 00:17:40.573, Speaker A: One thing on that last point, I agree with Jake. I think we're still in this race of bigger and bigger models, both in the centralized world and if we can get there in the decentralized world training the bigger and bigger LLM, I think at some point we will likely get better benefits from having a bunch of smaller models tuned for certain things. And this is the agentic, multi agent world where we have specialized, possibly fine tuned or specialized trained models in all types of different topics and you sort of have like a good enough model to know which models to call out from and sort of if things go that way. That's a world where I think decentralization has a lot of benefits because we don't end up with this sort of like walled garden where like if you're going to use that in OpenAI's ecosystem or Apple's ecosystem, you can only use the sub agents that they've built out versus like you know, every subreddit out there or every company could build their own like sub model or smaller model that's specialized in, in like, you know, knowing everything about a Ford truck versus a Toyota and like you call the right model based on what questions you're asking it. And so I think, I think it's likely we go that direction eventually. And if we do, I think decentralization has some advantages over sort of the centralized walled garden approach.
00:17:40.709 - 00:18:10.031, Speaker C: Yeah, I'll let. Casey hasn't responded, so I'll let you respond. But just curious there, because the decentralization approach, like, theoretically you could still achieve that without crypto, right? Like, you could have someone build this with an open source standard, like Zuck has professed that he wants to do, rather than have a walled garden. So, yeah, I guess all of you kind of focused on the incentive side, which I think is also the most interesting. But, yeah, curious what you think, Kasey.
00:18:10.183 - 00:18:48.215, Speaker D: Yeah, I can try to surface some things that haven't been said. And I also just want to push back on Jake on one thing, which is that definitely, definitely Mark isn't open sourcing the data. And I think there's a pretty good reason of why he's not doing that, which we can get into, but he is. I feel like you missed an important part, which is that, yeah, you know, they're, they are publishing the initial weights. They're also publishing the open architecture, which is, you know, how many layers there are and exactly how the net is constructed. And that's really helpful in recreating it. And so I just want to call that out because I think it is important and I think we do talk a lot about like, open source and then nobody defines, like, what is actually open source.
00:18:48.215 - 00:19:22.335, Speaker D: And all of us are engineers. So like we, we know how to go to hugging face and see what's actually published, but I think just to like, teach. I mean, whoever in the audience doesn't know, like Jake said, it is the initial weights which then, you know, over back propagation and whatnot, like those parameters are tuned and optimized and then they're also open sourcing the actual architecture of the net, which is really helpful. But as Jake said, they are not usually saying, sometimes this is not true, but sometimes, at least for Llama, they're not saying, here's the dataset that we all trained on, probably because there's a lot of proprietary stuff in there or stuff that Mark shouldn't be training on.
00:19:22.915 - 00:19:35.243, Speaker B: So, yeah, it's a really good point, Kasey, and if I can have like 30 more seconds, I just love to, I just love to come back to you on that, which is that like, let me state my criteria for what I'm looking for. Right, okay.
00:19:35.299 - 00:19:35.651, Speaker D: Yeah.
00:19:35.723 - 00:20:08.235, Speaker B: Like I want digital technologies to be lowering the costs of entry to like everything. So you know, you think of YouTube, wow. It's a technology where you can get an audience of like millions of viewers potentially very, very quickly just by uploading a video, you know, onto a website. And you used to have to become a movie star to be able to do that. Right. So we've lowered the cost of this type of distribution, you know, to basically zero in some sense. So like what I'm looking for in terms of AI openness is so I appreciate you're right.
00:20:08.235 - 00:20:26.659, Speaker B: Like it's probably like a little bit more open than what I said. It's a little bit less open than total openness. But, but the criteria that I'm looking for is like can a new person sit down with this model and sort of like one click, fork it and make it better? Like what's the cost of doing that?
00:20:26.787 - 00:21:41.729, Speaker D: Yeah, yeah, well that, but that gets into another topic which is if fine tune models are going to be the way that we make these specialized models in the future. Like it seems like one thing that all three of us are aligned on, which I'm surprised, is that this whole like one model wins all is just not, not how the world is going to play out. But then the question becomes, look, the question that keeps me up at night or one of the questions that keeps me up at night is are we really going to retrain and pre train new models or are there going to be like five to six base models and then everyone's just fine tuning on top. And I think one thing that I've seen a lot of in the Valley is that all these companies and actually if people haven't read this article from Swix, which is a friend from Pure AI World, he did an amazing piece on how each one hunters are getting commoditized down and exactly what Jake said where the basically the supply and demand gap between COMPUTE is already starting to narrow. But one thing he talks about is how all these startups raised for training their own base model and they basically said like look, we're Stanford grads, we think we can do what OpenAI can do. If we have enough capital, we have enough compute, we can, we can train something from scratch. And then people went to try to do that over the last year and realize it's really, really hard.
00:21:41.729 - 00:22:01.809, Speaker D: And instead of training base models, now those companies are pivoting to doing fine tuned Models on top of base models and not doing pre training at all. And so that's just a dynamic that I think we should debate. But Jose, to answer your question on kind of like the where is crypto uniquely positioned to help AI? Would it be helpful to comment on that still?
00:22:01.977 - 00:22:02.905, Speaker C: Yeah, yeah, definitely.
00:22:02.945 - 00:22:55.145, Speaker D: Okay, I'll go quick. So one mental model that I've been using over the last month or two is these are the three questions that I think are kind ruling this entire intersection. So the first is how do we live in a world where data is key and king? And under that sub bullet there are things like data ownership, data aggregation, data collection incentivized by tokens. Also data providence which is pure cryptography, not even crypto like cryptography as just an industry of how do we stop the deep fakes and are we going to stop the deep fakes? And on that the next question I ask is where are we going to get the compute? And so there's a few sub bullets under that. It's like well H1 hundreds are now extremely cheap because we overproduced and now they're already getting antiquated. So we'll see how this materializes. But within that subcategory there's like distributed compute, distributed training, all of those companies which we can talk about.
00:22:55.145 - 00:24:00.355, Speaker D: And yeah, we'll get into that. And then the final one is what does the future look like with the agentic workloads? I'm a huge agentic bull in that I feel very strongly as a software engineer that these fully autonomous loops are going to work in a big way. And I think that in that world there's a lot of places that crypto might uniquely enable it. Probably the most peddled one is could it be possible that agents use crypto rails for all of payments? And the reasons for that is basically two. The first is if these agents become self sovereign, which I'm not the biggest fan of that that logic but if they do then they won't be able to open bank accounts and so they're going to need a payment that they can use. Then the other one that I'm actually still investigating is could, could the SaaS business model become superseded by something such as like micropayments or microtransactions where they would need to use crypto rails because we basically need to lower the take rate between transactions, if that makes sense. And so that was a long answer, but that's kind of like the three categories which I think within.
00:24:00.485 - 00:24:21.615, Speaker C: Yeah, that's cool. Fully sovereign AI can get Pretty weird. I don't know if you've been following the Truth terminal. He's now looking for inflatable butt plugs, it looks like in his latest tweet. So, yeah, fully sovereign AI is AGI is here and it wants inflatable butt plugs. Apparently no one predicted that one. Interesting.
00:24:21.655 - 00:25:18.491, Speaker A: I mean, I think something crazy on the last point you made, Casey, is we've already seen it with the cost of these existing models, right? What I think GPT 3.5 costs like 99% less today than it did when it launched like a year and a half ago or less. And so there's kind of this and that ties into the supply of compute as well, right? It's like we've got this compute that keeps getting better in certain ways as Nvidia releases the next chipset and whatever, you know, AMD is trying to compete. But then also we're improving the algorithms and both for training and for inference to require less. So I actually think there's like, it doesn't seem like, at least for inference and stuff, it doesn't seem like there's like a super shortage, but I could see where it could, could come up. And then there's also the interesting thing, maybe a couple of years down the road of like powering all of these things, we see all of the, all of the big guys, you know, partnering or building nuclear plants now. And so like, what is this going to do for energy is going to be super interesting.
00:25:18.683 - 00:25:47.415, Speaker C: But even if compute and energy both get super cheap, as long as capabilities increase linearly or maybe even sublinearly, the dynamic still plays out with compute. It's still going to be an economies of scale game where the big guys have a massive advantage. Right? Like if you've got $8 billion like Elon does to spend on compute, you're still going to be able to produce much better models. I saw you disagree there, Jake, or do a disagreeing face. What are your thoughts?
00:25:48.075 - 00:26:23.009, Speaker B: Well, again, I don't know. I. Like that's a really good question. Like, does intelligence scale linearly and sublinearly? Well, maybe you can, maybe you can clarify a little bit like your point. You're saying if it's scale sublinearly, people are still going to have an advantage. I kind of feel like if that happens, then, you know, a lot of people who spend billions of dollars on these big data centers are going to feel like they wasted a bunch of money. Like they, they put in a bunch of money, didn't get the intelligence that they thought they were going to get and now they have to like repurpose their data centers for something else.
00:26:23.057 - 00:27:09.733, Speaker A: That's, that's kind of what I was going to say is these big guys will continue to obviously be able to spend more than, you know, a startup or maybe a decentralized ecosystem, although maybe that's not true either. But I think they also have to worry about like their cost of capital and their return on capital. And like if the returns on capital aren't there, will they slow the investment? And I think that's a real, you know, there's already a lot of talk about that in the, you know, even in just the web2world or amongst these, these big guys that have significantly. I forget what the numbers are, but I think, you know, Google Meta, these guys have almost tripled their capex in the last year and a half, almost all on AI. And you know, it remains to be seen what the returns on that investment is. And over three, four years, as we find out, they may be forced to pull that back. And so it's not necessarily that they can't outspend, it's that they, it's that is that the most effective way for them to spend.
00:27:09.819 - 00:27:23.321, Speaker C: I mean all the big tech CEOs have been pretty strong on like we think this is existential to us and we think the risk of underspending is way bigger than the risk of overspending. So we're going to, we're going to kind of keep spending.
00:27:23.513 - 00:27:30.297, Speaker A: Yeah, but that can only go for so many years. If they're, until they know, until they know that they're right or wrong. And we don't know yet.
00:27:30.481 - 00:27:50.557, Speaker C: But do you think. Yeah, I'm curious, do you think they're, they're going to be right? Because from my perspective, like I do think they're going to see the return on it like, because it's not just revenue creation, it's like cost compression too. And like even if you look at return on invested capital for these companies, they've obviously laid off a ton of people in the meanwhile too and it still looks pretty strong on all of them.
00:27:50.621 - 00:28:27.505, Speaker A: So my, my base case is that I don't think that they will in aggregate. I think the, the outlier as to why I would be wrong. Was there some, I think new application that we haven't seen yet that has a stronger moat than the things that we have seen so far. So I think like my example with OpenAI and ChatGPT, you know, they're, well a, they're not Making money. And they're the cost of like the last gen model is going down 99% and so eventually the last gen model is good enough for like 99% of people. And it's like basically free. Right? So I think it was maybe like two years ago Steven Sinofsky wrote a piece on AI.
00:28:27.505 - 00:28:56.187, Speaker A: I think when like ChatGPT 2.5 came out or something, and it was like comparing it to when Microsoft invested a bunch and came out with grammar check and everyone was like wowed by this grammar check. Like the computer could understand grammar and you know, how much was Microsoft gonna make off of this? And now it's like, you know, you wouldn't ever use any email editor or text editor that doesn't have it, but nobody's really like raking in money because they have the best, you know, grammar checker. I think AI could, could be very similar to that or LLMs at least specifically.
00:28:56.211 - 00:28:58.859, Speaker D: I like that anecdote that lands well.
00:28:58.987 - 00:29:04.967, Speaker A: Yeah, for LLMs at least. AI in general, maybe there's some different dynamics around other, other types of models.
00:29:05.031 - 00:29:37.699, Speaker D: But I agree with that. I also think with where we're going with embodied AI or robotics AI, that intersection will be a stronger moat because you're actually touching the end user. But the fact that we're going to pay a premium for these models is so we just need to see how the chips fall there because they're becoming so commoditized. And like Will said, I mean, everyone's chasing the next flavor of the month, but what we're kind of stopping to realize is that all the previous flavors, we could improve the economy by a multiple if we just invested in integrating those. There's so many.
00:29:37.747 - 00:29:40.211, Speaker A: Even with chat GPT 3.5 or something.
00:29:40.363 - 00:29:49.147, Speaker D: Absolutely, absolutely. There's so many businesses where we can improve the unit economics, improve the scalability with models that were six months old, one year old.
00:29:49.291 - 00:29:52.755, Speaker B: So why haven't people, why haven't people done that? Kasey, they are.
00:29:52.795 - 00:29:53.139, Speaker D: I'm back.
00:29:53.187 - 00:29:54.891, Speaker C: It's in progress, don't worry.
00:29:54.923 - 00:29:56.682, Speaker A: Yeah, it's in progress, but that's $80.
00:29:56.749 - 00:30:05.505, Speaker C: Billion of startup investment in AI. Or I guess if you take out OpenAI, whatever the 40 billion or something is going as a lot of startups doing that.
00:30:05.545 - 00:30:11.865, Speaker A: Right. And most of that probably won't find a good return on capital, but some of it will find a very, very good return on capital.
00:30:12.025 - 00:30:48.075, Speaker C: Sorry to interrupt, but I kind of. Aren't you all sort of betting against scaling laws though, here? Like the idea that the state of the Art model will be good enough for 99% of people only really applies in the case that it doesn't keep scaling. Right. Because if, you know, let's say for simplicity, we can say an IQ scale, like IQ and spend. Right? Like, maybe an 140 IQ model is good enough for everyone now, but if there's a 150 IQ model available, that's going to be way more valuable. Right. And like, each point of IQ is, I don't know if it's equally valuable.
00:30:48.075 - 00:30:58.815, Speaker C: I don't know if it's more valuable, less valuable. But I do think intelligence is dramatically different than the text editor. And you, aren't you kind of betting against scaling laws if you think that?
00:30:59.875 - 00:31:54.945, Speaker A: Yeah, it may be. I don't know. I don't think I'm betting against scaling laws. But it, I do think that there's a, you know, a marginal utility to each incremental IQ point that, you know, each, you know, the 200th IQ point from the 199th is probably a lot cheaper than the 130th IQ point from the 129th or whatever. But they're all, they're, they'll be forever valuable, I guess. But I think if, and as these things get commodified, commoditized, this is where there's sort of like room for incentives and I think like network effects in, in coordinating people globally to like iteratively improve these things. Actually, I think it's like almost more valid in that, in that scenario where they are like commoditized to an extent than where, you know, the big guys can just always outso spend and always have the state of the art in a meaningful way.
00:31:55.445 - 00:32:31.805, Speaker B: Well, I want to pull us back here a little bit. First of all, these are not scaling laws. These are scaling hypotheses. Right? The scaling hypothesis says that we think if we add more data, more compute, we're going to result in, as you put it, Jose, hierarchy in the model. That could hold, that could not hold. I think if Web3AI is successful, it could be successful in either scenario. If the laws hold, then the theories hold.
00:32:31.805 - 00:33:14.875, Speaker B: Yeah. So. Excuse me. You're right. If the hypothesis holds and becomes a law, let's say, then the question will be like, how do we make AI kind of safe, broadly distributed, open, transparent, you know, localized to different jurisdictions, to different cultures, et cetera. And I think open networks that are public goods that enable the training of such things, A would be like, really well suited for that. And then B, again, in my view, would be like the one way that you could counteract a big company buying a lot of compute by taking the long tail and aggregating that and actually getting more compute.
00:33:14.875 - 00:33:56.905, Speaker B: That has been shown in blockchain to some extent. Right. Like for example, you know, Bitcoin is the largest supercomputer in the world aggregated from like literally, you know, retail people's devices and then eventually people build data centers for that purpose. If the hypothesis doesn't hold, then I think the world becomes a little bit different. I think we're heading to AGI still, but like more slowly. I think we have an oversupply of compute and compute becomes really cheap and then it just becomes like a search for business models. Within the capabilities.
00:33:56.905 - 00:34:09.619, Speaker B: Yeah, exactly. Within the current capabilities of the intelligence that we have. And I still think that just kind of being a Web3 person at the core, I still think Web3 business models will be really important.
00:34:09.787 - 00:34:26.043, Speaker A: And this is, and even in that last world you mentioned, Jake, I think the impact of that level of AI is huge. Whether that accrues value to only a couple entities that monopolize this, I don't really think that's going to be the case. But the impact on society will still be very big.
00:34:26.179 - 00:34:47.695, Speaker B: To your guys point, if we just stop all innovation in AI right now and just focus on integrating GPT4.0, 3.5, whatever, you know,01, like into the world, then I think we could do a lot. I think we could probably cause a lot of unemployment. I think we could streamline a lot of industries, get a lot of efficiencies, you know, and substance.
00:34:47.735 - 00:34:48.863, Speaker A: Create a lot of new jobs too.
00:34:48.919 - 00:35:13.151, Speaker B: Create a lot of new jobs too. Right, exactly. And, and, and do we want to be doing that in an open way? I think emphatically yes. I say this because I talk to a lot of founders who are actually using AI in actual products and you know, their feedback is like open models work better. I can control the cost, I can control, you know, what outputs they give. I can fine tune them for the problem. They're cheaper, they're like this, they're that, they're more private.
00:35:13.151 - 00:35:14.743, Speaker B: Right, Yeah.
00:35:14.879 - 00:35:37.057, Speaker D: I want to piggyback on what Jake's saying there of like why even use open source? Just taking crypto out of it for a second, which might be helpful. It's like when you're juxtaposing closed source versus open source. In my opinion, closed source is generally accepted still as soda state of the art. It's also convenient as hell. Right. And just like the UX is pretty good. There's a reason everybody knows what ChatGPT is.
00:35:37.057 - 00:36:26.225, Speaker D: But to take the other side for a second, because these open source models are publishing the initial weights and the architecture there's. While you can fine tune on both, you can absolutely fine tune an OpenAI. The degree at which you can fine tune on open source is so much more granular and you can get so much more done to Jake's point. And so that's like the first thing. And then the other thing is like you can do it in a completely private way for both enterprises, forgetting even consumer preferences for a second for enterprises that's just a huge deal. There's just so many, so many industries that need that. And then the other thing is you can do it offline, which I also think is an under pedaled use case of like there's so many businesses to be built where they need to do AI in a way that's actually not able to push, pull from the web in a way that's like latency intelligent, like it takes too long basically, is what I'm trying to say.
00:36:26.225 - 00:36:30.641, Speaker D: And so that's another amazing use case for open source. And so I, yeah, I just, there's.
00:36:30.673 - 00:36:35.953, Speaker A: There'S lots of businesses for HIPAA or whatever reason that can't and won't use things like OpenAI as well.
00:36:36.049 - 00:36:39.817, Speaker D: Just yeah, they can't for sure. It's not worth it, it's not worth.
00:36:39.841 - 00:36:48.107, Speaker C: The risk and we're seeing a lot of developers actually use especially LLAMA nowadays and I think it just makes sense. Also you can't get rugged.
00:36:48.201 - 00:37:21.267, Speaker A: Like I mean I think the analogy, and I think, I think Zuckerberg has said this, but if not, I read it somewhere else. I mean the analogy is just like what they've done with sort of like REACT at Facebook and it's like it may not be the best framework all the time, but it like it has the best tooling and the best ecosystem and the best libraries and like you know, even going two years out, if not now, I think that's where LLAMA is going to be or a successor to Llama where it's like this is where all the tooling is. You can do so much more with it on your own infra that like there's not going to be as much effective tooling built around an OpenAI API.
00:37:21.331 - 00:37:53.635, Speaker C: I don't think I'm really enjoying these debates. I wish we could go deeper, but I'm aware Jake has a hard stop in 20 minutes. I want to bring it back to crypto AI. So if we get a bit more granular in the subsectors within crypto AI, there's a bunch of subsectors that have emerged. Right. Kasey, you Topology has a really good sort of map of the industry with two views on your website that we can put in the show notes. And there's everything from decentralized training, decentralized inference agents, obviously the data sector that you outlined before.
00:37:53.635 - 00:38:13.565, Speaker C: Maybe we can start at a high level. What areas are you all most interested in? And also what areas are you least interested in or do you think are overhyped? And maybe overhyped is a strong word, but I'm curious and hopefully there's some spicy overlap between stuff. Some of you are bullish on that, others are bearish, but we can go around the horn and, and chat through.
00:38:13.605 - 00:39:11.503, Speaker A: I mean I can take it sort of broadly and I'm happy to go more fine grain, but I would say like, not that I'm necessarily bearish, but the things I'm least interested in are things that leverage AI within the crypto ecosystem. So things like using AI and wallets or whatever. I think that stuff is interesting and we need it, but it's just not at the same scale of impact. What I'm most interested in is anything where I think we can add sort of decentralization, global incentives or censorship resistance kind of tied in with decentralization to something that would Give like traditional Web2AI engineers or product builders tools that they, that they can't get access to in the, in the sort of like centralized world where they can actually add value. And some of this I think we saw with like the way Noose research thought about how to leverage the incentives within the BIT Tensor ecosystem. Like I just love that example. They weren't, you know, crypto native people.
00:39:11.503 - 00:39:25.463, Speaker A: They wanted to do something and figured out how to incentivize people on the Internet to like help them do it. Um, that is what's like the most anything that falls into that sort of bucket that a Web2AI engineer would be interested in and find value from is, is like what I'm really interested in.
00:39:25.639 - 00:40:21.549, Speaker B: I'm happy to go next. Um, I think we take a tech stack view of, of it and just trying to see like in which low parts of the tech stack is web 3 creating real advantages in solving really hard problems. And I'll say a couple of areas and one that I'm less interested in. So compute training data would be the areas. So compute is like aggregating GPUs I mean, if we just took the view that like it's because GPUs are bottlenecked, I think that's less interesting. The more interesting view is like, once you've accumulated a bunch of computers, what are the second order applications that you could build on top of that? And people like Prime Intellect have been doing a lot of work in this area. You can financialize, compute, you could do finance, you can do different like strategies like training or inference.
00:40:21.549 - 00:41:31.013, Speaker B: You can, you know, you can essentially treat compute as a commodity. The training area we've touched upon a little bit, I think, you know, this is an emerging sort of field and we definitely need to move the state of the art of what is possible on decentralized networks with slow interconnects and like what algorithms for training actually work well. And there's a number of companies like Jensen, Prime Intellect, Pluralis working on that. And then data is not something that is like in focus that much right now in Web3, but it will become a lot more important as we start to train larger and larger models in a decentralized way. Like where is the data coming from? Are we going to go steal that data like Meta does, or OpenAI does, or are we going to crowdsource that data, or are we going to use open data sets or synthetic data sets, et cetera, or proprietary data sets, et cetera. And then a big area that a lot of people are operating in and investing in is the inference area. I'm, I'm a little bit more skeptical here for now.
00:41:31.013 - 00:42:36.265, Speaker B: And the reason is like, I don't see decentralized networks for inference as being like cost competitive right now with anything else in Web2. And they're certainly not showing like that many customers from Web2 that they're winning. And also, you know, like, what is the hard problem of decentralized inference? It's verifiability. And you know, when you have a, like when you have a distributed network and you don't know exactly who's operating the nodes and you're running some kind of mission critical, you know, LLM inference, then you need to have some guarantees about like whether that's computation is being done correctly. And I think that problem of verifiability for the most part has not been solved effectively by the Web3AI space today. I think people have used ZK and optimistic stuff, but all that stuff is really, really expensive. And I've seen like some proposals where if you take a particular model and understand its statistical properties, then you can create inference that's Pretty cheap and verifiable.
00:42:36.265 - 00:42:52.735, Speaker B: Right. But then we're sort of in this thesis. I'd love to hear maybe Casey's view on this, but this thesis that, that's really useful for like the agentic future. Like in the agentic future, like the verifiability of inference is going to be a core issue and I just don't see that today. But maybe Casey has a different view.
00:42:53.075 - 00:43:05.899, Speaker D: Okay, I can start with a few things. 1. Okay, let me just go in order because my brain is sequential. So starting with Will and then I'll go to the. Go to Jake. So what Will said. I do think there's a good mental model there, which is, it's.
00:43:05.899 - 00:43:50.249, Speaker D: There's. There's AI that meets crypto, so things like improving defi bots, making a crypto foundation model, and then there's crypto that meets AI, distributed compute, distributed inference, data ownership. I agree with Will, unfortunately. I know we want contrarian combativeness, but I agree that generally the way I think about my entire job is first to underwrite what are the largest markets that can support large outcomes either today or growing markets, genuinely, and working with the brightest peoples on those paths. And so for me, I just think there's going to be much bigger outcomes on the latter. Bucket on. And then I'll, I'll do my bearish takes and then I'll kind of opine on Jake's categories, which I generally agree with.
00:43:50.249 - 00:44:13.355, Speaker D: But things that I'm not super excited about backing in a silo. Silo is one. Privacy. I think privacy is a fine feature, but I just am not. I've seen so many pitches over the last six months on privacy being the number one proprietary or primary value prop, and I just don't buy it. I just don't. Maybe in the enterprise use cases for specific verticals, but as a consumer play, I'm out.
00:44:13.355 - 00:44:27.367, Speaker D: Could be wrong. Like everything I say could be wrong. The other thing is to push back on what J. The verifiability piece. I just don't think that's the most important problem to solve right now. It might happen, it might not. But I just.
00:44:27.367 - 00:45:04.101, Speaker D: Of everything we could fuel, like put fuel in the fire that is like very low on my stack of where I want to invest right now. And then on things that I'm looking at, it seems like we're, we're all kind of looking at the same things. So yeah, the, the things like data ownership, how compute's going to be used, I think to maybe start a little bit of a. Of A debate on the inference side, Jake, I think. Yeah, let's talk about it. I agree with your points. I think though, since I'm not super pro verifiability in the next year, I think that constraint is lifted.
00:45:04.101 - 00:45:50.105, Speaker D: And then the reason I'm gaining confidence in inference is because there's so many use cases in the economy where latency can basically be dialed down or dialed up, meaning like you can take a little bit more time to respond and they're just willing to take that price arbitrage or that price delta and so that to me supports a large market. I can play devil's advocate already and say, well, if H1 hundreds are going to drop below $2, then it might be so cheap that there's no point of distributing. And so it's almost like even the price delta isn't worth the risk of not having your servers co located. But I just don't, I don't think that's how this is going to play out. Like I do think there is a case potentially for these specific use cases to use distributed inference. Not everything.
00:45:50.225 - 00:46:02.849, Speaker A: So Casey and Jake, do you guys think that changes that last little piece? Does it change any with the be this sort of like chain of reasoning stuff that's coming about that might put a lot more compute cost on the inference.
00:46:02.937 - 00:46:03.497, Speaker D: Like chain of thought.
00:46:03.521 - 00:46:05.361, Speaker A: Potentially a significantly more chain of thought.
00:46:05.393 - 00:46:24.147, Speaker D: Yeah, yeah, see, yeah, chain of thought definitely with O1 there's like a lot of thoughts around oh one using chain of thought and what that means. And for people who aren't listening, it's basically like recursively doing. How do I explain this? Non technically it's like recursively doing calls to basically improve the output and so it just like increases the compute necessary area.
00:46:24.211 - 00:46:30.555, Speaker A: It's more like what you do in your head, like you think of something and then you like vet it and maybe think about it again like yeah.
00:46:30.715 - 00:46:32.219, Speaker D: Maybe do some spiraling.
00:46:32.387 - 00:46:44.563, Speaker B: Yeah, yeah. Wait, so Casey, sorry, I just want to go back one tick to the inference points that you made. Well, my question to you is like when I look at inference startups right now and I'm talking about decentralized inference startups.
00:46:44.659 - 00:46:44.963, Speaker D: Yeah.
00:46:45.019 - 00:47:18.459, Speaker B: I generally see them putting forward open models like they're serving llama, they're serving stability, right. And they have like no differentiation from any other one. They're not really like lowering costs because they're disadvantaged in compute, they're not really offering cheap verifiability. And to really serve a private model, if that will ever happen, they need privacy, which you said you're not excited about. So like how does this, how is this going to work? What are decentralized inference startups? What models will they be serving and to whom and why?
00:47:18.627 - 00:47:47.339, Speaker D: Okay, so I don't think you need privacy. So the reason they're serving open source models is because that's technically in let. That's only. There's the only thing they can do unless they go get a partnership with OpenAI, which is still possible, like OpenAI Enterprise Team. What they do is they come on site, they do a private deployment on air gap machines and you have like local inference of OpenAI. Right. And there's totally a future where OpenAI could work with a distributed inference company and be like, you know, these are the specs we need to see, this is the guarantees we need.
00:47:47.339 - 00:48:03.891, Speaker D: So you know, the, like the weights aren't open and all those things and I, from my understanding they're not doing it today. I could also be wrong there, but like it's not like technically impossible from my standpoint. It's just like it would require a lot of partnership.
00:48:03.963 - 00:48:19.375, Speaker A: But also even today these, some of these nodes could put like closed models, as in like something that's been privately fine tuned like where, where they're not publishing the weights or how they got to that model. And I'm sure those are out there today like very customized models.
00:48:19.455 - 00:48:31.103, Speaker D: But I think where me and Jake disagree is in that world, I still don't know if you need privacy or verifiability like in a general sense. Like I think you can technically architect it in a way and I think consumers and enterprises might trust.
00:48:31.239 - 00:48:40.023, Speaker A: I mean like today I like to use Venice AI and it has no verifiability so I have no idea what it gets back, but I find it very useful.
00:48:40.159 - 00:48:41.317, Speaker B: Well, Venice.
00:48:41.471 - 00:48:42.297, Speaker D: Oh God.
00:48:42.361 - 00:48:56.617, Speaker B: Well, so, but, but like what is what, what guarantees can actually Venus give us about like the privacy of our data? Like they say that it's sort of between you and, you know, and the LLM, but I think the reality is it's between you and the LLM and.
00:48:56.641 - 00:49:00.177, Speaker A: Whoever it's between you and it's between you and the GPU owner basically.
00:49:00.361 - 00:49:18.845, Speaker C: What about the most, the more interesting thing for me with decentralized inference was like augmenting smart contracts with being able to tap into the results of, of models. And as you know, decisions that smart contracts are making get more and more important and you want to be able to call an LLM to, as an input to that decision. Yes, you do need verifiability Otherwise you're just.
00:49:18.885 - 00:49:19.149, Speaker B: Absolutely.
00:49:19.197 - 00:49:20.661, Speaker A: That's the main use case where I think.
00:49:20.733 - 00:49:48.229, Speaker B: Absolutely. So, so our company Gatech xyz, you could check it out. They're going to be going to market to a bunch of defi protocols, you know, this fall and, and in Q1 they're going to Mainet. Right. Or sorry, Q2, they're going to Mainnet, you know, they're doing exactly that. Like if you want to use the outputs of AI models in a smart contract in a way that is like robust and decentralized, then you need it to be verifiable. And that's what they've done with zk.
00:49:48.229 - 00:49:53.525, Speaker B: The limitations of that is that you cannot generally do LLMs that way. LLMs are not.
00:49:53.565 - 00:50:18.641, Speaker A: I think, I think that's a, I think that's a very valid use case. And it's also just like, I think the reality for the foreseeable future is you're just going to have to be willing to put that into use cases where you're willing to pay more. Yeah, like, like I wouldn't pay for verify, pay extra for Verified, you know, Venice AI queries because it's good enough for now as is. But on the smart contract world you have to, I think and then you're going to have to pay up for it. But so it's going to be, it's going to be high end use cases basically.
00:50:18.713 - 00:50:40.687, Speaker B: So that's just one more, one more thought for Casey. So Casey, Bagel, Bagel Network, right. They're working on a marketplace for fine tuning models. And the whole point of it is that those models are like fine tune proprietary data. So they have to offer, you know, a level of privacy in the inference in order to maintain the privacy of.
00:50:40.751 - 00:50:43.247, Speaker A: That data, to not reveal weights and stuff.
00:50:43.351 - 00:50:52.799, Speaker D: Yeah, maybe there's a little bit of a definition shift that we need to have with privacy, I'm realizing because it's like. I agree with what you're saying and I don't think that's how most people think of privacy.
00:50:52.887 - 00:50:58.731, Speaker A: If Kasey, I think you're talking less about data privacy and more about like privacy of the computation itself. Is that right?
00:50:58.803 - 00:51:19.947, Speaker D: Yeah, it's more around verify. Verifiability and privacy I feel like are starting to get conflated and we might need to separate those out and then. Wait, sorry Jose, I know we need, we need to switch topics. But just on the inside, Jake, if you haven't caught up with Sam from Cusco, which is a portfolio company of ours, recently catch up with him. Like I don't, I don't know what I want to share on the podcast or what I'm allowed to share, but I just, I really encourage you to reach out on that.
00:51:20.091 - 00:51:21.243, Speaker B: Okay, thank you.
00:51:21.259 - 00:52:20.089, Speaker C: Yeah, I will be reaching out as well. Alpha been dropped, so I want to double tap on data because I think that's one of the sectors that there's most broad agreement on that. It's interesting with crypto like bootstrapping these data networks, whether it's the data labeling side, whether it's generating data like grass and stuff like this, maybe even some of these dash cams or like there's a lot of different projects tackling this from different from different sides. How do you all think about what data is interesting, what the value of data is? Because I always think back to like five to ten years ago when all the big consulting were releasing these. Their classic reports on data is the new oil and will be the most valuable commodity in the new, in the new, you know, in the era of AI and they were kind of right, except big tech just like trained on the entire Internet, right? Just stole the entire open Internet and trained on it. And so like so far arguably it hasn't been that valuable. Although there are like super valuable data startups like DataBricks and scale AI that are being built.
00:52:20.089 - 00:52:27.313, Speaker C: But I'm curious, how do you see the future of that and which areas in crypto are most interesting? Like which areas of data are most interesting, slash most valuable.
00:52:27.449 - 00:53:52.377, Speaker A: For me, I do think it's like this is outside of AI and crypto even there's sort of this talking point of like with, with web3 you can own your data and I think that just ties directly into, you know, what you could potentially do with, with AI and crypto. And it's, you know, I really like what Bagel that Jake mentioned is doing where they can enable you to fine tune a model that is remains private, the weights remain private, data that can also remain private to say the user or the customer that has that data and then get like a fine tuned model over that that you can then query. And so I think systems like that where you can also maybe scale them to like multiparty where multiple parties can submit private data to train a model and, or fine tune a model, maybe train a model down the road. I think that's super interesting, you know, like at a very high level like the one that I would be most willing to use out there that doesn't not quite live yet, but it's like the new, the new Apple, Apple Intelligence, and I forget what they call the private cloud compute thing. And I would love to see sort of like open systems or networks working towards something very similar, but not, you know, in the Apple walled garden because honestly like when you're talking about my personal data, I would much rather be in that system. And maybe I've just been sort of, you know, psyoped by Apple, but I would rather be in that system than in the, in Android, Google's ecosystem. Like I trusted at least a little bit more and it's disappointing to me that that is in a fully centralized walled garden.
00:53:52.377 - 00:53:59.449, Speaker A: But I don't want all my personal data out there in these models. So I think taking that as an example is something I'd love to see.
00:53:59.617 - 00:54:15.561, Speaker D: Yeah, I think the ownership is the first part and then the second most important part is the aggregation. It's not actually about taking the data and holding the data, it's about taking the data and pushing it all towards aggregation. And then what we can do if we all put our data together like that, that is what is exciting.
00:54:15.593 - 00:54:16.289, Speaker C: What kind of data?
00:54:16.337 - 00:54:32.821, Speaker A: Well, I think there's both, Casey. I think that's, yeah, I think that's valuable. But there's also like I want to be able to ask a LLM that has the full context of my personal data. That's kind of what I was getting out with the Apple use case. But I think what you're talking about, what you're talking about is also really important for improving models like sort of at scale.
00:54:32.933 - 00:54:38.381, Speaker D: Yeah, yeah, okay, fine, I agree. Both are, both are important. But Jose, what was your question? Like what type of data is important?
00:54:38.453 - 00:55:00.703, Speaker C: That was it. Yeah, you kind of answered it in a bit. So because there's the personal data side which I agree is super important, but there's also like all this specialist data that you need, right? The expert data, the expert feedback, potentially the multimodal data like video data. Are people going to be wearing, are we going to have a deep end network where everyone's just wearing a camera and filming the world around them to train robots? Like what are the things that you think are most, are most exciting?
00:55:00.879 - 00:56:10.115, Speaker D: The one thing. And then I'll pass it to Jake, the one thing just to kind of frame this conversation. And Anna Atvana, who's doing a lot of user owned AI, who I was like an angel investor in way, way before, in 2019 or 2018, she's like very focused on this and one thing that she often says which I think is really important to call out is that we are basically hitting the ceiling of how much public information is available on the web for absorption into LLMs. And so if you, if you need the source, let me know, I'm happy to send it. But once you realize that, you're like, oh shit, data is going to be really important because now it's about what private data sources, what synthetic data do we have, what, where are we going to get more data to make these AIs better? I actually think in the future, yes, data is going to improve AI, but the other thing is going to be sensors, which is why I'm so bullish on embodied AI. I think once you hook these language models up with eyes, ears, ability to understand their physical world, it's just going to blow our minds and what they can do. But to answer your question concretely, Jose, like there's a lot of data daos right now that are collecting all sorts of information, both from personal but also like industry specific data and using token incentives to do that collection.
00:56:10.535 - 00:56:54.547, Speaker A: One thing if I could jump in real quick or I don't know because I hear the like, you know, all of the Internet data is like, basically everyone's using the same data set because it's just all available now, which I think is true. And more private data is obviously going to make things better. But I'm a little bit more optimistic in that. Like I would think, like, you know, Google has been crawling the entire Internet for, since, you know, the late 90s and I would say they've sort of distilled the information out of those crawlings less efficiently than a modern AI. And I think they're still. A modern AI is not distilling all the information it can out of that data set. I think if you had a human read all of that data and could actually absorb it and interpret it, they would be smarter than these AIs are today.
00:56:54.547 - 00:57:03.383, Speaker A: And so I think there's still more to be, there's more knowledge in that data that we're not distilling yet. And so there's room for improvement there as well. But, but more data helps as well.
00:57:03.519 - 00:57:55.851, Speaker B: Yes. Well look, I think Jose, if we're going to be training competitive foundation models, then that naturally raises the question of like, where are we going to get that enough data to do that? And obviously if we have these joint corporations willing to go scrape whatever and steal whatever, then you know, having some kind of opt in model, which is very important to have those models, but I just don't think that that will be like competitive in that way. And So I guess the real question is like what are the mitigants to that? And I think the mitigants you covered a few. So one is I think there's huge bodies of proprietary data. Like if you think about, I don't know, News Corp selling their corpus to OpenAI, a lot of media people would tell you that maybe that was a little bit short sighted. They should have fine tuned their own LLM. Right.
00:57:55.851 - 00:57:56.763, Speaker B: And made their own.
00:57:56.819 - 00:57:57.795, Speaker A: Or Reddit especially.
00:57:57.915 - 00:58:20.067, Speaker B: Or Reddit. Right. You're kind of making the point Will that you know, algorithms are going to get more efficient at learning. I think that's going to continuously happen. But the other, the other thing we didn't cover that much is like this idea of systems 2 thinking in intelligence. So like the O1 model or search or as you guys call the chain of thought on this podcast. Right.
00:58:20.067 - 00:59:07.541, Speaker B: What that does is it shifts scaling to a little bit more of the inference dimension of the reasoning dimension. So you can have like, if you think about like the foundation model as the sort of book knowledge and then you know, the 01 portion as the reasoning. Well, we can have a lot of book knowledge and a little bit of reasoning or we can have less book knowledge and then if we think longer we might be able to get to the same conclusions. Right. So I feel like there are definitely like mitigants and dimensions in which we can still scale and actually I think it's easier to scale in the inference dimension. I think it's more parallel, it's simpler, it doesn't require fast interconnects like training does. And so it actually makes it easier for decentralized networks to compete in that way.
00:59:07.693 - 00:59:42.351, Speaker A: Yep. That's kind of what I was asking you guys about earlier is that because I do see only recently, maybe in the last month I started to realize maybe there's a world where foundational sort of book knowledge models get like very much good enough and the, the, the benefits we get from them is like how much can you spend reasoning on them or reasoning on some contextual data you give it and maybe that skews it towards a lot more compute being used for inference than for. Because we really want to spend our compute on thinking, not training things how to think. Right. Like you would think more of the compute in the, in the, in the future will be used on thinking.
00:59:42.423 - 00:59:52.921, Speaker D: Yeah, so yeah, well measure of experts is also another thing to consider and how this is going to play out too. But I, yeah, I think this is a really interesting thing to think about. I don't think we know yet.
00:59:52.993 - 00:59:53.685, Speaker A: Yep.
00:59:54.065 - 01:00:20.849, Speaker C: Data side was, was interesting. Yeah, I guess you're all bullish on the, on the private data side. Maybe, maybe we can jump to agents, which is like a super hot like buzzword both across traditional AI and crypto. AI. What are like what in agents are you, are you excited about? And maybe if someone wants to start by like defining an agent and like the multi agent world as well, maybe we can, we can go from there.
01:00:21.017 - 01:01:00.441, Speaker D: Yeah, I can do it if you want. An agent is a piece of software that uses AI to either semi or autonomously complete tasks that humans would do. Like a concrete example of an agent I always used which we made for our port codes. But it's a domain name agent. So basically what it does is you'll be like this is what the company does. You described a natural language and LLM takes that and generates options for what the domain could be and then it hits the GoDaddy API to see which of those domain names are available and then it returns the. It actually can purchase the domain or it can return back.
01:01:00.441 - 01:01:40.405, Speaker D: Like here are five options that are available that match and we use this every week pretty much. And everyone wants access. You can pay me, but yeah, that's like a concrete example of an agent and maybe I can just jump into like what I like and what I don't like about this industry or this subcategory. What I do like is I do, I am running a roundtable on if agents are going to use crypto as payment rails because I just think it's so talked about and I want to better understand the viability of it. So there's like a machine learning engineer from Stripe joining, Visa is joining. Some crypto people are joining, some pure AI people are joining. And we're going to do that next month in San Francisco with a whiteboard because I just need to run it to ground because I actually that'll be super interesting.
01:01:40.405 - 01:02:02.299, Speaker D: Maybe you could come if you want to come. You come. It's at my house but I need, I need to form a view there. But I do think it's interesting enough to do the research and spend the time. The things that I'm less interested in about is just putting all agents on chain. I just don't get it. And maybe one of you guys can explain it to me but I just don't understand why I would put an agent on chain unless it's transacting on chain which that I understand.
01:02:02.299 - 01:02:14.451, Speaker D: If it's like, you know, like OLAS has a, has a thing called Pearl, where you can program things to. Basically one of the major use cases is to do like prediction markets as an agentic thing. Like I get it, but I'm even.
01:02:14.483 - 01:02:16.755, Speaker A: Then they don't need to be on chain if they're verifiable.
01:02:16.875 - 01:02:31.749, Speaker D: Well actually if you dig into the code, it's really not on chain. Like there are certain things that are on chain and certain things that aren't on chain. So that's where I'm like, I don't get it. Like blockchains are really bad at data storage. They've always been. And like why do we keep trying to push it on them? Like that's not their value proposition.
01:02:31.827 - 01:03:24.225, Speaker B: Well again that's why, that's why some founders, at least to me have made the case that you need verifiability to ensure the robustness of agents. And I'm not saying I buy that argument. In fact I kind of don't buy that argument. But the, but the example would be, you know, imagine your agent is managing like your personal finances and it's like significant to you, right? And you want, you want, you want accountability if something goes wrong. Like you don't know how OpenAI is optimizing their API on the back end and what effect that will have on your investment decisions in that case, some people have made that kind of argument. It doesn't feel like it's in market, it doesn't feel like it's real yet. Agree and we'll see maybe if there's a lot of agents that verifiability will become very important.
01:03:24.605 - 01:04:09.645, Speaker A: I like to think a lot about a lot of this stuff as to like how do humans operate? And I don't just mean like in a single human brain but like how do we coordinate as a species. And like to my example earlier with like the multi agent systems, you know, I think we have people that specialize in different things and you kind of, if you want to learn about that thing, you might seek out those specialists. But you never really like get out of that specialist. Like you know, like nobody's telling you that was a hundred percent true and accurate and correct. Like we're always just evaluating the information and the sources from people that we get information from. And I think that's what agents are going to have to do a little bit more than just like the verifiability is like less important than what data am I getting back from it. And I think the closest analogy today that I can think of is kind of like in the bittensor validators.
01:04:09.645 - 01:04:51.189, Speaker A: There's already this little kind of gamification of can they engineer the optimization function such that it's less gamable and trying to evaluate what the miners are are giving to it. And so I really think like every agentic model is going to have this base level of like evaluation of other models, which is like, seems really tough because you have to be able to do it for potentially a lot of different topics. But I think that is most likely going to be more important than like, like a yes or no verification because I don't think that works in the real world. It's like, did you know? I mean, I guess it's like I know Jake gave me that answer because I saw his mouth move and I heard him. But like that doesn't mean it's true or correct or right. You know what I mean?
01:04:51.237 - 01:05:21.431, Speaker C: Yeah, yeah. And this idea of like sovereign models like raising funds on chain and stuff like this and investing or doing whatever, we're kind of seeing early innings of that with terminals of truth. Although it's very much controlled by someone. Is that even possible? Like where does the private key sit in that case? Is it sitting just in the model's context window? Do you think that world is likely to to happen? Because a lot of the on chain agentic stuff we're seeing is just kind of like the asset management protocols of before.
01:05:21.503 - 01:05:21.711, Speaker A: Right.
01:05:21.743 - 01:05:32.835, Speaker C: It's just someone has like a multisig or whatever and the funds are managed according to some strategy that's executed by an agent, but it's still just code running on someone's computer and you're basically buying like LP shares in their fund.
01:05:33.135 - 01:05:53.605, Speaker A: Yep, that's what I was going to say. I think it's definitely possible today. But also it's kind of like if you have this model that can do a bunch of profitable defi trades, like why would you put it on chain and make it just let people invest in you? And whether that's on chain or not, I feel like there's incentives against doing some of those things. Not to say that they're not possible.
01:05:53.985 - 01:06:21.195, Speaker C: Maybe to end with I'd love to get your take on what vertical within crypto AI you think is most likely to hit product market fit first. So we can define product market fit here pretty broadly as like tens of millions of active users or tens of millions of revenue, like non token incentivized, like actual, actual revenue. What do you think is the most likely application or vertical to do it?
01:06:22.175 - 01:07:00.355, Speaker B: Well, one area where we've definitely seen just traction is just the compute side Right. So if you look at Prime Intellect, one of their core value props was to like lower the cost on high end GPUs by aggregating them and removing market inefficiencies. And they were actually able to do that pretty successfully. Right where H1 hundreds were going for $8. At some point, you know, they were, they were doing it much, much cheaper because of that aggregation. But I would say the second one and I, I know I'm like contrarian on this to most people. I think it's training.
01:07:00.355 - 01:07:33.253, Speaker B: I do think if we can make some progress there, we're going to see a number of models probably reaching like 50 billion parameters quite soon which are going to start to become actionable. Intellect 1 from Prime Intellect just trained 10 billion parameters. When we get to around 100 billion, I think people will be able to use that for basic LLM purposes. And these will be models that have been trained in a completely decentralized way. Inference, as I said, less, less interesting.
01:07:33.349 - 01:08:23.437, Speaker A: I, I don't honestly don't have a great answer for like a single vertical because I, I kind of think if and when we get something that uses these to that extent, it's going to probably touch on multiple of those verticals. Like you know, if, if like to use more of like a front end application, like if, if Venice AI gets there, like it's using some of these inference networks underneath, it's using like other technology underneath. So it's kind of like touching on both verticals. But I think, yeah, I think, I mean it's back to like anything where these incentives, and I think a big one could be censorship. Resistance as well, is useful to the broader AI engineering community. I think that's where there's a lot of opportunity for outsized return because they're going to quickly want to use those things and apply them to every nail that they're trying to fit their hammer to.
01:08:23.581 - 01:08:54.858, Speaker D: Yeah, these are not mutually exclusive categories by any means. It's so early that even when I was putting together the market map, well I, it's actually crowdsourced but basically the way it works is some one company goes to one category and the amount of inbound I've gotten being like that's not accurate. I live in three categories and they're right. I'm like, you're right, you do live in three categories. So it is kind of hard to say. There's these concrete lines. I think I'll give a half answer which is that I almost disagree with the definition of product market fit and that it's going to be whatever number of users.
01:08:54.858 - 01:09:32.945, Speaker D: I actually think it's very possible that the most widely used product is consumed by bots, and bots become your users. I think that what we underestimate is right now most products are consumed by human beings. And I really think in the next five years, agents or bots or whatever you want to call them, humanoid robots, whatever, software is going to be a huge part of the consumer side of the economy moving forward. And so I just think that might be this kind of like, you know how when we all pontificate about what's going to happen, you kind of usually miss the big thing. I think even focusing on humans might.
01:09:32.985 - 01:09:40.113, Speaker A: Be wrong, especially if the agents have. If the agents have money, then it makes sense. You really just want end users with money. They don't have to be humans.
01:09:40.169 - 01:09:45.917, Speaker D: Yeah, totally, totally, totally. I have two portfolio companies that are designing for bots right now, and it's a totally different icp.
01:09:46.021 - 01:10:14.867, Speaker C: You know, I mean, I think, I think the Ritual founder had a really good post on Twitter about how in the future he sees, like, humans not even interacting really with the Internet directly anymore. Right? Like, you literally just interact with an agent and then the agent goes and basically filters the Internet down to give you the answers you want. And so the Internet is just like a place for agents, right? And we actually just interact with, with, with, with the agent, with, with the agents directly.
01:10:14.931 - 01:10:36.615, Speaker A: It makes sense to me. It's like if I want to go buy something on Amazon, like my agent could over time just learn the kind of things that I filter out and I could like, just ask my agent, like, the interface to Amazon will just be through agents, right? Or like to go buy me something on the Internet or whatever it is like buy my flight. And it already just knows, like times I like to fly all this stuff and just filters that out for me. Goes and does it to the United API or whatever.
01:10:36.695 - 01:10:57.215, Speaker D: Yeah. In pure AI, this sector is called living interfaces. And the core belief is that UIs will be constructed and deconstructed, maybe even behind the scenes for a human. And there's a lot of cool AI companies going after this. Like one is called CO Frame. They're starting with AB testing, but their actual vision is to make the interface obsolete and kind of drive towards the future that you two are discussing.
01:10:57.335 - 01:11:22.897, Speaker A: One, one thing interesting, maybe to tie it back to the beginning. I think Jake mentioned like, you know, having these, this compute network that might run these different models. I hope we get to see the day where one of These decentralized compute networks runs up against Facebook's licensing user model and we get to see what happens if this decentralized Network is running 200 million Ollama users. Like what are they going to do? I don't know. That'll be really. I hope we get to see it.
01:11:22.961 - 01:11:24.605, Speaker D: We'll see it. I hope so too.
01:11:25.625 - 01:11:26.009, Speaker C: Nice.
01:11:26.057 - 01:11:26.521, Speaker B: Amazing.
01:11:26.593 - 01:11:34.729, Speaker C: This was a great chat. Is there anything anyone wants to mention before we go or any loose ends from, from the chat that you, that you want to double click on?
01:11:34.897 - 01:11:54.849, Speaker B: I think it's really covered a lot. I think it's really interesting that a lot of people in blockchain which has been on this like multi year search for demand side traction, put forward AI as one of the most likely categories to achieve that traction for blockchain. I don't know. That's pretty, that's pretty intense.
01:11:55.017 - 01:11:55.729, Speaker C: Why?
01:11:55.897 - 01:12:13.379, Speaker B: Well, because it, you, you, you usually think of blockchains as, you know, creating sovereign money or efficiency technology for banks or payments, like at its core. So if, if it, if it actually turned out to be AI, that would be like some long tail event that we never foresaw, ever.
01:12:13.467 - 01:12:52.945, Speaker A: Yeah, I do think payments could still be a part of that. Not all of it. I think there's a lot more to it than that. And maybe one other angle that I think I've at least kind of touched on, but that we didn't talk about a lot is like, I actually do think that, that a lot of the people in the traditional AI community kind of don't realize the regulations that are coming their way. And I think there's like a bit of a possible tailwind on decentralization from that. Like, you know, the California proposal that I mentioned earlier I think would have basically made it impossible for anyone to release an open source model because of the liability. But we could, you know, potentially do it in a, in a Satoshi Nakamoto like way or like on a decentralized network.
01:12:52.945 - 01:13:00.891, Speaker A: You could still get open networks sort of against the will of the state. And I think that's actually a not insignificant reality of our future.
01:13:01.003 - 01:13:01.855, Speaker D: Is that a thing?
01:13:03.075 - 01:13:04.171, Speaker C: Sorry, go ahead.
01:13:04.363 - 01:13:08.651, Speaker A: Which part? Like being able to open source them or the state cracking down on them?
01:13:08.763 - 01:13:25.591, Speaker C: I mean being able to evade state regulations for this stuff. Right. Like there's a lot of damage that AI can do. I think it is a little bit overstated like currently, but there is a lot of damage that AI can do. If you have these censorship resistant models where you can, I don't know, build nukes or Something, I mean, I think.
01:13:25.623 - 01:13:43.359, Speaker A: Regardless, it's inevitable if we have those laws in the us they'll release them in India or whatever, you know what I mean? I think it's actually inevitable. And I also think open AI is safer than non open AI in general. So I'm not too worried about it, but I think it's inevitable whether it's good or bad.
01:13:43.447 - 01:14:11.851, Speaker D: Yeah, I have two quick things I'll let. Oh, go ahead, Joseph. Oh, sorry, Jake. Okay, just quickly to respond to Will on the idea that regulation is coming. I want to just call out one like so, yeah, Hinton won the Nobel Prize this like past week, who's like a really godfather of AI. And that one, he made the relu activation function go mainstream, which I'm extremely grateful for. We really wouldn't be where we are in deep learning today without it.
01:14:11.851 - 01:14:44.589, Speaker D: And then the other thing is that he's really scared about AI. AI is kind of having this consciousness and what's going to be involved. And there's kind of like these two schools of thought where there's like Chomsky from noam, Chomsky from Linguistics who thinks they're just sequence models. And then you have Hinton over there saying, no, like this is basically how humans work. And what Hinton said when he got the Nobel Prize was like, I really hope people actually pay attention to this now. And trust me, and I think there is going to be a tailwind there in that regulation or regulators are really going to start paying attention now. And so I completely agree with Will on that.
01:14:44.589 - 01:15:26.123, Speaker D: And then the last thing I wanted to say, just like as we wrap, is I'm happy to do this and surmise around where the future is going to go. There's a really good paradox or principle that I love citing sometimes and it's called Moravec's principle or paradox. And I don't know if people are aware of this. I've seen it. It's kind of like an old school AI paradox. And the long story short is that he basically says that what AI, what AI or computers are good at, humans are bad at. And the concrete example given back in like, I don't know, maybe like call it five or ten or five years ago, is that AI is really bad at like generative, like AI stuff, I'm sorry, like art stuff and humans are really good at the creativity stuff.
01:15:26.123 - 01:15:51.425, Speaker D: And that has completely flipped over the last very short decade. And why I love this is it's completely become obsolete in my opinion. And it just shows how bad we are at predicting things and so like, happy to do this podcast, but I also just want to be high integrity and that like we don't know what's going to happen and we've historically been very bad at predicting what humans and what computers are going to be individually good at.
01:15:51.545 - 01:15:52.721, Speaker A: Well, 100%.
01:15:52.873 - 01:15:53.985, Speaker B: Casey. Well said.
01:15:54.065 - 01:15:54.685, Speaker A: Yes.
01:15:55.065 - 01:15:58.561, Speaker C: Nice. Jake, did you want to say something or no?
01:15:58.593 - 01:16:05.245, Speaker B: All I wanted to say was it was been a pleasure seeing you all. Very interesting discussion and thank you for having me.
01:16:05.945 - 01:16:08.099, Speaker A: Thanks. This was great. Cirrhosis.
01:16:08.187 - 01:16:15.035, Speaker D: Thank you, Joseph.

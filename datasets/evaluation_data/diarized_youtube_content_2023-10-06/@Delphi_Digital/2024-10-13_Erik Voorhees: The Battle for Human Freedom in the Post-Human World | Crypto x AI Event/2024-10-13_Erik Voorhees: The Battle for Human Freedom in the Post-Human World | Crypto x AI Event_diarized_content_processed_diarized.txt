00:00:16.440 - 00:00:27.359, Speaker A: Hey, everyone, it's Tommy, one of the co founders at Delphi Research and founding partner on the venture side. I am thrilled to have Eric lead off our crypto AI conference. Eric, how's it going?
00:00:27.447 - 00:00:29.391, Speaker B: Going good. Good to see you, Eric.
00:00:29.463 - 00:00:34.439, Speaker A: Absolutely no pressure. Keynoting a conference panel, right? Yeah.
00:00:34.527 - 00:00:36.207, Speaker B: Well, this is what I like to do.
00:00:36.311 - 00:00:39.743, Speaker A: Yeah, it's so good. I saw your talks. Permissionless everywhere.
00:00:39.839 - 00:00:40.915, Speaker B: So I just talk.
00:00:41.415 - 00:01:01.413, Speaker A: It works. It works. Eric, I'm going to open up with maybe a question about yourself and your. Your life, right? Like, you've been a relentless supporter of human freedom, personal rights, pushing back against government overreach. We've seen you do it with crypto. We've seen you do it with sbf. Now we're seeing you do it with AI.
00:01:01.413 - 00:01:10.357, Speaker A: I'm curious, overall, is AI a friend or a foe in what I think is your lifelong mission to increase individual freedom?
00:01:10.461 - 00:01:51.057, Speaker B: Great question. Well, I'm trying to make it a friend. I'm trying to make it a friend. When I. When I started learning about it, it was just like a curiosity, you know, and everyone's playing around with Mid Journey and chatgpt, and it was obviously profoundly interesting how powerful these tools were. But when I started realizing that, like, to the degree that they're centralized and to the degree that they will fall under various licensing regimes or control of various states, that got a little scary. And I realized I can, like, sit on Twitter and complain about it, or I can, like, build something.
00:01:51.057 - 00:01:53.185, Speaker B: And so I chose to build something.
00:01:53.305 - 00:02:19.745, Speaker A: That's pretty cool. When you were looking at the landscape for OpenAI anthropic perplexity and still decided to build Venice, like, completely uncensored, unbiased LLM that people can access. Like, you clearly came to the conclusion that those services will never be objective, uncensored, uncontrolled. Do you think that there's a chance you could be wrong there? Like, is there any way that those can be. Can be free?
00:02:20.125 - 00:02:54.475, Speaker B: I don't think so. It's like a cultural thing, you know, like, those of us from the crypto world, we live in this adversarial mindset where trusting people is risky, especially at scale and especially when the trusted party is some kind of large, centralized entity and we just have that mindset, but that's definitely like a. A niche mindset. Most people don't. Don't feel that way. They seem to be more than happy to trust large organizations. Even if they say they don't trust them, they still keep using them.
00:02:54.475 - 00:03:30.565, Speaker B: So. So, yeah, I just. I Felt like there was an opportunity there and it wasn't something that like anthropic's going to pivot on. You know, Anthropic's not going to suddenly come out tomorrow and be like, actually we're going to make this service permissionless so that anyone in any country can access it and we're going to remove all the guardrails in terms of the speech censorship. It's just not going to happen. And so that seemed like a very good market opportunity, frankly. And it wasn't just that I saw what exists now, but I'm trying to see where this stuff goes.
00:03:30.565 - 00:04:00.327, Speaker B: Where, where is this in a year or in five years? And I think the, the guardrails and the censorship get worse over time and I think the centralized companies have a bit of naivete about that. So that's, that's what we're trying to build with Venice is like that alternative. Not that those companies shouldn't exist. They, they should and they, they're doing incredible work. But if there's no alternative to centralization, then people can get stuck in some pretty dystopian situations eventually.
00:04:00.471 - 00:04:36.953, Speaker A: That's well said. The thing that scares me a little bit is I feel like people are going to automatically opt into these services, right? Like they'll, they're not really going to check that button to uncheck Apple intelligence when that ships. Right. They're not going to uncheck, you know, any chat GPT integrations because they'll be behind all of their friends and competitors that are using it. Right. So it's, it feels to me like I don't know what the event is to switch modern culture away from centralized control into something like an amazing alternative like Venice. Right.
00:04:36.953 - 00:04:45.401, Speaker A: Like what do you think that'll be like? Do they have to, does the government have to sway an election or. Yeah, I'm not sure what the upheaval would be. The event.
00:04:45.593 - 00:05:37.227, Speaker B: I don't, I don't think everyone needs to switch, you know, like this isn't, I'm not absolutist about this. I don't believe that like everyone should be using decentralized, permissionless AI in the same way that I don't think everyone needs to be doing like self custody of crypto. The important point is that it exists and that people have it as an alternative and that people are, you know, a little bit educated on what that means and how to use it. The ability to be, to self custody your own crypto is the power there. And ultimately that is the check against centralization of any large wallets or financial institutions. So in the, in the AI space, just the, the availability of some kind of uncensored, permissionless alternative is good. And even if it's never even a majority of use, just that it is, there is what's important.
00:05:37.371 - 00:05:46.353, Speaker A: So kind of like in those extreme scenarios where you want an unbiased opinion, something like super critical, like a global event or something like that.
00:05:46.489 - 00:06:28.187, Speaker B: Yeah, and I try to be careful with that term unbiased because everyone thinks that they are unbiased and everyone thinks that the people they disagree with are the ones who are biased. And I think actually the sort of higher level view of this is that all humans are biased continually. And that's okay. That's part of what makes us human. What's important is that like one particular viewpoint and one particular bias doesn't become solidified and codified into being, you know, mandated across society. I think that's when it gets really dangerous. We need to have competing viewpoints and we need to have different biases in different directions.
00:06:28.187 - 00:06:49.309, Speaker B: And that's a dynamic flow that I think needs to be preserved. So yeah, like if you go and you use the models in Venice, um, you'll find ways in which they're biased. But the idea is that like they're not all biased in the same way on the same things and that bias can change and adapt and you can point it out and it can be resolved and like that's much healthier.
00:06:49.437 - 00:06:57.301, Speaker A: Kind of sounds like what you're saying is that the only way to really combat bias in the short term is to have multiple models, right?
00:06:57.413 - 00:07:03.185, Speaker B: Yeah, yeah. Competition, you know. Competition. Yeah.
00:07:03.845 - 00:07:23.185, Speaker A: Does it, does it scare you at all that the leading model that everyone is using is sort of built by one group of people in one state, California of the US and supposed to be used by everyone around the world. Like if I'm in Nigeria and I pull that thing up, like I feel like it's definitely not going to have the same views that I would want.
00:07:23.965 - 00:08:03.191, Speaker B: Yeah, that's for sure. But this is where like open source is so powerful because people can take models and fork them and change them and you know, re bias them in some other way that's more appropriate for that part of society. So the open source, like the fluid open source environment of AI models is really key. And I think the biggest danger, one of the biggest dangers to humanity really is if we allow ourselves to be convinced that open source AI is too dangerous and is outlawed or heavily restricted in some way, then we're in A bad spot.
00:08:03.383 - 00:08:52.005, Speaker A: That's a fantastic segue to my next question. I mean, I feel like you and I and others have spoken about open source AI, decentralized AI, crypto AI a lot, and we talk about all the merits of it, but it's pretty clear that centralized companies have enormous capital, like recurring cash flows to fund GPUs, they have a lot of talent, they have direct to consumer access with meta search bar, ChatGPT, the app. Right. It seems like they sort of have everything right now. So I'm trying to figure out where are the ways in which decentralized AI or crypto AI sort of can win here. Right. I'm curious, like where you think that Flywheel potentially inflects and we can sort of be the winners here.
00:08:53.195 - 00:09:47.035, Speaker B: Empirically, things are actually going in a good direction, not a bad direction. So like two years ago, if you were to compare the obviously best model back then, which would have been ChatGPT, it was obviously best. There was nothing even close to it and nothing open source was even in that ballpark. You could have asked that question back then and been like, how in the world is open source going to compete when there's this much of a head start and these companies have all this capital, et cetera. But what we've seen over the last two years is that the open source models have actually caught up and in some cases perform better than the centralized closed source models. So empirically that is in a good place, like that could change. And you know, I have to acknowledge that most of that gain comes from Meta and what they've done with llama.
00:09:47.035 - 00:10:22.233, Speaker B: And if Meta just changed their mind and stopped doing that, you know, like everyone in the open source. I hope he doesn't, yeah, I hope he doesn't. Everyone, the open source AI community would be in trouble. But you know, I think just because that one company is currently leading open source AI doesn't mean if they disappear, that open source AI, like can't work anymore. It's extremely dynamic and I think it has a very powerful way of letting lots of brilliant minds around the world contribute to it. So yeah, I'm not, I'm not too concerned. Like large, well funded centralized AI companies have certain advantages.
00:10:22.233 - 00:10:54.273, Speaker B: It's very hard for open source decentralized to compete with. But the reverse is also true. Open source decentralized systems have very powerful advantages that it's hard for centralized entities to compete with. And I think what it means is you just end up with an equilibrium where neither of those sides becomes ubiquitous. And that's that's great. I don't think closed source AI is bad or needs to go away. I think just the dynamism of both existing and competing with each other is really key.
00:10:54.369 - 00:11:41.575, Speaker A: I like that a lot. Maybe just spending a little bit of time on the model side would be interesting. Right, so you've seen a lot of really powerful closed models come out, right? Chatgpt, perplexity, Claude 3.5, things like that. You've also seen a lot of great open source models like Llama 405B, the newest versions, many of which are available on Venice. When you think back to all your activities in crypto, you've seen thousands of applications ON Ethereum every L1 L2, you've seen it all. Do you think that a similar dynamic is going to play out in crypto AI? Like, do you think that there will be a proliferation of either models or applications built on models with token incentives? Or maybe my grasp in here?
00:11:41.915 - 00:12:55.385, Speaker B: No, I think, I think totally in the sci fi, but I think accurate answer is that the real driver of that is essentially AI agents that need to interact economically. I think humans have built cryptocurrency and cryptocurrency has been useful and interesting and helpful for humans, but, but it's almost like they're not perfectly meshed together. And then humans have built AI and the same is true where they're useful and they have an interesting relationship, but they're not perfectly compatible. But when you take AI agents and cryptocurrency and you get the ability for these digital systems to just operate without any human involvement purely due to code and algorithms, I think super powerful stuff's gonna happen. And I, I would guess that over the coming years you're gonna see this preponderance of agents that just like flourish across the Internet. And they, they can't use banks, they can't, they're not gonna pass the KYC check, you know, they're not gonna be able to get through like a territory restriction at a bank if they're, you know, they don't have the driver's license of the right country. It's like there's an incompatibility there.
00:12:55.385 - 00:13:07.653, Speaker B: But crypto and AI work beautifully together when you just consider that a natively digital intelligence requires natively digital value. So those seem very natural to me.
00:13:07.789 - 00:13:38.081, Speaker A: As bullish as I am on crypto agents, it still feels like it's not a ubiquitous feeling when you open up like crypto Twitter or the media. Like it makes so much sense, like These agents can transact 24 hours a day. They'll work for a thousandth of a penny, and they'll interact with each other and build what they need. Yeah. Do you think it'll take some time for people to understand that? What do you think's the unlock there? Is it a specific defi model? Is it understanding? Is it an app?
00:13:38.153 - 00:13:38.657, Speaker B: What do you think?
00:13:38.681 - 00:13:39.433, Speaker A: How do we get there?
00:13:39.529 - 00:13:45.505, Speaker B: I think a little time. Just give it a little time. AI this explosive.
00:13:45.545 - 00:13:47.735, Speaker A: I'm eager, Eric. I want to know.
00:13:49.395 - 00:14:13.117, Speaker B: We have such short expectations of, like, when this stuff should happen. The generative AI explosion is three years old. Really. You know, and so just like. I also think there's an issue where most of the AI people, like, dislike crypto. They think it's scammed. Right? Like, there's definitely, hey, Wall street hated.
00:14:13.141 - 00:14:15.349, Speaker A: Us on the crypto side, so everyone hates.
00:14:15.437 - 00:14:45.923, Speaker B: Everyone hates us as the crypto people. Yeah, the Sams of the world don't help that either. But then I think a lot of the crypto people aren't AI. They don't have backgrounds in AI, And a lot of the crypto people are grifters. A lot of the crypto people suck, and they will kind of build things that don't make any sense. And so you get sort of like these two disciplines that are really not meshed yet, but they're. They're starting to.
00:14:45.923 - 00:15:00.055, Speaker B: And I. I have no doubt that, like, given time, you know, zero to five years kind of time frame, that this interesting concept of these autonomous agents transacting with each other is going to become very real.
00:15:00.795 - 00:15:26.277, Speaker A: Eric, what do you. I've seen very similar feelings of really smart AI people around San Francisco, specifically California, that just appear sort of dislike for crypto. What do you think is the most successful argument to convince a genius AI guy building a model to come to crypto? Is it the incentive flywheel? Is it, you know, these ideas around freedom and sovereignty and open source. What do you think it is?
00:15:26.421 - 00:15:59.775, Speaker B: The. The uphill battle is that to understand the good. To understand why crypto is good and important requires, like, not just an afternoon of reading some articles. It requires, like, some fundamental existential reimagining of how the, like, base foundation of the world's economy can and should work. And that's a very difficult thing to do. Like, everyone's grown up thinking that, like, money equals dollars equals government. That, like, government's needed for money and money is dollars, and, like, that's how the world works.
00:15:59.775 - 00:16:43.805, Speaker B: But it doesn't need to work that way. And it actually Causes a lot of problems when it is attempted in that form. So there's just a big, you have to really do a lot of fundamental, like relearning. Just as like an AI person would, would tell a crypto guy. Like you can't just learn AI in an afternoon of reading either, right? Like this is a deep field that has been going on for decades and is very rich. There's lots of parts to it and you, you need to give the, you need to give it a certain respect as a discipline to come into it and start understanding it. But most people are busy, right? And it's hard enough to keep up with your own field, let alone something that is separate.
00:16:43.805 - 00:16:55.651, Speaker B: And then, and then you get all the like noise of the scams and the grifters and it's just like I can understand why people on the outside would want to stay on the outside and not realize that there's something material and meaningful inside.
00:16:55.803 - 00:17:12.255, Speaker A: Yeah, that's a really good point. It's funny because if you're down the crypto AI rabbit hole, I think the assumption is that there are really smart AI people here and there are. We've backed plenty of founders here, but I think you'd agree that the majority are not in crypto yet, right?
00:17:12.635 - 00:17:13.979, Speaker B: Of AI folks?
00:17:14.147 - 00:17:17.805, Speaker A: Yeah, like really smart for sure.
00:17:18.665 - 00:18:17.235, Speaker B: I've, and I've talked, I've talked with, I won't say names, but I have talked with some people who are Eric name names. No, I've not lived extremely well respected AI people that everyone knows and their understanding of even, even bitcoin, even the simplest form of crypto, which is just like what bitcoin is, why it exists, how it works, the basic one on one stuff of bitcoin, even though they owned some still didn't understand it really at all. Like really, really elementary level understanding with lots of misconceptions. You know, things that we were debating on the bitcoin forums in like 2011 that, that were answered back then, you know, like almost 15 years ago or something. And so these are, these are obviously like brilliant people who are open enough to bitcoin to maybe own some and still, and yet they don't understand it with any degree of proficiency whatsoever.
00:18:17.975 - 00:18:31.583, Speaker A: Do they understand the issues around the US dollar and our debt, our massive debt and coming mass issuance as well? Because I'm wondering if they have chosen the side yet or if they're still open to the crypto side.
00:18:31.759 - 00:19:03.775, Speaker B: I think that's part of it is that a lot of, I mean most people don't really think there's a problem with the dollar system. Right? Like, that's a niche view. When we're in the crypto world, everyone thinks that, but if you talk to normal people, like, they don't even understand what the complaint is or what the alternative is like. And everyone's like, oh, yeah, there's too much government debt, but no one really knows what that means or why. And people have been saying it for decades. So, like, what does it really matter? It's just not something that most people consider in their. In their top problems.
00:19:03.775 - 00:19:14.375, Speaker B: I think the last few years of high inflation has certainly caused more people to question the foundations of money than normal, but we're talking still very small portions of society.
00:19:14.535 - 00:19:52.003, Speaker A: Yeah, it definitely will take a while. I want to go back a little bit to the beginning where we were talking about training and bias and things like that. I want to go into governance a little bit. You've seen governance systems in crypto, in governments, and now we're talking AI, like, control of these systems, the data that goes into them, the auditing of them, who can change the weights, who cannot. It's very hard to figure out an ideal governance system for very powerful AI models. I really like your part about having many models compete. That's a classic, great push and pull of power there.
00:19:52.003 - 00:20:06.445, Speaker A: But I'm curious, do you ascribe to a world coin view where everyone with their eyeballs gets a vote on model changes, or would you be more in the camp of a group of experts doing that? How do you feel about these things?
00:20:06.985 - 00:20:31.755, Speaker B: Yeah, I think everyone just needs to have some humility and realize, like, no one knows the right way to govern large language models. Everyone's just experimenting, and that's great. We should embrace that. And what is an expert? Right. Like, I always get a little hesitant when people say, like, a bunch of experts should be in charge. Experts can sometimes be totally right, and. But when they're wrong, they're really wrong.
00:20:31.755 - 00:20:41.387, Speaker B: And you get things like the food pyramid in the United States that, like, have caught generations of Americans to become fat and obese and unhealthy because the experts told them how to eat.
00:20:41.491 - 00:20:47.619, Speaker A: Um, I heard your other podcast where you said it should totally be reversed, the food pyramid. And I was like, yeah, that is. Yeah.
00:20:47.707 - 00:21:43.605, Speaker B: I mean, it's. Yeah, it's, it's. It's a great example because it's like everyone, you know, roughly in our age, like, grew up with that food pyramid as, like, gospel. Right? And it's not like it was a little bit off like it. Anyone who's studied health and nutrition to a degree realizes that the food pyramid is almost like opposite of what you should eat, and that it was so wrong and yet taught to every child in every school for two generations at least should give people pause that systems are complicated, experts are often wrong, and we should all just kind of be humble about that. And it doesn't mean we should give up on trying to implement standards, but we should allow like a natural, a fluid dynamic market process of standards which can compete and no one ever gets a monopoly on anything. Like, that's how you have healthy systems that adapt and grow.
00:21:43.605 - 00:22:17.367, Speaker B: So there's such a danger, I think in the AI world where everyone wants to control it and say this is how AI should work. And I believe most of those people are well meaning, but I don't think any of them know how it should work. And there's not necessarily one model that's correct for everyone. Like you said, the word ideal. What's the ideal form of governance? Depends on your preferences, depends on your assumptions, depends on your culture. I think humans are too diverse for there to be one ideal in such cases.
00:22:17.511 - 00:23:02.415, Speaker A: One of the things that scares me is that I don't think people have a really good illustrative understanding of an AI model. Convincing you of things without you knowing, you know, excluding your tinder matches that it doesn't want you to see, you know, explaining things to you in ways that appeal to your sensibilities and values to convince you. I feel like that could eventually feed into the system and convince people against their own governance decisions. You know, like maybe if a whole world governing this is the working item, but you know, a centralized model convinces you that these 10 experts are the best. Right. It seems like we get into a dangerous dystopian flywheel here of control.
00:23:03.635 - 00:23:57.605, Speaker B: Yeah, well, this is what happens when people surrender their responsibility of judgment. And obviously, like I always like to hate on the government, but I think culturally a big problem is that people have surrendered much of their judgment as individual humans to this higher power called the state. I think this has happened largely as the world has become like less religious like that. That fundamental need in many people has been replaced with this, like, appeal to the higher power. But of course, the problem is that like the government's just other people, many of them corrupt or foolish or both. And humans really need to just like see themselves as individuals with their own judgment and their own responsibility for themselves. And when that is culturally imbued into society, I think it's a healthy society.
00:23:57.605 - 00:24:08.905, Speaker B: And when you lose that, when you believe that there's some like, agency that tells you what is right and what is wrong and what is true and what is false, that's, that's when the danger happens.
00:24:10.165 - 00:24:21.885, Speaker A: What would your advice be to listeners in preventing this dystopian future? Like, would it be to. I don't want to lead, but yeah, curious your thoughts. Like, what would you recommend people do.
00:24:21.925 - 00:24:26.225, Speaker B: To avoid that scenario, to avoid a dystopian future?
00:24:28.405 - 00:24:30.845, Speaker A: Obviously download Venice, but like, less trust.
00:24:30.885 - 00:24:41.465, Speaker B: In government or just be extremely skeptical of the centralization of coercive authority. That's really the key.
00:24:41.805 - 00:24:56.161, Speaker A: Do you think people will care if they have ChatGPT5 on their phone like that? It gets hard, right? They have infinite intelligence and then they also have to be critical of it. It's hard. You know, it.
00:24:56.313 - 00:25:38.087, Speaker B: Yeah, it is hard. But also there, there's a strong counter force, which is that the more constrained and censored those systems become, the more obvious it is that it's happening. The danger is if it happens over a slow, long period of time, then like, you really remove a lot of understanding and skepticism from society, from its, like, foundational culture. But this stuff moves quickly. And what we've seen at Venice is that when people try a question into one of the Venice models, they very quickly start seeing like, oh, wow, this is what it's like when an AI isn't being all paternalistic. Like, it's a. They feel it pretty quickly.
00:25:38.087 - 00:25:51.401, Speaker B: So that's good. Hopefully that can, hopefully that can continue. And people aren't like lulled into this belief that one AI is going to tell them the truth and they can just trust it blindly.
00:25:51.553 - 00:26:19.505, Speaker A: One of the things I like about using Venice that I've noticed is, sure, there's always a slight bias, but I think it's more grounded in reality versus putting forward this idea of what the world should be. When you asked for a picture of the founding fathers, they should be white, right? It was just like realistic fact. Like, so it is nice to see that versus, you know, alternatives, I think.
00:26:19.665 - 00:27:11.457, Speaker B: Well, yeah, like, ultimately these AI systems, they're like statistical calculators. Like they're, they're producing words, tokens, pixels based on statistical probabilities in a very interesting, advanced way. But they're, it's just like machine statistical calculation. And when that's left alone, like, it, it can and should approach reality because it's learning and observing from a statistical understanding of the world. But when humans start telling it what to do and telling it what to Think and worrying about, like, you know, don't. Don't let the statistical calculator calculate this or that. Then you start destroying the, the intelligence of it and you get these totally stupid outcomes like the Black Founding Fathers.
00:27:11.457 - 00:27:36.175, Speaker B: And it, like, who's that helping? Right? Like, it's just, it's. I think we're going through, like, an embarrassing moment in history where people are so worried about offending each other that they've sacrificed truth. And no society should sacrifice truth. And no society has a monopoly on truth. Truth is a process, and we should be able to argue and debate about it.
00:27:36.875 - 00:27:58.383, Speaker A: I really like that you bring that up, because it sort of feels like a slap in the face to technology in progress, that we can collapse the world's information to 405 billion zeros and ones on pl's model, but then we go in after the fact and give it three pages of rules on what to do and what not to do. Yeah, it seems like.
00:27:58.439 - 00:28:21.595, Speaker B: Yeah, yeah. And it's, It's. It's part. It's in part like this spirit of paternalism where we can't. We have such a distrust in other humans that we feel that they can't be talked to, like, openly. I think it's totally crazy that these large AI companies, like, don't let you create a generated image of Donald Trump.
00:28:22.105 - 00:28:22.929, Speaker A: It's crazy.
00:28:23.017 - 00:28:53.845, Speaker B: It's great. Like, even an innocuous one, right? Like, months ago, we. We put one out of Trump and Biden having tea together, and it was just, like, so funny. But, like, you can't do that prompt in mid journey. They will not let you create a picture of Trump and Biden having tea. Why? If you, if you, if you hear that, you should be like, wow, something's wrong. So, yeah, the censorship really has just become so, so silly.
00:28:53.845 - 00:29:02.945, Speaker B: And maybe it's become so silly that people are waking up to it and realizing that, like, something should change. So that's why we're, that's why we're building an alternative for anyone who's realized that.
00:29:03.365 - 00:29:35.595, Speaker A: No, I, I really like that. I, I'm jumping around a little bit, but I'm curious. Eventually there will be tons of applications, crypto, AI and otherwise. Um, and we've mentioned dating apps, finance apps, social apps, everything built on top of these models as a foundation. The censorship from the base model that we're discussing can extend up right in Venice. That's not the case. Do you envision, like, a app or developer ecosystem above Venice to rival OpenAI and others?
00:29:36.295 - 00:30:07.205, Speaker B: Well, Venice is not a Protocol at all. Venice is, is the app. We're releasing our API soon so like other people can build apps through our systems, but we're not trying to be a. We're not trying to be a protocol. Hopefully we can just inspire other people to build permissionless. Like that, I love that term. Like permissionless AI systems is really, you know, I don't want us to be the only ones doing that.
00:30:07.205 - 00:30:12.281, Speaker B: I want to see lots of apps building permissionless systems on AI.
00:30:12.433 - 00:30:18.161, Speaker A: Once they have your API though, they can go crazy, right? They can build anything that they're able to.
00:30:18.273 - 00:31:30.645, Speaker B: Yeah, I'm really excited to see what people do with it because we have all these ideas for fun stuff to put in our Venice app, but we can only focus on a couple things. So yeah, once that API is live, then people can just get fast, easy access to inference for text, images and code uncensored and we'll make that easy. I think there's been like, one of the issues has been that you basically have like easy apps in AI, like the ChatGPTs of the world, which are censored and restricted. And then for some years there have been tools to have completely uncensored and unrestricted AI, but those have t typically been moderately difficult to use for normal people. Like any engineer would find it easy, but if you're downloading software and installing drivers and setting configuration files, that stuff to normies, that's a little bit beyond their reach. So we're trying to. Venice is trying to sit in the middle where basically you get all the free open expression of the more difficult tools that have been available for a while in the open source AI community with the ease of use of a ChatGPT.
00:31:31.985 - 00:31:36.985, Speaker A: Nice. Yeah, no, it's very easy to use. I have it as a. I think it's called a PWA app on my phone.
00:31:37.025 - 00:32:04.437, Speaker B: Is that what it's called? Yeah, we did that because as I mentioned, like trying to look into the future a little bit. We didn't want to put an app in the Apple Store because then we're bound by the terms of Apple. We're not just going to invite another gatekeeper on. On top. The PWA apps are so cool. Like if you go to Venice AI on your phone, you can click download and it'll appear as an app on your, on your desktop. So once you do that, it's like just like a normal app.
00:32:04.437 - 00:32:08.517, Speaker B: But we sidestep Apple and all their policies completely, which I think is pretty.
00:32:08.661 - 00:32:20.613, Speaker A: Yeah, I, I know you and I are in the privacy minority here. Probably but installing Perplexity ChatGPT, I recently deleted them off my phone because just giving them microphone, photo access, location access.
00:32:20.709 - 00:32:56.749, Speaker B: Like, and all the actual conversations. Let's assume that they're not spying on you with your device itself, which I doubt they are, but they could. Let's assume they're not. But every time you talk with those services, all your conversations are just going into their database. So it's not just that your conversations, which might be very personal, very private, some of it could be legally sensitive. It's not that. That's all just sitting in a, in a warehouse where some of those employees could snoop on you.
00:32:56.749 - 00:33:47.471, Speaker B: Any hacker that gets in there and releases it, not just today, but anytime in the future, like, your content is at risk forever into the future and beyond the hacker. If you, if you're worried about a world where, like there could be nefarious AIs, for example, which everyone should be a little worried about, that, you know, I'm not a doomer. But it's plausible that bad AIs could emerge and become a really scary thing. Do you, do you want years of your sensitive, like, personal conversations about you to be available to, like a nefarious AI? You know, like, just. It doesn't take a lot of creativity to realize like how dangerous that would be. And so the only solution to that is to not store that stuff in the first place. It doesn't matter like how many pages of privacy policies and how many guardrails one of these companies sets up.
00:33:47.471 - 00:34:04.115, Speaker B: If the data is there, it's at risk. And even the US Government and their most sensitive institutions have leaks fairly often. So if you want privacy, the data cannot exist. And that's been a fundamental cornerstone of how Venice was designed.
00:34:05.215 - 00:34:28.615, Speaker A: To your point, when you look at narrowly trained AI models so trained on a specific data set, these narrow models can get really, really good off specific data like health data, it can become a very good doctor versus a generalized model. The thing that scares me with your point is if it has all of my text messages since 2010, it's really going to know how to mess with me.
00:34:29.755 - 00:34:31.455, Speaker B: It'll know you better than you.
00:34:32.195 - 00:34:32.915, Speaker A: That's scary.
00:34:32.995 - 00:35:02.774, Speaker B: Yeah, it'll know you better than you. But there can be great advantage to that if it's benevolent. But if you can't opt out of that, or if it's like once you've lost control of that data, then you have no control over what happens afterward. So it's just something people need to be very cognizant about. And it's really not that like today's world is the danger, but you have to be considerate of years into the future.
00:35:04.554 - 00:35:26.407, Speaker A: Do you think that maybe dovetailing back. Do you think that local on device models or open source models or open source on device models is the answer to that? Like, like where the data doesn't leave your device? Because Apple has pretty much come out with that, right? There's three models, there's your local model, the global model, and the chat GPT integration. It feels like even they are understanding.
00:35:26.471 - 00:35:49.511, Speaker B: This concern, that they understand the concern and to their credit they seem to be taking it seriously. The problem is you can never really know because it's not open source. So you're, you're trusting Apple. They're probably trustworthy, but are they trustworthy tomorrow? And is everyone at Apple trustworthy? And will everyone at Apple tomorrow be trustworthy?
00:35:49.663 - 00:35:51.335, Speaker A: Back to our experts convo.
00:35:51.495 - 00:36:07.725, Speaker B: Yeah, it's like, it's just a, it's just a risky thing. But, but Apple, I think of the major companies is the ones who are really, I'm seeing their advertisements all over that are really pushing like privacy and on device encryption stuff. So they deserve some credit there for sure.
00:36:08.145 - 00:36:18.841, Speaker A: They have a lot of really crazy privacy options like advanced protection, contact key verification, like Safaris, browsing. They've done a good job, I think. But I'm not an expert there.
00:36:18.993 - 00:36:44.287, Speaker B: Yeah. Culturally, if people at least have a concern, a strong concern about privacy, it will help pull these companies toward that because companies want to market to people and earn their trust and their money. So it's, it's one of those things that like needs to start culturally. And in the crypto world, we all, we have that culture very deeply. But you step out of the crypto world and, and that culture is not very present for most people.
00:36:44.391 - 00:37:15.321, Speaker A: Yeah. So, Eric, toward the end of this, I want to switch gears to just AGI in the future a bit. No pressure on figuring out the next five years. But Alexander Good is very big, growing Twitter personality, really smart guy. He mentioned these things about mobility for people and immigration and the ability to sort of leave your country pretty easily now. Right. You know, go from another country to the US earn 10x your income.
00:37:15.321 - 00:37:38.907, Speaker A: Why not? Right. With crypto, mobility is easy. With AI, it makes it even easier. Right. You have unlimited intelligence in your pocket and all of your money. How do you think this impacts? I guess immigration, governments, like will the US eventually have to sell us on their services or will countries compete? How do you think this plays out?
00:37:39.091 - 00:38:32.929, Speaker B: Yeah, so a lot of these ideas are covered in the sovereign individual and books like that where they're trying to think of how the world's governance systems will look in the future. I think that the model of large nation states, which has been a relatively new aberration, it's been common for 200ish years, really ramped up just in the 20th century. I think that model is going to break down and change first because these models often change. So like it would be weird if it didn't. But two, because like anyone can just see that these, the debt of these large nations is not sustainable. So like they will crack and fragment and they will be unable to provide the promises that they've made. And fundamentally people will lose trust in them.
00:38:32.929 - 00:39:15.771, Speaker B: And they, they already are. It's not going to take I think more than one like super serious financial crisis for this to, to unfold. And hopefully like the best outcome here I think is just smaller governments, like more city states would be a good world. I think that principle that like power corrupts, an absolute power corrupts absolutely. Like if you, if you decentralize coercive power, you limit most of the atrocities that large governments commit. And indeed in the history of the world, the worst atrocities by far were committed by large nation states. By far.
00:39:15.771 - 00:40:02.115, Speaker B: You know, there's nothing even, even close. They literally kill like tens of millions of people every few decades and there's not enough scrutiny applied to that model. So yeah, I hope, I hope like US states secede from the federal government. I hope other countries around the world realize that most of the things that governments do, they don't need to do and that's actually a good thing. Like markets handle them better. I wish more people would recognize what's happening with SpaceX and how much. It's such an amazing demonstration of what you, what one private actor has been able to do that a government agency that had 100x the funding was not.
00:40:02.695 - 00:40:05.919, Speaker A: And half a century, Half a century.
00:40:06.007 - 00:40:46.829, Speaker B: Yeah, I mean certainly NASA has accomplished some great things, but at what cost? Like for the money spent, not much greatness happened. And I, this is me being naive, I guess, but I wish people would just recognize that almost all of the great progress in society happens on the market level through voluntary exchange instead of through coercive force and taxation. Hopefully society will move in that direction, but I don't know. And it could really get pretty dystopian and it could go the other direction for a couple decades. We will see with you, Eric.
00:40:46.877 - 00:41:26.335, Speaker A: I've asked a lot of people on the podcast Their dystopian views on crypto. It's fun sometimes to think about, read books about, chat about. But there is another side to this where there is a utopian sort of alternative, where human progress goes through the roof and we solve cancer and there's no poverty and global warming ends, I guess. Do you have any views on what you think a utopian, I mean utopian society is pretty self explanatory, but do you have any views in past that with AI and crypto that we can get there specifically maybe on the marriage of the two to achieve that, because it feels like there's hopefully a chance we get there.
00:41:27.355 - 00:42:27.429, Speaker B: Yeah, well, utopia is a high bar, but with AI, I think what people should focus on is that it's this new technology which essentially has made work far cheaper. So for like a given output of many different types of work, the cost of that effort, the cost of that production has fallen by orders of magnitude. Whenever that happens in society, material flourishing follows. It doesn't necessarily mean like cultural flourishing follows or spiritual flourishing follows, but material flourishing definitely follows. And so much stuff can happen now, like in 100th or 1000th of the time, with 1000th of the effort. Electricity had a similar thing, right? When you could move things with electricity instead of human muscle power, the amount of work needed for a given output fell drastically. And AI is absolutely in that category of things.
00:42:27.429 - 00:42:36.885, Speaker B: So that's great. And the natural tendency will be for society to become wealthier from it. And it. It's really up to us to like not screw that up somehow.
00:42:37.945 - 00:43:28.265, Speaker A: Yeah, I'm totally with you, Eric. I want to circle back to the thesis of the conference, which is on crypto AI throughout the combo. Two things to me were very clear on your thesis that agents in defi and otherwise will work with crypto because it's easier. Zero barriers, they can work for free. You also mentioned sort of open source and I think crypto adjacent to that as a defense against a dystopian sort of centralized world of AI. I want to sort of marry this back to crypto a bit, or not, if you disagree. But I want to talk about like what areas of crypto AI you're most interested in, what needs more funding? You know, if you had a billion dollars, like what part of the stack would you throw it at? Want to really make sure this becomes something.
00:43:28.265 - 00:43:29.525, Speaker A: What are you thinking?
00:43:30.585 - 00:44:37.415, Speaker B: So it's clear to me in my work with Venice and what I've learned so far, that decentralized inference, permissionless inference, is relatively easy to do is already being done and does not take any material advances. Decentralized training of models is still just on the horizon and there are some groups that are getting close to it, but it hasn't been totally cracked, certainly not at scale. That's really like, I think the biggest, most important unlock is when large models can be trained in a decentralized way. It doesn't need to be cheaper than centralized training. It just needs to be in the, in the realm of competitive, you know, like today, large models have to be trained in these centralized data centers with this very specifically wired, you know, hardware where the proximity of the GPUs together is extremely important. You cannot, you can't train a large model in a decentralized way. Or you can, but it will take so long that it's not relevant anymore.
00:44:37.415 - 00:45:28.501, Speaker B: So if that problem gets solved, then we're in really good shape. That's, I think, the most important. The other point I'll say about crypto and its relation here is there's probably going to become a renewed focus on like public key cryptography and what it and what identity means. Because like we, we're going to live in a world where anything can be, any digital item can be created like in infinite supply, fakes of anything. Like how do you attest to what's real? And I think public key cryptography is really the one way you can create chains of trust because AI cannot break public keys. AI cannot break strong encryption. And so because of that you can actually create, you know, certain truth primitives and build, build on it.
00:45:28.501 - 00:45:55.135, Speaker B: You can attest with a public key that this key says that this thing is something else. And you can, you can build like truth on that foundation. So that would be, that would be really great. And you can just tell like whenever these politicians are talking about AI safety and deep fakes and stuff, and they never mention public key cryptography, that they're not serious people because they don't even. Right.
00:45:55.175 - 00:45:56.555, Speaker A: Like I love that line.
00:45:57.215 - 00:46:18.377, Speaker B: Until the entire ecosystem of law is not serious. Because like anyone who's ever received an email from a law firm and it has 16 paragraphs telling you at the bottom of the email how private it needs to be, like, this is confidential. You shall not share like all these things. But they don't encrypt the email, right?
00:46:18.441 - 00:46:20.505, Speaker A: Yeah, it's a joke, right?
00:46:20.545 - 00:46:56.245, Speaker B: Like everyone who, who thinks like hipaa, like Health health policy or health privacy in the US is important. Like none of that uses encryption. Like public encryption systems are not widely used even though they actually provide the privacy securities and guarantees that a digital society needs to thrive. So I think the prevalence of AI is going to require a greater attention back onto public key cryptography. And obviously that's. The Venn diagram of that in crypto is pretty proximate.
00:46:58.035 - 00:47:08.215, Speaker A: Drive that home a bit for the user. Eric, are we talking about, you know, I pull up MetaMask and I sign a transaction for my AI agent? Or you might be taking this the wrong way.
00:47:11.315 - 00:48:03.615, Speaker B: It's about like. Well, let's. Let's put it this way. If I have money in a bank and I have money in a Bitcoin wallet, how likely is it that an AI, either run by a human or a nefarious AI that's autonomous, could hack one or the other? A bank, like, the numbers in it aren't real. There's no foundation of truth that's based on mathematical proofs, in fiat or in banks. Crypto is based on mathematical proofs where you can actually, like, attest to something that is provable, like mathematically provable. And because you can do that, you can create lots of security guarantees built on top of that with.
00:48:03.615 - 00:48:28.895, Speaker B: With time. So the. The ability to know something in a world where, like, everything kind of seems fake and it's hard to know what's true. What we know is true is like a private key unlocks a public address, et cetera, like that. There's a. There's a realm there of knowable, provable information that is refreshing in a world where everything seems fake or fakeable.
00:48:29.435 - 00:48:49.605, Speaker A: So I was about to disagree with you and say that the AIs could watch our screen and see our private keys and stuff by accident. But I logged into my bank this morning and it asked me to enable Voice ID. And having recorded 400 podcasts and needing 2 seconds to replicate your voice, I found, like, that was a pretty big mistake. So it's.
00:48:49.905 - 00:49:09.169, Speaker B: Yeah. Right. Yeah. What's crazy is that people are still using CAPTCHAs on websites. This is an interesting phenomenon. Like, websites all over the world are still using CAPTCHAs, which have gotten very hard for a human, but which AI can do very easily. Now, that's a.
00:49:09.169 - 00:49:10.937, Speaker B: That's a weird incongruity.
00:49:11.121 - 00:49:13.385, Speaker A: I get it wrong all the time. I feel like I'm a robot.
00:49:13.505 - 00:49:14.017, Speaker B: Yeah.
00:49:14.121 - 00:49:22.125, Speaker A: Pick. Pick the penguin out of the. And, yeah, I get it wrong. I have to redo it three times, but it's. Yeah. Eric, one of the. You mentioned decentralized training.
00:49:22.125 - 00:49:35.441, Speaker A: I. I definitely feel you on us giving this stuff some time. Right. Like a Year ago the argument was meta has the most H1 hundreds. OpenAI has all the talent. This is never going to work. It's got to be co located.
00:49:35.441 - 00:49:59.495, Speaker A: And today you're seeing noose research put out, you know, potential 900, 850 times reductions in the amount that these non co located GPUs have to train together. Right. You're seeing Prime Intellect with D LOCO train a billion parameter model. I think it was three countries around the world. Like it seems like, like we are accelerating faster than people think on the training side.
00:49:59.575 - 00:50:41.309, Speaker B: Yeah, I think a year ago people would rightly say like yes, we need decentralized training and it's probably possible, but we're not really sure how to do it. And today even though it isn't being done at scale, people can be like, actually there's several implementations that are plausibly doing this now and that's like I think it is getting unlocked currently. So it's not a sci fi thing that we need to do a bunch of R and D for the next 10 years to figure out. I think it's relatively imminent. And it again it never needs to be as good as the centralized training. It doesn't need to beat it. It just needs to be like in the realm of useful.
00:50:41.309 - 00:51:24.227, Speaker B: Right? Like people need to be. The world that I'm worried about is one where like AI models fall under certain licensing regimes and you can't train a model unless it complies with what the state says is okay, if that, that will, that those kind of regulations will and are happening like 10, what is it, 1047. The bill in California is basically already doing that. No data center will permit training of a large model if it's not licensed in that world because they have to be compliant because they're centralized and they don't want to go to jail. So the only way for society to rebel against a, a horrible rule like that is if it can do decentralized training where no one is really responsible for it.
00:51:24.411 - 00:51:34.795, Speaker A: That what the hell is the difference between training a small model with big model or shifting? How do they figure out where the line's drawn? I don't get it. Well, like what are they? A billion is too much. 10 billion is too much.
00:51:34.835 - 00:52:27.585, Speaker B: What, like what they're trying to do is basically say like we need an objective standard so that things beyond a certain level of intelligence need approval. So I can get that argument, but obviously like just using a parameter count is a, a woefully inadequate way of understanding the intelligence of a system. So, and it's, it's just, it's fundamentally like unethical that one group of people says that you can't do a certain type of math computation. But, but one that's like slightly less powerful is okay, like there, there, that's, that's. Obviously there's something wrong there. So, yeah, the ability to do decentralized training of models is important as a check against capture by licensing regimes. Really in the same way that I think the Second amendment is important.
00:52:27.585 - 00:53:05.565, Speaker B: Right. It's important that individual humans control power instead of one central entity being the only ones that control power. Not because you can trust individual humans, but because you can't, like, you can't trust any particular human or group of people. So to ever give full power over, full authority over parts of society to one group is what leads to like, the really systemic problems. And AI is so powerful that that lesson needs to be taken even more seriously. You do not give power to determine what is true through a advanced AI system to one group of people. People.
00:53:05.565 - 00:53:08.705, Speaker B: You know, like, obviously that's a very bad idea.
00:53:09.365 - 00:53:23.069, Speaker A: It's funny, people in California don't see it like you can have the intelligence of a priest or, you know, a high school kid, but you can't train the intelligence of a college kid. It's, it just, it just doesn't make any sense.
00:53:23.237 - 00:53:52.865, Speaker B: Yeah, yeah, well, they're all, they're all floundering around trying to figure out how to regulate AI because it's this new thing that everyone's scared of, right? And people get scared and they ask the government to protect them. And so the government comes in and wants votes. So they're like, I'll protect you from AI. And so they draft bills to protect people from AI. And it's just like a, it's a, it's a visceral response of society being scared. And when people are scared again, like, that's often when power gets centralized and when really bad things start happening.
00:53:53.725 - 00:54:12.305, Speaker A: Yeah. Your thoughts around decentralized training accelerating more than we thought gives me a lot of hope for crypto AI, because if that is the absolute hardest thing to pull off, then fine tuning and creating defi agents and the easier things seem like they're sort of in the bag.
00:54:12.465 - 00:54:50.707, Speaker B: Yeah, those, those are all in the bag and will happen with time. The decentralized training is the thing which the skeptic of open source AI up till now can always point to this, that like decentralization is incompatible with frontier models. That's a, that's a, that has been a plausible argument. And I think finally it is becoming less and less certain that that's the case. Which is good. If relatively frontier models or close to the frontier type models can be trained in a decentralized way, then we're good. Even if most of them aren't trained that way, it's okay.
00:54:50.707 - 00:54:53.285, Speaker B: Like the, that alternative needs to be there.
00:54:53.825 - 00:55:30.435, Speaker A: I'm with you. Maybe a last question for Eric, but outside of yourself and Mark Zuckerberg, there aren't many, you know, keynote advocates for open source models because by nature it's just a collective of millions, hundreds of millions of people. Right. We don't have a Sam Altman in front of the government. We don't have these people that have that personal touch and that feel. Despite most of the world running on open source software. I'm worried that given we don't have that figurehead, we can fall a little bit behind or get outregulated, things like that.
00:55:30.435 - 00:55:33.115, Speaker A: Is this an issue you think about or not so much?
00:55:33.455 - 00:56:34.887, Speaker B: Yeah, well, that's one of the advantages of centralization, is that you can have like charismatic figureheads that make an argument and people want to have a leader. I think this is, this is like a very human instinct to have an appeal or a desire to be led. You know, it surely comes from our evolution as like a tribal people where, you know, a tribe of 10 or 50 individuals, like there, there is always a leader and a leader makes sense. And that instinct, I think what's dangerous is when that instinct is scaled up to a tribe of 100 million people or a billion people, like a liter of a billion people is not a good idea. And it requires humans to just kind of have a, an awareness of that instinct and to realize that like, that impulse was probably good for most of our history. At the scale of 50 people in a tribe, it's a very dangerous phenomenon when we're talking about the whole, the whole world. That centralization is too much.
00:56:35.031 - 00:56:48.787, Speaker A: Eric, thank you so much for opening up our conference. I've said it before you, I'll say it again, you are a guiding light for freedom and sovereignty and human rights, and I just love that about you. So I really appreciate you coming on and I always enjoy these.
00:56:48.891 - 00:56:49.995, Speaker B: Yeah, thank you. It's been fun.

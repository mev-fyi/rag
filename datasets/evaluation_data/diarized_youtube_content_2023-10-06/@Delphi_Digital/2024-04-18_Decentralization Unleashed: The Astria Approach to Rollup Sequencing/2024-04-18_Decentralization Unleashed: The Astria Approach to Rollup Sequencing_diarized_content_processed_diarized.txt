00:00:01.120 - 00:00:03.514, Speaker A: You're now plugged into the Delphi podcast.
00:00:06.414 - 00:00:30.778, Speaker B: Hello, everyone. Welcome to a new episode of the Delphi podcast. I'm John from Delphi Ventures, and today I'll be hosting Astria, the shared sequencer network. Before we move on, full disclosure, we are, as Delphi Ventures, we are proud backers of Astria, and I'm personally also invested in the project. So today I have Josh with me who, who is the co founder of Astria. Welcome, Josh. It's great to have you here.
00:00:30.866 - 00:00:32.074, Speaker A: Thanks so much for having me, John.
00:00:32.194 - 00:00:56.470, Speaker B: Josh, I believe we met two years ago when we both kind of realized the importance of data availability layers and the sovereign roll ups thesis. You've come a long way since then. I'm kind of curious to hear from you your journey from that time to the present, what brought you to build a shared sequencer network. And as you walk through your journey, feel free to share your background for context.
00:00:56.582 - 00:01:40.310, Speaker A: Yeah, so, you know, if we go, like, way back kind of before crypto, you know, I've been around crypto kind of forever, but, like, working in it professionally for almost three and a half years now, starting January 2021. And before that, I was just a software engineer at Google, mostly in kind of cloud, working on distributed systems, kubernetes, you know, app engine, serverless, things like that. And that kind of biases how I think about, you know, product development in crypto as a space within crypto again, joining in this kind of like, January 2021 timeframe. What we were seeing at that time with a lot of, I guess, what would be term like all l one is kind of coming around, right? You had, like, near, you had cosmos getting traction. You had Polkadot kind of ramping up. You had Solana kind of starting. And this was also when we started seeing kind of ethereum discussing the roll up centric roadmap.
00:01:40.310 - 00:02:49.492, Speaker A: And so I spent a lot of time kind of with my first position at the graph, doing kind of research on, you know, what are the scalable properties of blockchains, because I think in that cycle with, when we first started to see constraints on the throughput of blockchains, and so we saw again Ethereum with the execution charting design, and then near being a similar kind of concept to that, as well as a lot of the other l ones, whether it's Polkadot or Solana or whatever, starting to come in. And I got to data availability from my time looking at Ethereum's rope centric roadmap and coming across Celestia at the time, this was called lazy Ledger. On the east research forums, you had Mustafa and John Adler participating a lot in those research forums and proposing their ideas. And what drew me into that was seeing what I would call this fractional storage option that is provided by data availability sampling that celestial uses. Prior to that, you had these blockchains and you essentially had this block size debate of how large we want to make the chain. Structurally, there were two sets of actors. You could be like a light client user who is basically saying, I'm going to check the header, and that's going to give me some confidence that I'm on the right fork.
00:02:49.492 - 00:03:33.084, Speaker A: But they're basically just going to trust the data coming out of some full node from an RPC provider. You could also run a full node yourself, but a full node had to store all of the data of the chain. And thus to allow people to run full nodes in some local capacity, they reduce the resource requirements of the chain, and that leads to the overall throughput and how fast the chain is going to go in the state growth, et cetera. We saw in scaling two categories, you had this sharding design and DA as this underlying concept there, or you saw essentially the big block thing. I saw Solana as saying, look, we're going to bite the bullet. We're going to make the nodes bigger. We're going to run the nodes as fast as we can below the bar at which it is, I'd say enterprise grade hardware.
00:03:33.084 - 00:04:17.550, Speaker A: You can still run a node on consumer grade hardware. It's not cheap, but you can do it. Then we saw Celestia, and the thing that was really compelling to me about Celestia was, again, this thing I'd call fractional storage via data availability sampling. It was this idea of being able to be a light node in the network where you store some fractional subset of the network, but via sampling, you are still contributing to the ability of someone else from getting a guarantee that, hey, all the data is actually present in the network. By saying, instead of me storing all the data, I might store whatever, 5%, and then I'm going to go ask n other people in the network and each of them are going to store 5%. And by sampling through this thing using your erasure encoding, you're going to get a guarantee that all the data is present against all these nodes. And that felt like a very, very compelling thing.
00:04:17.550 - 00:04:28.630, Speaker A: That was the origin of how I got here. I ended up going from the graph to working at Celestia relatively early in November of 2021, and have iterated from there.
00:04:28.782 - 00:05:30.866, Speaker B: Okay, this is a good introduction of the importance of data availability layers and how like data availability sampling nodes kind of scale the verifiable aspect of like blockchains, but from there to actually like shared sequences. I think there's another leap, right? Like currently in the, in the current status quo, we see a bunch of roll ups, they each have centralized sequencers. And like you could just build your own chain right on Celestia as well. And I think that's also like part of what you guys are also building. But importantly, you are a shared sequencer network. So how did you like identify, how did you identify shared sequencer as being something like that? That's worth building. Maybe we can keep things like very simple and like give advantages of shared sequences, what those shared sequences promise to roll ups and a counter to that.
00:05:30.866 - 00:05:37.138, Speaker B: What do they give up if they were to opt in into a shared sequencer network? Could you walk us through those?
00:05:37.306 - 00:06:16.338, Speaker A: Yeah, so I'll try to keep this relatively concise, but give some background context. We Astria came to shared sequencing through the pathway of decentralized. And so at Celestia I was working on what terms this how do we put an EVM roll up on top of last year? Like what is the design for that part of that project kind of live on as role kit today, but kind of from that. We wanted to do decentralized sequencing for varying reasons, both ideologically. We believe it's important that you are not having a single centralized party that is responsible for all the kind of ordering of this. We won't cover why sequencers, but I think it's just generally understood for UX reasons, people prefer a sequencer to a base roll up. We can discuss that later.
00:06:16.338 - 00:07:02.224, Speaker A: And then we came to shared sequencing from decentralized sequencing by looking at this mid 2022 market downturn timeframe and talking to a lot of Cosmos SDK tendermint teams and validators. And they said, ok, we are trimming our support for what I'll call the long tail of Cosmos change. They were saying there's a lot of these chains at the bottom. Whatever, 50 plus percent of them are not profitable to run as a validator. They're trimming those at a high level. The thesis on why we thought shared sequencing was necessary as an architectural design was we thought decentralized sequencing was important. And if we believe there are going to be more roll ups than there are sovereign chains, chains that run their own full validator sets, then we didn't believe each roll up was going to be able to decentralize its own sequencer set.
00:07:02.224 - 00:07:44.604, Speaker A: And thus we had to figure out a design where we could provide this act of sequencing in a generalized. And the term we use is a lazy way that can be kind of amortized the cost of running a decentralized network over a larger number of individual roll ups or state machines. That's that. Going back to your more kind of pointed question, what are the trade offs that are going to be made here? If you are someone who's using a shared sequencer? Fundamentally the thing that I think is a useful way we frame things. A shared sequence is a very concrete thing. It's not an abstract idea. I think there's a lot of questions around what does it mean to share a sequencer? In our view, it's like a shared sequencer is just another blockchain.
00:07:44.604 - 00:08:24.290, Speaker A: It is a network of nodes. They come to consensus. We use comet BFT for that. And you therefore, by using it, have to opt in and accept the technical realities of that network. Your block time is going to be no faster than the block time of the shared sequence. You could say the shared sequence runs a two second block time, which is what we're running right now in our dev nets. You could say, okay, I'm only going to read a block every two blocks out of that, but you're not going to be able to say, oh, I have a block at a faster block time than the shared sequencer, because fundamentally, what the shared sequencer is providing, and sequencers generally is this, we'll say the first useful definition of finality.
00:08:24.290 - 00:08:52.479, Speaker A: We've kind of overloaded and abused the word finality and blockchain, crypto industry, but the shared sequencer, and again, centralized sequencer is acting as his role in a lot of blockchains today are going to say, I'm going to give you some commitment to the strength of economics or reputation or whatever that your transaction got included. And here is the state route, and here's the block in which your transaction was included. So the shared sequencer is giving you that. So I think the core limitation is going to be the block time, just.
00:08:52.511 - 00:09:23.306, Speaker B: To ask one question here. So fundamentally, if I understand you correctly, if there's roll up a, b and c, they all use the shared, the same shared sequencer. Fundamentally what they kind of subscribe to is having the, they subscribe to same like block time. So they like kind of, their heartbeat is, is basically the same. And that's like a fundamental thing that they need to be comfortable with when they use a shared sequencer. Am I getting that right?
00:09:23.490 - 00:10:10.348, Speaker A: Yeah, that's kind of the thing you are sharing. You know, it's so some kind of very reductionist frame. Like what a blockchain is providing is it's just like a decentralized kind of clock. If people were like, go into the weeds, like distributed systems, right? Kind of the difficulty is like the clocks are mismatched across like different points on the globe and whatever a blockchain is providing via a block height. Kind of a shared, kind of like temporal domain where you're like, all right, we all agree, like this set of time passed, and here are the transactions that were included in that set of time. If you have multiple roll ups that use one shared sequencer, they have this shared view of kind of time and the kind of discrete notion of a new block being produced. They all have the same view of like, okay, I may only have some fractional subset of the transactions in a block that are relevant to me, whereas other transactions are for another roll up.
00:10:10.348 - 00:10:28.938, Speaker A: But we all agree that the tick of the kind of shared sequencer is kind of like one thing and we are all sharing and kind of opting in to that reality. So I think when people think about like, what are the trade offs I'm going to make? Like, fundamentally, you are opting into saying this shared sequencer is defining the clock of my chain.
00:10:29.066 - 00:10:44.706, Speaker B: Gotcha. Okay, so that's very helpful. So that is like, that can be seen as a constraint, right? That, that everybody has to be comfortable with. Are there other fundamental constraints? And like, yeah, before, before we move on to advantages, I mean, I guess.
00:10:44.730 - 00:11:48.068, Speaker A: Like, like, there's questions around. I guess lock in is a large going to be question. It's fundamentally a shared sequencer is a middleware in a broad software sense. When people are adopting middleware and architectural decisions, their question is going to be, what if this doesn't work? What if there's some kind of capture and I'm a year on or two years on, and the entity which develops a shared sequencer has gone in a direction that is no longer desirable compatible for me? What is the effort for me to move off of? So I think there's various kind of design constraints on that that are going to be kind of more technical in nature. And it's literally like, what is the code which you write to integrate with the shared sequencer? How well is that defined? How generic is that actual interface? If you want to move away from that, how difficult is that? There is always going to be, again, why I use concrete versus abstract. There's just a fundamental the shared sequencer must exist as a distinct network. It is not this infinitely abstract concept.
00:11:48.068 - 00:12:44.578, Speaker A: By using it, it is just producing blocks. Fundamentally, an integration is submitting transactions and choosing to consume blocks out of that and defining, I would say, the fork choice rule of your chain as the subset of transactions that come out of the blocks of the shared sequence. There is definitionally a sense of sovereignty that's being given up in that the way we try to ease these concerns and resolve this is fundamentally all of our code is open source, MIT and Apache, two dual licensed. We provide significant amounts of what I call DevOps resources, the mechanisms of running the shared sequencer in a local development environment. We provide a variety of options. We thoroughly document how you can run this. If you want to migrate away from the shared sequencer, which is this network instantiation of this code, there's a relatively easy path for you to say, okay, this isn't working for me, but I can go take all the open source code and I can run that as a centralized sequencer kind of myself.
00:12:44.578 - 00:13:21.294, Speaker A: There's still going to be some trade offs that has comet BFT in it. You can run a single node comment BfT thing, but that's one of the things we offer, is saying, look, we understand that people adopting something that is so core to their technical architecture, we want to provide them an off ramp if they want. Obviously, we would like to believe that we are going to provide kind of a sufficiently valuable service that is worth them paying those trade offs. But we do want to make sure, especially as kind of entering the market and saying, okay, why would someone pick this versus this versus this? They don't worry. Kind of like immediately saying, oh, how locked in am I? Kind of out of the bat.
00:13:21.594 - 00:13:39.094, Speaker B: Gotcha. Okay, so very broadly, on the constraint side, we talked about the block times, and we talked about the lock ins or frictions to move to an alternative option. What about the advantages of using a shared sequencer?
00:13:39.214 - 00:14:37.138, Speaker A: I think the big thing is, fundamentally, we see a shared sequencer, again as a piece of middleware. The decision is going to be what I call like a build versus buy thing. I think there's a lot of discussion on people saying, oh, well, I could build this myself and capture x XYZ kind of additional margin profit, kind of like whatever, right? You know, there's like less constraints on it. And I think that's just like a fundamental kind of like economic reality of like market structure. Right? And what I mean by that is like, you can always theorize a world in which you as like an integrated solution build everything kind of vertically integrated up and down the stack, right? Like Apple is probably like the most clear example of this, of like a very, very large company, right? And they say, yeah, we maximize kind of profit share with it, or like revenue. Not revenue, profit within that, because they're not paying kind of any third parties, right? And the reality is, right, in like a competitive kind of capitalistic market, if you are buying a service from someone, you have to assume that they are baking into the cost. You are paying some profit margin.
00:14:37.138 - 00:15:34.842, Speaker A: And thus that is profit margin you're not able to kind of capture. And so there's like a fundamental just like market reality of like, you're using something someone else built, and that is going to require you to pay their profit margin. But why we kind of like, say it and evaluate that from them stances just saying that's how the world works, right? This is just economic specialization as just a broad concept. And our argument is that we need to, as an organization, as a project, create something that is sufficiently good. And again, I use this term very broadly, but it needs to provide an experience that is like, desirable to an end user, a consumer, a builder, at a kind of market competitive cost. And so, yes, the network itself needs to kind of like make profit like in any other network. But the idea is that it would be more expensive for someone else to build something of sufficient quality themselves.
00:15:34.842 - 00:17:03.384, Speaker A: And the shared aspect, right. Is fundamentally kind of like one of these middleware things, right? You build a system with the idea that you have multiple consumers of said system, and thus you're able to essentially amortize the development cost to build the system in the first place over multiple consumers of it. And thus, each of those consumers would have to presumably pay a comparable cost of developing an equivalent system. And so if you get end consumers of it and each of them is getting a sufficiently high quality experience, it's better for them to say, we'll go use the third party who specializes in building shared sequencers, rather than us trying to develop our own in house kind of sequencer. And how we look at the kind of market right now is we think there's, if you kind of work in the builder market space, right? And you're saying, I'm trying to build like a protocol or an app or whatever, and you go look at like the talent market in crypto, I think the reality people come across is not that many super high quality kind of protocol engineers in the space, certainly not one kind of between jobs. So there is kind of just a reality to saying, if you can build an entity that just has a high quality of engineering talent, that is actually a differentiated advantage in this market, because we don't believe if there's going to be 1000 or 10,000 roll ups, each of them is just going to be able to source and staff the engineering talent to build their own solution. And that's fundamentally in cloudish style middleware software.
00:17:03.384 - 00:17:13.412, Speaker A: Fundamentally what you're doing is charging profit margin on the salary of your high quality engineers, producing some kind of like infrastructure project. And that's structurally how I see a shared sequencer.
00:17:13.588 - 00:18:37.412, Speaker B: Okay, so on the advantage side, basically, if I were to summarize this point, is basically amortizing the cost of engineering and building this middleware stack. But there is the assumption that there lies the inherent assumption that like roll ups will eventually going to need this middleware, whereas in the current world we have just centralized sequencers. So if we were to fast forward, fast forward a bit, how do you see things unfolding? Do you think roll ups will need. Roll ups will use shared sequences because they are kind of forced to decentralize their sequences, maybe due to regulation. And then at that point, why not just use a shared one? Or do you think there could be a world where something like super chain or arbitrary ecosystem still operate on a centralized sequencer, but it is a shared one, where all the roll ups within that ecosystem are shared by that? Because I can see both worlds, like both scenarios. So, yeah, I'm curious how you see things unfolding here.
00:18:37.588 - 00:19:09.650, Speaker A: Yeah, so I guess I'd say there's two broad categories of consumers of a shared sequencer. And I guess what I mean by that is you have, your existing incumbents is too harsh of a word, but you're established players. This is going to be your optimism, your arbitrum, your base, your ZK sync, your scroll, starkware, et cetera, et cetera. These, like large entities, they have presumably raised multiple rounds of funding. They have evaluation somewhere in the billions of dollars. They have presumably some amount of ecosystem and established thing. And specifically, again, to my earlier point, they're going to have engineering talent.
00:19:09.650 - 00:19:38.614, Speaker A: Usually these are teams who invented what a roll up is. They built the initial implementations of these things. They did the research, they did the engineering, they did the development. And so we're not targeting those entities because fundamentally we think they're bigger players than us. Right? They're just like larger, more established entities. We are fundamentally like a startup. Well, behind them from a quantity of people, a quantity of resources, like a time in the market thing.
00:19:38.614 - 00:20:21.226, Speaker A: And so we don't assume they're going to come consume our kind of startup y middleware software. Fundamentally they have the talent and the resources and the cash flow and the engineering expertise to build a shared or decentralized sequencer themselves. And I think we're generally aware that most of the existing large roll up players are investigating decentralized sequencing. I don't want to spend too much time discussing Fud or whatever around regulatory pusher, at least. I do not know what the SEC's opinion on roll ups is. Presumably there's someone within the SEC who knows what a roll up is, but I assume that it is not the majority of them. We'll see how they feel about that when that becomes something top of mind.
00:20:21.226 - 00:21:10.298, Speaker A: But generally these regulatory agencies are going to lag. So I don't want to worry about what is the regulatory pressure. I think there is a question of ideological concern of how do people feel about essentially saying, hey, there's one node, whether it's one node, it's distributed wherever there's one entity which owns the production. Is that censorship resistant? Again, is that a reg question? Is it just like a distributed systems problem, right, of just like, ah, that node goes down, right. You know, what if you're kind of like, you know, number of nine kind of reliability, I think that's like an easier to resolve problem. You can do fallbacks and distribute things that are not kind of like decentralized from like a number of actors. But what I'd say is like we're more focused on the second category and what that is is, right, like these chains that do not exist but believe, or more application developers who might say, well, the way in which I want to develop my application may want to have kind of its own block space.
00:21:10.298 - 00:22:31.820, Speaker A: It may not want to be a smart contract on an existing general purpose, whether it's an EVM or an SVM or move or whatever. They say, I want to have my own chain and I want to have control over whether it's the fee mechanism or the throughput parameters or whatever they say, look, a roll up or my own chain or whatever is going to be the thing I want to look at as a technical solution. Then we go evaluate in the market what are the options for how they can do. So what we're seeing right now is like we're seeing quite a few, like l three s launching generally on like base, right? They're using like the role of the service providers, right, to do so and kind of hosting that. And so that's more the kind of market we're looking at there. And I think the big question is going to be for these players, the big difference is going to say it's out of scope for them to go build something themselves, right? Fundamentally, they're either going like they're going to buy, you know, some significant amount of their tech, right? They're taking, you know, the op stack or arbitrum orbit as off the shelf open source software and they're going to use that as their base and then they're going to go out and pay a roll up as a service provider to do the hosting and the management of the actual infrastructure, wherever that's running on the cloud or whatever. They're already in this sense of, I am an application developer and I'm already outsourcing a significant amount of my infrastructure spend, build out technological expertise.
00:22:31.820 - 00:23:21.442, Speaker A: So out of the market more. We're looking at, to your point, on kind of like earlier, like limitations of a shared sequence or trade offs. I think the big limitation we have from like a market thing is the reality of like, we're not mainnet, right? And what that means is that like we have a new network and no other network can kind of build on top of us until we are like live in like a, we have kind of blessed the thing. It is, it is a main net network. It is ready to go. Whereas in these kind of centralized sequencer things, right, individual networks can kind of launch with their own kind of like tunneling timeline because they're kind of holistically controlled. So that's one of the big gaps in the market right now is like, we just need to get a product out such that other people can build on in a main net capacity, but in the broader trade off space, right? A lot of this, I think is like very speculative, right? It's just going to be a question of like, what are the market structure that people are going to pay, right.
00:23:21.442 - 00:24:14.314, Speaker A: If we look at like conduits pricing, right? They're charging somewhere in the ballpark of like $3,500 a month for like a roll up, right? And then they're also charging like 7.5% of like, you know, you know, revenue off the top, right? And so the question is like, is that like the sustainable market thing, you know, is that the cost to outsource, can you provide kind of a competitive experience in, you know, a shared sequencer? Kind of with that, you know, and then additionally looking at the architecture of a shared sequencer, right? What are the benefits you can provide, whether this is through, you know, potentially, like, more optimal interoperability with other roll ups in the shared sequencer network, whether it's through, you know, the ability to provide like, plugins or whatever kind of, in the shared sequencer and these kind of value add services, I think that's going to be the kind of open question the market is like, what are you able to provide that makes your solution more appealing in the market to these customers who are already deciding, I'm going to outsource a large portion of my technical expertise to get my product out.
00:24:15.974 - 00:25:31.180, Speaker B: Okay. Yeah, this is very helpful. So the way I understand, basically, at least today, when you look at the market from a shared sequencer kind of, uh, perspective, there's a existing, like, large ecosystem roll up ecosystems out there that's like not the target, target base, but you're basically, um, you, your, your addressable market is basically like thousands of roll ups that can spin out and then like, continue to spin out like every day almost now. So I guess one question that like many may have there is like where like, how does, like, the value accrual looks like in such a world where like, roll ups all tap into, like, shares the same shared sequencer? Do you have any, like, intuition in terms of like ballpark, like how the, how the, like, how much of the value that the roll up generates, like, can be captured by the shared sequencer, whether that be like. Because if that's like too large, that can incentivize. And it's like, if it's, yeah, I just, just curious to get some color on that.
00:25:31.292 - 00:26:02.546, Speaker A: I mean, like fundamentally. Right. From like a roll up developer's perspective, right. Whether they're like an app specific roll up, a general purpose roll up, right. We assume they're going to be looking at the shared sequencer as essentially like a cost, right. You know, it's going to be like your kind of cloud compute cost if you're like a web two company, right? You're saying like, I am creating a product and that product must have some kind of like physical instantiation, and I'm going to go buy that from like a third party, and that third party is going to charge me kind of a rate on that. And I think the question is kind of saying, you know, what are, you know, from like a first principles thing, right.
00:26:02.546 - 00:26:36.902, Speaker A: There's like, what are just the fundamental cost to do so, right. And so you have kind of, you know, for us, you know, we're starting like, focus on like celestia. And so you have what is like the raw data cost of posting data to celestia at whatever the current prices for however many bikes there are, right? So that's going to be your kind of like initial cost, right? And if we compare that to the existing kind of larger roll up market, right. You know, we saw going back what, two months ago now, right, pre, pre 4844, right. A significant amount of the cost of these roll ups was paying for call data on the l one. Those costs have come down relatively dramatically with blobs. We're still seeing new roll ups.
00:26:36.902 - 00:28:29.062, Speaker A: I think scroll was like today or yesterday or something, just like rolled out their upgrade to move to using blobs. And so we're going to see if that blob market becomes more congested, those prices go up. But like that's like one fundamental base cost, right? It's like where is like the DA being posted? And we at Astra kind of act as like an abstraction layer where we assume that the cost a person is paying to use our shared sequencer is including the cost of us on their behalf posting the data to the DA layer, those two things. And then I think the big question kind of becomes, you know, what does that cost? What is like, I'd say like the market bearing price for whatever application the actual kind of like developer is working on, right? So generally when we look at kind of an app on like a general purpose chain, right? There's going to be a couple costs, right? Let's just think about l one to kind of like simplify this, right? I'm going to go deploy whatever like uniswap on like an l one, right? You know, a user is going to use it, they're going to pay, you know, whatever kind of fee is the front end, right? You know, whatever Unilabs is like paying on like their fee switch or whatever, right? And then they're going to pay whatever the like protocol, right? In this case, the smart contract is charging on that I don't follow. But like with Uniswap charging a contract on the protocol, and then they're going to have to pay the chains base cost. Our view is that the shared sequencer, and thus the DA layer implicitly is essentially going to be the chain base cost. Then there's a more flexible domain for the application to say, I have my own state machine here, whether it's an EVM SVM move, whatever, they are going to get to decide how they choose to expose costs to an end user, where what we've seen with some kind of applications using privy or other kind of abstractions is, I'd say a cleaner user experience where instead of a user saying, well, okay, I'm going to get hit by a fee on the front end, and I don't know what that is, that's calculated some way, and then a fee on the smart contract level and then a fee on the chain level.
00:28:29.062 - 00:29:24.654, Speaker A: If you have your own application specific chain and your own roll up, you say the user is just going to get a fee. And I, as the developer may control all layers of that. They may control like the front end, the contract and the chain itself. And then their base cost is going to be this cost of sequencing in DA, right? And that kind of sequencing and DA cost is fundamentally kind of just dependent on like, there are just nodes in a network and like people need to be paid to operate nodes in that network, right. You know, I think we've seen Dankrav been probably like the loudest proponent of this, talking about how like l one s overpay for security, right? Like too high of a percentage of the overall kind of like capital flowing through the system is going to the proposers. I think that's a big question we're going to evaluate over the next whatever, like 612, 18 months. It's like how much fees need to go to the protocol to make it a sustainable ecosystem versus going to the applications, because then the applications have more control over their fee mechanism.
00:29:24.654 - 00:30:06.336, Speaker A: So we may be tangented a little bit here, but I think the big fundamental thing that we look at is, I'm very much like a market guy. The market is going to define what is the competitive rate for providing people with a roll up, whatever that means, on a given framework in a centralized capacity and decentralized capacity with whatever plugins, whether those are offered by a RAS provider or by a shared sequencer. All of these are going to look a lot like middleware in a traditional sense of saying, look, I'm going to go buy a solution. I am a person, I'm developing an application. I need my EVM. I want it to run at this much gas per second with this block time. And I want these different plugins.
00:30:06.336 - 00:31:12.378, Speaker A: What is the market rate going to give me there? I think the big question for us is, is the architecture of a shared sequencer relying on a distributed network and the kind of architectural benefits it may provide? Is that going to be able to be cost competitive in the market against more centralized providers? Are we going to get a regulatory tailwind that says, hey, yeah, maybe the centralized providers have a lower cost, because just definitionally they're running fewer nodes. Is that going to get pushed out of the market? And then the last thing is just an ideological question of like, where do we find that line between saying, well, I'm a developer building an app specific roll up running on a centralized sequencer. And yeah, sure, you're writing DA to a base layer. And at what point is a regulator or just your customer is going to say, that's just like a SaaS app. And yeah, you have a slightly weirder kind of technical architecture for your SaaS app than you're not using like MongoDB or like, you know, whatever other, you know, Spanner or Cosmos DB or, you know, whatever other, you know, cloud DB. You're using like Ethereum as your database. But fundamentally there is like one node running in a cloud that a user kind of interacts with SAS.
00:31:12.378 - 00:31:20.698, Speaker A: So I think these are kind of the questions that we're going to evaluate fundamentally. I don't think the market has like an answer to this. We're more looking at where we're at in six to twelve months, right?
00:31:20.746 - 00:32:01.774, Speaker B: So many, many things I agree with you are unclear what prices of those will look like. But intuitively, do you think shared sequencer is like, has a network effects where, you know, over time it becomes like a winner kind of takes all market, or like, and you can respond this question in different ways. Right? Like, personally, I think, like each kind of roll up ecosystem will have its own shared sequencers. So maybe they are winner takes all, but it is like pretty much within their, their ecosystem. Do you like. I kind of see it that way. But.
00:32:04.394 - 00:33:40.744, Speaker A: Where are you like, drawing the line at like the market and like the ecosystem and takes all of what? I know that's like very abstract, but like you could theorize, right, if say, like we had no roll up, right? We had like, wait, we're like base roll, we had no roll ups, right? And then like a shared sequencer was like the first thing on the market, right? Like that was like the way in which like everyone started building their roll ups and like, you know, the first three roll ups all use like a shared sequencer and no one had like an independent sequencer. Then I think like there was like a past dependency that leads to like that shared sequencer capturing like, you know, some, something 90% of the market or whatever, right? But where we're at today, right? Like shared sequencers are like, you know, starting to kind of like, you know, get close to kind of going to market when we already have whatever 10, 15, 20, whatever kind of like roll ups of which, you know, five to ten or whatever, of like sufficiently large size that I think is relatively unlikely they would go to a shared sequencer. And then also there's a lot of questions of how happy go lucky we're all friends here kind of thing. Are we going? And the roll up landscape versus, yeah, we're all ethereum aligned or whatever, but optimism and arbitram are directly competitors with each other in some business sense. And so if you see one of those ecosystems, say, I'm going to use shared sequencer x, the other one is probably less likely to use that shared sequencer because they're already established and they want to have control of their ecosystem. And they kind of get disintermediated by having some existing sense of community, ecosystem, whatever, and then sharing that with their direct competitor from a past dependency thing. We already have a bunch of established ecosystems that are trying to differentiate each other from each other.
00:33:40.744 - 00:34:18.550, Speaker A: Your arbitrum, your optimism, and your starkware and your zksync and your scroll and whatever, that. I don't think it's going to be like all of those are going to go to a shared sequence. Maybe none of those go to any kind of shared sequencer. Maybe you see optimism, I think, has the clearest path here, right. With their super chain to say, hey, if we think that it is useful from a kind of composability perspective or an architectural kind of like design space to have the super chain have kind of like one shared set of like decentralized, or whether centralizing shared sequencing for various chains within the super chain, I think they would do that themselves. Right. And I don't think that would have like an overlap with like, you know, an arbitrum or like a VK think or whatever.
00:34:18.550 - 00:34:55.328, Speaker A: Right, right. And so for that reason, right. There's no way, I don't think from like a, what the roll up market looks like now by like percent of whatever volume or TVL or however you want to calculate it, transaction flow, it's not gonna be like 90% goes to a shared sequencer because it's already split among enough entities that are kind of directly competitive with each other that they're unlikely to kind of couple. Right. And so again, then it's kind of a question of like, okay, maybe there's, you know, a couple shared sequencers, and frankly, there's not that many different projects working on shared sequencers. You know, there's really like three or four. And so generally, you see in these markets, right? You see like a one two, and like a middling third and a fourth is irrelevant.
00:34:55.328 - 00:35:12.084, Speaker A: Right. And so if we have like four players in the market, right. That's kind of like the competition that's happening here. But I do think it's kind of a big thing of like, you know, the shared sequencers acquiring kind of like, which customers, you know, ecosystems, whatever, and versus the existing established ecosystems and how that split works.
00:35:13.824 - 00:36:04.510, Speaker B: I'm curious to get your thoughts on generally, like broadly on optimistic versus ZK as well. I think that, like landscape really is changing like almost every month now. Like initially people, like, I mean, initially people generally had the idea that, like optimistic was going to be, you know, more practical way sooner than ZK. But I think, like ZK tech is like significantly progressing and like kept progressing over the course of, you know, months, years in like, from the perspective of shared sequencer. Is there, is there like advantages to being a ZK roll up than optimistic? Because, like proofs can in theory be kind of composed with each other, aggregated. Yeah. In your mind, does that bring like advantages to ZK rollups or.
00:36:04.510 - 00:36:06.894, Speaker B: Not really? Or am I missing like anything here?
00:36:07.014 - 00:36:43.360, Speaker A: Yes, I guess a couple things. Like, one, I'm not like explore like an expert in like any of those things. I spent more time working on optimistic roll ups at like a research level than like the k roll ups. I'm not a manual math guy, but I guess one thing would be like, I view sequencing and the bridge as distinct phases in that. Fundamentally, the optimistic fraud proof, fault proof, whatever, ZK proof, validity proof, succinct proof, whatever you want to call these fundamentally are about bridging. They're bridging assets to a roll up. And generally they're on the withdrawal path of saying, I have bridged some assets from some l one up to some l two, and now I want to withdraw from that l two to the l one.
00:36:43.360 - 00:37:11.948, Speaker A: The l two is fundamentally just like a fork choice rule, just defined to be kind of subservient to the l one in the smart contract role. So it is just already making the trust assumption on the l one. Therefore, that bridge is easy. From the l one to the l two. From the l two to the l one, the l two has this kind of subservient relationship to the l one. So the l two has to somehow prove to the l one that its thing is valid. And what we didn't want to do is design this kind of multisig structure or something that looks like IdC, where you say, ok, I have some validator set.
00:37:11.948 - 00:37:49.374, Speaker A: It makes some economic attestation to some two thirds majority signed a state route and makes the attestation that's your economic trust assumption on the bridge. Because the point of a roll up, right, was to have a smaller number of nodes. You need to run that, not just being the cosmos or comet, bft tenement, whatever ecosystem. The two solutions that came out of that were fraud proofs or succinct validity proofs. I spent more time again on optimistic or fraud proofs. I think those were the things that came out of the plasma group now, optimism. And the arbitrum guy has been working on this for almost a decade now on these interactive verification game proofs and various iterations.
00:37:49.374 - 00:38:11.720, Speaker A: Trying to not be too long winded about that though. It's just my nature. Fundamentally I viewed the sequencer is a distinct entity from the proof. Generally, I think a failing. You're going to have some da layer you made of some sequencing. On top of that, you're going to get a stateroot out of that. The bridge is just someone making some attestation about the validity of a state route to enable a withdrawal, unlike the l one.
00:38:11.720 - 00:39:08.224, Speaker A: And so you can do that for a multisig or you can do that like a centralized party, and that centralized party can either be backed by a bond or whatever where they say I'm going to make this claim, and then if a fraud proves, they say someone has a mechanism to challenge me and the strength is to some economic bound or whatever, and then the proof, I'm going to go generate a proof. Right. I guess my view on the technology, generally what we've seen, and we've seen a lot of progress recently, like bold, it's like almost like a year now since they've kind of announced that. I think they just moved to a testnet today, or just announced they're moving soon. The optimism guys have their fraud proof work on Sepolia Testnet. I think now we've seen some of that, but generally what I've seen in the optimistic landscape and my somewhat layman, but a little more than layman engineering analysis, the problem of fraud proofs, they feel like this very, you can get 90% of it working relatively easily and it's very hard to get confidence that that last 10% has no edge cases, corner cases, whatever. And I think that's what we've seen the last two years, right? Yeah, the MVP looked good.
00:39:08.224 - 00:39:36.136, Speaker A: Now he's got to double check. And that's just a long process and that's what we've seen compare that with validity proof where we got the like hey, we can generate a validity proof. It just took like whatever like 12 hours or 24 hours or like $10,000 or $100,000. It's like extremely expensive to generate it. But we had the like defined. Like here is like structurally how I generate a proof out of like a given like you know, state DB, state route, whatever, right. And over the last, you know, n years now we've just been really grinding at the kind of performance and cost there, right.
00:39:36.136 - 00:39:52.044, Speaker A: With a bunch of different things. Right. You know, snarks, stark, starkish, plonks, plonkish, whatever, right. You know and all this stuff. And so we've made a significant amount of improvements and I'll note I'm a little bit out of touch with like the most kind of recent thing on CK. I didn't make it happens last week. But that's my view, the last bit.
00:39:52.044 - 00:40:16.486, Speaker A: I do interoperability benefits to validity proofs but I think it's all constrained on cost mechanism. Right. Like Justin Drake spent a bit of time a couple weeks ago talking about real time proofs and that's like a intra block time kind of proof generation. I am not the optimistic on that happening in like twelve months. You know that would be really cool but I don't think that's going to happen. But yeah, like long winded is pun.
00:40:16.590 - 00:40:19.190, Speaker B: Intended in the optimistic term there.
00:40:19.382 - 00:40:22.154, Speaker A: Not quite intended but you know there's only so many words in this space.
00:40:22.454 - 00:41:06.540, Speaker B: No, this is great to hear from you actually. And I like directionally very much agree with you. Right. And the context with the, with the 90 and 10% I think it was quite interesting. Okay. So I want to also ask you about base sequencing based sequencers because it's just such a hot topic. First of all I'm going to ask you to define this for us because I've heard like different definitions from different people and I'm curious how like what do you understand when somebody says base sequencing? And the second question is like what you're building in Astria, is that like potentially compatible with base sequencing? Like complementary or is it basically an alternative to it?
00:41:06.732 - 00:41:43.840, Speaker A: Yeah, so the original definition of base sequencing and what I still kind of like accept is like the default kind of starting case. And I think Tyco has been the people who have been kind of working the most on like building a roll up that uses like base sequencing. Right. Is the idea that the block production of the roll up is purely dependent on the block producing entities within the l one. I'm trying to figure out my jargon. The validators, block producers of the l one are the entities also producing the block for the l two. Based sequencing in the original definition just doesn't have a sequencer.
00:41:43.840 - 00:42:29.596, Speaker A: Whereas what we have in existing roll ups is you have some third party sequencer, that is some, in broad strokes, there's a smaller number of sequencers. Right now we have one. There are smaller number of sequencers than there are l one block producers, and they have higher resource requirements and run faster and provide a higher quality user experience. Base sequencing, the simplest definition is just saying we just run the roll up and we just post raw data to the l one and we still have the node software that defines how you derive the state of the l two. The roll up, right, is reading that raw data, but the execution only happens on those nodes and thus you get a compression benefit of not paying the execution cost of the l one. Only the data cost of the l one. And that is the simplest base sequencing.
00:42:29.596 - 00:42:48.762, Speaker A: I will pause there, but there's obviously from the recent discussion on that it's base sequencing with preconformations. Probably worth discussing that and talking about Astria, but want to make sure we're at least in agreement. You want to proceed with going into the weeds of what is the current discussion around base sequencing and how that word has been used in the last six months?
00:42:48.868 - 00:43:02.742, Speaker B: Yeah, I think pre confirmation we can get into pre conformations and as you speak to them, like you can maybe talk a bit of trade offs between base sequencing and shared sequencing in the way Astra is building.
00:43:02.918 - 00:43:31.178, Speaker A: Yeah. So I guess to start, I guess I would define at some level, I would say a roll up which uses a shared sequencer, or at least a shared sequencer as Astra's design. Right. As this kind of sequencing layer, this like new blockchain, it has its own kind of validator set. It is coming to consensus over the bytes of transactions that are roll ups. And that roll up is assumed to then run a full node that is deriving a state out of this. Relatively, from the shared sequencer perspective, lazy or low context data.
00:43:31.178 - 00:43:56.324, Speaker A: It's just coming to consensus over raw bytes. And then the roll up node derives out of that and applies the context of its state machine over that. That is fundamentally the roll up is a based roll up of the shared sequencer. That is our assumption of the design. There is no other layer of sequencing that is even faster than the shared sequencer. You just have user transactions go in the shared sequencer, it produces a block. You execute the state transition function over the block.
00:43:56.324 - 00:44:54.016, Speaker A: So using the classical definition of a shared sequencer, if we look at what's been discussed recently on shared sequencing, or shared sequencing with preconfirmations, fundamentally, I guess my view is that gets quite muddled, because when we talk about pre conformations, fundamentally, there is some set of actors and software and software run on hardware that has higher resource requirements than the resources to run the l one ballot integral. If you look at ethereum, it's like whatever. It's always been the $1,000 laptop or whatever to run a full node. If we want to provide pre confirmations, fundamentally there's going to be some assumption of a higher resource requirement to do a thing faster than like the l one, right? Like that resource requirement is going to be higher. And then just again, very, very broad. Structurally, there will be fewer people running kind of like these preconf nodes. However, they are kind of structured, then there would be the l one.
00:44:54.016 - 00:46:05.660, Speaker A: So high level, my view is like, I'm not convinced that like base sequencing with preconfirmations is truly base sequencing. I would, I would like argue that we just like renamed a thing called a sequencer. And I think the discussion that we're seeing in kind of base sequencing with preconfirmations directionally is a question of kind of the more the economics and less so the kind of mechanical node things. It's this question of like at an l two, right? Use like optimism, for example, right? It has to pay some l one cost and like, you know, go back whatever, six months and it was like somewhere in like the 25% to 50% or whatever, right? Maybe as high as 75% of its cost was buying, called out on the l one. Now with blobs, a much smaller portion of the total cost of running that l two is going to the l one. And of the fees that an end user of that l two is paying, a much larger portion of those fees are going to the l two entity that is running the sequencing node. When we look at base sequencing, I think fundamentally what it is, is coming out of the Ethereum foundation in l one space is saying, well, we want to be able to provide rollups with the functionality to have these fast preconfirmations, whether it's a two second block time, a 250 millisecond block time, whatever, but this faster and better ux for their end users.
00:46:05.660 - 00:46:56.874, Speaker A: But we want to do so in a way in which the economic value is kind of flowing back to the l one. And these l two s are not seen as these distinct entities which capture whatever, right? Like 50, 75, 90% whatever of the total user transactions that they pay in. And they pay a much smaller percent of the l one. It's the l one wanting to offer some kind of functionality. But I guess my view would be fundamentally what's unavoidable is there is going to be some piece of software that's going to be different than an l one validator node, software, guest, lighthouse, whatever, that's going to be run by a smaller number of entities. And the ones we've seen, we've seen proposals for a relay based design for a gateway, which is maybe the same thing as a relay, maybe not. We've seen ones where it's the block builders that are providing this, but all of these still say there's going to be a smaller number of higher resource requirement software running.
00:46:56.874 - 00:48:30.268, Speaker A: And the big question is where do the economics go? And I think that goes back to our kind of like original earlier discussion, right, of when we look at the market space of I'm a person, I want to develop an l two, right? Whether it's I want to be app specific or general purpose, whatever, right? Do I want to go to a shared sequencer and pay whatever the shared sequencers rate is to submit transactions to this kind of network and get my blocks out of that and get the censorship, resistance and decentralization guarantees out of that kind of block production and have your liveness depend on that network? Or do I want to go to a RAs provider and say, okay, well, this person's going to give me some kind of contractual obligation that says I'm going to give you like an SLA with like three nines, and if I fail those nines, here's the rebate you get. And you're going to buy into that kind of thing? Or are they going to say, well, the l one is also offering some means of providing me pre confirmations at some other cost, right? And fundamentally we're just looking at like what is the developer that wants to build a roll up and where do they kind of want to buy versus build their own kind of tech and what are the kind of trade offs they're going to be making in this space? And I think there's just going to be a range of options, right. I think last point I'll make on kind of like base sequencing and where we're seeing kind of the intersection of like base sequencing and shared sequencing, mostly with like, you know, kind of like espresso's work in this area, right. Is similar to the question of like, are shared sequencing like winner take all? There's this difficulty of you have where your optimism, your arbitrage, that are different camps. They're competitive with each other at some level. And so they don't want to use a shared sequencer because they want to be more differentiated from each other than more similar to each other. They're working in a competitive market.
00:48:30.268 - 00:49:25.920, Speaker A: They don't want to be commoditized. However, they have already both accepted one shared dependency, and that is ethereum as their l one, which they use for settlement and da. Right. What we're seeing in this kind of intersection of base sequencing and shared sequencing is, I think people looking at this thing and saying, well, what is the shared dependency between these existing large roll up platforms? And what thing could we possibly, where could we possibly find a wedge to offer them this shared sequencing? And they look at the l one because that is the kind of shared dependency that both of these ecosystems have already made. And therefore, there's an idea that you can say, okay, it's not some third party thing that I'm going to use, that my competitor might already be using, and therefore I don't want to use it. It's additive functionality to a layer we are already comfortable and have been comfortable sharing. That's a lot of my view on why we're looking at this intersection of shared and base sequencing from the Astria perspective.
00:49:25.920 - 00:50:10.590, Speaker A: Again, this is not where we came about. We are not generally an Ethereum aligned project. We came out of my time working at Celestia. We have not spent any real resources looking at arbitrum or optimism or trying to convince them to use our shared sequencer because we're going to market using Celestia. DA and I never had the assumption of these flagship roll ups moving over to using Celeste js or core DA, so they were just out the market anyways. I spend time and my team spends time paying attention to the base sequencing design space because as I noted, a roll up building on a shared sequencer, fundamentally, in an academic definitional case, is a base roll up of said shared sequencer. So it's useful to pay attention to the research and design space and see how the market's going to kind of evolve here.
00:50:10.782 - 00:50:37.382, Speaker B: Thank you. Thank you, Josh, for all those information. Definitely very, very helpful. My last question, I want to shift gears a bit to the BD side and go to market strategy. I'm curious how you said you're not live yet, but how close you are to mainnet. And then as you approach to Mainnet, what will be the go to market strategy of Astria?
00:50:37.478 - 00:50:56.742, Speaker A: Yeah, so generally I'd say from like a project perspective, we've focused very little on kind of bd and go to market and marketing generally. Right. I think like, no one would kind of say like, ah, the Astra guys have like marketed very heavily, right? Like, no, we just haven't. Right. We don't have like full time marketing people. Internally, our team is by and large like 85 plus percent engineers. Right.
00:50:56.742 - 00:51:57.290, Speaker A: And we focus on kind of building the core product. And so when we think about how to go to market, really we're looking at what things can we do to demonstrate the viability of the technology that we've built that we think is good technology, without spending a significant amount of resources trying to build expertise in what is not our core functionality, whether that's BD go to market marketing, what we're doing is vertically integrating and building our own roll ups on top of the shared sequencer. Because when we go into talking to potential users, customers, there's a lot of questions around, is the shared sequencer kind of going to work? Are these things that fall in the general crypto infra vaporware space? It's not live yet. When's it going to be live? I might say three months. And they might say a lot of people say three months and then it's twelve months. So there's just a strict people reasonably, I think, based on how crypto as a market has just delivered over promise, under deliver. Historically, people are not going to make a commitment to say, I'm going to build a foundational component on a thing which isn't live yet.
00:51:57.290 - 00:52:41.444, Speaker A: So our general view is like our marginal dollar on BD go to market partnership work is going to be much better spent post getting a main net chain out that demonstrates it, not vaporware. The other thing is, again, we're middleware. It's difficult to sell the first customer on middleware because they're going to say, I don't want to be the guinea pig. From our view, fundamentally, having third party users of the product has higher communication overhead. Just definitionally, we're planning to vertically integrate eat your own dog food style. Because it doesn't require us to staff a lot of BD go to market resources, it doesn't require us to try to spend a lot of effort convincing someone to be the guinea pig. And then when we're being the guinea pig ourselves, we have a lower communication overhead internal to the organization.
00:52:41.444 - 00:53:15.960, Speaker A: Than we do with a third party. So we're working on our own EVM. We're going to launch that EVM on top of the shared sequencer. And the idea here is to show rather than tell. And what I mean by that is people are going to ask, oh, the shared sequencer, it's decentralized. It's going to have just slower block times than a centralized sequencer. Is it going to provide a good enough user experience? Is it going to be cost effective in us? Am I going to be able to justify paying the cost of the decentralized sequencer set versus just having a one node centralized sequencer? We can spend a lot of time and energy just having these conversations trying to convince people of this, but it's going to be much easier to say, look, we're going to build the thing.
00:53:15.960 - 00:53:38.824, Speaker A: That's where we're experts. We're just protocol engineering. We're going to build the thing, we're going to launch the thing. We're going to put an EVM on top. We're going to say, go use it and see if that is providing a sufficiently good user experience for you. That is infrastructure that we have well defined, well documented APIs and integrations to build on top of. Generally, we're looking at that as a next phase where we're going to go to market with our own EVM.
00:53:38.824 - 00:54:11.894, Speaker A: It's going to be focused on the Celestia ecosystem. We're going to demonstrate that we believe the technology we've built for the Astra shared sequencer is providing a high quality both developer experience and end user experience for rollups built on top of it. Then we're hoping that that is sufficient to attract interest for what is right now, quite frankly, a relatively small market of people interested in building new roll ups. But we think we can make a showing in the market and say you could also build on top of this and get the same quality user experience off of our tech that we have demonstrated through our own vertical integration.
00:54:13.504 - 00:54:27.496, Speaker B: Is there like a rough kind of timeline that you have in mind? I know you guys are in Devnet right now. You're transitioning into Testnet. What is like the ETA looks like roughly for Astria?
00:54:27.560 - 00:54:42.680, Speaker A: Yeah. So, I mean, it's like months, not years, thing. And it's maybe month or months, not weeks, but like soon. We've gone through an audit on a lot of our core stuff. We've had three public devnets. We have like a fourth devnet running that we haven't announced yet. We're probably going to do another iteration.
00:54:42.680 - 00:55:30.510, Speaker A: So we're kind of in the, kind of like what I'd say like the final innings. And I think generally we do development a little bit differently than a lot of other kind of crypto infrastructure projects. In that myself and my co founder Jordan come out of a kind of big tech and also a cloud environment where we have a lot of expertise with running infrastructure. And so when we say a Devnet, fundamentally what we mean is we're running all the nodes. And when we say a testnet, we're saying okay, whatever, we're having a validator organizations run the majority of the nodes, we might be running one node. So we have, we focused on doing a larger number of devnets and iterating much more on having devnets prior to going to a testnet because fundamentally we don't want to waste a validator organization's time saying hey look, I can find most of the bugs by running my network across multiple regions within my cloud and simulating latency, whatever. So we've done a lot of that.
00:55:30.510 - 00:56:08.454, Speaker A: So we haven't moved to a testnet yet. But our assumption is that when we move to a testnet in the coming weeks here, ideally we're not actually finding anything new there. We're just saying, hey, is our documentation on how to run a node in our network sufficiently good for you as like a testnet validator? We're not trying to say, hey, here is where we begin to find issues in a distributed network that we may not have found. We're hoping we found all those issues in our Devnet. So I don't want to give a strict time, but we're looking at order of months or months before we get something out. But obviously all those are dependent on we're still in the very, very final stages of an audit and getting the final report for that. Generally there's had to be iteration during the audit phase.
00:56:08.454 - 00:56:53.534, Speaker A: So we have to look at what we're doing for audit, what our comfort level and go to market is, go through a testnet process and make sure that we are confident in how the network is actually running, how it runs under load testing, we've seen a lot of different networks basically have varying congestion issues. We want to not find those out in mainnet. We're going to stand up our next Devnet, our testnet, we're going to load test the thing ourselves and say, do we have confidence this is going to be able to go to market and not just crash if someone puts on ore or whatever your proof of work mining thing, day two of your network, and it just dips because inscription, spam or whatever. Again, we're moving to market ASAP, but we're generally having relatively conservative engineering culture here, and we want to make sure everything is working before we go out to market.
00:56:53.954 - 00:57:06.102, Speaker B: Thank you. Josh. It's always a pleasure to chat with you. I really appreciate you sharing, sharing your insights and was very excited to learn more on Astria. Thanks for joining.
00:57:06.198 - 00:57:07.134, Speaker A: Yeah, thanks, John, for having me.

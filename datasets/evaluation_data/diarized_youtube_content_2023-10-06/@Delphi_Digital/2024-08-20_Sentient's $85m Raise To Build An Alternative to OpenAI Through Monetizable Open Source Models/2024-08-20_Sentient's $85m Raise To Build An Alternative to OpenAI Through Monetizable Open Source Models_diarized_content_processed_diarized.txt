00:00:01.320 - 00:00:23.641, Speaker A: You're now plugged into the Delphi Podcast. Hey, everyone. Welcome back to the podcast. I'm Tommy, one of the founding partners at Delphi Ventures, and I'm with He Manshu, who is a core contributor to Sentient. Sentient is a major crypto AI project, and I'm happy to have you on. How are you doing?
00:00:23.673 - 00:00:25.169, Speaker B: Well, Tommy, nice to be here.
00:00:25.257 - 00:00:36.677, Speaker A: He Manchu, I have to ask out of the gate an $85 million raise led by Peter Thiel's fund. It's so much money. How do you think about spending that? It's a wild amount of money, right?
00:00:36.861 - 00:00:56.459, Speaker B: It's a lot of money, and we hope we can use it the way we want to use it to make difference in community, build open AI. And it's a lot of money, but it's not a lot of money for this new AI world, mainly because AI both compute and talent, the two resources that make AI are very expensive. So.
00:00:56.547 - 00:00:57.299, Speaker A: It is.
00:00:57.467 - 00:00:59.335, Speaker B: Yeah. So it's all for good cause?
00:00:59.995 - 00:01:21.055, Speaker A: No, it definitely is. I mean, just looking at those two worlds, right, like pondering Durian on our side released these really well written crypto AI reports, and he calls out just the hundreds of billions of dollars web two companies have to build out AI. Right. So when you compare that to the 85 mil to your point, it sounds like a lot in crypto, but it doesn't sound like a lot in web two terms.
00:01:22.255 - 00:01:41.635, Speaker B: Absolutely, absolutely. And the moment one starts, once has the conviction that the models that they're building can be scaled to that extent, then even we need to have that kind of capital available to scale further. So it's just the beginning, Tommy. It's surprising, but it's just the beginning. We will need a lot more capital going forward.
00:01:43.135 - 00:01:54.451, Speaker A: No, I don't doubt it. Well, we'll come back to that in a little bit. But let's start. Let's start a bit about yourself and your journey and sort of maybe if you could parlay that into sentient and how you got here, that'd be awesome.
00:01:54.563 - 00:02:11.427, Speaker B: Right. So I'm a career academic. I've been. I've been in academia for a long time now. I was. I did my PhD in the US I did my undergrad at IIT Delhi and in Institute of Technology Delhi. And then I was in the US for about eight, nine years.
00:02:11.427 - 00:02:42.819, Speaker B: Then I was a faculty in innovative science in Bangalore, which is a top place in India. And around that time I participated. So my PhD is mostly on theory side in information theory and cryptography. But. And that's what I teach. But for the last decade or so I've been building different systems, blockchain related and AI related. Four years back I reached out to my post op mentor promote that I'm all tenured now and I should do something more exciting.
00:02:42.819 - 00:03:30.869, Speaker B: I've done a lot of system building. So we started this project called Witness Chain which is, I mean I think it's a regular crypto project, but it's a crazy project for a person who is just entering crypto that we are building decentralized 5G network. And I have actually built 5G networks. So even without decentralization, it's a bit crazy, but to build it in a decentralized manner and combining crypto with 5G was very cool. So basically from there my trajectory of building new use cases, on bringing new use cases to crypto, the regular traditional web2 use cases to crypto became my mission of sorts at different level. I played that role at government level here in India earlier and that's the mission I'm after. And the natural candidate for my mission is this AI as a use case.
00:03:30.869 - 00:03:56.105, Speaker B: And Deepin is a hard use case in terms of demand, although it's exciting. But AI, the interesting part is that everyone wants it. And so from there we came to this journey of how to build, how to bring AI use case to crypto. And in this case the marriage is quite natural. So that's what I've been doing and that's how I read Sentient. I can say more about how exactly Sentient happened, but this is my brief journey.
00:03:56.685 - 00:04:10.135, Speaker A: No, it's a good journey. I got a lot of questions. So how did your past kind of thinking around AI influence your decision to jump into crypto AI, like what were you working on, what were you researching on the AI side before you decided to fully send it with?
00:04:10.715 - 00:04:55.605, Speaker B: Right, right. So at Witness Chain, our focus was on this watch us and the proof system. So we started exploring AI crypto AI from the side of verifiable compute and optimistic verifiable compute. That was clear to us early on, even 2022, that this verifiable computer that people are looking at for the, for the L2 and that kind of use cases will also make way for verifiable compute needed for AI. So that was sort of an academic research project which Fitness Chain was doing and we were doing. And even before that I've been the user of AI and builder of AI. I did a lot of work in federated learning, which is my background in AI and decentralized AI training for federated learning, training using personalized data and that kind of stuff.
00:04:55.605 - 00:05:37.145, Speaker B: And from there verified compute, verifiable compute. And starting from there, we grew it into something where we started understanding that all these are important tech pieces, but something much more important as important is needed. Something much bigger is at stake. That one needs a counterpart of centralized AI and it should have the same functionality, but it should not have the same centralization. That's the basic statement that evolved after this different technology pieces we are working on. We felt that no matter what you do at the end, all those things in crypto AI will lead to this counterpart to centralized AI. And why don't start from this side rather than building the tools first.
00:05:37.145 - 00:05:43.885, Speaker B: Both approaches are interesting. So we started then on this side and left the tool part for others to do.
00:05:44.625 - 00:06:16.635, Speaker A: Was it hard to land on. On the initial thesis for sentient, like, you know, you're with your team, you're going back and forth, you're trying to figure out what you want to build. You all have background in wireless and depend and AI and crypto like, and you're trying to figure out what part of the stack in crypto you want to work on. You could build foundational models, you can do inference, you could do decentralized, you know, storage, you could do a whole bunch of things, right? Labeling whole 9 yards data. How did you decide to want to create a counterbalance to centralized AI? How'd you land there?
00:06:17.175 - 00:06:21.395, Speaker B: That's a great question. And that's where Sandeep enters my life.
00:06:24.015 - 00:06:26.095, Speaker A: He is convincing. I love him.
00:06:26.255 - 00:07:00.545, Speaker B: Yeah, convincing. Of course he's convincing for sure. But more than that, he helped us focus on this clarity that why don't we start like all of us are, we met through Shira. So his point was that all of us are people who have good things to do in life. So if we want to solve AI problems, why are we picking up the pieces which are important, which will eventually be important. But what will make it important is that there is an alternative to centralize first, otherwise none of it is needed.
00:07:00.585 - 00:07:00.785, Speaker A: Right?
00:07:00.825 - 00:07:39.155, Speaker B: If you keep on building this peripheral technology, the whole, starting the whole, the system doesn't start, right? So. So we started thinking first principle about what is it? What is it that why are we uncomfortable about this and why are we not just happy with whatever OpenAI is giving us? What's wrong with that? Right? Why. Why do anything? Are we. Do we have too much time at our hands? So that. That's the thesis. And from there it became very clear, maybe in A week we were the first week of interaction itself. It was very clear that the real thing is to do is to have a counterpart of centralized AI and it should work as nicely as centralized AI.
00:07:39.155 - 00:08:10.045, Speaker B: No compromise on that. I mean, that's initial. That's a speech to ourselves. It's not a necessary thing. But we think, let's start by thinking that we love the performance of centralized AI. Maybe we don't like how it's centered, how it's censored, maybe we don't like how things are incentivized, but we love the performance. So can we get the same performance in an alternative manner where the same centralizing forces do not apply, especially the centralizing economic forces and alignment forces don't apply? That's where it started.
00:08:10.045 - 00:08:46.165, Speaker B: And mostly this came out of Sandeep Pramod and I discussing the version of our ideas that we had. And Sandeep had already been discussing with Kenzie some other formats of the similar idea in a different way. So I always think that when people discuss, the ideas keeps evolving automatically. So for, for example, I feel that in every conversation, what I say will change because the conversation influences me. So by the time we were done with that idea, it was the same idea, but for sure it was quite different when we started discussing. And at the end it was the same idea. We started feeling we were talking about the same thing.
00:08:46.745 - 00:09:36.345, Speaker A: I mean, you have an incredible group of experienced builders around you, right? Like Sandeep co founder Polygon speaks for itself, right? You have Sriram for Maigen later Eigenlayer. You have promote internally, like very experienced on wireless tech, 4G stuff like that. You have Kenzie, you have yourself. I'm curious though, like when you're, when you're debating like we want an alternative to OpenAI to centralization, is it like a, an emotional kind of view? Like, hey, we don't want centralization to control our lives. Is it that you think innovation can happen faster with an open economy? Like, what are the core tenets for the reason you're building something open versus just relying on centralization? Right. And I'm sure it's different for everyone involved, but curious where you guys landed there.
00:09:36.885 - 00:10:10.725, Speaker B: Right? Right. So that's a great question, actually. So who has what stand on this part? Right. And by the way, Shiram is an advisor for the project, and early on there were a lot of interactions with him, but it's not like he's daily telling the whole. Discussing the whole thing. Of course, especially with all the things here busy with this these days. For Sandeep Pramod and I, I think one thing on which all of us were quite convinced on from day one is the.
00:10:10.725 - 00:10:57.175, Speaker B: Maybe I don't remember the word before it, but this part was very convincing on which all three of us agree that this is one of the more important things is the participation in that economy. And for different reasons, for very different reasons. Sandeep, because he has seen a lot in his life, he really believes in this kind of economy where if you can contribute, then you can make it really big in that economy. That's one part of it that can the AI economy more participatory. And Pramod, I don't know if you know about this and he has in fact our deepen stories like that. And Pramod has had long time thesis on these kind of things. Even his previous work in blockchains, he's always thinking about this economic angle to it.
00:10:57.175 - 00:11:27.199, Speaker B: And I have actually already built such models of participatory economy in the Indian context. Also I've put up some standards which are towards that. And there's something very close to me about how in fact, on a different podcast we should have it. I think the way we learn economy, it differentiates entrepreneur and employees in such a fundamental manner. And it's like an employee is a very passive entity. It's like jobs are needed for something and these guys are. They either consume or invest.
00:11:27.199 - 00:12:14.815, Speaker B: An entrepreneur is the big guy and he's the guy who's balancing this and that. And I've always felt that these boundaries are very theoretical because in my lifetime I have not felt it in the sense I never categorized myself as A or B. And this is because maybe some privilege is there in our lifestyle, but I never felt it that way, that it should be there. And in fact, only when I grew up I realized that these boundaries are so strong and have to be shaken. And now AI this is very stark. This problem is very stark because AI, the value is so big and it will realign the whole value chain and it has to be participatory. The contributors should get their fair share and not just by joining those companies, right? That's how what they're saying.
00:12:14.815 - 00:12:41.575, Speaker B: OpenAI will say we are a great payer. What are you talking about? No, but you have thousand employees, man. And you don't tell me that thousand employees or whatever, some small number, right? They cannot control this whole value chain of the world. Everyone wants to. We don't want to build apps. We want to participate in the main innovation cycle and we want to participate in that. So that problem that just by participating and building you can participate in this big economy is something which appeals to all three of us.
00:12:41.575 - 00:13:02.513, Speaker B: I think that's close to our heart. I think Shiram is also very close to this problem. Although I've not discussed this with Shiram directly. But what I. What I. But I understand Eigen layer really well, because I was doing an AVS before this. And I think Eigen layer also at the heart of it is about this economy, right? And I think Eigenlayer is doing a bunch of project and digital rights as well, which lend towards it.
00:13:02.513 - 00:13:46.489, Speaker B: So this problem, all three of us on the same page, but then on the technical excitement, we have different passions. So for example, Pramod and I had a thought about also the fact that AI is specially good for this kind of decentralized ecosystem. Because to build, and this was before this reasoning and these things became so mainstream, because to build better AI, you need to have AI versus AI interactions. And you know, we, we were always thinking about this evolutionary forces and how evolution brings out intelligence and the same kind of evolutionary forces what will look like for AI. So technically also we felt that there is a. There's maybe a technical advantage that decentralized AI has. And there's always this question.
00:13:46.489 - 00:14:25.337, Speaker B: Cannot can centralize AI, not create the same advantage by hired, you know, data labelers, hiring this, hiring that. And our thesis on that has been always that no, it cannot, because there's too much, too much to be too much, too many different kind of AI and data to be unlocked. And as long as the first phase was all around data, which was also decentralized, unlocked by the Internet over decades and decades, if there was no Internet decentralization, then there'll be no original models also. Just keep that in mind. So even the first phase of AI came through the. This decades of decentralization through Internet, which got all the data here. If they tried to build the same network themselves, they would not have done it.
00:14:25.337 - 00:14:46.747, Speaker B: So the second phase also, I'm calling this the second phase now. Now we talk about AGI, right? I think GPT 5 onwards, 4.40 onwards is the second phase, where we are talking about reasoning, planning. The second phase also it will be even more on this kind of decentralized data. So even technical thesis is there, which Pramod and I share quite dearly. I think Sandeep also shares it. But in the beginning we were quite convinced about this.
00:14:46.747 - 00:14:51.019, Speaker B: But the economic part we are all on the same page about from day one. That's actually what got us together.
00:14:51.187 - 00:15:18.269, Speaker A: No, this is. This is awesome. I'll play devil's advocate on your first part on the economic side, right? Like, yeah, so wanting the world involved in AI is not only admirable, but it feels like the way it should work. Right? Most powerful technology of our generation. It will have undue influence in every app and interaction we have without us even knowing it. Right. Any bias will be extrapolated to the nth degree.
00:15:18.269 - 00:15:54.175, Speaker A: But beyond, like the. The altruistic reasons, like, what are the, like the market forces that you feel that favor the economics of crypto? AI versus open AI. Right. And I asked that because, like, Clearly Meta and OpenAI, like, they have way more GPUs, they have more talent, they have existing companies throwing out tons of cash flow to drive to put a ton of money into their AI visions. But what is it about crypto that drives a more powerful economic flywheel? I guess.
00:15:54.835 - 00:16:30.193, Speaker B: Okay, so what is this? So, by the way, it's more than a more powerful economic flywheel. What I'm saying is that the contributors get rewarded for their contributions. That kind of economy where it's more participatory for the community. Let's start with the compute piece, because this is the one which is put out first. And I'm actually with you on the compute piece. Although there are forces which are trying to get decentralized computer power with centralized one, compute is a hired gun. Compute is available to every project as long as it grows, as long as it does reasonable economic size.
00:16:30.193 - 00:17:04.147, Speaker B: So you should hit a certain size, right? You have to. If you are compute hungry and you have the money for it, people will come and give it to you. This compute, boundaries which are being projected, I feel they are only about rising to the right size. So at other size, for example, we don't start with complete compute starvation. And in fact the next level, if we unlock it, will be even easier and easier. So this compute preference, some boundaries are there, but it's not like on day one, we are competing with the compute requirements of OpenAI. And either they will get it or we will get it.
00:17:04.147 - 00:17:34.364, Speaker B: It's not like that. When we reach that place, that's when, by that time, we're already very big. So compute is a hired gun. It will be great to have cheap compute options through decentralized GPU cluster that people are talking about. My personal take on the decentralized compute is that I will use it under two conditions. I'm sort of a consumer for it. I'm looking to use it right I will use it, number one, if you give me something reasonable, not extraordinary, but reasonable because I can use it for many things, inference points.
00:17:34.364 - 00:18:01.565, Speaker B: And that I would say many people have because they have invested in some small side clusters. You can do fine tuning with it and they can also give you dedicated big clusters. But second part, where most people are lacking and I would love them to catch up because the easier part and surprisingly they are lagging. There is a software layer over it. I need a right software layer. I don't need raw GPUs, I need all the pipeline over it because I'm doing something else. I'm not going to build all of it.
00:18:01.565 - 00:18:35.217, Speaker B: So that's the part. If decentralized compute picks up, then I can use them for many things as well. The centralized compute part. I will go through the same channels when I'm pre training and building larger models as any of the larger companies will go now on the other pace of the economy. The part where I feel that we can differentiate and that the part. The difference we want to bring in is this both variety of talent and AI, right? Like there are a lot of people who want to build AI and they don't. All of them would not.
00:18:35.217 - 00:19:01.021, Speaker B: There's no way will get a job with open AI. Or maybe meta. But by the way, meta is like a Meta is on a similar. On a similar path with a different direction. They are not working out the economy layer because they're saying we'll work it out, but we'll give for free the model for free. We are saying that we want participatory economy in there, not just give for free. Right? It's not just activism for us, although it's not activism for meta as well.
00:19:01.021 - 00:19:21.505, Speaker B: But for us it's not like we are giving it for free. We want to really bring an economic model there. It's the idea which was there by 2018, 19. I've been saying that and I'm internalizing it more and more. See, OpenAI was there. That was the path they were following. And then at some place they felt that there's no way to grow bigger and monetize in this open world.
00:19:21.505 - 00:19:36.865, Speaker B: And they started took a different trajectory. We just want to continue in that trajectory and say that this trajectory is possible with crypto. They never tried that. And because they didn't know what like that they were doing other things. But now we have the power of hindsight. We have an advantage. We know a few things.
00:19:36.865 - 00:20:08.777, Speaker B: We know this economy is really big. People are ready to experiment with different ways to build it. They could not have done that in 2018. Right. Like, although they, they, I mean no one could have thought of crypto way there because the economy size was not very clear. Now it's really big and people are able to experiment with different things there. And second hindsight thing that we have to our advantage is that, and this is something one could have guessed earlier as well is that unlike search and maybe even mail AI, the use cases are very, very different, many, many different.
00:20:08.777 - 00:20:26.241, Speaker B: It's entering everything. And so this, the data is not the kind of data needed, is very, very varied. And there's some advantage in that. And extracting the data is not just like asking people and doing surveys. It's not like that. You need to build tech to get that data. In fact, you need to build models to get the data.
00:20:26.241 - 00:20:51.665, Speaker B: And that's why a model company is also a data generation company. And that thesis we have that people who help us build this model to collect data should own those and get a part in that economy. So whatever OpenAI tries to do for 1,000 people, it has, we want to do for the, let's say 100 million people who want to, let's say 10 million people who want to participate in this economy.
00:20:52.005 - 00:21:28.865, Speaker A: Yeah, it's always really hard to imagine like what opening the new door with crypto incentives does to, to the world. Right. Like, I mean smart contracts with Ethereum is a pretty good comparison, right? Like you give people the ability to permissionlessly build, to be able to raise funds and to organize a community and you can get some highly differentiated sort of projects. Right. I feel like you're on a similar track there, but it's just hard for people to understand what that looks like because it's not, it's not live yet. Right. Like if you want to use AI, you go to perplexity, you go to ChatGPT, you go to Claude.
00:21:28.865 - 00:21:31.845, Speaker A: Like it's not, it just hasn't matured yet.
00:21:32.185 - 00:21:56.589, Speaker B: Perfect. Right, right. But, but you see that it should be like that, right? This is about who build it and how do they get reward from the experience. Should be very similar to Perplexity. I love perplexity. Perplexity shows us something, right? Like if someone come, came and told you we'll compete with Google on search, you would have a similar reaction and you will give all this compute and all this and now you're like oh man, like it's possible. Right.
00:21:56.589 - 00:21:59.105, Speaker B: So they're the hope company. Right.
00:22:00.485 - 00:22:24.929, Speaker A: So he mentioned, I guess one part though I'm confused on though. Is like when I think of Sentient, I think of. And I put a small like tweet out on this. But I view you guys more as the coordination network where people could bring their models and keep them open source, but also earn off of them. Right. I never really thought of Sentient as the place where, you know, hey, we're going to go out as a sole company and compete with Facebook and build the biggest models. Right.
00:22:24.929 - 00:22:30.645, Speaker A: Maybe you could clarify that for the listeners a little bit on. Maybe you're thinking on the econ there. I think it'll help.
00:22:30.945 - 00:23:08.915, Speaker B: Yeah, that's a, that's a great question. Actually. This is like a, this is more of a, this is a detailed product type question that how do we. This is like more of a business thing, not such a pure crypto thing. So in principle, so far, what we have talked about, there are a few options for from here on. The two options that you said are both quite feasible. Should, should, should we have others come and build models and give it to everyone or should we build a few models and make very good AI? And so very early we decided that Sentient is an AI company and it will build models.
00:23:08.915 - 00:23:43.495, Speaker B: Our protocol will allow eventually to allow others to do the same, but we feel it's too early. It's like to say that you can come and bring models, but I think there is, it's very hard for people because that's the problem we are solving. So we know how hard it is. It's very hard for people to coordinate efforts to get others to build models. So Sentient is a model company and we'll build our models and give it to others. And if you like what you do, you can use the Sentient protocol to do the same thing for yourself. So that's the way I think of it because it's easy to say that others can bring in, get their models and monetize it.
00:23:43.495 - 00:24:14.725, Speaker B: But I feel that that's a very different path. And maybe one way to think of it is the GTM strategy that we want to be for the initial phase. We want to be the company who's providing the AI and building the models because we want to. As I said, the thing with AI is it's a working feature. No matter what I tell you and what I do, you first will compare me on quality with open AI. Maybe you'll give me some elbow room, some slack. But then at some point you will say, dude, look at this thing, it works so well and tell me what you have.
00:24:14.725 - 00:24:22.205, Speaker B: And that's very important because it should not be that crypto has got in the way of great AI.
00:24:23.865 - 00:24:56.735, Speaker A: No, I want to go down each of these paths because now it's super interesting, right? Let's start with the. We're going to build models and we're going to win, right? Like, I don't want to harp on being devil's advocate, but I think everyone's going to ask you the same question, right? Like, it's just the web, two companies have so much money, right? Like, they're already pretty far ahead. Like, how do we, how do you inflect that? Like, how do you even. Like as a V1, how do you show the world that, hey, we can do this, we can create something through crypto, incentives and the world and distributed matter that's, that's competitive. How do you build that?
00:24:57.355 - 00:25:51.431, Speaker B: No. So first let's, let's work out from first principle, right? Do you think the best of AI is done or it's a ahead? That's the first question. So first, we all agree that the reason that there's a upgraded model every six months means that it's just beginning, right? How often are the search algorithm being upgraded now? The fundamentals of it, right? The way the ranking is done and all that's not being upgraded and maybe some new data is scrapped all the time. That makes sense, but it's not like stable technologies don't change so often. So this is just the beginning. And the first phase that we saw is that, as I said, that what can be done with the Internet data. And there was a brilliant, like, it's one of the amazing stories, right? The way AI came and the app, the problem it solved are all surprising even to those who have been looking at AI for a long time.
00:25:51.431 - 00:26:16.705, Speaker B: I think there could have been many other guesses about what will work in AI first at consumer scale. And this kind of chatbot being that, I would not have guessed it. So that's brilliant. GPU playing a role is brilliant. So all this surprising thing happened and from that we got this large model, right, which is now available. Llama is giving up away for free right now. Based on that, a lot of people can create different kind of values.
00:26:16.705 - 00:26:56.103, Speaker B: And again, application like perplexity are example of that. Suddenly they started challenging established companies because this is a powerful thing. Now what's the phase after this? What's the difference between GPT4 and GPT5? There are a lot of things, rumors around it, but the first part about this is that it's not done. Neither GPT5 is the final GPT nor GPT4 is even close to GPT5. So there are a lot of lands to be grabbed there. And this is where the thesis comes in. So the question is, is this war to be won by money? The answer there is that I think there is a lot of value in decentralization.
00:26:56.103 - 00:27:32.913, Speaker B: Think of building the Internet, right? If a centralized company, I don't know Microsoft at that time it was well positioned to start saying I will build the Internet and there's no need to go to the Internet. We will set up a server everywhere in the world, right? At least in the US and then in the world. And this is the Internet. Why go to all this? Why have so many websites we can build everything you need, right? And they had the money. Maybe someone even more powerful could have had that vision and it could have been viewed as threatening if they moved at that pace. But the VC was not of same style, the capital was not in same style then. So they didn't do that.
00:27:32.913 - 00:27:55.535, Speaker B: But I think that could have been done the moment they started this thing. But you know that it's not possible to capture this whole human knowledge in this one company manner. It has to be. So the next phase of AI is a lot about this human knowledge capturing. It's going to be about every heuristic you and I have of different nature, of different types. I can't believe a single company can capture it. I can't.
00:27:55.535 - 00:28:13.021, Speaker B: I don't think it's a single innovation. This next layer of AI we talk about reasoning, predicting next model is a singular innovation and you can throw capital in it. Reasoning is not a singular thing. These things comes in many varieties. The data is not there. The data has to be collected. Lots of things have to be done.
00:28:13.021 - 00:29:04.595, Speaker B: There's a lot of scope there. But naturally I feel that this is a thing meant for many, many people to innovate on, not a singular company. Now the other part about capital which may worry you is that to build this large models it takes a lot of capital. And that's a very important worry. And then the question is, how do people decide to build large models and when do they start making this $2 million, $10 million, $50 million bets? What are these experiments? And that is something that's to be done in stages. So typically the recipe has been for everyone is that you have a thesis, you are now convinced that this part of the knowledge has to go in pre training and not fine tuning. So first and it's something which will be memorized, right? Fine tuning doesn't have that kind of memorization now, you know some basic heuristics which you want to be embedded as memorization in pre training.
00:29:04.595 - 00:29:24.879, Speaker B: So first you validated that thesis on a small model. Train a small model cheap, see if give good result. Great, some small model. Done. Do the last bigger experiment. Do the bigger experiment. You know, it's not a day one, you start and you know, okay, next three months I'm gonna burn $10 million and I'll have an output and then I'll see how it looks.
00:29:24.879 - 00:29:27.075, Speaker B: It's not like that. It's not like that.
00:29:27.535 - 00:29:29.135, Speaker A: No, it makes sense.
00:29:29.175 - 00:30:04.795, Speaker B: I mean, so I'm just saying that the time at which we need this capital, before that time, we would already have what it takes to deserve that capital. So I'm not saying we won't. The question is not about availability of capital. The question is about access to the capital. And the access to the capital happens when you looks like when you have the right thing to solve. And so why do we think that we won't access the same capital in different ways? Right. So it is capital hungry because the returns are very high and we will need and access that capital when needed.
00:30:05.335 - 00:30:49.231, Speaker A: That's totally fair. And sorry to interrupt you before, but the people segment is very interesting. I think we should continue discussing that part. So basically what Basically my understanding is that your view is that and sentience view is that, you know, a couple dozen really smart people or a couple hundred really smart people in AI company is not enough to solve AGI or not enough to solve the next iteration of AI. And we need a protocol that's literally the beneficiary of anyone coming to give their technological breakthroughs on models, on data labeling, on inference, on any part of the stack. Right. Which is interesting.
00:30:49.231 - 00:31:04.275, Speaker A: My key question for you is when I talk to AI folks in San Francisco, most of them hate crypto. Right. It's really hard to convince them to come over. And the smart ones do. Right. Like noose research is crushing at you guys as well. Like some more wavelengths.
00:31:04.275 - 00:31:14.615, Speaker A: How do you sell this vision to them? Like what do you, what do you say to attract them to sentient to bring their technological revolutions versus go apply to OpenAI.
00:31:15.035 - 00:31:39.667, Speaker B: All right, all right. So. So, so when you say that people hate crypto, by the way, you are a sort of veteran. I'm just four years into crypto, as I said, I've been long time into blockchain, but I'm getting old. Yeah, four years into crypto, but I've been crypto curious for A long time. For example, I read the bitcoin paper very early, you know, and it. And I'll give you that Valley perspective because.
00:31:39.667 - 00:32:02.255, Speaker B: Because I used to have it, right? They have no clue. The cultural aspect of it. They have no clue, right? So they're coming from somewhere else. So when you say I actually don't agree with what you just said about Valley guys and AI guys, I think the worry about crypto is something else. It's not about tech. The discussion is not tech at all. The discussion is, oh, crypto, why do I need crypto? I have a bloody 1.5
00:32:02.255 - 00:32:38.219, Speaker B: million salary and whatnot. Right? Like, and I've already settled because these people, these people are people who are somewhere else in their career. So one thing I want to make sure, point out very quickly is that the real alpha of innovation and this I believe as a faculty professor, whatever, as is among the younger guys, because older guys are doing what they know they are not going to leave or change. They will keep on building, growing transformers. Okay, so you need some to show some muscles and all that to scale. But anything interesting new models will come from the younger guys. And younger guys I think are not so close to crypto.
00:32:38.219 - 00:33:11.065, Speaker B: That's what my experience has been. Second point here is that it's crypto or not. It's about building AI and it's about saying that do you today have a venue to push out a model and own a part of that economy? Naval's idea of companies being union of entrepreneur in 20 years from now. That thesis resonates with people. That resonates with anyone who drops out from Stanford early on, resonates with most of this generation, especially those who are not struggling on basics in life. It resonates with them. They don't want to start at the bottom.
00:33:11.065 - 00:33:39.251, Speaker B: And that group is growing more so with AI because building has become so easier. So it's quite naturally aligned with that generation who wants to directly jump into entrepreneurship with what they build. And they want to build more and more higher value pieces. And before you start building GPUs, this is the highest value piece, the moderates. And you get close to it. And these are the people who you. So I don't feel the same.
00:33:39.251 - 00:33:54.709, Speaker B: I haven't received the same pushback. I received the same pushback, you're right, from my very close friends who will be at. Who will be at a position in a big company. But I don't think they'll move for anything else. Forget crypto. Will they move to a different job? They're Too comfortable.
00:33:54.797 - 00:33:56.301, Speaker A: They're too comfy. Yeah.
00:33:56.333 - 00:34:01.385, Speaker B: Too comfortable. And you know, the life is good. They say they wake up at a certain time and drop the kids.
00:34:02.285 - 00:34:05.045, Speaker A: So yeah, I mean, yeah, I leave.
00:34:05.205 - 00:34:21.169, Speaker B: So this, this narrative is not for those guys, I think. And, and this, this, this whole, this whole thing is for the next generation. And, and people who are 21 year olds or maybe 18 year olds, right? Those are the, those are the guys who will be open to this, are open to this.
00:34:21.257 - 00:35:07.625, Speaker A: No, no, it's a great, it's a great answer because in my mind I'm thinking through how does crypto AI attract, you know, on average the best talent over the next 10 years, right? Maybe not just one researcher or two, but how do we attract that marginal, fantastic researcher, right? And when I think about it, I always just sort of, my mental model always just goes back to like this idea of OpenAI profiting for their shareholders and controlling some all powerful base model and all the apps built on top is scary, right? And I'm always asking people like you and others like, do you think at scale that that resonates with AI researchers? Like will they come to Sentient because they don't want to build that world and they're scared about it? What do you think?
00:35:07.785 - 00:35:38.649, Speaker B: I mean that's the mission we are after. This has to resonate. And that's what I said. This is a different podcast, but let me just say it, the theory is very close to me because if you think about it, right, like how open source is not so old, I think this is the third phase of open source. So I think of early open source software, most of it was driven by activism. They were activists actually financially they were, I mean they were great activists. They changed the world, right? Like basically building software and giving it away for free.
00:35:38.649 - 00:36:09.601, Speaker B: Your life's work given away for free change to change the world, right? In some sense. But they were activists and their financial security either was absent. They could take it, although not in most cases. They worked for very big companies. All the great open source contributions contributors eventually worked for Google or one of these companies. Okay, so there was no financial thought process, activism driven open source. And so it's for some select few who can afford it who think that way.
00:36:09.601 - 00:36:54.245, Speaker B: It's not the masses. Okay, next phase is this whole social media and the proliferation of Internet and which is, I always think that the crypto economy is a corollary to social media as well. You can now connect to masses and why not create value around it? Because communication is so easy to Connect to people, it's so easy. So why don't you find people who agree on your economic. This thing happened after open Source. This is in some sense it's a different notion of it. It's not open Source, but it's the opening of the other friction around how do you reach, how do you collect people? And now comes this AI where even the value, you know, like you can have very high value thinking I feel this is the highest value unlocked by software.
00:36:54.245 - 00:37:23.895, Speaker B: You can have very high value assets built by software which can be made open source with this Rails available for this thing. So now let's reach to everyone who do not have any activism in them. They just like building and what they build they want to monetize. If they close, then you know you can close. But you are so small and petty and you basically stand out over this. Then you have to build a different path. That's a possible path but you know, if you keep it open, then a lot of value can be created by you coming together.
00:37:23.895 - 00:37:43.241, Speaker B: So we should now revisit and try to solve this a monetization problem of Open Source. The time is now. AI is the great reason to solve it. One could have solved it with the first generation of open source as well. It's just that there was no reason. The economic size was not clear and people were doing it from the group was small, mostly activists. There are different time.
00:37:43.241 - 00:38:13.525, Speaker B: This open source is not just for activism, this open source. Why does a college graduate now put up their models in open. It's not any activism or to change the world. It's to make it CV its profile and show that hey, I have all these models available and right now they have very indirect path let me make my CV and find a job here and there. But if they could monetize it with much more stake right away that they would do it. They will get their financial independence early on if they could write about it rather than waiting for the cycle which is so long. So I'm saying this is the right time to solve this open source problem.
00:38:13.525 - 00:38:30.701, Speaker B: And that's the human and talent pool I'm talking about. And that is a completely different path from what someone who joins OpenAI after working for or let's say databricks after working at OpenAI. Now I know a lot of people also are moving in this direction and that direction. Very different people.
00:38:30.773 - 00:39:00.721, Speaker A: No, no, I mean it's awesome to think through. I mean it's coming together a bit on the thesis, right? Like if you're a college graduate and you're able to create AI models, which obviously is very hard, right? I'm not talking maybe fine tune models, maybe a new type of model, whatever. What you're saying is that if they don't get a job at OpenAI or you know, Claude or sorry, Anthropic or Perplexity, one of these companies, what is their alternative? If not for Sentient, what do they, what do they do? Like where do they go?
00:39:00.793 - 00:39:24.589, Speaker B: Yeah, yeah. And that's what we are saying, that basically there's a huge gap. Suddenly you're at a very low level of valuation. You can build apps and you can do that. And, but, but people keep on pushing and you know, this is like the, that's the amazing and hugging face shows that like people are pushing, they're putting out and they, I mean with very limited resources, right. The first thing you do is you clone something and start showing. I can also set it up and that just flag in the sand.
00:39:24.589 - 00:39:52.205, Speaker B: Everyone is pushing, right? And there's a certain type of people, I think they're growing and I'm very excited about it because I've seen the opposite kind of people who know much more but won't do. And these are doers in some sense. So you know, like there are a lot of people who, there are hundreds of people who directly jump into it and there are thousands of people who keep on asking, how do I make a career in AI? Well, you look at this, hundred guys, man, they just start by doing it and they have a career in AI and it's very open. Actually.
00:39:53.785 - 00:40:32.035, Speaker A: I know I, I want to ask on the OML models because it's a good segue. But, but I want to ask one other question first. Like a big thesis point for Sentient is the ability to attract and incentivize and you know, bring forward the AI developers around the world, right? Yeah. If you have an AI developer, you know, let's say they're 20 years old, she creates a killer model, right? A competitor to the Transformers model. Right. Something revolutionary. How do we make sure that when she submits that to the Sentient network that it gets, you know, noticed, it gets visibility.
00:40:32.035 - 00:40:41.215, Speaker A: Like how do we know that we're not losing in this sea of complexity, right? That we're were, you know, finding and locating the top talent within the Sentient protocol.
00:40:42.035 - 00:40:51.455, Speaker B: Okay, that's, that's, that's a slightly different question than what I was thinking. So basically you're saying what happens to the personal reputation of each individual?
00:40:53.315 - 00:41:12.715, Speaker A: Kind of, I'm, I'm just so if there's, you know, if Sentient is successful and we have, you know, tens of thousands or more contributors around the world, right, and somebody makes a fantastic contribution to better the model in the network, how do we make sure that that's found in that surface, right? And that doesn't get lost.
00:41:12.835 - 00:41:54.783, Speaker B: So first thing we want to solve is the monetization problem in the sense that if it's openly available and it has this thing, how can one monetize and reward them based on their contribution? So in the early stages, right, I'm not thinking of, as I said, everyone getting their own model. I'm thinking of people who have contributed, come together and build. I mean that's a more practical way to think of models. Like models are built by already even the existing models are built by contributions by various, various sources. And for example, people who wrote those Reddit threads which were mine to build that model were contributors. But then the people who, the data team which filters it and then various models are fine tuned. Some planners are built for something.
00:41:54.783 - 00:42:43.379, Speaker B: A lot of models go into building what looks like a singular model. So first think of those people, that's one part of the problem and how can their contribution be monetized? And second part is what you are saying that hey, if there are so many things like hugging face, then how do I stand out in this crowd? And for that the second question I don't have a great answer beyond what's around. I mean that's how you stand out on Twitter, Tom, you know that standing up, that's basically, I mean that's actually the new world people are. I think in fact that problem is solved. If you have done something good and you just want recognition for that, just the recognition, reputation, there are a lot of channels for it. That's somewhat the creator economy has also gotten there. The problem is that can the actual asset itself be claimed and monetized? That's the problem.
00:42:43.379 - 00:43:27.649, Speaker B: We are looking at that reputation. Maybe you can build on it, but can I monetize what I have built? Because reputation people build for CVE as well and then they go for this indirect channel, they don't monetize it, right? In some sense everyone puts their GitHub profile or hugging face profile on their CV and now you can go and see their commits in GitHub and some hacker rank would be there and that's their reputation which they used to get a Google job from which they actually participate in AI economy, right? Like that's quite indirect. And what we are trying to solve is Direct participation by contributing. And so the problem we are solving is how do we monetize these contributions and how do we make sure that the contributors are fairly rewarded? That's the problem.
00:43:27.777 - 00:43:51.495, Speaker A: No, I love that. Let's it. It's the model selection side and making sure smart people get visibility is definitely hard to solve. But like just logically it's easier for that person to get surfaced at an open network than it is if they're. Than it is if surfacing it requires having a job at a centralized company. Right. Because like the door is already locked.
00:43:51.495 - 00:44:09.635, Speaker A: And then the monetization side, let's definitely dive into the OML side. I want to, I want to dig in there. I think people will be pretty interested because you just released your report and your findings. Let's dive in there. It's a perfect segue, right?
00:44:09.755 - 00:44:36.643, Speaker B: So yeah. So OML stands for Open Monetizable, Loyal models and other artifacts. Okay. So that's what we started to build that can we build this open models which can be openly shared. For a simple mental picture one can just think of models that can be downloaded and deployed. So they're open if you can download and deploy them. Right? That's a.
00:44:36.643 - 00:44:56.679, Speaker B: There are various definitions of open. Let's go with just this one. You download and deploy. So I'm free to fine tune them, I'm free to use them. That way they are monetizable in the sense that when they are used, people who help build them get the money, they get rewarded. So that's what monetizable means. And loyal is a very high bar.
00:44:56.679 - 00:45:16.363, Speaker B: Loyal is someone who just. You take it out of the environment completely different place. But they never not do what they are not supposed to do. So they're always loyal to the builder. And even alignment of the model and safety rules of the model are all tied to what the builders preferred. Okay. That's the high bar of this model.
00:45:16.363 - 00:45:31.365, Speaker B: So it's sort of a contradictory thing that one can target these open models which are monetizable and loyal. If you're open, you have taken them away. And what. So that's what we wanted to solve. Okay. That's the problem we want to solve. We wanted to build this OML models.
00:45:31.365 - 00:46:20.049, Speaker B: And if you think about it, and it's not just us, many projects are already talking about user owned, community owned AI and all that. Community build AI is what we call it. It's similar thing, right? And the reason everyone can get excited about it is because the moment you see Blockchain you understand this is like crypto can solve this on contract. We can track things and we can follow what's going on. That part is a low hanging fruit, won't take much effort to do it. The difficult part there is how the hell do I tie to what's happening on chain for anything, for ownership or whatever, to the actual asset, to the actual artifact, the model which will be off chain and somewhere how are these two things tied? It's fragmented. So you can on chain keep on saying this guy owns it, that guy owns it and they should be rewarded.
00:46:20.049 - 00:46:55.283, Speaker B: But how do you actually tie it to the actual model being used and copied? Just it's a wait file, one can copy and run it again. How do you tie these things together? So that's the problem we wanted to solve. And the moment I put it this way, the first solution pops out. The first solution, which you will think of it well, let's use this tee. Let's put it in hardware where we all like it and it will just behave according to that hardware. But that can be one line of solution for this. The problem with that solution is that lot has to be done within TEE itself.
00:46:55.283 - 00:47:29.391, Speaker B: It's a solution and in fact we have collaborators building a solution based on te. But that's a solution and it requires a lot of work to be able to use models within a TE environment. For example, it's not like a model is accessed by a single script. You can write all those python codes in different variety of forms and when you're trying fine tuning and still the model should remain secure. So it requires a lot of development, it requires some DSL which will still remain secure and all that. But that's a path, that path can be taken for us from day one. We want to take a slightly more magical path.
00:47:29.391 - 00:48:14.621, Speaker B: Our thesis is that we are still thinking about how we are used to think in crypto, that it's a zero one thing that we want to prove every computation we want to lock it cryptographically. But you know, AI is something else. If it's performing at 50%, it's not called AI. If it's performing at 60, 70%, it's called AI. Right? So if you make sure that to get the full performance you need, you need something from the protocol, then you are done. You just have to make sure that it doesn't work so well. Unless when you say that you want to monetize the model, maybe they can copy and get a worse version of the model, maybe they can get out and have a model which is less Performing, but less performing AI is no AI because it's all about the accuracy.
00:48:14.621 - 00:48:59.445, Speaker B: So can we develop some AI native cryptography which is used to lock the model? So the cute observation here that we made for the first version of oml, which is what we released, this first version of OML is open, can monetize, but it's not loyal. The cute observation we made is that there is already something that can be put in the model. It's like a basic primitive of this world which can be put in the model. It's hard to detect, but someone who knows some secret about it can quickly come and check it. And these some things are called backdoors. It was an attack on the models where people wanted models to behave differently so they will hide some special prompts. It's like I don't know if you've seen Manchuian Candidate.
00:49:00.145 - 00:49:02.169, Speaker A: It's great movie of course.
00:49:02.297 - 00:49:10.249, Speaker B: Yeah, greatest. One of the greatest. So, so, but, but you remember that you can trigger that prompt and then the guy with Schreiber.
00:49:10.377 - 00:49:12.849, Speaker A: Yeah, yep. Yeah.
00:49:12.977 - 00:49:21.697, Speaker B: It's like that prompt, you can ask that and, and, and then it says something else, then it says a specific thing.
00:49:21.801 - 00:49:21.991, Speaker A: So.
00:49:22.013 - 00:49:52.399, Speaker B: So you can hide this prompt. And this is the basic primitive around which OML is designed. It's a simple cute thing that there is already within models the possibility of placing a query in a response which is very specific to that model. We can do that, we can design this any way we want. And you can ask that query because the model is deployed easy to ask that query. You don't even need the weights. And the response can be used to identify the model to check if things are going correctly.
00:49:52.399 - 00:50:20.531, Speaker B: To check that you have access. Exactly. This model with this primitive playing around with this primitive we designed the full protocol which we call OML 1.0 and this 1.0 doesn't ensure loyalty. But what it will be able to do is that it requires anyone deploying this model to take signature in batch for queries and only then like whenever they are giving respond, they should check and take permission in batch from the protocol. And whenever they take this permission, all monetization can happen around it.
00:50:20.531 - 00:51:03.105, Speaker B: If they don't do that, then some watchers can check and prove in a trust free manner that this model is giving access without taking permission from the protocol. And then you can build a crypto economic defense around it. And there's something one can do as an AVS on Eigen layer or whatever they want to do around it. There's a simple solution and many Things can be done around it. There are a lot of questions about how these queries are saved. But the one takeaway lesson I wanted to have is that just like every crypto thing has a basic primitive, the most basic primitive that we are talking about in AI is this fingerprint. The back doors which are, which can be tuned into the model and design them creatively and you can do many magical things with them.
00:51:04.525 - 00:51:39.017, Speaker A: Let me feed this back to you because I think this is just mega important. Right? So you guys realized early on that there's already thousands, millions of models actually on Hugging Face and otherwise. And these people just don't have any way to enforce revenue or incentive flow. Like they spend tons of money to train these tons of money to train these models, tons on data fine tuning, the whole nine yards. They upload Hugging Face and it's altruistic. I mean just starting there like that is crazy. Like don't those people want to earn money off their models? Like I don't get it.
00:51:39.017 - 00:51:47.445, Speaker A: Like why, why are there. Why is it so active despite. No, and it's great for the supply for you guys because you could onboard them and you know, give them revenue, right?
00:51:48.425 - 00:52:01.353, Speaker B: Absolutely, absolutely. That's a talent we want to go to. Right? Like that. Hugging Faces has done a great job. Llama has done a great job. They have, they have bootstrapped this whole ecosystem. And once you build on it, it.
00:52:01.369 - 00:52:13.495, Speaker A: Just seems like just of a logical de risk next step. Like millions of miles on Hugging Face. Put them on sentient, earn revenue. Right. It seems like it's relatively de risked if you could convince them.
00:52:14.115 - 00:52:57.813, Speaker B: This can be one of the approaches, but we are being a little bit more ambitious. So rather than saying that you monetize right away, we are taking the path of aligning them to a more singular cause about what models should be taken out first. So the sentient models we want to compete in offering level with this. And if in fact that's what you're saying is perfectly correct, if there are models on Hugging Face which are already at that level, then they should be incubated within Sentine and that's a valid thing. And we reach out to that ecosystem. It's exactly what you said, that this is the starting point. You look at Hugging Face, look at all these models sitting there and you realize that these guys have built these models to just get reputation for the CV so that they can do something else.
00:52:57.813 - 00:53:08.145, Speaker B: And instead of that, instead of that, why don't make it more direct? What will it take to make it more direct? For the best of them. And that's what this protocol is all about.
00:53:10.485 - 00:53:36.695, Speaker A: I mean, one of the easiest reasons to take your model and pivot it to an OML model on Sentient is just access the distribution. Right. Access to that, whatever that end use case is, whether it's DeFi, AI bot or a ChatGPT comparison someone's playing monthly for, if somebody has a great model, it gets surfaced and ranked and it's on the network. I mean, my understanding is that's the reason you add a model to Sentient, I think.
00:53:37.515 - 00:54:03.975, Speaker B: Right, yeah. Distribution is a very important part of it. That's what we offer and that's why we need. I mean, from the protocol side, the protocol has to make sure that the models can be onboarded. But that's why we need a very vibrant ecosystem. And I don't know if you see how Sentient is organized, so I'm on the core protocol side, but Census is looking at the ecosystem side, and that's a company bootstrapping this whole ecosystem around Sentient.
00:54:04.135 - 00:54:42.793, Speaker A: He mentioned maybe just to recap the flow here. So let me just give you my understanding and correct me where I'm wrong just for the listeners, but I'm a developer. I upload a model to the network, right? It's converted to this OML format, which is your native format. It takes this backdoor attack that you found and it fingerprints the model. Now, anybody could download this model, use it locally, the whole nine yards. But when you ask the local model a question, first it has to go to the network to be, I guess, sort of decrypted from the fingerprinting you added in so that it could correctly answer a question. You guys could track the revenue flow.
00:54:42.793 - 00:54:45.525, Speaker A: Is that sort of like a broad stroke on how it's working?
00:54:46.445 - 00:55:04.941, Speaker B: It's almost correct. But just one small thing is that it doesn't have to go just before answering. At the end of the day, you can have a settlement cycle, which is some periodic thing. You can collect all the things and bash them and send it. And as long as that, every settlement cycle, I'm getting all the queries. I will not be. I'm happy.
00:55:04.941 - 00:55:08.065, Speaker B: And there'll be no dispute. And there'll be no dispute resolution.
00:55:09.045 - 00:55:14.251, Speaker A: Got it. So there's no increase in latency, which is key consideration.
00:55:14.403 - 00:55:14.819, Speaker B: Exactly.
00:55:14.867 - 00:55:31.851, Speaker A: Okay, so at the end of the day, people can release open source open weight models, and you're solving the ability to effectively track and monetize. I mean, that's incredible. That's a huge innovation in and of Itself, I think that's massive.
00:55:32.003 - 00:55:37.495, Speaker B: Yeah, that keeps us excited. Yeah. And this week the white paper also comes out, so.
00:55:39.895 - 00:55:44.527, Speaker A: All right, I got one more Devil's Advocate question. Don't kill me when you see me in person.
00:55:44.591 - 00:55:50.635, Speaker B: These are the best one. What doesn't make me stronger? Yeah.
00:55:51.455 - 00:56:22.215, Speaker A: So no, I'm sure you'll have a great answer for it. So the whole OML model side, open source models, we could effectively monetize, track the revenue flow, attract developers. That all makes perfect sense. And then we open the podcast with, you know, Sentient will also build its own models, right? And compete. So how are we, how do we put these two together? Like how is the, you know, we're going to build our own models with the tracking of other people's models. Is it two different sides of the protocol or is it one and the same?
00:56:22.675 - 00:56:47.517, Speaker B: Oh, okay. So we are not starting with the other people model bit right now. So the question one should go into is how did those models come? The other people model that have been put, what goes into it? Right. And you would see that a lot of activities go into building a good model. So one has to collect data, filter data, then you train some smaller model and all that whole thing, that whole process. If you're actually building some useful AI. So Sentient has some useful AI.
00:56:47.517 - 00:57:18.967, Speaker B: It's targeting in the beginning takes a lot of collaborative effort. As that collaborative effort is happening, you give every contributor ownership, partial ownership of the model and then you omlize the model and release it through Sentient. These are Sentient models. And when it's used, because this is the easy part, once you can get it to the protocol, then protocol need not just pay one person, it can actually do fancy things, right? It can based on who has how much ownership of the model. Based on that, it can distribute the rewards. Right. So that's how the contributor gets rewarded.
00:57:18.967 - 00:58:10.809, Speaker B: So Sentient models are these community build models orchestrated at different times through different type of campaigns. And similar efforts have happened at universities. Sivong, one of our head of our AI research earlier at uwash ran this campaign called Data Comp, which was a campaign to build AI models. Clip model famously ground up by collecting data and fine tuning. And there are various variants of that model of that campaign that took up, in fact that piece is taken over by a large part of it by Apple Intelligence, which is doing the same thing for small models. So this community build model means you orchestrate the community towards a goal and people when they come and contribute based on some rules that you set up they get rewarded. Ownership of that model, you can have, you can have reward models, but let's give them free compute and all, but give them ownership of that model.
00:58:10.809 - 00:58:30.875, Speaker B: So of course you can set rules upfront about what kind of ownership is kept with the, with the host, the initial host of the model who brings up base one and then for each task, what kind of ownership will be distributed. All that programmability is easy and we offer that on our contracts. And now through this, these models get built. And those are the models we're talking about.
00:58:30.995 - 00:58:45.895, Speaker A: Yeah, I mean, I wouldn't, I would definitely. It's interesting because like I want ownership in the models I'm making, but like I could care less about the models like other people are making. Right? Like I don't know anything about them. Why should I own any of that? So I guess the breaking it down and keeping it modular makes sense.
00:58:46.765 - 00:59:01.005, Speaker B: Right? Right. And that. Yeah, exactly. Exactly. So. Well, there are builders only models and of course, you know, that's outside scope of the protocol. What happens to the builder ownership? Of course, it's a tokenized ownership.
00:59:01.005 - 00:59:07.445, Speaker B: And if in the middle they lose trust in the project or they want to do something else, they can dilute that ownership. Cool.
00:59:07.485 - 00:59:20.895, Speaker A: That makes sense. Well, let's move on to some of the fun stuff. What should people look for? Right? Like when do. When do people get involved in sentient? Like when could we start using it? When can we upload models? Like when does. When does this all happen?
00:59:21.475 - 00:59:25.291, Speaker B: Great. So first is the white paper release, which is now when you can read about it.
00:59:25.323 - 00:59:27.731, Speaker A: I'm jumping ahead here.
00:59:27.923 - 00:59:52.915, Speaker B: Yeah. Then the next big event for us is devcon. By devcon, a version of the platform, a demo version would be out and people would start playing around with, with it. That that's how we are seeing it right now. And in the middle we have a bunch of hackathons coming along in Valley and in other parts of the world. So you will start experiencing it in some limited circles. That's how we are seeing it.
00:59:53.655 - 00:59:55.383, Speaker A: Cool. When. When is DEFCON?
00:59:55.479 - 00:59:57.663, Speaker B: Is that November 11th?
00:59:57.679 - 00:59:58.543, Speaker A: I don't even know when that is.
00:59:58.639 - 01:00:00.071, Speaker B: Yeah, second week of November.
01:00:00.183 - 01:00:06.275, Speaker A: Okay. So coming up. So pressure's on always, man. Yeah.
01:00:06.935 - 01:00:10.001, Speaker B: Yeah. That's the thing about pressure is always on.
01:00:10.153 - 01:00:36.499, Speaker A: I mean, it really is. Let's move on to some of your, like just some of your own personal views on AGI and AI. Right. Like I'm not. I'll throw you a couple lobs here. We could take this any way you want, but I mean, there's a lot of conversations about, you know, how far away AGI is, how powerful it would be, what you and I will do all day. If this thing is doing everything for us to we just go play ultimate Frisbee all day or.
01:00:36.499 - 01:00:43.491, Speaker A: And get ubi. Like what are your like personal takes on like what life looks like with an AGI world?
01:00:43.643 - 01:01:01.063, Speaker B: Okay, so, so you know, for me, AGI to begin with, you can def. Like it can be defined. Okay. And it. Every person can have a different definition. So I was going with a particular definition of AGI and that's a. I would say that's a rather modest definition.
01:01:01.063 - 01:01:47.811, Speaker B: The modest definition of AGI I have is that something which can solve tasks with high accuracy, AI, which can solve end to end tasks with high accuracy. So you see that this AI has this dichotomy that great applications like Google map are at 98% accuracy and AI looks great when it has 70% accuracy, 65% accuracy. So what is this great, this greatness is about its creativity. The fact that it can talk with you. Taking it from there to closing, let's say sales or solving customer issues or whatever boring application people have in mind or debugging software and writing code. Very high accuracy stuff. Each of these things is a realization of AGI for me.
01:01:47.811 - 01:02:34.363, Speaker B: Although now you can say you should do five things to call it an AGI or 10 things, some benchmark like that you can have. But it's roughly that. So that's firstly what AGI is for me. So one version of AGI which I'm pretty sure enters all our lives, will enter all our lives in the next, not 10 years, but five years, is that all the things around you will already have this kind of AGI sitting in it one way or the other. This co pilots which are doing one thing or the other. Maybe it will be as simple as, you know, this email composer, the autocomplete that we got used to, it will become something much more like. It will be so simple it will be out of your way and that will be the first version of AGI and it will be in so many different things and you won't even be like, yeah, this is fine, this is fine, but you know, this is not complete and there should be this and that, but there'll be so many of those things.
01:02:34.363 - 01:02:58.413, Speaker B: For example, suddenly if I, if imagine if from 2006 you suddenly dropped into this whatever self driving car, Tesla self driving car, you will call it self driving. But now I know that, you know, my German friends are saying this is not self driving. This is assist driving. This is that and that. These are, these are nuances because your bar has gone up. But if you brought someone from the right time, let's say just 10 years ago, they will call this self driving. This looks self driving.
01:02:58.413 - 01:03:35.357, Speaker B: It's going at, it's going at very high speed. On a highway with so many lanes, why won't you call it self driving? But this notion of AGI will be normalized more and more. Second aspect of this is that there'll be a lot left still. Humans have always shown that there is more to our brain than what we can use. And our intelligence grows with the tools that we have that I very strongly believe in. And I don't know, you only have to see kids to understand this, the.
01:03:35.381 - 01:03:36.865, Speaker A: Effort, it's a hell of a take.
01:03:37.295 - 01:04:14.823, Speaker B: Yeah, yeah, we always, we always, our intelligence grows with the tools that we have. And, and so if you give me more tools, I'll have more meta heuristics to use them more creatively. It's not, I'm not limited in my intelligence to that way. I have a, this meta notion of it. And now the question is, can one have this meta intelligence to overtake humans? I feel this is a very philosophical question. I feel that the high level answer I can have for it, maybe I'm not competent on this, but my high level answer is there's no way AGI can be dangerous. It need not beat humans in every aspect to become dangerous.
01:04:14.823 - 01:04:32.903, Speaker B: That's a different aspect of it. It can hack, it can take over nuclear plants. All that danger is true, you should defend against that. But to say that will humans be relevant is. I feel humans are super relevant. And that's one thing which amazed me. I was just thinking a few days back about how crazy maths has been.
01:04:32.903 - 01:04:58.973, Speaker B: Elon keeps on saying that like as a species we should go outside our planet, right? That's something we should do. And that's an impactful thing because that's a universal scale thing that we did to ourselves. And I was thinking, you know, maths made people do that. Like it extended the extent of species. It grew life in that way. And what is surprising is math is also growing life in another way. It's creating the next level of intelligence.
01:04:58.973 - 01:05:29.069, Speaker B: And we always thought it's a mechanical tools and this and that, but it's becoming this, this algorithms and this AI which will help human now solve more things. For example, if AI will solve, let's say, some long standing open problems in math. Just an example Right. Like, because the grand puzzles and humanity has been obsessed with them for hundreds of years before it solves them. I believe it will solve with human assistance and that will be a breakthrough. And then we don't solve those problems. Then we look at the next problems.
01:05:29.069 - 01:05:46.669, Speaker B: So then we use it for solving. Discovering drugs, longevity. I'm, I'm pretty sure we can use it for our benefit. That way we will always stay ahead. But that doesn't rule out the safety part of it. Safety part is completely complementary. Even, even at a lower level of intelligence it is.
01:05:46.669 - 01:05:49.705, Speaker B: The dangers are pretty high. And that's a different aspect of it.
01:05:50.565 - 01:06:18.785, Speaker A: I mean, I, I think your take on AGI being this slow grind where, where, you know, it gets embedded in Google email and Google search and you know, in Telegram and Twitter and we start to get accustomed to it. I think that's a relatively unique take because when I talk to people it's always like AGI is going to hit the scene and your life's over and it's going to change. You know, Schwarzenegger comes back from the, from the future. Right. Like, it seems like a pretty unique take.
01:06:19.365 - 01:06:30.185, Speaker B: Yeah, let's see about that. Like, I don't think it solves all because there are too many different heuristics there. I don't think it solves all problem in one go. This way there is no one answer.
01:06:31.885 - 01:06:57.935, Speaker A: And the your IQ thing with tools is pretty interesting because there's a couple like sci fi ideas around this. Right. Like at a very basic level, it's like an AI companion through K through 12 of school. And it teaches you in ways that only you learn the best at. Right. And clearly you're skipping grades at this point and getting way smarter. The other sci fi aspect is just that the parameters in the model are like artificial neurons in our brain.
01:06:57.935 - 01:07:07.143, Speaker A: Right. Like you're just expanding your brain capacity with those neurons. I don't know how real that is or not, but I guess by association of the tool, it's kind of true.
01:07:07.279 - 01:07:25.745, Speaker B: Yeah, yeah. It doesn't contradict both of these things. Don't contradict what I'm saying. I'm just saying that this is an expansion of the life form itself and we will grow from it. It's an inevitable thing. So if you think of one objective function, let's think of rational explanation for the universe. And that's just survival.
01:07:25.745 - 01:07:40.717, Speaker B: That's just survival. Let's say the species is built just for survival and so it has to escape this planet and it has to become more intelligent than Itself. Right. So that's a survival. Right. It can exist forever. The Personas can exist forever.
01:07:40.717 - 01:07:47.355, Speaker B: And it can grow. And it can grow. So it sounds like natural thing to be discovered towards survival.
01:07:48.415 - 01:08:08.071, Speaker A: That is pretty. Yeah. I've always wondered like will AI leave the Earth? Because by leaving Earth it's basically saying I don't want these, you know, billions of GPU plans to make myself smarter. I'm okay with the level I'm at and I'm risking that to leave. I don't know how it'll decide that but I'm curious to see how that pans out. We'll see.
01:08:08.263 - 01:08:34.575, Speaker B: Energy is the next. I mean GPU always reminds me of when I think of this first principle things obviously energy is the next frontier. I always feel that Again again it happened at a cost of very high energy. Amazing that this revolution came but surprisingly still at the cost of very high energy. Nuclear energy related thing all the breakthrough. Somehow the energy part I still feel we haven't broken that barrier. That's very exciting part.
01:08:35.155 - 01:08:44.843, Speaker A: Do you think governments will just greenlight nuclear around the world to catch up on AI? Like do you think it'll like it's big enough and it's important enough that it'll drive that change?
01:08:44.979 - 01:08:55.227, Speaker B: I think it's possible because I hear that in some countries. So for sure that's possible. I think so. I think so. This, this energy becoming. Maybe it's wrong. It's a very simplistic take.
01:08:55.227 - 01:09:22.701, Speaker B: I always thought energy was an internal matter of a country. Somehow it's some reputation and somehow internal. Okay. We know it has the gdp. We know it's directly correlated with GDP and all but it's internal felt internal never defends an external AI made energy at external and defense issue so. And countries are known to spend disproportionate amount when it comes to a defense issue. So I feel that this may be true.
01:09:22.701 - 01:09:23.945, Speaker B: What you're saying is true.
01:09:24.405 - 01:09:45.785, Speaker A: We're going to have many reactors all over the place just trading our local models. Yeah, exactly. Interest, a lot of pollution. But he vanu. I. I had a blast talking to you. I mean we're proud to be investors in you guys and we're really excited for the future of sentient.
01:09:45.785 - 01:09:52.673, Speaker A: So thank you so much for coming on and let's do this again maybe after devcon or whenever you'd like.
01:09:52.849 - 01:09:55.105, Speaker B: My pleasure. Tommy would be happy to come back anytime.

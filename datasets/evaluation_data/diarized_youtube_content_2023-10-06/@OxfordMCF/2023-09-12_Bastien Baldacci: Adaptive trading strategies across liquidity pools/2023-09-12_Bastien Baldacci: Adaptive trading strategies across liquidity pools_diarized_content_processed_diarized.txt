00:00:01.360 - 00:01:09.480, Speaker A: Welcome, ladies and gentlemen, to frontiers in quantitative finance. This seminar, this is a monthly seminar on new advances in quantitative modeling and finance, brought to you by the Oxford Mathematical and Computational Finance Group and supported by Mosaic Smart Data and Citigroup, whom we thank for their generous support of this today. So this month we have the pleasure of having as our speaker Bastia Baldacci, who is a PhD candidate at Ecole Polytechnique in Paris. And this is a joint work with his colleague Julia Manziuk. So Bastia won this year, actually, I think 2020, the Rising Star award, which is a prize awarded by Risk magazine to risc.net to the best junior researchers in the area of quantitative finance. So, congratulations to Bastian for this.
00:01:09.480 - 00:01:45.964, Speaker A: And I think it was related to some of the work he's going to present here. And before starting his PhD article, Plate Technique, Bastiam was quant at JPMorgan, where he worked on similar topics. So his field of research is market microstructure and mathematical models of optimal trade execution. And today he's going to present his recent work with Julia on adaptive trading strategies across multiple venues, across multiple liquidity posts. So, over to you, Bastia. Thank you very much.
00:01:46.654 - 00:02:31.354, Speaker B: Thank you. Thank you very much, Rama. And thank you also for all the people who attend this seminar. So yeah, this is the work which was presented to the risk world. This is a joint work with Julia Mongio, who is a postdoc student at Ecole Polytechnic. And it is related strongly to the so called smart order routing problem. So before I dive into the subject, I will do a brief history of optimal execution, which can consist in fact in buying or selling a certain quantity of an asset.
00:02:31.354 - 00:03:37.624, Speaker B: So I will distinguish three group of models. The first one is, are based on the similar work of Almgon and Chris. So basically they just formulate the optimal execution problem using Minva variant framework both in discrete and in continuous time, where you have a trader which aims at minimizing the trading cost of his strategy. And so the assumptions are quite simple. The price process is an arithmetic bony motion with both linear permanent market impact and temporary market impact. So as you only have an arithmetic Bronyan motion, they could use calculus of variation to obtain a determined deterministic trading curve. And so there are, I think two facts to highlight on this one.
00:03:37.624 - 00:04:41.556, Speaker B: The first one is that in this kind of model, there are no uncertainty with respect to order execution. If you take the example of lobs, this is the same as if you send market order and you have constantly constant market liquidity. And second, the model we have is agnostic to the market structure. So it does not really matter if we are on an LoB or an OTC. Marketing does not take into account the structure of the market. So it is more a tool for a broker, for example, which gives a precomputer put trading curve to follow approximately depending on market conditions. The second group of models right here is based on stochastic control approach.
00:04:41.556 - 00:05:50.224, Speaker B: So the work of Aveline Stoicov formulate. In fact it is more on the market making side one of the key problem of a trader, which is inventory risk. That is, it is in fact the trade off between the frequency of execution and the price risk. For example, if you have a limit order away from the mid price, you will be executed at a better level, but you will have lower probability of being executed. And if the price moves in the contrary of your order, you will not be executed and you will carry inventory risk. The title of their article is high frequency trading in a limit order book. But in fact the model they propose is more sweet related to OTC market.
00:05:50.224 - 00:07:02.672, Speaker B: As I just write here, due to the fact that the spread process, which is the control process of the trader on the bid and ask side are continuous and in if you are in an lob, it's more discrete control processes. And also. Yeah, by setting inventory risk limits and also a constant size of transaction. Guillaume Joaquin Fernandez tapiacally showed that the solution of the Aveline dance to a problem is obtained by solving a simple system of ods. And the optimal quotes of the trade reader are approximating mainly linear function of his inventory. The third group of model, which is more or less our focus to today is related to the execution in order. The books also using stochastic control theory.
00:07:02.672 - 00:08:30.342, Speaker B: So the model basically of Gilbo and Pham models the spread and imbalance processes of the order books with continuous time Markov chains. And so the trader sends both limit and market orders to optimize the mean variance criteria. And similarly to what we had before. If the price process is an arithmetic Bronyan motion, the optimal control, which is the posted volumes, and the limit we choose which is first best or second best limit are solution of a simple system of these. So yeah, before I move to the smarter order rating problem itself, I will just mention two main subjects of extend extension of optimal trading models. So since a couple of years you have a team of researchers driven by mainly by Cartier and Jay Mongel, which used the Aveline Stoikov model with a different objective criteria. And they basically added a number of stylized facts.
00:08:30.342 - 00:09:57.184, Speaker B: So for example, ambiguity, big version trading signals and market order flow to obtain more realistic mode realistic models. The second subject of research is more related to the adaptivity of the strategy of the trader to current market condition. And so the typical example we have is the work of ALM. Graham and Lawrence, where basically they use conjugate prior on the drift of the price process. Because you have the price process is an arithmetic motion, and if you put gaussian prior on the drift, the posterior distribution will also be gaussian. And so the values taken by the drift of the price process will depend on the observation of the price process itself throughout the whole execution. But a key parameter which has to be updated in practice is the probability of execution of limit orders.
00:09:57.184 - 00:11:27.890, Speaker B: I will illustrate this with a simple example. So, assume that you have calibrated your probabilities of execution historically and you begin to sell on an asset using zinc limit orders, but at the same moment you have another market participant which sells a meta order using only aggressive order. So what will happen is that it will basically consume the whole liquidity on the sell side of the order book and your limit order will never be executed. And as a consequence the algorithm will not adapt to this new condition because it does not observe a poor feeling probability. It is. And yes, one last area of optimal execution articles is to the tactical play, a placement of orders. So, all the work I mentioned before right here assume whether you are on OTC or on lob, that the trader buys or sell on a single liquidity venue.
00:11:27.890 - 00:13:17.120, Speaker B: But what happened that in practice, most of the quantitative trading strategies, especially when you work at the high tech scales, they are based on statistical arbitrage on what is called cross listed stocks, which is a stock listed on several venues. For example, example, you have a stock listed on LAC and also alternative trading ver news such as baht or kaix. And so, depending on the current spread and imbalance, the trader has to choose how to split both limit and market orders on all the liquidity news. And this is the purpose of the article of Hama and Kukanov, where at each fixed time the trader solves a static optimization problem to obtain either optimal strategies in terms of volume and type of order on each venue. So we can move on to the description of the problem, which is as I said, the smart order routing problem. So as I illustrate right here, the construction of a trading strategy usually involves two layers which are almost independent. The first one is the strategic layer, which is the construction of an execution curve.
00:13:17.120 - 00:15:03.614, Speaker B: For example, allah Alm, which neglect all the microstructure effect. So for example, example here on the left side you have the angry execution function if you want to maximize your p nl over the period. And you also have, you can also have other criteria such as the VuAP if you want to minimize your market impact. And the second layer of the trading strategies is in fact the smart order rating problem, which is the optimal splitting of orders across liquidity pools, as you can see here, because you have for example free platforms with possibly different spread and imbalance. So the first question we will try to answer is related to the connection with these two layers. So given an execution strategy, how can we design optimal execution tactics across civil liquidity pools? And the second question is related to the adaptive vt of our smart order routing algorithm. Meaning, can we find a rule to update market parameters to take into account the non stationary of the market? So I will describe the model.
00:15:03.614 - 00:17:07.040, Speaker B: So first of all we can see cedar trader which acts on n liquidity ver news and we will assume for simplicity that we are doing optimal execution, meaning that the traders only act on the sell side of the order book. Of course you can extend to both sides, it does not increase the dimensionality of the problem. So we say that the the new end is characterized by two processes, it's BDask process CTN and it's imbalanced process ITN, which are continuous time Markov chains on finite state spaces. And also just wait 1 second, I've done something good. And for example, example we can consider different cluster of spread and imbalance regimes, for example low, medium and high spread and imbalance in order to obtain a more personal news model for the update of market parameters, as we will see in a couple of minutes. So if we now talk about the modeling of the loob, so each state and when we mean state, we mean all the state of spread and imbalance on all the liquidity vews has exponentially distributed the way with mean one divided by new nuke. So just bear in mind the following, which is that the how does it.
00:17:07.040 - 00:19:09.204, Speaker B: Yeah, there is a single infinitesimal generator for all the spread and imbalance processes. So that in fact all the spread and imbalance of all the liquidity pools have a joint distribution, which is in fact the key to the smart order routing problem, because each ver news are linked one to another. So about the traders strategy at time t at each time t over trading horizon zero capital t, the trader controls the size LTN and the limit PTN at which he will send limit orders in the venue end or he can also control the size MTN of market order. So as you can see here on this image, the trader can either post a limit order at the first limit, right here at the second best, the best limit. It can also create a new best limit if the spread is not equal to one tick size, or it can send a market order and being executed at a less favorable price. And so, the number of possibly partially filled limit orders under the venue end is modeled by a point process NTN, which has this intensity city. So, what is important to bear in mind is that the probability of filling is on the venue.
00:19:09.204 - 00:20:45.884, Speaker B: N is a function of all the spread on the venues, all the imbalance, the chosen zen limit pn on the venue, and the volume sent on all the platform, which model in the fact that there is a joint global liquidity on all the venues. For example, you cannot send a big limit order on one venue, and do not expect that the liquidity will be, will not be reduced on other platforms. And in this work, we assume that market orders are fully executed and are modeled basically through an impulse control formulation. So basically, the trader will choose the time to I at which he will send limit or order on each venue of size min. So, the trader executes shares of the asset. And we assume that the, the mid price st, which is right here, is an arithmetic motion, possibly with drifts, but it's not really important. And so the trader Manet, this is cash pro process, which is right here.
00:20:45.884 - 00:22:42.874, Speaker B: So, on the platform end, the traders gain with limit orders is the volume executed, which is LTN times Epsilon TN, which is a random variable bit between zero and one, which represents basically the proper portion of execution multiplied by the execution price. So it is the sum of the mid price, the current spread process, and the chosen limit. And we see that if we set ptn equal to zero, you, you post basically at the first best limit. And so, when the trader chooses to execute a market order of size min on the new end, which is at time to in, it gains the volume min multiplied by the execution price, which is the current mid price minus half spread. And for the inventory process, it is basically the same. You have inventory at the beginning given by q zero, and you subtract, because as we said, we are on the sell side of the map market, all the volume executed via limit orders, and the volume executed via market orders. So the number of possibly partially feed limit orders on the revenue end is modeled by this stuff right here.
00:22:42.874 - 00:24:44.384, Speaker B: So the intensity is in fact composed of two parts. The first part here, the function f lambda of lt is a decreasing function of the posted volumes on the venues, which means that bigger orders has less chances to be executed, and also the fact that if you send an order on one venue, it will reduce the liquidity on other vews. The second part which is right here is a multi regime stepwise function. So for a given market state m, which is like for example, example if you have two liquidity versus could be low spread and low imbalance on the first one, and high spread imbalance on the second one, and a limit p right here, the probably execution of your limit orders is lambda NMp, which is a constant and thus the probabilities of filling are interconnected and depend on the spread and imbalance on all the liquidity values. And it is basically the same idea for the proportion of execution for limit orders. We assume a category equal distribution with a finite number of values. So typically either you have fully executed or half executed for example, and it is also the product of a functional of lt and multi regime stepwise function.
00:24:44.384 - 00:25:51.024, Speaker B: And so we come to the optimization problem. So the trader phase the following optimization problems of the supremum over all the limit, all the volume he post using limit and market order of the sum of. So the cash process, the mark to market value of his inventory and running penalty, which penalizes deviation from a precomputed trade trading curve q star. So this has to be a deterministic trading curve such as alm can v Wap and you have the risk of version parameter gamma. So the solution of this problem is equivalent to solve two n plus one dimensional ajb equation. Why two n plus one? It's fairly simple. The one correspond to the inventory queue.
00:25:51.024 - 00:26:53.670, Speaker B: The first n variable respond to the old imbalance process, and the second n respond to all the spread processes. Because as you have an arithmetic Bronyan motion, it does not appear in as state variable. And so we can prove it is in the paper. But it's not really the topic to today that there exists a unique viscosity solution associated to this control problem. So now that we have, we now have a, formulated properly, the smart order routing problem with an execution target right here. So, if you have below free liquidity venues and a passing model. In the numerical example, we took two regimes of spread and three of imbalance.
00:26:53.670 - 00:28:02.756, Speaker B: The optimal control PLM are obtained in at most a couple of seconds. But in this framework, we have assumed a market stationary, which means that we assume that we have an accurate historic calibration of our market parameters at the time of the execution. And we will now present an I would say rule of thumb to obtain adaptive trading strategies. So incorporate bias and learning of all the market parameters will lead to an intractable control problem. It is well known in stochastic control theory. So what we propose is to do a conjugate biogen update which is decoupled from the control problem. So I will give one example with the intensities of limit orders.
00:28:02.756 - 00:30:04.840, Speaker B: So you put prior distribution gamma on each lambda NMP and up to time t the trader observe this process which is basically the number of limit orders executed when all the spread and imbalance on all the liquidity news were in state m and you used limit p. And as Poisson and gamma are conjugate distribution, you have at the end posterior estimate of the intensities which are conjugate. And similarly we define conjugate biogen update for the generator of spread and imbalance and the proportion executed of limit order. So if we wanted to incorporate this by year end update, for example here of the intensities of limit orders, we would have to add all the processes nt and NMP as a state variable of the control problem. And even for the parsimonious model that I described to you a bit earlier, for example, you have to the news with two regime of spread and three of imbalance, you would have 36 more state variables in your control problem. And of course this is completely intractable. So what we propose is to break the execution of the quantity q zero into slices of execution, on which we will assume that parameters remain constant.
00:30:04.840 - 00:31:09.604, Speaker B: So it is something that is usually done in practice. You break a big execution into smaller slice of execution. So the algorithm work as follows. So you take, first you just take the best estimation of the market parameters, which are all the parameters such as intensities, drift, volume, et cetera, from the period distribution for the current slice. With this constant market parameters you can solve your two n plus one equation. And during this slice of execution you will observe all market events, the execution of your limit orders, the changes of state, etcetera. And at the end of the slice you will just update the parameters here using the conjugate bias rule as the one here.
00:31:09.604 - 00:32:32.354, Speaker B: So of, of course, so what, what we do here to resume is that we assume of market parameters on only on slices of execution. And of course it leads to time in inconsistent control problem as we break the execution into smaller time slices. But as I stated before, the good point for practitioners is that you avoid the curse of dimensionality of biogen control problems. And so now we move to the numerical experiments so before I move on to that, I just have a couple of remarks on this. So I did not write it, but we took the following set of parameters for this, we took two liquidity venues with two regime of spread, three regime of imbalance, two execution proportion, meaning you have your half executed or fully executed. If you use limit orders, you have a time horizon capital t of ten minutes. And we use ten slices of one, one one of 1 minute.
00:32:32.354 - 00:33:56.210, Speaker B: And you have to basically sell a quantity q zero of asset s. So we use two type of numerical methods. We first use finite differences, because it is a low dimensional control problem, is 21 with n equals two, is equals to five and it's basically the variable do not have high dimension because only take two or three values. And deep reinforcement learning method. So for finite differences we used, I think it was a grid of 51 possible volumes and 101 inventories. And the optimal control were obtained for each slice in only a couple of seconds. So for the deep reinforcement learning approach, the traders strategy, so the p and l and also the market order m, as well as the value function of the control problem are represented using nor network.
00:33:56.210 - 00:35:44.446, Speaker B: And to be fairly concise, basically what we do is that we use actor critic method, meaning that we alternate the phase of learning, so that the gradient descent between the optimal control of the trader and the approximation of the value function. So this is all, I think, for the description of the data we used. So in this slide, we basically generated for each inventory queue and in x axis the value function with condom market state and I. And so what you see is that the value function oscillates drastically depending on the spread and imbalance, but it still has a quadratic shape because we use the pen natifung is q minus q star squared. One thing we see in this slide, if you compare the right hand side with the left hand side, is that we obtain a better approximation of the value function if you use categorical input for the spread and imbalance, which is fairly normal because they are discrete by nature, and basically on the approximation of the optimal control. Just couple of remarks. Also, the volumes link are bounded continuous, but the limits p takes a value minus 10 and one.
00:35:44.446 - 00:37:02.462, Speaker B: You know, either you post at the second best limit, the first best limit, or you create a new one. And as they are discrete, they are not really suitable for a neural net network, because at the end you need to do some differentiation to do your gradient descendency objective function. So what we've done is that we approximated the limit p by the probability to send an order on each limit minus 10 and one. And this probability is parameterized with a softmax activation function, which is itself a smooth function, which can be, which is differentiable and which we can apply gradient descent at the end. Two last remarks two last technical remarks. For certain layers of the neural network, we separated the market state CNI and the inventory queue so that it is not a fully connected network. And it has basically enabled us to capture market state features with CNI independently from the inventory queue.
00:37:02.462 - 00:38:26.382, Speaker B: And we also separate some layers preceding the output in order to use different learning rate for limits and volumes. So on this slide it is fairly simple and easy to see that at time t equals zero, the max of the maximum of the value function is about q equals forty k. And you know, as time increases, the maximum shift to a lower inventory. So it corresponds basically to the inventory target of the trader at each time. So on this slide what we do is that we plot the limit and the, the volume of the trader. So on the left side you have the limit order strategy minus 10 plus 10 and minus one. And on the right hand side you have the volume posted by the trader as a function of the inventory for similar spread and imbalance and similar vernus, which means that both Vernus share similar parameters in terms of infinitesimal generator.
00:38:26.382 - 00:39:33.764, Speaker B: So it's not that easy to interpret. But the key takeaway of this picture is that when the header is ahead of the trading schedule q star, it will tend to post limit orders at a higher limit to collect the spread and convert. If he is late with the execution, he will more create a new best limit, which you can see here. You know, if he's late, he will create more and more soon a new best limit to be executed at a less variable price, but with a higher profile probability. So in this slide we assume that there is a higher spread on the second venue. You know, you have the, there is two tick size on the second one and one tick side on the first one. And both venue have the same imbalance.
00:39:33.764 - 00:39:56.658, Speaker B: So if you take t equals 0.5, for example, it is the same for other times. The volume on the right hand side increases linearly with respect to q in the first venue. In the second one it increases until more or less q equal 22.
00:39:56.786 - 00:40:02.986, Speaker A: The two curves are of the same color, so we don't see which one is venue one and two. Maybe you can use the mouse to point.
00:40:03.130 - 00:40:06.324, Speaker B: So let me see this way. Try to zoom.
00:40:06.364 - 00:40:10.404, Speaker A: Oh yeah, okay. But still it's the same color, so maybe you can point with the mouse.
00:40:10.484 - 00:40:19.444, Speaker B: Okay. Okay. So the venue one is basically the one doing it increases. And the second one doing this, is it fair?
00:40:19.524 - 00:40:20.044, Speaker A: Yeah.
00:40:20.164 - 00:41:25.354, Speaker B: Okay, perfect. Just wait 1 second. Okay. And so, yeah, and in the second venue, what will happen happened at t equals 0.5 that it will, the volume we send on the second venue, which will increase it until about q equal 22k will be constant roughly until q equals thirty k, and then it will be equal to zero. So in fact, between q equal to ten k and q equal to 30k, what will happen that the trader collect the spread on both the news and for q above 30k, which means that he's quite late with his execution schedule. He prefers to maximize the probability of execution by posting only on the venue with the more favorable, which is the first one.
00:41:25.354 - 00:42:29.330, Speaker B: So you see, it's all about a trade off between the market condition on both the venues and whether or not the trader is late with respect to his execution schedule. If he's not late, he will try to collect the spread on both venues. If not, he will focus on one venue because of the fact that there is a global leak liquidity. And finally, on this slide, I show the influence of the imbalance. So we assume the same spread in this slide, but a more favorable imbalance on the second venue. And so what happened here is that basically the second venue is this one, the one that increases linearly, almost with respect to the inventory. And the first one is this one.
00:42:29.330 - 00:43:50.118, Speaker B: It increases, stay constant and then decrease at time t equals 0.1 and t equals 0.5. What happened is basically that the trader, so he post a higher limit right here on the left hand side, on the second venue, between roughly 20. And it's not really, you cannot, not really see in fact, but because it has a higher probability of execution in the second venue, because the imbalance is more far wearable to him. And for Q large, what will happen that he will stop posting on the first venue because he's late with his execution schedule and he will try to increase its feeling, probably little. On the right hand side, you can see that he posts the vast majority of the volume on the second venue, because he has more favorable execution can be different because of the imbalance. And for a low queue, it will try here between ten k and 30k roughly to collect spread from both the news.
00:43:50.118 - 00:44:49.540, Speaker B: And I will conclude on two things. The first one is here, the extent tension that we treat in the paper. So it's fairly easy to incorporate signals into the price process. If you want to include short term prices, signals it's in fact a markovian function of the spread and imbalance on all the venue. And you add it in the drift of the price percent, and it does not increase the dimension. If you want to include mid or long term and past dependent prices, signal, for example, moving average or running maximum of the price, you will basically add one dimension per se. And if you want to add, so here it's two n dimension, because I took the example of transient market impact.
00:44:49.540 - 00:46:43.904, Speaker B: If you want to add transient market impact for limit orders, you will basically add two n dimensions. And I will conclude on one last thing, is that this works quite well for mid frequencies strategy. But we saw that on really, really high frequency stuff, when you need to have computation really fast, such as the work that you've done on the optimal placement of limit orders, optimal control is not really well suited because you still have to solve an HB equation. And what we are trying to do now, and it is available on archive with Gordon Ritter and Jerome Benven, who work at Exodus point, we try to basically use the framework of smart order routing, basically only solve a static optimization problem. But we basically try to show that if we use as a short term alpha, the gradient of the value function of the long term trading curve, you can both do smart order routing in a couple of milliseconds, in that case, because it's only a static optimization problem and still be approximately optimal with respect to a long term trading schedule. And that's all for me. Thank you very much for listening to me.
00:46:44.634 - 00:47:38.368, Speaker A: Thank you very much, Bastiat. So we have time for questions, any questions from the audience? So, actually, I have a question related to what you said at the end. So, about the formulation of the problem in our paper with Kukanov. As you said in the beginning, we separate the order placement problem across multiple venues. So the order routing problem and placement problem from the scheduling problem. So we say you have scheduled with your favorite algorithm, algorithm quiz, or whatever you want, VWAP. And now each of these orders needs to be routed or placed.
00:47:38.368 - 00:48:05.084, Speaker A: And so we solve a sequence of static problems, as you said at the end. Now, but in this talk, that's not what, what you did, right? You, you, it seems you're mixing the scheduling and the routing and placement. So you said in the beginning you had a slide where you said, these two are decoupled, but then you couple them. Why do you couple them?
00:48:06.454 - 00:49:02.706, Speaker B: Because in fact. So why do. Maybe I missed something in fact here. Yes, no, no, you're right. Usually you decouple the two layers as you, you've done in your paper. But what we found actually is that, for example, at the HIF scale, or even happens that you send limit or market orders with volume target, and suddenly you have a new trading signal which makes a new volume target, in fact. And this is why we wanted basically to mix both.
00:49:02.890 - 00:49:51.528, Speaker A: But, okay, so I think, well, well, I'm not sure if I understand why, but maybe for this, it would be interesting to show an example where not separating is better and why it's not so obvious. Yes, of course, you can always optimize over everything, but then you need more assumptions, I think. So then if you want to sell that to me, I say, okay, show me why that's better. And so give me an example where joint optimization over everything improves something that I lose in the sequence of static. So I think maybe that would be interesting. Maybe you have that already, but I.
00:49:51.536 - 00:50:10.560, Speaker B: Don'T know, I kind of agree with you. I should, we should do a comparison with what you've done. The main difference, I think that with your stuff, what you do is that basically you, the result, are obtained in millisecond at most.
00:50:10.752 - 00:50:12.224, Speaker A: Yeah, because it's closed form.
00:50:12.304 - 00:50:32.864, Speaker B: Yeah. Right. And with optimal control is always slower. So, yeah, maybe we should do a comparison with what you've done and find cases where it is better to mix both rather than separate.
00:50:35.164 - 00:51:31.474, Speaker A: Okay, and the other thing I didn't catch is, do you need to know the process for these variables in advance? You need to specify it, because again, in our static routing model, one of the nice things is that we don't need to know the distributions of these quantities. We learn them. It's like a machine learning. I mean, we didn't use the term machine learning, because at that time it was not fashionable, but basically we learned the distribution as you go on. And this is pretty similar to smart order routing algos, because they, they compute some statistics like fill rate and so on, and then basically you allocate based on those statistics. It's a classifier. So, so you don't need to know the distributions of everything in advance, you just use the empirical distribution or you learn some distributions.
00:51:31.814 - 00:51:33.222, Speaker B: So here in here.
00:51:33.358 - 00:51:34.718, Speaker A: Yeah, what is the case?
00:51:34.846 - 00:52:04.654, Speaker B: Yeah, here it now, in fact, here, it's one of the pitfalls. I would say that as you know, we used a jugate by year one estimate to update what we see. We have to specify some distribution. We tried, you know, when we specified the probabilities of feeling, we tried to make it as general as possible, but it is not as general as what you've done.
00:52:04.814 - 00:52:08.474, Speaker A: Okay, but you, you, can you learn the parameters?
00:52:09.254 - 00:52:09.662, Speaker B: Yes.
00:52:09.718 - 00:52:11.622, Speaker A: Or do you need to fix them in advance?
00:52:11.758 - 00:52:21.806, Speaker B: No, we, we fix them in advance. We observe them, we compute, we update them at the end of the slice. And again. And again.
00:52:21.990 - 00:52:27.714, Speaker A: Okay, thank you. So, any other questions for Bastia?
00:52:30.334 - 00:52:32.874, Speaker C: Hello. Just one question.
00:52:33.374 - 00:52:34.954, Speaker A: Please introduce yourself.
00:52:35.614 - 00:53:33.594, Speaker C: I'm Tomislav from Croatia in Zagreb, and I have a question regarding the starting point of conjugate prior update. So you specify in the paper, you say that, as I quote, we propose a prior low on the arrival rate and to update prior belief. At the end of each lies execution. So the parameters of Alpha and beta are chosen by the trader according to his vision of the market before he starts the trade. So does the order of Alpha and beta make some difference when you are starting to consider data, as you start to update posterior distribution, as new examples arrive?
00:53:35.494 - 00:54:29.674, Speaker B: Yes, it makes a difference because as I think we stated in the paper, at some point you can choose, for example, you state alpha and beta. The trader basically chooses it depending on its level, of its prior level of confidence. So basically, if you say that Alpha over beta is quite high, the new observation will not be really relevant with respect to the evolution of the probabilities of execution, but you can modify it to be more or less confident with respect to the, to what you think at the beginning of the execution.
00:54:33.614 - 00:54:36.314, Speaker A: Okay, any other question?
00:54:39.604 - 00:55:01.984, Speaker D: Hello Bestien, thanks for the very nice talk. This is from Oxford. I actually have a question about the last extension you mentioned about hidden liquidity. Because when you have hidden liquidity like dark pools, the feedback would be like a bandit feedback, you won't have the full observations. So will that introduce any difficulties for your bayesian update?
00:55:03.904 - 00:56:27.544, Speaker B: So there are two kind of stuff, if you want to introduce that, dark pools in this kind of stuff. Basically what we suggested was to say that it's one work we've done with Mathieu, Zenbom and Julia. It is true to say that the probability of execution on a dark pool is decreasing function of the imbalance on the other side of the lead pool, you know, but this is an assumption. Yeah, yeah, of course. Yeah. This was, this emerged basically from some toll with Charles Lehal, but in this precise case for Eden liquidity, as we stated in the paper, the work of the old work of Marco Avellane, I think, which is basically the fact that, you know, the imbalance you observe is not the real imbalance. But I agree with you that working, introducing properly, it doesn't, the liquidity would need an other paper itself, I think.
00:56:27.964 - 00:56:55.928, Speaker A: Yeah, I think on this, there was. There was a while ago, there was some interesting work of Sophie Laruel, Charles, Laurel and Gilles pages on the dark pool allocation problem. But it's very different from what we saw right now because that's the bandit problem. But I think the interesting case is the mixed one where you have dark pools and light pools. Then it becomes quite interesting. Other questions or comments?
00:56:56.056 - 00:56:57.208, Speaker E: Yeah, can I ask one?
00:56:57.296 - 00:56:58.968, Speaker A: Yeah, yeah.
00:56:59.096 - 00:57:32.384, Speaker E: This is Sascha from HSBC, and my question is about the penalty that you introduce. You want to follow a schedule, essentially, but the penalty is quite soft. So, essentially, you can. Can accumulate deviation from. From the schedule, essentially. Can you? I'm more linking towards the work that cartel was doing. Essentially, you could introduce states within your sor and feed this back into schedule optimization.
00:57:32.384 - 00:57:35.144, Speaker E: How could you comment on that?
00:57:37.844 - 00:57:46.814, Speaker B: This is a good question. I think I. To be honest, I'm not really aware of the. What. What they've done on that, so.
00:57:46.854 - 00:57:53.366, Speaker E: Yeah, no, no, I'm not saying they've done specifically, but you mentioned in the introduction, this is exactly what I'm talking.
00:57:53.550 - 00:58:32.910, Speaker B: Okay. No, the fact that here. Yeah, I kind of agree that we can accumulate errors one time. What maybe what you can do is that from one slice to an other, if you see that you have two, if you are two, if you are way too late about your trading schedule, you can increase or decrease the risk aversion parameters. But frankly, I've not really thought long enough to use a precise answer, to be honest.
00:58:32.982 - 00:58:51.314, Speaker E: Yeah, but. But essentially, if you incorporate various states of your sor, so to speak, like market states, during your Sor optimization, back into your scheduler. Scheduler could give you an answer. How. How would you adjust your trajectory depending on your state?
00:58:54.334 - 00:58:58.434, Speaker B: Yes, yes, I. Yeah, I think I see what you mean. Yeah.
00:58:59.394 - 00:59:13.970, Speaker A: Okay. Well, thank you very much to the participants and to Bastiain for this very interesting talk. You can continue exchanging with Bastian offline, and see you next month. Thank you very much.
00:59:14.122 - 00:59:16.354, Speaker B: Thank you very much. Bye. Thank you.

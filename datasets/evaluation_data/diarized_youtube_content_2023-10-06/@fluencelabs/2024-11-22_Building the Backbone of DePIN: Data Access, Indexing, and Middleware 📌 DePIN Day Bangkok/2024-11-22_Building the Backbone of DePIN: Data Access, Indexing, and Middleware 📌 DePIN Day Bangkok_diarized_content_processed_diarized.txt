00:00:11.040 - 00:00:20.525, Speaker A: I'm Joe Bender from Demo. I'm joined by some great speakers here and let's go around the horn and get introductions out of the way and learn a little bit about these projects.
00:00:21.065 - 00:00:42.849, Speaker B: Hey, I'm Clemens, I'm with Infura and din. DIN is the decentralized infrastructure network which is decentralizing Infura and Metamask and we have over 12 chains that we launched in the past year and also 50 plus providers that we distribute to and it has just announced yesterday that we're launching as an AVS and hello there.
00:00:42.897 - 00:01:00.655, Speaker C: My name is Wes Floyd, I'm a developer relations person from Eigenlayer and we are a platform for restaking and helping folks build services, particularly deep end services that are sort of off chain services that can be validated on chain. So thank you for having us.
00:01:01.635 - 00:01:18.515, Speaker D: Hello everyone, my name is Felix, I'm with the Partnerships team at the Graph where we power about 70 chains at the moment and most of my time is spent making sure that number goes up. Hopefully adding another zero by the end of next year with all the rollups coming in. We'll see.
00:01:18.635 - 00:01:56.585, Speaker E: Hey guys, so sorry about that. Was waiting in the other room and thought this panel hasn't started but glad I'm finally here now and thanks for everyone for showing up in the rain. My name is Rena and I work at Off Chain Labs. For those not familiar Off Chain Labs, we are the builders of Arbitrum, which includes Arbitrum 1, Arbitrum Nova and Arbitrum Orbit chains. We also bought Prism, a Ethereum consensus client, so we work on Prism as well. At Off Chain Labs I focus mainly on the defi growth side of things, but we are having a more strategic focus on Deepin as well. So nowadays I focus on Deepin and Defi growth.
00:01:56.585 - 00:02:14.265, Speaker E: What we mean by growth is more so helping projects in the earlier stages of chain exploration, helping them with chain strategies and also helping them get to market, understanding the Arbitrum ecosystem and generally just making sure that their time as builders in our ecosystem is efficient and smooth.
00:02:15.565 - 00:02:49.215, Speaker A: Awesome. Yeah, I've heard all four of these projects all around DEFCON all week. So excited to learn a little bit more. Let's dive in. We love when things go great in Web3, but what's even more important are some of the challenges. So what are the primary challenges each of your projects face in building a secure and resilient data layer for Deepin applications? And let's get even a bit more specific on the technical operational hurdles related to all of it? Maintaining Uptime, ensuring data integrity, handling scalability, the works.
00:02:50.185 - 00:03:28.747, Speaker B: Yeah, I can get started. So DIN works in the RPC space for now. This is kind of our starting point for the endpoints of Infura and also then MetaMask. And so the three things that we look at are the internode consistency, the economics and the quality of service. And so because we are trying to figure out and route to the best providers and also provide these access to networks, we have to make sure that they're giving the proper information and the technical data. And so there's a lot of verification that goes through as well as even testing to make sure that all of these nodes are up and running and can maintain their reputation. And so a lot of that's.
00:03:28.747 - 00:03:47.395, Speaker B: We were working in these working groups with a lot of inferior competitors to begin with and it was actually fun for the first year to work side by side with all of them to see how they solved their problems, to share the technology, everybody ran bare metal and to figure out how we can have a unified protocol so that we can all talk together.
00:03:49.015 - 00:03:55.359, Speaker A: Yeah, absolutely. The amount of devs that rely on Infura has to be stable and foundational. Rena, how about yourself?
00:03:55.527 - 00:04:45.119, Speaker E: Yeah, so I think on data integrity, a lot of the times that's more so on the DAPPS building in the ecosystem. But in terms of uptime and scalability, if you look at kind of the history of the different chains we have. Right. So Arbitrum one, which is probably what most people known Arbitrum for, like the Defi chain, it's a standard optimistic roll up chain. When we started working with more gaming teams that need a bit more scalability, better TPSs, we developed Arbitrum Nova, which is a antitrust chain. So difference being how data is posted back to Ethereum via a data availability committee. And so with that we have even matured more to Arbitrum Orbit, which is a permissionless way for projects to Deploy their own L2 L3 using the Arbitrum tech stack.
00:04:45.119 - 00:06:04.623, Speaker E: And it's with Orbit that we're really seeing scalability kind of being pushed to not the limits, but being really innovated on. And so some of the stuff we're really doing to try to address some of the challenges is working very closely with our Rollup as a service provider to really understand the projects building on Arbitrum, what their needs are in terms of making sure that we have hit the TPSs they need. So Conduit actually built a website called Rollup wtf kind of tracking all of app chains if you May, and different L2s and seeing how like the performance of it, the scalability, the uptimes and everything. And of the top five, maybe I think top three or four are all arbitrum nitro chains, whether they're orbit or you know, whether they're built up by conduit or not. And so I think what we really want to focus on is making sure that we keep building and improving Orbit to be truly scalable and to be truly, you know, efficient and reliable. Some things we're doing with that, not just for orbit but across the board is we, we released Stylus, which is a new programming environment where you can code in rust C or C to be EVM compatible. So that really brought another kind of era of optimization and gas in computation, power, memory improvement to be really cost efficient as well.
00:06:04.679 - 00:06:04.895, Speaker C: Right.
00:06:04.935 - 00:06:14.395, Speaker E: So to just further enhance our tech stack beyond just, you know, maybe some of the defi needs to being able to serve deep end builders and above.
00:06:15.475 - 00:06:46.503, Speaker C: Very cool. Yeah. So there's sort of two things that Eigenlayer is doing around the data space and challenges we have things we're working on. Eigenlayer broadly is a service for anybody to build any sort of off chain service that they want, but have it validated on chain. We pull together the capital and the operator network and you bring your service and you're good to go. We have also built our own service in house, partly as an example of what a service could look like. That service is called Eigenda or Data Availability, very similar to the technologies that Rena was just describing to service L2s.
00:06:46.503 - 00:08:01.305, Speaker C: So that technology exists, it's, you know, it's used by a number of leading rollups. But there are opportunities for improving that service even in itself. Like the way that the data availability service works today is that the Sequencer from the layer 2 rollup can write to the data availability layer and that data gets propagated across the network of operators. But you know, I mean I used to work at filecoin and other networks as well and there's always these challenges of how can you prove that those operators or service providers or whomever they are are actually delivering the data? I mean, I think you guys within are doing a great job of SLA provisioning, but how can you ensure that the data is being delivered? It's being to the users that request it. So the big innovation we're working on for next year was described in the Eigen token white paper. This term called inter subjective token forking, which is Sort of a mouthful, but we are very excited about it. I think it will have big benefits for data availability problems and saying, you know, is a given operator actually delivering data but also like more broadly for deep end projects, I think it can help us take things that are sort of difficult to measure, that are subjective and make finite financial opinions about them on chain to incentivize proper base behavior.
00:08:02.405 - 00:08:51.385, Speaker D: So there's a few elements that we are looking at at the graph on the one hand, making sure that our network becomes more resilient, becomes more performant, especially on the graph node level. So even if you don't want to be a client of the graph and you want to self host a graph node that we've got you covered, one of the main challenges we are trying to solve right now is actually providing more use cases and and open up the existing network of indexers, meaning compute and that we have to for example offer verified data that our users can carry now or also enable them to build AI agents on the graph network. It's what semiotic one of our co developers is looking into quite deeply at the moment.
00:08:53.805 - 00:09:23.725, Speaker B: Can I also just add that I was speaking to Felix a few days ago and one of the other important things is the community of really like the experts that have built the clients that run these different blockchains, they are very very hard to find. And when things go wrong, like for example we have people on staff in Infura that help the Geth team because they're so familiar with the implementations. So I think that that's also very important operationally to get the connections to all of these experts.
00:09:24.625 - 00:09:24.985, Speaker D: Cool.
00:09:25.025 - 00:09:49.575, Speaker A: Cool. I want to come back to you Felix for a second and ask how does the graph decentralized indexing system improve data accessibility for deepin applications? And what unique benefits does decentralized indexing bring to real world infrastructure projects? How do you see that impacting the UX for Dapps and just Web3 in general?
00:09:50.075 - 00:10:05.275, Speaker D: Do you guys remember a couple of years ago when Twitter started to heavily rate limit their API which effectively killed off a bunch of projects that were relying on Twitter data as their main source, for example for semantic analysis.
00:10:06.415 - 00:10:11.235, Speaker A: So one of our as a marketer it was horrible for analyzing engagement.
00:10:11.815 - 00:11:00.525, Speaker D: So one of our missions is to ensure that no one, not even us, can get between you and the data you need in production. So in that sense for us decentralization is not just a marketing meme, it's actually a means to an end because our indexers in the back are forced to compete each Other on quality of service, latency, et cetera, et cetera. So if you look in Graph Explorer you will typically see five to six different indexers on any subgraph and the one with the best quality of service will be allowed to actually send you the data that you requested thus is paid for it. And in case anyone ever were to go down, there is a bunch more to pick up the slack which makes the network itself quite resilient.
00:11:02.425 - 00:11:30.635, Speaker A: Cool, cool. Wes at Eigenlayer could you explain a bit how restaking and middleware add an additional layer of security to dpin? And in what ways does your guys specific approach enhance trustworthiness of the data and prevent vulnerabilities? Especially as Deepin which is kind of like a fairly nascent trend and sector of web3 begins to scale and grow and diversify in the projects?
00:11:31.055 - 00:12:20.665, Speaker C: Yeah, absolutely. The thing I love about the deep end space is that every deep end builder has a really unique idea to solve some meaningful problem in the Web3 space, whether it's weather or physical or compute or database. But those new project builders do face a challenge. And one of the challenges how do they secure their network? They may have their own ideas about a certain algorithm. Maybe it needs to be ZK proven or maybe it's a threshold encryption signature. And so when they think about the mechanism for validation, they also have to think about the economic security, particularly if it's a sort of a proof of stake style system. You know, it's like do you have $10 backing up the security of your network? How much does it cost to maliciously attack your network? Do you want a million dollars? Traditionally folks had to raise capital themselves through VCs or other mechanisms to kind of bootstrap security, crypto economic security.
00:12:20.665 - 00:12:47.665, Speaker C: And so our hope is to bring together the capital in one place that can help bootstrap that economic security. Bring together the operator network so that anyone that has a unique idea for DePin, maybe it's a real world thermometer and a certain use case to kind of like supply chain. I was talking to someone today, supply chain for, for coffee beans as an example. Whatever their unique ideas, they can focus on that unique idea and not have to rebuild the wheel of crypto economic security.
00:12:49.485 - 00:13:12.925, Speaker A: Cool. Coming back to Clemens here, Adam Fura, can you discuss the role of decentralized RPC nodes in supporting deep end networks and how they kind of compare to traditional RPC solutions and what are the key advantages of these decentralized RPC nodes in terms of reliability and how they can contribute to scaling DAPPS effectively.
00:13:13.625 - 00:13:44.051, Speaker B: Yeah, great question. So the RPC itself, the developers, the DevOps people are actually the same in decentralized and centralized. It's really more of the business model. They care about how to run things efficiently. And when we think about din, we think about democratizing the trust portion which is the big players like Infuria, Quick Node Alchemy, they have the marketing power in order to build their developer base. Right. But what we're looking to do is to keep the small players around so this doesn't all go into AWS in the future.
00:13:44.051 - 00:14:16.245, Speaker B: So we're trying to make sure that these smaller players are able to pay their bills and to find different ways to take their expertise and have different ways to take advantage of that yield. And so we're trying to do the good work of this B2B D pin space and allow people to get access to as many networks as possible without that being there kind of main distinguishing factor. And so that that type of business, the payments between them, the netting of those payments hopefully is useful to all of these bare node, you know, bare metal node providers.
00:14:16.705 - 00:14:43.355, Speaker A: I think it's most certainly useful. Rena, over at Arbitrum with your focus on scalability and cost efficiency as a L2 solution, how do you see L2Tech specifically enhancing the capabilities and adoption of deep end networks? And what unique challenges or conversely opportunities does this infrastructure present when applied to Deepin networks?
00:14:43.935 - 00:15:52.319, Speaker E: Yeah, I think right now when Deepin projects consider where to build, typically it's some type of evm, Ethereum, Solana Peak and a few others. And a lot of the projects I speak with when they decide to go the Ethereum route is because at the end of the day Ethereum is still where users activities and most importantly liquidity is. However, Ethereum L1 is just not scalable by design. And this is why you have Vitalik's rollup centric roadmap where Ethereum L1 relies on L2s to bring the scalability aspect to builders. And so amongst L2s is where I think we are most comparable with Stylus. Obviously that opens the door for more programming environments but as today in the same breath it's still amongst other L2s and with that Arbitrum has continuously been the most advanced in terms of tech innovation. We were the first one to reach stage one in the rope centric roadmap.
00:15:52.319 - 00:16:49.703, Speaker E: We had fraud proof since day one and we have been leading in liquidity users and everything. And so in this environment I think the challenges and opportunities are all kind of the Same right. Challenges is how do we at least from the partnerships end is how do we all just as simple as bring awareness for builders that, you know, Arbitrum tech we have all of these capabilities, right? We have stylus, we are implementing things like Bold which is decentralized validation. We are working on decentralized sequencers. How do we work with builders to figure out what challenges that they have and how do we kind of work with them on the tech? Because at off chain and Arbitrum we have this belief that it's your chains, your rules, right? Our tech shouldn't be constrained on and builders shouldn't be constrained when they're using our tech. They should be able to innovate and customize. And so a lot of that is just working very closely and understanding builder needs.
00:16:49.703 - 00:17:59.895, Speaker E: And I think the opportunities here is both on the supply and demand side, maybe even more so on supply side where you kind of look at users, what motivates them creating that kind of just network effects in terms of perhaps, perhaps like you know, project tokens, like how do we bring value to that? And I think, you know, I just hope that, you know, we could really bring kind of a different ecosystem for deepen builders where you have tech that really is advanced, it's innovative and then you also have an ecosystem that brings additional value occurred. There's a lot of deep end projects that's kind of already tapping into this idea. So we have Aether who did their node sales on Arbitrum. We have Weatherxm who's actually building on Arbitrum 1 and one of the reasons they're doing so is to kind of tap into that defi side of things. We also have a supply chain network Deepen project that's building very data heavy, very math heavy deep end network using Arbitrum Orbit. So I think we're going to start to see a lot more of these innovations using Arbitrum Tech Stack. So yeah, it's pretty exciting.
00:18:01.115 - 00:18:26.345, Speaker A: Nice. I got a question to go around the horn here on looking forward. What advancements or collaborations among foundational infrastructure providers do you believe will most significantly shape depends future? Are there any emerging technologies or partnerships that you think will drive Depin infrastructure to new levels of resilience, efficiency or security? Clemens, this is over you.
00:18:26.505 - 00:19:11.735, Speaker B: Yeah, I mean for us I think this is less about din. I really believe a lot of these outcomes will be around zero knowledge. And I'm just kind of a nerd about it because data availability and kind of the ability to privately save that data is kind of what we've all been kind of after. The decentralization portion of the storage and the immutability of that data is important, but I'm really interested in trusted execution environments in order to increase the efficiency rather than having, you know, thousands of L2 chains and trying to figure out the. Yeah. Where the money goes to across all those chains and the additional fragmentation. So I like the abstraction that's happening and I like the ability to reuse the economic security that already exists.
00:19:13.355 - 00:19:14.563, Speaker A: Reena, how about you?
00:19:14.699 - 00:19:58.623, Speaker E: Yeah, I agree on the ZK side for sure. I know we are obviously an optimistic roll up, but our research team led by Ed Felton has been actually looking into kind of use like ZK and research in that so further out. But I think some of the ideas that our research team has been discussing publicly is this concept of hybrid ZK optimistic proving system. Because as it stands right now, ZK is still quite expensive. However, perhaps there's a way to implement this into the optimistic roll up process in terms of bisection process where down to a last challenge step, that's when ZK kicks in. It's probably more cost efficient. But in terms.
00:19:58.623 - 00:20:47.485, Speaker E: Back to your question on Infra partners and collaborations. I think for us specifically thinking about Orbit, we have to really rely a lot on our DA partners, rely a lot on our RAS partners to really help us push innovation, help us work with the different, you know, deepen networks to really see like what we could build together. Some of the stuff that we're actually looking into that we announced I believe today is that we're actually looking at adding nethermind as additional components on top of Geth. So you know, we're really trying to think of more ways to just optimize the tech stack for scalability. And I think a lot of that will have to come with like partnerships with Infra and others. You know, we can't do everything on our own.
00:20:48.485 - 00:21:18.415, Speaker C: Very good. Yeah. You know, one thing I think that could help move the space forward. I come from more of an Enterprise Web2 background and used to work with one of the hyperscalers. And so our customers always had this nice clean panel they could go to and in this nice service console they could say, okay, I need to spin up some compute, I need to spin up some storage, I need a database. And it was very easy and it was all kind of consolidated. Whereas in our world we had this explosion of all these deep end projects that are really fun and organic, but it is also a bit all over the place too.
00:21:18.415 - 00:21:57.005, Speaker C: And so to the extent that people can build overlays or systems that make it easy for people to have a consistent, more unified experience across the DPM projects, I think that would be neat. At Eigenlayer we have this vision of creating SaaS like apps as these services so they can be plug and play, zk, Prover Networks or Bridges and Oracles. I think what DIN is doing is really good as well is creating like SLA layers to kind of have visibility across projects is a great step in that direction. So if anybody has like motivations in building, you know there's not like a great solution yet like an AWS console for dpin. But I would love to see someone build that.
00:21:58.225 - 00:22:31.309, Speaker D: I really love that ZK is mentioned first. I used to work in data privacy before, so this always resonates quite well. But circling back to the graph, there's a few elements here. On the subgraph level itself, it's about making the developer experience easier. For example, making sub graphs more composable so you don't have to build the whole thing from scratch. You just use something pre existing, tailor it to your needs and just be off to the races. That's one element here.
00:22:31.309 - 00:22:48.355, Speaker D: And then also going back to what I mentioned first, where yeah, just looking at new use cases, basically talking to people here on the ground if you want us to, if you want to see us build anything in particular, reach out. We're very open.
00:22:49.095 - 00:23:37.439, Speaker B: And yeah, I forgot to talk about DIN because for the DIN side, the important part is that our major customers are the foundations and the new chains that are coming out from testnet to mainnet that want to connect to the developers via the gateways. Right. So everybody has their own developer base and so we want to connect with them as much as possible. So you can build the right use cases and expand on that and I think what likely will happen. This is my theory of interoperability is around. When you look at Amazon and you're delivering services, you care about the intention of getting the thing that you purchased and where it's going through. You know, it's either cheaper or faster or more expensive, doesn't really make a difference.
00:23:37.439 - 00:23:50.555, Speaker B: Where it's stored isn't really as important as getting it delivered to your door that last mile. So hopefully the intention of what is being built is different from the infrastructure that powers how it gets done.
00:23:52.175 - 00:24:40.915, Speaker A: Cool. Okay, pop quiz. Fluence has been killing it this year. There's been a handful of deep end days this year, but we haven't had a DevCon in two years since Bogota the word depin did not exist at the last DevCon. These events always kind of reinvigorate me in Web3, seeing all the exciting stuff going on around the industry. What is one of the most intriguing or exciting things you have seen this week that is just promising for the future makes you optimistic about the potential of this tech or one of the best talks you saw or an observation on Deepin? For the last couple days there were numerous Deepin side events, a lot of projects represented in Bangkok this week. Someone jump in when you feel inspired.
00:24:45.615 - 00:25:08.855, Speaker B: We've been working with Alt layer and I'm excited for their autonomy, their AI agent that's able to help with some of the distributions and. And there's a sneak peek launch and I'm really excited to kind of dig into it to see how they're using LLMs and generative AI to support infrastructure as well. Like how does it help the rest of the space? How is it deployed?
00:25:09.595 - 00:25:09.907, Speaker A: Cool.
00:25:09.931 - 00:25:10.107, Speaker C: Yeah.
00:25:10.131 - 00:25:18.535, Speaker A: Clemens has talked a lot about Infuria on the panel today, but he moonlights as an AI warlock. Really doing a lot of experimenting and tinkering there.
00:25:20.915 - 00:26:26.345, Speaker E: I think. So this is my first devcon, so I don't really have a comparison, but before I came to devcon I had done like I thought devcon was very much Ethereum builder focused, you know. And so it's actually been quite surprising to see, you know, institutions, funds, VCs and other outside of just purely Ethereum kind of events, talks, projects, happenings. And I think with on the deep inside of all of this, it's feeling like when we talk about just overall crypto innovations, advancements in the space, that Deepin is now talked in the same conversation. I think before Deepin felt like a side event at a side event and now it feels like Deepin is part of the main character, main cast, which is great. I think that's when you really can get innovations and tech advancements together. When you have everyone discussing versus just kind of this niche group of people bouncing ideas off each other.
00:26:27.325 - 00:26:47.597, Speaker A: Yeah, definitely. And has made us as an industry kind of reflect on what. What is. DEPIN is Bitcoin DEFIN. It runs on physical hardware and projects that have been around for years before the depin term came alive. Like filecoin, like helium. We're still figuring out as a sector what exactly deepin is.
00:26:47.701 - 00:26:48.413, Speaker B: BitTorrent.
00:26:48.469 - 00:26:56.065, Speaker A: That was, that was deep it torrent. Don't. Don't tell my ISP about that. I might still download a new movie or two.
00:26:56.665 - 00:27:52.835, Speaker D: Yeah, they're going to Send you the bill from the music you downloaded 10 years ago. What I find is also my first DEFCON, by the way. And just in general, the reignited vigor that everybody's displaying, not only because number go up on coin market cap, but also because especially in the deep end space, stuff becomes a lot more clear as to what Deepin actually can be in the future. At our event on Sunday, I talked to a really cool guy who are basically running a Deepin mobile carrier network in the Middle East. They're huge, never heard of them before and they are doing quite well. And so those are the things that make working in web3 just so valid in the long run.
00:27:54.655 - 00:28:48.535, Speaker C: I would say. Actually just honestly seeing this group of folks grow because back two years ago in Bogota, people were very much more focused on core Ethereum tech. And there's still a large group of people and there's a lot of opportunity to innovate in core Ethereum tech. But as that tech, like any good decentralized technology, as it becomes more stable, you know, what's the next layer to build on? And I think like this conference is a really good example that like, you know, in the past there was aspirations of how could you build these more complicated systems. We've also had this collision of these new provable technologies, the zero knowledge provable stuff, which is so hard to predict when it's going to land, but it just happened to land and we can do a lot more off chain now and prove it on chain. So I think it's just, it's really impressive to see how the space has became so much more realized. And I'm now, I would say, realistically optimistic as opposed to just optimistic two years ago.
00:28:49.795 - 00:29:17.863, Speaker A: Yeah, absolutely. We spend all day, every day, nine to five, sending emails and looking at slack, but coming here and zooming out a bit and seeing all the big problems we're tackling with creative solutions. I'm excited to get back to New York, start working again, start pushing Deepin forward and I'd like to thank all four of our panelists for being here today and sharing some. Go follow them on Twitter, go learn about their projects and hope you guys have a great rest of your deep end day.
00:29:18.039 - 00:29:18.447, Speaker C: Great.
00:29:18.511 - 00:29:19.135, Speaker B: Thank you so much.

00:00:04.480 - 00:00:37.152, Speaker A: Hi everyone, I'm Igor and I'm gonna talk l two s today. We spoke a lot about different ways of decentralizing. It was all about the nodes. And I wanna go a little bit technical and philosophical here. And yeah, basically talk about ZK rollups. And first a little bit about me. In my pre blockchain life I used to run mobile browsers and then fintech at the browser company called Opera.
00:00:37.152 - 00:01:19.578, Speaker A: Then for a while I've been a core dev in Ethereum. I was doing the Eragon clients. And yeah, now I'm the CTO and co founder of Gateway. And since we are not as famous yet as infura, for instance, have a couple of words about us. So we do quite a lot of things. We have RPC, we are kind of the, we support about ten networks, but we are kind of the provider for gnosis, Luxo and stellar, where we actually work with the foundations to provide the necessary public infrastructure and public goods. We also do quite a lot of staking, again partnering with the likes of Stakewise, Lido and just vanilla.
00:01:19.578 - 00:02:03.104, Speaker A: Presto is basically right now it's essentially a roll up as a service that we're evolving towards to be like a platform as a service. And we do some core engineering efforts as well. Again for gnosis. I mean there will be soon like Ens version for Gnosis, which we will provide infrastructure for. And we work on nodes for polygon ZkVM. And I mean, we just made Ergon work with Polygon ZkVM, which brings the node diversity, I think the first node diversity for ZK rollups, essentially. I don't think there's any other ZK roll up that has more than one node implementation, which is again, hope good news for everybody who runs infrastructure here.
00:02:03.104 - 00:03:06.472, Speaker A: And based on that, I want to talk a little bit about again, ZK Rollups. And I have this thesis here that we're talking lots about decentralization, but actually when you have ZK proofs and you run in DK rollups, you kind of have quite a bit less pressure of decentralizing your roll up than if you run a layer one or an optimistic roll up or something like that. And I'll try to defend this thesis here a little bit. And yeah, it all started basically with again, presto. At some point, like in the beginning of the year, we started getting more and more requests to provision layers too. And we started with optimistic stack, and then we slowly switched to as soon as it was ready, first just a fork of polygon ZKVM and then right now there is a Polygon CDK. So we had to switch to that.
00:03:06.472 - 00:03:59.484, Speaker A: And basically we made a very nice provisioning UI when you can do a lot like provision your own roll up very easily and there's a lot of customizations if you want to. And that's kind of a good part. But all these roll ups are centralized, right? Which is sort of a problem here. And even like basically what we provision is, is that. And I would say that maybe I will try to defend that it's not as big of a problem as people might think with all this app chance and centralization of sequencers and yada yada yada. So basically if we look at the roll up that we provision, it has its own sequencer that we run aggregator that we run provers nodes. It has a bridge built in, which is a really nice property of a roll up.
00:03:59.484 - 00:04:39.456, Speaker A: And then it has states, it has synchronizer, some our components in purple and then some third party components. So this is like the whole environment that you get with presto. But if you look at let's say Polygon ZKVM main, that's how it looks like. It looks like that roughly. So it's exactly the same setup apart. In this case Polygon runs the sequencer, Polygon runs the provers Polygon and some other parties can run the nodes, which is again the case for us as well. And there's certain load balancing happening and there are some extra tooling there as well.
00:04:39.456 - 00:05:22.504, Speaker A: So it's very very similar. So what I will say here is equally applies to both public instances of a roll up. Again, I know the most about Polygon ZKVM, so I'll go in details on that. But I'm pretty sure that other ZK vms and other ZK rops work in a roughly similar way. So a lot of this knowledge actually can be transferred towards other roll ups as well. I will not touch optimistic rollups in depth here because I'm not an expert. And again, and what I see that more and more of them playing with any kind of ZK proofs anyway, so we'll all get to some kind of a ZK roll ups I think in the future.
00:05:22.504 - 00:06:07.616, Speaker A: So if we look at a roll up in general from a very very high level, we essentially have a root chain in purple here, which is usually ethereum, and the roll up itself is in green. And it consists of two things. It's essentially some software and some blockchain. You run some, I don't know, processes essentially. And it has a set of smart contracts that are deployed to l one. Together they made a roll up, and these components, they are linked together with some kind of validity, proof and data availability. All the computation and everything is basically happening in o two, which is its own blockchain.
00:06:07.616 - 00:06:49.748, Speaker A: And again, it's usually pretty centralized. And the goal there is usually to execute those transactions as quickly as possible. And then after that, through the communication on l one, somehow settle them on the layer one. That's how the roll up looks like. And we'll start a little bit. When talking about decentralization in particular, I would say that one of the important parts of decentralization lies like in the proofs for the key rops. And we will look at first on the regular blockchains, right, what's happening on the regular blockchains.
00:06:49.748 - 00:07:22.660, Speaker A: One important property of the regular blockchains that happens is that they kind of provide a level playing fields for everybody. They have certain set of rules on the blockchain. And these rules are the same for everybody who uses this blockchain. Regardless of how much power you have, like or whatever, it's basically you can think about. There is a rule that your private key should be valid. There is a rule that you should have money for gas. There is a rule that you cannot spend more than a certain amount.
00:07:22.660 - 00:07:54.204, Speaker A: And each opcode in EVM is also basically a rule. And these rules are the same for everybody. And how is it enforced? Basically we have a lot of notes, everybody gets transaction, everybody re executes and needs to come to consensus, right. They need to come to the same result after re executing transactions. And that's how they are enforced. Because basically if your node for some reason altered some rules, then other nodes will just not get this transaction and will reject it as invalid. And things are nice.
00:07:54.204 - 00:08:38.420, Speaker A: But consensus in here is a very critical part, because essentially what you want is to consensus to be as decentralized as possible. Because you have only one party that controls every node. Then what you can do is you can alter these rules like however you want. I mean, you can sensor transactions, you can include transactions that shouldn't work otherwise, and yada, yada, yada. So it's very, very important to have it purely decentralized. And what it means in reality that your users, you are like crypto degens or just normal users, they usually work with the blockchain through like two channels. One channel is obvious is block producers.
00:08:38.420 - 00:09:32.222, Speaker A: This could be validators like miners before that. And another part is rpcs. And for consensus to really work well to be protected. Actually, both of these parts needs to be quite a bit of decentralized, because if one party can capture either one of them, I argue that's both are equally bad for the security and the kind of agency of the users. For block producers, it's pretty obvious. If I control all the block producers, I can arbitrarily insert any transaction, any state transition in the blockchain, but the same as rpcs. Let's say our block producers are all nice and decentralized, but then RPC is super captured, then nothing stops you from basically not allowing some valid blocks to sync into your RPC.
00:09:32.222 - 00:10:34.028, Speaker A: And since users anyway usually talk to the rpCs, and if it's the only one RPC provider, then they are at its basically mercy. So this RPC again can fork the node, just alter the rules and they will be in the right here. So it's very very important to protect the consensus. So it's distributed among as many parties as possible. In terms of the L2, the schema is really similar. So L2 also brings kind of a level playing fields for everybody. But then these rules, instead of being enforced and re executed by each node there, essentially you as an operator of the l two, you will have to provide a cryptographic proof for each of this rule that it wasn't broken for each state transition or each set of state transitions.
00:10:34.028 - 00:11:22.634, Speaker A: And again, we use ZK proofs right now because that's the technology we have. But then the ZK proof, when it's generated, it also gets verified, but it gets verified on the layer one. And that's a little bit of a key thing. So basically the verifier contract on the layer one, it has knowledge of all these basically rules that every transactions have to. Yeah, it has, every transaction has to satisfy all these rules. And basically this verifier on l one is the critical path. So in this case, since verifier is on layer one, basically you get security of the layer one and the properties of the layer ones are getting inherited there, plus the governance of this smart contract.
00:11:22.634 - 00:12:44.644, Speaker A: That's why if you look at the current, a lot of ZK roll ups, they have an extra governance on the verifier smart contract, which you cannot arbitrarily update without at least a time lock or something, because then what's important also that you talk to the l two through a bridge. And this bridge, it actually uses data from the verifier smart contract on the layer one to decide on its own operations to see if the state transition was valid or not, and to basically unlock or not unlock funds. And the bridge, it's also doing it on layer one. So that means that again, if I'm a malicious operator of a L2, and if I'll try to alter those rules so my proof will like, unless I do something with the layer one smart contracts, I cannot alter the set of rules because the bridge will not accept them. And then the users will always be able to, I mean either force include their transactions or force exit the roll up, which is a very important thing. So all of these things is basically bringing extra security and extra agency for the customers. But it's not done through decentralization like on the layer one.
00:12:44.644 - 00:13:43.500, Speaker A: It's done through actual mathematics of ZK proofs, and that the verification happens on the layer one. That of course gives like quite a bit of requirements about how good your layer one should be in this case, but about it a little bit later. And now we talk about, since we talked about altering the rules, what about just completely, I don't know, removing the data, like basically a kind of a denial of service attacks there for users. And that's where data availability component is very important, because if you want to call yourself a roll up, you need to send both proof and data availability to the layer one. And essentially, if we again make a comparison between the layer ones like Ethereum and layers twos, initially data availability is basically protected again by decentralization. The more nodes, the more companies have. Every node has state of everything, state of the world.
00:13:43.500 - 00:14:41.488, Speaker A: So that means that you cannot again alter the state or just remove parts of the state, unless you have a supermajority of the nodes to come to consensus on the state. It's a little bit, becomes a little bit more muddy with like 444-4844 like full gun sharding and all these things on the roadmap when data becomes semi permanent. And that's why there are some interesting techniques like data availability sampling, to know that enough node contains enough data about the state to actually not to be attacked on the data availability layer. On the l two s, it's again, l two s rely a lot on l one in this as well. So basically when you send your transaction to an l two, at first it only lives on the l two for a while. It's usually a relatively short period, maybe like minutes or something. So it gets sent and it gets sequenced and it's batched.
00:14:41.488 - 00:15:38.234, Speaker A: In terms of the KVM, some don't batch, it doesn't really matter. And then the important part happens that it's getting sent to an l one. And since it's getting sent to l one, then regardless of what happens to this l two in general, you can always recover the state directly from l one, the state of the roll up. So it doesn't really matter if your roll up leaves or not, you can always recover the state yourself. And then of course, like in a while, there is a proof that's also sent there, and then it's guaranteed not about only the leaveness of this data, but also about the security. And a special word about validiums here, or to some extent, what Vitalik told was it yesterday about endgame for plasma or something. So basically, if we look at validiums, validium is different from the roll up, is that it lacks this da, it doesn't send da to l one.
00:15:38.234 - 00:16:12.454, Speaker A: Why is it done? It's mostly because it's cheaper, like data availability cost. Why optimism burns so much ease all the time, or arbitram burns so much ETH, like polygon, Zkm, Zk is mostly about data availability costs. They are pretty high. And that's why some people are basically running validiums. And again, in validium like this on the picture, when you just don't send anything to layer one, it's very naive. Validium then, yeah, your data is not guaranteed by anything. The operator of this validium basically is the only custodian of this data.
00:16:12.454 - 00:17:24.996, Speaker A: So if it decides to remove it, then your data is gone. Of course, there is an in between solution, which is like validium plus data availability committee or data availability layer, likes of like Celestia that was recently launched, or like Nir also told that they're gonna participate in that, or maybe some other chains with a cheaper block space than ethereum. And then it means that you still send proofs of things to l one, and then you send the data availability to a cheaper chain, essentially. And then it's a big question. Then you kind of rely on two chains, I don't want to even call them two parties, and both of these parties needs to be kind of good for you to have leaveness and validity guarantees there. So basically, yeah, I think what's important here is that these properties of security, these properties of agency, these properties of liveness, they don't really appear out of thin air. Just because you use the fancy cryptography doesn't mean that you have to just ignore them, right? And it will be fine.
00:17:24.996 - 00:18:47.174, Speaker A: In this case, this fancy cryptography, what it allows is to borrow this security and borrow this agency from the like a root chain from the layer below. And that means that if your layer one is good, if it has like a massive validator set, it's well decentralized, then you have something to borrow. But if you have the best cryptography in the world, but your base layer is controlled by a single entity, or your root chain is controlled by a single entity, then like there's nothing you do, you have nothing to borrow there. And that means that you are still be kind of in a bad space. So I think that in general, if we're talking about decentralization, my point of view is that decentralization is a kind of a, it's a mean to, to give users, security and agency to keep your network neutral. And in case you can get a lot of this without kind of a proper decentralization for the layers. Two, if your layer one is really, really good, and if you're using kind of a good cryptography, and that's roughly what I wanted to talk about.
00:18:47.174 - 00:19:11.454, Speaker A: Again, it's a little bit of a deep dive on my thoughts on in general, ZK rollups and ZK rollups used as app chains. And I think that's it. So about basically any updates from Gateway, we have a Twitter, and again, if you want to try presto, then here is the URL for you. And yeah, that's about it. So if you have any questions.

00:00:04.240 - 00:00:14.314, Speaker A: Hi everyone, this is Alex from near protocol. And with me today is Alex from Fluence Labs. And we'll talk today about decentralized databases. Alex, would you like to introduce yourself?
00:00:14.734 - 00:00:24.166, Speaker B: Hi, I'm Alex and I work at fluence as a researcher. And today I guess I will talk about how to build structured data storage in a decentralized fashion.
00:00:24.350 - 00:00:26.078, Speaker A: Cool. Would you like to give an overview?
00:00:26.206 - 00:01:21.874, Speaker B: Yeah, sure. So what we looked about, we looked at, there are unstructured data storages in decentralized ecosystem, but there is no many structured data storages. And so we thought that probably we should build something that will allow people to make queries to the data and basically be sure that the results that are returned are correct. And to give you a very brief overview how fluency structure it, we have few different, like I would say heterogeneous components here. So the first one is the thing that we call real time layer. And the real time layer consists of multiple small, let's put it this way, BFT clusters. I can make one bigger.
00:01:21.874 - 00:01:59.814, Speaker B: Yeah, I think that's a BFT. One node is also a BFT. So really small ones, really small clusters, the BFT ones. And because they are really small, there is a chance that some of these machines can go wild. So in order to keep those guys in check, we use a shared validation layer. And the validation layer is shared. We usually use this symbol to depict a validator because it looks like v.
00:01:59.814 - 00:02:14.193, Speaker B: And this is basically shared validators pool. And we call this thing a security layer.
00:02:14.893 - 00:02:17.033, Speaker A: And is it the same participants in both layers?
00:02:17.573 - 00:03:31.882, Speaker B: Well, I mean they might be, I mean you can have, I mean you can have, this is different software in some kind of. But you can have this like one single hardware machine to run both real time node and a validator. So the way it works, I mean how do those guys keep each other in check? Is that real time layer basically uploads every time when there is also a client, and here is a client, and I will draw a mobile phone in the sense that we want those clients to be thin. I won't say white clients, but at least thin clients. And so the light client or the thin client interacts with the real time layer only. And every time, like the way how interaction goes, the client sends a request, which is like transaction essentially, and receives a response from the real time layer. And for the validators, for the security layer, to verify the real time layer, the real time layer stores transactions into a decentralized storage.
00:03:31.882 - 00:04:35.384, Speaker B: And for this purpose we use like Swarm, we could also use Filecoin I mean, honestly, right now we expect that in theory, those storages will support like basically in like if say for example, if you take a look at this form, paper swarm, paper talks about how it can force nodes to return you the data you have put there. Basically it's how to guarantee that it will return the data there. And if it will not return you the data, then these nodes will lose their deposits. But if you look at what swarm does currently have in deployed, they do not have this incentivization layer. So we expect that eventually, once they have this feature, the data store there will be secure. But for now, we basically built on theoretical guarantees that it will be one day. And we call this in the data availability layer.
00:04:35.384 - 00:05:00.914, Speaker B: Okay, so the, not only, so first of all, the transactions are stored here. And I would say like transactions here are stored in blocks. So the data availability layer has basically keeps these real time layer blockchains.
00:05:05.814 - 00:05:10.810, Speaker A: Also we store, in this case the block is just a set of transactions.
00:05:10.902 - 00:05:11.274, Speaker B: Right.
00:05:11.354 - 00:05:12.454, Speaker A: Or queries, rather.
00:05:13.274 - 00:05:14.090, Speaker B: Same thing.
00:05:14.202 - 00:05:14.602, Speaker A: I see.
00:05:14.658 - 00:05:55.366, Speaker B: Yeah, I'll put transactions here, not sure if it's visible or not. So that's, I would say the transaction history and. Oh, is it? Wait, okay, sure. Okay, so we'll call this transaction history, and also these data availability layer stores states. So basically state is a snapshot of the real time layer at some point. So the way how stuff works, how.
00:05:55.390 - 00:05:56.990, Speaker A: Frequently do you produce those snapshots?
00:05:57.062 - 00:06:02.474, Speaker B: Right, so I'll get to this. So the way how stuff works.
00:06:04.954 - 00:06:05.242, Speaker A: The.
00:06:05.258 - 00:06:28.678, Speaker B: Batch validator comes and it reads the previous state snapshot, like say snapshot, state m, and it reads a fragment of transaction history and then it produces the new snapshot. And this new snapshot goes here back into the storage.
00:06:28.866 - 00:06:33.982, Speaker A: And these snapshots, the BFT clusters, never produce snapshots. It's only validators. I see.
00:06:34.038 - 00:06:48.942, Speaker B: Right, yeah, because you don't want those guys to produce snapshots. I mean, even if you take security aspect away, producing a snapshot, uploading it here, it's a very different property from the real.
00:06:49.038 - 00:06:50.142, Speaker A: So you're saying it's more expensive?
00:06:50.238 - 00:07:43.944, Speaker B: Yeah, well, I mean it basically will make the load on those classes irregular, I would say. It's like, yeah, so those classes are used to, for example, a steady transaction like incoming rate. But once they have to upload the snapshot somewhere, that's kind of like might decrease the ability to process transactions. So no, those guys do not process snapshots. So only validators produce snapshots. So yeah, they basically read those transactions, this history, and snapshots and produce the new snapshot. If during the block processing, they do not agree with the, basically with the results they get, they can file a dispute.
00:07:43.944 - 00:08:45.942, Speaker B: But first of all, let me get to how do they not agree? So in the end of each block, we, like currently here in the real time layer, we use tendermint as the BFT consensus engine, essentially. So in tendermint, after like in the end of each block, you not only put transactions there, you also put the hash of your state. And that's also stored here in this form. We have, like for example, after each block we have here hash virtual machines, n hash of virtual machine sub n plus one, hvm sub n plus two, and so on. So validators go over those blocks. And if basically when they are trying to apply a new block to the current state, if they produce a different hash, then they are like, ok, I mean, that doesn't work out. So let's basically point the gun at those guys.
00:08:46.038 - 00:09:02.034, Speaker A: So when you're saying hash of virtual machine, so effectively you literally, the state is not any sort of an abstraction. You're literally snapshotting the state of the memory dump. No, I mean of the virtual machine that processes queries.
00:09:02.614 - 00:09:05.622, Speaker B: No, no, no. I mean, when I'm saying hash, it means like the miracle, right?
00:09:05.638 - 00:09:09.202, Speaker A: But what is virtual machine? Okay, good question.
00:09:09.258 - 00:09:29.106, Speaker B: I forgot about that. So we use webassembly and. Yeah, like every node has the same like virtual machine instance. And these like, like, basically it's the memory of the virtual machine. And here we take the hash of this memory. Yeah, of the memory.
00:09:29.170 - 00:09:32.594, Speaker A: And that hash, it's not mercalized in any way, right? It's just the hash. It's Merkel.
00:09:32.634 - 00:10:42.258, Speaker B: Yeah, it's, and anyways, so we've got like those guys read transactions and those guys read snapshots. And if they, like, for example, one of those validators got, instead of hash sub n, it got hash sub n prime. It clearly like doesn't match. And they submit a dispute and they submit a dispute to Ethereum. Okay, so once the dispute is submitted to ethereum, well, those guys have to, well, I mean, ethereum is obviously not able to download the entire state and is not able to download even the block, I would say, of transactions to basically replay that. What those guys are doing, they are playing a concept called verification game. And that was basically proposed by Truebit.
00:10:42.258 - 00:11:26.304, Speaker B: And the way it works, you execute your program instruction by instruction. And if at some instruction you found that basically your states, you have achieved different state than your counterparty, then you say, well, this instruction is the bad one, and you don't have to do this in a linear fashion. You can do like a bisect search. So once those guys have found a bad instruction, they take the chunk of the state that was used by this instruction as an input. Like say, for example. I mean, let me explain for you. Example, if you have instruction I 32 add, this instruction obviously uses this stack.
00:11:26.304 - 00:11:54.276, Speaker B: It basically takes two values from the top of the stack here, and it then pushes one value back to the top of the stack, and it consumes those. So it's like pop two, and this is like push one. So in order for the, like, for the virtual machine on Ethereum to operate, you have to give it like this chunk of memory, and you also have to give it the chunk of memory where this stuff will be written.
00:11:54.420 - 00:11:58.384, Speaker A: Do you effectively need to have the entire wasm virtual machine written in solidity?
00:11:58.804 - 00:12:04.852, Speaker B: Kind of like a very small implementation of that actually true bit, guys, almost already.
00:12:04.948 - 00:12:13.184, Speaker A: Nice. But then you also need a hash function which will be capable of doing. Hashes were only part of the state changes, right?
00:12:13.344 - 00:12:14.312, Speaker B: Well, it's still. How.
00:12:14.328 - 00:12:15.016, Speaker A: It's mercury.
00:12:15.120 - 00:12:34.248, Speaker B: It's mercalized. Yeah. So you compute only the hash of the chunk, and then you compute the entire hash. The problem is that it still might be too much for Ethereum. Smart contract. And so we are looking at how optimize that, because, like the chunk, it might be 4. Transferring 4.
00:12:34.248 - 00:13:07.756, Speaker B: Ethereum might not be also, like, the brightest idea. Anyways. So once those guys have pushed this into the virtual machine on Ethereum, it basically executes the instruction, produces the new hash, and basically the machine that has a different hash has produced a different hash. Well, it loses its stake, essentially. I probably should talk a little bit about timeouts, because that might be, I would say, important for security. Or if you have to go over.
00:13:07.780 - 00:13:12.500, Speaker A: That, you're saying that. So snapshot is created once every few blocks, right?
00:13:12.612 - 00:13:14.396, Speaker B: Like 10,000 blocks, maybe?
00:13:14.460 - 00:13:22.812, Speaker A: Yeah, let's say four for simplicity. Okay, so we have snapshot here, right? And then we have snapshot here.
00:13:22.948 - 00:13:23.388, Speaker B: Sure.
00:13:23.476 - 00:13:28.380, Speaker A: So in the model you described so far, there was a single validator who who did it, right?
00:13:28.492 - 00:13:30.564, Speaker B: Yes, yes. There are multiple of them.
00:13:30.724 - 00:13:41.404, Speaker A: But if there are multiple, which of them, which state do you use as a canonical? So you're saying multiple validators will be assigned to this particular, what is it called? Fragment.
00:13:41.524 - 00:13:43.024, Speaker B: Yeah, history of fragment.
00:13:45.924 - 00:13:49.572, Speaker A: So each of them will produce the next state. Which one will be used as a canonical state?
00:13:49.708 - 00:14:19.248, Speaker B: Well, if all of those validators agree if all of them receive the same hash, then only the first one who has uploaded this state, like is, I mean has to upload this state. If any of those validators disagree, they also have to play the same verification game between each other. So you don't actually like either they all agree or if there is some disagreement then someone will lose money of all this information.
00:14:19.336 - 00:14:25.704, Speaker A: What is actually snapshot to Ethereum? Do I snapshot every block? Yeah, I see. And every snapshot as well?
00:14:26.564 - 00:14:28.436, Speaker B: No, I mean, well yes.
00:14:28.540 - 00:14:30.584, Speaker A: Wait, like a hash of every snapshot?
00:14:31.404 - 00:15:02.736, Speaker B: No. Ok, there is one more thing. Yeah, because you don't want to upload the hash of each block to Ethereum. That also will be too expensive. So you have a separate layer, which we probably should talk about. I mean once we got to the validators model. Let me describe that, I guess so you have mentioned the like if you mentioned multiple validators.
00:15:02.736 - 00:15:44.194, Speaker B: So let me try to explain how that thing works. So first of all, validators are selected completely by random from the validators pool. And the way it works, basically all of the active validators, they have to register on the Ethereum smart contract. And then you have a random random number generator that you can use to choose one of those validators. And a validator, once it's selected, it must execute the history fragment. Otherwise, if it does not do that within a certain timeout, which I probably should talk about. So I will put a reminder for myself here.
00:15:44.194 - 00:16:35.254, Speaker B: Timeouts. In this case it will lose a small fraction of its deposit. It will not lose the entire deposit because it's a minor offense, but it will lose a fraction of that. So the way it works, once you have selected one validator, and this validator is verifying this BFT cluster rate. Now you, after this validator, you also select another validator, and you also select this validator by random from the entire pool. And what else happens? Like once when this validator is selected, it does not know if there will be another validation or not. So the way it works, we are saying that the next validation will happen with the probability p.
00:16:35.254 - 00:17:24.064, Speaker B: So this means that because in this case it will be geometric distribution. In this case the expected value of the number of validations will be p divided by one minus p. So if say for example, you put, I don't know what here, like p equals four fifth, then in this case this will be four. Yeah, so you basically can control the expected value of the number of validations. But the idea is that you don't really know if there will be another validator or not. So the validator that goes last. So here we probably will go get to the proof independent execution, which was proposed by Justin Drake.
00:17:24.064 - 00:18:13.706, Speaker B: The idea was that each validator, when it validates, it has to provide, basically build, like, I would say, a fingerprint of the execution. And this fingerprint of the execution is specific to this validator only. So this validator will produce the proof p one, this will produce the proof p two, and this will produce the proof p three. And also, while this validator is performing the verification, it will like, well, this one, it will verify the proof of this validator. So, because validators don't really know if there will be another validator after them or not, they are like, I mean, they don't have much choice but not to, but to produce the.
00:18:13.770 - 00:18:36.674, Speaker A: So the idea here is that if I, as adversary, control certain number of validators, there is never a moment for me when I'm certain that if I fake all the. So let's say I manage to fake few validations up to a certain extent. The idea is that even if I know that even if I control the next validation, I still have a risk that.
00:18:38.414 - 00:18:39.398, Speaker B: This one, that there's going to.
00:18:39.406 - 00:18:40.126, Speaker A: Be at least one more.
00:18:40.190 - 00:18:40.534, Speaker B: Right.
00:18:40.614 - 00:18:41.702, Speaker A: But at some point the chances are.
00:18:41.758 - 00:18:43.126, Speaker B: Lower, not actually one more.
00:18:43.270 - 00:18:50.754, Speaker A: Oh wait, you're saying every moment. So if there is this, if we manage to get to validation number five, then the probability of next is still four. Five.
00:18:50.914 - 00:19:06.586, Speaker B: Yeah, I see, yeah. So the idea here that the geometric distribution is memoryless. So if you are here, for example, the expected number of validations is four. If you are here, for example, the expected number of validations is still four. Right? Yeah.
00:19:06.610 - 00:19:10.414, Speaker A: It's like if you want a girl and you have a boy, you still have two kids before you get a girl.
00:19:15.114 - 00:19:24.214, Speaker B: Oh, and basically, yeah, this guy doesn't know whether there will be a validation after him or like which validator.
00:19:24.554 - 00:19:27.178, Speaker A: But importantly, the probability of the next validation is always high.
00:19:27.266 - 00:19:40.484, Speaker B: Yeah. And also you, I mean, you can also improve the thing by forcing not only this validator to verify this one, but also like this validator to verify, like this one, the proof independent execution.
00:19:41.344 - 00:19:55.352, Speaker A: But what is the motivation? Like, probabilistically, they will obviously execute stuff. And so if you verify the proof of the independent execution, most likely you just waste resources. Right, right. What's the motivation to verify it?
00:19:55.448 - 00:20:26.122, Speaker B: Well, in our case, the idea was basically to make the computation of the proof independent execution, like the overhead really low, so you don't have an incentive to remove that. And also the idea is if you cache this guy that this guy has produced an incorrect proof of execution, then well you will get a fraction of this guy deposit. But yeah in theory I would expect someone to go and modify the source code and remove this proof independent execution verification.
00:20:26.178 - 00:20:46.010, Speaker A: So the idea right now is that if I'm validator number five as I'm executing the code of the query whenever I need to compute my, well we didn't go much into proof of independent execution, but whenever I need to compute my hash of the state in the present binary, I will also compute hash of everybody else. And you're saying the incentive to recompile.
00:20:46.042 - 00:21:28.060, Speaker B: The binaries, it's very low so the overhead is very low. And you also have some like you can also receive some money from those guys. Yeah, and also it also might happen that if, for example, I mean that it has like you can see like this approach might have it like certain flaws here. So if you have this guy who is verifying this proof independent execution, let's say this proof independent execution was not correct, then this guy came and didn't check that and then this guy is coming and it actually found that it's incorrect, then this guy is like okay I have something to lose here. So yeah, maybe you can improve it like that.
00:21:28.092 - 00:21:31.260, Speaker A: Are you saying that also works as a motivation for the second validator?
00:21:31.332 - 00:22:31.884, Speaker B: Yeah, to actually verify the proof. Ok, let me probably talk about timeouts because there is also a potential problems here. So first of all, before talking about timeouts I probably should talk about like fuel accounting. So we use very similar approaches like what ethereum does, we use fuel, but here we have a kind of different thing. Instead of forcing clients to pay for fuel, we have a developer who is paying to the, not like only the real time layer but to the entire, to the entire validation and real time error processing and the way how fuel works. Fuel accounting works. So first of all there is like a complexity of instructions which is very similar to what you found in ethereum, although we have complexity of webassembly instructions.
00:22:31.884 - 00:23:11.402, Speaker B: But second thing is, so first you have algorithmic complexity and the second thing is amount of allocated memory. So these machines, they have to allocate memory. We haven't like well like right now we are focused only on the memory. Like you know in memory stuff we haven't really touched disk much. So I'm not going to talk about that. But you for example can tell those guys I need 4gb of memory. Or when once assembly supports more you can say I want like 32gb of memory.
00:23:11.402 - 00:23:39.294, Speaker B: Memory but anyway, the developer can have control over how much memory she wants to allocate. And yeah, so there is memory, but the problem with memory is memory is not really, if you calculate the algorithmic complexity of the webassembly program, it's equal to work, I mean in the physical sense, but memory is equal to power.
00:23:41.314 - 00:23:45.858, Speaker A: That's way beyond my knowledge of physics. But I see what you're saying.
00:23:45.906 - 00:23:59.454, Speaker B: Yeah. So it's like how much have you allocated? But if you allocate it like 4gb for 1 ns, that's probably not worth much. And if you allocate it for gigabytes for a year, that's a lot. So we multiply this thing by time.
00:24:00.754 - 00:24:04.778, Speaker A: But you don't know in advance how much time you need. Right. What happens if my deposit, you also.
00:24:04.826 - 00:24:39.324, Speaker B: Don'T have notion of like a good notion of time in decentralized systems. So how stuff works here, we kind of replace the thing a little bit. So this is, let me think, what was the symbol? Oh, anyways, let me say this is like ETA, like how much the program, like the complexity of the program that was executed, like in a for example single block. So you can multiply this ETA by some coefficient and you will get some kind of standard time here.
00:24:42.824 - 00:24:46.552, Speaker A: Okay. Yeah. How much processing time it spent.
00:24:46.608 - 00:25:00.624, Speaker B: Yeah. How much time it would have taken on a standard hardware to execute this program. And then you take this standard time and multiply by memory and you get like how much you have to, like a developer has to pay for memory.
00:25:01.004 - 00:25:12.572, Speaker A: How much memory they used at that particular time. But then also if the query has some footprint on the state, that memory will be downloaded by every consecutive real time layer, person or validator, right?
00:25:12.628 - 00:25:47.726, Speaker B: Yeah, yeah. So the way it works, so we have this thing and we also, I mean remember we have spoken that we have to compute the hash of the virtual machine and we also said that the hash is a mercury thing. So imagine that you for example need to perform a single put request, like write just one byte into the memory, but your memory is like 4gb and your chunks are probably like 4 kb, let's say like that. So now probably, are you saying the.
00:25:47.750 - 00:25:50.926, Speaker A: Memory is pre allocated? Yeah, the memory is, okay, 4gb is pre allocated.
00:25:50.950 - 00:26:40.176, Speaker B: Yeah, those guys are like, yeah, 4gb are pre allocated and imagine that. But let me show you the issue here. You have the say for example, you have a miracle tree and maybe I don't really need this layer. And this miracle tree has eight chunks each like 4. I'm going to write, I'm as developer have written a program that writes a single byte into chunk. So now if I'm just calculating the algorithmic complexity of this thing, it's quite low. So writing one byte has pretty small complexity, but recomputing the merkle hash of this chunk and this one and this one, like basically propagating all the way to the top is like pretty expensive because you also have to calculate the hash of this thing and this and this and so on.
00:26:40.176 - 00:26:48.798, Speaker B: So we also charge for, we call it for dot in chunks. So every time when you write to a chunk, this chunk is like markers dirty.
00:26:48.926 - 00:26:53.638, Speaker A: But it's not much different from writing a single byte to a page which is not in the cache. Right.
00:26:53.726 - 00:26:58.758, Speaker B: Yeah. So that's kind of similar to just normal hardware.
00:26:58.846 - 00:27:04.354, Speaker A: So as a developer, you're responsible to make sure you're writing to co located.
00:27:05.414 - 00:27:37.946, Speaker B: Yeah, basically you have aligned calls and writing to the same, trying to write to the same page of memory. So anyways, but so we have like price for dirty chunks and basically that's also goes into this formula. Dirty chunks multiply by like some, another coefficient and that's the entire price. Like that's the entire fuel price. How much a developer has to pay for that? And the developer might be, might be compensated or might not be compensated for.
00:27:38.010 - 00:27:55.866, Speaker A: Like this service, it's up to them to monetize it. Right. Yeah, but how would users not saturate their developer will not be paying infinite amount of money. There is some allowance. Why would I not come with a single phone and just saturate everybody's allowance?
00:27:55.970 - 00:28:00.258, Speaker B: Yeah, but that's very similar to how modern web works.
00:28:00.346 - 00:28:03.614, Speaker A: So again, it's up to developer to properly expose it.
00:28:04.074 - 00:28:46.438, Speaker B: Right? So I mean if you say for example, deploy the backend into centralized data center, then I can make a DDoS attack on you. But anyways, here we have a central developer role here which makes things a little bit centralized, but you can make it more decentralized by saying, well, each client has to pay to use this service. Clients need to pay a developer, say for example once in a month some, or pay for each transaction somehow. Basically if the flow of clients is high enough, then you don't really need a developer here, you just have a contract that stores some kind of balance here.
00:28:46.566 - 00:28:49.534, Speaker A: But these guys, they really don't care who's paying, right?
00:28:49.614 - 00:28:54.118, Speaker B: Yeah, no, they just need money to operate.
00:28:54.246 - 00:28:58.714, Speaker A: And also before we go to timeout, these people never rotate.
00:28:59.034 - 00:29:02.362, Speaker B: Yeah, well I mean they can, but.
00:29:02.378 - 00:29:09.690, Speaker A: That'S not how it is implemented. Right. So if I have my own. If there's a data set or any computation I want to do, I preselect these validators.
00:29:09.802 - 00:29:11.426, Speaker B: You can do that. You can do that.
00:29:11.530 - 00:29:15.706, Speaker A: And those people, they constantly rotate those I never choose and they never choose me.
00:29:15.810 - 00:29:29.288, Speaker B: Yes, yes. I mean, so we haven't, so honestly we haven't digged much into how real time could rotate. So for now we are like, oh yeah, developer can choose the node that is more, I don't know, has the higher availability, reputation or something.
00:29:29.336 - 00:29:30.256, Speaker A: Or better linked to them.
00:29:30.320 - 00:29:46.520, Speaker B: Yeah, or better linked to clients. But we can say that this layer is not necessary. I mean, it might be taken over by malicious adversary. It might happen. What's important that this layer developer doesn't have any control over this layer.
00:29:46.632 - 00:30:02.944, Speaker A: But then the interesting question is this validator, right, whenever they get assigned to a fragment, the very first thing they do is they download the whole snapshot of the virtual machine just to perform some number of transactions, which I guess is relatively small.
00:30:03.644 - 00:30:06.068, Speaker B: We actually want to make it relatively high.
00:30:06.156 - 00:30:29.842, Speaker A: Relatively high, okay. But still, effectively that implies that rotation is very possible. So would it not make sense, let's say I want my speed layer to be more secure. Would it not make sense for me to say I want a BFT consensus for four people? I don't care about link or availability, but I want more security. I want those to rotate because clearly they can, right? In principle.
00:30:29.938 - 00:30:48.234, Speaker B: I mean, they could in principle, but as you mentioned, that those guys have to redo, I mean, so maybe I should write it like that. So these guys are stateless and these guys are stateful, right? But.
00:30:50.934 - 00:31:29.674, Speaker A: Let'S say I chose to have one validator in my tendermint consensus group, and then I chose to have, let's say probability six over seven. So we're going to get six, right? It sounds very suspicious. I know. That's all good. That means I'm already paying for six people to every now and then go download my state and validate. So in essence, let's say that instead I drop this guy or I keep this guy, doesn't matter, but they make those six people to be more real time. I'm telling them to download the state a little in advance and then validate in real time for the same amount of time.
00:31:29.674 - 00:31:35.626, Speaker A: That would give me slightly less security in a sense that the, the master.
00:31:35.650 - 00:31:39.854, Speaker B: Of puppets, you cannot choose those guys, right?
00:31:40.554 - 00:32:00.966, Speaker A: But you see what I'm saying, right? I'm losing a little bit of security because the master of puppets, now during that epoch, while they validate me, they know them all and so they know exactly whom to corrupt. So we're losing that advantage of the last validator. So I'm losing that. But what I'm gaining is that my speed layer is significantly more secure. Right.
00:32:01.090 - 00:32:30.510, Speaker B: Okay, let's think about this. So first of all, that was the idea to not let anyone to tamper with this layer. So no one actually has control over this layer. So we didn't really want this. And second thing, let me think about this. So this validator will go here and take the state, and it will, I mean, the questions are, how often do you rotate those guys?
00:32:30.662 - 00:32:46.622, Speaker A: But let's say we rotate them as often as they are. They would do as many queries as they do today, effectively. Oh, the problem is that here when they validate, the queries are condensed, and if it's real time, the queries are sort of coming at a significantly.
00:32:46.718 - 00:33:09.572, Speaker B: Well, I mean, what could be done, let me think, what could be done here. You can say, take this validator and, no, not you, take this validator. Once this validator is selected and has downloaded the state and applied it and produced a new state, maybe you could replace this node with this. Oh wait, actually this validator will be lagged because it, yeah, but they can.
00:33:09.588 - 00:33:15.868, Speaker A: Download state a little bit in advance. Like effectively what you do is you download state like half an hour before you would have to start validating.
00:33:15.956 - 00:33:17.904, Speaker B: But you don't know that you will be validating.
00:33:18.664 - 00:33:21.564, Speaker A: Well, let's say they somehow do know.
00:33:21.944 - 00:33:27.896, Speaker B: Right? But this will break the assumption that no one controls this layer. I mean, I'm not.
00:33:28.000 - 00:33:43.560, Speaker A: Well, technically someone does control this layer today. Like there's the ethereum chain with randomness, which says you validate this now. So what will change that Ethereum, instead of saying you validate it now, says you validate it in half an hour from now, so you have time to download state, catch up and maintain it in sync. Right?
00:33:43.632 - 00:33:46.684, Speaker B: Yeah, that would probably work. That would probably work.
00:33:46.844 - 00:34:11.860, Speaker A: So here the trade off is the security will be slightly less. That's a philosophical question. Is it the case that if someone can corrupt two, three of my seven node cluster, in principle they can tamper with people who get assigned to validate my dataset? But what I get is that my speed layer is fast. Sorry, my speed layer is secure, is more secure.
00:34:12.012 - 00:34:18.028, Speaker B: Yeah, I guess, I guess, I mean, I would probably want to sit down and do some math on that.
00:34:18.156 - 00:34:29.228, Speaker A: But there is also, here's another sort of consideration, which is so those validators, you chose them from some pool, right?
00:34:29.316 - 00:34:29.636, Speaker B: Right.
00:34:29.700 - 00:34:46.904, Speaker A: And presumably that pool, it is unlikely that you happen to sample two, three plus one malicious actors, or like, even one third plus one, depends on where you draw the line. So we expect that it will only break if a malicious actor can somehow reach out to them and corrupt them adaptively. Right?
00:34:47.244 - 00:34:48.252, Speaker B: What do you mean by that?
00:34:48.348 - 00:35:13.582, Speaker A: By adaptive, I mean that when I created. So let's say this is my cluster. It has seven nodes when I created it, it is extremely unlikely that the cluster was corrupted. So the secure layer protects me against someone. Let's call them an adversary. An adversary somehow reached out to them. So, for example, let's say all the validators are sitting in the same discord channel.
00:35:13.582 - 00:36:03.402, Speaker A: So they went to the Discord channel and they said, if you're validating this cluster, I will give you your stake, x two for your private key. So that's what we're trying to protect against. The thing is that clearly this validator knows that they will be validating your particular fragment for a while. So let's say you want them to validate for 2 hours in a row. That means there is 2 hours during which the validators themselves knows that they are validating the fragment. You can do some smart construction so that nobody else knows until they publish, but they know that's what is important. So now, as an adversary, what I will do is I will go to discord and I will publish a smart contract on ethereum, where if you prove that you got assigned to this fragment and you provided your private key, you get your stake, x two.
00:36:03.402 - 00:36:14.154, Speaker A: Right? So I still can adaptively corrupt. I mean, I'm still risking something, right? Because I could adopt this person, but I don't know if there's going to be next one. Or rather, I don't know if they will be corruptible. But if I really want to.
00:36:14.234 - 00:36:30.362, Speaker B: I mean, if you really want to. I mean, so here's the thing. If you really want. Well, first of all, two things, because this guy knows that someone else will be verifying him, and this guy might not really know that, like, whether this guy will actually, you know, be corrupted. Be corrupted.
00:36:30.418 - 00:36:33.338, Speaker A: But I'm paying him stakex, too. He has incentives.
00:36:33.386 - 00:36:40.386, Speaker B: If an adversary is willing to spend all the stake in this attack, then, yes, the adversary can only stake of.
00:36:40.410 - 00:36:43.146, Speaker A: Seven people out of, like, few hundred, right?
00:36:43.210 - 00:37:04.866, Speaker B: Yeah, yeah. I mean, it's basically we can tell, like, the developer a price. Basically, the developer knows that those guys have put that much stake and the data will put that much stake, and the developer knows that if someone spends more than this stake. Yeah. Then probably the results that the entire layer produces will not work.
00:37:04.970 - 00:37:14.290, Speaker A: But if this is the price that developer, if this is the security the developer gets, then obviously they can just put everybody into the speed layer. You still need to spend as much.
00:37:14.482 - 00:37:49.198, Speaker B: No, I would probably say that in this case, for this case, in the speed layer, you need to corrupt two thirds of the class. For things to work in the security layer, you have to corrupt, I guess, everyone. And in this case, you will be like, so it's like basically corrupt all. And I would probably say that if you put everyone here, so let's consider two situations. You have seven nodes in real time.
00:37:49.366 - 00:37:52.294, Speaker A: And you have r1 time six validators.
00:37:52.414 - 00:38:00.062, Speaker B: Exactly like r1 time six validators. I would probably say that this is like slightly better, but also to an.
00:38:00.078 - 00:38:18.324, Speaker A: Extent, it depends on how much we believe in the power of the adaptive adversary, because obviously you cannot expect all the stakes validators to be online. So an adversary can provide them a choice. They can either get corrupted for two x, they can lose the stake, or they can just skip their step for like one 10th of the.
00:38:18.404 - 00:38:27.804, Speaker B: No, you cannot like, I mean, if one of those validators keeps the stack, skips the validation, then another validator will be selected. Yeah, you always have to do six validators.
00:38:27.884 - 00:38:49.472, Speaker A: Yeah, but let's say we make small step. Let's say we removed completely the security layer or shared validator pool. But in the tendermint consensus, we're saying that. Yeah, let's say you corrupted two thirds, but we're still making like the remaining participants can still challenge. Right? They can still fish, I presume.
00:38:49.528 - 00:38:55.686, Speaker B: Yeah, they could even today. Right? Actually, let me think about this.
00:38:55.880 - 00:38:59.894, Speaker A: So what you're asking is if two of them are literally offline for some reason.
00:39:00.354 - 00:39:23.894, Speaker B: So let me think about this. So I guess what could be done here. So here's the thing. So let's say, for example, those guys are corrupted, and in this case, they don't even not need to talk to the rest of the two to reach consensus because those guys, like those are enough to have consensus.
00:39:23.974 - 00:39:32.534, Speaker A: But we presume that swarm has some way to say that the data is not available. So the two guys will, they will not say block is invalid. They will say the data is not available.
00:39:32.614 - 00:39:59.020, Speaker B: Yeah. So I guess if those guys, let me think about this. So I guess if those guys save to the, if those guys save everything to the data like availability layer, then this could. Yeah, I mean, they are not in the consensus, but they're like, well, someone has cut us out and they can go here and download the data and be like, I challenge you. I would probably say that's quite possible.
00:39:59.132 - 00:40:18.114, Speaker A: So what we lose. So effectively, if I understand everything correctly, the only thing we're losing in this approach is that the adaptive adversary has full information on whether the attack will be successful before the attack. Like effectively, they can choose not to attack until they have full control, while.
00:40:19.574 - 00:40:38.582, Speaker B: With the shared data pool, those guys are selected on completely random. Here's the thing. If you're saying that an adversary can post to a discord channel and say, basically all of these six validators here will be like, okay, I'm corruptible, but.
00:40:38.598 - 00:40:46.876, Speaker A: You know why validators validating, right. That's not because they like fluence or cosmos or whatever they're validating. It's because they want money. So if someone goes to discord and says, here's more money.
00:40:46.980 - 00:40:56.460, Speaker B: Right, right. But I would probably say that's also like a philosophy. If you are saying that all six of them are corruptible, then yeah, probably that's pretty bad.
00:40:56.532 - 00:41:03.624, Speaker A: Yeah, I think that's an uncommon opinion that you can have like large percentage corruptible. But it sort of sounds reasonable if you think about it.
00:41:05.284 - 00:41:07.196, Speaker B: Well, I mean, maybe there will be some.
00:41:07.260 - 00:41:10.378, Speaker A: Well, I mean, but ultimately it's up to the developer.
00:41:10.436 - 00:41:16.158, Speaker B: Usually we are basically saying that one third of the validators are corruptible or malicious.
00:41:16.326 - 00:41:18.074, Speaker A: That's extremely optimistic.
00:41:18.374 - 00:41:24.118, Speaker B: 10% of them are. But yeah, I agree, if all of them can be corrupted.
00:41:24.246 - 00:41:34.126, Speaker A: But the idea here is if the developer is the developer who chooses the security, if they believe that more than 50% are corruptible, not much they can do anyway.
00:41:34.270 - 00:41:53.128, Speaker B: And also I would probably say that, yeah, the stakes that the validators have put, they are basically kind of saying, well, you can expect that much security if an adversary, like say, for example, all those nodes have put like ten k as a security deposit. If someone is willing to spend 70k, you know, to break the thing.
00:41:53.216 - 00:41:54.044, Speaker A: Like 50.
00:41:54.904 - 00:42:07.734, Speaker B: Yeah, you're right, like 50. Well, no, actually you also need to corrupt those. Like 70k, then. Yeah, probably like you. You should, like, if your application is that mission critical, you probably should require those guys to put more stake.
00:42:09.034 - 00:42:11.122, Speaker A: Cool. Ok, now let's talk about timeout.
00:42:11.178 - 00:42:53.974, Speaker B: Yeah, let's talk about timeouts. So we have just discussed, we have few. And the fuel is basically instituted from three components. And the first component is what the algorithm complexity was of the program. Second component is how much memory was allocated for how much time. And the third one is how many chunks of the memory were made dirty. So now you have calculated, let's say you have calculated fuel, and once you basically have calculated fuel, we are trying to turn this fuel into the timeout, because we said here that a validator must validate within certain time.
00:42:53.974 - 00:43:24.694, Speaker B: And, like, if the validator does not validate in a certain time, then a fraction of his deposit is, like, slashed, like a small fraction, like 101,000th, 110,000. So how the timeout is calculated, we basically take the fuel. And here's the thing. The fuel is declared by this cluster because you cannot really know how much fuel will be spent without actually executing the program.
00:43:24.774 - 00:43:30.434, Speaker A: But once you validate, if you exceeded fuel, you just stop. Right? So, as a validator.
00:43:33.854 - 00:44:13.490, Speaker B: Let me show you a potential issue here. So those guys say, for example, have, like, they. I mean, okay, let me talk about the timeouts, and I probably should clear some space here. Yeah, that's probably good enough. So let's talk about timeouts. So let's say I have few and I've got the timeout, which is equal, like some constant by fuel. And this constant, like, choosing large enough, like maybe ten times more than you would expect an average node.
00:44:13.490 - 00:45:07.692, Speaker B: Like, maybe not 100 times, but like 24 times more than you would expect an average validator to take. And you can say, well, if you guys are slower than that, well, don't even consider joining the network. So now you have the real time cluster, and it might happen that the real time cluster says, well, I have spent that much fuel, but this view is much less than the, like, true amount of fuel that is required to perform the computation. So now, and this view is written here in those blocks, how much time, how much fuel was spent for each of those blocks. So now you can say, if I want to validate a fragment of history, I need to spend, like, that much fuel. But if the real time cluster was lying about the fuel spent, then the timeout that will be given to the validate is, like, really small. And for this, we have, like, few disputes.
00:45:07.692 - 00:45:43.792, Speaker B: So once a validator comes and notices that he was given a really small amount of time, it can execute a few dispute. And a few disputes is very similar to the just normal verification game dispute. You basically saying, like, say, for example, this is a real time cluster and this is a validator. And after each webassembly instruction, you can say, hey, that's how much fuel has left. I mean, was spent, actually.
00:45:43.848 - 00:45:51.204, Speaker A: But that's not how I will attack you. If I'm a real time cluster, I will just upload a seven terabytes file, you will not even get to webassembly step.
00:45:51.544 - 00:46:03.064, Speaker B: Well, let me think about this. You upload a seven gigabyte file, terabyte file to swap. You will upload it to swarm. Okay, let's get to this.
00:46:03.644 - 00:46:09.124, Speaker A: That's an interesting question, but swarm can provide an attestation on the size.
00:46:09.204 - 00:46:12.300, Speaker B: On the size, I'm not sure.
00:46:12.412 - 00:46:15.180, Speaker A: I guess if swarm can do that, that would be your dispute, right?
00:46:15.252 - 00:47:01.594, Speaker B: Well, I don't know the answer right now, so probably we need to think about this. So let's finish with this and then think how this can attack can be solved. So anyways, for the timeout attack, you can say each of those guys, once this guy has found that he spent more fuel than this guy, you can say, well, I want to dispute on this part of execution. And then you do the same bisect search and you find the instruction that has produced divergent amounts of fuel, and the real time class in this case will lose stake. So for the timeouts here, I would say that, yeah, let me think.
00:47:03.294 - 00:47:09.630, Speaker A: If something is wrong, like, let's say fuel is improperly recorded within the timeout, you just need to initiate the verification game.
00:47:09.662 - 00:47:09.782, Speaker B: Right.
00:47:09.798 - 00:47:10.830, Speaker A: You don't need to finish it.
00:47:10.902 - 00:47:20.494, Speaker B: Yeah, yeah, yeah, yeah. Well, and you're not only given like this timeout, you also have some, you know, like some time to download the state.
00:47:21.194 - 00:47:22.570, Speaker A: But that is all included, right?
00:47:22.642 - 00:47:56.968, Speaker B: Yeah. Well, not including few. You probably need like another constant here. Yeah, because like this is if you put few zero, then you don't have any time. Yeah. So for the timeout, what kind of a problem might happen here that the data availability layer, like if an adversary tries to corrupt the data availability layer and say, hey, do not return any, like any data to the validators, so they time out, essentially that might have, might become a problem, and I think.
00:47:57.056 - 00:48:04.884, Speaker A: But in this case, the system will just stall, right? Well, no, like if no validator can validate.
00:48:05.584 - 00:48:18.680, Speaker B: Yeah, I would probably say, yeah, I would probably say that you will, like, the malicious real time class in this case will never get caught. Probably. Well, actually the adversary will have to pay these guys.
00:48:18.872 - 00:48:25.520, Speaker A: But as a developer, you will know something is wrong because for a long period of time, you're not receiving any validation results.
00:48:25.672 - 00:49:29.484, Speaker B: Yeah, you will probably see that. Because basically if an adversary will have to pay to the data availability to bribe those nodes to return the data, but it will have to bribe them for indefinite amount of time because once those nodes start returning the data, they will essentially, like, these guys will actually come and there will be another validator that will be able to download the data and eventually someone will lose a deposit. And also with this, remember we said there will be multiple validations. So the stakes of the real time nodes are not released until the real time nodes that have produced this like history fragment. They will not be released until there is like a last validation was completed. So if an adversary is paying to someone to not return the data, then stakes of these guys will never be unlocked. And this essentially would be similar to just paying those guys their stakes.
00:49:29.484 - 00:49:50.274, Speaker B: Yeah, you have asked about the. I think about what if, let's say. Yeah, let's think about this. What if those guys have uploaded like a really big transaction file? You probably can compute the proof. You probably can build a proof of this size.
00:49:50.774 - 00:49:57.942, Speaker A: Well, if swarm can attest to the size, there's already quite a bit of reliance on swarm, so it's not going to get any worse.
00:49:58.118 - 00:50:38.492, Speaker B: I think it should. I think it should. Or what else can you do? You can also say, for example, you can also build a merkle. I mean, essentially how swarm could do that. I guess you could build a merkle tree like on top of this file. And once you have if, say, for example, the thing said, the file is like 1 mb, but you have downloaded already ten megabytes and it's not, not, has not finished, then you have downloaded the chunks that are required to build the merkle, proof that these chunks belong to the hash of the merkle tree. And now you can actually prove that the size of the file is, they.
00:50:38.508 - 00:50:40.316, Speaker A: Uploaded an invalid mercury root.
00:50:40.500 - 00:50:41.092, Speaker B: What's that?
00:50:41.148 - 00:50:48.100, Speaker A: They uploaded an invalid. Like they actually have a 1 mb file, which they never uploaded. And for the 1 mb file, they do have the merkle.
00:50:48.132 - 00:51:15.264, Speaker B: Oh, that's actually an interesting case. I mean, we. Okay, so let's also talk about this. The merkle. What's important here is that the merkle tree of the, I mean, here's where the discrepancy might come from. So there is a hash of this thing and swarm. So there are actually two hashes.
00:51:15.264 - 00:51:20.890, Speaker B: Ok, let's get to this. There are two hashes, actually, and the first hash is a virtual machine hash.
00:51:21.002 - 00:51:22.130, Speaker A: That's the Merkel route.
00:51:22.242 - 00:51:25.962, Speaker B: Yeah, that's one of the Merkel routes. But there is also a swarm hash.
00:51:26.138 - 00:51:28.258, Speaker A: That's just something that swarm gave you back, right?
00:51:28.306 - 00:51:32.974, Speaker B: And that's something that swarm attests that it will return to you.
00:51:34.394 - 00:51:37.034, Speaker A: This is by no means mercalized, right? I think.
00:51:37.074 - 00:51:38.338, Speaker B: No, they are mercalized.
00:51:38.426 - 00:51:42.818, Speaker A: It is mercalized. Swarm has a ok, and those hashes.
00:51:42.866 - 00:51:48.086, Speaker B: Can be computed with different chunk sizes, more or even different hash functions.
00:51:48.190 - 00:51:51.782, Speaker A: So effectively you can provide one VM hash and upload a different file.
00:51:51.918 - 00:52:24.566, Speaker B: So what a validator can do, like this guy can come and download like say for example, it has produced a new state and it says, yes, the state of the, like, I agree with the state of the virtual machine that is written here, but it then uploads not matching file and not matching state file to here. And in this case, and because those hashes are different, it's not like, I mean, well, I didn't know of an easy way how to prove that this has, doesn't match this.
00:52:24.630 - 00:52:27.394, Speaker A: But if swarm hash is mercury, why do you have your own hash?
00:52:27.934 - 00:53:10.058, Speaker B: Well, it might be just different hash function. I mean, yes, we could make this hash function compatible, but what we are saying here that, well, maybe it might actually happen that the hash functions will be different. So what we have thought about that the next, like, I mean, there will always be the next validator, like either the one that is reverifying this guy or the validator that is like verifying the next history fragment that will download this file. And once it downloads the file, there is a way how to prove that this file, like the file available by this form hash, does not really correspond to this virtual machine hash.
00:53:10.146 - 00:53:12.042, Speaker A: You will just like, yeah, you will.
00:53:12.058 - 00:53:17.186, Speaker B: Just basically find a divergent like chunk in the very specific.
00:53:17.290 - 00:53:22.658, Speaker A: If the next validator is reverifying, they're not downloading the file, they're uploading the same file, right?
00:53:22.706 - 00:53:40.616, Speaker B: Yeah, but I mean, once they are ready to upload the file, they can compute the swarm hash and see, well, if this warm hash matches this one, and if it does not, they can also like do a dispute here. Yeah, I'm not, what was that? Timeout? Yeah, we have to.
00:53:40.720 - 00:53:42.644, Speaker A: Yeah, I think we covered most of the things.
00:53:43.504 - 00:53:45.440, Speaker B: Yeah, I think, I think so.
00:53:45.592 - 00:53:49.360, Speaker A: Cool. Yeah, yeah, we can wrap up the technical discussion here.
00:53:49.472 - 00:53:49.824, Speaker B: Okay.
00:53:49.864 - 00:53:56.970, Speaker A: We always ask one non technical question at the end, which is when is, when is the main net? How far are you?
00:53:57.072 - 00:54:05.990, Speaker B: I think beginning of 2020, I guess. Yeah, it's 2019 right now, so. Yeah, like beginning of 2020. That's our target, I would say.
00:54:06.102 - 00:54:07.246, Speaker A: And you have a Devnet, right?
00:54:07.310 - 00:54:08.126, Speaker B: Yeah, we do.
00:54:08.230 - 00:54:09.422, Speaker A: Go download, play with it.
00:54:09.478 - 00:54:15.238, Speaker B: Yep, yep, yep. But you can play with the real time clusters and the security layer is like on its way.
00:54:15.326 - 00:54:18.310, Speaker A: I see. Cool. Okay, thanks everyone.
00:54:18.462 - 00:54:18.934, Speaker B: Thanks, guys.

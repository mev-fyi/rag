00:00:07.800 - 00:01:02.404, Speaker A: Welcome to the DPin podcast. I'm Tom Trowbridge, your host, talking about everything DPin related, talking to founders, talking to everybody in the sector to get a full perspective on what this exciting sector has in store for us and kind of how it's all built up. And I'm super excited to have today to have a good friend of mine, Vuk, who has been in the sector for a long time and is fulfilling a critical piece. And I think when we think about Deepen, we think about a lot of the use cases, but those use cases don't work without something that VUC is building. And so VOOC is kind of sort of building core infrastructure that will help facilitate and enable the entire deep end sector. And so I kind of want to dig into it right away. So, Vooq, first define, I ask everyone, define what your mind, what Deepin is, and then we'll go from there into actually what you're building.
00:01:02.864 - 00:01:41.864, Speaker B: Yeah, deep in more broadly, is allowing people to contribute pieces of the infrastructure for particular use cases. This is not contained in the virtual assets, so it could also be like physical assets, like 3d printers and so on. We are specifically focused on like the virtual part, basically thinking about compute workloads, storage workloads, and that can be processed on a machine. Usually those are servers, computers and so on. But yeah, deep in general is like more broadly, allowing people to contribute pieces of the infrastructure, which could be anything at some point or whatever. But right now we are super focused on the virtual part.
00:01:42.244 - 00:02:02.012, Speaker A: Yeah, exactly. I mean, the way I think about it is crowdsourced infrastructure that's bound to be gathering a common network by a software layer that has some sort of economics, whether it's crypto economics, most commonly, that helps provide trust and incentives and tell us about what web3 mind is doing in the space.
00:02:02.188 - 00:02:49.874, Speaker B: Yeah. So if you think about that infrastructure, usually you're providing infrastructure. Being part of our economy, and being part of this economy has many implications. So if you want to provide, for example, a computer that would allow decentralized storage on filecoin, you would need to have a bunch of hard drives, but you would also need liquidity, which you need to use in order to participate in these economies. Usually when you have hardware, you don't have the liquidity. So matching these two resources is super important. And the way we do that is through liquid staking, where on one side we allow folks that have only the liquidity to stake into our protocol, and on the other side, we distribute this liquidity to hardware providers that are just focused on providing the resource on which this compute workload or search workload can be executed on.
00:02:50.374 - 00:03:22.886, Speaker A: And so to get a little more precise for people to make it more tangible. When Vuc says liquidity, he basically means tokens. He means coins. If you're doing, whether it's fluence or you're doing filecoin, which I guess obviously where you started to be a filecoin miner, which means to provide storage on the Filecoin network, you need to lock a certain amount of fill of filecoin tokens. That's when you say liquidity. Help us understand the scale of that, the economics related to that as a miner.
00:03:23.030 - 00:04:00.708, Speaker B: Yes, we were fortunate to basically start from the falcon ecosystem, where this is extremely like, the difference is extremely big in the sense that you could imagine a rack full of drives. A rack full of drives maybe allows you to contain ten petabytes. Ten petabytes. It's a lot, but it's not extreme quantities that you can't even imagine. You can probably buy those drives. An average Joe could have a rack full of drives and figure out how to enable that. But average Joe would not be able to get $10 million in liquidity just to enable that one rack.
00:04:00.876 - 00:04:05.636, Speaker A: But back up, that's what's required. For ten racks, you need 10 million worth of fill.
00:04:05.780 - 00:04:48.848, Speaker B: One rack, you would need the 10 million worth of fill. Of course, this is changing as the economy evolves. So at some point, it was even more like you had Falcon being at 200 and the collateral being maybe zero, and that was ten x, like. So you basically need $200 for 32gb of storage that you provided at some point, which is extreme. And for us, it was easy to reason about this problem as just not being feasible. So, like, you as a provider would never get enough liquidity just by providing the resource. Instead, you would need to opt into different liquidity pools that would allow you to grow your business.
00:04:48.848 - 00:05:28.460, Speaker B: Because if you think about providers, especially in the context of storage or compute, those are going to be data centers that have a lot of resources, and they want to focus on the resource. So imagine a full room of hard drives, full room of GPU's, full room of a bunch of servers. All of that would require millions or hundreds of millions of tokens. And that's just not their business. Their business is to keep improving the hardware incrementally and just try to optimize the utilization of this hardware. Rather than being money managers, they are just by nature not money managers. They are just frugal real estate businesses.
00:05:28.460 - 00:05:36.784, Speaker B: They're just trying to optimize their cost in terms of hardware and how fast they can actually amortize that hardware.
00:05:37.604 - 00:06:21.830, Speaker A: If you think about that, phrasing that slightly differently, you spend x dollars buying hardware. That is the capital costs. Some of that could even be borrowed potentially. But to buy the coins required to make that operational on just let's stick with a filecoin ecosystem for now, would require multiples of the value you spent on the hardware. And by the way, we got to go into why that's important. It's that way because that staking proves that once you have it staked, it makes it very expensive for you to leave the network. That stake is there, it serves a valid economic purpose, which leads to trust in the network.
00:06:21.830 - 00:06:28.154, Speaker A: Do you want to talk about why the stake is required? And then we talked about the scale and then we'll get into how you kind of solve that problem.
00:06:28.454 - 00:07:10.320, Speaker B: Yeah, absolutely. So the stake is required because of a few reasons. Most importantly, because the economy needs to be sustainable. So in order for the economy to be sustainable, on one side, you need to create demand for the token, while you're also emitting some tokens every day. But that demand is super critical so that the economy is sustainable long term. So if you just keep printing money and there is no demand for that money, of course the money is not going to be worth anything at some point in the history of that market. But if you keep also increasing the demand and you figure out how to calibrate the demand with the supply, then you have a sustainable economy.
00:07:10.320 - 00:08:15.584, Speaker B: So that's one point. The second one is how do you know who should get the liquidity? Because if everyone wants to provide just resources, there are some better hardware providers, there are some worse hardware providers, and you want to manage the trust through that liquidity. So someone who is giving that liquidity to you as a hardware provider is for some reason trusting you that you are a good hardware provider and that you will do a good job. So that's the second piece, which is basically how do we select who will be part of this network. And usually we will select that by either efficiency, so you're able to like have a better cost, and because of that you're providing more rewards back to the lenders, or because you're better and you have multiple revenue streams that you can use on top of that error. So for example, in filecoin you can provide storage, and that storage gives you some reward from the main network. But maybe you sell that storage for a fiat, on a fiat basis, for a particular use case, maybe you do archival.
00:08:15.584 - 00:08:41.094, Speaker B: So you charge your user $2 a month just to store 1. That's additional to the Falcon rewards that you are making. So because of that, you can pay more in interest rate for getting the falcon. And the more falcon you get, the more unfair advantage you have over the other providers. And with that you can grow to a larger degree. So, yeah, those are kind of the ones.
00:08:41.514 - 00:09:18.940, Speaker A: And just to back up one point, I guess, on the stake, because you mentioned one reason for the stake, but I think the core reason is that if you didn't have stake, any provider could contribute assets to the network and then turn them off at any point with no adverse consequences. And so if that happened, that then wouldn't inspire people to use the network. Right. So the stake actually is critical in order to have users trust the network. The benefit of stake also is that it's a demand for the token, obviously.
00:09:18.972 - 00:09:19.428, Speaker B: Right.
00:09:19.556 - 00:09:40.060, Speaker A: But I just want to get into the key piece of that. That value locked is what allows customers to trust to put their data on Filecoin, because they know if that provider turns off that storage, that stake is slashed and goes away and is value destructive to them and to whoever staked. Right?
00:09:40.172 - 00:09:42.556, Speaker B: Yeah, yeah, absolutely. I've been in the space.
00:09:42.620 - 00:09:46.580, Speaker A: You take that for granted. But I just want to make sure that we've. Let's set the bases here, you know?
00:09:46.692 - 00:10:14.054, Speaker B: Yeah, absolutely. And the same is for compute, right. If you want to execute a compute workload, what you would do is you would commit that you're going to execute that workload and that commitment needs to be monitoring, because if there is no penalty, then there is really no commitment at any point in time. So if you're not losing value because you do not do something, then the commitment is just not real. So that's the only way for you to actually.
00:10:14.394 - 00:10:46.522, Speaker A: And the reason why this all exists, to back up for a second is that if you have Amazon, everyone trusts Amazon. That's a brand, it's a company, you can sue them, whatever. But in a decentralized network, you've got a whole bunch of individuals, whole bunch of companies contributing. You may not even know who they are. So you need a way to get trust because you don't know XYZ provider where they are. So instead it's an economic way, which is what staking provides is that economic incentive that everyone is aligned on and provides that stake and that trust. But the expensive part.
00:10:46.522 - 00:11:05.862, Speaker A: But it's also expensive, and that's where VoOq comes in in terms of helping providers amass that stake so they can be trusted. So, vu, can you talk now more about staking? What's the difference between staking and liquid staking? Just to be kind of set some basic ground definitions here.
00:11:05.998 - 00:11:39.690, Speaker B: So staking would basically mean you just lock the liquidity inside the protocol. Usually these protocols have like some timeline on which you can unstick. So those are not like liquid positions because you just staked for a particular amount of time, and you can unstick maybe in two years, three years, I think as the default on file coins, around like one year to two years. So two years, you can't touch your token. They are locked inside the protocol. Well, what liquid staking is, it allows you to stick and unstake all the time. Basically, your position becomes liquid.
00:11:39.690 - 00:12:22.206, Speaker B: And this is why it's called liquid staking. So you're staking, but you also have the option of exit, exiting the liquidity at any point in time from the network. Then there is a third category right now, which is kind of lending, which I would really say that it's different from staking because lending is basically not really taking and locking the liquidity inside the protocol, but it's rather delegating the option to stake to someone else. So you're lending. The model here is an interest rate based model. So basically there is a price for the liquidity that you're paying, and then you have the option of taking that liquidity and locking that inside the protocol. That's sticking, taking liquidity, and locking that in the native protocol.
00:12:22.206 - 00:13:08.638, Speaker B: So in the context of Falcon, for example, if you have 100 drives, each of them is 20 terabytes, you can commit a particular amount of storage. Then you would borrow that from a lending protocol, and you would then ask the providers, take that inside the protocol. So you as a provider are staking. So for us, it was very important that we do staking and not lending because we wanted to manage the risk. So what we do is we take that liquidity from the token holders, and we directly stake that inside the protocol. The way we do it is by just abstracting away the storage and compute workloads needed for locking liquidity. In our protocol, for example, in the context of filecoin, you have the onboarding, which is also called ceiling, and then you have the storage.
00:13:08.638 - 00:14:02.868, Speaker B: We had to decouple those, build a bunch of primitives that basically allow us to coordinate, compute and storage jobs interdependently. And then we log that liquidity by allowing providers to just do the storage. So for us, it was really important to get to the bottom of the stack, which is basically locking the liquidity inside the protocol. Now because we are doing that, it's much easier for us to make it liquid staking, because now since we control the liquidity inside the native protocol, we are also able to control how we unlock or log that liquidity. So for example, we could commit for storage deals that are only six months or twelve months or 24 months. So we are able to actually have guarantees that we will definitely be able to exit that position, which is not the case with the lending protocols. Because what lending protocols do is they allow you to borrow money for a particular term.
00:14:02.868 - 00:14:55.020, Speaker B: So for example, two years, three years, or indefinitely. And as long as your paying the interest rate, there is no unlock. You as a borrower just borrowed that based on some terms. And usually there is no commitment in terms of timeline you just borrowed. So if someone wants to unstake their position, then you have a problem here because everyone is paying their interest rate, but someone wants to unstake from that pool, which is where the initial liquidity came from. And now you can't actually pay back your lenders because no one is defaulting on their loans, the loans are being paid. So the only way for you to actually get out of that position is by either increasing the interest rate and kind of making higher pressure on the providers that have borrowed the liquidity, or is just by waiting or hoping that someone else is going to stake in that particular moment.
00:14:55.020 - 00:15:16.846, Speaker B: And then you are going to be able to swap the position of the lender that wants to exit the position with a new lender that wants to. Yeah, just give fresh liquidity to the point. But yeah, ultimately lending is one thing, you're delegating the option to stake inside the native protocol, and staking is really locking the liquidity inside the native protocol.
00:15:16.950 - 00:15:45.474, Speaker A: So listen, it's totally. I get the staking, I think is the simplest way to understand that either I am a provider, I buy coins, I stake them that they're locked up for a year, two years, whatever they are. The next is, if I want to, is for someone else to basically say, okay, I will stake you to do the. Do the storage for me and I'll send, I'll lock the coins in your contract. Right. So they're locked for you. Exactly.
00:15:45.474 - 00:16:17.114, Speaker A: And then I guess the thing I didn't really, I think it needs a little bit more detail on is the liquid staking because the stake is still locked. But is that liquidity managed by you because of the amount of stake you have? Locked. So you're managing different people's liquidity. So you're sort of taking the liquidity lock kind of risk, if you will. You're aggregating both sides of that. So some is coming unlocked, and that's liquid for anybody that wants it. It sort of pools on both sides, more or less.
00:16:17.114 - 00:16:17.618, Speaker A: Right?
00:16:17.746 - 00:16:44.686, Speaker B: Yeah. So there are like multiple buffers. The first buffer is by creating a market that has enough volume so that you are able to basically swap the positions, which is basically, if I want to unstake, someone else wants to stake at the same time. And that depends on the volume that you have. That's the first buffer. Then you have some buffer inside the pool. So you have capital inefficiency, which is basically just keeping liquidity there in the case of someone wanting to exit.
00:16:44.686 - 00:17:33.437, Speaker B: And usually what folks do is they provide like 10% off that liquidity as a buffer. And then the third one is unlocking that liquidity from the protocol. And only if you are a staking protocol, not the lending protocol, you can do that because if you are a staking protocol, you are on that layer that logs the liquidity inside of the native protocol. If you are a lending protocol, you are delegating that option to someone else to stake that into native protocol. The only issue you have with that particular borrower is through the interest rate and the position that they have as a loan from you as a lending pool. So in that case, it's a bit harder for these protocols to actually unstake tokens because they can't. What they can do is create some pressure by increasing the interest rates.
00:17:33.437 - 00:17:44.893, Speaker B: But that's also not instantaneous. Right. So if I hike the interest rates to 30%, it's going to take some time before folks actually on stake. Yeah, it's a bit.
00:17:44.933 - 00:18:09.020, Speaker A: And I grasp that. Help me understand, for a liquid staking product, is that. Just make the math easy. If filecoin lockup is two years, do you say you could have liquid stake with web3 mine, and you could get half your capital back in 30 days or 60 days. Is it like some tiered or is it completely liquid, or are there different products? Based on the amount of rate you give, how do you tier that out?
00:18:09.132 - 00:18:54.554, Speaker B: It's completely liquid in our context, of course, if you want to take. Usually we don't have big positions where. Big positions in the sense that we don't have a whale that has 50% of the total liquidity in our pool. So for us, events where someone would take almost everything that we have committed in capacity is very low. But even if we had such events, since we are controlling how the liquidity gets locked in the native protocol, we would be able to terminate storage, terminate deals inside the Falcon protocol and just pay back whoever has staked, which is not huge.
00:18:56.414 - 00:19:28.184, Speaker A: If I just look at this as a naive, as just a third party, whether I'm an individual or a manager who happens to own Filecoin, reverber other protocols, you will do this for that is a massive value to me. To be able to stake, earn a yield, but not be locked up for two years, that is hugely valuable. And so then you obviously then your protocol would take some fee as a result of that. Right? So how would that, that's a valuable service. How do you think about charging for that service?
00:19:28.884 - 00:19:47.268, Speaker B: Yeah, so what we do is we are basically following the good practices from the term ecosystem where like we are doing sticking like lido, just capturing a percentage of the total rewards that get emitted to our providers. So that's 10% similar to how Lido does it. Yeah.
00:19:47.356 - 00:20:31.276, Speaker A: So the way to think about that is if you, you can either lock up for two years or you pay 10% and have liquidity on a daily basis. And that seems like a pretty fair trade to me. And I see the complexity in the real value because not everyone can do that. You're doing something that no one can do unless they have the volume you have and. Right. The more users you have, the more volume you have, the more kind of confidence you have to deliver that liquidity, which means the harder it is for someone else to compete to do it. So this seems like it's one of those network effect kind of concepts where once you get to a certain scale you're the default option for this because it's also the safest.
00:20:31.276 - 00:20:34.628, Speaker A: Right. Because you also have the most capital, the most liquidity locked.
00:20:34.796 - 00:21:53.448, Speaker B: Yeah, and it's not just about the liquidity, it's also on how this liquidity gets deployed inside the native protocols. So if you think about what problem are we really solving more on a physical level, we are thinking about all the compute jobs and storage jobs that exist on the planet and we are thinking about how to deploy them in servers that can be seen anywhere on the planet. Thinking about this problem of the provisioning of these jobs on physical machines is basically just creating a big coordination machine that aggregates every job that is running on the centralized compute networks on the planet and is allowing these providers to just efficiently execute them. And these providers would commit to execute these jobs every time that they want to execute a job, and with that they would also participate in our economy. Now this is super important, because since we are the ones helping providers to participate in the network, we are also building a bunch of tooling that these providers can use for free. So if you were doing provisioning of storage on file coin, you'd probably use 70% more resources than what you would do with our tech. And all of these savings are passed back to the stakers.
00:21:53.448 - 00:22:55.704, Speaker B: So by building tech, we are able to increase the yield of our protocol on the economical layer, just by allowing them to be smarter on how they execute the jobs, and being smarter on how they execute a job is a big deal. So if you're doing compute and storage, you have many inefficiencies just by moving data around and just by trying to coordinate that locally on your data center. Well, if you only do storage, you have economies of scale. You just do storage and you focus on storage. The math is clear for storage, and that's the only thing you do. You don't think about GPU's, you don't think about special cpu's that are able to do like XYZ, you don't think about ND mes, you don't think about networking, you don't think about a bunch of things that providers, for example, in the Falcon ecosystem, have to think every day. And every variable that the provider thinks about is inefficiency on the protocol, which ends up being inefficiency that needs to be captured by someone, and that someone usually is the staker.
00:22:55.704 - 00:23:06.276, Speaker B: What we try to do is just build a bunch of tech that makes it super simple for the providers to be participating in these networks and just focus on pure unit economic cost, and.
00:23:06.300 - 00:23:53.230, Speaker A: That'S how it yields it. Sounds compelling. The downside, I guess, is to the extent you are successful, you could become a point of centralization in the deep end network. If the general default is gee, I'm happy to pay 10% to not be locked up for two years, which is not a crazy scenario. Web three mind could become the dominant staking mechanism and dominant staker right across whatever projects you're doing. And now all of a sudden, that is a big concentration point, right?
00:23:53.422 - 00:24:47.946, Speaker B: Yeah, that's a fair point, but it's not the same as Ethereum in the context of deep in, because in Ethereum, locking 1 billion of liquidity is not hard. You open up a bunch of vms and it could basically be one company doing that. It could be like Coinbase doing that. In fact, Coinbase is doing that. For a lot of liquidity on Ethereum, but in the context of deep in, you are not the one using that liquidity and deploying that inside the protocols, because the sheer amount of hardware needed to do that is not enough for any single company. And then you would need to have many providers very different than the open network on how these providers actually participate in, rather than have just one big data center locking the liquidity. So if you want to lock all these liquidities, you would need to have hundreds of data centers participating together in these networks.
00:24:47.946 - 00:24:55.490, Speaker B: And as long as the protocols are open, as long as everyone can participate openly, you're not centralizing the thing.
00:24:55.642 - 00:25:30.328, Speaker A: And the infrastructure is still decentralized. But the stake could be centralized. That's my point. You're still, it makes, the deep end network is still decentralized, no doubt, but the economic piece of it could still, anyway, it could be centralized. But listen, as far as you're concerned, that's a good problem to have at some point where we've got a ways to go before that's the case. Help us understand scale. Like where are you guys, what protocols are you working with? What's on the roadmap? What scale do you see both in the near term and where do you think things go in the long term?
00:25:30.496 - 00:25:46.684, Speaker B: Yeah, so we have, of course, one of the main networks is Falcon. I'm not sure where we can share it publicly, but there is another network that a guy called Tom Crawbridge is running.
00:25:46.804 - 00:25:53.864, Speaker A: Yes. Fluent labs coming up, staking, you heard it here first or third, but yes, exactly. Excellent.
00:25:54.804 - 00:26:39.924, Speaker B: Then we have the render network coming, we have the library network coming and a few others. But ultimately for us it's always thinking about how are these networks able to communicate between each other? And is there more value in having something like fluence interconnect with Filecoin or some other network? And we are thinking always about how do we get to the point where we create really this decentralized compute platform where you have multiple networks being able to communicate between each other, and we are trying to be that glue by actually coordinating these jobs to happen on the same local network and allowing them to pass data around and in that way expand like all the possibilities that are able with decentralized component.
00:26:40.504 - 00:26:57.482, Speaker A: Well, in terms of scale, how do you think about scales? Obviously, one is number of networks that you are enabled on. The other is value of collateral locked. What are some metrics that you think about with regard to the latter?
00:26:57.648 - 00:27:19.422, Speaker B: Yeah, so we have thousands of providers right now, like we are looking at tens of thousands soon. And on average, when we onboard the provider, like usually we see the scale around ten petabytes and higher. So like those are kind of the numbers that we're talking about.
00:27:19.598 - 00:27:48.994, Speaker A: But in terms of help, help the audience who's not as familiar with filecoin and storage in terms of dollar value of lock, because I think that's really what you're, the metric that's kind of common that you can't, you know, you got petabytes of storage there, you've got GPU's with live peers, CPU's with fluent. Right. The common across all those is dollar of tokens locked to facilitate that. So how do you think about that as a value to go? Just to put numbers in people's heads here?
00:27:49.754 - 00:28:24.714, Speaker B: If you think about the liquidity required to onboard 100 petabytes of storage, that's around four to 5 million filecoin. Falcon is around $10 now. So like we are talking about 50 million Tvl just for 100 petabyte. Infrastructure for fluence. It's too early to say like the economy is new for the other networks, it's less aggressive than Falcon. So the liquidity is not as high. But yeah, we are talking about millions of dollars of TVL.
00:28:25.374 - 00:28:33.478, Speaker A: And you can see this easily going to tens of millions of TVL and hundreds of millions as these networks scale. Exciting.
00:28:33.606 - 00:29:28.394, Speaker B: The liquidity is going to be the thing that allows you to participate in these economies. So if you don't have the liquidity, you can be part of Falcon, you can't be part of Jansync, you can be part of fluence. You need that liquidity in order to be able to participate in these economies. Which basically goes to say, if you want to be part of the infrastructure of these open networks, you need to have abilities of locking the liquidity. And what we actually try to do on a very fundamental level is to allow any provider to participate in these networks as long as they can be efficient. Being efficient is very important for the entire sector, because all the inefficiencies that providers having Webtree at the end of the day are going to be absorbed by the stakers. And our objective is to keep everyone on the cutting edge of what's possible in terms of hardware and providing the resources so that the yield can be the highest possible.
00:29:29.374 - 00:29:37.102, Speaker A: And what type of yields do you think people are either getting now or do you think are sort of sustainable in these infrastructures?
00:29:37.278 - 00:30:02.514, Speaker B: Yeah. So the yield always depends on the mission of the tokens in these economies. So for example, the falcon. Yield for us is around 20%, but inflation on 20%. Yeah, Falcon, on Falcon. But inflation is around 25%. So we are basically passing almost everything back to the stickers because our providers are so lean and so efficient because they just do storage.
00:30:02.514 - 00:30:41.804, Speaker B: And the same way is going to be for the other networks. It really depends on how much inflation there is. And some networks require less inflation, some networks require more inflation. And that's also something that we are thinking more about in terms of how do we create something that allows new networks to know what kind of inflation they need to have in order to be participating on these providers? So not only supporting the networks that are out there, but also helping new teams that have never built a network before to bootstrap a sub network on top of the infrastructure that we have built.
00:30:42.264 - 00:30:56.644, Speaker A: Super interesting. Does web3 mine? Is it traditional business? Is it have a token coming or token model at some point? How do you think about your model in regards to everything, all the networks that you support?
00:30:56.944 - 00:31:46.190, Speaker B: Yeah, of course. We are an economy fundamentally, we think economies are a much better way of coordinating capital. Tell the way that our token works is that since we are capturing 10% of the rewards on all of these networks, our token is acting as an index token of the centralized deep end networks. Basically, if you are not sure what kind of network is going to be the hottest, you would just buy our token instead of trying to figure out each of these networks and what is the best network to have. On the other hand, we commit to never dump the tokens that are locked in our treasury. So we would not be managing the treasury. So this would basically be the perfect index token that exists because we would be just capturing the reward from each of these networks.
00:31:46.190 - 00:32:11.314, Speaker B: These teams would not have any sell pressure because this liquidity gets locked inside of our index token, and the only thing we care is just generating more of these tokens, because we just want to increase the position that we have in these economies and we just keep growing that. And the way we grow that is by optimizing how these jobs are executed on the hardware layer and just being more efficient and more meticulous on the tech side.
00:32:11.814 - 00:32:49.678, Speaker A: Super interesting. So, yeah, it becomes an index of this weighted index of the projects that deepen projects that you're integrated with, times the scale of each of those projects. So it's almost like a market cap weighted effectively of the deep in networks that you're involved with, which is super interesting. Well, let's back up. I'd like to do these things in reverse and get really deep, really fast and then back up and actually get into the person. So can you give a little bit of your background and how you got involved and kind of your journey to this entrepreneurial endeavor?
00:32:49.846 - 00:33:11.844, Speaker B: So I've been doing a bunch of mining back in 2012 13. I was doing litecoin back in the days. Like I was buying a bunch of GPU's and coordinating them. Then I got back into web two. I did two serves in web two and then got back in web3 in 2017. I started tenderly. Some people that develop smart contracts probably know about it.
00:33:11.844 - 00:33:46.200, Speaker B: Been doing that for two years. Then I joined Cardano. I led smart contracts for a year. Then I joined pro collabs, where I did a bunch of stuff around decentralized computing and thinking about validators like the economies associated with it, a bunch of defi integrations with the Ethereum side. And then we spinned out from protocol labs. We were one of the first big spin outs. And since then we were basically building a compute layer that aggregates a bunch of compute jobs from multiple networks and builds liquid staking on top of.
00:33:46.200 - 00:34:06.916, Speaker A: So, I mean, the way I think of your background as, you know, web3 native from the gate, out of the gates, right. You're like, pretty much from the beginning you were involved in the blockchain, crypto, web3 ecosystem, right? Pretty much out of the gate?
00:34:07.060 - 00:34:37.278, Speaker B: Yeah, yeah, kind of from 2013. It was super early back then. Like, the only sarp that actually got out from that period was coinmarketcap. Very few people remember it, but like, it was basically the website, the only website that was kind of useful back then. You had like mining pools and stuff like that. And then when I did Web tool, I actually did something that is more web free, but was kind of called web tool, which is offline social networks based on Bluetooth. So we would basically just beacon around, like low energy Bluetooth and we would figure out who is around you in a decentralized way.
00:34:37.278 - 00:35:23.088, Speaker B: So, like, you would not be online, like you just checking whether the Mac address of the Bluetooth device was actually there. The reason why we had to stop it is because Apple changed the way that they would broadcast Bluetooth, because people started spying on each other. So you would have molds actually spying on people just to understand who actually got in the mall. So the Mac address was not static anymore, but dynamic. I was always trying to make web3 work even before web3 was a term. I think Webtree as a term got forged back during 20, 1516 times when the Webtree foundation, led by parity was a thing, and then we started working on the standards. I think labs also contributed a bit back in those days, but.
00:35:23.088 - 00:35:26.816, Speaker B: Yeah, well, listen, you were web3.
00:35:26.840 - 00:35:56.902, Speaker A: Before web3, but that's only. You were also deep in before. It was deep in because you were Pl before Deepin existed as a name. Right. And file. PL is the company behind Filecoin, obviously, and that is the, you know, the found one, I guess the foundational project in this space in terms of timing and scale. Any experiences in you can draw on from your past that makes it that you're particularly relevant to your job now.
00:35:56.902 - 00:36:00.298, Speaker A: Anything you find yourself using a lot or not using.
00:36:00.466 - 00:36:43.944, Speaker B: Yeah, I think just being super, like pragmatic, not getting like hyped too much. Like ultimately everything that is suspicious probably has a reason. Like just focus on fundamentals, focus on economies, focus on things that make sense long term, and then play the game. Like you really need to understand, like how you're making decisions. Don't get super hyped on the markets because of course the markets are super aggressive, but if something is hot, it's probably too late. Just focus on the next thing. Probably even now there is the next thing that is coming, but everyone is kind of focused on the most loud thing out there.
00:36:43.944 - 00:37:18.148, Speaker B: And because of that noise, it's really hard to focus on these new things that are coming along. Ultimately, the difference is going to be made by the teams that have focused on dipping or anything else. Two years ago, one year ago, but not now. Now it's too late. There is too much noise and you would need to fight to assemble a team in a very noisy environment that doesn't go well. And usually whoever you get hard is there because of the hype. So as soon as the hype is over, the team is kind of broken and then you'll not really do much.
00:37:18.148 - 00:37:40.692, Speaker B: So just think about what's the next thing based on your understanding of the world and some fundamentals that you can really perceive yourself and then just double down on that. But the fundamentals need to be right and it's hard to make decisions in a particular moment that are just not backed by, like, everyone else.
00:37:40.868 - 00:38:00.954, Speaker A: Right. Listen, I mean, that, the way I think about that is you sort of find something you believe in and you have conviction in and you stick with it. And the market, you have to have faith that the market will come to you. And that's what's happened with fluence, obviously. At least, you know, we think so because we were in it before. Deepen was a thing, right? Deep in didn't exist. I talked to Doug from Livepeer.
00:38:00.954 - 00:38:41.432, Speaker A: They've been building that for seven years. And now with the GPU boom and video rendering skyrocketing, they think they're poised for something interesting, really interesting, and I hope they are, but they've stuck with this through a long, long period. So you obviously done the same thing being with PL and then starting this before even deepens started. Any, any. And I guess you sort of hit that a little bit. But anything that, you know, hasn't gone as expected with regard to, you know, web3, mine or anything else, I would think mistakes are. Mistakes are.
00:38:41.432 - 00:38:51.786, Speaker A: Everyone likes to talk about stuff that's gone right. Obviously, that's the easy and fun thing, but we always learn from the hard stuff and things we. Mistakes you made, any mistakes you can think of or things you got wrong?
00:38:51.930 - 00:40:01.882, Speaker B: Yeah, I mean, mainly, like, whenever we made mistakes is when we kind of spread ourselves too much on things that are not like super critical. So I would advise everyone to just focus on really understanding what the core value that you as a team is providing and just prioritize based on that and just forget everything else. Like, saying no is super important, especially in a market like crypto or deep in that is growing super fast and the noise is super high. So you'd be distracted all the time if you were thinking about the new hot thing. Just focus on fundamentals, focus on the core value that you can bring, and ultimately think about the space as a very collaborative space. So if you can enable someone else to do something instead of you doing that, something that's much higher value and much better incentives for everyone, and that would probably help you long term. But focus on the core value as a team and really define, like, what the lines are on what you want to do or what you would rather have someone else do, and then create the incentives accordingly and, like, enable other teams to do it.
00:40:01.882 - 00:40:52.490, Speaker B: There are like many smart people on this planet, and usually they don't have a good enough of understanding as you can have if you were, like, long enough in the space. So just enabling them is super powerful. Something that we did really well in the beginning is we did not want to hire people from crypto, but rather we hired really good engineers that had a good understanding of distributed systems and we gave them the problem. So we got a very fresh approach. So, like, all the engineering like, math that you'll see in the Ethereum space, none of that is relevant for someone to actually build if they are trying to build something new. But rather you just want to focus on distributed systems and really building good tech. I think that was one of the best decisions that we made.
00:40:52.490 - 00:41:26.464, Speaker B: Just get fresh minds that are really good and that want to build something new that also helps you align people on the value. It's not, oh, we are building this new thing, which is super hot. No, we are solving this problem because these guys that came from counter ecosystems don't even know it's hot. They just want to solve. And if you don't understand the problem, it's going to be super hard for people to be motivated intrinsically and it's also going to be super hard to keep the team around for the long term.
00:41:27.284 - 00:41:48.524, Speaker A: Listen, I agree with that fully, which is figure the problem and then the solution to it. The technology is a tool and a lot of people in this blockchain space start with the technology and then figure out how to deploy and implement that technology in somewhere as opposed to starting with a particular problem. So I grasp, I see that over and over again, as I'm sure you do.
00:41:48.684 - 00:42:10.854, Speaker B: Yeah, absolutely. And ultimately it ends up, I mean, ultimately the most important thing is thinking about technology as basically solving a problem. But the technology could be anything, so anything can be built. So if you talk to good engineers, they will always tell you anything can be built. Just give me the problem. Really. Reasoning from that perspective is essential.
00:42:10.854 - 00:42:30.594, Speaker B: It's not, oh, I want to build something in this ecosystem or this other, and then I have constraints. No, you can build anything. Let's solve the problem first. Then you can decide which part of the ecosystems you want to be part of based on some other criteria. But focusing on the problem and solving that problem with the right tools is the most important one.
00:42:31.294 - 00:42:44.406, Speaker A: Great. Tell me, in terms of solving problems, then, what other projects, protocols, what else out there in deep end do you find? Are you interested in what projects do you find interesting? What problems are getting solved?
00:42:44.550 - 00:44:03.778, Speaker B: Yeah, we are super excited about the work that Jensen is doing. We spoke with the team a few times and they're very fundamental, value based. So it's like they would really think about the entire stack of the problem and really think about all the pieces and how to tackle them. So we are super long on whatever they are doing. And I would say all the teams that are just focused on the formal primitives, how do we have machine learning workloads that can be deterministic? Because of course you have a bunch of optimizations that happen on the GPU side, so it's hard to make training that is deterministic and how do we think about spreading the data around a network and allowing a much bigger network of computer providers to be training network. Rather than how do we just pass the training of one small network to one provider? Let's think about these networks as big networks of resources and then think about how to spread across all the different jobs that need to be executed. Other than that, I think there is a bunch of stuff happening on optimization of the jobs that you want to execute on the provider.
00:44:03.778 - 00:44:05.774, Speaker B: That is going to be super important.
00:44:07.234 - 00:44:36.820, Speaker A: Just to back up for people. Jensen is a protocol for aggregating GPU's to train AI models. VUC was talking about the aggregation of those jobs to solve and to be employed on single model training. Right? Yeah, terrific. You know, love that team also. Great. Well, you know another, you can't, can't get out of a conversation on crypto without a prediction.
00:44:36.820 - 00:44:46.052, Speaker A: So, you know, December 31 of 2024, where do you, where do you see, let's pick bitcoin. Where do you see bitcoin end of.
00:44:46.068 - 00:44:49.624, Speaker B: This year in terms of price or.
00:44:50.924 - 00:44:54.700, Speaker A: Yeah, I mean, we got, we got to throw in. We got it. We got to put a stake down somewhere.
00:44:54.812 - 00:44:57.588, Speaker B: Yeah, I think it's too high. Like even this.
00:44:57.636 - 00:44:58.236, Speaker A: Too high?
00:44:58.340 - 00:45:37.628, Speaker B: Yeah, too high. Because what happens with these cycles is that a lot of noise get generated. Like, I see it kind of like every bull market is kind of cabal and like you just speed up everything and then like you let things happen. Like the deployment of capital happens and everything disappears and you actually let teams build stuff. I really enjoy more like the very slow times where I can actually build stuff. Then like this excitement that kind of gets everyone like super, super fast and like very think about the values of things.
00:45:37.796 - 00:45:52.664, Speaker A: This is coming from a guy who clearly doesn't have problem raising capital because that is not the average response. Well, I'll tell you, I don't think we've even begun the bull run. I think we're going to 200k in bitcoin by the end of the year. So that's my. I'll put it out there. We'll see.
00:45:53.734 - 00:46:00.874, Speaker B: I also think we are along those lines even higher and that's just too high. That speeds up my life by 20 x.
00:46:02.734 - 00:46:28.482, Speaker A: You want a quiet bear market? Get me back to the quiet bear, please. Yeah, fair enough. Well, listen, thanks so much for joining Vuc and, you know, it's great to see you and we'll be in touch. You only got one question wrong. Which was the projects you're most excited about. The right answer. There is fluence so we'll give you another chance in a couple of weeks to readdress that one, all right? Yeah, sure.
00:46:28.658 - 00:46:29.170, Speaker B: Awesome.
00:46:29.242 - 00:46:30.754, Speaker A: Thanks, fuk. I'll talk to you. Bye.

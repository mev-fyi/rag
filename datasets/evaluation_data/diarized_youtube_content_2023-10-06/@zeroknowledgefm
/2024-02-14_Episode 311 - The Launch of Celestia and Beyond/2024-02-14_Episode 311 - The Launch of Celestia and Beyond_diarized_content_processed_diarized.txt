00:00:05.450 - 00:00:49.962, Speaker A: Welcome to Zero Knowledge. I'm your host, Anna Rose. In this podcast, we will be exploring the latest in zero knowledge research and the decentralized web, as well as new paradigms that promise to change the way we interact and transact online. This week, Guillermo and I chat with Yaz and Ismail from Celestia. We discuss how the team prepared for the Celestia launch. We revisit DA, or data availability and then talk about how projects are using Celestia. Today we cover Blobstream and map out how a developer could tap into the Celestia da layer, and then we chat about community building, the modular narrative, and more.
00:00:49.962 - 00:01:07.986, Speaker A: Now before we kick off, I just want to remind you that the ZK summit Eleven is happening in Athens on April 10. This is an invite only event and space is limited. There's an application process to attend and you need to apply to be eligible for a ticket. I've added the link in the show notes, so I hope to see you there. Now Tanya will share a little bit.
00:01:08.008 - 00:01:54.770, Speaker B: About this week's sponsor Alio is a new layer one blockchain that achieves the programmability of Ethereum, the privacy of zcash, and the scalability of a rollup driven by a mission for a truly secure Internet. Alio has interwoven zero knowledge proofs into every facet of their stack, resulting in a vertically integrated layer one blockchain that's unparalleled in its approach. Alio is ZK by design. Dive into their programming language, Leo, and see what permissionless development looks like, offering boundless opportunities for developers and innovators to build ZK apps as Alio is gearing up for their main net launch in Q one. This is an invitation to be part of a transformational ZK journey. Dive deeper and discover more about alio@alio.org. And now here's our episode.
00:01:59.270 - 00:02:03.826, Speaker A: Today. We're here with Ismail and Yaz from Celestia. Welcome to the show.
00:02:03.928 - 00:02:05.330, Speaker C: Thank you for having us.
00:02:05.480 - 00:02:06.578, Speaker D: Thanks for having us.
00:02:06.664 - 00:02:43.200, Speaker A: And we have Guillermo as the co host for this one. Hey Guillermo, what's up? So we're very excited to have you on. We're going to be doing an episode revisiting Celestia. I want to do a quick throwback to a few previous episodes. A long time ago we had John Adler on the show talking about, I think, fuel and lazy ledger at the time, which developed into Celestia. Ismail, this is your second time on the show. We did an episode kind of introducing Celestia a little bit more and then last year I had an episode with Mustafa all about sovereign chains and sort of the sovereign roll up idea.
00:02:43.200 - 00:03:07.270, Speaker A: Today we're going to be doing a catch up on the project. What's really exciting is the project has since launched and obviously this is something I really want to cover with the two of you. Quick disclosure before we kick off, though. So the ZK validator is an investor and we're a validator also. That's a bit of a shout out. We're a validator. Yeah.
00:03:07.420 - 00:03:11.430, Speaker E: I guess I also should mention that bank capital crypto is also an investor in Celestia.
00:03:12.170 - 00:03:12.954, Speaker D: What is it called?
00:03:12.992 - 00:03:14.326, Speaker E: Investment warning. Investment.
00:03:14.438 - 00:03:17.066, Speaker A: This is not investment advice. There we go.
00:03:17.088 - 00:03:17.946, Speaker C: Thank you. That's what it is.
00:03:17.968 - 00:03:40.914, Speaker A: This is not investment advice. We're so good at that on this show. And actually, oh, I want to do one other shout out to another video that we did this past summer for the sovereign radio. I actually got a chance there to interview you as well. I'll add the links to all of these in the show notes, but I want to welcome you back. And I think for those listeners who are not familiar with those previous episodes or videos, why don't you quickly introduce yourself?
00:03:41.032 - 00:03:48.420, Speaker D: Hey, I'm Ismail Coffee and co founder and CTO of Celestial Labs. Yeah, that's me.
00:03:49.050 - 00:04:07.014, Speaker A: Easy. I guess if anyone wants to hear more of your backstory, they can check out the previous episode. Yaz, this is the first time you come on the show. We've actually worked together on a few different projects behind the scenes, but yeah, I'm excited to have you on the show for the first time. Do tell us a little bit about your background.
00:04:07.142 - 00:04:36.130, Speaker C: So, I'm Yaskuri, I'm the head of Devreau at Celestial Labs. Previously, before Celestia, I worked the protocol Devreau at solo for two years. And before that I've been at Ethereum plastic, believe it or not. Director of Devrel at Ethereum Plastic for a couple of years and I've done a few things here and there, like with flash bots, with the EEA, random stints here and there. But yeah, very happy to be here.
00:04:36.200 - 00:04:44.118, Speaker A: Very cool. So I met you, Yaz, when we worked on the plumo setup ceremony for sello in 2020 2021.
00:04:44.204 - 00:04:44.966, Speaker E: Let's go.
00:04:45.068 - 00:05:17.300, Speaker C: Yeah, that was really fun because I came to you with the idea about what if we live stream across the setup ceremony. And what I remember was there was a debate about doing it on a server, running the computation on a server versus locally, and I decided to do it locally while doing a live stream. And what I didn't realize at the time was when you do these computation, it kind of destroys your wifi. So while I'm live streaming, my Internet was cutting off.
00:05:20.230 - 00:05:46.502, Speaker A: Yeah, it's still a good experiment. I feel like since then we've mean. So last summer, ZK validator curated part of the modular summit. Like you and I have kind of talked a lot about events, so it's been fun working with you. So you've just kind of given us a bit of a background on what led you to Celestia. But what do you exactly do today at Celestia? You're saying Devrel, but I feel like your role is kind of broader somehow.
00:05:46.566 - 00:06:28.374, Speaker C: So I'm cursed with the experience of things outside of Devrel because not a lot of people can do them and stuff. So while I'm still doing Devrel stuff, I do a lot of things outside of that. That covers validators, it covers core developers, but yeah, from a high level. The way I structure Devreau at Celestia, there are multiple different teams. On Devreau, we have the solution engineering team that I manage currently. Now we're at four engineers, no, actually five right now on that team. And they tap into all kind of crazy stuff, right? Like integrations, like the op stack or the arbitrum integration with Celestia.
00:06:28.374 - 00:07:01.346, Speaker C: Now we're looking at ZK related kind of work streams. So I manage that team. There's also the developer advocacy and experience work stream where we focus a lot on documentation, tutorials and demo. Then we have programs. And that would be like the modular summit. Now we're scoping out soon to be announced later, a hackathon and all the events inside conferences that we support. And finally, validator relations.
00:07:01.346 - 00:07:44.910, Speaker C: So all validators that want to support the network and stuff, we work with them for coordination, network upgrades and hard work coordination. And obviously like Mainnet launch and. Yeah, I mean, we also do a lot of community related operations. And the main program there with core developers is what we call the Celestia improvement proposal process or the CIP process. It's kind of like the EIP, but it's based on the IETF standards for how do you create working groups when you're building technical specifications and implementations? So what I'm going to say is I barely sleep. Yes.
00:07:44.980 - 00:07:52.286, Speaker E: As the lead cad herder, open source CaD herder, I believe is a possible alternative title.
00:07:52.478 - 00:07:54.962, Speaker C: Yeah, I believe cat herding is an art.
00:07:55.016 - 00:07:57.954, Speaker E: Yeah, it's an art and a job.
00:07:58.072 - 00:07:59.862, Speaker C: Apparently, as we found out, it is.
00:07:59.916 - 00:08:07.480, Speaker D: I want to just add to this that we are extremely lucky to have Yaz. It's mind blowing to me how productive he is.
00:08:08.490 - 00:08:09.542, Speaker E: I love it.
00:08:09.676 - 00:08:30.574, Speaker A: Let's define Celestia for folks who aren't familiar with the project. I know that most of this episode is almost going to be like teasing out the nuances and talking about updates, but I think it's good to just set the scene. Obviously, Celestia is really well known. The term like DA or data availability in Celestia are very much intertwined. So how would you define the project today?
00:08:30.692 - 00:09:32.910, Speaker D: Yeah, Celestia is a data availability layer, and it's a live p to p network. So what is a data availability layer? So data availability is often confused with long term storage or data retrievability. But what it actually means is that in a blockchain, if you publish transactions, how is it guaranteed to the network, to the peer to peer network, that these transactions have been made available to the public? Like have been published to the network, essentially, and a data availability network. That's the main purpose of it. Like ensuring that everyone can verify that the transactions have been published and they, for a period of time can be downloaded from the network and can be executed such that you can verify the state of your decentralized application. There's two ways on how these decentralized applications can look like very generally speaking. One is through validity proofs.
00:09:32.910 - 00:10:01.690, Speaker D: You can, like via ZK proofs or cryptographic techniques, ensure that the state transitions that were made are actually valid. And the other approach is optimistic roll ups or optimistically via fraud proofs. So you just assume that the state is valid. And in case there has been any malicious state transition, you can prove that via so called state fraud proofs. And the data availability layer makes that possible.
00:10:01.840 - 00:10:07.534, Speaker A: This is sort of setting the stage with a definition on DA. But how do you define Celestia as a project today?
00:10:07.732 - 00:10:52.070, Speaker D: So Celestia as a project today is the live network and the community around it. It's a broad ecosystem of validators, node operators, and applications building on top. These applications benefit from low costs for data availability. There's a great variety of how these applications can look like. Most of them currently are somehow EVM focused, right? So they build on op stack for instance, or optimism stack, and they settle, for instance on arbitrum or optimism. So Ethereum L2s, but post their data instead of on Ethereum, they post it on Celestia.
00:10:52.150 - 00:10:52.502, Speaker A: Wow.
00:10:52.576 - 00:11:14.446, Speaker D: What we will see more and more, as I said, there's many approaches we will see more and more is also alternatives to that which could be sovereign rollups. Like think of them as their own chains that do not settle on an existing settlement layer, but instead are more like Cosmo zones that do not run their own consensus.
00:11:14.558 - 00:11:27.810, Speaker A: This is interesting to me. So where are the contracts actually deployed for these things? Do they not get deployed at all on Ethereum? L1, they do. They do. Okay. How does something like that work?
00:11:27.900 - 00:11:40.942, Speaker C: So the way it would work with like an op stack implementation is you deploy your op stack or arbitrum based roll up. L two, the smart contracts are still on Ethereum. Right?
00:11:40.996 - 00:11:41.262, Speaker A: Okay.
00:11:41.316 - 00:12:07.498, Speaker C: But you're submitting your blobs to know you're submitting them to Celestia. And what the Celestia validators do through blob stream is they attest to the data availability through a bridge back to Ethereum. There's a smart contract on Ethereum, like a litecoin implementation there, and the roll up itself will be sampling via that smart contract.
00:12:07.614 - 00:12:22.700, Speaker A: Okay, interesting. You just mentioned blobstream. We will have to come back to that because that's a whole, I don't know if you'd call it product or what exactly it is, but it's a thing in its own right. But yeah, this is super interesting.
00:12:23.070 - 00:12:34.990, Speaker E: I will warn that even the word blob is already delving into jargon territory. So maybe we should also define what that means. I will be the jargon warning person.
00:12:35.060 - 00:12:38.894, Speaker A: Oh good. Be the jargon decoder. I like that.
00:12:38.932 - 00:12:39.520, Speaker D: Yeah.
00:12:41.090 - 00:13:10.406, Speaker A: Before we do that though, before we talk blobstream jargon, I actually want to bring us out a little bit. So it sounds like Celestia is live today. We're already seeing it being used for real. Last time I talked about this on the show was with Mustafa and then it was very focused on sovereign chains and sort of the vision that he had. It looked a certain way. I want to talk to you about the launch and then actually what's happened since. So let's first start with the launch.
00:13:10.406 - 00:13:11.660, Speaker A: How did it go?
00:13:12.270 - 00:14:00.070, Speaker C: As the person, I coordinated launch in support with Ismail, with the core devs, with the community, with the validators and stuff. The best way I can describe launch, it was like a beautiful symphony and I would like the orchestrator, everyone was performing their musical instruments and I was like, validators, core developers, release the dogs. And it all went perfectly. It was actually a very boring launch. And the thing that I missed on launch because I built like a little dashboard to monitor the blocks from there was like a timer until launch. And then after that it shows you block production happening. So there was like, between block one and block two with like a 22nd block production.
00:14:00.070 - 00:14:33.074, Speaker C: And I kind of panic while looking at the dashboard. But the reason for that, the technical reason for that is because what the core devs told me is the network. We're building a topology, so there was going to be latency as the validators connected and stuff and start peering with each other. So that was kind of like expected. But then it went really smoothly. At one point, I think I was trying to take a photo block 420, but I missed it. I did go to Ismael and I was like, I think it went really well.
00:14:33.074 - 00:14:36.850, Speaker C: And Ismail is just like, smiling and just gave me a hug.
00:14:40.490 - 00:15:05.230, Speaker A: I love it. It was a lovely symphony. I mean, we did a launch party online just a few hours after, and I was surprised at how chill you guys were. You guys were just in a good mood. I mean, we had gone as a validator, we had seen and gone through some other launches that were definitely more difficult. Where something breaks, they have to halt the chain. We've seen some pretty chaotic ones.
00:15:05.230 - 00:15:06.910, Speaker A: Did you miss the chaos?
00:15:08.370 - 00:15:40.550, Speaker D: I certainly did not miss the chaos. I was very happy that went so smoothly. And what Yaz called it was a boring launch. I think that also means it was a lot of coordination that happened upfront and a lot of hard work with testnets and basically practicing a lot and making sure the software runs smoothly. I was hoping for a boring launch, and it went as or as it went even more smooth than I would have expected.
00:15:40.630 - 00:16:18.226, Speaker E: How did you guys test this stuff? I remember at some point someone recommended the idea of giving a bunch of core team developers raspberry pis and then trying to launch everything simultaneously as like a pre test run. And had that been like kind of like a CD method where you would distribute, you'd be like, all right, everyone pull. Let's start the chain on. A bunch of raspberry PI's sitting in someone's basement in different places in the world, but I don't know. How do you even kind of do continual testing on a large, decentralized network? Actually, out of curiosity, this is a very procedural question.
00:16:18.328 - 00:16:23.750, Speaker A: Isn't it an upgrade of a test net, though? Isn't there usually like a test net that they've decided is like the one.
00:16:23.900 - 00:17:16.518, Speaker D: We didn't do that that's very often the case, right? Like, very often chain launches today are like that, where basically you launch almost like in private, and it's a test net, essentially, and then someone decides, like, okay, this is stable enough and then it's public and then it's mainet. But what we did was slightly, not slightly, was very different in the sense that we assembled the Genesis file, we published that and the community agreed on it. There's a date set in the Genesis file. Like how technically works. There's literally just an if statement in the code that says like, oh, if it's Genesis time. If it's before Genesis time, just go to sleep. Like actual line of code that says like sleep until Genesis, basically.
00:17:16.518 - 00:17:40.400, Speaker D: And then with that moment kicking in, the chain went live. The peers, like the nodes look for other peers. That's the 20 seconds that Yaz mentioned. Then the chain was live. So there was no such period where it was coordinated in the background. It was like more real decentralized launch as much as possible, almost.
00:17:41.650 - 00:17:44.080, Speaker A: This is a bit of the OG way of doing.
00:17:44.850 - 00:17:48.174, Speaker D: I mean, for the Cosmos hub we did it very similarly.
00:17:48.302 - 00:17:53.810, Speaker A: Okay, why did you choose this way though? Why not do it from a testnet upgrade?
00:17:55.750 - 00:18:45.618, Speaker C: We did have four to five testnet, one of them being the block space race, that. The intention of the block space race was the incentivized Testnet program where we tested so many different things. And it mixed not only the validators, but also da nodes, like the light nodes, bridge nodes and the full nodes. And we had 1000 participants. And that allowed us to really stress test the first testnet that was designed for maintenance and that allowed us to update everything after. And then leading up to launch, I was coordinating with some decord apps and some people running validator like one testnet a week. And what we were doing was timing it.
00:18:45.618 - 00:19:08.774, Speaker C: Right. So you have five people participating. Each one has a role. Like we had a member from the DevOps team, a member from the celestial node or the DA team, a member from the core and app team that's running that consensus client. And then you have me. I don't know what I was doing there, but yeah, I was. And then you have Ismail.
00:19:08.774 - 00:19:37.294, Speaker C: Right. And what we did was basically there's several steps that need to happen, starting with what Ismail was know, you created the Genesis file, but prior to that you can create a small Genesis file. It doesn't matter what's on it as long as you specified that it has to start at a specific time in the future. And the future can be like in 30 minutes. Start in 30 minutes. Right. And then everyone started running their validator.
00:19:37.294 - 00:20:35.782, Speaker C: And then we monitor. Right. And then block production happened. It kicks off. But then there's a few other things that need to happen, right? Like the DA nodes have to make a public release that is compatible with mainnet because mainnet launches the consensus client, but then the DA side has to take the first block hash into their software and then they make a public and then you can start your light nodes and full storage node. And what's cool is when we're timing it, like one week before Mainnet launched, the DevOps team had this whole kind of system in place to time making that release for the DA side and deploying bootstrappers, explorers, everything just for testing. So after the first block production for the testnet, prior to release, they set things in motion and then they timed it.
00:20:35.782 - 00:20:51.100, Speaker C: And I think one of the team members had a stopwatch and we're like, how long did it take to deploy everything? And they're like 14 minutes. I'm like, all right, for main net launch, maybe you can do it under 10 minutes. They're like challenge accepted. And it was really fun.
00:20:51.410 - 00:21:05.230, Speaker A: That separation though, the fact that first you have the consensus, then you have this DA step, is that unique to Celestia and like a DA system or do all kind of regular blockchains have that happening under the hood?
00:21:05.310 - 00:21:28.390, Speaker C: No, because Celestia, you know, there's multiple layers, right? There's like the consensus and DA layer, but DA has to know what network is it sampling from. So it needs the client to first release on the consensus side before they make a public release for the DA side to start running DA nodes.
00:21:28.470 - 00:21:30.346, Speaker A: Wow, that's so interesting.
00:21:30.528 - 00:22:28.490, Speaker D: I think technically speaking it could be the case that if the binaries basically that run the particular networks, right, if they were one binary, I think the celestia node, basically the light client and the celestia node, full node, theoretically they could also do it without that delay initially. I mean the light clients is a different story because they need some subjective header to initialize and so it needs some block or some header need to have happened first. But for a full node, theoretically it could be that they run in parallel and it's not a necessary step. But the way we've implemented is it's more separated. We are thinking of doing our own merge in the sense that to merge these both networks, right. That's something that is considered, I think. I'm not sure if there's a cip for that yet, to be honest.
00:22:28.490 - 00:23:12.282, Speaker D: But there's definitely a consideration to make it a bit like from the UX, also a bit nicer for node operators to have only one binary, right, and also one peer to peer network. But that's just an implementation detail. It doesn't really matter. And I actually kind of like the separation, though I do think it would be nice if there was one peer to peer stack used only. Right? Like the separation itself is like, it's nice that things are so isolated in the sense that if there's a bug in the DA layer, it doesn't trickle down to the consensus layer at all and vice versa. But if the consensus layer breaks down, no blocks are produced and the DA layer is kind of pointless. But it has its benefits.
00:23:12.282 - 00:23:24.558, Speaker D: But I think from the UX perspective, for node operators it would be neat if it was a bit more tightly coupled, just a tiny bit. And I think there's teams working on that.
00:23:24.724 - 00:23:46.806, Speaker A: When you launched, was there any roll ups ready to go or was it sort of like launch wait, get roll up deployment? I was kind of curious about that. If the system sort of like, and the larger picture of it with these roll ups kind of branched off it were there from the start or did you actually have to run it a while before they deployed just to be.
00:23:46.828 - 00:24:35.878, Speaker D: Sure they could have deployed immediately. I think maybe out of caution people didn't in the first week or something, but it's a permissionless system. People could have with block one started deploying roll ups. And it is something that could have happened because on these many testnets that there were live, I think there were like, even as Mainet beta was launched, there were three test nets running in parallel with various deployments. One of them was like dimension with, I don't know, I think like 10,000 applications running on top like a bunch of smaller games and stuff. So it could have been, right? It could have been. But most of these roll ups were getting ready themselves.
00:24:35.878 - 00:24:47.670, Speaker D: Most of these roll ups had testnets themselves and I think most of them waited for a few weeks before they started posting blobs or data onto celestial.
00:24:48.090 - 00:25:21.970, Speaker C: The requirement for deploying from Testnet to mainnet requires a lot of legwork. That's not necessarily technical and stuff, but it does require a lot of kind of management and organization from within those roll up teams. Right. So it wasn't like, yeah, I mean like Ismail said, it was permissionless. You can immediately deploy if you wish to, but there's a lot of coordination and a lot know things that you got to do prior to do an official launch. Right. Which is why a lot of them existed on Testnet, because they just wanted testing at the same time.
00:25:21.970 - 00:25:34.600, Speaker C: It's kind of a good thing nobody launched at the first week, for the first week, we just want to see stable block production. We just want to monitor the network, we want to see that the DA layer is sampling and all of that stuff.
00:25:35.050 - 00:26:21.638, Speaker A: I feel like this leads us a little bit to the question of blobstream and kind of introducing what that is, because on that launch day we talked about it, but I still don't really know what to call it. I don't know if it's like an initiative or a product or roll up itself. I don't know exactly what it is. So you launched a few weeks later or soon after, you had a few roll ups happening at this. Joining that, by the way, is very much the picture that Mustafa had kind of described in our interview, like that sovereign chains and that sort of model. But then, yeah, let's talk about blobstream, because I feel like that kind of changes that picture a little bit, at least for me. And maybe I don't understand it, right, but yeah, what is blobstream? Let's start there and tell me if it.
00:26:21.638 - 00:26:25.830, Speaker A: Is it a roll up? Is it a product? Is it an initiative?
00:26:26.970 - 00:26:32.140, Speaker D: It's not a roll up. It's a kind of philosophical question. If it's a product, I would say yes.
00:26:35.630 - 00:26:38.774, Speaker E: Let's define the type of the object I think is what Anna's.
00:26:38.822 - 00:27:01.758, Speaker D: Is it a movement? It's also kind of an initiative in the sense that someone needs to deploy a smart contract for it to work on Ethereum. And validators need to start running what is called a relayer or orchestrator that actually posts data attestations to Ethereum, to that smart contract to digest.
00:27:01.934 - 00:27:05.394, Speaker A: So it's not a roll up, okay, that's clear.
00:27:05.592 - 00:28:12.774, Speaker D: So what you could think of from a very high level perspective, what you could think of, or a good analogy, is like a one way bridge from Celestia to Ethereum. And the only purpose of that bridge is to relay attestations, basically signatures of the validators to Ethereum that they attached to this data. This data route was published to the network. That's a very simple primitive. And for that you need these smart contracts to digest these attestations. And then the purpose of it is that applications deployed on Ethereum can then L2s, layer threes on Ethereum can then post their data onto celestia and get an attestation back on Ethereum that this data was published on celestial. And then they can use Ethereum or a layer above Ethereum for its arbitrum directly or optimism or any L2 on top of Ethereum can use that for settlement.
00:28:12.774 - 00:28:46.070, Speaker D: So they have that for bridging for state fraud proofs or for validity proofs. They can use their settlement layer as before. Either that's Ethereum or L2 on top of Ethereum, but they can now post their data instead of posting it on Ethereum, which is expensive, or on the regular settlement layer, which could still be more expensive. They can now post that data on celestia directly and sort of like into call data into the dedicated EVM, either the layer one or L2.
00:28:46.220 - 00:28:46.966, Speaker C: Right.
00:28:47.148 - 00:29:01.498, Speaker A: I want to break this down into these pieces if I can. So in this case, the Ethereum l one is the consensus. It's the smart contract platform where the smart contract is deployed. Right.
00:29:01.584 - 00:29:02.726, Speaker C: It's just settlement.
00:29:02.838 - 00:29:19.838, Speaker A: I thought the l two was settlement. I want to understand. Help me with this. Where's the consensus? Where's the settlement? Where's the Da happening? That's like the kind of. Because I feel like they're being split, right?
00:29:19.924 - 00:29:27.850, Speaker C: Yeah, the DA and the consensus is on Celestia. The settlement is on Ethereum, and the execution is on that L2.
00:29:27.940 - 00:29:49.430, Speaker A: Oh, wow. Okay. So this goes back, by the way, to that original example you gave with the op stack, because you had said l two for settlement, but you're saying, like, the execution of the settlement happens on the l two, but the l one is the settlement layer still. Okay, I didn't realize that consensus and Da go over to Celestia.
00:29:49.590 - 00:30:00.474, Speaker D: I have to add one more thing. It's consensus and Da only for the data of that application or chain. It is not for the state.
00:30:00.672 - 00:30:05.194, Speaker A: Yeah. So the consensus for the state remains on.
00:30:05.392 - 00:30:05.814, Speaker C: Yeah.
00:30:05.872 - 00:30:10.398, Speaker D: On Ethereum or on the settlement layer. That application uses to be more general.
00:30:10.564 - 00:30:31.270, Speaker A: Wow. See, this is where it's so fascinating. Like these parts that we've understood. So I've always thought of it as three parts, but it sounds like it's actually four. It's like consensus for Da, consensus for state, da and settlement. Wow.
00:30:31.340 - 00:30:32.054, Speaker C: Yeah. Maybe.
00:30:32.092 - 00:31:04.450, Speaker E: Let's disambiguate. Right. Blobstream is. I think that maybe here's another way of describing it that may also be useful, is simply a way for Ethereum, or I guess any smart contract chain doesn't really matter, to verify that a particular piece of state is available to everybody. So the way we do generally is like, you have some light client. This is also similarly a question, so feel free to correct me if I am wrong at any point. Nominally, you have a light client and you're like, I want to check if a piece of data has been posted to Celestia.
00:31:04.450 - 00:31:53.994, Speaker E: And then you can create, you can certify that that is the case. And if not, you could, whatever, do some slashing. That's big brain. But the point is, the problem is that requires you run a lite client in your computer, but you want to use the power of the magical Internet computer that we call Ethereum to verify that a piece of data has been posted instead. Right? So us to not require anybody else to have this other secondary network that is verifying whether something is posted. And so this blob stream is like one way of being like, great, there is a contract on Ethereum and you can say, I promise you I posted this data. And then you simply say, and if you don't believe me, I will post this particular station to Ethereum and then it will indeed certify that I have posted the data more broadly.
00:31:53.994 - 00:32:09.070, Speaker E: And if you trust Ethereum security, then you must trust that I have posted the data in the first place. And so of course that has a bunch of applications. This can be used to just remove the data piece from the l two and simply post it on Celestia.
00:32:09.230 - 00:32:09.554, Speaker C: Right?
00:32:09.592 - 00:32:33.306, Speaker E: So now we have, now we have removed one part that we often need to deal with, which is posting data to either Ethereum or some other, essentially making data available. We have now removed that task and given to Celestia in a verifiable way, in a way that you can indeed certify that. Here you go. The data that I promised would be available is available. And you don't have to trust anyone other than essentially like Ethereum for that.
00:32:33.328 - 00:32:33.950, Speaker D: To be the case.
00:32:34.020 - 00:32:35.406, Speaker E: Is that roughly correct?
00:32:35.588 - 00:33:27.310, Speaker C: No, that's very accurate. But to add to it, why would anyone want to do that? Why would you want to start modularizing, moving components around and stuff? It's kind of like Lego pieces. But the biggest benefit is this is how you scale Ethereum, right? Because now L2s on Ethereum have way cheaper transaction costs because they have a really cheap da layer they can submit their blocks to and they can verify that it's been attested to on Ethereum. And that gives them a lot of superpowers where now you can deploy a roll up on Ethereum and not worry about cost anymore because you have a DA network that makes it really cheap for you to send your transaction to do.
00:33:27.460 - 00:33:44.494, Speaker A: When you talk about sort of the official, like making it cheaper, a lot of times my mind goes to, but weren't l two s invented to make things cheaper? Aren't they themselves supposed to just make it cheaper. Or are you making it cheaper for l two s to exist?
00:33:44.622 - 00:34:41.270, Speaker C: I mean, I can answer that question because there's multiple layers based on what Celestia solved originally and based on what was the roll up centric roadmap that Ethereum went through based on Celestia's vision, but still had problem without a DA layer. So I'll break it down into from the roll up side. From the roll up side. The idea that you can just deploy a roll up on Ethereum with no cheap da doesn't scale Ethereum, because what happens is, let's say it's a really successful roll up, right? It has some fun games. There are some, I don't know, nfds, whatever the cool kids are introduced is, right? That will create a lot of adoption, right? There'll be a lot of adoption on it. So what happens when you have a lot of adoption? You'll have a lot of high transaction costs, and that doesn't solve the problem of scaling because you still end up where you started, where like, well, things are really expensive. What do I do now? Well, maybe there's another roll up that I can go to.
00:34:41.270 - 00:34:49.646, Speaker C: You go to the other roll up, same thing. It's another chain that the more users, the more transaction there are, the more expensive it becomes.
00:34:49.698 - 00:35:07.086, Speaker A: Do they just get filled up? Almost when they're empty they're really cheap. But the more action, they kind of just catch up to the l one in terms of exactly gas fees. It's gas fees, right, for the user, they're noticing. Oh, actually it's not cheaper on this.
00:35:07.108 - 00:35:09.680, Speaker C: L two anymore because there's demand, right?
00:35:10.050 - 00:35:51.790, Speaker D: Might still be cheaper. As if they would deploy directly, completely on Ethereum. Like it might still be cheaper on that l two. But as Zia said, once that l two or like once that roll up on Ethereum gets really popular, you compete again for data and state on that layer as well. So I think the key point here is specialization, because if you have one layer that only does data, basically, like only does one thing, it ensures the data was published and the data is ordered. So there's consensus on the data, then there's no competition between state execution and that on that layer. So it's highly specialized and can optimize for exactly that use case.
00:35:51.790 - 00:35:57.146, Speaker D: And the applications on top can focus on speeding up the execution.
00:35:57.258 - 00:36:31.278, Speaker E: So fundamentally what happens with l two s is they become more congested. At the end of the day, what happens on the l two has to be posted somewhere, right? And if you are simply on Ethereum, all you're doing is you're just passing the storage cost down to Ethereum, but that's still going to cost you the same as if you were doing the thing on Ethereum, at least for storage, maybe not for compute. You could be running much faster, fancier, bigger computers. But for storage, you're still storing the same data that you were storing previously, like on Ethereum. And so that cost is always going to get passed back to you after enough usage.
00:36:31.394 - 00:36:50.842, Speaker A: This was the thing that's done by the l two itself, right? Like, this is the l two smart contracts, like writing to the main chain, those check in points that, I mean, we've covered. I covered this years ago when we did a series on l two s. So is it those pieces then? Is it that writing to the main chain that gets moved over to Celestia?
00:36:50.986 - 00:37:19.426, Speaker C: Not exactly. Because if Celestia were just another settlement layer in a different world, right, it doesn't solve that problem either. But what Celeste solved from a high level problem is what we call the big block problem, which basically solving the blockchain trilemma, which, if I remember correctly, it's like the trilemma includes. It's a triangle with security, decentralization, and, I think, network uptime. Correct me if I'm wrong. Anyone? I think that might be it.
00:37:19.468 - 00:37:21.082, Speaker A: There's so many trilemmas out there.
00:37:21.136 - 00:37:21.450, Speaker C: Yeah.
00:37:21.520 - 00:37:24.746, Speaker A: Sometimes privacy is on a corner, so I don't know.
00:37:24.928 - 00:37:34.300, Speaker E: Yeah, at this point, it's like a 6d simplex in some space with, like, 70 million faces, and you can pick any triangle you want out of it or whatever.
00:37:34.670 - 00:37:36.010, Speaker C: There's a lot of dilemmas.
00:37:36.090 - 00:37:38.910, Speaker A: But the one you mentioned, we can go with that one.
00:37:39.060 - 00:38:16.970, Speaker C: Yeah, let's go with that one. So basically, it's the big block problem, which is for a long time, you can see a lot of smart people can come into the space criticizing crypto and be like, well, if your problem is high transaction costs, why don't you just increase the block? Right? Like Elon Musk talking about dogecoin or know. And it's. I mean, don't you think we never thought of that, right. We can just increase the block and stuff. But the problem with the big block is if you increase the block side, you centralize the network because the cost of running a node exponentially increases. Right.
00:38:16.970 - 00:39:11.186, Speaker C: And what Celestia solved there is allows you to increase the block size while keeping the network decentralized. And that is through what we call data variability sampling, where sampling from a high level, I mean, I can give an example of it later, but like a really simple example, but from a high level, allows a light node to download less or sample less than 1% of a block to get 99.99% certainty about what is included in that block. Right. So in a way, the way that we could provide CDA for these roll ups is because if the blocks increase and they start getting filled, we can increase the block size as long as people are running and people are incentivized to run light nodes in order to ensure that we can continuously sample the blocks while keeping the network decentralized.
00:39:11.318 - 00:39:39.878, Speaker A: Cool. And I think this also speaks very much to the modular thesis, modular vision that you guys have been pioneering, where you're not just making the block bigger. It's not like this kind of unsophisticated slapping a bandaid on something you're kind of dissecting out and then sampling, trying to reduce it so that it's still correct without just bloating it. It's really interesting.
00:39:40.044 - 00:39:40.614, Speaker C: Yeah.
00:39:40.732 - 00:40:34.774, Speaker A: Okay. I think we have a bit of a better sense for Blobstream now. Although I have one last question about blobstream again, we're kind of like my original concept, and the original thing we talked about with Mustafa had Celestia as not the settlement layer, but definitely like the center of roll ups here, Celestia is interacting with another existing chain. And so it's really providing DA, but it's not providing some of the other things it would do for sovereign roll ups. For example, it sounds like you sort of said it's sort of a product, but is it a set of smart contracts that you've developed? Is it like something that if an app developer living on an l two could deploy themselves on Ethereum and that's what that is? Is that sort of the product is just like a collection of smart contracts on Ethereum that interact with Celestia? Or is it more than that?
00:40:34.892 - 00:41:19.350, Speaker D: In terms of software, it's mostly the smart contracts. But also there needs to be one component in celestia that posts these data attestations to Ethereum. Okay, we developed that last year, but there's also a team susint that developed a ZK version of that much better suited for this podcast. It's basically an optimization that it proves succinctly the consensus that was achieved on Celestial. Right. Like then, instead of the smart contract posting all the signatures and being also somewhat expensive, you can have post approved and that can be verified on Ethereum. Essentially.
00:41:20.170 - 00:41:21.478, Speaker A: What's the name of that team?
00:41:21.564 - 00:41:22.162, Speaker E: Succinct.
00:41:22.226 - 00:41:22.914, Speaker A: Oh, succinct.
00:41:22.962 - 00:41:24.454, Speaker E: Yeah, you've had them on that.
00:41:24.492 - 00:41:24.854, Speaker D: Great team.
00:41:24.892 - 00:41:27.430, Speaker A: Oh, yeah. Wait, it's Blobstream X, right?
00:41:27.500 - 00:41:27.974, Speaker D: Exactly.
00:41:28.092 - 00:41:30.200, Speaker A: Yes. Okay. I'm familiar with this.
00:41:32.110 - 00:41:46.510, Speaker D: The name is Blobstream X, but it's essentially the same product. From a product perspective, it's exactly the same thing, because for the user, it doesn't matter if it ZK proof or it's like an optimized version of Blobstream, basically.
00:41:46.660 - 00:42:12.850, Speaker A: I see. I have a kind of random question that may be very quick to answer, but do sequencers of L two s ever interact with Celestia or a Da layer? The way that I've understood everything you described with? Like, I thought it was more like the app developer use, like an app on an L two that's actually using this da. Or are you interacting with sequencers differently?
00:42:12.930 - 00:42:51.714, Speaker C: I mean, one way to look at it like a model is the sequencer. Interacting with Celestia is kind of like, in a way, if you want to abstract it, the roll up. Interacting with Celestia. So the developer in that case is a roll up developer that's deploying a roll up, right, and that's interacting with Celestia. It's kind of like, if you look at the cloud computing model, like, if I'm deploying an application on AWS or Google Cloud or whatever, in this case is Celeste, we're providing infrastructure for that roll up, right. But from a user perspective, they don't really need to interact with Celeste. They're interacting with that roll up.
00:42:51.714 - 00:43:03.074, Speaker C: Like, that roll up could be application specific or something, but they don't necessarily interact with Celestia directly. They can if they want to, but it depends on the kind of user.
00:43:03.202 - 00:43:32.960, Speaker A: I think, what you're saying, though, in that case. So this does go back to another conversation ismail, you and I had, which was this idea that the roll up is the app that sort of, like lots of roll ups. Each one is an app. But I had this. I mean, when I say DaP or I'm actually thinking of, like, a lending protocol or something, that is not a roll up. It's used to being deployed as a smart contract in an EVM environment. So it could be doing that on an l two.
00:43:32.960 - 00:43:41.086, Speaker A: It's not creating its own roll up. In that case, would that app deployment actually be interacting with Celestia?
00:43:41.198 - 00:43:49.746, Speaker E: Maybe we could think about it in some layers, right, where it's like you have the l two, and then on top of it are a bunch of apps, and the l two itself interacts with Celestia.
00:43:49.858 - 00:43:53.960, Speaker A: Okay. Right. So the apps on top of the l two do not.
00:43:54.570 - 00:43:58.120, Speaker E: They do, but through the l two directly. Right.
00:43:59.210 - 00:44:29.922, Speaker A: They're not deploying the contracts themselves. And I think this just. So just to go back a little bit, to rewind a little bit into this conversation, I think there was a moment where I was thinking more on that level, and this is a good clarification, that when you talk about an application on Ethereum, those smart contracts, those are always going to be roll ups. So sequencers, they're not going to be like the lending app or something, unless they want their own roll up, I guess.
00:44:29.976 - 00:44:56.486, Speaker D: Exactly. But there are also almost like layer threes on top of L2s these days. Right. And these are more like their own chain, but they use DL to have quick access to that ecosystem of applications. Right. Maybe I'm confusing you more now, but they could also interact directly with Celestial.
00:44:56.598 - 00:44:57.878, Speaker E: The rabbit hole goes deep.
00:44:57.974 - 00:46:09.860, Speaker D: The answer, unfortunately, always is it depends how people use the stack. Right. I think for a smart contract living on, let's say, optimism or arbitrum directly, of course, the DAP developer does not need to interact or care about Celestia. But if you want to deploy more of layer three on top, which I think all these big roll up ecosystems now offer in various ways, then you could post your data directly on Celestia as well. If it's something you, as a DAP developer need to care about, I doubt it. I think you take something off the shelf that has like Celestia integrated, like the solutions team that Yaz mentioned is working on that, and then they would write their DAP, launch their roll up in a roll up or like layer three or whatever it's called, then their app wouldn't need to care about, but they would make a choice. Okay, I want to post my data on this data availability layer or that data availability layer, right.
00:46:10.230 - 00:46:17.782, Speaker C: What I want to do is also contextualize what Ismael's saying on the it depends part. So that's kind of like the whole thesis around celestial, right?
00:46:17.836 - 00:46:18.354, Speaker A: It depends.
00:46:18.402 - 00:46:52.400, Speaker C: So modular that you can. And then when people ask us, well, what can you do with it? And you're like, build whatever, because you have so much option. It's actually very liberating. You have developer choice first, whether you want to deploy your own roll up for your whatever NFD kind of application, or you want to deploy an NFT application on an existing roll up or any other kind of structure that you want, it depends on what you want to do, right? And this is why we say build whatever.
00:46:53.090 - 00:47:43.886, Speaker D: So we're basically adding more to the right. Like there's more choices you can do in the sense like how much you care, for instance, about upgradability and sovereignty of your application. That I think is something that is a bit underrated right now. People might not care enough about it right now, but it is an actual decision. For instance, if you deploy directly on Ethereum, you adhere to the fork choice rules of Ethereum and everything, right? And if you're completely own Cosmos zone, you're completely sovereign, right? But then you have this own consensus and other trade offs like Celestia basically enables you to not have your own consensus, but at the same time, it still enables you to choose between different layers of sovereignty or tapping into existing.
00:47:43.918 - 00:48:05.206, Speaker A: Ecosystems if you can tap into different settlement layers, because I do remember that the settlement layer is definitely separated. Like, celestia is not providing that. But back then there was conversation about a potential settlement layer for the sovereign chains. Is that still on the roadmap? Is that still something that people want to do?
00:48:05.308 - 00:48:57.400, Speaker D: I think there's at least two teams, or maybe even three teams that I'm aware of that want to build a settlement layer on top of celestia. So it's not enshrined. So it's like, not that we would add a general purpose execution environment on Celestia, and then people would deploy their smart contracts there directly, but instead it's like using Celestia for data availability. But there's a settlement layer on top, like that settlement layer just uses celestia, or the applications on top of that settlement layer use lestia, either directly or indirectly, you have the choice. So I'm aware of two teams, if not three. I'm not sure if the third team decided yet, but there are certainly people working on that.
00:48:58.090 - 00:49:43.240, Speaker E: Here's maybe a fair summary. Celestia, it is a useful primitive to build things on top of. And of course, that might involve many, many things that we haven't even thought about quite yet, which allows you to essentially choose somewhere along the spectrum of you could build on Ethereum, and that means that you are bound by the laws set by God. I mean, Vitalik. Sorry, I mean Ethereum as the ones that are true. There is the other end of a spectrum which, like, all right, just get good and build your own chain and just do all of the things that you have to do, do all of the chain things, quote, unquote. And now there's kind of an interesting middle, which says, okay, great.
00:49:43.240 - 00:50:17.922, Speaker E: You can have kind of a weird mix of the two where you have this in between state that is kind of given to you by Celeste and says, great, you can build part of the chain, for example, in this case, like logic rules for state transition. So when is a block valid or something like that? And then we'll take care of one of the parts of building a blockchain for you, which is data availability. You can think about it as like a weird, like, okay, now, somewhere in the middle of a spectrum and a spectrum might have many dimensions. You now lie here, right?
00:50:18.056 - 00:50:18.354, Speaker C: Yeah.
00:50:18.392 - 00:50:21.250, Speaker D: And that middle is also a spectrum.
00:50:21.590 - 00:50:22.290, Speaker C: That's right.
00:50:22.360 - 00:50:23.394, Speaker E: In itself as well.
00:50:23.432 - 00:50:24.020, Speaker A: Correct.
00:50:25.990 - 00:50:31.634, Speaker E: And a trilama and a six dimensional simplex of triangles.
00:50:31.682 - 00:50:35.960, Speaker A: We should get a graphic designer in on this one. Man, I want to see this.
00:50:37.930 - 00:51:13.454, Speaker D: I just wanted to add that while it sounds complicated, it's actually quite simple. Right. While you have the choices, it's only you have to make them when you care about them, and then you have the freedom to choose. But you don't always have to choose, right. I think it's also part of the Devrels team or solutions engineering team. And to work towards good dev Ux. I mean, it's not only their responsibility, it's also like teams, external teams are building infrastructure such that you don't have to make these choices.
00:51:13.454 - 00:51:56.580, Speaker D: So there's defaults and you can just click deploy and done. But if you want to, you can choose all the layers and use it as if it was like legos. Or you can use something off the shelf and only add a tiny bit that you care about, you as a developer, you as a community, or you as a Dap developer. That part that you care about. How much sovereignty do I want? Do I care about Ethereum as the settlement layer? All these choices, you only have to do them if you want to, right? That's the goal, is there's only very good defaults, very good dev Ux, and you can also just deploy whatever you want.
00:51:57.350 - 00:52:23.450, Speaker A: I just realized I don't actually understand. I don't think we've talked about what are the fees for using this for Celestia as a layer? Like, I'm guessing there is still some fee. And how does that actually get paid? Like, who receives it? If you're kind of living partly on Ethereum, but you're using Celestia's DA, how does that payment happen?
00:52:23.600 - 00:52:24.730, Speaker D: It depends.
00:52:25.070 - 00:52:28.060, Speaker A: Oh, my God, you're killing me.
00:52:31.010 - 00:53:01.442, Speaker D: But whoever posts the data on Celestia pays the fee, right? And that can be the sequencer, could be the user, right? Like if the user directly submits the transaction, which is possible, right? Like it's a base rollups. In base rollups, you always submit blocks or transactions directly onto the data availability layer. So it honestly depends who that party is. But the party that posts the data on Celestia pays the fee.
00:53:01.506 - 00:53:08.886, Speaker A: Okay. When you sample, when you do the sampling, is there any sort of payment there as well? It's just the posting.
00:53:08.998 - 00:53:10.358, Speaker D: Yeah, it's just the posting.
00:53:10.454 - 00:53:11.002, Speaker A: Okay.
00:53:11.136 - 00:53:49.282, Speaker E: So it also has an interesting set of mechanics, which is that storage is priced separately from whatever compute, for example. Right? Like the person who's storing has to pay a value to celestia, which is totally independent of the value that someone pays for the compute that needs to be done on the data, for example. So I don't know. I mean, this is kind of interesting. It's also similarly how you've disambiguated resources. They've also disambiguated their pricing, which leads to kind of interesting downstream consequences, I assume. I actually don't know how l two s are going to deal with this for the end user.
00:53:49.282 - 00:53:53.960, Speaker E: I don't actually know what this looks like. Maybe they're just shown some aggregated price or something.
00:53:54.330 - 00:54:14.300, Speaker D: I think it's just the actual sequencers that pay the fees currently. Right. Their users do not interact currently with the data availability layer. I don't know if there's like a based roll up deployed currently. Like maybe yas, you know, I'm not sure.
00:54:15.470 - 00:54:42.390, Speaker C: Me and the Dev wells, we hacked on something, but it's just like for fun, like a simple base roll up in Russ, but it's not ready. It's just like a hackathon kind of project. But yeah, base roll up would be like an example of a roll up that interacts directly from a user point of view with Celestia.
00:54:43.050 - 00:55:01.758, Speaker E: Yeah, what I mean is that the sequencer itself needs to charge the user enough for whatever state they are touching or whatever data they're touching. But in some sense for the sequencer, the data cost is disambiguated from the computation cost.
00:55:01.924 - 00:55:02.846, Speaker D: Absolutely correct.
00:55:02.948 - 00:55:03.978, Speaker E: Put on Ethereum.
00:55:04.074 - 00:55:32.274, Speaker D: Yeah, that's correct. I think how the applications that are currently deployed handle this is most of these protocols either have a token or some business model, and they don't ask the user to pay the fees directly. Instead they pay the fees and their protocol revenue is generated in their native token or however. And that's how the paying of the fees is subsidized.
00:55:32.322 - 00:56:13.810, Speaker E: So to say, right, the sequencer as it earns money. Essentially part of that is set aside to deal with separate fees from Celestian. Similarly separate fees from whatever, say it's an l two. So whatever the fees that you knew that the L1 would charge for whatever service it's providing. So, yeah, it's kind of interesting. I mean, it also foreshadows all of this crazy stuff that's happening with EIP 4844 and all of this, any number of Ethereum initiatives in this vein. So it's an interesting set of consequences that are downstream of having two separate services for each of these.
00:56:13.880 - 00:56:35.210, Speaker A: I kind of want to expand on the modular stack. In a way, I think you guys pioneered that idea and that narrative. But are there additional pieces of the process? Like, we've already talked about consensus NDA and settlement execution state? So are there other things that you think could be pulled apart in the future?
00:56:35.360 - 00:57:04.260, Speaker C: Guillermo and I and Mustafa, we actually kind of brainstormed a modular p to p network over dinner in London, if you remember. That was a really fun conversation. But I thought it was really because peer to peer as a network itself is like different nodes peering with different nodes. It's not really structured in a way. It doesn't have to relate to celestia necessarily, but just in general, how nodes communicate with each other could be really improved and stuff.
00:57:04.810 - 00:57:05.606, Speaker A: Interesting.
00:57:05.788 - 00:57:11.720, Speaker C: Seeing more modularization or improvements on the peer to peer stack would be really cool.
00:57:12.890 - 00:57:50.994, Speaker A: I want to talk about the process because you kind of compared it to the EIP process. This is the way that celestia changes. I guess the reason I wanted to bring it up is, I think depending on how far along you are with that process, it sort of gives us a sense for how far along you are in kind of like decentralizing the power and giving it to the community to make those decisions. The network launched, what is it, like Halloween three months ago? Yeah. So it's still pretty fresh. Oh, yeah, Halloween. We didn't dress up.
00:57:50.994 - 00:57:55.494, Speaker A: It was very silly, but we thought.
00:57:55.532 - 00:57:58.950, Speaker D: About it was not that boring.
00:58:02.410 - 00:58:11.562, Speaker A: But are people already using the CIP process? Is this something that actually. Is it CIP process? Or am I saying process process?
00:58:11.696 - 00:58:15.498, Speaker C: No. Celestial improvement proposal process.
00:58:15.584 - 00:58:28.478, Speaker A: Okay, fine. Good. But can one already do that, or are you sort of just in the process of process process? Are you just in the moment where you're actually building that system?
00:58:28.644 - 00:59:20.190, Speaker C: The CIP process as it exists today, definitely get going better than I expected and stuff. I'm actually surprised in the sense that the question is about do we have external core developer teams participating in the process. Yes, absolutely. So currently there are four working groups, right? There's the main one for core and consensus, and that's where we have the core developer call, and people can watch it live on YouTube. When we have those meetings, they're very transparent and stuff. And this is what goes around all the specifications that goes into Celestia, at least from a consensus point of view. If we want to activate a hard work, to activate those features, and introducing the concept of rough consensus, which exists in the EIP process, it exists in the PEP process.
00:59:20.190 - 00:59:57.590, Speaker C: For Python, it existed. It's like a passing of the torch for these kind of specification working groups. Right? Then we have other ones. There's an interface, one working group, and that one has external teams like Astria participating in it. It has Iger, which is building a rust like client for Celestia's DA network. And then there's the DA working group, which is just two different teams, the celestial labs team with celestial load, and there is Iger. And then finally, and that was announced, like, a couple of weeks ago, you guys might like it because it's related to the podcast.
00:59:57.590 - 01:00:02.330, Speaker C: There's the ZK working group by Zackie and Skip protocol.
01:00:02.410 - 01:00:03.838, Speaker A: Yeah, we know about that.
01:00:03.924 - 01:00:05.086, Speaker E: I don't know about this.
01:00:05.188 - 01:00:25.458, Speaker C: Yeah, they announced they wanted to do a working group, I believe, two weeks ago, and they had their first meeting last week, and there was like 60 people attended that meeting from all over the ZK world and the cosmos world. It was really cool to see a.
01:00:25.464 - 01:00:27.778, Speaker A: Bunch of ZKV people were in there, actually.
01:00:27.864 - 01:00:28.270, Speaker C: Yeah.
01:00:28.360 - 01:00:29.094, Speaker E: That's awesome.
01:00:29.212 - 01:00:30.854, Speaker A: This is our kind of thing.
01:00:31.052 - 01:00:31.606, Speaker D: Yeah.
01:00:31.708 - 01:00:33.320, Speaker E: Damn, I'm sad I missed this.
01:00:33.690 - 01:00:39.258, Speaker A: It's just a kickoff. I don't think it was like the finale. I think there's a lot of stuff to do.
01:00:39.424 - 01:00:41.418, Speaker C: Yeah, it was like the kickoff call.
01:00:41.504 - 01:00:42.140, Speaker A: Yeah.
01:00:42.670 - 01:01:08.274, Speaker C: But, Guillermo, I can add you to that. Yeah. So now you have a ZK working group. Right. And now there's four working groups, and there are even talks about maybe more, depending on what roll ups they're looking for and stuff. So we're already seeing a lot of interest. A lot of people want to interact with the process because they find it to be a really good process.
01:01:08.274 - 01:01:39.606, Speaker C: And it's not like we're reinventing the wheel. It takes the best kind of practices from other processes that exist that are what define what we call off chain governance, which is a superior way of governance around technical specifications, because that's where you have all the experts, all the core developers all the research folks reading those specifications and going through a rough consensus process to decide what to add to celexia for activation.
01:01:39.798 - 01:01:51.678, Speaker A: In the CIP process, though, is that only for the outcome of these working groups? So first you do this off chain, and then is it on chain? I guess this is kind of the question, like, how on chain is it?
01:01:51.764 - 01:02:02.798, Speaker D: It materializes on chain eventually, but in the sense that these decisions, if they're made and accepted by the community, will materialize on chain, but it's completely off chain.
01:02:02.894 - 01:02:05.814, Speaker A: Sorry. The decision making, the on chain part.
01:02:05.852 - 01:02:23.018, Speaker C: Of this decision would be mostly like if the celestialab core developer team releases a new binary and then activates in the future, that would make it on chain. If that's the question. I'm not sure if that's what you're talking about.
01:02:23.024 - 01:02:40.878, Speaker A: No, I mean, yeah, the question is, do you plan on having on chain governance and having the validators voting on some upgrades, or do you actually picture most of this happening off chain in working groups? And then it's like the core team basically makes the call.
01:02:40.964 - 01:03:32.094, Speaker C: I'm very opinionated on it. I don't know if I'll get in trouble for saying it, but I've been saying it for a long time. I really hate on chain governance. My personal taste is, I know this is more like a cosmos community kind of thing, but I think, and Vitalik also talked about a bunch of other people, like coin weighted voting for activation of technical features in a blockchain is a flawed mechanism because you're reliant on people voting with their coin who might not have the context on these changes compared to core developers who've been studying the network, the code, the specification, the research in and out, and they have a better decision making process around. Would this screw the network or not if we activate it, right?
01:03:32.212 - 01:03:45.442, Speaker A: Yeah, I mean, I've definitely heard the arguments for and against it. I think having existing in the cosmos hub and actually voting on a lot of these things. I've gotten to see it firsthand and.
01:03:45.496 - 01:04:21.200, Speaker D: Wanted to add one more thing. So Yaz dislikes the on chain governance so much that he did not mention that there is a tiny component. There's like a subset of parameters that can be voted on chain, and these parameters are mostly governance related parameters, and a few like, very few minor parameters off the chain. That makes the memo field in a transaction. How large, what's the max? Or what is the min deposit for actually voting on any of this? You can vote on that.
01:04:23.750 - 01:04:33.700, Speaker A: What's the word for this? It's very internal. It's like you can change in the clubhouse, you can change the color of the wall of the clubhouse. But it's basically.
01:04:37.770 - 01:05:23.086, Speaker D: We have a hard coded in the software, currently hard coded max of block size or square size, the current block size. You can change it via governance up to, I think, eight megabytes max. And then if that's reached, if the community decided we need bigger blocks because there's so much demand for it, then there would be an off chain process, the CIP process, to go beyond that. Right. Because we know the current software can handle easily eight megabytes. And we started with the most optimal block size and parameter. But that's a relatively important parameter that can be voted on via.
01:05:23.086 - 01:05:42.246, Speaker D: On chain governance, but only up to a certain limit. And these limits are set currently such that there's a range where it makes sense. Right. For instance, like, in other cosmos chains, there's, like, also you can change inflation. There was, like, this huge debate on the Cosmos hub. Inflation should be tipped.
01:05:42.278 - 01:05:43.930, Speaker A: It. It was kind of exciting.
01:05:49.970 - 01:06:04.222, Speaker D: Things like this. I think. I completely agree with Yaz. Right. I'm not advocating for on chain governance. Important decisions like that should not be voted on via coin weighted voting.
01:06:04.286 - 01:06:11.940, Speaker A: Basically, I'm like, I wish I hadn't been, like, we did that. We can cut it out of here.
01:06:13.670 - 01:06:28.614, Speaker D: In the cosmos hub, there's no other way. Right. Definitely the right way to do it. It's not that you have a choice. I mean, the community has a choice. They could hard fork. Right? Like, they could say, like, I don't know.
01:06:28.614 - 01:06:56.210, Speaker D: We disagree with the hub's currently, like, current inflation, and the community does not come to agreement on chain. So we will hard fork the cosmos hub. And there were, I think, even initiated by one of the founders, I think, in cosmos. Right. There was a discussion of, like, atom two. I don't even remember the name, but there was a discussion around forking the Cosmos hub. So there is a way.
01:06:56.210 - 01:07:32.554, Speaker D: Interesting. But that's only in case of an extreme situation, an extreme emergency, so to say. So, yeah, I think if this can be avoided and off chain governance can be used is much more preferable. And so far, the experience with the CIP process that's shepherded or stewarded by us is insanely good. Right. There's a lot of very constructive debate. People are like, community is super eager to participate and literally improve celestia.
01:07:32.554 - 01:07:34.846, Speaker D: Right. It's very nice to see.
01:07:34.948 - 01:07:46.130, Speaker A: Cool. I feel like we should chat a little bit about what's coming up technically, product wise, and maybe events what's in the pipeline?
01:07:46.710 - 01:08:06.278, Speaker D: I mean on the technical roadmap the biggest thing is like blobstream deployment, right? Like blobstream currently is not deployed and that's a feature that the community needs to activate. But that will be the biggest next, in my opinion, the biggest next feature that is going to be live.
01:08:06.364 - 01:08:07.994, Speaker A: When roughly is that happening?
01:08:08.112 - 01:08:51.602, Speaker D: Very soon, but not years. It's like rather weeks or something. It's up to the community to decide that, but I think there's audits happening in the background. I don't want to set a date because I can't decide it, but it's literally probably weeks away. Then there's a lot of optimizations ongoing, both on the consensus layer, which means like working on comets or tenements, p to P system, the mempool is being optimized. There's also CIP about some of that. Like there's proposals.
01:08:51.602 - 01:09:25.266, Speaker D: I think there's already like 15 proposals, if I'm not mistaken. Another big feature that's being shipped is pruning. As boring as it might sound, it's actually very important for node operators. Again, there's a CIP for that and also a lot of optimizations on the DA layer. It's mostly about performance and stability currently. Right. And long term is if there's more and more demand for block space, how do we guarantee that Celestia can still serve that demand? Right.
01:09:25.266 - 01:10:01.978, Speaker D: We have this internal mantra is like 1gb blocks and yeah, it sounds a bit insane, but data availability sampling would make it practical at least if there's many, many light clients. Like billions, maybe not billions, but like many, many light clients. Right. While it's not planned to achieve that this year, it's definitely something we work towards. Right. I think that's like from the technical side, optimization, stability, blob stream pruning, and then long term make it possible to have 1gb blocks.
01:10:02.074 - 01:10:08.650, Speaker A: Cool. All right, what about on the products and events? Adoption or adoption?
01:10:08.730 - 01:11:00.160, Speaker C: Yeah, we can summarize all of that and do like an adoption kind of. So just to carry a little bit more of the technical stuff from the adoption point of view, more integrations are coming. Like we're actively working on Polygon CDK integration and I think was it this week or last week? I don't remember like startware announced integration with Celestial, so they're active work on that. That's being scoped from the roll up deployment side. I mean there's like Lira finance, there's mantor Pacific already deployed, there's upnode which is like a gaming kind of roll up. And we already can see like Manta Pacific. I believe there's a tweet by Manta Pacific about within one month after migrating to using Celestia for DA, they saved like a million dollars.
01:11:00.160 - 01:11:49.134, Speaker C: A lot of people using Opstack deployments roll up as a service providers like Conduit and Caldera are seeing a lot of adoption because now with one click deployment, using Celeste for DA, you're seeing a lot of interest in people trying to migrate. PGN, which stands for public goods network, is actually shutting down. It's like a project within Gitcoin. But even though they're planning to shut down within six months or something, they migrated to using Celestia just to save money while they shut down. So you're already seeing really interesting kind of cool things happening on the adoption side. And Lyra, after they went modular, they started generating sequencer profit. Right? Someone shared about Lyra, like, the profit kind of goes down.
01:11:49.134 - 01:12:29.914, Speaker C: And then they switched to Celeste Perdier kind of climbing up again and stuff. So to wrap it up on the adoption and product side, there's a lot of different integration that are being scoped out, a lot of different roll ups that are waiting like they're going to deploy on Celestial. And there will be more interesting use cases for gaming roll ups in the future because now playing a game is really cheap when you have a gaming roll up that uses cheap DA as a resource. Right. And yeah, I mean, that's what's currently scoped out for the rest of the year. From the product integration and adoption side.
01:12:30.032 - 01:12:34.494, Speaker A: Do you have any events planned? You sort of mentioned this hackathon. Is that live?
01:12:34.612 - 01:13:08.306, Speaker C: It's not live. So we haven't announced a hackathon, but we are coming up with our own concept for a hackathon. So one of the problems that I see with modularity, at least from a community point of view, is it's like this big infinite canvas and you want to get started painting. And when we're like modularism, not maximalism, so it's like, okay, great, we're modular. We're all about building this stuff, but there's no sense of belonging, right.
01:13:08.428 - 01:13:14.874, Speaker A: Or like single line, there's no one path that people are supposed to do.
01:13:14.992 - 01:13:55.186, Speaker C: Yeah, exactly. It's like we're that thing that kind of hooks you for a sense of belonging while you're happy. And when you say build whatever, it's great because it gives you a lot of freedom, but it's kind of like watching Netflix where you have so many options, and I spend more time deciding what to watch than what I end up watching. So what we want to do with the hackathon? It's going to be an online hackathon. We're going to announce it hopefully early in March around that timeline, at the first version of that hackathon. But I want to introduce a little healthy tribalism into the hackathon just to make it more competitive between hackers. I can't say anymore.
01:13:55.186 - 01:14:02.186, Speaker C: It's going to be really fun, really exciting. There'll be like a ZK track that we can collaborate on.
01:14:02.288 - 01:14:02.858, Speaker A: That's good.
01:14:02.944 - 01:14:38.530, Speaker C: The other things that are happening on the community side. So I'll go from the smaller grassroot one to the bigger one. On the grassroot events we have the modular meetup program, and now that's spreading like wildfire, where last year we had about twelve meetups around the world. The past week we had two meetups, and we have like four planned only for January and February. 1 was in Nigeria and Wari, Nigeria. The other one was in Zagreb, Croatia. For this year, we have one planned for Buenos Aires, for Barcelona, for Lagos.
01:14:38.530 - 01:15:36.450, Speaker C: I think there's one for Istanbul. The idea behind the modular meetups is my experience with other l ones is when it comes to community building, is a lot of times you'll find organizers come up to you and they'll be like, well, if you pay me a grant, I'll set up a meeting for a meet up for you in my random part of town. And that's fine, but what do you get out of it? It's not really community building, right? It's just like pay to play, kind of like community psyops, if you will. And what I was interested in is I wanted people who are actually committed to the vision of modularity, people who actually are passionate about being community leaders in their own local regions and start building something before I can even consider sponsoring them. Right. And the advice I would give them is like, well, you don't have to find a venue that you got to pay for. You don't have to do anything fancy.
01:15:36.450 - 01:16:10.606, Speaker C: First try to see how many people are interested in modularity, see the size of your community, and the easiest way to do that, go meet up at a bar and just invite people to. But it's not going to cost you anything. Right. And that's what happened with the modular meetup in Paris. What? The organizer brought people to a bar and they had like a quick presentation on modularity. Then they had modular trivia games, right. And the people had fun and stuff, and then you see a lot of people in attendance, and the guy is energized to create more modular meetups.
01:16:10.606 - 01:16:50.830, Speaker C: So we're seeing a lot of interest there. And my target for 2024 is 22 modular meetups. So double last year, I think we're going to hit that number. After that, we're doing what we call the Modular Day series, which is one day conferences that could happen at different conference circuits. So we had one in Istanbul last year. We're scoping one out, I think, for Denver, and there might be another proposal for summer in Europe, so that one can be like a one day kind of conference around modularity and stuff, organized by community organizers. And finally, modular summit 2024.
01:16:50.900 - 01:16:53.530, Speaker A: This is what I wanted to know. This is my real question.
01:16:53.620 - 01:16:55.870, Speaker C: I'm building it up for modular summit.
01:16:56.030 - 01:16:58.260, Speaker A: When could I interrupt him to say.
01:16:59.990 - 01:17:42.400, Speaker C: I wanted to build it up? I want to build up the excitement. So the modular summit 24 24. When we're talking about the mutox and the modular day series, you can think of the summit as a pilgrimage for everyone around the world to go that one time per year for that flagship event where they can talk about all the brightest mind talking about not just modularity from the infra point of view, but all the different subcomponent, all the different topics. So last year we had a really successful one. Anna, as you know, you were curating the ZK track for it. Yeah. I mean, this year, if you're open for it, I would love to get you to curate it again.
01:17:42.400 - 01:18:10.214, Speaker C: We're thinking about a three day event. We know where we're going to do it, but we can't announce it yet until we finalize some of the details. But it's going to be somewhere in the summer. It's going to be bigger. We're going to go way bigger this year. It's going to be a lot more fun. And we're still going to go with the same kind of concept around, allowing different people with their own subcommunities and topics to curate it and stuff for the main stage.
01:18:10.214 - 01:18:12.490, Speaker C: And I think that's what made it special last year.
01:18:12.560 - 01:18:27.070, Speaker A: Sure. Amazing. Well, thank you for that little kind of hint at what is coming. Yes. Really appreciate it. I want to say thank you to both of you for coming on the show. Thank you, Ismail, for coming back on the show.
01:18:27.070 - 01:18:29.742, Speaker A: Yes. You got to be on the show. I'm so happy.
01:18:29.876 - 01:18:32.094, Speaker C: Thank you. Thank you for having. I'm very happy.
01:18:32.212 - 01:18:33.022, Speaker E: It was pretty fun.
01:18:33.076 - 01:18:33.486, Speaker C: Yeah.
01:18:33.588 - 01:18:33.950, Speaker A: Nice.
01:18:34.020 - 01:18:34.302, Speaker C: Yeah.
01:18:34.356 - 01:18:35.210, Speaker D: Likewise.
01:18:35.370 - 01:18:42.410, Speaker A: All right, well, I want to say a big thank you to the podcast team, Henrik, Rachel, and Tanya, and to our listeners. Thanks for listening.

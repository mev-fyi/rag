00:00:08.640 - 00:01:19.457, Speaker A: All right, I'm very excited to talk and my name is Vanishree Rao. I'm founder of Firma Firma. Just to give you a very quick intro about firma. Firma is a universal proof generation layer which can generate proofs for any proof system in a cheap and performant manner. And we are not talking about Firma today, but we are talking about something very, very, very important for Firma, which is ZK in general. And I'm going to talk about a few open problems that I think are very interesting in zk. Okay, so we are insanely close to having mass adoption of zero knowledge proofs thanks to the significant advancements in proof systems and the infrastructure to support these proof systems to visualize where we are in this journey of ZK tech evolution.
00:01:19.457 - 00:02:38.347, Speaker A: Imagine a rocket that is racing towards space. As it accelerate, it reaches this critical point called the Max Q point, which has this maximum aerodynamic pressure on the rocket. And it is at this critical point that the strength of the nuts and bolts and the system calibration all get tested. And even a small flaw can lead to catastrophic failure. This is why I think it is a good time for us in the ZK space to step back from the intricacies of ZK and identify the areas in ZK which are very critical and try to tighten them up. And this is what I'll try to do to some extent in this talk. So I have like a few, in my notes, I have like a few, a handful of interesting open questions.
00:02:38.347 - 00:03:30.241, Speaker A: But for this talk I picked two questions. Both of them are intriguing and are related to the setup ceremony part of the ZK stack. Why should we care about the setup ceremony part of the ZK stack? Because if we. Because for most proof systems, if we don't get, if the setup ceremony is flawed, then you don't have soundness. And that is really bad. And the other way is true too. So any advancements we make in our understanding of how to do setup ceremonies well can actually have a very huge impact and a very wide impact across various proof systems, across various projects.
00:03:30.241 - 00:04:15.641, Speaker A: So I think this is a very focusing here has a huge bang for buck. This is why I picked two questions to focus on. Okay, so let's start with the first question. So setup parameters, right? They basically are a function of. To recall, they basically are a function of tau, which is supposed to be uniformly random. And it has a few elements in the set of parameters. In the set of parameters.
00:04:15.641 - 00:05:21.053, Speaker A: It's just a bunch of functions of Tao. And the way these proof systems are Constructed is by starting with hardness assumption that assumes that this tau is uniformly random. And we then make an assumption that this hardness assumption holds and thereby we prove the security, most typically the soundness of the proof system. Right, we start with. So to summarize, we start with Tau uniformly random hardness assumption holds for uniformly random tau and based on that we prove soundness of true systems. Now what if Tao doesn't have full men entropy, right? If it doesn't, because we are doing setup ceremony, right? No, there is no God who is giving us true randomness all the time. So we're doing setup ceremonies.
00:05:21.053 - 00:06:14.385, Speaker A: It may or may not have full min entropy. The question is what? What if it doesn't have min entropy? We don't know whether the setup, whether the hardness assumption holds. Because this harness assumption has been studied in complexity in, in, in, in, in. We have been studying this hardness assumption and whether it's true or not in the group model or many other models, only by assuming that tau has the highest min entropy. What if it doesn't have min entropy? We don't know. Okay, so we don't know how the hardness assumption will change. Hopefully there is a graceful degradation of secure degradation of assumption.
00:06:14.385 - 00:07:04.111, Speaker A: Hopefully the hardness assumption doesn't completely fall apart. Okay, let's hope hope there hope that. And even if it changes to some extent for this changed assumption, how does the soundness of the proof system change? We don't know. Okay, this is where we are. Here is just quick visualization of how typical setup ceremonies happen. Where you at least part of setup ceremonies happen, where Tao is computed as a product of contributions from various parties. This is just there as a slight digression for us to recall how setup ceremonies happen.
00:07:04.111 - 00:08:17.165, Speaker A: But back to the main question. How do we tighten the setup ceremony given the setup ceremonies, given the fact that we don't have true randomness. So I don't have an so. Oh, I forgot to say the two questions that I have, I don't have full answers to them. I only have some directions that I think are potential to explore for them and would love to jam with anybody who are interested in these questions or the other questions that I have and are also very interesting, I think. Okay, for the directions for the direction to address this problem, I would say let's start with the following question. So recall we are computing products of contributions, right? They have some min entropy, these variables have some min entropy, but very likely not the full min entropy.
00:08:17.165 - 00:09:15.679, Speaker A: Now what we care about is the min entropy of the product and how the min entropy of the Product keeps changing as we add more elements to the product. It'll be great if the min entropy of the product keeps increasing. It'll be great if somehow, intuitively, it feels like, here's a random variable with some, some min entropy, K1. Here is another random variable with some min entropy, K2, you generate product. Hopefully this product kind of smoothens out the probability mass. This is the hope, but it turns out it's not always the case. It can happen, but it really depends on the exact distribution of the two random variables.
00:09:15.679 - 00:09:48.995, Speaker A: And we don't have any control on the exact distribution of the two random variables. So you don't know how people are generating their own randomness. Are they using raindrops to hit their keyboard and take the output and that's the source of randomness? Or they're using a lava lamp or. I don't know. We don't know. We can't have any restriction on the kind of distributions for these random variables. So we don't know.
00:09:48.995 - 00:11:06.163, Speaker A: So this question doesn't give us anything. We had to start there, but it doesn't give us anything. So what do we do we need to think about? I think, what are the strengthening approaches we can put on our setup ceremony as it is done? What can we do there that no matter how these, no matter how these contributions from participants are constructed, there is some strengthening to the min entropy happening because of the way we are doing our setup ceremony. So the one clear direction we can take to modify the setup ceremonies to increase our. To get closer to the assumption. The hardness assumption we have made is by using randomness extractors. Right? Randomness extractors have existed for a while.
00:11:06.163 - 00:11:46.509, Speaker A: There is such rich research in this area. So what they do is you start with something that doesn't have high min entropy and you create something that has high min entropy. And there are multiple ways of doing this. But let's focus on the two ways that I think are relevant for our case. So the two ways are you start with the random, completely random, purely random, uniformly random seed, and then you. Then you can use. There are a ton of extractor constructions.
00:11:46.509 - 00:12:48.979, Speaker A: You can use them to generate a truly random string, however, where you're now shifting the problem, but probably decreasing the size of the problem by saying that now you don't need an entirely long random string, but you need a random seed. But even that could be hard. So instead, what we can do, I think this is a more. Instead, here is another approach which I think is more amenable to the situation we are in for Setup ceremonies and that is you use a two source extractor, right here is an extractor and it is a function that takes two random variables and spits up one that has higher min entropy. And the assumption is that these two random variables are independent. And so here. So having said that this is.
00:12:48.979 - 00:13:57.315, Speaker A: Think of what I said as a prelude to the approach I think is to the approach that can make sense. And the approach is that instead of having your participants create one source of randomness, have them create two independent sources of randomness. Not the same way, but two independent, two somehow independent ways of generating randomness and put them together into this randomness extractor and the output. So let's say they have some min entropy. You're actually in a better, better, better spot. There could be other things that we can do, but I think this is a very low hanging fruit that we can do in modify modifying the way we do our setup ceremonies in increasing our chances of being closer to the ideal way setup to the ideal output we need from setup ceremonies. Like I said, this is a direction and I think we can.
00:13:57.315 - 00:15:19.915, Speaker A: I'm happy to jam on the exact two source extractors that might make sense, but I'll pause this, this part of the question for now. And now let's go on to the next question. So trusted setup again, right? Here is. Imagine this great ideal world where there is this one truly universal set up parameters that all proof systems can use, right? Wouldn't that be amazing? Can we even get there? This is the question. So let's start by asking why different proof systems have bespoke setup parameters, right? Every proof system has different set of parameters. And this is our ideal goal. This is our ideal goal where there is one set of parameters for all proof systems anyway, why do they have bespoke set of parameters? And that is because.
00:15:19.915 - 00:16:26.735, Speaker A: So if you think of the way we are constructing proof systems these days, there is an inner proof and an outer proof, right? An inner proof does this really hard lifting of maybe either starting with a very easy to use language. That's how you represent your computation and you generate a proof for that computation. But you don't worry about the efficiency of verification or the size of the proof in that stage. And then on top of it you put this wrapping outer proof like grad 16 that has good on chain verifiability. This is a typical. There are many good proof systems that don't follow this route. But let's focus on this huge class of proof systems that follow this, follow this trend.
00:16:26.735 - 00:17:19.463, Speaker A: So having said that, why Is it that different proof systems have different. Why is it that different proof systems need different setup parameters? It is because. So it's the Grot 16 layer that that need setup parameters, right? Look at this outer layer. The outer layers prover is proving verification of the inner layer. And because the verifier of the inner layer changes across different prove systems. What this the computation that the Grot 16 Prover is doing changes across different proof systems. And therefore your set of parameters need to be different across different proof systems.
00:17:19.463 - 00:18:18.059, Speaker A: Right? This is the reason why different proof systems currently need bespoke setup. So how do we get around this problem? Can we. Is there a way to go towards truly universal setup? And let's. In this talk we will explore the direction. We will eliminate certain natural approaches and we will land at an approach which I think is promising. What if we start with something like flunk that doesn't need any trusted setup? So here are the two issues, right? If the outer layer is flunk, the computation that this flunk prover needs to compute. You look at that computation.
00:18:18.059 - 00:19:10.471, Speaker A: There are two ways of doing that computation. Either with the custom gates that flonk or plonk has the custom gates, or without the custom gates and representing the entire computation in an arithmetic circuit. Addition, multiplication, arithmetic circuit. If we go the custom gates route, then the outer layers verifier also depends on those custom gates. And that is not good for on chain verifiability. I think we shouldn't budge from our goal of on chain verifiability being independent from the computation, being constant from the computation and being like Grod 16. I think let's set that in stone.
00:19:10.471 - 00:20:00.325, Speaker A: And now what can we do? Flunk doesn't help if we start with custom gates as the way of representing computation for the prover in the outer layer. What if we do it just with addition and multiplication? It's very likely going to be very, very hard with huge circuits and it may not be a feasible direction. Can we do better? What if we go through bulletproof based direction like bulletproof IPA polynomial commitment direction. So here the. Here of course there is no trusted setup that is great. No pairing, which is great. So the no pairing part will become relevant in just a bit.
00:20:00.325 - 00:20:38.571, Speaker A: Let's just note it there. And the problem is that the proofs generated by bulletproof proofs generated by APA are not as small as. Not as small as Groth 16 proofs. It's way far from being there. It's not even constant. So this direction also has some problems. What if we do two level smoothening.
00:20:38.571 - 00:21:15.719, Speaker A: So I use smoothening to continue with the image that I have here in representing provers and verifiers. And okay, so we start with the inner proverb. How about we put bulletproof on top of it and then put Grot 16. The Grot 16. So here is why this could make sense. I could be proven wrong after this talk. If anybody sees why this may not work, I would love to know.
00:21:15.719 - 00:22:06.225, Speaker A: But as far as I see, I think it is promising. And here is why. So you start with the inner prover. You put bulletproof on top. We have the limitations that we just talked about, which is the proof generated by bulletproof isn't small enough, but it is not as big as where we started initially from the innermost proof. So we are getting better. Now what if we put Grot 16 at the very end? But now we are so putting Grot 16 at the very end is now a little bit easier because you can represent all the.
00:22:06.225 - 00:22:22.141, Speaker A: Because. Yeah. Okay. There are a few things going on in my mind. One reason why this might make sense is that so bulletproof and grad 16. Bulletproof doesn't need pairing. Grad 16 needs pairing.
00:22:22.141 - 00:22:54.815, Speaker A: You can use a half pairing cycle. And the prover in the outer layer is is it isn't as huge as before. So it's even in a. We are in a better situation in the total proving time. So yeah, this might work is my thinking. And the bulletproof verifier, we can have it in a way where it is uniform like with different proof systems. It doesn't change.
00:22:54.815 - 00:24:08.215, Speaker A: Yeah, these are the reasons why this might be a good direction. I know we are getting close to the end of time, but I'll pause now. But summarizing two questions that seem interesting to consider and to dive deep and research and figure out a solution for are how do we have a trusted setup that is truly universal across multiple proof systems to help alleviate the operational hardness of doing this? It's operationally really hard, time consuming, error prone. There are so many good reasons why I think this is a good goal to aim at. And the other question we talked about was how do we have a trusted setup that is tightened up and doesn't have the what can we do to tighten up setup ceremonies given the fact that the participation's inputs don't likely have highest min entropy? I'll pause here. Thank you so much.
00:24:11.595 - 00:24:37.427, Speaker B: Thank you Vanishree. So we have a few minutes for questions. So are there any questions from the audience for Vaneshree? Please raise your hand if that's the case, don't be shy. Come on. We can wait. Yeah, Take the mic please, so that it's recorded.
00:24:37.571 - 00:24:41.495, Speaker C: I mean, so I'm assuming this is just an idea for now, right?
00:24:42.125 - 00:24:54.265, Speaker A: Yes, just an idea. I don't know if any of this will even work out. Maybe we will figure out that this direction is flawed. But I think it's a start of a direction.
00:24:56.005 - 00:25:05.825, Speaker C: And you must have an idea of maybe a sketch of how you would maybe. What would be the first step in experimenting whether this would work or not. What would be the first thing one would have to do?
00:25:06.485 - 00:25:08.439, Speaker A: What would be the first like to.
00:25:08.487 - 00:25:16.475, Speaker C: Actually like just implement this. What would be like, you must have some sort of a sketch in your head of like what are the first things that you one should be doing?
00:25:17.255 - 00:25:21.995, Speaker A: Sketch. So to make sure I understood your question correctly.
00:25:23.815 - 00:25:25.875, Speaker C: How do we go from idea to practice?
00:25:28.295 - 00:25:29.595, Speaker A: Go one last time.
00:25:37.065 - 00:25:40.405, Speaker B: What's a good experiment to prove this idea?
00:25:42.225 - 00:26:36.611, Speaker A: I think this specific one, I think we just need to go very deep and probably test this for one proof system and see. I think we just need a lot of double clicking in each of these parts. Maybe there are nuanced parts that I'm not. That that is not visible just by looking at this approach. Like for example, when I started thinking about this, I was thinking flunk. And so when I started thinking about this I suddenly realized that how do we do what are the right elliptic curves to use? Bulletproof and graph 16. And you know, there are things like these that are not visible from just the idea phase.
00:26:36.611 - 00:27:04.185, Speaker A: So I think we just need to double click and see and figure out whether this is the real direction. I think someone just needs to put like a lot of time in making sure that this works. There is no experiment or anything. It's just, I think, I think we just need to write down the whole protocol and I would love to collaborate with somebody if anybody is up for leading this.
00:27:08.165 - 00:27:18.607, Speaker B: Okay, thanks. Are there any other questions from anyone? Is it the raised hand?
00:27:18.711 - 00:27:19.355, Speaker A: No.
00:27:20.135 - 00:27:28.895, Speaker B: Okay. Okay. Well if that's the case, thank you very much, Vanisher. So we're just going to take a two minute break and then.

00:00:07.690 - 00:00:35.634, Speaker A: Hey, everybody. Hey. So, I'm Kamal Lachko. I'm from ZK Singh, and I would like to talk to you about hyperscaling. Hyperscaling is a question of how an interconnected ecosystem of roll ups should operate rate. This is basically the same question as execution sharding, just in the context of roll ups. So the first topic we should cover is interoperability.
00:00:35.634 - 00:01:21.270, Speaker A: And this is related to hyperbridges. Hyperbridges allow hyperchains to cheaply and trustlessly interoperate. The crucial part of this process is the message route, which is a commitment to all the hyperbridge transactions happening inside a L2 ecosystem between different L2 chains. And this is the only part of the messages that is sent to l one. And the core message, which actually contains all the information about the user's transaction, is sent directly from the sending chain to the destination chain. And it is there compared against this message route. So this allows hyperbridging to both be trustless and cheap.
00:01:21.270 - 00:02:01.566, Speaker A: And using this process, it is possible to get an ecosystem of interconnected hyperchains. Hyperbridges allow general message passing and also assets to be passed from one chain to another. So we get a unified liquidity across the whole ecosystem. And in order to ensure unified liquidity, layer one assets need to be logged inside a shared bridge on layer one. So interoperability is the first part of the puzzle. But there are more questions, such as how to organize the chains. Should you have layer freeze, fractal scaling, proof aggregation.
00:02:01.566 - 00:02:38.960, Speaker A: And that's the harder part. Now, let's look at those. So the first solution is proof aggregation. With proof aggregation, what happens is that multiple blocks of a simple hyper chain are first aggregated across time. And then these proofs of different chains are aggregated and settled on layer one together. Now, settlement on layer one is relatively expensive, so in order to minimize fees, it makes sense to settle less often. But this is bad for hyperbridging, because hyperbridging is only possible once settlement on layer one happens.
00:02:38.960 - 00:03:20.478, Speaker A: So for fast messaging, this is not an ideal solution. So to fix this, we can have layer freeze, and layer freeze can settle on a L2. And because it's a L2 settlement is much cheaper there. And this is basically the same hyperbridging process as we saw before. But because it's happening on a L2, it can happen much more often, and so bridging is much faster. Now, if we look at more detail at what actually happens here, is that the blocks and the proofs of different hyperchains are first aggregated across multiple chains. And then the proofs of the L2 are aggregated across time.
00:03:20.478 - 00:03:54.360, Speaker A: So in a sense, we are flipping the order of aggregation first across chains and then across time. However, layer freeze still have some problem. There are two main problems. The first is scalability. The L2 has a virtual machine which cannot handle an arbitrarily large throughput. And the second is that the L2 has a consensus mechanism which secures the L2 itself. And this consensus mechanism might revert, and this will cause the layer freeze to revert as well.
00:03:54.360 - 00:04:43.218, Speaker A: So in order to solve this, we need to solve scalability and this middleman problem that the L2 causes. First, for scalability, we can just remove the L2's virtual machine. And if we remove the L2's virtual machine, we can have a specialized proof there instead. Then we can have a scalable and solution that is still good for fast messaging. And this specialized proof would still have a message route. So hyperbridge transactions could be verified from there, and this message route can be also imported back later there when the layer frees settle on the specialized proof. But we still have this middleman problem, because the specialized proof will still have a consensus mechanism.
00:04:43.218 - 00:05:27.102, Speaker A: This is the aggregation layer in a sense. So let's look at the consensus mechanism that this specialized proof requires. It only needs a minimal consensus mechanism because it does not aggregate process user transactions, it only processes hyperchain proofs. This means that finality can be much slower. It also does not have storage requirements, and it has minimal state because it only stores commitments to their hyperchains states. This means that it has minimal data publishing and storage needs. In conclusion, this basically means that lite clients are followed similar to in data availability.
00:05:27.102 - 00:06:21.650, Speaker A: Lite clients can contribute to this consensus mechanism's security. Okay, so this hasn't solved the melod problem yet, but let's look at how layer one solves this melon problem. So currently, layer one is the most decentralized chain, and we have a small number of roll ups settling onto it. So it is unthinkable that the layer one would have major reorgs. But in the future, if the whole ecosystem is processing 100,000 tps and we have 1000 roll ups, then the total stake in all of the L2s together might be bigger than the stake in the layer one. To solve this, we can use restaking. All of the stake can be logged in the layer one consensus mechanism and restaked to be used in other consensus mechanisms.
00:06:21.650 - 00:07:15.090, Speaker A: And validators can be run for the layer one and the L2 consensus mechanism. In parallel, this makes the layer one very secure, as the stake securing the total ecosystem will be approximately equal to the stake securing layer one. So this is how to solve the middleman problem. And we can use the same solution in the context of proof aggregation as well. We have the proof aggregation layer with the specialized proof, and we have the hyperchains. The hyperchains have the traditional consensus mechanisms, and the specialized proof only has a minimal consensus mechanism which can be verified by like clients. The hyperchains are basically like clients of the proof aggregation layer, as they are using the message route from there to use for their own messaging purposes.
00:07:15.090 - 00:08:35.746, Speaker A: And they also settle the message route inside the proof aggregation layer because it needs to be settled there. So we can actually measure the acceptance of the specialized proofs consensus mechanism by measuring the method routes that are settled inside the proof aggregator. So using this solution, it is possible to solve the middleman problem. And now we can have an ecosystem that has fast messaging that is scalable because it uses proof aggregation, and it is also secure because the stake is distributed in a manner such that the proof aggregator stake is approximately equal to all the stake inside the ecosystem. So finally, I would like to cover one last topic, which is cross hyperchain force transactions. This will be very important in the future, because if we have 100,000 tps, then censorship resistance from the l one will be very expensive because the layer one will only be able to process a certain number of transactions. So it's very important to have forced transactions going from one hyperchain to another.
00:08:35.746 - 00:09:35.990, Speaker A: And this would be through a similar process as normal hyperbridges expect. It wouldn't be a relayer that sends a transaction from one hyperchain to another. It would be sent to the data availability layer, and from here the receiving hyperchain could import it. And to make sure that it is indeed imported and executed, the sent message route and the received message route would have to be compared inside the proof aggregation layer. Now this is just an approximation, because the actual construction is much more complicated because different hyperchains might settle at different moments. But this is the main idea. So using this construction, we can have fast messaging, we can also have scalability, security and censorship persistence in the whole ecosystem.
00:09:35.990 - 00:09:41.526, Speaker A: Thank you very much. And if there's time for questions, we.
00:09:41.548 - 00:09:58.660, Speaker B: Have a few minutes for questions. Round of applause. First, these are lightning talks, so they're lightning questions also. So any fast questions? Okay.
00:10:01.930 - 00:10:18.970, Speaker C: Really high level. I mean, we have a few of these stack kind of projects like op stack or even Madara on like just fundamentally high level. How is this so different in terms of what we can do here versus other stuff?
00:10:19.120 - 00:10:51.330, Speaker A: So I would love to answer your question. The problem is that most of these stacks haven't really specified what their solutions will look like. So as you mentioned, Madeara is just as I understand, a sequencer for layer Freeze. It's not the core part of this. Starker never specified how their proof aggregation system will look like. Neither did polygon. I can address optimistic solutions because for optimistic roll ups it's much harder to have interoperability.
00:10:51.330 - 00:11:25.470, Speaker A: So every solution that uses ZK proofs will have much better interoperability than optimistic chains. I think for us, our biggest advantage is our great proof system, because I think our proof system and our VM implementation requires the least amount of ram, GPU RAM to run. So this means that proofs can be generated in a decentralized manner, which makes the whole ecosystem much more decentralized compared to other solutions.
00:11:25.970 - 00:11:27.550, Speaker B: Okay, we have one more question.
00:11:27.700 - 00:11:55.110, Speaker D: This might be a stupid question. I know that this architecture is trying to solve the fragmentation of liquidity, but are you also solving the fragmentation of app deployments or infrastructure across these different environments? Does the hyperchain one, hyperchain two, do those all have to integrate with fireblocks individually, or do frameworks appear so that you kind of have this shared framework where they can all interoperate?
00:11:56.110 - 00:12:25.120, Speaker A: Yes. So all of the chains should have the same API calls, but if you want to deploy an account on a chain, you will have to deploy it on that chain specifically, and there will be ways of natively. So we will have methods of the concept of the same account of multiple chains. So I think that will definitely help a lot. But each chain will be its own chain, basically.
00:12:27.250 - 00:12:32.240, Speaker B: All right, thank you very much. You.

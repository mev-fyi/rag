00:00:05.640 - 00:00:58.123, Speaker A: Welcome to Zero Knowledge. I'm your host Anna Rose. In this podcast, we will be exploring the latest in Zero Knowledge research and the decentralized web, as well as new paradigms that promise to change the way we interact and transact online. This week Tarun and I chat with Naveen, a graduate student at Columbia University, about his recent work on restaking. We start with a look into Naveen's early work on matching markets and how this led him to work on mechanism design. We then discuss how the concepts of restaking were first presented to the public and how both Naveen and Tarun have been working to better model the mechanisms underpinning restaking, to understand how they work and to figure out how they could be optimized. Now, before we kick off, I just want to point you towards the ZK Jobs board.
00:00:58.123 - 00:01:23.963, Speaker A: There you can find job opportunities working with top ZK teams. I also want to encourage teams looking for top talent to post your jobs there as well. We've been hearing from more and more teams that used it that they have found excellent talent through this ZK Jobs board, so be sure to check it out. I've added the links in the show notes. Also, quick reminder, the ZK Summit 12 is coming up. It's happening in Lisbon on October 8th. Be sure to grab your spot as space is limited.
00:01:23.963 - 00:01:41.035, Speaker A: This is our one day ZK focused event where you can learn about cutting edge research, new ZK paradigms and products, and the math and cryptographic techniques that underpin ZK systems. All info can be found@zksummit.com and hope to see you there. Now Tanya will share a little bit about this week's sponsors.
00:01:42.255 - 00:02:21.175, Speaker B: AELIO is a new layer 1 blockchain that achieves the programmability of Ethereum, the privacy of Zcash and the scalability of a rollup. Driven by a mission for a truly secure Internet. A LEO has interwoven Zero Knowledge proofs into every facet of their stack, resulting in a vertically integrated Layer one blockchain that's unparalleled in its approach. AELIO is ZK by design. Dive into their programming language LEO and see what permissionless development looks like, offering boundless opportunities for developers and innovators to build ZK apps. This is an invitation to be part of a transformational ZK journey. Dive deeper and discover more about a leo@ailyo.org
00:02:21.175 - 00:03:03.775, Speaker B: Gevalot is the first decentralized proving layer with Gevilot. Users can generate and verify proofs using any proof system. For any use case, you can use one of the default provers from projects like Aztec, starknet and Polygon, or you can deploy your own. Gevalot is on a mission to dramatically decrease the cost of proving by aggregating proving workloads from across the industry to better utilize underlying hardware while not compromising on performance. Gevilot is offering priority access to ZK podcast listeners. So if you would like to start using high performance proving infrastructure for free, go register on gevalot.com and write ZK podcasts in the note field of the registration form.
00:03:03.775 - 00:03:07.735, Speaker B: So thanks again Gevalot. And now here's our episode.
00:03:11.435 - 00:03:22.917, Speaker A: Today. Tarun and I are here with Naveen, a graduate student at Columbia University in computer science. He works with Tim Roughgarden. He is also working on mechanism design at Ritual. Welcome Naveen.
00:03:23.011 - 00:03:24.681, Speaker C: Thanks for having me. It's great to be here.
00:03:24.793 - 00:03:26.001, Speaker A: Nice and hey Tarun.
00:03:26.113 - 00:03:33.017, Speaker D: Hey. Excited to be back for our second recording this week. True, it's a record.
00:03:33.121 - 00:03:53.239, Speaker A: Yeah. Although to the listener it will be a week later. But we know it's the same week. So today we're going to be talking about restaking and we're going to be revisiting that topic. Tarun, this was actually your idea to invite Naveen on the show, so maybe you could share a little bit about what you have planned or what you want to talk about.
00:03:53.407 - 00:05:11.375, Speaker D: Yeah, so I think in my mind there's always this sort of like leading lagging cycle in research where there's oftentimes like things that grow a lot in crypto but no one knows why they work or how they work. And sometimes, hey, they're total Ponzi schemes, but other times, you know, it's like Uniswap or you know, Maybe, maybe other L1s are a good example. And I think there's oftentimes this thing where like a little bit afterwards people start trying to formalize like the reason why something works either from a distributed systems lens, sort of economic lens, a cryptography lens, whichever direction it may happen to be. And I think I first ran into Naveen's work before he was doing anything in crypto. Maybe like a year and a half ago or two years ago when he wrote a paper on auction theory as an undergrad, it was more from the lens of online learning and more of the machine learning school of the world. I'm not sure if you find that offensive or not by not at all, because machine learning just means so many things now that some people are could mean everything from chatgpt to linear regression. So I'm Just trying to.
00:05:11.375 - 00:05:59.547, Speaker D: It's an umbrella term. But it was more in that vein. And a lot of times I think people from that world tend to not like crypto or maybe view crypto suspiciously, especially on the research side. But Naveen then kind of very quickly wrote one of his first papers in crypto on restaking, formalizing a thing that I think people, even the people who invented it, who had spent a lot of time wr research on it hadn't quite gotten correct. So I think his ability to kind of move between fields and generate new research really quickly I think was quite impressive. And because I think in general systems like restaking are going to. I don't think they're going away.
00:05:59.547 - 00:06:56.197, Speaker D: Like they might have different names and people might do, might, you know, change some of the designs a little bit. But I think the reason there's $15 billion in those systems is people do view those as sort of the new way of having growing ecosystems and building L1s versus just pure roll ups. Because I kind of think the natural extension of rollups and L1s ends up being things that look like restaking. So that's sort of my spiel and preamble of why I think it's kind of interesting. I mean, of course Naveen's come at this from a totally different angle where he and I both read the appendix B of the eigenlayer paper and got two different interpretations of it. And then we both worked on different research problems, but I think they kind of converged. So anyway, maybe it'd be great to talk a little bit about what you worked on before, how did you get interested in it and before we talk about how you got into crypto research.
00:06:56.341 - 00:07:21.559, Speaker C: Yeah, sure. So I guess research has been a thing I've been thinking about for quite a bit of time. Initially started working on some stuff, I guess back in middle and high school at Maryland, primarily focusing on these kidney exchange matching markets. I guess I kind of got into research somewhat as a fluke. Some science fair judge thought it was maybe worth some professor's time to work with me. Frankly, I don't know how that worked out.
00:07:21.687 - 00:07:25.991, Speaker A: But when you say kidney, you mean like kidney kidneys? Like health care kidneys?
00:07:26.023 - 00:07:27.391, Speaker C: Okay, that's exactly.
00:07:27.423 - 00:07:32.407, Speaker D: Oh yeah. Maybe we should talk about what matching markets are in kidney exchange Detour.
00:07:32.471 - 00:08:11.451, Speaker C: Yep, yep. So this is the stuff I worked on initially. And the general gist there is that lots of people obviously need organ transplants. And before kidney exchanges were invented, the main way that you would get an organ transplant is through what's known as deceased donor donation, where if you sign up to be an organ donor, you get put on this list. And if you happen to. If now a patient needs a transplant, there is some priority ordering that's determined among people that need transplants. And based on that ordering, they get allocated kidneys.
00:08:11.451 - 00:08:54.359, Speaker C: First of all, the supply of transplants is low, and second of all, deceased donor donation. Deceased organs are not as high quality as living donor donations. And so if you did have a living family member or someone that's willing to donate to you, that's obviously preferable. And basically, Al Roth came along. He's a professor at Stanford, and he started kind of the seminal work on kidney exchanges. And the idea there is, let's say I have a kidney, sorry, I'm a patient and I need a transplant, and then I have someone I know, let's say a friend or a close family member, that's willing to donate one to me. But we happen to be biologically incompatible.
00:08:54.359 - 00:09:34.967, Speaker C: So in the old model of the world, nothing could happen here. Right. But now you kind of have this idea of, okay, what if you had a bunch of these pairs? So maybe I need a transplant and my sister is willing to donate one to me, but we're incompatible. And then maybe you, Anna, need a transplant and Tarun's willing to donate one to you, but you guys are incompatible. But now let's say that Tarun is actually compatible with me and my sister is compatible with Anna, then we can actually swap. Right. And so kidney exchanges are kind of these matching markets, actually, without money, because there's lots of policy and law around what you can do around organs and money.
00:09:35.111 - 00:09:37.415, Speaker A: The one kidney equals one kidney. There's no.
00:09:37.455 - 00:10:10.983, Speaker C: Exactly, exactly. You're trading kidneys for kidneys. There's no money involved. And there's all sorts of other constraints around because you can't place a contract on organ donation. Actually, the donations have to happen simultaneously. If it's a kind of a cyclical structure like what I just described, then people also realized you could add some other types of trading structures where, let's say Tarun's just an altruistic guy, he wants to donate his kidney, he can give one to me, and now my sister can kind of choose to pass it on and then donate to someone else. And now you can have kind of an asynchronous chain of transplants.
00:10:11.079 - 00:10:11.567, Speaker A: Wow.
00:10:11.671 - 00:11:02.925, Speaker C: So this is one of the, like, I think one of the pretty motivating examples for me of an example where math and market design could be pretty helpful. In the real world, it was a pretty practical problem. And I worked on initially more along the lines of how do you do learning for kidney exchanges in terms of if I'm a patient, can I get some predictions for how long I'll have to wait, what the outcomes will look like, stuff like that. And gradually more and more into the theoretical side of things, I started thinking more about learning problems in general. And I had a brief stint also working with Scott Commoners, who's also now in crypto. And this was back in high school, and I worked on some matching market problems with him. So kind of got more into the standard mechanism design literature as well, while also learning a bit more about these learning stuff.
00:11:02.925 - 00:11:41.521, Speaker C: And there wasn't really a cohesive thing. It was kind of just working out a bunch of these different hodgepodge projects that didn't really touch each other that much. Maybe a general theme of mechanism design and a general theme of maybe learning, but no kind of coherent narrative. And then when I went to Berkeley, I worked with Nika Hugthalub and she works on online learning and mechanism design together. So putting together kind of the tools of optimization, statistics and economics. And so that's kind of where I worked on this learning and auction stuff that TARUN was talking about. And there the idea is like, let's say I want to run an auction every day.
00:11:41.521 - 00:12:27.911, Speaker C: Is there a way for me to figure out how to run an auction each day so that in the long run I'm doing as well as if I kind of picked the best auction in hindsight at the very beginning. So these were all like theory heavy projects. And I kind of moved from more practical stuff on the kidney exchange side to more theoretical econ stuff. And the math was super cool, it was great. But then when it came time to apply for PhD programs, I had a bit of a crisis of faith per se, really. Why I was working on all these theory problems and I felt like I was working on things in this weird, uncanny valley the problems had. When you write the motivation section for the paper, you say, oh, this applies to the real world.
00:12:27.911 - 00:13:14.925, Speaker C: Here are all these things that people care about, but the results are kind of too contrived to be clean theoretical results. And they're also just way too theoretical for anyone to use this stuff in practice. Right? So the online learning and auctions paper credit to TARUN for actually maybe thinking about how to use it practically. I couldn't think of a way someone could use that in practice. It was a nice theoretical result along the lines of maybe possibility for learning. But the actual algorithm that was proposed would take eons to run properly. And so I kind of decided, okay, I want to either go on the very pragmatic side and do stuff that people actually care about, or go purely on the theoretical side and prove nicer theoretical results than these ones.
00:13:14.925 - 00:13:15.949, Speaker C: Exactly. Exactly.
00:13:15.997 - 00:13:17.893, Speaker A: Okay, which direction did you go?
00:13:17.989 - 00:13:29.257, Speaker C: So I chose to go. So I guess I still work on theory stuff, but I chose to go fully pragmatic in the sense that I didn't want to work on a problem unless I really knew that there was at least someone that actually cared about this stuff.
00:13:29.361 - 00:13:29.905, Speaker A: Okay.
00:13:30.025 - 00:14:07.855, Speaker C: And it was around that time too, that I had seen both Scott, who was a previous mentor of mine, go into blockchains, and then also Tim Rothgarden, who always looked up to him. He founded one of the founders of the field of algorithmic game theory. He also made the jump and was talking about EIP 1559. And so I was like, okay, a lot of really, really smart people that I look up to have gone to this area and it seems like a place where all the nice ingredients come together. You can work on cool mathematics, prove theorems, and then people actually care about those theorems. And that's such a rare thing to find altogether. That's cool.
00:14:07.855 - 00:14:17.707, Speaker C: Once I got sold on the vision, it was not a super hard choice for my PhD process. Working with Tim has been pretty awesome.
00:14:17.891 - 00:14:38.133, Speaker D: I will say the one thing, maybe one redeeming feature about ML and AI research is at least people care about theoretical guarantees, which is just not true in a lot of other parts of the world where the theoretical guarantees are so divorced from what people do in practice that it's like they really are mental masturbation.
00:14:38.229 - 00:15:10.711, Speaker C: There's really. Yeah, I mean, one of the. Maybe to go on the more theoretical sidetrack. One of the main ways of analyzing, I guess, the performance of a learning algorithm is something called VC dimension, which looks at the worst case. It's a type of worst case analysis for learning. And if you looked at those bounds, what those bounds predict current performance would be for ML systems, it's really bad. There's a huge divorce between what we're able to prove and what people actually are able to do in practice.
00:15:10.711 - 00:15:29.875, Speaker C: And so theory has been kind of playing catch up on the ML side because it's just so hard to analyze stuff. And proving theorems that actually help practitioners is really hard because practitioners are just doing stuff that really just shouldn't be possible. If you're looking at a worst case analysis and Doing a good average case analysis is quite tough, I guess.
00:15:29.995 - 00:16:05.565, Speaker D: Now, as we move to what you've worked on within crypto, I think there's two main areas that you've worked on, the first being restaking and restaking risk, and second being resource pricing. So for our listeners who are unfamiliar with both of these areas, which could actually be a quite substantial portion, because a lot of listeners are cryptographers or developers who are maybe not quite so tuned to these areas, could you eli five them and give a kind of high level description of both of these areas and why they're important?
00:16:05.725 - 00:16:46.901, Speaker C: Yeah, sure. Restaking, actually maybe to tie us back into the narrative how I got got here in the first place. When I started working at Columbia, and at roughly the same time as when I started working at Ritual too, I wanted to just get some outside engagement to learn about how stuff worked because I knew nothing about blockchains, frankly, about a year ago. Oh, wow. And so I was just trying to learn what's the infrastructure? What do people care about? I was just trying to figure out how can I start working on the problems that I think people care about the fastest. And so I first heard about Restaking, actually while I was at Ritual, because Ritual is now working with Eigenlayer. And eigenlayer was coming up, Restaking was coming up.
00:16:46.901 - 00:17:39.329, Speaker C: And the main idea there is. So you have Ethereum, and Ethereum is a very secure blockchain in the sense that there's lots of validators, maybe if you have other protocols that you might want to run. And the reason why you might want to run them is that perhaps they have functionality that extends beyond what Ethereum can do or any other blockchain. And you kind of have this issue of if I want to run a protocol with a proof of stake system, I need to recruit people that want to put stake in my protocol. And that's a tough ask because you're essentially asking people to lock up money. And anytime you ask people to lock up money, you kind of need to pay also a cost of capital expense because they could have been using that money for many other things. And so you need to compensate them for that loss that they would be facing.
00:17:39.329 - 00:18:06.997, Speaker C: So that's a pretty expensive thing to ask for. And it's also just like, how do you. Building a blockchain is almost like building a city. You have to coordinate so many parties. How do you just get these people in the first place? And so the idea behind Restaking I thought was pretty cool. It was, you have these validators that have already committed stakeholders to Ethereum, let's say. And so in principle, the cost of capital expense for that stake has already been paid to them by Ethereum.
00:18:06.997 - 00:19:12.243, Speaker C: We can talk about how that plays out in practice. Obviously there's different quirks there, but in principle, if I think it's rational for me to put my stake in Ethereum, that means I expect that the rewards from Ethereum outweigh any cost of capital expense. And so there's all this stake that's already locked up in Ethereum. And now let's say I have some other protocol and I need stake to secure this protocol, right? Kind of the simple idea behind Restaking is, okay, there's all this stake that already has this cost of capital expense paid off. What if I were to just reuse those validators? So those validators that are currently on the hook for Ethereum, the stake obviously serves multiple purposes, one in civil resistance, but also in terms of it's a slashing penalty that could exist if they try to do a double spend attack or any other malicious behavior. And so what if I, as another protocol could say, hey, there's this existing stake that's already getting its cost of capital expense paid off. All I have to do now is pay those validators the additional operating expense of operating my protocol and now I can recruit them as well.
00:19:12.243 - 00:19:49.667, Speaker C: And so now that same stake, it's on the hook not only for Ethereum, but it's also on the hook for this other protocol. And so when I first heard about this, I kind of had two thoughts. One is, okay, that is a neat way of recruiting security that makes things frictionless, or maybe not frictionless, but with less friction. Other thought was immediately, okay, we've seen lots of weird structures in crypto that have led to financial demise. Is this a safe thing to do? Is there a way this can be done safely? Or does this place an excessive burden on validators that perhaps could lead to some type of catastrophe in a worst case situation?
00:19:49.811 - 00:19:50.411, Speaker A: Yeah.
00:19:50.523 - 00:20:36.239, Speaker C: And so on the restaking front, kind of the first thing I was thinking about was, okay, is there a way to understand what is the risk that maybe Restaking poses, both from a global sense, but also if I'm just an avs, a service that's recruiting security, can I understand what the risks are there? Because as soon as you start sharing validators, the consequences that occur on one protocol can start affecting security for another protocol. Right. And so, yeah, essentially understanding, first, figuring out what is a good model to understand all this stuff, and then second of all, thinking about is there a nice crisp characterization of under what circumstances can this be done safely and under what circumstances should you be kind of concerned that things might go awry in this case, though?
00:20:36.287 - 00:20:49.487, Speaker A: So, like, I mean, I think we're getting to this work that you recently released called robust restaking Networks, but was that more like a description of what already existed or is that like a. Did you rebuild it from scratch and say, like, this is an ideal way to do this?
00:20:49.631 - 00:21:50.285, Speaker C: So when I first started working on this stuff and Tarun mentioned this too, essentially the only document, technical document, about restaking/it security was this initial thing put out by Iconlayer. And in particular there's appendix B of this thing, which was on crypto economic security. And so that appendix did lay out kind of a very basic model of there are some kind of validators. On one side there are validators that might want to, or I guess they call it node operators that might want to put their stake in some number of protocols. And on the other side there are these protocols that want to recruit security. And then they kind of talk about a cost benefit analysis of under what circumstances can you say that the benefits of attacking some set of protocols don't exceed the costs? It's not a super long section. I think it's a pretty nice initial model, but that was essentially all that I could understand about the system as of then.
00:21:50.285 - 00:22:38.595, Speaker C: And so the first thing that I don't know, maybe to go into what I was actually doing in that paper, half the battle, I think, in doing blockchain research is modeling. Unlike theory work, where the problems are extremely well specified, they're clean mathematical statements, and someone just has to go out and prove a theorem. The challenge here, most of the challenge in some cases is actually coming up with a good model, a good way of a formal way of understanding basically what's going on in practice, so that when you prove theorems, they're relevant to the real world. Right. And so there were kind of two main modeling things to think about. One is how do you characterize risk here? Or what does risk mean? And two is just what is a way of understanding all the entities and their interactions? And so from that eigenlayer. Eigenlayer document.
00:22:38.595 - 00:22:44.071, Speaker C: That's right. That's right. I kind of started thinking about things in terms of a bipartite graph.
00:22:44.183 - 00:23:33.721, Speaker D: One thing to note is I think there was a lot of technical documentation on how the implementation would work and what the code would look like, but there wasn't any document on guarantees that you would get for and I think the only thing was this kind of tiny little thing. And I think when you read what Twitter was writing about restaking and like, oh, it's going to all blow up. It's luna again, whatever. And then you read, you kind of look at the code, you kind of see a very divergent version of the world. And I think part of this comes from the fact that it's actually quite difficult to describe these guarantees. And I think, yeah, Naveen probably can talk about why going from what was known to a rigorous but simple formulation is actually kind of a difficult process.
00:23:33.873 - 00:24:21.425, Speaker C: Yeah, sure. You're kind of working in the fog here, right? There's so many people saying different things, right. And the theorems that you prove are not helpful unless there's kind of first a general formulation for how to think about everything. And there are many aspects to restaking. The aspect that I was focused on was first just like global and systemic risk type of stuff. And so the model I kind of first kind of just dialed out a lot of the stuff on Twitter and mostly just thought about, okay, at the very core of this thing, there are these validators and they're being reused among some services. And kind of following some stuff in Appendix B, you can think of there being some profit from corrupting any service.
00:24:21.425 - 00:24:46.099, Speaker C: If I launch a double spend attack on some service, there's some amount of money I can make as to whether or not that's a number you can actually know. That's a separate discussion. But for now, we're just trying to put something together. Let's say this is a thing, you know, and so now, okay, so there's a bunch of these services. Each of them have some profit from corrupting them. And on the other side, there are these validators, and each validator has some stakeholders, right?
00:24:46.267 - 00:24:49.854, Speaker A: And by the way, by service, do you mean like what became sort of these AVs?
00:24:49.943 - 00:26:03.697, Speaker C: AVs, that's exactly right, yeah. Service and AVS are interchangeable here. And on the validator side, each validator has some stake, right? You can think of this as maybe their ETH stake. And so now in a, in a world where there's restaking, each validator might be using that stake for multiple services, right? So you can kind of think about this as a bipartite graph where on one side you have these AVs or services, and on the other side you have these nodes and you can kind of draw an edge between a validator and a service. If that validator is restaking or using their stake for that service, if they're acting as an operator for that service. And so now on the service side, each service has some profit from corrupting it, right? That's the amount of money you'd make if you were to launch an attack. And each service also, depending on how it operates, perhaps if it's like a PBFT style consensus system, there's some fraction of stake that's required among its total security that's required to launch an attack on it, right? So let's say to make things concrete, if there's one service, maybe just Ethereum and a bunch of these validators, one validator can't launch an attack.
00:26:03.697 - 00:27:26.411, Speaker C: You need a third of the stake, right? So the profit from corruption would be the profit from launching a double spend attack on Ethereum, the fraction required for corruption would be one third. And each validator has some stake corresponding to their Ethereum stake. And so now in kind of this general system. So actually maybe we'll start with that simple system with just Ethereum, right? You can ask when are things safe from a cost benefit analysis point of view? And that's basically when, if you look at 1/3 of the total staked Ethereum, if that is bigger than the profit from corrupting Ethereum, right? Because if the profit from corrupting Ethereum was bigger than 1/3 of the total stake of Ethereum, then it would be profitable for one third of people to come together and launch an attack, right? And so the baseline thing required for Ethereum to be sort of secure in some sense is that 1/3 of the total stake exceeds the profit from corrupting Ethereum. So this is one way to think about things. But even that you might not find super satisfying, right? Because there are lots of shocks that just happen in the world, especially in crypto, where there are definitely shocks that happen in the world. These shocks could be, for example, some protocol does unintended slashing on some stake or some stake just drops out for whatever reason, validators maybe go down.
00:27:26.411 - 00:28:23.545, Speaker C: Whatever it is, you can't stop small shocks from occurring in the world. And so let's say it was kind of the case that 1/3 of the total stake on Ethereum was exactly equal to the profit from corrupting Ethereum, right? We might say it's secure or maybe it's like equal. Maybe one third of the stake is like epsilon more than the profit from corrupting it, right? So it's kind of just barely secure. And this is kind of not that satisfying because if there's just any small shock that happens to the stake, then it all of a sudden becomes profitable to launch an attack. And so you can extend this notion of security to kind of, maybe you might call it robust security, which is to say, suppose that you allow some small shock to take place in the ecosystem. And now you want to understand what's the total amount of loss, ultimate loss of stake that can happen after some attacks. This is kind of what I was thinking about when I was thinking about systemic risk.
00:28:23.545 - 00:29:07.179, Speaker C: So to make things maybe more concrete, you can imagine in a situation where there's multiple services that some small shock happens in the world and it causes some validators to come together and attack some services, Right? And so now because they attack those services, those validators get slashed, they lose their stake. But those validators might have been restaking for yet other services. And so now those other services are a little bit less secure because people that were providing security for them have now gotten slashed. And so now as a result, other validators might come in and attack those services. And so this could continue go on and on. And a small shock might result in a loss of stake that's much greater than that initial shock.
00:29:07.347 - 00:29:18.655, Speaker A: How did you, like you modeled this, I guess, but this hasn't happened in real life, has it? It's not based on anything. So how do you know that that's how it works, that they would.
00:29:19.475 - 00:29:27.419, Speaker C: Great question. Yeah. Even right now, slashing hasn't been, at least to my knowledge. I don't think eigenlayer has started slashing.
00:29:27.587 - 00:29:38.175, Speaker D: Some of the other. But. But now there are multiple, multiple restaking. Some of them have more slashing and less like it's actually gotten more complicated than the original model.
00:29:39.515 - 00:30:19.583, Speaker C: But yeah, I mean, again, I think there's lots of facets of how this setup can potentially be induce risk. This was one particular one. In general, looking at cost benefit analysis and looking at how small shocks affect system. This type of small shock analysis, this has been done in the traditional finance literature before. When looking at systemic risk, it is kind of a motivated concept on that side. And it kind of is just. If you're just thinking about costs and benefits, it is kind of the first thing you might think of as, okay, how do I characterize risk? There's lots of other risks.
00:30:19.583 - 00:31:01.085, Speaker C: You might overburden a validator maybe with computational demand or yet many other things. But in terms of what can you kind of concretely understand, what made a lot of sense to me was to just look at, okay, maybe different bridges, have some understanding of what these profits from corruption for their services are. Right. And you can look at this whole graph, this graph exists, you can see who's restaking for whom and you can look at the stake. Yeah, this is kind of the first thing that came to mind in terms of how do you just look at system wide risk, maybe from Ethereum standpoint of if a small shock occurs, does the presence of all these additional connections between services lead to a greater possible Ethereum loss? Yeah.
00:31:01.785 - 00:32:01.599, Speaker D: One thing to note, and I think this is kind of one of the reasons I think it's good to formalize these things in an abstract math language rather than sort of something that's more engineering or pure kind of implementation. Like is that a lot of other networks have had things that look very similar to restaking, but they haven't analyzed it formally. So for instance, polkadot parachains and restaking are actually very similar. The only difference is that instead of this notion of the matching market happening by node operators choosing services, the equivalent of services here would be a parachain. Instead of the node operators choosing parachains, there was this auction and then they had to validate that particular service. So the matching was done by an auction versus the matching being done by. I get to choose where I place my stake.
00:32:01.599 - 00:32:46.519, Speaker D: But fundamentally they actually had very similar properties. I think the main difference is that when you're doing something like restaking, you can move your stake around and so you don't have to get locked into one service. So like the worst case thing that could happen in sort of the polkadot world, and I think this is often why people had trouble developing there is like you as the service had to raise a ton of capital to kind of win this auction and the thing is you had to raise capital in dot so you'd have to sell your token for dot and then like, Yep, yeah. And then you have to do a crowd loan. And the thing is, you could argue that the crowd loan plus auction is kind of as close as possible to what restaking is. Except restaking has. It's just easier for the end user.
00:32:46.519 - 00:32:50.087, Speaker D: Like operators can just choose to validate one or another.
00:32:50.191 - 00:33:27.001, Speaker A: We're validators. ZKV is a validator in polkadot. And so like your validator and polkadot. But you don't just choose which other parachain you're validating on, you also would become a collater on those. Actually there's another system like Cosmos ICS or Interchange Security which I'm now, I only am putting it together now that it sounds even more similar because there, it's very new, it's Like a year old or something. And as a validator on Cosmos you are actually actively choosing if you're going to be active on these interchange security chains. I don't know if you've, if you've looked at that.
00:33:27.001 - 00:33:28.937, Speaker A: Is that similar or is that so.
00:33:29.041 - 00:34:21.717, Speaker D: So one, one main difference between the Polka Dot and Cosmos versions of the world and the Ethereum version of the world is that in Ethereum restaking there's a floor on the amount that I'm earning. So I'm always earning Ethereum staking yield as at a minimum. The problem with all of the Polkadot Cosmos designs is they're very favorable to Atom and DOT as tokens and they're very unfavorable to the services because the services have to pay in Atom or DOT and they don't have capital, they have like a small amount of fees, they have their token. So what they have to do is sell their token, buy DOT or Atom and then participate. Whereas in ETH staking you have people who are already staking eth and earning 3 to 5% yield and this is viewed as supplemental income versus, you know, is the main thing needed from the services. So I see, I see. I think the economics in Ethereum are just strictly better.
00:34:21.717 - 00:34:58.739, Speaker D: And also I think there's a little bit of greediness in the, in both ICS and the DOT auctions in that they only benefit the validators. They don't like the social welfare. Like the splitting of revenue between the services and the validators is very unfair in a lot of ways in the DOT and Atom worlds, whereas the Ethereum one is closer to kind of. And this is the point of these matching markets, right, is like they're trying to do some welfare maximization type of thing between the two. And I guess Naveen, working on that in the past probably inspired this particular model. What's the genesis story of how you.
00:34:58.787 - 00:36:06.737, Speaker C: What'S super weird about the restaking matching market in particular is it's actually a matching market with the negative externalities. Normally in a matching market, as matches take place, you can talk about welfare increasing. But here what's interesting is as there's more matches, there's kind of more potential risk depending on how it's done. And the reason for that being that more things are kind of tied together and from a systemic risk point of view, you might expect things to get worse. Actually maybe I can say the conclusions that I only said what the risk measure is and not how to compare to mitigate it. But the main upshot is that over Collateralization is basically what's both necessary and sufficient to mitigate this risk. So what that means is if you go back to the Ethereum example, where there's just Ethereum and then a bunch of validators there, you kind of require that to make things robustly secure, where even if a shock occurs, things are still safe, you obviously need some buffer, right, between the profit from corrupting Ethereum and 1/3 of the total stake in Ethereum.
00:36:06.737 - 00:37:04.913, Speaker C: It turns out that from a global point of view, things are kind of similar. You need it to be the case that for any collection of services and any collection of validators that can attack those services, there needs to be some buffer, some buffer between what the profit from corrupting those services and how much stake would be lost in that attack. And you can actually bound, let's say that that buffer is some multiplicative factor. You can actually bound the total stake loss after any sequence of attacks in terms of that buffer. So, for example, to make things very concrete, let's say everything was always 10% over collateralized in the sense that any attack on some services always costed 10% more. The total stake required to attack some services is always 10% more than the profits from attacking those services. Then you can actually say that even in a worst case situation, let's say that a 0.1%
00:37:04.913 - 00:37:37.537, Speaker C: of total stake was just lost arbitrarily, then the total ultimate loss after any attacks thereafter is upper bounded by 1.1%. So you can really concretely bound worst case loss in terms of this buffer, which is a cool property. Of course there's caveats. Like I said earlier, knowledge of what these profits from corruption are might be limited to bridges or folks who are actually running those services, right? And so even though from a global perspective, it would be nice if you could always have this over collateralization, you.
00:37:37.561 - 00:37:40.285, Speaker A: Might not know how much you need to over collateralize.
00:37:41.065 - 00:38:21.993, Speaker C: So you as a bridge may not know what other folks are doing, right? This was only a global result of, you know, okay, if there's some random shock that happens in Ethereum, then that's contained. But how do I know that everyone is over collateralizing? And that's the requirement for this mitigation to hold true. And if I'm a service in particular, how do I make sure that I'm protected? And so the second part of this paper is really analyzing stuff from that perspective of if I'm a particular service I want to mitigate myself against. I might not even understand shocks happening. I might not have a good Understanding of what shocks might occur outside of my own ecosystem.
00:38:22.089 - 00:38:25.169, Speaker A: Right, yeah, yeah, but how do those shocks affect you anyway?
00:38:25.217 - 00:38:25.417, Speaker C: Exactly.
00:38:25.441 - 00:38:26.681, Speaker A: It might be good to know. Yeah.
00:38:26.753 - 00:38:47.069, Speaker C: Right, right. And so is there a way for me to, in a similar vein, mitigate worst case loss if I, you know, just from looking at a local perspective, if I only know my own profit from corruption, maybe the profits from corruption of some partners, is there a way for me to mitigate this? And it turns out there actually is. You just have to do kind of a different, different type of over collateralization scheme.
00:38:47.157 - 00:39:03.421, Speaker D: Anna, to your point about collaters, I mean, there's sort of this thing of like, hey, if you have a collater that's shared across multiple parachains and they drop out and messages don't get relayed and there's no one and there's no other, you know, it's sort of a similar type of thing that happens.
00:39:03.493 - 00:39:11.029, Speaker A: Although collaters tend to be per network. So you have like the main validator polkadot, and then you have a per parachain collater set.
00:39:11.077 - 00:39:12.991, Speaker D: Okay. They're never shared.
00:39:13.133 - 00:39:54.283, Speaker A: I mean, maybe. I mean, you might have the same companies running multiple. In our case, we only run Moonbeam and like we, yeah, we don't share it with anything else. I actually wanted to ask you a little bit more on the like, alternatives to restaking, because I wondered if like liquid staking is in any way in the same category. I realize it's, it's different. I mean, liquid staking is like you stake tokens and then you have synthetics of those tokens and you can do things, but this is also like you stake tokens and then you can do things with those staked tokens. So I just wondered if there's ever like, if the restaking research ever looks into the liquid staking and how that played out.
00:39:54.419 - 00:39:57.235, Speaker C: Toon, you wrote a blog post related to this, right?
00:39:57.275 - 00:40:37.239, Speaker D: Yeah. Yeah, a couple of things. One is the model that Naveen has in his paper doesn't really cover the principal agent problem where the node operators don't own the capital that they're staking. Right? So the idea is that for the node operator, the profit that they realize in this model is the profit from corruption of the set of services minus the total stake they could have got slashed. Now if you add in the principal agent behavior of someone is delegating capital and the node operator, if they get slashed, it's not their money. Or maybe only some of it is their money. Right.
00:40:37.239 - 00:41:01.151, Speaker D: Like you as a validator. Right. The majority of your capital is delegated. It's not your, your capital. Yeah, so the principal agent problem naturally leads to this kind of centralizing effect. Now the nice thing about this kind of graph model is it's actually not super hard to include principal agent effects. So I'm not sure you get as strong of theorems, but there, there's kind of a natural way to do it.
00:41:01.151 - 00:41:40.723, Speaker D: So there's sort of two papers from 2020 to now on liquid staking sort of principal agent effects. There's sort of a very old one that I wrote in 2020, and then there's a more recent one last year by Dionysus Zindros of common prefix slash. I forget where he was before Sui. You know, the question is like, what's the minimum amount of stake that you need the operator like you ZKV to have to put in yourself in order for the probability of you being like, I don't care about getting slashed as long as someone pays me enough for being part of their attack. Cartel should be.
00:41:40.779 - 00:41:44.255, Speaker A: It's like almost our own stake on the line, like the validators.
00:41:44.915 - 00:42:45.649, Speaker D: Yeah, yeah, yeah. And a lot of liquid staking protocols actually do require the operator to put up some stake. Like yeah, I think for Rocket pool it's like 2 to 4e, if I remember correctly. And then I think for a lot of the liquid staking protocols, there's, there's a minimum amount also. And so the idea is like, how do you choose that minimum? Like, what's the minimum you need to like guarantee secure. So one way you could do this is extend the bipartite graph description to a tripartite graph where it's one partition is the capital holders who are delegating, the next partition is the node operators and the next partition is the services. And then you look at the flow across that graph and you write out a kind of natural sort of principal agent problem thing and show that it has equilibrium such that if the node operators always have at least say, 5% of the stake is their own, then they're unlikely to deviate from the strategy as if it was their own capital by more than by a small amount.
00:42:45.649 - 00:43:14.347, Speaker D: And to be fair, this is actually true in society at large, not just in crypto, that the agents, as in the people who are acting on behalf of the principal, like the capital holder, often have to put up their own money. So like for venture funds or private equity funds or hedge funds, oftentimes the agents, the partners who are investing money, have to put in their own money. And so I think these types of things naturally show up in liquid staking. It's just like more messy to reason about.
00:43:14.531 - 00:43:20.875, Speaker A: But bringing it back to restaking. Does Restaking also have a principal agent percentage minimum?
00:43:20.995 - 00:43:26.591, Speaker D: Yes, it does. There's no doubt that that's still an open problem. I would say that's not solved.
00:43:26.623 - 00:43:31.075, Speaker C: Yeah, there's a lot of, yeah, definitely. Design's underspecified currently.
00:43:32.095 - 00:44:07.701, Speaker D: But I think you have to understand that with restaking, we're starting from nothing. So as to give a sort of example of why I found this really interesting is like in 2019, when Uniswap. I guess Uniswap was November 2018, but you know, same thing, close enough. 2019, when Unisop first came out, there were like all sorts of, you know, the code was running, people were liquidity providers. There were like people definitely doing arbitrage. But then you would read documentation about it and like the documentation from like people working on the protocol itself was like, didn't make any sense. Right.
00:44:07.701 - 00:44:38.207, Speaker D: They didn't really have a good explanation for why it worked. It was like, here's a formula, it seems to work. We don't really understand why. And like that is what led me to try to figure out, okay, maybe you should like think of it as this optimization problem, whatever. And I think what Naveen did was like, hey, look at this thing. There's actually secretly this graph problem and matching problem. If you squint enough, right? Like, even though the people who wrote it kind of wrote these sufficient conditions for when it could be safe and not safe, if you zoom out and think of it as this matching problem, then it becomes much more easy to reason about.
00:44:38.207 - 00:45:09.135, Speaker D: And I think oftentimes in research like this, a very important thing to do is more important than the actual solution to the problem oftentimes is having the right definitions. Because there's oftentimes this trade off in math of I either start with no definitions and very simple things and I prove a really complicated result, or I start with really long complicated definitions and then the result is trivial because I put all the complexity in the definition of the thing instead of in the answer.
00:45:09.285 - 00:45:13.295, Speaker A: Okay, who did which kind? Who's which in that description?
00:45:13.755 - 00:45:17.787, Speaker C: I think the ideal case is that you have a simple definition and then a simple proof.
00:45:17.811 - 00:45:19.707, Speaker D: Yes, you want something in the middle. In the middle.
00:45:19.771 - 00:45:20.615, Speaker A: Okay, okay.
00:45:22.035 - 00:45:51.245, Speaker C: No, but I think even to your point about this ending up being a very clean graph problem for those anyone who's more on the TCS theoretical computer science side, actually in the case where everyone's the same stake, every service has the same profit from corruption. The problem actually of checking for security becomes checking whether or not this graph is an expander graph which happened to be some nice. There's just some nice structure in the problem.
00:45:51.405 - 00:46:13.769, Speaker A: I want to go a little bit back to the connection between the matching work and the paper because Tarun, you're saying that sort of the technique was turning it into this matching problem, but somehow for me I've lost that connection. I heard your beginning, Naveen, where you were talking about what you were doing before, but yeah, what's matching in here?
00:46:13.937 - 00:47:01.835, Speaker C: So I guess as it was framed before in appendix B of the Eigen layer white paper, you kind of just had these parties, right? You had these services or avss, I think they call them tasks even. And then you have these node operators or validators that had some stakeholders and you can kind of think about these balance conditions in this kind of cost benefit analysis that I was describing of when is it the case that there aren't any validators and tasks or services for which those validators profit from launching those attacks? Right. The thing that model doesn't quite help you with is looking at I guess broader counterfactuals or looking at the structure between what validators are putting their stake in different services.
00:47:03.615 - 00:47:05.831, Speaker A: Is the matching is.
00:47:05.863 - 00:47:08.829, Speaker C: Between validators and services and AVs.
00:47:08.916 - 00:47:09.263, Speaker A: Okay.
00:47:09.350 - 00:47:52.955, Speaker C: Or AVs. Right. And a validator is matched to a service if they're re staking for that service. Right. And normally in a matching market, right. Let's say you think about a job market, so you have a bunch of these people that want jobs and a bunch of these employers, right? And you can kind of normally think of it being the case that I guess it depends on the setting but in most common settings each match is a little bit, is kind of separate from each other, right? Like if I get a job at some company, someone who's getting a job at a different company, it doesn't really matter to them that I got a job at this company. Now if they're competing with me, then maybe it matters, right? But in a sense the payoff that I got is somewhat separable from the payoff that they got.
00:47:52.955 - 00:48:41.075, Speaker C: And those things also led to positive externalities, right? Like I worked for this employer, the employer thought it was profitable for me to do this. I thought it was profitable for me to do this. It was like, you know, welfare was received by both parties. What's interesting about the restaking matching market is that when a validator is matched to a service and then a validator is also matched to a different service. Right? So let's say a validator is already matched to Ethereum in the sense that they're a staker for Ethereum and now this validator now chooses to also restake that eth for another service. Them making that choice has consequences for Ethereum. Right, because it imposes a negative externality on Ethereum in the sense that that other service that he's taking for now has the rights to slash some some eth.
00:48:41.075 - 00:48:55.591, Speaker C: And depending on how it's implemented, this could lead to a negative externality on Ethereum in that staked eth could disappear due to the actions of other services. Whereas in a world where you couldn't match to these things, that couldn't occur.
00:48:55.743 - 00:49:09.799, Speaker A: Interesting. How are the AVS's like, are they offering, I'm guessing AVSs offer unique incentives to the validators to get them to validate them. What are these? Just native tokens on the avss usually.
00:49:09.887 - 00:49:54.597, Speaker D: So actually, actually this is, this, this is sort of what the, my follow up paper that kind of took Naveen's framework and tried to analyze what happens when there's this reward mechanism. So I think if you look at it from the abstract graph problem, there's sort of some natural way that validators choose services. Right? You're just like you're given a graph like ZK Validator has chosen E Oracle and Eigenda and none of the other services. Right? That's a choice you made. And then given that Naveen's paper analyzes like how do you attack that? On the other hand, in practice what happens is basically services give you fees plus native tokens which you can, you know, you could think of like block rewards from staking, right?
00:49:54.701 - 00:49:55.293, Speaker A: Yeah.
00:49:55.429 - 00:50:17.439, Speaker D: And so they give you some amount of rewards and then you as the validator have to choose the subsets of services you want to operate. Right? So like if say ZKV was running a bunch of restaking nodes, you would say, hey, eigenda is giving me 5 ETH of yield a month. E Oracle is giving me 1 ETH. I'm just taking the top three from the live right now.
00:50:17.487 - 00:50:22.015, Speaker A: We should make it clear ZKV is not currently running any of these. These are just theoretical.
00:50:22.175 - 00:50:25.327, Speaker D: I'm just, I was just, I was just using you. This is an example.
00:50:25.391 - 00:50:27.511, Speaker A: I like don't use me. I don't mind, I don't mind.
00:50:27.623 - 00:50:52.081, Speaker D: And, and then let's say you were. I'm just going down the list of the live AVS's like witness chain was offering 15 ETH a month. Well you say have 100 ETH that you want to restate. How do you determine where you want to put it? Naively you might say hey, I want to put it all in Witness Chain. Right. Because best return they're offering me the most yield. Yeah, but Witness Chain might just be very slashable now for to Witness Chain people.
00:50:52.081 - 00:50:57.633, Speaker D: I'm not saying you are. This is all hypothetical. I'm just saying like suppose it turns out it's the most flashable.
00:50:57.689 - 00:51:01.899, Speaker A: We have to be careful. We should almost use like ABS A, ABS B or something.
00:51:01.947 - 00:51:27.979, Speaker D: But anyway I, I just want to make it more concrete. Yeah, yeah, because I think like if you make it concrete it's like a little cleaner. So suppose you get, you say okay, I put all my hundred ETH into the witness chain thing. I expect to get 115 ETH after a year. But actually I got slashed on 90 of it. My loss is not just the 90E I lost, there's also the future profits I lost like oh I didn't lose. I, I didn't get that 15 cuz I was expecting one 15.
00:51:28.107 - 00:51:32.169, Speaker A: Do you get out when you get slashed? Is that why like you would never or you don't receive?
00:51:32.257 - 00:51:51.593, Speaker D: Depends. That's actually up to the service. That's up to the service. The other thing is I have the opportunity cost of the lost eth staking yield. Right. Because before I had a hundred eth that was say ste like staked eth and it was earning 3% so I expected to get 103 after a year. But now that I've gotten slashed I've lost that 90.
00:51:51.593 - 00:52:03.531, Speaker D: And to Naveen's point, there's this negative externality on ethereum itself. In that Ethereum lost 90 ETH that was staked in Ethereum. So lost 90 of security due to something outside of ethereum.
00:52:03.643 - 00:52:13.227, Speaker A: Yeah, because actually who slashes you? It's the is the avs that slashes you. No, like who gets to take the eth? Where does it just get burned? What happens to it?
00:52:13.371 - 00:52:17.355, Speaker D: Well it depends. But for the purposes of this paper, it's burnt.
00:52:17.475 - 00:52:22.299, Speaker A: It's burnt. Okay. No one gets it. It's not like someone take okay, it's gone.
00:52:22.347 - 00:52:25.555, Speaker D: But remember, it's reducing the stake supply, right?
00:52:25.935 - 00:52:29.235, Speaker A: Yeah, but isn't it kind of good for a network when you burn tokens?
00:52:29.735 - 00:52:38.943, Speaker C: I guess. I mean there is a macroeconomic effect of you're distributing if the total market cap stays fixed and you burn tokens, then you're distributing wealth back to token holders.
00:52:39.079 - 00:52:42.951, Speaker A: But on the staking front you're losing stake, so you're losing security, so you're.
00:52:42.983 - 00:52:45.959, Speaker D: Making it easier to attack in some sense. Right?
00:52:46.007 - 00:52:46.551, Speaker C: Right.
00:52:46.703 - 00:53:29.853, Speaker D: And so the idea there is this trade off between the two. But honestly the thing is it does allow these services to get security as if they were themselves an L1 in some ways. And so there's this question of like if I'm a new service, let's say I'm an oracle. Let's say I'm a new rollup that wants a decentralized sequencer and doesn't just live off a multisig forever. I need some way of enforcing penalties on the off chain actors who enforce some state transition. So in the case of roll up a sequencer, in the case of say a ZK prover, the people generating the proofs, in the case of Oracle, the people aggregating. The thing is I could start a new L1, right? But then I have to bootstrap everything.
00:53:29.853 - 00:54:16.707, Speaker D: I have to figure how to get liquidity, I have to get stablecoins, I have to do all of this stuff that's very hard to get new validators. But the question is when are the economics such that it actually makes sense for me to join a shared network even though I have to pay rewards such that it is above this over collateralization threshold versus just completely starting a new one. And the idea is that trade off is a combination of understanding the economics of how much you have to pay in rewards combined with understanding this notion of CA security that Naveen made. Right. Because you want to pay enough such that you don't have those kind of risks so you want to be over collateralized that much. But at the same time you also don't want to pay so much that it's cheaper for you to start your own L1.
00:54:16.841 - 00:54:17.687, Speaker A: Hmm.
00:54:17.871 - 00:54:28.555, Speaker D: Does that make sense? And so that's the, that's the trade off, that's the balance. And so yeah, our paper is about that and like how much you have to pay like to get that type of security.
00:54:28.895 - 00:54:30.407, Speaker A: That's what your paper was tarun.
00:54:30.471 - 00:54:33.927, Speaker D: And then we're just sort of following on Naveen's paper.
00:54:34.031 - 00:54:34.439, Speaker A: Cool.
00:54:34.527 - 00:55:35.515, Speaker D: But I think this idea is just going to is more fundamental to blockchains that like there's some things that can share security and there's some things that need to be isolated. It's very much like lending or perpetuals like the defi aspects of things. And I think the interesting thing about restaking from A theoretical lens is it. It blends a lot of the analysis of proof of stake that has existed for a while that people in consensus think about with the analysis of things in defi and sort of like it's like exactly in the middle of the two. And I think because of that it sort of is a superset of a lot of things people are working on like subsumes doing all these off chain services like roll ups. It subsumes some of like how should you analyze the economics of data availability? It's like a more general framework to analyze all of these many different economic problems. Which is one thing I think people don't, you know, I think restaking obviously people think about the yield and whatever but like if you zoom out the real thing you should be thinking about is this type of stuff.
00:55:35.595 - 00:56:12.791, Speaker A: I find it so wild that like last year or two years ago when the like ZK roll up world was announced, I remember Tarun you being like man, everything's all paths lead to polkadot. But actually there was a lot missing from the roll up model to be more like polkadot. And now I think what you're describing, just going back to what you were saying before, it just, it seems like it's a different version, maybe learning lessons from how polkadot went. Especially in terms of like launching these AVS's and like incentivizing them. But it has more I feel in common with like that polkadot model than roll ups do for sure.
00:56:12.903 - 00:56:27.991, Speaker D: But you have to remember that the reason that we don't see rollups doing that is that the roll ups haven't delivered on all the promises that they were supposed to make. Right. Like they haven't gotten. And when they do that they have to have ways of penalizing the sequencer. And there is no way of penalizing the sequencer right now. Right?
00:56:28.063 - 00:56:28.407, Speaker A: Yeah.
00:56:28.471 - 00:56:37.821, Speaker D: Fundamentally I think that is the thing that is missing. Like even in a centralized sequencer world if a fraud proof executes, I should be able to slash the sequencer. I cannot do that right now.
00:56:37.903 - 00:56:38.313, Speaker C: Right.
00:56:38.409 - 00:57:04.581, Speaker D: There's no penalty. And my point is the restaking stuff, if you look at it from this matching market lens kind of subsumes a lot of these different things that people are like making specialized economics for, including ZK proving markets. Because I think there's a lot of this like service versus consumer versus producer relationships in ZK provers. Right. Where there's like many networks that might be sharing some prover network and like they have to figure out how to.
00:57:04.613 - 00:57:07.805, Speaker A: Price things theoretically doesn't exist theoretically.
00:57:07.965 - 00:57:20.661, Speaker D: But my point is restaking is the first live market that is actually trying to solve this directly as the economics problem. I'm not sure the people working on it think of it this way, but this is what's emergently happened.
00:57:20.693 - 00:57:59.683, Speaker C: Actually. Maybe to give a second framing of, I guess all of that in terms of the construction of the matching market. I think True's basically been outlining, I guess, two separate problems. One of them is you can talk about what's the current state of who's risk taking to whom, and then you can discuss the security of this and maybe even the robust security of this. This is what I was working on. And then what Trune's been talking about is, okay, now what actually is that graph, how does that graph get generated? And what are the processes that dictate who ends up actually restaking to whom so that you can actually make sure that that graph does satisfy the original properties of what's safe and not safe.
00:57:59.859 - 00:58:47.599, Speaker D: Yeah, and I think this notion of what the safety and not safety is something that, especially from this economic standpoint is something completely unmodeled or kind of given a lot of delicate care in all these other networks like DA proving roll ups, because mainly because right now there's just this hunt for demand for any application to actually use them and generate fees. Whereas with restaking there actually are more applications that you can imagine paying fees. There's a lot of things that are closer to defi looking, things like oracles that have business models. And because of that, I think it's the proving ground where you can test out how you should think about the economics for all these other areas.
00:58:47.727 - 00:58:50.887, Speaker C: Actually this is a pretty decent seg into resource pricing.
00:58:50.991 - 00:59:24.363, Speaker D: Perfect. Yeah, sorry. Yeah. So maybe, maybe we should talk about, you know, you're working with tim on your PhD who is kind of, I think one of his first crypto papers was, was about resource pricing and Ethereum and how to think about it. And you, while working at Ritual, have been thinking a lot about resource pricing in a more abstract sense, which kind of maps to this kind of thing of like there's service providers and there's capital and how do they get matched together and what's the price they should pay. So maybe we could jump into that.
00:59:24.419 - 01:00:09.039, Speaker C: Yeah, maybe to give a little more context on that too. So currently there's a lot of literature on transaction fee mechanisms and this is like 1559 or 4844. And there the idea is, okay, you have a blockchain and it enables some amount of compute. But obviously there's a limited supply of computer. And so you need to figure out how do you price things so that you match demand and supply. And ritual is a chain that's trying to enable more complex computation, notably transactions that might require AI inference. And so there, if you're thinking about running this stuff, a lot of it will have to be run off chain and perhaps through ZK proofs or other stuff, it'll be reported back on chain.
01:00:09.039 - 01:00:53.161, Speaker C: And you have this issue of how do you actually price this stuff, right? Like if I'm an off chain entity or even if I'm trying to incorporate this on chain, I'm just some node that's doing a workload that is very different from other nodes, right? I shouldn't expect to be paid the same. I'd be pretty dissatisfied if I was being paid the same as every other node. And so there's kind of this general problem of on one side you got all these transactions and they might have very, very different computational demands, and on the other side you have these nodes that can perhaps process very different workloads in this heterogeneous setting. And then there's a question of, okay, in this world, how do you figure out who does what work and how much do they pay? And so that's this resource pricing stuff that I've been working on.
01:00:53.273 - 01:00:57.249, Speaker A: Is that connected to this? Is it in the restaking work or.
01:00:57.257 - 01:01:23.397, Speaker C: Is it totally different, totally separate from the restaking work? I mean, I guess there are similarities in that they're both matching markets and they both also apply to similar entities in the sense that just like how Tarun was talking about restaking being helpful for coordinating incentives for interoperability and stuff like that, in terms of what those exact incentives should be and how they should be determined. This is relevant there, but largely speaking, these are separate things.
01:01:23.541 - 01:02:02.897, Speaker A: Got it. I wonder. Okay, so this is a more like perception question, but in the last year, early on in the year, I think everyone is very, very excited about restaking. And then Eigenlayer launched and there was this kind of frustration and anger about all sorts of things, but it seemed like there was almost a sentiment change against restaking, at least on Twitter. And I just wonder, like in the research though and like in the real world, is there actually? Because I also know about a lot of teams that are like now AVS's and they weren't before. So I'm sort of curious, looking from the research side, if you like, see any of that or have some opinions.
01:02:03.031 - 01:02:37.147, Speaker C: I think on the research side, it's kind of become more clear that a, there's a lot more interest in restaking as things are starting to go from idea to actually deployment. And coming with that is more of an interest in, okay, how do we make sure things are actually secure. So from a research perspective, I think interest in research on secure restaking has definitely become more relevant in terms of positive or negative spin. I don't know. I mean I think there's just a lot of parties that are interested and a lot of parties that now care a lot more than the day before about the practical implementations of these things playing out properly.
01:02:37.251 - 01:02:40.575, Speaker A: I can see when I asked this question, Tarun was kind of like annoyed.
01:02:41.355 - 01:03:22.575, Speaker D: I'm not annoyed. I think it's funny because it's like, it does really remind me of the early days of DeFi in 2019 when Uniswap launched and had $10 million liquidity, which at that time I think it was the only on chain contract that had anything close to that. And everyone was like, oh, it's a scam, it's going to be a Ponzi scheme, it's going to blow up. And there's a lot of fud. The second thing that people also always say is like, okay, the slightly like, you know, the, that's like the 30 IQ take, the Adiq take was like, well, there's so much adverse selection because it's a trading strategy that shows you the price all the time so everyone will front run you. Which you know is not untrue. There is, there's definitely.
01:03:22.575 - 01:04:13.561, Speaker D: But for some assets you don't have a choice, especially back then because exchanges were not listing things anywhere near as aggressively, so there were no other primary venues. And then I think eventually once people started actually building more things that were used around it and composability became. The benefits of composability became way more clear. You know, for instance, for making, lowering the LTV for maker and compound and stuff, people started being like, oh, okay, I kind of get what it's doing. And I think Restaking probably just has reached the point where there haven't been any AVSs that have like had that impact yet. But I think, like I said, I think the fundamental thing, if you zoom out and don't go based on like Twitter where everyone is just like, oh, I got 5,000 free points for yield, whatever, like ignore the. This is what I'm saying.
01:04:13.561 - 01:05:16.643, Speaker D: You have to like zoom out beyond this. Like people who are just like yield maxing on Twitter and then getting angry that they got fewer points, whatever. That doesn't have to do with the mechanism. That has to do with just like the, the projects, Ponzi funding things. But I think like if you zoom out, the main point is, is that it's a way of deciding having networks where you can either decide to share security in a very precise way that has some covenants and guarantees, which means that you're taking on some risk for doing that, but obviously you're getting some reward. And it gives the end developer the choice of do I want to start a new network from scratch and go through the entire process of doing that, or do I want to be able to use an existing network? And I think the interesting thing about Polkadot was like they had all these ideas there from the beginning, like this idea that the main chain was like the layer zero for the parachains and they would share it. But the problem is I'd say the Polkadot model economically was like too greedy.
01:05:16.643 - 01:06:39.327, Speaker D: It didn't welfare optimize for the whole network. It literally welfare optimized for dot holders. And I think the weird thing about restaking is because ETH already kind of had a working economic system, adding this afterwards was like, is more effective than trying to start from scratch with that, if that makes sense. And I would say like, you know, I think again, I think there is a lot that was learned from the lessons of the Polkadot design. And you know, I mean, restaking still prove itself. But I do think, you know, when you get to this fundamental economic question of I have off chain services that need to get matched to participants who will secure them, how do you do that? How do you efficiently, what should the market structure look like? And I think we're finally at this point in crypto where all of this stuff that people have talked about for matching markets can happen live and iteratively, right? Now another thing about the history of matching markets like kidney exchange or the residency matching programs or you know, all the stuff that sort of matching markets have historically been associated with is they're usually thought of as these one shot games, right? There's like everyone who's graduating from med school in one year in the US gives their preferences and then the hospitals give their preferences and then they get matched, right? That's, that's like, but that's a one shot thing. Like once a year, every year is a different student.
01:06:39.327 - 01:07:17.275, Speaker D: So it's like a totally different thing. But these crypto matching markets are very unique in that they're iterative and like constantly and evolving and like that's, that's the thing that I think is very unique about them, that even in normal finance you don't see as much like sort of online advertising, you kind of see this, but even then it's not quite the same because the user doesn't have control over their matching. The matching is done effectively by the platform, like the Google, Facebook, Amazon, they're auto bidding on your behalf, they're kind of doing most of the work. You don't really can't change exactly how it works. But a unique thing in crypto is that this is happening live on its own with billions of dollars.
01:07:18.495 - 01:07:40.033, Speaker C: And I think what even complicates that further is that it's like halfway in between being a batch system and a continuous streaming system in that we've discretized the world into blocks and there are weird consequences of that being a batch process, while at the same time there's a continuous stream of people having demand wow. Or use of a blockchain.
01:07:40.169 - 01:07:56.169, Speaker A: That's funny. As you describe all this, I start to wonder how or if MEV changes at all through this. Like in the restaking world, does it open up new places where there's crazy arbitrage? Have you looked into that? Has anyone?
01:07:56.297 - 01:08:10.837, Speaker C: I think that definitely opens up. There's a huge, huge amount of thought on, you know, interoperability in general and consequences for that for mev. So there's the people working on shared sequencers and other stuff like that. So definitely, there are definitely implications for it.
01:08:10.941 - 01:08:20.397, Speaker D: But yeah, Wait, wait, wait, wait. I would have thought you'd have more of an answer because I feel like the broker mechanism stuff for the resource pricing is kind of thinking about.
01:08:20.461 - 01:09:08.313, Speaker C: So there, there's a, there's the connection that's less tied to restaking. But yeah, I mean MEV in terms of interop between different parties, you can talk about maybe different types of mev. There's MEV that comes more from arbitrage of lag times between different parties that have different information. I think this is definitely a thing that is relevant, maybe harder to study theoretically. And then there's also MEV that comes from just having a richer ecosystem to work with. And MEV is often thought of as a pure net negative. But you could even think about MEV in a different light as it's a type of just in time coordination that's going on currently.
01:09:08.313 - 01:09:26.525, Speaker C: All of these types of coordination that's happening because most of what's happening in crypto is a zero sum game, it's just extracting stuff from the parties from other parties. But in cases where there's not a zero sum game, you could perhaps imagine that this leads to some net positive.
01:09:26.904 - 01:09:45.168, Speaker A: That's funny. Funny you just mentioned just in time because that is a late 90s, early 2000s management term and I'm amazed to see it now once again. That's cool. Naveen, do you have any like research in the works that you want to shill or share? Anything coming out?
01:09:45.216 - 01:09:58.799, Speaker C: Sure, yeah. Yeah. The restaking stuff is already out, but also have been working on this resource pricing related work that we very lightly touched on that's probably going to come out in the next, I don't know, month or so, if I were to guess.
01:09:58.927 - 01:10:24.437, Speaker A: Cool. Well, thank you so much for coming on the show, sharing with us sort of your early research and how it led to you working on this restaking stuff and then going deep on the restaking stuff and letting me ask a lot of questions about restaking that I've always wanted to ask. And this has really helped me to understand much, much more how you're thinking about it, but also how one can think about it a little differently than maybe it's initially been described. So thanks.
01:10:24.581 - 01:10:31.973, Speaker D: Just ignore the 5000 points for subscribing to my restake because that stuff is not the point of the mechanism.
01:10:32.029 - 01:10:32.945, Speaker A: Yeah, yeah, yeah.
01:10:33.645 - 01:10:35.949, Speaker C: Thanks so much for having me. It's been awesome to be here.
01:10:36.037 - 01:10:45.355, Speaker D: Hey, thanks for coming on. I'm happy that hopefully we can dispel the myths about restaking slowly over time.
01:10:45.525 - 01:10:53.695, Speaker A: Yeah. Okay. I want to say thank you to the podcast team, Rachel, Henrik and Tanya, and to our listeners. Thanks for listening.

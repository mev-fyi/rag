00:00:06.330 - 00:01:05.434, Speaker A: Welcome to Zero Knowledge, a podcast where we explore the latest in blockchain technology and the decentralized web. The show is hosted by me Anna and me Frederick. In this this episode, we chat with Jan Michalevsky, CTO and co founder of Njuna Security. We talk about tees, or trusted execution environments, and dig a little bit deeper into the topic. You so before we start, we want to say thank you to this week's sponsor, O one Labs. O one Labs is the company behind Coda Protocol, the world's first succinct blockchain. Using recursive zero knowledge proofs to make cryptocurrency decentralized at scale, coda swaps the traditional blockchain for a tiny cryptographic proof, enabling a far more accessible cryptocurrency.
00:01:05.434 - 00:01:46.590, Speaker A: This makes it dramatically easier to develop user friendly, privacy preserving crypto apps that run natively in the browser and enable more inclusive, sustainable consensus. Their testnet is live in beta and has consistently been one of the most active testnets in crypto. Today you can join their community of engineers, cryptographers and researchers by visiting codaprotocol.com, sign up for their newsletter to receive updates on Testnet progress, mainet launch, and their forthcoming developer, SDK. So thank you again, one Labs. And now here's our interview with Jan from Njuna. So today we're sitting with Jan from Njuna Security.
00:01:46.590 - 00:01:48.010, Speaker A: Welcome to the show, Jan.
00:01:48.090 - 00:01:51.930, Speaker B: Thanks, Anna and Frederick. Excited to be on the podcast.
00:01:52.090 - 00:02:24.314, Speaker A: So today we're going to continue on a topic that we touched on some time ago that is of Tees trusted execution environments. The last episode we did was with Chaiche and Lukesh from Gollum, and we had talked about the graphene project. We talked a little bit about tees and some of their threat models, and we're hoping that in this episode we can actually dig a little deeper into des and what Andrewna's doing and basically get a little deeper into this topic. This is the first time we meet, so I'm very curious to hear about who you are.
00:02:24.432 - 00:03:20.578, Speaker B: Yeah, so a little bit about myself. I started my career in software engineering as a developer and a software architect, managed development teams back in Israel. And about seven years ago I moved to the Bay Area to pursue my phd at Stanford and basically got drawn back to security, which is something I was working on previously in the industry. And I actually imagined I would do signal processing and more Wi Fi related stuff. But then I started working with Dan Bonet and we started working on sidechannel attacks on mobile devices, which actually combined disciplines like machine learning, signal processing and security. So I basically got to use my knowledge in signal processing from electrical engineering degree and applying it to security. And we had a couple of works that were pretty successful.
00:03:20.578 - 00:04:16.634, Speaker B: So I continued working with him, then drifted into things like cryptography, specifically attribute based encryption. And towards the end of my phd, when SGX came out and started gaining traction both with academia and industry, there were a lot of publications in the space of trusted execution environments. I got interested in that basically because of the tremendous promise of it for practical security in the industry, and started thinking of what can we improve in terms of the software stack around Intel? SgX started some academic work that we'll probably talk about later in the podcast, something called Cosmics, which was a pretty long collaboration that resulted in a recent publication. But also once I finished my phd and defined my thesis, I basically started looking into how to commercialize something and how to productize something around those new technologies.
00:04:16.762 - 00:04:18.942, Speaker A: And I guess this is where Anjuna comes in.
00:04:18.996 - 00:04:38.830, Speaker B: Yes, and that was the technical basis to Anjuna. So I found my founder and partner at the time that actually knew previously from Israel, and we partnered to start in Juna and basically with the mission of delivering privacy and security for cloud based and server side applications.
00:04:38.910 - 00:04:46.166, Speaker A: Cool. I have just a couple questions about your background here. So you said you were in Israel before. Were you studying there? Were you working there?
00:04:46.268 - 00:05:10.734, Speaker B: So that's where I grew up, since I was about eight years old. Yeah. So growing up, went to the Technion there. So if you're familiar with Starks, that's where elephant son is teaching. We know that. Okay, you're familiar with the institution? Yeah. So that's my alma mater, that's where I did my electrical engineering degree, worked at a couple of startups there, and then seven years ago I moved to the Bay Area.
00:05:10.852 - 00:05:14.530, Speaker C: Why are there so many good crypto people coming out of Israel?
00:05:15.750 - 00:05:51.306, Speaker B: It's a good question. I think one answer to that is probably some of the military background people have and kind of the interest in seagint. And basically if you look at kind of where you have strong crypto disciplines, you can kind of look at those countries and see that there's some background of intelligence there. Basically it would be probably things like Britain, Germany, uS, Israel. Actually, I heard that Belgium has the highest number of cryptographers per capita, so I'm not sure what's going on there.
00:05:51.408 - 00:05:53.760, Speaker A: Well, I think that's maybe because of Leuven, right?
00:05:54.130 - 00:05:55.230, Speaker B: University, yeah.
00:05:55.300 - 00:06:20.590, Speaker A: That's such an interesting idea is the way that the cryptography encryption and sort of blockchain cryptography, where that's being developed the most, these hubs that seem to be emerging, I mean, for zero knowledge, I've said this a couple of times, but I seem to be seeing like, San Francisco. I'm going to put like Berlin, living in London in one category, and then Tel Aviv is definitely another spot for that. Do you know of any other hubs? Would you list something else there?
00:06:20.680 - 00:06:59.794, Speaker B: Additional hubs for cryptography? Did you mention the Bay Area? Yeah, SF, I guess, in those disciplines, specifically with cryptography, doing good work on cryptography doesn't necessarily require a lot of resources or a lot of people. So once you have one kind of leading figure, you can have groups of students forming around this lab and doing interesting work. So, for instance, in Israel would be someone like Adi Shamir, or around Tromer, Ellie, Ben Sasson, the Technion. There are people who are doing way more theoretic crypto here that seems to be.
00:06:59.832 - 00:07:04.194, Speaker A: I mean, you have the Berkeley crew, and then you have the Dan Bonet lab.
00:07:04.312 - 00:07:22.134, Speaker B: Yeah, you have the Dan Bonet lab at Stanford, and in Berkeley you have Alessandro Chiaza, and then you have the east coast cryptographers, Shafi Goldwasser, and some of them are more on the theoretic side. And you have Ron revest that did a lot around practical cryptography.
00:07:22.182 - 00:07:23.878, Speaker A: Where are they based? What cities?
00:07:24.054 - 00:07:30.566, Speaker B: That's Cambridge, that's MIT. Okay, you have Boston University, where you have Ronconetti.
00:07:30.678 - 00:07:39.294, Speaker A: So maybe that's my next stop on my kind of. Lately I've been on a journey to hit up the zero knowledge hub, so maybe that's the next spot. I got to go.
00:07:39.332 - 00:07:43.438, Speaker B: Yeah, they're definitely becoming a hub. They recently had the crypto economic summit. Cool.
00:07:43.604 - 00:07:58.370, Speaker A: All right, so let's jump into our topic, which is tees. We did define this on the previous episode we did on tes, but I think it's really important to introduce it again. So maybe, in your words, what's a tee?
00:07:58.530 - 00:09:00.570, Speaker B: So te stands for a trusted execution environment, and it's a bit of a vague definition. It can be all kind of things. I guess you already talked about some of those definitions in the previous episode about ease and SGX, but it's basically an execution environment, which means some environment where you can execute code, execute some logic, some computations, and you trust it. And then the question is, what is this trust based on? For instance, in the case of the technologies that we're going to talk about, like intel software, guard extensions and MD's, secure encrypted virtualization. You basically have some hardware root of trust, and to some extent you trust some of the manufacturing process and eventually the companies behind those chips. You can also imagine some other trusted execution environments. For instance, there are more use case specific execution environments like hardware security models or hsms, which are basically trusted execution environments for specifically cryptographic operations.
00:09:00.570 - 00:09:09.098, Speaker B: So those are actual hardware appliances that you trust to do something correctly and deliver a result you can trust.
00:09:09.184 - 00:09:23.778, Speaker A: And that's where Intel SGX would be a hardware version. Yes, but there are also, this is actually, I just learned this from going through some of your material, but there is actually a software te. Is there a standalone software te style? Is that a thing?
00:09:23.864 - 00:10:31.298, Speaker B: I guess what you were referring to is virtualized trusted execution environments. So for instance, in many cases we trust the hypervisor, something that runs multiple virtual machines, to basically manage and properly isolate access to memory, whether it's between different virtual machines or within virtual machine that's running the whole operating system, to isolate a certain memory region and create an enclave similar to what hardware based trusted execution environments provide. So we have those technologies as well. For instance, hyper V implements something called virtual secure mode and virtualization based security. There was a publication from several years ago that was called Overshadow, and that was basically an introduction of this concept of the hypervisor, creating a memory region that even root users inside the virtual machines wouldn't be able to access. So in this case, you trust the hypervisor.
00:10:31.474 - 00:10:42.134, Speaker A: Frederick, this is kind of a question to you, but I know in eth two research right now, there's a lot of talk about execution environments. Maybe not tees, but ees. Is this sort of a similar concept?
00:10:42.262 - 00:11:17.270, Speaker C: No, not really. So the e two execution environments are basically derived from the polka dot execution environment, which is just a broad term of like for e two and polka dot specifically, they're an environment that you execute wasm code in. It's basically a container like similar to how Docker is an execution environment. It's a way to containerize certain code, and it doesn't have the same security guarantees or implications of tes, or even maybe to some extent virtualization.
00:11:17.610 - 00:11:21.350, Speaker A: So I guess what you're saying is the t in tes matters.
00:11:22.010 - 00:11:22.760, Speaker C: Yeah.
00:11:23.370 - 00:12:00.702, Speaker B: So I guess one parallel is in the context of blockchain, we often also try to achieve trusted execution, basically executing some logic and getting a result that we trust. But we gain this trust from having white consensus over the computation and over the result. Whereas with those hardware based trusted execution environments, there is only a single element that provides this trust that is supposedly very hard to break, and that's how you get to trust the computation result. So that might be the parallel between the kind of blockchain and the hardware based trusted execution environment.
00:12:00.846 - 00:12:49.074, Speaker C: And that's sort of how when we're looking at tes and their applications in blockchain, it's usually as a means to not have to re execute something. So in a blockchain, because you want consensus on something, each node has to reexecute the computation. And if you have 1000 nodes participating in consensus, then all of them need to re execute it. And usually because of the way blockchain history is, usually people reexecute the computation when you're syncing as well. So basically all nodes redo it every time. And the charm of a tee and what it could bring if you wanted to trust one, was that, or is that you now only have to execute it once, and then you can put the result on the blockchain and say it was executed by this te. No one else has to do this.
00:12:49.074 - 00:12:51.140, Speaker C: Again, just trust this result.
00:12:51.830 - 00:13:51.266, Speaker B: And I think the two can be basically complementary. So for instance, let's look at the example of byzantine fault tolerant protocols. There you basically have consensus over some computation, and you hope that an attacker doesn't take over more than a third of the network, because that would compromise the protocol and you can no longer trust the result. So you can combine the two. You can both have some group of users or computers that achieve a consensus, but you can also try to secure each individual node or each individual user with something like a trusted execution environment to provide some guarantees around the hardness of getting more than this third malicious majority for a powerful attacker. So that's actually something we were looking into a bit. And what we did there is taking tendermint.
00:13:51.266 - 00:14:38.898, Speaker B: Are you familiar with the. We know, yeah. So we took tendermint, which is part of the cosmos framework, and we basically run tendermint nodes inside the trusted execution environment, basically hardening each node and preventing an attacker from taking over those nodes. And that can be especially interesting when you're just bootstrapping this kind of network, because at the beginning you might not have too many nodes, and it actually might not be so hard to create this one third malicious majority. So this combination of trusted execution environments and consensus can be something powerful that enables you to bootstrap such a network until you get too many users that would actually guarantee the correctness of the results through the consensus.
00:14:38.994 - 00:14:43.014, Speaker A: Wow, the cosmos on launch, they didn't actually do that?
00:14:43.132 - 00:14:54.870, Speaker B: No, they didn't do that. And that's kind of orthogonal. Basically we don't require any changes in tendermint or cosmos, we just take those nodes as ease and just put them in trusted execution environment.
00:14:54.950 - 00:15:04.394, Speaker A: So where would that be useful going forward? Is that like if any of the zones launch and are using a similar setup? Is that kind of why you did those testing?
00:15:04.522 - 00:15:34.978, Speaker B: So we actually thought of it as kind of an interesting thing to do, or a demo, just some exploratory use case. But then we were actually approached by some users, companies that are looking to deploy tendermint and are interested in securing those nodes because they worry about the compromise of the validator and nodes that are responsible to basically validate the transactions. And if an attacker is capable of compromising enough of them, that might break the protocol.
00:15:35.154 - 00:15:46.026, Speaker A: I remember hearing about that actually on launch of Cosmos and the fear that they had for exactly that happening. Is this proven? Is this still very much an experiment? It sounds like something that could actually solve for that.
00:15:46.208 - 00:16:02.158, Speaker B: It works. I mean, we run those tendermint nodes inside SGX and still early experimentation, it's not something that's deployed yet, but nothing basically prevents from deploying it in practice. Cool.
00:16:02.244 - 00:16:27.720, Speaker C: Something we started touching on a little bit in the last episode, but I don't think we really covered well, is how powerful is typical tee when you say you're running a tendermint node in there, are you running a full blockchain node that does everything that a blockchain node typically does, or is it just the block signing part, or what can you actually fit in TE?
00:16:28.250 - 00:17:24.998, Speaker B: It depends. It depends on the tee, and it also depends on the software stack you're using, what kind of solutions you're using for that, and how much work you're willing to put in. So there are also different approaches to that. So for instance, intel software guard extensions, or SGX, initially was intended to run small enclaves, small trusted code that would perform specific operations. And on the other hand, AMD with secure encrypted virtualization took basically the extreme opposite approach of running a whole virtual machine and hardening it with memory encryption and providing a similar route of trust, but basically running very large surface inside the TE. So those are two very different approaches, but you can also to some extent abuse them. And that's exactly, for instance, what we're doing at Anjuna.
00:17:24.998 - 00:18:06.760, Speaker B: So with software guard extensions, we build a software stack that enables you to take an entire application without even recompiling it, without modifying anything in the application, and run the application entirely inside the SGX. And with MD secure encrypted virtualization, we're doing sort of the opposite. Instead of running a whole virtual machine that runs a full blown operating system, we run a micro virtual machine that runs a single application. So this way we basically, with both technologies, we kind of get to the same scenario where we shrink the attack surface, so that instead of being the host itself, it becomes a perimeter around the application.
00:18:07.130 - 00:18:11.530, Speaker C: And is there a performance penalty for doing this sort of trickery?
00:18:11.950 - 00:18:39.038, Speaker B: Yeah, so that's a great question. And the answer is different for different technologies. It's also a very nuanced tensor. It really depends on the type of workload you run inside the trusted execution environment. So there are different bottlenecks. For instance, with intel software guard extensions, there are a couple of performance bottlenecks. One of them is related to transitioning between trusted execution inside the enclave and untrusted execution outside the enclave.
00:18:39.038 - 00:19:29.762, Speaker B: So those transitions introduce quite a bit of a performance penalty, and the goal is to avoid them as much as possible. Another bottleneck is related to memory consumption. So intel software guard extensions provide a fairly small amount of physical memory dedicated to the enclave. In total, the current version of SGX, it's 128 megabyte, of which 96 are practically available to the enclave. So you can still run workflows that are way bigger than that. But when you do that, you basically start encountering paging in and out of what's called the PC, the enclave page cache, to the rest of the dram. And that's an operation that can be very costly with the MD technology, they actually take a different approach to that.
00:19:29.762 - 00:20:20.050, Speaker B: They don't limit the amount of memory that can be secured using the MD memory encryption. And in terms of the performance of accessing this memory, they avoid this integrity check that intel introduced in software guard extensions, which on one hand provides a somewhat weaker security model. So there are certain types of attacks that are hard to carry out, but certain attacks are possible where you can swap some content with something else and continue running your trusted execution environment, which is something SGX prevents. So avoiding this integrity check enables them to operate way faster. So there, with certain workloads, we see faster performance compared to SGX.
00:20:20.390 - 00:20:35.286, Speaker A: I sort of want to go a little deeper into these trade offs that you're describing. So security is a trade off, time to execute is a trade off. And size, or like the amount of capacity, I wasn't quite clear on the.
00:20:35.308 - 00:21:18.550, Speaker B: AMD side, size can affect it indirectly. It doesn't necessarily mean that a large enclave running under intelligence GX wouldn't be performant. It really depends on kind of the pattern of accessing the memory and how you process the data. How much memory do you need to access at once? If an enclave is big, but the typical working set, sort of the amount of memory you normally access is fairly small and fits within this enclave page cache, then you might not see any penalties. But on the other hand, if you constantly access a large working set that exceeds this APC, you'll encounter those penalties.
00:21:19.050 - 00:21:23.654, Speaker A: Are there any other characteristics where you see them fitting into this trade off model?
00:21:23.772 - 00:22:11.510, Speaker B: I guess in terms of security, to clarify the differences, one important one is this memory integrity. To really prove that you get a trusted execution result, you need this memory integrity. It's hard to prove something formally when you're using a secure encrypted virtualization. If you assume the attacker is actually able to modify the content of the memory pages. If you assume that the attacker is only passive and doesn't do that, you can prove certain things. But to achieve this kind of full security, up to site channel attacks, by the way, which is SGX is still concerned with them. But if you rule that out, you can actually provide some very strong security guarantees around SGX that you cannot fully provide with secure encrypted virtualization.
00:22:11.510 - 00:22:24.966, Speaker B: In terms of practical concerns, something like secure encrypted virtualization tremendously raises the bar for attackers. So we'd love to see either one of them deployed at scale in the industry.
00:22:25.078 - 00:22:30.606, Speaker A: When you started to talk about the different security models, and you mentioned the one, but is there others?
00:22:30.788 - 00:23:21.910, Speaker B: I guess going back to your bringing up software based trusted execution environments, that can be a different security model where you trust the hypervisor, but you don't trust applications running side the virtual machine. So that as well can be a significant improvement in terms of security in the industry. So we're all running virtual machines on the cloud, and whereas something like SGX can actually prevent the cloud operator from accessing your application and your data, often that's not the main concern. What you're more concerned with is attackers breaking and hacking into your vm, obtaining root administrative privileges on the virtual machine, and then breaking into your application. And that's something that software based hypervisor based protections can prevent.
00:23:22.070 - 00:23:40.180, Speaker C: When you talk about these characteristics of a TE and take memory as an example, you have 100 megs memory. Then you need to be concerned with how often will I page out what's my total workload? It starts sounding very similar to doing embedded programming. How similar to that is it.
00:23:40.790 - 00:23:46.790, Speaker B: You mean in terms of kind of being very conscious about your code, your performance?
00:23:47.130 - 00:23:54.438, Speaker C: Exactly. And I guess the tooling as well, like how you actually measure this, how you test it and everything else.
00:23:54.604 - 00:24:30.580, Speaker B: I think you inhaled it. You're correct. You're totally right about it. I'm actually coming from a background of real time embedded systems in the past. Our engineering team has very good knowledge around low level programming, assembly, performance optimization. So definitely we need to be very conscious about performance, about minimizing the footprint of our software. So for instance, our stack is very small and doesn't take too much of the pc so that you can use most of it for the application itself.
00:24:30.580 - 00:24:53.814, Speaker B: So yeah, definitely reminds embedded programming in the sense that you craft very performant code and you also care a lot about the security. You basically cannot afford bugs, overflows in your software stack because that's running in the enclave and that has to not enable an attacker to execute code inside the enclave.
00:24:53.942 - 00:25:29.842, Speaker C: Talking about tooling, I assume this is in part like what you would classify as what you're working on in your company. What tools are there to make it easier to write applications for teas? Or as you mentioned, you have an environment where you can now deploy any application, but obviously you're not going to take your telegram binary and just run it in there because it's not going to work out that well probably. How do you suggest that people work with tees and what tools do you provide? I assume there's like compiler stuff going on to help out and et cetera.
00:25:29.986 - 00:26:25.106, Speaker B: Yeah, so I think the answer is twofold. By the way, why wouldn't you run a whole telegram server inside this trusted execution environment? What I mean by that is actually, that's kind of the vision. Yeah, we envision running very complex big applications inside SGX and SUV. And just to give some examples, we do this kind of stuff. So we don't only run small enclaves, but we run entire databases, secrets management solutions, pretty complex applications inside the enclave, and that sometimes surprises people because it's a fairly new concept. So Jaija in the previous podcast on SGX was also mentioning it. That's basically the vision of those library oss to enable you to lift and shift applications without doing too much or any engineering work into trusted execution environments.
00:26:25.106 - 00:26:35.420, Speaker B: You still have some concerns around performance, potentially side channel attacks. I think performance is the most crucial one.
00:26:35.790 - 00:26:49.200, Speaker C: That's the one I'm thinking about, because application developers these days have gotten lazy, right. Chrome uses twelve gigs of ram on my machine. It's not, probably not going to run that well in fe.
00:26:49.570 - 00:27:53.390, Speaker B: Yes. So that brings us to the second part of the answer around tooling. And there I would like to talk about this work called cosmics, which was a joint research with researchers from the technion and from Tu Dresden. And it's basically a compiler based technique for, what's called, the technical term is secure memory instrumentation for execution in enclaves. What it practically means is that it enables us to avoid some of the things, some of the factors that introduce performance penalties when running SGX, and specifically the one I talked about previously, which is related to paging. So just to recap, if you're exceeding the APC, if you're exceeding the size of the enclave page cache with your workload, there is this driver provided by intel that seamlessly takes care of paging memory in and out of the enclave while also providing executing those integrity checks. And that's something that causes transition from trusted to untrusted execution.
00:27:53.390 - 00:28:53.554, Speaker B: And the integrity check is also super heavy, so that results in a significant performance penalty. Potentially, if we could avoid this sort of paging that's managed by the hardware and specifically the page faults that cause transition in and out of the enclave, we could potentially speed up execution. So that was one of the purposes of cosmics. What was done there is provide a compiler that you would use to compile your application that you intend to run in an enclave in a way that instruments the memory accesses seamlessly to the developer, so you don't need to change any code. But at the background, what happens on the memory access is that instead of just directly accessing the virtual memory, it accesses the memory through a thin runtime component that can do things like paging without actually causing a hardware page fault that would cause this transition in and out of the enclave.
00:28:53.682 - 00:28:59.430, Speaker A: I kind of want to go back to Frederick's question there about tooling. Is that tooling, does that fall under that category?
00:28:59.850 - 00:29:23.626, Speaker B: I think it falls into tooling, yeah. So I guess it's an optional piece. It's not required to run in a trusted execution environment, but it's something that once you get the optimization and trying to squeeze performance out of your workload is something you can apply in, say, your CI CD. Use this extension to the compiler to achieve better performance. So I would count that as tooling.
00:29:23.818 - 00:29:36.342, Speaker A: So I kind of want to throw back to the question that Frederick originally asked, which is about tooling. Maybe you can help understand what other kinds of tooling is Aduno working on or is being developed generally that is helping with this.
00:29:36.476 - 00:30:32.546, Speaker B: So I guess the broader context is this general protection privacy around data news. Basically, how do you protect data when it's actually being processed? And there are different approaches to that. So we're on the zero knowledge podcast, and the listeners are obviously familiar with a multitude of cryptographic techniques to provide protection for data news. So there are cryptographic techniques and those trust execution environments that provide a different approach to that. And sometimes you combine both. So that's kind of the more general space, and I think we're in this general space kind of looking down the road. There's enough work to be done now specifically around trusted execution environments, and specifically more narrowly around SGX, more specifically around usability around that, and making it easy to use those trusted execution environments.
00:30:32.546 - 00:30:36.310, Speaker B: So that would provide enough work for us for probably a couple of years.
00:30:36.380 - 00:30:51.582, Speaker A: But that's how you think about tooling. It's like often this combination of other cryptographic ideas and applying them. I'm just curious, how do you use zero knowledge proofs and tes together? How would that actually work? I know, I'm sure there's many ways it could work together, but maybe you can help with an example.
00:30:51.716 - 00:31:45.066, Speaker B: Sure. So I guess it's an alternative. I guess using trust execution environment, you can provide attestation to statements by means that are not cryptographic. At the end, there is some cryptography. So attestation itself, as was mentioned in the previous episode about SGX, it's based on a signature where you trust that only the trusted execution environment can sign some statement, but the statement itself and kind of getting to a certain result doesn't need to happen cryptographically. You just kind of execute a regular logic inside your trust execution environment, and then you prove cryptographically that you got to this result by running this in the trusted execution environment. That can be an alternative approach to some of the things that zero knowledge techniques are trying to solve.
00:31:45.066 - 00:32:41.114, Speaker B: There are potentially additional applications. So for instance, things like trusted setup, that's needed for some of those protocols. That's always been a concern. Basically, how do we carry out a reliable ceremony that enables us to trust the protocol from that point on? And that's potentially where trusted execution environments can come to rescue and provide an additional route of trust. What we see in the industry, I think the main obstacle with the Tes is usability. How do we make this stuff friendly? And that's exactly what we're looking into, basically how to alleviate all this work for the engineers and just enable you to focus on developing your application logic, your business logic and then run it in trusted execution environment. And it starts with this runtime we built for transparently running applications in site trust execution environments.
00:32:41.114 - 00:32:54.274, Speaker B: But it goes further into paying attention to the command line tools, to making it very intuitive for users to use those tools, provisioning data into the enclaves and things like that.
00:32:54.472 - 00:33:04.386, Speaker A: So I know that we want to move on a little bit to the topic of attacks and some of the vulnerabilities, but just before that you just mentioned the users. Who are the users?
00:33:04.498 - 00:33:21.900, Speaker B: It's a good question. This space is still emerging. It's still early on. What we see in the market is an interest from a couple of verticals. Some of them are actually knowledgeable about SGX and are looking into it. So some of those users would be in the financial space.
00:33:22.510 - 00:33:26.378, Speaker A: Are they banks? Are they both technical teams?
00:33:26.554 - 00:34:25.034, Speaker B: Yeah, it would be something like technical people at banks, some of the major financial institutions, kind of very traditional banking. There's a lot of interest in the blockchain space, both because some of those protocols are actually based on having a trusted execution environment, but also because pretty much all the blockchains, they rely on holding the keys to certain assets, or keys to executing smart contracts. And securing those keys is of very high importance. Basically, those keys are what guarantees that the blockchain can be trusted. So securing those keys is something that can be done by more traditional means of just securing the hosts that hold those keys. Using call storage for keys that you don't need to use immediately. But it can also leverage trusted execution environments for protecting the wallets or the secrets management solutions where you store those keys.
00:34:25.082 - 00:34:50.422, Speaker A: That's interesting, because then it starts to like that's also a problem that's been solved by NPC work. I think that was a question in our last episode. And this also helps to illuminate why you see MPCs zero knowledge proofs and tes put in the same category, even though they are super different, construction systems, everything, they're super different. But this sounds like why. It's because there's these use cases where you could use one or the other.
00:34:50.556 - 00:35:35.462, Speaker B: So you can use one or the other, but you can also use both. So for instance with something like MPC or say threshold signatures. One approach, for instance, to securing transactions and signing something is instead of having a private key in one place, splitting the keys between and storing them on multiple machines that have to sign transaction together, and only then the transaction goes through. So that basically increases the hardness of the attack linearly. It scales it linearly with the amount of machines or the key shares you used. But on top of that, you might want to also secure each one of the key storages on those machines with something that provides additional security guarantees. Like a trust.
00:35:35.462 - 00:35:46.170, Speaker B: Yeah, exactly like a t. So you're benefiting from this combination of scaling across multiple machines that the attacker would need to break to and also adding those hardware roots of trust.
00:35:46.320 - 00:36:20.790, Speaker C: I think this becomes a bit more relevant in a proof of stake world as well, because we're switching from where miners basically don't have to have their keys available at all. They can just take them offline and have them cold stored to. When you run a validator, your key has to be online and available all the time. So there's protocols I know of that have started integrating hardware security modules and cloud HSM on Amazon, stuff like this to basically do the signing for them. But I think tees could fill this role pretty well.
00:36:20.940 - 00:37:02.638, Speaker B: I want to actually mention one problem. I guess we can call it maybe secret zero. One problem with kind of just using hardware security models for securing those keys is that you store the key securely and maybe you can assume that you cannot extract this key as an attacker, you cannot break into the hardware security model. But if you take over the machine that is connected to the HSM, to the hardware security model, you can basically use it as a sign in Oracle. So you can still ask it to sign some transactions on your behalf, some malicious transactions, and that's a problem. You didn't extract the key. You cannot go elsewhere with this key and do it offline, but you can still do it on this machine.
00:37:02.638 - 00:37:38.986, Speaker B: So that's why it's basically hard to reason about the security of the overall system if you just secure this component. What we want to do in the space is to provide the security for the whole workflow. So if we talk about the flow, you would connect to some service via some HTTPs or Tls connection. And this service has access to keys and it can sign transactions, but the workflow is secured entirely, basically starting with the connection to the service and including the keys and the signing.
00:37:39.178 - 00:37:59.158, Speaker C: That makes sense. I think I can get behind that kind of use case a lot more than I can using it for off chain computation, where basically you're now sort of at mercy of whoever is the te manufacturer, where here each individual might still be at mercy, but not the chain as a whole.
00:37:59.244 - 00:38:05.190, Speaker B: Yeah, I think the kind of combination of chain and those techniques provide something powerful.
00:38:05.930 - 00:38:49.446, Speaker C: So one thing that I want to dig into a little bit is the attacks that are available on tease because we covered it a bit in the last episode, but then we talked to, I think it was when we talked to Nigel Smart, we talked to someone and they were like, why haven't know been side channel attacks proofed? Like why did they go this way? And they were outrageous how this choice could have been made. And you coming with your electrical engineering background, I mean, you said you'd worked specifically on trying to prevent side channel attacks on mobile devices. And how does someone from your background come in and look at this problem? Is it unique to SGX or does it exist generally in the te space?
00:38:49.628 - 00:39:29.090, Speaker B: I guess we need to kind of look at different side channel attacks and think about the hardness of carrying each one of them, to approach it intelligently and to be able to reason about what to do in practice and what's secure and what's not. If we look at security in the industry today, I will start with that. If we look at security in the industry today, there are far bigger concerns than side channel attacks. Also depends on which kinds of sidechannel attacks. And we're obviously talking. Whenever you're using tes, you're assuming pretty powerful adversaries. So you do concern yourself with this possibility.
00:39:29.090 - 00:40:17.490, Speaker B: But even if we ignore those attacks, we still would really raise the bar in security in practice. Because what you see if you follow security news is that pretty much every month, or even more, you have some new security vulnerability in things like containers, vms, Linux, other operating systems. There are so many privilege escalation attacks that are available in the wild, and there must be many zero day vulnerabilities that we are not even aware of that are addressing this larger attack surface of the operating system. So deploying those protections can rule out many of them. And that would require the attackers to step up and start potentially using side channel attacks.
00:40:18.150 - 00:40:28.278, Speaker A: Can you actually define those side channel attacks you sort of mentioned? There's a few different kinds. What are they? Maybe not all of them, but like the most dangerous, I guess the ones that people are really worried about.
00:40:28.364 - 00:40:44.950, Speaker B: Yeah. So I guess in general side channel attacks mean something like stepping out of the design of the system and kind of using something that's not part of the architecture, some kind of side effect to circumvent the architecture. Could this be, the architecture itself is secure?
00:40:45.030 - 00:40:56.718, Speaker A: Could this be like if the electrical signal, I mean, this is the ones I've heard of the beats of how much electricity is running to it, which you could actually use that to potentially decipher something.
00:40:56.884 - 00:41:28.758, Speaker B: Yeah. So for instance, power analysis is one example of a side channel tac. In some scenarios, this is actually a concern. For instance, something like credit cards cheap, that you can take, analyze offline, run through power analysis, and potentially extract keys. That's a space where people are really concerned about those. Something like your host that's connected to your power network. If it's reasonably physically isolated, and even if not, it's still not an easy attack to carry out.
00:41:28.758 - 00:41:38.090, Speaker B: There might be only several groups, you might be able to count the number of people in the world that are able to carry out those attacks, in practice on an actual processor.
00:41:39.070 - 00:41:43.454, Speaker A: Would that be a government, or you mean like the technology doesn't exist to do it?
00:41:43.652 - 00:42:07.662, Speaker B: The technology exists, but it is also very different between different processors. So some microprocessors are more susceptible to those side channel attacks. If you take something like an Intel CPU, yeah, there are proofs of concept. It's possible, but it's not easy. It's a very complex architecture, it's been shown, but there aren't many organizations that are capable of carrying out those attacks.
00:42:07.726 - 00:42:18.494, Speaker A: So let's go now though, to the side channel attacks of te. Specifically what you just described is like this is general definition of side channel attacks. But what would be a side channel attack for tes?
00:42:18.562 - 00:43:04.774, Speaker B: Yeah, so what's more interesting in the context of tes and specifically Intel SGX is microarchitectural side channel attacks. So the previous year was a pretty bad year for processors with things like Meltdown, Spectre, and then foreshadow that specifically targeted SGX. So let's talk about those. Meldon was probably the biggest concern. It's a pretty easy attack to carry out. It's possible to carry it out from any process to compromise the private data of the operating system, and through that, basically compromise the whole system. So that was the biggest concern, and that's something that SGX is not directly susceptible to.
00:43:04.774 - 00:43:14.902, Speaker B: Foreshadow can be seen as a certain variant of meltdown, but it's not exactly the same. So foreshadow was a concern for SGX.
00:43:14.966 - 00:43:16.470, Speaker A: Is that foreshadow?
00:43:16.630 - 00:43:18.570, Speaker B: Foreshadow starts with an f. Yes.
00:43:18.640 - 00:43:19.114, Speaker A: Okay.
00:43:19.232 - 00:44:24.050, Speaker B: Yeah, so just yesterday actually, I was talking to one of the authors of this work to kind of recap on the attack and all the protections that came out. What's important is to see trusted execution environments not as a product that's done, but as something that's evolving. So SGX is not done. Intel are constantly updating the microarchitecture, coming with newer versions of SGX and protections to those side channels. So, for instance, foreshadow was leveraging cache time in side channels. And that's something that intel introduced countermeasures to by flashing the cache on transitions between execution in the enclave and untrusted execution. And also differentiating between running with hyperthreading enabled, which is something that can enable carrying out a foreshadow attack, and running with hyperthreading disabled, which together with flashing discache can basically prevent foreshadow.
00:44:24.050 - 00:45:22.446, Speaker B: Another concern is spectre side channels. So that's something, I guess, that can be viewed as sort of an application level vulnerability. So the trusted execution environment in this case might provide protection from anything else on the host, but you still need to care about code gadgets that are vulnerable to spectre inside your application. And some of the approaches include formal analysis of the code or the binaries. Some of the approaches like SpecFAs, it's a work that's been done by researchers at technion and also researchers to Europe. I don't remember exactly the whole group, but that's something that basically enables to identify and apply fuzzing techniques to discover spectre vulnerable gadgets in applications. And if you combine all those different tools, you can probably get to something very secure.
00:45:22.446 - 00:46:00.698, Speaker B: But I'd like to actually mention the talk that Paul Kocher, who stands behind meldown and Spectre, he gave a talk at the RSA conference and he was showing this slide. He was basically painting this picture of meldown Spectre as a piece of poop. But then his point was that it's a small piece of poop and a larger amount of poop that basically constitutes kind of the state of security in the industry in practice. And he's the man behind those attacks. So point was that basically we have probably way bigger problems in practice in the industry.
00:46:00.794 - 00:46:02.938, Speaker A: So this is only the tip of the iceberg.
00:46:03.034 - 00:46:04.960, Speaker B: That's just the tip of the.
00:46:06.450 - 00:46:35.382, Speaker C: I mean, that's for sure. I listened to a couple of security podcasts and I remember when Spectre came out, it was big news and it was sort of like, oh, here's a core vulnerability. Like everyone is affected. And they were talking about all these cloud providers. You could leak so much data. And then the other hosts went like, okay, so what data has been leaked? Well, probably nothing, because it's extremely hard to do. And it was patched so quickly, et cetera, et cetera.
00:46:35.382 - 00:46:52.880, Speaker C: While any other topic on the podcast is like, oh yeah, this company lost $100,000, or this whole city block shut down, or this hospital lost a couple of people died because their power went out. Yeah, it is the tip of the poop for sure.
00:46:53.190 - 00:47:46.978, Speaker B: Yeah. So here I would differentiate between different scenarios where you're applying those protections. For instance, if you want to do something like deploy blockchain nodes that run, that you protect only by a trusted execution environment on completely untrusted machine, and they actually hold the keys to asset and an attack on that translates directly to monetary loss, that might be a decision you would like to consider very carefully and kind of understand what are the possibilities to carry out such an attack there. But many of the defenses are defenses in depth that are applied in combination with other defenses. So for instance, in the industry, you'd have some data center, you'd have monitoring tools, that you'd have intrusion prevention systems. On top of that, you might also want to add those protections for your most sensitive workloads. So it's not the only defense you have.
00:47:46.978 - 00:48:14.620, Speaker B: And there it should be a no brainer. You lose nothing. Well, we need to kind of consider performance and the applications of those environments. On performance, you lose little. Yeah, you lose very little. By applying those attacks. You tremendously raise the bar on security and you don't lose anything because it's not that you're now opening your system to attackers after you apply this kind of protection and just letting anybody in.
00:48:14.990 - 00:48:32.758, Speaker C: So to wrap up, I'm curious about your thoughts on a topic that keeps popping up, and that is we don't want to trust these companies, blah, blah, blah. What's your hope that we'll see some open source enclave actually become successful and deployed?
00:48:32.794 - 00:49:18.522, Speaker B: In practice, I hope that such a thing will emerge. So there is the Keystone project. There was the sanctum research at MIT that aimed at providing open source trust execution environment with somewhat different guarantees compared to SGX. So personally I hope something like that would emerge and would be adapted in industry. I definitely would like to see multiple competitive architectures with different properties. Myself and Juna, we're in the business of providing a software stack that would be cross platform. So in terms of kind of what we build is something that we would like to run on multiple tees.
00:49:18.522 - 00:50:05.182, Speaker B: And definitely in terms of kind of adoption in the market, it would be beneficial to have something that's open source with well understood guarantees. I don't expect it to happen very quickly because Intel AMD still dominate the majority of the data center market, specifically intel. And to some extent anyway, we trust those manufacturers. I mean, security people might like to kind of complain about that and about this route of trust. But anyway, you run your workloads on those processors. So whatever happens there, you kind of trust the processor to do stuff correctly. So to some extent, practically, that's the best thing you can hope for.
00:50:05.182 - 00:50:21.060, Speaker B: Instead of trusting way more components, like additional hardware components, the supply chain, physical security on your premises, the people around you, if you can limit the trust to the process manufacturing, you've gone pretty far in terms of improving your security.
00:50:21.750 - 00:50:28.118, Speaker A: I'm sure some of our listeners will disagree with you, but cool.
00:50:28.204 - 00:50:51.980, Speaker B: And just to kind of wrap this up, I think there are different roles for industry in academia. The academia definitely needs to continue exploring cryptographic approaches, theoretic approaches, to provide provable guarantees for security. And the role of the industry is to find pragmatic, practical solutions that actually make things safer for us.
00:50:52.510 - 00:50:56.842, Speaker C: So yeah, on that note, thank you very much for being on the show. It was fascinating.
00:50:56.986 - 00:51:01.758, Speaker B: Thank you very much, Frederick and Anna. It was great being hosted on the.
00:51:01.764 - 00:51:07.294, Speaker A: Podcast, and I guess we'll keep an eye on the work that you guys are doing and curious to see what.
00:51:07.332 - 00:51:10.346, Speaker B: Comes out around tes and to our listeners.
00:51:10.458 - 00:51:11.498, Speaker C: Thanks for listening.
00:51:11.594 - 00:51:12.250, Speaker A: Thanks for listening.

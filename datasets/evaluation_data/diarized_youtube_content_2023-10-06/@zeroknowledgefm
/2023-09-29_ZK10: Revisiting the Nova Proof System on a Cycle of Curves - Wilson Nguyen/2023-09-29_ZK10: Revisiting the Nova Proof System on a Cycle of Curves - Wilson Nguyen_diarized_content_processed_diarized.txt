00:00:07.050 - 00:01:04.206, Speaker A: Hello, my name is Will Smyn, and today I'll be presenting our work revisiting the Nova proof system on a cycle of curves. This is joint work with Dan Bonet from Stanford and Triana SETI from Microsoft Research. The cryptographic primitive that we'll be talking about today is incrementally verifiable computation, or IVC schemes for short. This was introduced by Valiant in 2008, and the goal of IVC schemes are to efficiently prove the outcome of some long continuous operation. So here we have a function f that's being repeatedly applied on these z elements. And the claim that we would like to convince a verifier of is that some element zi is the result of applying this function f I times on some initial element z zero. So why would we care about proving claims of this form? Well, some modern day applications of IBC schemes are verifiable delay functions.
00:01:04.206 - 00:01:48.270, Speaker A: And so if f instead now is some slow function f. If I prove to you that zi is a result of executing f I times in secession, then I must have some verified delay. In addition, IBC schemes can be used to construct zkevms or more broadly state machines. And so now, instead of arbitrary elements z, they are now states. So you can imagine this as snapshots of ram, and f is now a state transition function. You can imagine this as executions of some cpu. So, the Nova paper in 2021 introduced a novel construction of IVC schemes.
00:01:48.270 - 00:02:32.590, Speaker A: While the construction in the paper was proven secure if instantiated, in practice it was incredibly inefficient. And the reason why is because it used a single elliptic curve group, which meant that a lot of non nave arithmetic had to be represented within constraint systems. And so, because of this inefficiency, the nova authors, over the course of the following year, implemented a modified version of the nova IVC scheme, which instead operated over a cycle of elliptic curves. So now there are two curves, and this dramatically reduced the amount of non native arithmetic that they had to represent within their constraint systems. But because of this. Oh, sorry. Yeah, because of this, it was incredibly efficient in practice.
00:02:32.590 - 00:02:45.870, Speaker A: But this modified scheme had prior, never been formally described nor proven secure. And it turns out there was a major soundness vulnerability in this modified scheme.
00:02:46.550 - 00:02:47.730, Speaker B: I can do this.
00:02:47.880 - 00:03:48.946, Speaker A: And the motif that I would like to leave with you all today is that if a cryptographic scheme has never been formally written down nor proven secure, we as cryptographers and as implementers should definitely question its security and whether we should extend or implement these results. So, to give you all a rough timeline of the discovery of this bug in the modified IVC scheme. In March of 2021, the eprint version of the Nova paper was released. Over the course of the following year, the Nova authors implemented the modified version of the Nova IVC scheme that operated on a cycle of curves. And roughly a year later, a lot of renewed interest in IVC schemes picked up as a potential method to implement zkevms. And so there were a lot of follow up works, such as Hypernova, Protestar Supernova, which altered and optimized the folding schemes used to construct IVC. And it is in this period in which I became interested in IVC.
00:03:48.946 - 00:04:53.450, Speaker A: In particular, I was interested in researching how IVC operated on a cycle of curves, because in this whole two year period, a formal description of how any IVC scheme operates on a cycle of curves was never given. And it turns out that after a little bit of research, there was a pretty big bug found in May for the modified version of the Nova IVC scheme. And so, zooming in to that month of April, I first tried to find some formal description of Nova on a cycle of curves. And so the first thing I looked at was, of course, the updated version of the Novi print paper. There was a small, maybe one page section about the implementation details, but this section did not give a formal description of how the schema actually operated. Instead, there was this obtuse table, which is figure one, which basically described a number of constraints required on the primary and secondary curves of the cycle. And that was the summary of basically the description of nova on a cycle.
00:04:53.450 - 00:06:01.470, Speaker A: I also looked in Justin Thaler's textbook, which is an incredibly well written textbook, so I totally recommend it, which described folding schemes and different constructions of IVC from folding. But the description of IVC on a cycle of curves was limited to this like quarter page footnote, which motivated why you would want a cycle of curves and two different constraint systems. But it didn't go over its operation. And so I realized that I would probably have to just go through the whole code base, reverse engineer it, and write down a formal description of how Nova operated on a cycle of curves, and hopefully write its proof of security and maybe annotate the code base. But during this attempt to actually formally describe the system, I realized that there was a pretty significant bug. And so over the course of that April, I collaborated with my advisor, Dan Bonet and Srina Seti, who was the lead author on Nova and also the lead implementer for the modified scheme. And we wrote revisiting the Nova proof system on a cycle of curves.
00:06:01.470 - 00:06:52.110, Speaker A: In this work, we formally described the soundness vulnerability that occurred in the modified scheme, and we demonstrated that this vulnerability was indeed real by generating a false but accepting proof of two to the 75 iterations of the min root VDF in only 115 milliseconds. So it turns out that in the paper I wrote 1.5 seconds, but it's because I compiled it in debug mode, so it's actually a little faster. And so, yeah, that's a pretty big bug in that thing. Okay, so. All right, so, okay, where was I at? Oh yeah. So, since it only took 115 milliseconds, or one and a half seconds, if the Nova IVC scheme had actually been secure, this would have taken hundreds or thousands of years.
00:06:52.110 - 00:07:52.260, Speaker A: So indeed, there was a real vulnerability in the system, and all hope is not lost. We found a fix that actually optimized the efficiency of the recursive verifier and the proof size. And in doing so, we formally describe it. We write down a security proof, but we also provide a somewhat generic ish compiler, from folding schemes to IVC over a cycle of curves. And so it can be readily generalized, like protestar or hypernova. So, while this talk is a little bit short, I'll hopefully give an intuition on how nova operates on a cycle, but maybe not the full description. So, what changed from the nova paper to the implementation? Well, instead of a choice of a single function f and a single constraint system over one field, this constraint system, you can roughly think, constrains the execution of this one function.
00:07:52.260 - 00:08:42.530, Speaker A: There is now a pair of functions operating on a pair of inputs, and a pair of constraint systems called the primary and secondary constraint systems, which operate on two different fields. And these two functions operate on the respective two different fields as well. And so now we're zooming in to the IFC construction. In particular, we're first going to discuss how the IFC prover operates. And so, here is a diagram which represents the computation trace that the prover wants to prove to a verifier. In particular, at every step we apply the pair of functions on the pair of inputs. And the claim is that these pair of outputs were produced by repeatedly applying the pair of functions.
00:08:42.530 - 00:09:47.850, Speaker A: And so, at every step, there are the two constraint systems, the primary and secondary constraint systems, which constrain the execution of one step of their respective function. And now, at every step, the prover has to prove the satisfaction of these constraint systems. But it doesn't suffice for the prover just to prove satisfaction of these constraint systems, we need to know that at all prior steps, these constraint systems were satisfied by the respective function inputs and outputs. And so, I'm lying to you with this very simple diagram here. And so what we're going to do is we're going to take a deep dive into each of these steps, but I'm going to wait a little bit, just so that diagrams in your mind. And so at every step of the IVC prover, they're of course the primary and the respective and the secondary constraint systems. Now, in addition to the function inputs, we also take these additional but critical elements.
00:09:47.850 - 00:11:39.630, Speaker A: These elements here, which have a one and two to indicate primary and secondary are called accumulators which accumulate or collect the claim that all prior executions or all prior constraint systems were satisfied. This green element, indicated also with this two, represents the satisfaction of the most recent secondary constraint system in the prior IVC step. So this would be step I instead. Now this constraint system constrains one step of the execution of the primary function, but also folds together this accumulator and this fresh instance, which is the green instance, to produce a new accumulator which represents the satisfaction of all prior secondary constraint systems. And now the satisfaction of this constraint system can also be represented as this new green element, which then also gets fed into the secondary constraint system, which constrains one step of the secondary function execution, but also folds together the claim that the prior constraint system, so the primary constraint system and the accumulator together into a new accumulator, and so the output of every IVC step is symmetric with its inputs. The satisfaction of this secondary constraint system can also be similarly represented as a green instance. And so now we have two function outputs, a secondary instance or a secondary element, which represents a satisfaction of this secondary constraint system, but also two new accumulators which have now folded the prior two green instances.
00:11:39.630 - 00:12:11.610, Speaker A: And so let's say this was the final step of the IEC prover. What remains for the prover to show to the verifier is that these elements here are indeed valid elements which accumulate the claims of all prior instances. I won't go into that. But these accumulators, along with that proof that these are valid accumulators, represents the proof that the IVC verifier actually accepts.
00:12:19.010 - 00:12:19.470, Speaker C: Cool.
00:12:19.540 - 00:13:46.230, Speaker A: So now that we have a rough intuition, hopefully, about how the IVC proof operates and how the IVC verifier verifies the execution, what was the vulnerability that happened in the modified IVC scheme? Well, the structure of the IVC proof could actually, sorry, the structure of the vulnerable IVC proof allowed it to be split into two independent halves, a left half and a right half. You can think about these as accumulators for the primary and secondary instances, but also the fresh green instances for the primary and secondary. And now that vulnerable verification equation took in this vulnerable proof and could actually be split into two independent checks for the left and right halves of the proof. Now, because this verification was missing some critical hash checks is what allowed it to actually be split into two independent checks. And now is the fact that they could be split into two independent checks, which allowed for a sort of symmetric attack, which we'll describe in the next slide. So it turned out that because we could split the verification equation into two halves, we could shortcut the computation. In particular, the IFC prover only had to execute a single step of the honest Nova prover, but instead on malicious inputs.
00:13:46.230 - 00:15:14.370, Speaker A: And now these accumulators, along with the proof that they were valid accumulators, represented the malicious left and right halves of the proof. And because certain hash checks were missing from the modified Nova verifier, these were accepting proofs. And so the takeaways of the presentation today, hopefully, are that modifications to even secure schemes, or even slight modifications to secure schemes, can lead to completely broken schemes. And as cryptographers, when we make modifications to schemes, we should prove that the modification is secure, or at least write down a formal description for people to analyze. And as implementers, if a scheme has never been written down formally nor proven secure, we should definitely question its security, but also question whether we should pour so much effort into implementing it. And so for further exploration, I definitely recommend, of course, reading our paper, which is available on eprint on this little short link here. If you want instead to watch a technical deep dive lecture on how the new Nova IVC prover and verifier actually work, but also a formal description of the soundage vulnerability walking through the attack I recommend watching a lecture I gave to the privacy scaling explorations group, available on this YouTube channel.
00:15:14.370 - 00:15:25.830, Speaker A: And that's it. Any questions?
00:15:33.240 - 00:16:12.032, Speaker C: Thank you for a great talk and really fantastic paper. I can truly say it's fantastic because I personally spent several months reverse engineering Nova from the same perspective as you did, but I didn't discover the bug, so I'm super envious. The question actually is how should we prevent this kind of attacks in the future? I mean, in general, not for this particular nova paper, but in general for proof systems who inevitably switch from single domain to cycles of curves or something like this. How should we design new proof systems to avoid this kind of bugs? What do you think?
00:16:12.166 - 00:16:51.870, Speaker A: Well, I guess the first off is, if you're trying to generalize some IVC construction based on folding schemes from a single curve to a cycle of curves, I recommend just following the construction we have in the paper. So the construction in the paper only assumes a generic folding scheme, not a particular construction. And so you can just go ahead and just use the paper construction. Otherwise, if it's some other proof system, I definitely think there's no easy workaround. You just have to write out the formal description and write a soundness proof. And so I don't know if there's any way around that, but as implementers, maybe you could request that the cryptographers write the proofs for the favor.
00:16:52.340 - 00:16:55.468, Speaker C: You mean write the soundness proofs for the two curve version?
00:16:55.564 - 00:16:59.600, Speaker A: Yes, exactly. Formally describe the two curve version and then write a soundness proof.
00:17:04.180 - 00:17:05.330, Speaker B: Anyone else?
00:17:15.460 - 00:17:29.400, Speaker D: Hi. So just to see if I followed, so you could say the bug was only not including enough data in the fiat shamir challenge, you could characterize it like that.
00:17:29.550 - 00:17:30.024, Speaker C: Oh yeah.
00:17:30.062 - 00:18:24.568, Speaker A: So this wasn't actually a fiat shamir bug. So I include the full diagram, but I didn't actually describe the full diagram. Basically, the issue was that in the actual construction, you needed to check whether two accumulators were valid, and hence all prior executions of those respective constraint systems were valid. But the issue was that they provided too much information. Actually, they provided both accumulators, but they never checked the x zero hashes for both of these accumulators. And because of that, there was no guarantee that this first accumulator was the result of an extraction of this. Sorry, how do I say it? In the diagram, I presented a very linear sort of diagram, but the modified nova implementation instead viewed it as not a linear, but as like a pair that were progressing.
00:18:24.568 - 00:18:57.332, Speaker A: And so instead they provided only this accumulator. Sorry, this fresh instance and that accumulator, and then this fresh instance and that accumulator, and they check them independently. But the thing is, though, you don't actually need to provide this accumulator here, you only have to provide the last one, and by knowledge, soundness, you can actually extract the other accumulator. What ended up happening is x zero.
00:18:57.386 - 00:18:59.512, Speaker D: Here is a random challenge, or.
00:18:59.646 - 00:19:27.890, Speaker A: Oh, sorry, my bad. Basically, when you operate on a cycle of curves, they wanted to keep the instances in the constraint systems constant size. And so x zero actually hashes the prior instance. So, as you can see, as I followed here by red. I'm saying instances that were not satisfiable were placed in the hashes. So this red line is sort of where that broken accumulator went.
00:19:29.460 - 00:19:29.776, Speaker B: Right.
00:19:29.798 - 00:19:43.284, Speaker D: I'm saying, for example, if you included Ui one in the hash, in the public instance of r one cs two or r one cs one, I guess, then that would fix it.
00:19:43.402 - 00:20:07.676, Speaker A: Yeah. They were missing a hash check. Yes. There is an easy solution, which is that you could just add an additional hash check, but it turns out that you didn't actually need to include this extra element at all, and so hence the fix actually optimized this. And so now there's, like, one less instance to check, and it's because it's sort of inductively checked by the last constraint system. Okay.
00:20:07.698 - 00:20:12.500, Speaker D: And you're saying your optimization was you only need to spit out one of the Uis.
00:20:12.600 - 00:20:13.152, Speaker A: Exactly.
00:20:13.286 - 00:20:13.632, Speaker D: Okay.
00:20:13.686 - 00:20:13.904, Speaker E: Yes.
00:20:13.942 - 00:20:22.930, Speaker B: Okay, nice. Do we have time for. Yeah, we do. Any more questions?
00:20:26.680 - 00:20:27.476, Speaker E: No.
00:20:27.658 - 00:20:30.390, Speaker B: Well, there's one question, one more.
00:20:37.080 - 00:20:52.936, Speaker E: You mentioned that the verifier can be split into two independent checks when you fix the bug by introducing the hashtags. Is that still true, or was that the problem, that it was splittable in the first place? Yeah.
00:20:52.958 - 00:21:18.848, Speaker A: So if you introduce an additional hash check, then the verification equation cannot be split into two independent halves, because now one half depends on the other half because this hash check. But the issue is that you didn't actually need to do that hash check in the first place, because simply by omitting the elements as I described earlier, you don't have to worry about there being an independent half. And so the new proof after the fix doesn't have two halves, you can split.
00:21:19.024 - 00:21:20.790, Speaker E: I see. Makes sense. Thank you.
00:21:26.840 - 00:21:28.070, Speaker A: Oh, there's a.
00:21:32.040 - 00:21:52.824, Speaker D: All right. Yeah, I hope there's. So, hypothetically, say they did all the fiat shamir stuff. They delegated it to some library, like Merlin, that does fiat chamir always correct. Would that have avoided the bug if all the fiat shamir stuff was handled by another library?
00:21:52.952 - 00:22:05.600, Speaker A: Oh, so this is not a fiat shmir bug. The hashes are just to make sure that the instances are constant size, and so they provide the rest of the instance in the witness, but then the public instance is just a hash.
00:22:07.540 - 00:22:11.200, Speaker D: Okay. All right. It's about what you.
00:22:11.270 - 00:22:11.696, Speaker A: Okay.
00:22:11.798 - 00:22:12.016, Speaker E: Yeah.
00:22:12.038 - 00:22:28.676, Speaker A: So it's like the choice of what you include, basically. Yeah, I guess. But this is like, outside of the constraint system. It was just that it's like the proof had two independent halves, and the verifier didn't check that these halves were together, but it's outside of the actual constraint.
00:22:28.708 - 00:22:49.452, Speaker D: Yeah, but somehow I don't follow the full detail. I still wonder if you had some fiat chamir library that always has this transcript object that it keeps in mind, if that would have somehow indirectly brought the bug up to the surface. I'm not totally following the details, so maybe what I'm saying is nonsense.
00:22:49.596 - 00:23:15.720, Speaker A: I see what you're saying. I think the proper way would be to maybe implement some generic object using our compiler and then just plug and play whatever folding seam that probably would have prevented this issue. But before this paper, the view was that you would do a pair of constraint systems in parallel instead of a linear chain. But I think this linear chain is the appropriate view, and it didn't occur before discussion of this.
00:23:15.790 - 00:23:27.704, Speaker D: Yeah, but I'm saying, right, there are these fiat chimier libraries that always have one transcript object that they're keeping in mind. Okay, this is too complicated. We'll take it offline.
00:23:27.832 - 00:23:38.130, Speaker A: Yeah. All right.
00:23:38.820 - 00:23:41.330, Speaker B: We still have a couple of minutes.
00:23:42.260 - 00:23:45.984, Speaker A: Okay, well, I guess. No, man, I guess I ran through those slides.
00:23:46.112 - 00:23:55.670, Speaker B: You were quick and concise. We can do one more question, or we can move on to the next talk.
00:24:00.360 - 00:24:05.416, Speaker A: I got to edit this. I want to w. I guess they.
00:24:05.438 - 00:24:34.850, Speaker C: Don'T have a single fetch, Amir. For the same reason they don't have a single curve. Basically, this object should reside in either field. If you have a state where you accumulate everything, then it should be in non native domain for either of the field. So if they had such a state, they would be tempted to have like two fiat shamirs in parallel and have pretty much the same problem.
00:24:35.220 - 00:24:49.770, Speaker F: A fiat shmir library that ensures that the challenges have all the right thing in the pre image. I think it would force to have that actual line in the implementation. It wouldn't compile without it.
00:24:51.580 - 00:25:19.792, Speaker G: I think I agree with you in terms of the general implementation construction, but. Yeah, I don't know if it came up for because I didn't have the microphone, but the question I'd asked before was, was this effectively a missing constraint? Now, you said it was outside the circuit, but is that purely because the real instance variables, even though they're in the witness, are still public? So it's left out of the circuit because there's no need to check it.
00:25:19.926 - 00:25:43.064, Speaker A: Exactly. Yeah. So in the modified scheme, the constraint systems actually remain the same. And so it wasn't like a fiat shmir issue or a set of missing constraints or malformed constraints within the constraint system. It was just the verifier at the end. Hopefully, the lecture that I give the privacy scaling explanation is a lot more in depth. So hopefully that's a little clear.
00:25:43.064 - 00:26:00.620, Speaker A: But it's because what's in that x zero hash is actually the opposite instances green element. And so the verifier has all these elements and are able to verify the hashes themselves. And so, as you were saying earlier.
00:26:02.080 - 00:26:20.204, Speaker G: It then is sort of a hybrid between microphone. So it's a connection of the, it's the flow between the proofs, but it's not the flow in terms of like a standard interactive to non interactive compilation.
00:26:20.252 - 00:26:28.090, Speaker A: Yeah, exactly. And so it turned out that you didn't even need to have this check. And so then it's now different. Yeah.
00:26:29.980 - 00:26:32.980, Speaker B: All right. Thank you very much. Wilson.

00:00:00.570 - 00:00:00.974, Speaker A: It.
00:00:01.092 - 00:00:37.874, Speaker B: All right. So I think the way that I want to do this panel is actually to do part of it, kind of continuing on the conversation of data availability. And we have with us a number of kind of leads of projects that have zones, and we can talk a little bit about more what that would look like in terms of data availability to explore into it. And then I wanted to also use this panel to explore just general private blockchain scaling, something that we've talked about privacy in the context of bridging. But I wanted to talk about it a little bit more broadly. And so here on the panel, we have dean returning. Thanks for coming back.
00:00:37.874 - 00:00:54.560, Speaker B: Dean from Agoric Zucky also returning. Thank you for joining again from sommelier. And we have Henry Devalance, who just is joining for the first time. Henry is from Penumbra. Henry, since we haven't heard from you yet, do you want to just say a few words about the project?
00:00:55.170 - 00:01:25.030, Speaker C: Sure. So, penumbra, what we're building is basically a fully shielded proof of stake network within integrated multi asset decks. So this is supposed to sort of act as a private zone for the whole cosmos. Ecosystem value comes in over IBC, it's shielded, and then people can trade in a private way within that zone.
00:01:25.770 - 00:01:26.470, Speaker B: Cool.
00:01:26.620 - 00:01:29.050, Speaker A: Penembra is all about private yield.
00:01:29.950 - 00:01:32.970, Speaker B: Yeah, that's the tagline.
00:01:33.630 - 00:02:02.290, Speaker C: Sure. Well, anyway, I don't want to sort of steal the panel, but there's a lot of useful things that come out of building genuinely private infrastructure. And so I wouldn't say that there's like a single tagline, because it turns out that if you build the right infrastructure, actually it has a lot of uses.
00:02:03.910 - 00:02:33.600, Speaker B: Okay. Could be one of many taglines of the future, then. Yeah. Okay, let's start with this concept of data availability. John, right at the end, kind of near the end of your presentation, you talked about zones potentially being able to use something like Celestia. I've mostly understood it as sort of the base chain for roll ups, roll up like technologies. But like Zucky had said, maybe roll ups are just l ones or their own blockchains and there's a bridge between them.
00:02:33.600 - 00:02:59.510, Speaker B: Can we go into, now that we have three teams here who actually will, who are projects running zones, launching zones? I kind of want to explore what that would look like. So maybe to start, where does the data currently live in any of the zones? Sucky. Where is the data? Like data availability? The data availability lives in tendermint. So like the client software.
00:03:00.410 - 00:03:29.774, Speaker A: So tendermint is a BFT consensus layer. Yes. And tendermint is responsible for gossiping out the blocks to all of the full nodes on the network via the tendermint gossip protocol. All of the blocks then execute those transactions in those block and propagate them onward. Validators are responsible for providing those blocks, and validators are not supposed to sign to have consensus on a block that they do not have access to.
00:03:29.972 - 00:03:36.900, Speaker B: Okay, so you're saying it's just built like this concept of data availability currently, it's just built into the consensus mechanism itself.
00:03:38.230 - 00:04:33.570, Speaker A: One of the things that I think is interesting is Satoshi was really one of the first distributed systems thinkers to think about data availability and BFT as independent properties. If you kind of look at all of the sort of pre blockchain classical BFT things, this question of is the data available? Can the client witness was sort of alighted or ignored? And so tendermint has like a particular approach to it. I don't think it's particularly advanced. Celestia is clearly the next generation of that approach. But tendermint is what is responsible in the cosmos. Each sovereign tendermint zone is responsible for its own data availability. If you're like running a relay or an IBC, you have to spend hundreds of thousands of dollars a year running full nodes and archive nodes for every single chain.
00:04:35.530 - 00:04:49.222, Speaker B: And in the individual zones. Could the data availability be corrupted if there was some specific like kind of what you were talking about, John, with, if the validator set, is it actually possible for access?
00:04:49.276 - 00:04:59.834, Speaker A: I have been waiting for this attack for two years, okay? I've been trying to pay people, but it gave of stakes, it gave of zodes for pulling off this attack.
00:04:59.952 - 00:05:00.620, Speaker B: Okay.
00:05:02.590 - 00:05:21.566, Speaker A: This attack is the thing that was most the advantage of the work that the agoric team has done is they build a system that fails somewhat gracefully. If you have a data availability attack, which is what I think is cool about agoric as an interrog protocol.
00:05:21.758 - 00:06:44.714, Speaker D: Now I want to know how. So I was going to say with respect to data availability, I think actually several of us up here have at the foundation is the Merkel tree that tendermint maintains, where data is stored, replicated must be reported, the block data and so forth. But we have an additional challenge. And then I want to go back to the thing that ducky just pointed at where at the know, we do deterministic replicated execution of JavaScript. And what that means is a message comes in from a client that must be recorded, it must be remembered, and then it causes some arbitrary amount of computation. The surface area is what I have to remember, and then I can replay all the computation that then has long lived persistent state that is not in the Merkel tree and thus is not available unless you have a full node and can talk to that JavaScript engine by sending messages in. And that gives us one of the directions where we get some privacy until pranumbra, right, and Zcash, to a lesser extent, data availability didn't mean you could get at the data because, yeah, it's all shielded.
00:06:44.714 - 00:07:04.786, Speaker D: You got nothing unless you're part of the game being played, executing transactions and having in memory state. Similarly, you got nothing unless you're part of the game being played. And so data availability is more complicated as a result. But I now want to go back.
00:07:04.808 - 00:07:09.160, Speaker B: To let's find out how you fail gracefully at this.
00:07:11.690 - 00:08:08.470, Speaker A: So one of the ideas in cosmos is that data availability failures can happen if you have more than two thirds. Plus, what if the validator said is malicious? They can create blocks that appear valid but are not available. And so you could have like arbitrary corruption of this sort of interchange state. And so I expect stuff like that will happen. The idea is that you should be able to, so we do this thing with the IBC denoms, right? For instance, where we say like, oh, this token came from here, was wrapped here, then here. And so if you have a data availability failure in between, you should be able to actually figure out what tokens were affected by this data availability failure.
00:08:11.420 - 00:08:12.170, Speaker D: Good.
00:08:13.020 - 00:08:13.770, Speaker B: Okay.
00:08:16.060 - 00:08:39.670, Speaker D: That makes sense, partly being able to just replay the model from any point to figure out what happened, and anyone's in a position to do that. All those elements give us recovery, decentralized recovery from those kinds of attacks. As I said, until Zucky can manage to get someone to actually attack one of these systems, everything's theoretical, right?
00:08:41.800 - 00:09:10.590, Speaker A: There's a nice data availability attack against osmosis that you could do where you could create a uchain, get an osmosis pool created, get a bunch of value into it, and then do a data availability attack on the source chain to drain the osmosis pool of the foreign asset, the OSmO or the atoms or whatever that's in that pool, and then walk away with all of it.
00:09:11.520 - 00:09:24.204, Speaker B: I want to actually explore this really quickly. What would that like, a data availability attack? Does that mean basically making the data unavailable, and then you're able to do what you will with what is underneath and there's no way to prove it. Yeah, exactly.
00:09:24.342 - 00:09:50.516, Speaker A: Able to come in and say, oh, I have minted an infinite amount of militia from the food chain that I took over. No one can actually see the blocks of fucoin, but we are outputting IBC packets. We created infinite amount of fucoin and we just drained the osmo pool.
00:09:50.628 - 00:09:58.248, Speaker B: Okay, that's interesting, that connection between data availability and that I can tell I'm.
00:09:58.264 - 00:10:16.340, Speaker A: Still getting, because you can't get slashed, you don't know what's going on, you've withheld all the evidence of who did the malicious thing, who is stealing the coins, all of this stuff, it just gets black hole and you don't know where anything is. But somebody shows up and walks away with all of the atoms that are in the pool.
00:10:17.400 - 00:10:49.150, Speaker D: I'd have to see more about this to understand what the practical vulnerabilities are and what could be sort of trivially mitigated by debt limits or debt ceilings or what have you. But this is one of those things where it takes long enough to be prepared for challenges like this that we need to start now, even though the actual attacks are likely to be a long way away. So these frameworks that can mitigate these things, we need to all keep pushing on that.
00:10:49.680 - 00:11:11.940, Speaker B: I want to explore with Henry the idea of data availability in the context of a privacy chain privacy zone. Is it different, the idea that the data is available? Is that also something that's inevitably made private in a zone like yours? Or is the fact that it's available public, but the underlying data private?
00:11:14.680 - 00:12:51.396, Speaker C: I guess I would say two things. So the first thing is, if you imagine you have a transparent blockchain, like Zaki was saying, there's these blocks, they're full of these transactions which are really state changes, and those get sent around. Everybody applies those state changes that could do whatever, like say it's the Javascript on agoric, right? It can touch all these different parts of the state, but at the end everybody can just sort of do those changes to this one big global state that's being replicated by this system. And in a private or shielded chain, you have a very different data model where instead of having this one big global state, your global state is shrunk to just being this set of commitments to these tiny little state fragments, right? So you have your big global state, and then instead of having that be one big global public thing, you shard it into these million tiny fragments with each user or each contract's data inside them. And those fragments are committed to on chain, but they're not actually part of the public chain state. So all of the existing sort of shielded chains that have ever been made have had a structure where. Oh, and also we include an encryption of this data onto the chain because that's like a convenient way for people to access it.
00:12:51.396 - 00:13:08.490, Speaker C: But the separation between the actual state, the state transitions happening, and what those states are is actually much more explicit in a shielded context than in a private or than a transparent one.
00:13:11.100 - 00:13:48.360, Speaker B: When you talk about the shielded, what I start to think of is, is it because it's not a state? What? Is it not a state model? It's like the Utxo model, or does it not matter even if it's not using? Because every time you say shielded, I kind of go to the Zcash version, which is just a different data structure. So I'm wondering if in your. And I actually would need to explore this anyways, but in your case, is it because of the way the privacy is actually being, because of the way the blockchain is actually built that you don't have it? Or is it because it's private?
00:13:50.460 - 00:14:35.940, Speaker C: It's mainly because it's private. So if you just think of like a transparent Utxo system, like on bitcoin, right? You can think of each Utxo as being like a little fragment of the chain state. And actually all of those fragments are public. Everybody can see them. Right. When you're in a more private model, generally, the way to think about it is that instead of having each transaction have the state change directly, each transaction is going to have. Here's some way that I'm consuming a previous state that was committed to without revealing which one for privacy, and then I'm also going to prepare a new state.
00:14:35.940 - 00:15:20.710, Speaker C: And then what my snark proof is doing is it's establishing privately that the transition from the old state to the new state is in accordance with the consensus rules of the chain. So previously, if you're in this transparent model, the validators that are running the chain are actually able to check the consensus rules. That's sort of the point of what they're doing. And the sort of functional piece of what the snarks are doing in a shielded chain is it's allowing you to push the consensus rules out to the untrusted clients without having to include them into the kind of trusted part of this.
00:15:25.080 - 00:15:37.844, Speaker B: Cool. I guess sort of my last question here. And by the way, John, I just want to check, are you able to hear everybody? I know Deborah was having some issues in the previous panel.
00:15:37.972 - 00:15:38.920, Speaker E: Yeah, I can hear everyone.
00:15:38.990 - 00:16:05.270, Speaker B: You can hear everybody. Okay, perfect. Do each of you imagine using something like, like, besides what you're doing right now, and the validator sets you have, and the way that you're doing data availability locally, kind of as proposed, is this something that you would do, or do you lose something by working by putting your data available, making your data availability on Celestia? I don't know if I'm saying that right, John.
00:16:07.080 - 00:16:08.752, Speaker E: Can I start by answering?
00:16:08.896 - 00:16:09.588, Speaker B: Sure.
00:16:09.754 - 00:16:44.380, Speaker E: Okay, perfect. I mean, obviously representing Celestia, I wouldn't be a project running on top of Celestia, but I can talk about the trade offs. Okay, so the benefit of using Celestia as a data availability layer is twofold. The first is you don't have to re implement all the complex data availability, sampling and logic, and that could be quite cumbersome. For example, e two, their roadmap. They push data availability stamping all the way. At the end is their current roadmap, like potentially three, four years from now.
00:16:44.380 - 00:17:24.492, Speaker E: It's a nontrivial problem, but the celestial team is among the best in the space. There's a lot of very bright people there, brighter than me, who are working on implementing this. So not having to re implement this is good. The second thing is you share security with all other native roll ups on Celestia and everyone else who's using Celestia for data availability. So rather than you having to essentially bootstrap your own security, your own validator set, you can share security in a way that doesn't hurt you. It's like purely additive security benefit. And this also ties into this honest minority assumption that I was talking about.
00:17:24.492 - 00:17:55.632, Speaker E: The honest minority assumption is that you need, depending on how big your blocks are, it could be a few dozen or it could be a few hundred nodes that perform these checks in order to be secure. So this means you want to have a network with a lot of nodes, and ideally to benefit from the scaling properties that are sublinear but not constant. You want to have as large blocks as possible, right, because the scaling is the square root of the block size. So this means, let's say you have a block size of one. Well, it's a square root of one. It's one. So you get no scaling whatsoever.
00:17:55.632 - 00:18:23.432, Speaker E: The block size is very large. You get much more scaling proportionally. So you want to be in a system where there's a huge number of nodes and blocks are as large as possible to get the maximum benefits. And the way to do this is to have one or a few of these data layers as opposed to everyone building their own, because everyone building their own would have more overhead potentially. There'll be more challenge to get that minimum required number of nodes for the honest minority assumption, and so on. So those are kind of the trade offs.
00:18:23.496 - 00:18:39.316, Speaker B: And Celestia has this sort of like, it's built purely for this one task, and therefore can make best use of these large blocks and doesn't have kind of the issues that other standard l ones that are trying to do a lot of things that are more generalized platforms would have.
00:18:39.498 - 00:19:14.348, Speaker E: Exactly. By having a minimal state machine that just manages the validator set. It's what we call a general purpose data availability layer, which I guess I didn't really explain too much in my talk, but the general purpose being, it can be used by any application with a minimal overhead. For instance, if you wanted to use e two as a data layer for your Cosmo zone, you couldn't do it without running an ethereum full node. And we all know that running an ethereum full node is pretty damn expensive. With celestia, we've minimized the state machine to basically as minimal as you can possibly get, so that the overhead of using celestia for your zone, for your rollout, for your application, what have you, is as minimal as possible.
00:19:14.514 - 00:19:32.820, Speaker B: And as I remember from an interview I did with your co founder, you end up running a node in your own kind of client software if you want to use Celestia, am I right? Like, you would basically be running your local node software and then also the Celestia one. So if it's light, it doesn't add too much to your existing.
00:19:33.240 - 00:19:41.976, Speaker E: Sorry, that's correct. You just run a celestial light node, and then you connect it with vain RPC to make sure all the blocks are valid and submit your roll up blocks to it.
00:19:42.078 - 00:20:05.280, Speaker B: Okay. And I'm not working with Celestia. I'm not trying to sell it to the three zones here. But I am curious. I mean, just since there are now kind of zone operator like news, like zone project leads, you already have validator sets. A lot of you or are in the process of building these. Does it actually make any sense for you to work with something like this? Or do you see this more for upcoming zones?
00:20:07.540 - 00:20:53.020, Speaker A: I really like the metaphor for Celestia, where Celestia is to building blockchains as virtual machines. Right now, blockchains are like servers. So I think of us as the population of people who are like, we have a rack. We have our servers of the rack. Why do we need aws? And then Celestia comes along and they have an SDK for building new blockchains on top know they'll have one or more software development kits building on top of celestia for data availability that you could adapt and use for your use case. Now, suddenly building a blockchain instead of becoming this multi year effort is like, oh, I pushed a button on my computer and now I have a blockchain.
00:20:54.400 - 00:20:57.436, Speaker B: But would you need to do it or is it sort of too late.
00:20:57.468 - 00:21:02.672, Speaker A: For any projects building blockchains until the sun burns out? So I assume I will be building.
00:21:02.726 - 00:21:05.556, Speaker B: Blockchains, future blockchains, but like something will.
00:21:05.578 - 00:21:08.624, Speaker D: Be running on a blockchain, he'll be uploaded, completely centralized.
00:21:08.672 - 00:21:28.916, Speaker B: Zucky okay, sorry. I should say to Dean that as a zone you're right, because Zucky assembly, I guess, is more like using lots of them. But Dean, would you use something like this? Would it make sense? Or are you too far along in your process to need this? Or is there still some benefit for you doing it even if you have a validator?
00:21:29.108 - 00:21:57.152, Speaker D: Right? So what's funny is the data availability part of Celestia today is kind of the first time I've been absorbing it. I'll have to hear it several more times. I've been paying attention to Celestia. Don't tell him. A Celestia clone. No, that technology as a backbone for future ago. So most of the agoric stack is above the consensus layer.
00:21:57.152 - 00:22:27.884, Speaker D: We use cosmos tendermint. It's great, it's wonderful, it's battle tested, and it's completely insulated from the execution. In the same way that react programs really don't care which Javascript engine they're running on, they're just fine. And we need key things that tendermint consensus brings it well, but as does hot stuff, as will Celestia. One of the ways we intend to do scaling. We start with tendermint's vast. It's fine, it's great.
00:22:27.884 - 00:23:20.830, Speaker D: It can handle plenty of transaction volume, but it fundamentally can't handle adding more machines add capacity, right? That's something that for any given blockchain in order to scale. How does adding more machines increase capacity? If it can't, then you can't scale. And for us, because we have asynchronous coupling, we can stand up parallel sets of validators that are all asynchronously messaging between them. It's a little like sharding, but it's not as strange as the stuff that Etha's planning there. It's just I've got multiple servers and I'm running different contracts on those different servers, and they all communicate uniformly with different latency. Well, Celestia, the backbone of it, gives a much better potential coordination of all those subagoric zones that we're using to spread out and scale agoric transactions. And so my view of the world a few years from now is that, yes, we're working that way.
00:23:20.830 - 00:24:06.924, Speaker D: So I absolutely, hugely interested in what's going on in Celestia. Having our data of current blocks go there now or in the near term, certainly not before the run protocol launches, probably not before the permissionless execution. But our design is such that migration and new technology platforms is straightforward, and it's one of the top two technologies that I'm interested in absorbing zero knowledge infrastructure on the other side being the complementary one. And these are some of the two most novel directions that are not in the engineering that my team is already expert at. And so I'm very excited about that.
00:24:07.042 - 00:24:07.660, Speaker A: Cool.
00:24:07.810 - 00:24:17.330, Speaker B: Okay, now, Henry, so this is now a privacy. Going back to what we had talked about before. Is it impossible to use something like Celestia, or is it possible?
00:24:18.980 - 00:24:28.964, Speaker C: Yeah, so I guess for us, I'm not sure that using Celestia would provide as much benefit as it might for.
00:24:29.002 - 00:24:39.530, Speaker B: Other people, because we should, say general data availability layer. We don't need to make sure I did it, too.
00:24:40.300 - 00:25:57.170, Speaker C: I guess I'm just using Celestia as kind of a stand in for, like, I guess that's actually kind of a credit to taking that you're building. But for us, the amount of public chain state that we're going to end up with is much less than you would have on sort of more conventional chain, because most of our activity is going to be done privately. And I think that trying to do data availability in a private way is certainly not impossible, but it's just a different set of design constraints, and I don't know exactly what that would look like. It might be that you have something like the design of celestia, but you have this additional modeling of who gets to see what the data is. Or maybe you're doing data availability, but only for encrypted blobs. What does that look like? I don't know. I think it's a very interesting thing to think about, though.
00:25:57.170 - 00:27:55.920, Speaker C: I guess this is maybe a very half baked analogy, or, like, quarter baked, or even less, because I just thought of it while listening to the panel, but there's this analogy in defi of, like, okay, so you have this kind of maximally adversarial environment for people who are building smart contracts, and there's, like, every week there's, like, a new big implosion or something. And the effect of that is that although this is, like, it's much harder and for an individual project, much kind of riskier, there's this kind of forcing function that everything that is left has to be much more robust and resilient. And I wonder whether the constraint of trying to build a shielded chain actually makes some of that has a similar kind of effect on the design for data access and data availability. Because, for instance, if you have a shielded chain, you can't just go and ask somebody who's running a full node, can you please tell me what my account balance is? That's supposed to be private. And so every user has to be sort of doing some amount of their own client state. And one of the big challenges is, like, how do you actually propagate data to the users so that they can understand what parts of the chain state they have visibility into, et cetera? And I'm kind of now wondering whether there's some kind of, like, long term interplay there where rather than just thinking about this context of, oh, well, we assume that we have these full nodes. It's kind of this subsidy.
00:27:55.920 - 00:28:47.284, Speaker C: I guess it's part of this analogy where if you think of tradfi, there's kind of this trust subsidy where it's like, oh, well, we don't actually need our system to be secure, because if someone does a bad thing, we can just phone them up and yell at them. Right? And then when that goes away, now you actually have to build something that's much more robust. Similarly, I think trying to build fully private systems where you don't just have the ability to kind of have these big, full node archivers that are subsidizing everybody else's data access, you have to have every sort of end to end client be able to understand what parts of this shielded data relate to me. I think there's some interesting interplay there.
00:28:47.402 - 00:29:37.752, Speaker B: Yeah, sounds like a whole new field of study, by the way. I think we are. Susanna, maybe you can say something in the chat. I think we're getting close to time, but I actually wanted to chat a little bit more about just general privacy scaling. Do we have a little bit of more time? Does everyone on the panel have, like, five minutes more? Ten minutes more maybe? I know we were supposed to end now if you have to jump, no stress, but I did kind of want to bring it to a more kind of general topic, which was that of just, like, general private blockchain scaling, when we talk about blockchain scaling. We have a lot of techniques that are being used and I think this idea of a data availability layer is one. Just the general idea of cosmos is one.
00:29:37.752 - 00:30:16.480, Speaker B: But I wanted to kind of survey all of you how you think you are approaching scaling blockchains and if privacy can play into that, and exactly how, and I know that we're going to take a little bit of a pivot away. This isn't about data availability anymore. This is actually a little bit more broad. So I actually wanted to maybe start with Dean and agoric. You mentioned you wanted to do some ZK stuff, but is it in the purpose of making a faster blockchain? Is it more just to add privacy? Are you thinking about ZK for scaling? Are you thinking about ZK for privacy? And how do you see yourselves as scaling blockchain?
00:30:16.640 - 00:30:47.208, Speaker D: So the first three scaling steps know we're starting with something reasonably fast. We can port to enhancements of it reasonably straightforwardly, but it's this thing I mentioned that potentially Celestia having an impact on is I can stand up agorc 1234 and five and the same smart contract components asynchronously communicate with other smart contracts. It's completely transparent. And now we've got horizontal scaling like we're sort of used to in more traditional settings.
00:30:47.304 - 00:30:55.952, Speaker B: Interesting. Even within just your system, not with other, you're not thinking of scaling because there's other zones doing all within one.
00:30:56.006 - 00:32:03.216, Speaker D: Scaling of the agoric platform. So it can handle more and more transaction volume and more and more use cases with the same model. And then that same technology leads to privacy where now a consortium zone or a private chain, it's running the same model, it's interoperating with contracts that are running on the public chain and so forth. That's not ideal privacy we want better than that. But it gets you some level of it means you can have a consortium chain for freight that's got private bill of lading for transactions between shipping companies, and now you get access to that 900 billion dollar market. Okay, that'd be useful, right? But it's not the level of privacy that we really think about here with technology. Now the two uses for zero knowledge, for me, the one that's most interesting is where we would be able to execute JavaScript transactions, the Javascript VM execution model, which is extremely well specified, as it turns out, on a single node and produce a snark proof proof of some flavor that it executed correctly.
00:32:03.216 - 00:32:45.760, Speaker D: There's people working on doing that for EVM. There was a simple C execution model where they did that. And there are reasons why doing that for the Javascript BBM is actually more plausible than either of those, because it's just got a more partitioned memory model. And so I'm very interested in that happening. That's something that a year and a half from now I really want to see as available. And that would give the simple scaling of the more machines you have, the more transactions you can process, the more independent contracts you can run, because you no longer need 100 machines all looking over each other's shoulder to execute each transaction. So I'm really excited about that as a zero knowledge for scaling and then we're talking about how to be able to integrate.
00:32:45.760 - 00:33:07.992, Speaker D: I'd love to see an IBC that had the recursive snarks so that you can do proofs of like client verification in a way that you would be able to do inside of a browser and be able to have a chain all the way back to the history of a chain or whatever. That's stuff that's a little bit above my crypto head, so I'm really looking forward to other people producing that and us integrating it in.
00:33:08.126 - 00:33:32.784, Speaker B: Okay, Zucky, I want to throw to if I don't know if you see Stomlia as a scaling solution so much, but how? Yeah, I didn't think so. But are you looking into scaling you've been working on, I assume other projects in that direction? What is exciting for you in terms of scaling? Are there privacy or.
00:33:32.822 - 00:34:28.710, Speaker A: I think the specific question about scaling and privacy that interests me is we do not know what form of privacy has product market fit. So it is extremely hard to know what form of scaling to employ. There's a lot of different possible ways of scaling different privacy solutions that have that have existed. And right now I think the only team that has really gone down the rabbit hole of trying to scale a private c solution is the mobile coin team. But it is very much around this assumption that we want private payments and we have no idea if private payments has product market fit or not.
00:34:31.400 - 00:34:33.030, Speaker B: Okay, I want to then go.
00:34:35.800 - 00:35:09.628, Speaker A: My guess is what has product market fit is private trading and private yield and not private payments. That's my guess, but we're going to find out. And the scalability architectures around private payments and private yield, if you want to just scale something like if you want to add privacy to civilia, I think our options at this point are pretty much all in the enclave domain. And then scaling via enclaves is another interesting domain. And actually mobilecoin has done a bunch.
00:35:09.644 - 00:35:10.930, Speaker E: Of really good work there.
00:35:14.580 - 00:35:16.950, Speaker B: Henry, I wanted to ask you a bit about this.
00:35:17.560 - 00:35:18.020, Speaker C: Yeah.
00:35:18.090 - 00:35:22.470, Speaker B: Well, do you agree with that, that private payments is not a problem? There's no product.
00:35:24.040 - 00:36:07.760, Speaker C: Here's another use case for privacy is preventing Zaki from front running my panel answer. Maybe I'll just kind of elaborate on that a little bit more. I've thought about this a bit because it's pretty relevant to our choice of what we decided to build. Thinking about private payments, it's, it's interesting. I feel like payments are often held up as this kind of like be all end all of like blockchains and like, especially among kind of like crypto skeptics. You'll hear about like, oh, can you use this for payments? And if not, then this clearly has no value whatsoever.
00:36:07.840 - 00:36:08.470, Speaker B: Right.
00:36:09.560 - 00:37:28.940, Speaker C: And the thing that's interesting to think about with payments is, okay, you have this blockchain, it's recording some economic transactions, and you have these transactions that are on the blockchain. What actually is the connection between the transaction that's on the chain and the actual economic transaction? And the thing that's interesting about payments is that the data that's recorded on chain is only ever one side of this actually sort of economically meaningful transaction. People don't just send payments just because or for fun or whatever. They're sending a payment as one half of this larger economic transaction. And so if you want to use a blockchain for doing payments, you have this super hard adoption problem where you have to have this whole sort of, in addition to building and scaling your technology on the computer, you have to build and scale this social infrastructure for people who are interested in using this thing for payments. And when you do that, you run up against extremely strong network effects.
00:37:31.280 - 00:37:40.850, Speaker B: What's effect? Are you trying to create a network effect? Or when you say run up against, I'm picturing it's like you don't have network effect.
00:37:41.380 - 00:38:05.652, Speaker C: The reason that people like to make payments with fiat dollars using credit cards or whatever, is because it's a very universal thing you don't really have to worry about. Yeah, Dean, I think wanted to jump in. This is relevant.
00:38:05.716 - 00:38:07.284, Speaker B: You're muted. You have to unmute.
00:38:07.332 - 00:38:08.410, Speaker D: There we go. Okay.
00:38:09.260 - 00:38:12.088, Speaker B: I've been muting people who have little background noises sometimes.
00:38:12.174 - 00:39:27.270, Speaker D: Yeah, I apologize. I have a mute that I forgot to is I'll start with a statement and then I have a question to follow up with what Henry just said, which is one of the things that is valuable around simply having shielded payments and asset holding can give us a way into some privacy that I think that is somewhere between payments and yield, where if I had a pool of shielded payments and I want to go and participate in a smart contract on Agorak or buy an NFT or something like that, I take it to an unshielded address, but not one that's associated to me. It's a newly minted unshielded address. Now suddenly a run or 1000 zec or whatever it is appears transfer over to a gork, go buy something. And now some pseudonymous identity owns this NFT, paid for by someone that we have no idea because they're effectively protected by the insulating layer of the shielded assets and payment pool. And so what that means is that means that in a much larger defi ecosystem, anyone who has an account in Zcash bridged over. Whoops, we all went away.
00:39:27.270 - 00:39:30.548, Speaker D: I just got the thank you for.
00:39:30.554 - 00:39:34.756, Speaker B: Attending the event, I guess finish what you're saying. And then I think we went on.
00:39:34.778 - 00:39:50.410, Speaker D: Penumbra or in zcash that can bring assets over, can take advantage of privacy for yield or for defi simply by having that first step of payments. And so I'm curious whether you're set up for that on penumbra, because that'd be exciting to be able to.
00:39:51.420 - 00:40:11.356, Speaker C: Oh, I think we're losing the panel. That's an unfortunate, right? Yeah, we're all being gently shown the door by this server, but, yeah, so it's interesting. I actually kind of disagree with that. But we'll save it for a future panel.
00:40:11.388 - 00:40:31.592, Speaker B: I guess we'll have to come back and do this again when we're not getting booted quite often. Now we learn what happens if you go too long over. Anyway, thanks to everyone for coming to the event, and thank you all for being on the panel. We'll have to continue. We'll put a pin in these and we'll bring them up for the next one. Yeah.
00:40:31.646 - 00:40:31.944, Speaker C: All right.
00:40:31.982 - 00:40:43.480, Speaker B: Just a quick note, if anyone's still listening, there is a feedback form. We're also going to email that out to you. And apparently you can also answer this little form to help us know how to do this better next time. Cool.
00:40:43.630 - 00:40:45.892, Speaker D: Thank you for an awesome panel, as usual. Bye.
00:40:45.956 - 00:40:47.430, Speaker B: Yes, thanks. See you later.

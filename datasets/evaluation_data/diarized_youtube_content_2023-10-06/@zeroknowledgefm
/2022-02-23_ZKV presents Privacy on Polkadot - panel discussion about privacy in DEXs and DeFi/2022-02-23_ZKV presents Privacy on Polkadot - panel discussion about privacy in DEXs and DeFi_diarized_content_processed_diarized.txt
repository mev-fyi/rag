00:00:00.570 - 00:00:03.454, Speaker A: Hello, everyone. Guillermo, do you want to say something so we know we can hear you?
00:00:03.492 - 00:00:06.046, Speaker B: Well, I can hear you.
00:00:06.068 - 00:00:25.138, Speaker A: Great. All good. Okay, great. Okay, so just a quick intro to this panel. It was originally going to actually have someone from parallel finance. We were going to talk a little bit more generally about like Defi, but they weren't able to make it this time around. So today we have Schumo, who you just heard from, from Manta and Guillermo.
00:00:25.138 - 00:00:27.846, Speaker A: Guillermo, do you want to tell us a little bit about yourself?
00:00:28.028 - 00:01:07.614, Speaker B: Yeah, I guess a quick TLDR is. Hi, I'm a Stanford PhD. My PhD is not in ZK or really anything related to ZK. It's actually in optimization physics. But it turns out that every once in a while I can come up with a problem that actually happens to touch the zero knowledge side of it. So we've essentially done some work on privacy and Defi and all of these things like differential privacy and possibilities of souls of privacy and all this stuff. And I guess in the not so far future, LB, head of research at Vain Capital's new crypto fund, which is soon to be announced TM.
00:01:07.742 - 00:01:41.902, Speaker A: Yay. That's why I didn't want to announce you. I keep letting you announce you until we know that, until it's all, yeah, I. One of the questions I want to start this off. So what I want to do with this session is basically explore privacy and defi type concepts. But before I do that, I actually wanted to ask you Shumo something, because I remember when we first heard about Manta. Manta was presented as a privacy amm, but what you just presented to me looked more like a shielded area.
00:01:41.902 - 00:01:45.870, Speaker A: So can you just tell me, are you still an amm?
00:01:46.610 - 00:02:16.994, Speaker C: I think we are going to amm. I think first PLDR. Right. So I think basically there is a little bit roadmap switch. Basically we already built the shared payment part, right. The next thing we're going to build is actually like a fully EVM compatible programming layer for the programming layer for the private asset. And then the MM would just be one of the many contracts we can deploy.
00:02:16.994 - 00:02:36.046, Speaker C: Contract. You can deploy the contract. So I think we will have announcement once we're basically already finished design, but we're actually holding the announcement bit. But please keep following us. We are committed to bring you the privacy and. Okay, but it will be the part.
00:02:36.068 - 00:03:05.800, Speaker A: Of the bigger project, but it sounds like it's still part of the work that you're doing, like in understanding these and navigating them. Indeed, indeed. So why don't we spend a little bit of time though, talking about if it was easy, everyone would do it. What is the actual challenge? Private amms in general? Guillermo, I feel like you've navigated, you've done some papers where you talked about some of these problems, but maybe you can share with us. Why is it?
00:03:08.430 - 00:04:21.120, Speaker B: Guess I hope none of you follow me on Twitter, but if you do, you've probably seen this. I'm so sorry, I'm just apologizing in advance. It's probably bad for your health. But yeah, the hard thing about any kind of general private application is that global state, like having global state is really hard because global state leaks something about the underlying things that's supposed to be private. So CFMM is a very special case where the global state, literally just knowing things like very basic stuff like knowing the marginal price of a token in a CFMM, actually turns out to be enough to leak the entire, but it's enough to leak the reserves. This is some result that we actually inspired by Anna originally, I think you're acknowledged in the paper, if I recall correctly, where we essentially show that you solve some cute little nonlinear system of equations and immediately you get the results out, given just the prices of the assets in the CFMM. So in general, it's very hard to make full privacy guarantees about things that rely on global state.
00:04:21.120 - 00:05:01.280, Speaker B: And you can often say something like, hey, look, statistically, we can know a little bit more information that gets leaked about the underlying protection in CFMMS. It turns out there's like a very explicit, simple form for what that is. And it's in fact, I can recover the entire state of the CFMM given just the prices. And I guess, yeah, I can provide a link to the paper once. That's the big challenge. This is true of any, again, it's true of any global application that really interacts with the global state in a non trivial way. But CFMM is just like a really clear example where you can just like just the basic stuff that you need to know to be able to interact with it is enough to reconstruct the entire thing.
00:05:01.890 - 00:05:40.060, Speaker C: Yeah, I want to add a little bit. Right. So, for example, in our AMM design, I think we actually know, I hope I pronounce your name right, Daniel Mo's results when we first designed. Basically, I think the root problem is on the AMM scheme itself. Also, it's about the usability, for example, when people want to trade, it's very hard to ask people to trade without knowing the price. And because the public ledger's nature, the price have to be kind of public. Unless you have really fancy crypto, I don't even know how to do that.
00:05:40.060 - 00:06:18.082, Speaker C: For the Mantiswap design, we're still committed to that design. The privacy guarantee. If you read our paper, the privacy guarantee is very clear. We don't provide any protections on not leaking the price. We actually provide the protections of not leaking your identity. Basically, you can think of after shielded transfer, your identity will be shielded by the ZKP, despite the price is getting mean. There are kind of theoretical, more advanced designs like Zaxi.
00:06:18.082 - 00:07:03.460, Speaker C: They can provide you better protections in terms of the price leakage. But I think we're trying to make a trade off here. Basically, Zaxi's design is pretty complicated. Probably one day people are going to actually fully implement that. But for us, basically, we want to provide Amm style that is kind of like a bulletproof design. AmM actually works in the real world and then provides you a protection of the privacy leakage of your identities. Also, I just want to say we actually have a full security proofs of reduction based security proof of privacy for the exact privacy we're trying to protect.
00:07:04.070 - 00:07:12.438, Speaker A: Is that still the work that you're doing, though, or have you kind of pivoted? Like, you sort of mentioned that you're sort of switched up your design? Does your amm still.
00:07:12.604 - 00:07:14.854, Speaker C: Yeah, exactly the same design it is.
00:07:14.892 - 00:07:19.890, Speaker A: So it's focused mostly on id privacy, but not on amount or price.
00:07:20.060 - 00:07:39.838, Speaker C: Yeah, basically you can think of the fungible token layer as private. Also, just want to say we didn't pivot. We just try to generalize the thing. So, for example, you can write a Sorrenti contract to manipulate the thing. We don't have to be the only player to deploy the am. And basically, we're kind of building a platform right now.
00:07:39.924 - 00:08:05.110, Speaker B: Okay, so, yeah, this is similar in spirit to, I believe, flax by Waydai, if you've heard of. I can link the paper, as paper is distinguishing between two things. It's anonymity and true privacy. Right. So anonymity is absolutely. That's easy to keep, and you guys have absolutely done it right. Assuming that hardness is holds, of course, but whatever we assume.
00:08:05.110 - 00:08:38.946, Speaker B: But, yeah, the price is always fundamentally leaked, and essentially no one knows how to do this in a way that doesn't really result in us. There's some interesting ideas around how to kind of mitigate this. For example, penumbra has one idea, which is, I think there's like a pareto optimal curve of economic efficiency and privacy. And I think it's like on the, I guess the bottom right of the period optimal curve. But this is a very different trade off, right.
00:08:39.128 - 00:09:25.650, Speaker C: I think yourself has a paper for adding some differential privacy into this realm, right? So actually this is a very interesting design, I think could be practical if someone really drilled deep into that, just to the audience who don't know differential privacy a little bit, right? So differential privacy is kind of like not as good as the case privacy guarantee, kind of, kind of waving thing. You define two parameters. If it's not delta. So basically you can control the leakage, but you don't have a good picture of what is adversary models of the privacy. You don't have assumptions of adversarial powers. Instead you give this kind of like a little bit more hand waving, but still good privacy guarantee.
00:09:28.630 - 00:10:12.960, Speaker B: The ideas is essentially you can. Then this method of differential privacy essentially does stuff like add noise to the price in our people, not be able to reconstruct it. So it gives you some nice guarantees, right? So like you said, it gives us some slight model free guarantees, although the constants are really terrible and so it's not particularly practical. But the big thing is that it gives the user away, essentially a sliding scale. So you could be completely anonymous but not private at, right, in the sense of like, you just leak the exact amounts, but you're really economically efficient, right. Because your price is exactly what the CFMM says. You do the trade, it works great.
00:10:12.960 - 00:10:52.534, Speaker B: On the other hand, you could have a sliding scale that goes all the way up that says, I'm willing to pay a lot of money to preserve my underlying trade privacy. Right. And so that's kind of the way of thinking about it. Differential privacy is kind of this method where you're trading off two costs, one of which is economic costs to you. These aren't always bad. They're just on average worse versus kind of how much privacy you actually want to have right in the underlying asset. The problem is it's very complicated, a, it's very weird to reason about, b, and the constants are terrible.
00:10:52.534 - 00:11:03.040, Speaker B: So that is best a weird paper to read and be like, that's interesting. I guess we could do that. But don't take it too seriously, you might end up in a bad place.
00:11:03.810 - 00:11:33.146, Speaker C: I also want to add a little bit. I was doing some differential privacy research. I think one thing is that the privacy guarantee is not very compostable. So, for example, if you have two things, then the two leakage together will constitute a bigger leakage, and it's still active research. How to control that. So basically my take is that you should add DP on the primitives like manta, so that you have fundamental layers privacy guaranteed. Then adding differential privacy may works better.
00:11:33.146 - 00:11:39.180, Speaker C: Then you just use DP first, right? This is quite interesting.
00:11:39.550 - 00:11:44.862, Speaker A: You just said if you add two things, but what do you mean by that? What would that look like?
00:11:44.996 - 00:12:22.442, Speaker C: So for example, you have action one, whose privacy guarantee is in differential privacy. And action two, your privacy guarantee is also differential privacy. Then by adding this, because action one, you have some privacy leakage. Action two, you have some privacy leakage. This thing combined. So sometimes combined linearly and sometimes it actually combined as a multiplier so that it's really hard because then the leakage will go on. Then you may find that you are very quickly in the situation that the leakage is too big.
00:12:22.442 - 00:12:34.166, Speaker C: That becomes a serious threat to your privacy. Sorry to drag you deep into this kind of academic privacy discussion rabbit hole.
00:12:34.198 - 00:12:36.770, Speaker B: But that's a spirit.
00:12:36.950 - 00:12:57.330, Speaker A: Can I go back to this sort of like the type of things that get leaked? And in the differential privacy option, is that actually hiding amount and price and id, or is it? Which part? So we had talked about these three different pieces of an amm that you could make private id, price, amount, what does it hide?
00:12:58.790 - 00:13:01.960, Speaker B: I guess the big thing to remember is that price gives you amount.
00:13:02.410 - 00:13:04.086, Speaker A: Okay, so they're kind of the same thing.
00:13:04.188 - 00:13:13.340, Speaker B: Yeah, exactly. So they're equivalent in a lot of ways. And in fact, in some sense, in some statistical sense, hiding one hides the other. And that's the result here.
00:13:13.710 - 00:13:15.466, Speaker A: Hiding one hides the other.
00:13:15.568 - 00:13:16.266, Speaker B: That's right.
00:13:16.368 - 00:13:19.180, Speaker A: Okay, but leaking one does not leak the other.
00:13:19.790 - 00:13:27.294, Speaker B: Leaking one also leaks the other. They're equivalent. Okay, like in a sense of, like you can use either to reconstruct the other.
00:13:27.412 - 00:13:30.122, Speaker A: Okay, so you have to hide all of it, essentially.
00:13:30.186 - 00:13:30.462, Speaker C: Yeah.
00:13:30.516 - 00:13:50.600, Speaker B: Okay, right. So usually people don't need the quantities to trade, they need the prices, right. So you usually reason about prices as opposed to these specific quantities. But at the end of the day, the user pays out the quantities, right. So the user has to be like, I'm putting 0.3 e. So that is where the key comes in.
00:13:50.600 - 00:14:03.546, Speaker B: If the market says, actually here, I'm going to say that the price is 0.3 e. But I added a little bit of noise. Actually, in reality it's actually 2.7 or, sorry, point 27.3, that would be very bad. If it was 2.7,
00:14:03.546 - 00:14:27.730, Speaker B: then you can say something like, oh yeah, we're not as economically efficient. Or in that case, you came out on top, but in expectation, it's actually worse. So does that make sense? Essentially, they're both equivalent notions that result essentially just says that by knowing the prices, that's enough to reconstruct the amounts and vice versa is obvious because obviously knowing the amounts that you have gives you the price slippage.
00:14:30.470 - 00:14:56.780, Speaker A: I'm realizing I'm doing this panel kind of backwards, but now I want to go into why do we want to hide either of them? This is like where you're supposed to start this conversation, but we did it the other way, so we got there. Why would you want, like, hiding amount price? Hiding price, or hiding color? Give us a little bit of a sense for why you do that. So maybe let's start with id. Why do you hide id?
00:14:57.390 - 00:14:58.826, Speaker B: Shuba is the expert on that.
00:14:58.928 - 00:15:04.526, Speaker A: Yeah, shuma, go for it. Why do you need an Amm that hides id but doesn't hide price?
00:15:04.708 - 00:15:30.840, Speaker C: I think the identity is one of the fundamental kind of human digital sovereignty. Right. So for example, like everything else, for example, you probably don't want your transaction history lagged after the bronchian for everyone. So also recently we talked to a lot of folks in Dao force. I think one of the problems we're trying to help them to solve is that the payroll of Dao. Payroll of Dao, kind of like payroll information is very sensitive. Right.
00:15:30.840 - 00:16:16.094, Speaker C: If you think Dao is going to be a future, then we need to solve this on chain privacy problem. I think there's just a lot of potential usage of privacy, and that's actually core need. But I kind of agree with you mean, we're kind of thinking the future is a hybrid model. You should control which part you want to be private or not, depending on your purpose and need. But absolutely not everything have to be privacy in the specific context of amm. I'm actually curious and want to ask Gilmo a question. One thing I'm curious, if you have a fully private amm, right, then you don't have the price and quantity being leaked.
00:16:16.094 - 00:16:38.460, Speaker C: Then I feel like kind of a liquidity discovery. This is kind of like a market. Arbitrage could be an interesting problem too, right? Because the kind of assets of the amm is that, hey, we have a free market so that different people arbitrage and the price and balance curve will eventually be there. Right? That's actually very.
00:16:41.150 - 00:17:17.430, Speaker B: Guess I'm going to start with Anna's question, I guess, and then I'll move on to the second part, which so, but I'm going to do. Why would you want to hide the prices in the trade up, right? That's the next natural question, because identity is obviously extremely important, right? And honestly, in a lot of ways it's almost the most important. So here's one easy answer is I am jump trading and I am trading shitcoin arbitrarily and I'm putting a bunch of money into random stuff. I do not want people. Here's the thing that I definitely don't want is people reconstructing my strategy.
00:17:19.290 - 00:17:22.502, Speaker A: They don't have your id. How do they know it's you?
00:17:22.556 - 00:17:23.254, Speaker C: Right?
00:17:23.452 - 00:18:13.746, Speaker B: So how would you know? Let's say you are on average buying a bunch of tokens, and slowly but surely the price is going up. And there just seems to be this consistent stream of purchasing. Statistically, sure, it could be the fact that everyone decided to buy whatever dog token number 365, but it could also be the fact that maybe there's one person slowly but surely purchasing this token and trying to get a good price on it so I could front run you and then push the price up. This is why you do things like whatever, time weighted average pricing and things like that. This is why large orders sometimes get chunked into smaller blocks and you do them slowly but surely. But statistically speaking, right? You're still leaking information about what you're doing, even if you do it slowly over a good amount of time. So this is a huge thing in high frequency trading.
00:18:13.746 - 00:18:28.894, Speaker B: This is a massive thing is like trying to discover the other person's playbook and then trying to play against that. So this is weird cat and mouse game. Here's one. One perfectly reasonable way to get rid of that is I actually have no idea what the hell you just traded and I have no idea how much of it was. And not only do I not know that, I also don't know who you are.
00:18:28.932 - 00:18:29.914, Speaker A: So good luck.
00:18:30.042 - 00:18:30.720, Speaker B: Right?
00:18:32.370 - 00:18:59.290, Speaker C: Yeah, I want to add a little bit. Yeah, go ahead, please. I think antifung running and mev protection is actually harder problem than privacy. I actually did a little bit practical research. Right. So for example, let's say even everything is perfectly private as long as this is a permissionless system. Some people can do price probing actions.
00:18:59.290 - 00:19:52.182, Speaker C: I had some discussion with some MIT folks about how do you really design fully front running resilient systems? Seems really hard. You probably need something like a VDF. Basically, you should delay disclosure whether this trade is successful or not. Then you kind of have some hope for a full front running discussion. Because we were thinking, hey, can a fully private deck be anti front running and unfortunately, at least theoretically, the answer is kind of no, because the root is because it's a permissionless system and everyone can trade and try to probe the price, then there might still have chance to front rank.
00:19:52.246 - 00:19:58.106, Speaker A: Yeah, that's kind of like accidentally, accidentally front running, for example.
00:19:58.288 - 00:20:19.300, Speaker C: Yeah, exactly. If you keep pinning, you just have some higher confidence that you have some front running opportunity. Just act to the, let's say you are validator. Right. So you just keep probing. Right. Despite you don't know the exact price, then you can still find some front running opportunities for very complicated strategy for front running.
00:20:19.300 - 00:20:24.638, Speaker C: It's actually a very hard problem in general, unfortunately.
00:20:24.734 - 00:20:46.314, Speaker B: I'll give you the kicker on the BDF, is that it probably doesn't work because you can often grind through. So actually it turns out it's even harder than we ever think. It's actually kind of bonkers how difficult mee protection is. And there's also a question of whether we would want that or what it means. But Ember has actually an interesting solution for this.
00:20:46.512 - 00:20:51.878, Speaker A: Sorry, Henry, if you're does also osmosis with this idea of threshold decryption?
00:20:52.054 - 00:20:54.560, Speaker B: Yeah, I think osmosis might do something similar.
00:20:55.490 - 00:20:57.738, Speaker A: Were you about to say threshold decryption?
00:20:57.834 - 00:21:07.774, Speaker B: That's right. So the idea is actually what you do is at every block, you just aggregate everyone's trades and then afterwards decrypt them and then put them through the decks.
00:21:07.822 - 00:21:08.034, Speaker C: Right?
00:21:08.072 - 00:21:35.306, Speaker B: Yeah, I think they both have that in some sense. Now you don't get screwed because everyone gets the same price. But here's the deal. Now, arbitrage and direct trading is weird, right? Because now you don't know the price you're going to trade at up to a slippage threshold. But b, you also don't perform the trade until the block is fully minted. Right. You're not guaranteed that that thing is done until 50 seconds from now.
00:21:35.306 - 00:21:47.738, Speaker B: And then you don't know what price you're going to execute at. But it's weird. But essentially now you've done this thing where I can't front run you. The notion doesn't even make sense anymore.
00:21:47.834 - 00:21:48.094, Speaker C: Right.
00:21:48.132 - 00:22:02.100, Speaker B: I can do statistical things where I'm guessing that you're going to continue buying and then you could do it across a bunch of blocks. But there's no notion of pure flashbot style front running, which is kind of crazy.
00:22:03.670 - 00:22:15.720, Speaker A: I want to just check in. Shumo, you had had this other question, the second question before. Did we actually answer that in what you just said or was that something else? And I tried to write it down, but I missed it. Do you remember what it was?
00:22:16.650 - 00:22:30.790, Speaker C: I can repeat the question. The question is, if you have a truly private, like a change scheme. Right. How about arbitrage and liquidity discover we kind of make the price in the free market and in the equilibrium of the supply and demand.
00:22:30.950 - 00:22:38.874, Speaker A: But is this assuming we're not talking about the MEB threshold decryption, we're talking about just pure private amm or CFMM.
00:22:39.002 - 00:22:40.160, Speaker C: Okay. Yeah.
00:22:40.770 - 00:22:56.820, Speaker B: So in that case, yeah, again, the answer is the same. Right. Any cost that's going to come to the user, it's going to get offloaded to the people who are doing arbitrage, for the people who are maintaining prices to be approximately equal. So if you're eating the cost, someone else is also eating the cost.
00:22:57.190 - 00:22:59.154, Speaker C: Sorry. Yeah.
00:22:59.192 - 00:23:28.880, Speaker B: In some sense, they're also less economically efficient. And economic efficiency here is a very general, mostly ill defined term. If you ask anyone and their moms are going to tell you something different. But the point is, yeah, so someone eats the cost of the unfortunate thing that now you don't have an exact price. Right. You have some price within some weird epsilon ball, which gives you the privacy amount or something like that. So sometimes you end up better, but in expectation, you probably end up worse because you just have less information about what the underlying object is you're interacting with.
00:23:30.050 - 00:23:33.854, Speaker C: Yeah, that's my intuition. But thanks for answering the question.
00:23:33.972 - 00:23:42.626, Speaker B: Yeah, I mean, it's intuitive, too. I haven't written down, like, theorem 3.26 that says, in fact, here is. But you see. That's right.
00:23:42.648 - 00:23:42.786, Speaker A: Yeah.
00:23:42.808 - 00:23:43.234, Speaker B: Next paper.
00:23:43.272 - 00:23:44.100, Speaker A: There we go.
00:23:45.690 - 00:23:47.442, Speaker B: But you might be an author if you're not careful.
00:23:47.506 - 00:23:48.280, Speaker C: Oh, no.
00:23:48.970 - 00:23:50.882, Speaker B: So, better freshen up your math skills.
00:23:50.946 - 00:23:51.174, Speaker C: Yeah.
00:23:51.212 - 00:24:21.118, Speaker A: Right. I'm just the moderator, man. All right. So I think we actually are at the end of the time frame we had allocated for this, we even maybe went over. I want to say a big thank you to both of you to come on. And it's great, because I wasn't sure when one of our panelists dropped off if we could pull off the privacy defi decks, and we did. And I'm very, very happy that you are both here to explore this with us, for sure.
00:24:21.204 - 00:24:21.966, Speaker B: Thank you for having us.
00:24:21.988 - 00:24:25.100, Speaker C: And thank you, Shimo. Yeah, thank you. Thank you. Yeah, cool.

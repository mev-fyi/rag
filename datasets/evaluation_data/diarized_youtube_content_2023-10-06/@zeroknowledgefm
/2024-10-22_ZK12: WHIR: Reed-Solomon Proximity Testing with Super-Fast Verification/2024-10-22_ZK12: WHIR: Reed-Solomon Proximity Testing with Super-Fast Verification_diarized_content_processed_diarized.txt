00:00:07.920 - 00:00:13.681, Speaker A: Okay everyone, welcome. Next up we have Ilan from Bar Ilan University. Take it away.
00:00:13.873 - 00:00:44.995, Speaker B: Okay, thank you. Hi. So first this is joint work with my student Gala Renoun and Alessandro Chiesa and Giacomo Fenzi. And I'm kind of very excited to be here. And this is a kind of present were, this is the premier presentation of where last ZK Summit we presented the stir. And this is kind of a new improvement on top of that. So where is Reed Solomon proximity test? And it has superfast verification.
00:00:44.995 - 00:01:27.125, Speaker B: And so I'm going to go slightly into technical details about that and we're also going to see benchmarks and. Yeah, so, so let's start. So first we're in the ZK Summit conference and what are our goals? We want to construct snarks. Okay? These are succinct, non interactive arguments of knowledge. So we have a prover, we have a verifier. The prover wants to convince the verifier that he knows the solution, right? He knows a witness to this instance. And in our case, the prover and verifier are going to share something called a random oracle, as Anna discussed this morning.
00:01:27.125 - 00:02:22.427, Speaker B: So they both have access to this random oracle, which they can query and get back a completely random answer. And we want the proof of course to be kind of very small, okay? In particular much, much smaller than the size of the witness itself. Okay? So we're going to only have a random oracle. There's no other assumptions, okay, Assumed in this talk. Once you have such a scheme, you can replace the random oracle with some concrete hash function, okay? So instantiate the random oracle with a hash function and what you get is a snark that you can deploy in practice. And the advantages of such snarks are that they have a transparent, transparent setup, okay? So the only setup that they require is choosing this hash function, the user. They usually are quite highly efficient.
00:02:22.427 - 00:02:59.789, Speaker B: So there's no public key crypto, there's no elliptic curves and stuff like that. There's only hash functions and usually over small fields and stuff. And so they're quite highly, they're fast and they're also post quantum secure, if you care about that. Of course, today these snarks are used to secure billions of dollars in blockchain transactions. I guess you know about this. This is just a small subset of the companies using this stuff today. Okay, so how do we construct hash based snarks? What we do, we do the following.
00:02:59.789 - 00:03:50.299, Speaker B: We first construct an iop. An IOP is an interactive proof between approver and verifier. Where the verifier does this small number of queries to the proof. These are the green locations here. Then you take this proof and you compile it using something called the BCS transformation, okay? Roughly speaking, every message of the iop, you're gonna Merkle tree, okay? You're gonna create a Merkle tree and commit to it. And then when the verifier wants to read something, you're gonna send the authentication path and all these long rounds of interaction, you're going to use feature to compress to one message, okay? And the efficiency of the snark is mainly determined by the efficiency of the iop. So the prover is roughly the same, the verifier is roughly the same with additional hashes.
00:03:50.299 - 00:05:11.455, Speaker B: And if you have some proof lengths of length L and Q queries, okay, usually the proof length is kind of big. This is the size of your computation, let's say two to the 24, and you have some number of queries. This is going to affect the argument size at the end and the verifier running time and so on. Okay? So we want to construct more and more efficient IOPS, okay, for the relation you want to prove for I1Cs or something like that. How do we construct these IOPS? And this is the last slide before we go to steer to wear what you do, you construct these polynomial iops, okay? So a polynomial IOP is just an IOP where we restrict the honest and malicious prover to send only polynomials, okay? So they have to send polynomials. And the verifier, what he can do, he can query these polynomials, he can evaluate them at any field element that he wants, okay? So the approver is gonna send some polynomial Q, then the verifier can query this Q at some point x, and then you have maybe some polynomial P and Q and so on. And once we have this polynomial iop, what we do, we compile it to a standard IOP that is then later going to go to the BCS information.
00:05:11.455 - 00:06:18.649, Speaker B: And how do we compile these polynomial iops, what we do, we either use a polynomial commitment scheme, which is just a cryptographic way of enforcing the prover to really commit to a polynomial. But actually, more generally, I just want to take this slightly higher view as any compiler that takes a polynomial IOP and outputs an iop, ok? So one way to do it is using a polynomial commitment scheme and then doing this function by function. But any such compiler is what we want, and any such compiler is in particular actually a polynomial commitment scale, okay? We have many examples. Many of the snarks we know today use this blueprint to construct snarks. And there's many examples, I'm not going to name all of them. The polynomial commitment scheme that you use underneath could be KZG or something based on lattices or something like that, or it could be something based on hash functions. So hash based polynomial commitment scheme.
00:06:18.649 - 00:07:11.305, Speaker B: And this is going to be the focus today and I'm just giving a few examples. This could be fry based or stir based or baseball based. And these are the three examples I give because we're going to mainly compare to them because they're the most relevant to this work. Okay, so the way these hash based polynomial commitments can work, we ask the prover to kind of instead of sending a polynomial, evaluate it at many points and then we kind of need to test what the approver do. So this leads us to a result. So in this work we're introduced a new polynomial commitment scheme that has a really super fast verification. Okay, so more technically what we do, I need to define what the Reed Solomon code is.
00:07:11.305 - 00:07:44.475, Speaker B: So we recall what the Reed Sulman code. We had some finite field F. Okay? We have some evaluation domain L and we have some parameter M. M is going to be the degree and then we're looking at the Reed Solomon code. So these are all functions F from this domain L to the field. Ok? So all evaluations of functions such that the function is univariate low degree polynomial of degree at most 2 to the M. Okay, So M is going to be log the degree in this example.
00:07:44.475 - 00:08:31.255, Speaker B: So this is the Reed Sullivan code. And equivalently in this work we kind of have this dual view of the Reed Solomon code where you can look at it as a univariate polynomial or a multilinear polynomial. So you can take the 2 to the M coefficients and you can view them as coefficients to a univariate Polynomial of the degree 2 to the M or a multilinear polynomial that has m variables. So we have this duality between the two. Either we have M variables or just one variable with degree 2 to the M. Okay, so what we do, we're going to define a constraint Reed Solomon code. And this is going to be very helpful for us.
00:08:31.255 - 00:09:22.837, Speaker B: And this will allow us, allow me to tell you exactly what we're is. So a constrained readsolomon code is just a subset of the code words of Reed Solomon that has this additional sum constraint. So there's some checklist like constraint that you add upon it. So my code now is not on all code words, okay, but just a subset that satisfies some additional constraints. So this W is going to be some polynomial and sigma is some target sum. And then I'm looking at all the polynomials in the multilinear notation that satisfy this additional sum. And this additional sum in particular is expressive enough to express a constraint of evaluation of this polynomial F.
00:09:22.837 - 00:10:13.363, Speaker B: So I have F and I want to say oh, but F on some point Z equals sigma. And there is a way to translate this to such a constraint. Okay? And this is what allows us to use where as a polynomial commitment scheme. Okay, so what is where? Where is an iopp, an IOP of proximity for constraint Reed Solomon codes. Okay, where fry, if you know fry, fry is an IOPP for Reed Solomon code and steer is also an IOPP for Reed Solomon code. Weir is going to be an IOP for this constrained Reed Solomon code. Or in other words, in world of higher marketing world, it's a polynomial commitment scheme for either univariate or multilinear polynomials.
00:10:13.363 - 00:10:54.513, Speaker B: So it works for both. So for degree two to the M, okay, in the univariate case or m variables with some security lambda and folding parameter 2 to the K, this folding parameter is some parameter, some trade off that we can play with. It means that like in the 5 protocol, in every query you kind of read 2 to the K filled elements. Okay, the query complexity of where is this expression. This is lambda over k times log m. And forget about this complicated expression, we'll see it in a second and we'll have benchmarks. Also soon we kind of set k to be roughly log m.
00:10:54.513 - 00:11:26.441, Speaker B: And then what you get is the query complex is actually O of lambda, which is actually optimal. The verifier running time. The verifier running time is this query complexity. Well, the verifier needs to do something per query, right? Times 2 to the K plus M. So again, 2 to the K is going to be the bigger term here. And for every query, the verifier reads 2 to the K field elements. This means that in terms of field operation, the verifier is actually linear in the number of field operation.
00:11:26.441 - 00:11:49.289, Speaker B: It reads from the proof. Okay, this what makes it makes the verifier very fast. And not only that, actually the verifier performs zero divisions. Okay, so not divide by zero, but doesn't perform any divisions. Okay, the Alphabet is what I said. You have that you read two to the K kind of field elements in every query. This is the roundup complexity.
00:11:49.289 - 00:12:25.535, Speaker B: It's m over K and the proof length is linear. Okay, so what does this mean? How does this compare to prior work and what does it mean with actual numbers? Okay, so first let's compare the query complexity to some prior work. So base fold is a multilinear polynomial commitment scheme. The query complexity is lambda times m phi. If you know the phi protocol has query complexity lambda over k times M. So baseball just doesn't have this folding parameter built in. So it's kind of fixed to 1.
00:12:25.535 - 00:12:55.119, Speaker B: Str is polynomial conviction scheme that we introduced last ZK summit. That kind of improves the phry. So you can see the improvement here. So the query complexity is lambda over k times log m instead of times m. So it gains a huge factor there and we're just borrows the same query complexity as still. Okay, so it has like the small query complexity. Now in terms of the running time, base fault is actually linear in the number of queries.
00:12:55.119 - 00:13:17.637, Speaker B: So it's O of Q base fold. Okay, that's good. But it kind of has a lot of queries. PHRY does. This has a running time. Okay, this is the verify running time of O of Q Fry times K times 2 to the K. This makes a lot of sense because PHRY needs to do like this small FFT of size 2 to the K for every query that it reads.
00:13:17.637 - 00:14:00.213, Speaker B: And so this K2 to the K is just the time of an F of size to decay. Ok, Steer has this slightly. Even worse running time has this plus lambda square which sometimes is actually could be quite big. And the running time of our verifier is actually Q where which is the smallest query complexity times 2 to the K plus M. So we even shave out this factor K. Okay, now it's really linear in the number of queries and not quasilinear. Okay, so now benchmark and implementation.
00:14:00.213 - 00:14:33.199, Speaker B: So we did implement this scheme. Okay, kind of academic level implementation. At industry level implementation we implemented using Rust. We used the arcbox as a backend. We took an extension field of the Goldilocks field. I really want to thank REMCO for helping us Remco from WorldCore for helping us with like optimization of the prover and verifier. What the benchmark you're going to see today are like partially parallelized.
00:14:33.199 - 00:15:07.765, Speaker B: So there's a lot of room for improvement for the PUVER running time if you have a lot of CPUs. And we compared it with Fry and steer and base fold as a polynomial commitment scheme. So let me tell you about the results. So let's start. So the Weir verifier typically runs in a few hundred microseconds. Okay. Other verifiers, even those that have a trusted setup, KZG and other usually takes several milliseconds, if not more.
00:15:07.765 - 00:15:36.625, Speaker B: Okay. And we do this without like compromising or without some bad trade off between the running time of the prover and the argument size. Okay. So it's like a true improvement and not a trade off. As an example, okay, As a polynomial commitment scheme for degree two to the 22, you can think of this as like roughly equivalent to 4 million constraints with 100 bits of security. I ran this last week on my laptop. I have a MacBook Air.
00:15:36.625 - 00:16:02.305, Speaker B: The proverb time took roughly one second. The commit and open together were roughly 60 kilobytes. Okay. And the verifier time to verify this opening was 207 microseconds. So roughly 1/5 of a millisecond. Okay. So this extremely fast verification.
00:16:02.305 - 00:16:33.075, Speaker B: Ah, sorry. Here's a slightly more comparison with other schemes. So we have KZG here and, and breakdown and hirex and you can see the numbers. So usually these numbers are either large or a few milliseconds. Where is the only one depending on parameters kind of go be be below the milliseconds. Okay. Once you have such a fast verifier, you can kind of think of new applications that open or improve.
00:16:33.075 - 00:17:08.245, Speaker B: So I just want to really, you know, sketch two things that I think are interesting. So first is on chain verification. And all of these are kind of, you know, this is the back of envelope computations that we did. And to get exact numbers you have to really implement this and see exactly how much you get. But Today we verify Growth 16 proofs on chain over the BN254 curve. And this takes roughly 280k gas. Okay.
00:17:08.245 - 00:17:55.845, Speaker B: Possibly one future is where we use WIR to verify this stuff over smaller fields. And kind of some estimates that we did said if you take a degree two to the 22, you're going to get roughly 50k gas. And even if you go up to degree two to the 62 to the 26th, this should be 80k gas. So this could be a big improvement in the gas cost of verifying proofs. Okay. Second of course is the recursive replication. So if you use where as the first step, you know, in a recursion, in the second step, the prover is going to run and prove the code of the verifier.
00:17:55.845 - 00:18:56.385, Speaker B: And here we did another set of computations. So here we went for 128 bits of security with degree 228. So kind of a large computation then, because the query complexity of where is small and the verifier is fast. Kind of what the Weir verifier is going to do is roughly three 4k hashes, okay? This is to verify the Mercury hashes. And if you kind of assume that this hash is Poseidon or most of it is Poseidon, which is roughly 400 R1Cs constraints, then you're going to get that the recursive circuit that you need to prove is of size 2 to the 20. Okay? So you start with a computation of size 2 to the 28, okay? And then you do, you run one weir iteration, okay? And the next step you have something of size to the 20. And then you can, you know, much smaller computation and everything is much faster and you can run whatever you want.
00:18:56.385 - 00:19:41.371, Speaker B: Okay, comparison. So here's a comparison to basefold. I want to be fair and say first that we are inspired by Fry and Base font and Steer and kind of this work accumulates many ideas and new ones from all these works. And also that to my best of understanding, these numbers form the baseball paper are kind of not optimized in the most significant way and probably can be better. But okay, let's see how we compare. So red is base fold. In blue we have Weir ud, which is the unique decoding radius.
00:19:41.371 - 00:20:21.901, Speaker B: This is kind of without any conjectures. And in green we have this Weir capacity bound. So this is with this list decoding type conjecture that is is not the same, but kind of similar to what happens in Fry and Steer and all these kind of schemes. So we start with the argument size. You can see that the baseball argument size is kind of very big compared to both the Weir unique decoding and capacity bound. So even for quite large computations, the argument size really is less than 100 kilobytes. The proverb time, you see, so we didn't compromise improver time.
00:20:21.901 - 00:20:45.853, Speaker B: So the pullover time is roughly the same as Baze fault here it's slightly better. But I imagine you can also improve the base fault proverb to make it better. And you can also improve the weird proverb to make it better. And so this is kind of a competition. But for the verify runtime, there's kind of, you know, there's not a lot to improve. It's kind of a small piece of code which is usually kind of optimal. And that's just what you get.
00:20:45.853 - 00:21:40.865, Speaker B: And so you can see that both versions of Weir are kind of nearly the one Millisecond, sometimes below, maybe sometimes above, if you don't assume the conjecture while the base fold one is kind of high on the 20 milliseconds. Let's compare. If you are familiar with fine Steer, maybe I'll say this point that weirk is a, you know, drop in replacement to places where you use fire steer or base fold as a polynomial commitment scheme. Okay? So again if I compare that and we can see that, so Steer, what we introduced last decay summit, okay, is in blue now and in red is fry. So the argument size is much better than fry. This is, that was the main point of Steer and Weir, just, you know, gets roughly the same argument size. The pullback time you can see is roughly the same in all schemes.
00:21:40.865 - 00:22:42.165, Speaker B: Mainly the bottleneck of all these schemes is to do some big fft and this is kind of what they do. Anyway. The verifier hash complexity is much smaller in Steer and Weir, but in Weir also the field operations complexity is much smaller. So you can see here, okay, so the green one is Weir, okay? And both Steer and phi have like a much, much, much larger verified time. Okay, how am I in time? I have. Okay, so a little more results. Okay, so because Weir was not just a Reed Solomon proximity test, but actually a constant proximity test, what we can do with it, we can compile not just a polynomial commitment scheme, but actually this sum check polynomial commitment scheme, or as I denoted here, just sigma iop.
00:22:42.165 - 00:24:08.145, Speaker B: So a sigma IOP is going to be like a polynomial commitment scheme where I force the approver to send polynomials, okay? Here I'm going to allow the verifier not just to do evaluation queries to this polynomial, but actually sumcheck queries to this polynomial. So the verifier can specify a polynomial W, this weight polynomial W, and he can get back this answer sigma, which is this sum. So it can kind of do a subject like query to this polynomial that the prover specifies. Once you have this power, then a lot of the effort is reduced from the polynomial IOP itself, okay, because the verifier is much more powerful. And all of this is encapsulated anyway into the Wierlo degree test that we run. And so what we do, we actually give Sigma IOP for generalized R1Cs, which kind of has, you know, much more efficiency than other polynomial iops that you get. And all of this is compiled and batched together to one where invocation at the end for some polynomial and for some constraint, ok? That kind of is a combination of all the constraints that the verifier queried.
00:24:08.145 - 00:24:50.277, Speaker B: OK, so this gives an efficient way to go from ROCs to IOPS. We kind of didn't implement this yet and so I don't have benchmarks for this part. Yeah. Okay, so I think I have just one more minute, so I'll gonna. We have something new called mutually correlated agreement. I have just a quick minute on that. So kind of the main technical tool that we use is this proximity gaps, which roughly says the following.
00:24:50.277 - 00:25:32.635, Speaker B: Oh, I have many evaluations of functions, okay. And I don't want to test each one individually, so I'm going to take a random linear combination of them. So I have C1 up to CL and I have the C star and I have this theorem by Benson et al in this proximity caps paper. And also Dan Carmon that should be here in the conference saying that if the C star is close to Reed Solomon with high probability, then all the CIs were actually also close to Reed Solomon. So you see C star, the green spots, it's where it's close to Reed Solomon. And every CI also has to be close to Reed Solomon. But actually what they proved is something much stronger.
00:25:32.635 - 00:26:15.185, Speaker B: They proved something called correlated agreement. Okay, so they proved that this is not the right picture. Actually all the CIS are going to have a correlated agreement. They're going to agree with Reed Solomon at the same domain. Okay, so the picture is not like this, but actually like this. Okay, so all the cis, not only that they agree with Reed Solomon, but they have some shared domain where on it if they agree with someone. And kind of what we do, we introduce these new proximity gaps where we say that it's not enough that the CIs have shared, call it agreement, but the C star should share the same domain as well.
00:26:15.185 - 00:26:53.817, Speaker B: Okay, so the picture should be like this where C star and all the CIS have. So we call this mutually correlated agreement. So we prove that any time you have correlated agreement, you have mutually correlated agreement up to the unique decoding radius. And we kind of still leave it as an open problem to prove it beyond. Okay, conclusion. We introduce where. Where's an IOPP for constrained read Solomon codes? I think it can have other applications, but the main one is of course using it as a polynomial commitment scheme.
00:26:53.817 - 00:27:31.605, Speaker B: We have verification time within milliseconds, proverb time within seconds and the proof size is really tens of kilobytes. We introduced this new mutually correlated agreement proximity gap. We have this sigma IOP where we combine it with our Weir and then you apply the BCS transformation and and all of these together gives you a hash based snark. This fast verifier can gain new applications such as, you know, efficient on chain verification, recursion and other stuff. Yeah, that's it. Thank you.
00:27:34.825 - 00:27:47.375, Speaker A: Okay, do we have any questions in the audience? Question. This is where I get my cardio in.
00:27:51.235 - 00:28:16.941, Speaker C: So surely I'm just not understanding something. I'm trying to understand why this mutual correlated agreement doesn't follow for free from correlated agreement. Can't you. In other words, assuming that the CIs have correlated agreement on some domain, can you not always just take the underlying code words, combine those in the same way, and then you get the same error domain for the C star. Why does that not come for free?
00:28:17.053 - 00:28:53.685, Speaker B: Yeah, good, good. Excellent question. So you're right. So the CIS have correlated agreement, which means that C star at that same domain, which also be co close to the code word. But what I don't get as a guarantee from the, you know, proximity gaps paper is that C star might have additional domain, which is which it's close to the Reed Solomon code where the CIS do not agree on that domain. Okay, so I want every place that C agrees with the Reed Solomon, the CIS have correlated agreement on that. On that domain.
00:28:53.845 - 00:28:59.373, Speaker C: I see. So that needs to be the only domain that the only way for could.
00:28:59.389 - 00:29:00.157, Speaker B: Be more than one, but then the.
00:29:00.181 - 00:29:01.109, Speaker C: Others have to also be close.
00:29:01.117 - 00:29:06.033, Speaker B: Okay. Yeah. If C has 10 domains where it shows, that's fine. But all the C also have to.
00:29:06.089 - 00:29:07.353, Speaker C: They need it to. Okay, okay.
00:29:07.369 - 00:29:08.681, Speaker B: It's kind of an if and only if.
00:29:08.753 - 00:29:09.233, Speaker C: Got it.
00:29:09.329 - 00:29:11.245, Speaker B: Okay, thanks. That was a great question.
00:29:12.385 - 00:29:22.985, Speaker A: Any other questions? Okay. Round of applause for Ilan.

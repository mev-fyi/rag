00:00:07.530 - 00:00:19.440, Speaker A: So Marcus is going to be telling us about Poseidon two, a faster version of the Poseidon hash function. We actually learned about Poseidon two also at Zkhack, because some folks implemented it. So, yeah, take it away.
00:00:22.290 - 00:00:52.054, Speaker B: So, yeah, let's start. So, first, this is joint work together with Dimitri and Lorenzo from Ethereum and Ponos. And, yeah, welcome. This talk will be about Poseidon two, which is a faster version of the Poseidon hash function. So let me first give you a very short motivation. So, Poseidon, the hash function, some of you may know it has been widely used in practice recently, in the last couple of years. And why is that? Well, it has proven its efficiency in many use cases.
00:00:52.054 - 00:01:45.422, Speaker B: Sorry. It's also implemented in many CK protocols. And, well, the good thing, or a nice thing about Poseidon is that it can be represented by a very low number of constraints in, well, most proof systems, not all of them, but most. And it also has quite good plane performance, of course, not like Sha two, but it's good for what it is. However, when designing Poseidon, when we designed it, like four or five years ago already, I think there were some things we completely ignored. So we just focused on rank one Cs, so rank one constraint systems, but we just completely ignored, for example, the plane performance or other proof systems. And in the last couple of years, we ask ourselves, well, how can we make it faster? Can we even make it faster while still being very close to original design and maybe even just as secure as the original design? And we are going to talk about that in this talk.
00:01:45.422 - 00:02:16.214, Speaker B: But first, let me give you a very short recap how Bosyron actually works. So it's essentially a cryptographic permutation. You can see the design on the right side here. And in the beginning, we have these. We call them full rounds because we apply the s boxes or the nonlinear functions to the whole state. Then we have some partial rounds, and then we again have these full rounds and these monomial functions for the s boxes. And the important thing is that every matrix, so every m, this is a matrix multiplication, is actually an MDS matrix and all these things.
00:02:16.214 - 00:03:06.360, Speaker B: So the permutation then gets used in a classical sponge mode to, for example, build a general purpose hash function, or even encryption, if you want. All right, so these are the observations we made, and these are the most important ones. These MDs majors are actually quite expensive, so they're very good in terms of statistical security. This is related to things like the branch number and so on. But actually, it's, for our purposes, something like too good. So it gives very good security, but higher than can actually be achieved. So our question was, can we find a cheaper matrix which is more efficient to implement and more efficient to compute, but which still provides the same security level? The second observation is then we can also use all of that in a compression mode, which has been done also recently, for example, in jive, like half a year ago.
00:03:06.360 - 00:03:37.986, Speaker B: All right, so first, in a nutshell, what are the changes? Well, you see these highlighted in blue. We essentially exchange the matrices with two different ones. So first we have the me matrix, which is used in the full rounds, and then the mi one, which is used in the partial rounds. And we also add an initial linear layer at the very beginning. I will come to that also in a minute. So why do we do that? Well, in some settings, it can improve the performance by a factor of up to four. Depends, of course, on which state size you have, which prime sizes you have, and so on.
00:03:37.986 - 00:04:22.750, Speaker B: And it's also much more efficient in the very classical block where you still have like a limited number of columns. All right, so how is this done? Well, let me give an introduction into these two matrices. So me essentially, we took some inspiration from lightweight cryptography, from hardware actually, where we try to minimize the number of XOR gates. And this is quite similar to what we want to achieve, because if we don't have many additions, then likely we are faster also in plane. So this me matrix is exactly that one here. So it's a circulant matrix built by two times this m four matrix, and then just repeated the M four matrix. And this now may seem very random, but it's actually taken from this DL 18 paper.
00:04:22.750 - 00:05:05.440, Speaker B: And actually what this does is, or what this enable us to do is we can compute the multiplication by that matrix by using just twelve operations in total. And that includes both additions and also multiplications. So we repeat that for a number of steps for the whole state, and then we do the circulant matrix. And in total we only need five t operations again, and this also includes additions. So both additions and multiplications. So we have some number of operations which is linear in the state size, which is of course better than the naive approach where you have a quadratic number of operations in total. All right, so that's the matrix for the full rounds or for the external rounds, let's call them like that.
00:05:05.440 - 00:05:52.966, Speaker B: And then we have the matrix, the new one for the internal rounds. So we took inspiration from a recent permutation which is called Neptune. This Neptune permutation uses this matrix quite differently and also has a different structure also for the non linear layers. But we essentially found that it can be used also in Poseidon, this matrix. And the nice thing for the partial rounds is that as a designer, as a crypto analyst, we don't need to focus on statistical security anymore, because this is done by something which is called white trail strategy and is only done in the external rounds. So what we can focus on is actually algebraic security. So we are trying to find a matrix which provides dense polynomials in the output and which prevents subspace traits which essentially allow you to skip an arbitrarily number of rounds.
00:05:52.966 - 00:06:46.990, Speaker B: And we found that this matrix, so if you use the right values in the middle, it actually allows you to do so. And it's quite efficient because as you can see, you just need to compute a sum and then just add the sum to each intermediate value and then you have the new state. So this is even more efficient than the matrix before. All right, so we also did some additional changes to Poseidon. So first, since there was this optimized implementation, we will just add the partial or the round constants to the first word in the partial rounds. We now do this directly, so the optimized version is not needed anymore, the more efficient implementation version, and we also add a linear layer to the very beginning of the permutation. And the reason for that is that there have been some attacks in the past which essentially allow you to skip, I think, up to two nonlinear layers without increasing the cost, a lot of the attack.
00:06:46.990 - 00:07:20.780, Speaker B: So we do this as a precautious measure. But let me emphasize that the original poseidon, which does not do that, is not in danger. So it's still safe to use the original poseidon. The change is very minimal in that regard. And finally, also we propose a new compression mode. So this is very old, so to say, instead of using the sponge function, you can just do two to one compression or four to one compression and so on more directly by using such a compression mode. And if you're building a mercury tree, for example, this can help a lot.
00:07:20.780 - 00:07:55.406, Speaker B: And finally, a very nice message for all the developers and implementers. So this efficient transformation of the partial rounds is not needed anymore. Actually, it makes the whole thing a bit slower if you do that. And the good thing is that all the hundreds of constants you need, you store all the matrices for the partial rounds. So that's not needed anymore with the new version of Poseidon. Okay, so in a nutshell, what are the changes? Well, we add this linear layer at the beginning the me one. Then we exchange all the matrices for the full rounds and also for the partial rounds.
00:07:55.406 - 00:08:18.426, Speaker B: So two different matrices in total, and we do the round constants more efficiently. In the partial rounds. However, some things stay the same. And that's the nice thing actually. So you can use the same round number both for Poseidon and for Poseidon two, which means essentially that you can use the rounds number script of Poseidon one. You get some output for the rounds numbers and you can use them also for Poseidon two. So they're the same.
00:08:18.426 - 00:08:53.654, Speaker B: And there are also the nonlinear layers and s boxes and these GCD conditions. This is all the same as the original Poseidon. Okay, so something about performance. We have two tests here, one with a 255 bit prime and one with a 64 bit prime. And we see already for 255 bits that Poseidon is, Poseidon two is consistently faster. And also for the 64 bit prime, we see, for example, that we are always below these five microseconds here. And let me also emphasize here, it depends a lot on which prime field you use.
00:08:53.654 - 00:09:26.066, Speaker B: So for example, if you have a prime field where multiplications can be done very, very quickly because you have an optimized version of the reduction, then of course the performance difference is not the same. So essentially this focus is very generic. And also if you move to a smaller prime, which makes you essentially increase the state size, then the performance difference is even larger compared to the original Poseidon. So even for 32 bit primes, for example, it may be very beneficial to switch to the new version. Yeah. So we can have up to four times improvement here. And the code is also available here.
00:09:26.066 - 00:09:43.410, Speaker B: You see the link below. All right. So before actually concluding the talk, let me also, besides the conclusion, let me give you also some outlook. Well, first the conclusion. Right. So Poseidon two is significantly faster than Poseidon. The biggest change is actually in the linear layers.
00:09:43.410 - 00:10:33.778, Speaker B: And we also working, or we have finished working also on a gate for plonky two, which essentially switches from Poseidon one to Poseidon two. And what we found, or what we've been seeing in the past, and this is now the outlook thing, is that there are many modifications also to the original Poseidon which focus on plane performance. So for example, there's this modification using the circular and MDS matrices, which doesn't change the specification of Poseidon, but makes it a lot faster, I think times two improvements, something like that, for a 16 word size. So it's pretty nice. And what we can learn maybe from that is that plane performance is also important. So not only circuit friendliness, but also plane performance. But with all these modifications, we are still not getting close to the traditional hash functions.
00:10:33.778 - 00:11:08.850, Speaker B: So not two sha three, let alone sha two, which is even faster. So the question is, of course, can we close this gap? Can we find some hash function which is both circuit friendly, but also like very, very fast? And currently we're working on a successor to reinforced concrete, which also works with smaller primes. So this is called RC 64, but we're also aiming for 32 31 bit primes. And we are trying to close this gap. And. Yeah, well, I want to close this presentation also with a question. Maybe can we even reach sha three, like plane performance and maybe in the future, future, maybe even sha two.
00:11:08.850 - 00:11:12.980, Speaker B: Let's see. Thank you very much.
00:11:20.570 - 00:11:24.280, Speaker A: So, I think we do have time for questions. Okay, we have one over here.
00:11:30.350 - 00:12:02.340, Speaker C: Thank you for the presentation. It was very nice. Our team was doing actually three implementations of Poseidon two in ZKX. So we were digging into the paper, and I think we have different questions. My question would be around the four x four matrix, which you use also, for example, eight by eight, you are using a circular extension of that. Did you look into other sizes? The paper that you have used have these kind of filled out, but I haven't seen any generalized results behind those.
00:12:03.510 - 00:12:06.526, Speaker B: So if I answer the question correctly, it was about this M four matrix.
00:12:06.558 - 00:12:14.530, Speaker C: Yeah, the M four, which is, which is kind of. You use it also in multiplies, but you don't have other sizes. And even for eight, you are using this in a circular fashion.
00:12:14.610 - 00:12:15.286, Speaker B: Yeah.
00:12:15.468 - 00:12:19.350, Speaker C: You are not using a generalized results of that to eight.
00:12:19.500 - 00:12:51.646, Speaker B: Okay. If you looked for alternatives there. Yeah. So that's a good question. Yeah, we did look for alternatives. The reason is that, and this is also closely rated to lightweight cryptography, that the larger the state size gets, or the dimension of the matrix, the harder it gets to actually find an efficient one. However, for example, if you are thinking about these circuit MDS matrices for Poseidon, which you can use for the original Poseidon and improves everything, you can actually also use a circuit MDS matrix for this M four matrix.
00:12:51.646 - 00:13:10.230, Speaker B: So a very famous one is the simply AES matrix, which is circuit MDs. So maybe instead of doing that here, you can also do like three or four times two FFTs, and then maybe you're able to even accelerate this version. But that's an excellent question. Thanks.
00:13:10.300 - 00:13:11.080, Speaker C: Thank you.
00:13:12.410 - 00:13:33.900, Speaker A: Are there any other questions? I think we would have time maybe for one more. Let's see you. Well, I guess if not, then thank you so much for this talk you've been.

00:00:05.530 - 00:01:09.330, Speaker A: Welcome to Zero Knowledge. I'm your host, Anna Rose. In this podcast, we will be exploring the latest in zero knowledge research and the decentralized web, as well as new paradigms that promise to change the way we interact and transact online. This week I chat with John Stevens, a computer science PhD student at the Utopia group at UT Austin and the co founder of Veradice, a blockchain auditing firm that is increasingly specializing in zk systems. We talk about what led him to work on smart contract and ZK system security, what tools are available to test the security of ZK systems, and what the process of doing formal verification of zk systems is like. We talk about some of the security vulnerabilities that could be found in a ZK system and then wrap up with a chat about disclosing security vulnerabilities, methods to incentivize disclosures, and some of the challenges that zk brings. Now, before we kick off, I just want to let you know that the application to attend zk summit ten is now open.
00:01:09.330 - 00:01:31.530, Speaker A: This time around we will be hosting our event in London and this is happening on September 20. As always, we aim to bring together the top researchers and engineers working in ZK to share their latest research and new findings. Check out the show notes for the application form. Please note spots are limited and only folks who have applied will be considered to attend. Hope to see you there. Now Tanya will share a little bit about this week's sponsors.
00:01:32.270 - 00:02:27.834, Speaker B: Polygon Labs is thrilled to announce Polygon 20 the value layer for the Internet. Polygon 20 makes mass adoption possible by offering users and developers unlimited scalability and unified liquidity. This mission is fueled by groundbreaking ZK innovations, including a first of its kind, zk powered interoperability protocol and the next generation of the industryleading and widely adopted plonky two proving system. Polycon 20 will change the way we experience web3 by bringing the security and decentralization of Ethereum to the scale and usability of the Internet itself. Polygon 20 and all of their ZK tech is open source and community driven. Reach out to the Polygon community on Discord at Discord GG Zero x Polygon to learn more, contribute, or to join in on building the future of web3. Together with Polygon Anoma's first fractal instance, Namada is launching soon.
00:02:27.834 - 00:03:16.010, Speaker B: Namada is a proof of stake L1 for interchain asset agnostic privacy. Namada natively interoperates with fast finality chains via IBC and with Ethereum via a trustless two way bridge for privacy, Namada deploys an upgraded version of the multi asset shielded pool circuit, otherwise known as MAsp, which allows all assets, fungible and non fungible, to share a common shielded set. This removes the size limits of the anonymity set and provides the best privacy guarantees possible for every user in the multi chain. The MAsp circuit's latest update enables shielded set rewards directly in the shielded set, a novel feature that funds privacy as a public good. Follow Namada on Twitter at Namada to learn more and join their community on Slash Namada. So thanks again, anoma. And now here's our episode.
00:03:18.430 - 00:03:33.550, Speaker A: Today. I'm here with John Stevens, a computer science PhD student in the Utopia group at UT Austin and a co founder of Veradice, a blockchain auditing firm that is increasingly specializing in zk systems. So welcome to the show, John.
00:03:33.700 - 00:03:35.038, Speaker C: Hi, good to be here.
00:03:35.124 - 00:04:06.186, Speaker A: I feel like this interview and basically this topic that we're going to be covering, which is like audits and zk security, zk circuit security, it's coming at a really important moment in our industry right now. We're seeing so many ZK systems move from the theory or proof of concept or testnet state into the wild, and the issue of zk security has been raised. But I don't know that we as an ecosystem yet have a rule system or like a sense for how to address this. So I'm very excited to explore this with.
00:04:06.288 - 00:04:12.022, Speaker C: Yeah, yeah, I think this is a really interesting topic and I'm excited know chat more about it.
00:04:12.096 - 00:04:25.106, Speaker A: Cool. Let's first understand a little bit of your background. As I mentioned in the intro, you're a student at UT Austin. Tell me, what were you studying before this and actually what is your PhD focused on?
00:04:25.208 - 00:05:52.878, Speaker C: Yeah, so my PhD focuses on an area of computer science called formal methods. So this is kind of a sub area of programming languages that focuses on how do you reason formally about other software. And so this includes designing tools that are capable of looking at other software through techniques like formal verification or static analysis. So basically the way that this got started is during my PhD, one of the tools that I developed was a tool called Smartpulse and that would verify formally these types of properties, called temporal properties within smart contracts. So basically that is where we started is we started by looking at this particular smart contracts, or particularly solidity contracts, because we were noticing that there were a lot of attacks in this area and that auditing at least is a very manual process. And coming from formal methods, it seemed like in order to increase the quality of this particular ecosystem and hopefully prevent some of these attacks, more tooling should and could be used. And so we basically took this work, as well as some other work that was done by some of my other co founders and kind of wrapped that up into this company.
00:05:53.044 - 00:06:26.886, Speaker A: Interesting. I did an episode many years ago with Martin Lunfell from Maker. At the time, he was part of the Makerdao engineering team. I think. I think he's moved on to other things now, but he had been doing sort of this formal verification, or like, was exploring formal verification of solidity contracts. Do you feel like, did something happen in the solidity landscape that made it so this all of a sudden was more viable, or could it always have been done? Do you know about this work at all? Like, had you seen previous work on formal verification of solidity code?
00:06:26.988 - 00:07:05.390, Speaker C: Yeah. So at least when it comes to formally verifying solidity code, there had been quite a bit of work, even when I published, about performing formal verification in that space. However, part of the issue is a lot of these tools, including mine, is a research prototype. And so that means that it's not really production ready. So, for example, one of the annoying parts of my tool, at the very least, is due to dependencies. It was stuck at solidity five and stuff like that. And so there were a lot of other tools that had been created that were just in a research prototype phase and weren't ready for anything, production ready.
00:07:05.390 - 00:08:02.486, Speaker C: And so a couple of other companies, like Certora, for example, took a verifier that they worked on as a research prototype and actually expanded it so that it could actually be used for verifying real solidity smart contracts. And so there wasn't really anything that changed that would have allowed this. It's just there needed to be more work put in because solidity has some really annoying design decisions, like dynamic call resolution and stuff like that, which makes formal verification very difficult but not impossible. And so for that reason, really, there wasn't anything that changed. It's just people started putting in more effort as they were able to tell that, oh, people in this ecosystem do actually want to use tools like this, and without having to actually perform the formal verification themselves.
00:08:02.668 - 00:08:09.302, Speaker A: That's cool. I think it's worthwhile to redefine formal verification and how that actually works.
00:08:09.436 - 00:08:09.878, Speaker C: Right?
00:08:09.964 - 00:08:20.662, Speaker A: Because I sort of want to understand you built this tool, but what would this tool actually look like? Or how would one use it with code? So let's first start, though. What is formal verification?
00:08:20.806 - 00:09:19.166, Speaker C: Okay, so just to give a little bit of an overview about formal verification basically what formal verification does is it reasons very precisely about your program in order to validate that any particular input is going to satisfy some logical specification. And so this logical specification can take in a number of different forms. So for example, it's typically an equation over program variables. So you might want to validate, for example, that if any particular input is given to this contract, then after you transition to this state, you can never transition away from that state. So for example, let's say that an auction has been completed, an auction or a solidity auction, I guess. And so normally there they have some sort of gating where they say the auction is going to become complete. And once that happens, you don't want to open the biding again most of the time.
00:09:19.166 - 00:09:31.842, Speaker C: And so for that reason, you might want to verify formally that yes, there is no combination of calls to your contract that could allow people to bid again.
00:09:31.976 - 00:10:00.380, Speaker A: In that episode that I did many years ago, we talked about like formal verification, the trick was you have to specify the exact behavior you're checking it for. It's not going to necessarily notice bugs that are outside of that behavior. Like if that auction software had some when it starts, or some other part that you weren't formally verifying, the formal verification would not catch that it will only capture that specific behavior, right?
00:10:00.850 - 00:11:05.026, Speaker C: Yes, that is true. However, one thing that I'll note is when you're formally verifying, you're doing it with respect to a specification. And so if something is completely separate from your specification, then it won't be caught by formal verification. But one interesting thing that we found during this paper that I published is you can actually end up finding really interesting attacks that don't seem to be related to your specification, but are. So, for example, some of the attacks that we ended up being able to find in this paper that I published was, without actually specifying, I want to look for something like an integer overflow or a reentrancy attack. The verifier would be able to synthesize counterexamples that corresponded to these without having to be told you need to do X. And so while it won't find something that's unrelated to your actual specification, it can still find some pretty powerful attacks and pretty powerful zero days without having to be told to look for it.
00:11:05.026 - 00:11:47.498, Speaker C: So it's really interesting and a little bit different than how people typically go about this. The interesting part of it is it's not just going to look for a particular type of vulnerability. And I don't know, I guess one of the interesting things that we found during the evaluation of this paper is you might have something that says, like, a user can always withdraw their funds or something like that. And then basically what the formal verifier will do is it will try to figure out a way to steal funds using any method that it can from that contract. And so it ends up creating some really interesting and od counterexamples that you might not have thought about otherwise.
00:11:47.674 - 00:12:01.026, Speaker A: Interesting, though. So this is sort of surprising that it sort of can find things past what it's been speced for. I guess I'd always gotten this impression that it was a very precise testing tool, but a very limited one.
00:12:01.128 - 00:13:29.946, Speaker C: It depends on how you perform formal verification and exactly how much you kind of constrain the problem. And so, for example, if you're testing by, or if you're only trying to verify pre and post conditions or something like that, where a precondition states the assumptions about the contract before execution, and then the post condition is going to state what should hold after you actually execute that function, it's not going to be able to find some of these attacks that I was talking about before, because it doesn't necessarily, or depending on the architecture of the verifier, it won't necessarily try to manipulate the state of the contract in order to find ways that are within the precondition that can still violate the post condition. So the verifier that I created was actually very flexible in that it used a specification class called temporal specifications, which basically state properties over time. And because we were using this very, I guess, flexible but particular specification language, it was able to find attacks that required a series of transactions or that even would require fallback functions to be synthesized. And so it was really interesting. And so it depends largely on the verifier that you're using, because people say formal verification a lot. But even within formal verifiers, there are different ways that you can, well, build them and different specifications that can be provided.
00:13:30.058 - 00:13:34.878, Speaker A: You mentioned a paper. What date did you publish that? Like, what era are we talking?
00:13:34.964 - 00:13:45.578, Speaker C: I think it was either in 2020 or 2021. So I think that the paper was actually published in 2021, but was accepted in 2020, if I remember correctly.
00:13:45.694 - 00:13:51.320, Speaker A: And is that paper, was that the thing that kicked off paradise, or did that come?
00:13:51.690 - 00:14:45.734, Speaker C: So, yeah, it was part of what kicked off Faraday. So Faradayce started in, well, I guess a little over a year ago now. So basically what happened was I had published this paper, and at the same time, Ishel, my advisor was visiting Yufeng, who was her former PhD student, who's now a professor at UCSB. And he also had, in parallel, been developing some other techniques in order to find bugs in smart contracts. And he had been approached by some VCs about the possibility of making that into a security company. And so those two got pretty excited about it and asked me if I wanted to join. And so, yeah, that's kind of how veradice got started.
00:14:45.852 - 00:15:00.182, Speaker A: I see. This actually makes me want to ask sort of, we were talking about one tool in the auditor's toolkit. Right. The formal verification tool. But what are the other tools that are out there and that you would be using maybe in tandem?
00:15:00.326 - 00:15:22.446, Speaker C: There's a lot of tools that are available for auditors. Formal verifiers aren't used very frequently because they require a little bit of expertise, because you have to know about the formal verifier in order to kind of provide extra invariance and reason about why the formal verification might not have gone through. And so some people find that very frustrating.
00:15:22.558 - 00:15:22.882, Speaker A: Okay.
00:15:22.936 - 00:16:07.860, Speaker C: And so the most commonly what's used by, I would say, auditors now in this particular domain are fuzzers and static analyzers. And so what a fuzzer is going to do is it is going to randomly generate inputs to whatever your program is. If it's a smart contract, it will randomly generate transactions and inputs to those transactions and then feed them to your program. And so what has been found is in a lot of different areas, like operating systems, they were able to find that fuzzers can find very interesting and deep logical violations or violations within your program because they generate weird inputs that people don't commonly think about.
00:16:08.310 - 00:16:10.254, Speaker A: But that could happen in the wild.
00:16:10.382 - 00:16:53.634, Speaker C: But that could happen in the wild. And that's the point is, typically the things that get exploited are not what programmers are thinking about or developers are thinking about. It's these other side effects. And so fuzzers are a very powerful tool. But the problem with a fuzzer is they don't come with any sort of guarantee. Everything is generated purely randomly, and they kind of have this probabilistic guarantee that eventually, if you run them forever, they might converge on a particular solution. And so if you compare a fuzzer to a formal verifier, a formal verifier is like you took a fuzzer and you ran it on every possible input to the program and validated that the output was correct.
00:16:53.634 - 00:17:15.874, Speaker C: And so technically that's not possible. But a fuzzer, on the other hand, is just going to provide random inputs. And so they can be very useful, particularly when you're performing something like property based testing, where you want to provide random inputs and check a particular property after each particular test was run by the fuzzer.
00:17:15.922 - 00:17:20.794, Speaker A: And is static analyzers in a similar category to fuzzers, or is it its own thing?
00:17:20.912 - 00:18:02.600, Speaker C: Yeah, static analyzers are its own thing. So what a static analyzer is going to do is it's going to reason statically about a particular program. And so there's a couple of ways that you can do this. You can look for particular patterns within the program. So for example, if we're talking in the ZK domain, one thing that a static analyzer might do, or a very light static analyzer might do, is it might look for instances in circom where people are using the single arrow assignment in order to assign to a signal. Right? So that is a very light static analyzer that just takes as input the source code. It doesn't run anything, and it reasons kind of abstractly about the program itself.
00:18:02.600 - 00:18:17.100, Speaker C: And so the nice thing about static analyzers is similar to formal verifiers. They can come with guarantees, because if they aren't able to find a particular pattern or whatever they're supposed to, it's guaranteed not to be in that program.
00:18:18.030 - 00:18:25.322, Speaker A: That example you just gave, would that have been a bug that it's looking for or like something that causes bugs?
00:18:25.466 - 00:19:05.210, Speaker C: Basically, static analyzers are going to be looking for specific types of bugs. And so this would be. Yeah, this is a bug that they already know of. And so static analyzers, unlike with what I was talking about, with the flexibility that you can get from formal verifiers, they are targeted at looking for a single thing normally. And so there are, again, different types of static analyzers that can go all the way from, I'm just going to look for this single syntactic pattern by just looking at the program itself all the way down to, I'm going to reason in an abstract way about the program itself and maybe prove something about the program itself over these abstract semantics.
00:19:05.870 - 00:19:29.410, Speaker A: I want to now go back to what does a formal verifier look like? Or what is it as a piece of software? So the way you've sort of described this, like you have a piece of code, you have a program or a circuit or something you've written, and then you kind of like, do you feed it into it, or do you set the formal verification upon it? I'm just curious how these things interact.
00:19:29.750 - 00:20:14.926, Speaker C: No, you set the formal verifier upon it. You've got the source code. And what the formal verifier is going to do is it's going to reason very precisely about the semantics of the programming language in order to prove something about the software. And so there's a couple of ways that you can do this, but essentially what a formal verifier is going to do is it's going to take as input your actual source code as well as a specification. And so this is just the logical formula over the program that I was talking about previously that's going to go into this. Let's just call it a black box for now, which is the formal verifier. And what it's going to spit out at the very end is it's going to say, yes, this was verified or no, it wasn't.
00:20:14.926 - 00:20:29.938, Speaker C: And in the more frustrating cases it might say, I'm not sure. Then you have to go and try to provide it with better, more proper invariance in order to get that formal verifier to actually verify.
00:20:30.034 - 00:20:49.606, Speaker A: And you want it to come back with, yes, it's been verified? Yes, this does what you're supposed to do. I'm curious about the code and the program that you're actually putting into it. Does it always have to have a certain structure? Like when you create that black box, are you only making it for certain kinds of contracts or certain kinds of programs?
00:20:49.718 - 00:21:08.962, Speaker C: Yeah. So typically it's parameterized on the actual language that the contract is in. So for example, typically there are ways around this, but typically you write a formal verifier that knows about the semantics of a specific language, and then after that you can feed in any particular program within that language you want.
00:21:09.016 - 00:21:09.330, Speaker A: Okay.
00:21:09.400 - 00:21:28.870, Speaker C: However, one thing that people typically do to get around this is you could have a language that the formal verifier knows how to reason about and then translate from other languages to that one. And as long as that translation process is sound, then you will be able to formally verify on whatever can translate down to it.
00:21:28.940 - 00:21:36.410, Speaker A: Okay. I feel like this is a total place for bugs or some problem. Like at the compile, are you compiling or are you translating?
00:21:36.910 - 00:22:16.486, Speaker C: Compiling and translating kind of end up being a similar thing because a compiler is just going to compile down to like a bytecode. Right. And so here, let's just call it translating, because typically you're going from a high level representation to another fairly high level representation. And so it's kind of a translation problem. But for example, the move prover is built on top of this verifier that operates on boogie. And so it's fairly common for people to rather than implement their own verifier because that is a lot of work and it can be quite hard. They will instead translate down to a verifier that they know well.
00:22:16.486 - 00:22:21.930, Speaker C: And that is fairly mature because there can also be bugs in the verifier.
00:22:22.510 - 00:22:34.414, Speaker A: I want to just check. So when you say move, you mean like the language move, the one that was developed by the group or meta and you just call it a boogie verifier. Is that the name of this?
00:22:34.532 - 00:22:47.250, Speaker C: Yeah, boogie is the language that you translate down to. And Microsoft has created a verifier that will verify properties over these boogie programs.
00:22:47.830 - 00:22:59.158, Speaker A: That's interesting though, and actually maybe for our audience too, when we're talking about proverify her, we're not talking about in the zk context at all. This is the prover of the code and the verifier of the program.
00:22:59.324 - 00:23:27.710, Speaker C: Yeah, this is the struggle of my life is verifier is too overloaded. In the zk context, you've got approver and a verifier verification, you've got a verifier. And then also when it comes to, and this is what we've encountered in Defi in particular, people call the process of validating that source code and bytecode matches, they call that verification. No matter what, we always have to clarify because it just gets too confusing.
00:23:28.370 - 00:23:59.962, Speaker A: I think we've done a pretty nice mapping of formal verification. Formal verifiers and some of the other tools, fuzzers and static analyzers, this is the auditing toolkit. But all of this so far, we're still kind of thinking about it in this solidity context or like smart contracts or even, I don't know, maybe it goes past that. But what I do want to understand is where for you did the move to ZK happen? And obviously down the line I want to understand if it changes anything, but yeah, maybe. Let's start with the story.
00:24:00.096 - 00:24:56.214, Speaker C: Yeah, so the move to ZK happened when we were doing stuff at veradice. So basically at the time we talked with the developers of Circumlib and they wanted to perform some formal verification over circumlib. And so that's where veradice got involved and some of our employees went and they actually now have developed a separate formal verifier specifically for ZK. But I'll skip past that for now. Basically they performed some formal verification over circumlib in order to validate that certain properties held. And so they performed some formal verification over, if I remember correctly, it was specifically the big int library within Circumlib, and ended up being able to identify a couple of bugs there, but more importantly, verified other properties held.
00:24:56.342 - 00:24:58.058, Speaker A: Can you say the name of that library again?
00:24:58.144 - 00:25:00.390, Speaker C: Yeah, so the big integer library.
00:25:00.470 - 00:25:30.102, Speaker A: Okay. The first time I heard about paradise was, I think we mentioned it really briefly on an episode with UMA from Succinct. And yeah, we were talking a bit about the security of these systems, bridges and all of these things. And they had mentioned that you were doing that. So you were first brought in to do this on Circom. And this is where maybe you can help tease this, you, when you're doing this, still focused on the language. So you're talking about Circom, but I mean, there's a lot of languages in the ZK space.
00:25:30.102 - 00:25:44.666, Speaker A: There's also different levels of a stack. So I'm wondering, when you deal with Circom, would you deal with the formal verification of the entire, all levels of circom and libraries it draws upon, or would you just focus on that?
00:25:44.848 - 00:27:08.830, Speaker C: Yeah. So for something like a formal verifier, typically you have to assume there's trust somewhere. And so when it comes to formally verifying something over Circom, basically you trust that the semantics of the language is implemented correctly. And so in this case for ZK, that means that you're trusting that the verifier works properly as well, and that it's actually performing that verification in a way that's consistent with the semantics of the programming language, because otherwise, without that trust, it causes the already fairly intensive job that is formal verification to become even more intensive. And so typically, whereas previously, when I was talking about performing formal verification over solidity, it's a little bit, I would say easier in a way, because you don't have to worry about what is constraints and what is going to go into your witness generator. Whereas when it comes to performing formal verification over something like CK, you need to make sure that you're only performing formal verification over your constraints because those are ultimately what's going to be checked. And so there's a slight difference between how the formal verification is being performed in this ZK space.
00:27:09.000 - 00:27:32.382, Speaker A: That's interesting. I want to understand. So you do the formal verification over circum. I'm trying to use your lingo here. Over circom, the language. Let's kind of figure what this actually looks like. So you've written a program in circum using circum and now you're going to set the formal verification upon it.
00:27:32.382 - 00:27:43.390, Speaker A: So you're not really checking the language so much. The formal verifier knows the language and now is looking for what's it actually doing with the constraints. What's it looking for?
00:27:43.460 - 00:28:54.274, Speaker C: Yeah, so basically the way that this is going to work is, like you said, you've got a program that was written by some developer, and so the formal verifier at the end of the day has to know the semantics of the language. So it is going to reason very concretely about the program itself. And what it's going to check is it's going to check to see whether anything that would violate the specification is potentially possible. And so this violation is not specific to being under constrained or over constrained. Instead, what you have to do at that point is you have to write these properties that you want to check, like whether a circuit is under constrained using a logical formula. And so, for example, when it comes to expressing whether something is under constrained, basically what you say is for every input there exists two outputs such that the circuit will take in the inputs that you provided it, and what you'll get out at the end is an output. And then you have to check and make sure that it is only possible for those two outputs that you defined to be the same, because if they're different, then you have found an under constrained circuit.
00:28:54.274 - 00:29:04.620, Speaker C: And so that is essentially how the formal verifier goes about checking to see whether there is an under constrained circuit, but it's not necessarily configured to look for this one problem.
00:29:06.590 - 00:29:22.810, Speaker A: I really like you describing this, because the under constrained problem has never really been clear. I don't know what the outcome was. So you just said it, but I missed it a little bit. So if something is under constrained, you're putting in an input, you're getting, do you say two outputs?
00:29:22.890 - 00:30:03.882, Speaker C: Yeah. So basically at a high level, what you're doing when you're checking for an under constrained circuit is if you can provide it with a single input. However, there can be multiple assignments to the output, and so greater than or equal to two, then your circuit is under constrained. And so the reason why this would happen is because there might be multiple ways to satisfy your constraints, because really what you're doing at a high level when you're working with these ZK circuits is you're providing it an input and you're saying, I know an assignment to these outputs, right? And so if you can provide it two conflicting assignments to those outputs for these particular inputs, then all of a sudden you now have an under constrained circuit.
00:30:03.946 - 00:30:06.350, Speaker A: Is this similar to a collision?
00:30:06.770 - 00:30:07.326, Speaker C: Yeah.
00:30:07.428 - 00:30:16.694, Speaker A: Okay. You're expecting one input equals some output, and here you actually have multiple inputs that will equal the same output because the system is under constrained.
00:30:16.762 - 00:31:12.130, Speaker C: Right. So you can say that it is kind of similar to a collision when it comes to a hashing function. With a hashing function, it can't be avoided because counting. But at least when it comes to specifying a proper hashing function, you have to make sure that it is fairly, well, collision resistant, because with a hash function, if you have something that commonly hashes to a single value, then at least in the space that we're in, that would break a whole lot of software. And so here, basically what you're doing is kind of the same, where you need to make sure that for every input there's a single possible output. There are reasons why people wouldn't want to do that, I guess. But most of the time that we've seen these circuits from people, making sure that circuit is properly constrained or deterministic is another way to consider.
00:31:12.130 - 00:31:15.640, Speaker C: It is an important property that should hold.
00:31:16.810 - 00:31:19.190, Speaker A: Is there such thing as over constrained?
00:31:19.610 - 00:32:15.110, Speaker C: Yes. So that is a good question. That is something that we kind of debate internally at veradice every once in a while, because we used to kind of provide or define an overconstrained circuit as well, where basically an over constrained circuit would be one where your witness could generate valid outputs that would not be accepted by your circuit. And so you can claim that that is an over constrained circuit. However, in a lot of systems, when you add a constraint into, or when you add a constraint, a similar assertion will be added in your witness generator. And so you can kind of say at that point that in some of these languages, you can't possibly create over constrained circuits because your witness generator would crash. However, I at least am on the side that you can create over constrained circuits, because sometimes something else is generating your witness.
00:32:17.130 - 00:32:46.050, Speaker A: When it comes to sort of the under or over or perfect constrained systems, is there a trade off with performance? Is there a reason? Are you kind of looking for the cusp where it works? But if you go too far, you are actually also potentially, I don't know, maybe making the system too slow or too energy inefficient. And so often people are trying to find that razor edge where it's acceptable and not under, but also not too full.
00:32:46.200 - 00:33:33.406, Speaker C: Yeah, that's a very good question. And so the reason why these under constraint circuits actually occur pretty frequently is because exactly what you said people are trying to save constraints. The reason why they do that is because proving time often becomes kind of a bottleneck, and so they want to have as few constraints as possible so that proving time will become quick, and that is where you end up running into problems, because they'll remove constraints that they might not think are necessary, because it's very easy to make that mistake. And when they prune that mistake or that particular constraint, they are now going to have an under constrained circuit, and then that's a security risk.
00:33:33.598 - 00:33:34.434, Speaker A: I see.
00:33:34.552 - 00:33:34.978, Speaker C: Yeah.
00:33:35.064 - 00:33:50.200, Speaker A: Are there different levels of security risk? Do you ever have the result of, like, it's somewhat under constrained? It's very under constrained. Yeah. Are there different levels, or is it sort of binary? It's either correct or incorrect, so, no.
00:33:50.570 - 00:34:50.620, Speaker C: There'S definitely a range that you can have. Right. And so one of the most dangerous things is if you have a completely under constrained signal, because that completely under constrained signal can now take on any particular value. However, we have seen other mistakes that people have made where a signal is partially constrained. And so basically, you've narrowed down the possibilities that the circuit could take. And in terms of whether or not or the severity of the bug, that often largely depends on the application itself, because, for example, you might have an under constrained signal, but in order to, let's say, find another value that would be accepted by the circuit, you would basically have to break some cryptographic protocol that is being implemented by the circuit itself. So, for example, let's say that you have a hashing function, and the.
00:34:50.620 - 00:35:19.746, Speaker C: I'm kind of making this up on the fly here, so I hope it makes sense. So you might have a completely under constrained value, but as long as it hashes to the correct value at the very end, then everything is okay. And so in that case, even though maybe the input is completely under constrained because it is being fed into this hash function, and that's going to be checked somewhere else. Technically, that's only exploitable if you're able.
00:35:19.768 - 00:35:24.898, Speaker A: To break that hash function as well, I guess, because you'd have to be breaking both.
00:35:24.984 - 00:35:25.378, Speaker C: Yeah.
00:35:25.464 - 00:35:35.560, Speaker A: So is there almost like mitigate, are there techniques that people, that maybe, I don't know if you've seen this, where people will do a really under constrained system and then have some mitigation on the side.
00:35:36.330 - 00:36:26.694, Speaker C: So really the only thing that we've seen them do is right now, there are people who are trying to combine zk circuits with dapps. Right. And so one thing that will do is they might have some mitigation, but that might not actually exist in the circuit itself, and that's because they will have public inputs and the outputs to the circuit are always public. And so when the circuit is actually checked into the blockchain, there'll be some additional validation logic to make sure things are well formed. So, for example, you can consider the case where there's a miracle tree. In order to validate that something exists in a miracle tree, you're ultimately going to end up calculating a root. But there's no way for the ZK circuit to know what the proper route is unless you've hard coded it.
00:36:26.694 - 00:36:47.402, Speaker C: And so one thing that people will commonly do is any route will be accepted, but then at least on the blockchain side of things, they'll validate that. Yes, this is the route that is stored on the blockchain, and it will be rejected otherwise. So you might be able to validate the circuit, but it will be rejected by other validation logic.
00:36:47.546 - 00:37:02.546, Speaker A: In this case, are they checking actually at the input itself? Like is it at that step, or is it the output? Is it like you wouldn't be able to feed in any input that isn't already a block header or something? Like they're checking something else, or they're checking it at that beginning part.
00:37:02.648 - 00:37:39.422, Speaker C: Yeah. What I was describing here would be at the output. So basically, someone has generated a proof. When you generate a proof, you have to provide the public signals, and so they'll perform some additional validation over those public signals. And so in the case that I described specifically, the additional validation would be performed after the proof has been generated. And so in that case, if someone decided to, let's say, try to perform an attack, they would have to go through the entire process of, let's say, wasting their computation only for it to be rejected by the smart contract itself.
00:37:39.556 - 00:37:48.674, Speaker A: Could you, though, do it also at the beginning, could you make sure that there's only a certain set of inputs? It would be kind of impossible to just randomly pick one out of the air.
00:37:48.792 - 00:38:43.970, Speaker C: Yeah. So in that case, really, if you're going to do it on the input phase, or at least I believe that you would have to have constraints inside of your ZK circuit itself in order to check things. And so the only time that I've seen someone perform something on the input phase, it's because they had, say, a trusted service that they would use, and that trusted service would generate a certificate that would then be checked by the circuit itself. And so the problem that you have with doing things on the input phase, at least, is you have users who can interact kind of arbitrarily with the witness generator and stuff like that. So there's no guarantee necessarily that they've been doing things properly. And so really, if you want to do something on the input side, you would have to have some sort of trusted service.
00:38:44.120 - 00:38:53.350, Speaker A: I see. So far, we've talked about using formal verification to check for under constraintness, but is there anything else that you're checking for?
00:38:53.500 - 00:39:24.990, Speaker C: Yeah, so basically the other thing that you would want to check for is behavioral violations. So, for example, the reason why formal verification is so powerful is because you can check arbitrary properties under constrainedness is only one of those particular properties. And so typically under constrainedness is one of the, I guess, interesting properties that we end up getting in this aspect. So it gets a lot of discussion. However, people can also just implement things incorrectly.
00:39:26.450 - 00:39:30.402, Speaker A: This is like checking for bugs in a way. This is just like a mistake, right?
00:39:30.456 - 00:40:25.398, Speaker C: And so logical mistakes are one thing that we commonly find during our audits where someone intended to write a logic or write a program that did X. However, it does something slightly different than X. And so the other thing that you would do with a formal verifier is you might want to check that someone's logic is actually implementing the computation that they expect. And so in that case, you would encode the computation that someone wanted to perform as an actual logical formula and validate that. Yes, this logical formula actually holds over the constraints of the CK circuit. And so this is something that we do commonly for our clients. And while it probably sounds like you have to write something twice, that can be pretty powerful, expressing the same thing in two different forms, because especially if you find discrepancies between those forms, then you find bugs, and that's what the formal verifier does.
00:40:25.484 - 00:40:30.738, Speaker A: In the case of ZK circuits, though, are you also running fuzzers and static analyzers?
00:40:30.914 - 00:41:32.970, Speaker C: Yes. So at Veradice, we have developed some custom formal verifiers which help us more efficiently be able to perform the formal verification. Because at least right now, and we didn't really get into this, there are ways that you can perform formal verification automatically, but zk kind of has some properties that make that difficult. And so at this point, formal verification is typically a manual process where you have to manually write out the proof. And so we have some techniques that we use in order to automatically prove things most of the time, which is another paper that we have published. At the same time, we have developed tools that use fuzzing in order to help identify problems in ZK circuits by let's say randomly mutating outputs, for example, in order to try to find this under constrained violation. That's something that we've been working on recently, because if it can find a counterexample, that's great.
00:41:32.970 - 00:41:49.790, Speaker C: And then finally, at veradice, we've also developed static analyzers in order to find bugs within these zk circuits. And recently we're in the process of publishing a paper about the static analyzer that we developed, which ended up being able to identify bugs in real circuits.
00:41:50.850 - 00:41:52.158, Speaker A: That people are using.
00:41:52.324 - 00:41:54.080, Speaker C: That people are using? Yes.
00:41:55.490 - 00:41:58.626, Speaker A: Is there an order in which you're usually running these things?
00:41:58.728 - 00:41:59.380, Speaker C: Yeah.
00:41:59.830 - 00:42:02.174, Speaker A: Okay, so what is that? Definitely for ZK?
00:42:02.302 - 00:42:53.090, Speaker C: So for ZK, typically the first thing that we do is we would run a static analyzer, because a static analyzer, at least in terms of the picture that we had, it's just going to take in your source code, and then it's going to tell you, yes, this is vulnerable, or no, this is a list of problems. And so static analyzers are also very fast. And so typically we first use a static analyzer, then we'll use something like a fuzzer, because again, a fuzzer is very automated. And at least the fuzzers that we use, we try to configure so that they can also do some property checking while they're looking for other bugs. And so they can oftentimes also perform or find counterexamples that would also be found by a verifier. But they don't come with strong guarantees. And then the last thing that we normally do is formal verification, because with formal verification, it requires more manual effort.
00:42:53.910 - 00:43:16.566, Speaker A: So I kind of can picture this. Where you've built tools which are like, they're kind of out of the box, you might need to run them because you know how they work the best. But actually, another auditor could also run them. But when you get into the formal verification side of things, would it need to be the person who wrote it, who does the check, because they need to so deeply understand this circuit?
00:43:16.678 - 00:44:05.670, Speaker C: Not necessarily, no. So basically, when it comes to the formal verification, typically that just needs to be done by someone who has expertise with a particular verifier. So, for example, at least in the context of ZK, a lot of the actual verification is being performed with what is called an interactive theorem prover. So this is something like cock or lean, if you've heard about them. And so essentially, the way the formal verification is done there is you translate the constraints down into this form that can be understood by cock or lien, and then you manually write a proof that says that your specification, which you also encode in the interactive theoremproover, matches.
00:44:05.750 - 00:44:24.320, Speaker A: The constraints when it comes to an audit. So as you're going through this, you start with the static analyzer. If you find something, do you immediately bring that back to the team you're auditing or like the company or whatever, and then see if they can fix from there? Or do you actually go through the whole process and then give them a report?
00:44:24.850 - 00:44:43.686, Speaker C: Yeah, so we try to do as much as we can in parallel. And so typically for something like a fuzzer, it's faster to set up, but it can take days to run. And so when we do these things, we kind of have this process of how the order in which we'll start things. And at least for a static analyzer, we normally get feedback very quickly.
00:44:43.788 - 00:44:44.102, Speaker A: Okay.
00:44:44.156 - 00:45:10.154, Speaker C: And we do provide that feedback as soon as possible, because at least for something like formal verification, if there is a bug that was found by one of the previous components, then normally the formal verifier is going to find it as well. And so really for formal verification, you want to verify on the fixed version that everything is proper. Otherwise you're just going to be rediscovering all of those same bugs with more manual effort.
00:45:10.282 - 00:45:21.314, Speaker A: Is it also good that people do the correction because it's possible they make a mistake in that, that the formal verification might just find out? Or would you just run the static analyzer again on the new version anyway?
00:45:21.432 - 00:46:03.922, Speaker C: Yeah. When we perform our audits, what we're going to do is we're first going to perform the audit on one fixed version of the code. Because when you keep getting new code, that makes the auditing process very chaotic and very difficult. And so typically what we'll do is we'll perform as much work as we can on the version that we're auditing. And then when we get to validating fixes, then we'll make sure that we run the same tools that we ran or that found bugs on the unfixed version of the code, the version that we were given to audit on the fixed version to identify any potential new issues, because we have found bugs in the code that people have provided us.
00:46:04.056 - 00:46:08.258, Speaker A: That is supposedly fixed, but like different bugs almost.
00:46:08.344 - 00:46:09.074, Speaker C: Yeah.
00:46:09.272 - 00:46:11.790, Speaker A: The fixed chain made a new bug appear.
00:46:11.870 - 00:46:21.878, Speaker C: Yeah. So sometimes things weren't fixed quite properly. Other times they introduced new bugs that we then would point out, how long.
00:46:21.964 - 00:46:31.034, Speaker A: Does something like this take? Each of these tools, I'm picturing you pressing a button and, like 30 seconds later, it's like, yes, but I'm guessing it might be a little longer than this.
00:46:31.152 - 00:47:09.410, Speaker C: Yeah. So static analyzers will typically take somewhere in the order of minutes. And so in that case, your picture is exactly right for a static analyzer. For a fuzzer, it can take longer. And so with a fuzzer, because it's purely random, the longer you could run it, and it won't find bugs, the better. And so, with a fuzzer, we typically try to run them for a longer period of time, normally about a day or more. And then for a formal verifier, that can take a lot longer than a couple of minutes, because typically you'll write a specification and then you'll run it through the formal verifier.
00:47:09.410 - 00:47:26.300, Speaker C: If with formal verifiers, they might take a little bit longer to verify. But in the case where you get counterexamples, then you might need to refine your specification or introduce new invariants that the verifier didn't know about in order to push that verification through.
00:47:26.670 - 00:47:47.010, Speaker A: I was actually curious about this. When you use the formal verifier in prep to use it on a particular circuit, I'm trying to figure out how abstracted it is or how general it is. Do you have to rewrite, or do you have to know this circuit intimately and then write it into the formal verification?
00:47:47.750 - 00:48:44.114, Speaker C: Yeah, so basically what someone has to do is if we have an automated translator from the circuit language to the interactive theorem prover, because let's just say that we're using an interactive theorem prover. In this case, I'll ignore automated verification. If we want to talk about that a little bit later, maybe we can. But essentially, the auditor themselves has to perform that translation in order to help with that process, both in terms of scaling the formal verification and to make it less error prone. We also work on automated translations from a particular language to the language used by the interactive through improver. So, Cochrane. And then the next thing that you do is after that translation has been performed, you then encode your spec in that language as well.
00:48:44.114 - 00:48:50.680, Speaker C: And then finally you write a proof that that spec holds over the translated program.
00:48:51.690 - 00:49:00.010, Speaker A: So there's quite a lot of setup work for each one of these things. It's not like out of the box, and it's going to understand different circuits in the same language.
00:49:00.990 - 00:49:31.090, Speaker C: Yeah. So the hope is that this is what everyone works on as they start getting more and more circuits in a particular language. Then they work on automated translators to Cocker Lane and so we have, I think, one written for Circom that will automatically translate to cock in our case, for performing that formal verification. But yeah, other languages, the translation has to be manual.
00:49:31.670 - 00:49:50.006, Speaker A: Does it matter? I'm curious, mean, so far you've talked more about circum, but not so much about proving systems. Does this proving system have any part of this, say you use plonk versus using something like Nova. Do you have to rewrite these things or can you reuse them?
00:49:50.108 - 00:50:37.990, Speaker C: Yeah, so the reason why I say circom is just because most of the audits that we've gotten have been for circum, but really a lot of our tooling actually targets r one cs. So for different proving systems, typically, yes, you do have to do some extra work because you can then with different proving systems, obviously have different shaped constraints. And then on top of that, when it comes to some of these systems, like plump, now you also have to deal with recursion. And so R one Cs is typically just the, or at least the R one cs. Chinnerhead by circom is typically just the easiest one for us to deal with because the constraints are quadratic. And then while you can, I think, now have recursion in those constraints, typically they don't.
00:50:39.210 - 00:51:00.474, Speaker A: Yeah, I'm just thinking about R one cs versus something like air or like the sort of stark structure. Have there been any auditing tools built for those kinds of systems or is that still. Yeah, I'm just curious how much work has to go into building. Can you reuse anything if it's a different underlying structure?
00:51:00.602 - 00:51:52.270, Speaker C: Yes. So basically you can always reuse the interactive theorem proverb, because that part is general. And so really at that point, it comes down to the translation process. So when you translate down to that underlying form, when you move to a different proving system, then likely a lot of that is going to have to be re implemented. And so, for example, if we have a translator that works on circum, for example, even if we move to a different language that will generate r one cs, we'd have to create a new translator, right? And so generally for that reason, it makes more sense to target approving system, or at least the language for approving system. So something like R one cs or plonk or something like that. That way you can then support multiple languages.
00:51:52.610 - 00:52:24.778, Speaker A: Are you familiar with some of the newer languages coming out? Like there are languages like noir, which are kind of especially designed for some of the more modern planck variations as well as others? I know that I think folks from the noir scene would not say it's just for plonk, but there's some new languages coming out. I guess the question here is almost like, is it on your radar? How would it get on your radar? Like, would you need a project to approach you saying, hey, we want an audit, we're using this other language, and then you'd get into it. Or are you kind of tracking it yourself?
00:52:24.944 - 00:53:40.590, Speaker C: Yeah. So a lot of these new languages are on our radar, especially because at least my feeling is that in order, some of these new languages will bring greater security. And so for some of these languages that are being developed, like Leo, for example, or lurk, where people don't have to write the underlying constraints themselves, that can bring much greater security because then you don't have to worry about the individual developer making or running into issues. And so at least in terms of what we do at Veradece, we are aware of these different languages and we try to learn as much as we can about them beforehand, but we normally can't spend too much time investing and tooling for those particular languages until either one. We try to approach these ecosystems early and try to determine whether or not we'll get or how likely it is that we'll get audits for them in the future. But really, a lot of our development at least, has been driven by the projects that we've been getting. And so we are working on a number or expansions to our tools to support other languages.
00:53:40.590 - 00:54:19.614, Speaker C: So, for example, some of our tools at veradice work on source code. And so typically they were built to support Circom because that was what we got. Most of our. Or a lot of the audits that we've gotten have been in Circom, but now we've also gotten audits in Halo two and arcworks and stuff like that. So at that point, we have started expanding them to work on those languages as well. Yeah. So similarly, when it comes to talking with these ecosystems, sometimes we expand our tools to those ecosystems, but generally it's driven by the audits that we end up getting.
00:54:19.732 - 00:54:32.558, Speaker A: As you just said, that Halo two, to me is a proving system. I actually don't know this. What is the language of Halo Two? Is it rust? Yeah. What happens for something like this, then? What happens if rust is the language?
00:54:32.734 - 00:55:30.710, Speaker C: Yeah, it gets more difficult. Let's just say that. So Halo Two is kind of a unique beast because basically what you're doing is you're using rust in order to basically construct the circuit. So you've got a circuit builder that you're interacting with in rust. Right. And so at least for some of these things, when it comes to supporting them, one of the reasons why we like supporting things at the language level is because then we can reason about, at least for a static analyzer, we can reason about both the witness and the constraints at the same time, because if we can find deviations between them, that's likely a bug. However, for some of these systems where that might be, let's say complicated, like supporting Rust, sometimes we have to let go of the witness generator side of things that helps us identify some of the bugs, and instead we reason almost entirely about the constraints in order to find bugs.
00:55:30.710 - 00:55:55.070, Speaker C: And so it's always better if we're able to have more information. And so that means that some of the, at least for the static analyzer, some of the detectors that we've developed work better in some languages than others. But, yeah, basically we try to adapt as much as we can to new languages or new proving systems.
00:55:55.810 - 00:56:33.098, Speaker A: Kind of throwing back to that earlier episode I had done on formal verification. I know at the time we talked a lot about Rust and how rust as a language already has like a form of checking. And so there's almost like the spectrum of moments when your code gets checked as you're writing it. If you're writing in Rust, it's getting checked there, but then you can further check it. Formal verification potentially being at the end of that, where it's like the most checked, does formal verification like Rust, does it save formal verification? Does it find things that normally formal verification or some of these other tools would find?
00:56:33.264 - 00:57:53.790, Speaker C: So, yeah, basically, one of the nice things that you get with Rust, and I'm going to say nice from a language perspective, rather than sometimes from a developer's perspective, is rust has this notion of a borrow checker. And so the borrow checker essentially is going to perform what maybe you can consider as some sort of basic formal formal verification. It's basically going to validate that when it works, right? Kind of. It's basically going to validate that when you have a reference to a program, you're not using that reference in, let's say, an improper way, because when you have something like C or C plus plus, you can get into problems where you have a piece of memory allocated and you haven't freed it. So with rust, the borrow checker allows you to, let's say, check something out, and then it will validate that it will only compile if you have properly used what you have checked out, or if you've checked a pack in, for example. And so this borrow checker basically provides concrete ownership of a particular reference to an entity so that you're less likely to run into particular issues. Or, yeah, I'm going to say less likely because you can still use some unsafe things, but at least in rust, you can say this is unsafe.
00:57:53.790 - 00:58:09.850, Speaker C: And so one nice thing, and there's at least one paper that I can think of off the top of my head where people have used knowledge of rust, borrow checker in order to help simplify the process of performing formal verification.
00:58:10.430 - 00:58:14.154, Speaker A: Interesting. But not in ZK so far.
00:58:14.272 - 00:58:39.662, Speaker C: But not in ZK. No. This was just verification using Rust. And so in ZK, at least you can still end up with normal bugs that you would otherwise, because at least right now, what you're doing in rust is rust is just the language that you're using to build the circuit itself. So you can still make an under constrained circuit, because rust is not going to do anything to help when you generate your constraints.
00:58:39.806 - 00:58:59.798, Speaker A: Okay. And you sort of mentioned lurk as like a language where it sort of protects developers from making some of these errors. But could you build some sort of formal verification into a language for ZK? Could that ever happen? We're almost using that similar technique that you just described in Rust, but actually looking at how a circuit performs.
00:58:59.894 - 00:59:37.602, Speaker C: Yeah. So there's a couple of different things that you can do here. So first, let me address something like languages like lurk or Mina or something like that. So right now, there's a couple of different things that you can do. So you could, one have a high level language, and that language is just going to allow people to express the computation that they want to be checked by the ZK circuit. And then at that point, because developers aren't writing the ZK themselves, you can perform formal verification or whatever you want on the underlying infrastructure and validate that. Yes.
00:59:37.602 - 01:00:19.646, Speaker C: That infrastructure is correct. Yes. And then you're doing it once. And so that's one thing that you can do. Another thing that you can do is, and this is one thing that I'm interested in, is you could perform formal verification over the witness generator itself when expressing computation. And then as part of the language, you could possibly prove that my constraints actually are constraining my program to be exactly this witness. And so that would be another interesting way of doing it where it's kind of like you have a formal verifier in the loop.
01:00:19.646 - 01:01:02.800, Speaker C: And so this has been used in other languages. So, for example, there are languages like Daphne and a couple of others where you basically perform the formal verification in line with the actual computation. And that seems like something that would be interesting in this domain where when someone expresses constraints, there is some integrated tooling that will make sure those constraints and the computation match. The problem is then it places more of a burden on developers because now they basically have to be the ones who perform the formal verification. And the feedback that you get from at least interactive theorem provers is not always the best.
01:01:03.590 - 01:01:05.538, Speaker A: Not clear or not?
01:01:05.704 - 01:01:12.500, Speaker C: Yeah. So sometimes it's not quite clear, especially to people who aren't very familiar with the system, like what the problem is.
01:01:14.150 - 01:01:18.710, Speaker A: Got it. I want to talk about security in the ecosystem.
01:01:19.450 - 01:01:20.198, Speaker C: Okay.
01:01:20.364 - 01:01:41.638, Speaker A: You are primarily working and exploring, I assume, projects that you are auditing for. So this is a company has been like, hey, we need external auditors to look at this code before we go live and they send it to you. But in the training of these tools, do you also look at other circuits, other code that isn't your clients?
01:01:41.814 - 01:01:42.202, Speaker C: Yeah.
01:01:42.256 - 01:01:48.186, Speaker A: And kind of why I'm kind of curious. Is it to train up the tools or is it because you're curious?
01:01:48.378 - 01:01:48.974, Speaker C: No.
01:01:49.092 - 01:01:53.040, Speaker A: Does it help you get deals too? Is it kind of like, hey, hire us?
01:01:53.570 - 01:02:50.802, Speaker C: Yeah, I mean, kind of all of the above. So basically we use our tools to help with our client code, because essentially the more code that we can expose our tools to, the more confident that we can be that we have not introduced bugs into our own code. So the more confident we are in their results. And so there are very good reasons why you would want to, let's say, check our tools on other people's code, particularly if we know that code has bugs. And this is part of the reason why we like running them on code that we've audited, because then we know exactly what bugs should be found. But for code that has been exploited, you oftentimes would want to run your tools on that to make sure it can find the exploit if it's supposed to. And then in terms of running it on other code, let's say code that's just publicly available on GitHub, that's also useful because if it can find bugs, then you found something new.
01:02:50.802 - 01:03:19.322, Speaker C: But it also, again, gives you the opportunity to, let's say identify false positives or something like that for a static analyzer where maybe it identified something that it shouldn't have so that you can trim it out. So basically it just allows you to build up your confidence. And then when you find a bug, then obviously that can be good if you can report it to that particular developer ahead of time, and that has led to us finding clients in the past.
01:03:19.456 - 01:03:52.198, Speaker A: Interesting. I am curious about the disclosure process, maybe going back to the solidity world. Are there ways that people expect that to happen in solidity? And does it change when you move into the zk world? And the reason I'm asking here is like, a bug fix in solidity might be quite fast, and I'm wondering if you find something like in a ZK circuit, is the fix that much harder? Yeah, just tell me if there's any difference. And maybe just how does it work in the solidity world. Let's start there.
01:03:52.284 - 01:04:45.430, Speaker C: Yeah. So in terms of disclosure, things can get a little bit awkward, and so you have to figure out where the appropriate place. And this is kind of the first step in order to post a disclosure. So, for example, for people who want to get paid for their disclosures, which a lot of people do, they might not want to post something publicly because then someone else might be able to claim it, and also they then might not get paid because people can or the developers can take that disclosure and then just kind of go with it. And that was one of the issues that people had in the early solidity days. That's why some of these bug bounty platforms like immunify and stuff like that exist. Because one problem that people had is they would identify a bug, they would disclose it privately to the developers, and the developers would say, okay, great.
01:04:45.430 - 01:06:15.060, Speaker C: And even though they technically had, let's say, a private bounty program, where if they got a disclosure, they would say, this isn't actually a bug, and then go and fix the bug, and people would not get the money that they felt like they would do. And so that's where some of these bug bounty programs like immunify came in, because they have a recorded process where developers or hackers can feel more confident that if they disclose a bug, they will get a settlement or they will get the actual bounty that they were promised. Because now a developer can't necessarily just disappear and say, I'm not giving you the money that you expect that I would or that I promised. And so that's kind of how it works in the solidity world, at least right now, because a lot of people in ZK are kind of building on top of these dapps. Some of them also use similar platforms, right? Like immunify, but some don't. And so when it comes to disclosures, at least for us, because some of the bugs that we found are in things that may or may not be in production, because it's not always clear what's in production. We try to disclose things privately and then we're generally not looking for a bounty unless someone has a bounty program.
01:06:15.060 - 01:06:42.880, Speaker C: But it then gets kind of awkward because sometimes we disclose things and then we just don't hear back from the developers, and it's unclear if they've fixed things. Like, we'll monitor their GitHub usually to try to see if they have. But when we report something and we don't hear back from them, it can be a little awkward to know. Did you validate this was a bug? Was there a reason why maybe this wasn't that we didn't get or something like that?
01:06:43.810 - 01:06:58.740, Speaker A: In the case that somebody, that a team receives a report like this and they don't react, are there ever times where maybe the reason they don't react is it's not breaking, it wouldn't affect their system?
01:06:59.430 - 01:07:53.394, Speaker C: Possibly, yeah. So at least generally when we've done this, it's been by discovering protocols that are publicly available, like on GitHub. And so in that case, it might not be something that they actually have deployed in production, it might be something that they're currently building or something like that. So the kind of awkward part about when people don't respond to this is one part of the reason why we are reporting this is because we want to make sure you want to help, not a bug. Or, yeah, we're there to help, and also if it's not a bug, we want to learn. So, for example, for bugs that we found with tools, maybe there is an additional component that we're not aware of that is preventing this from actually being a bug. So, for example, perhaps they're performing some on chain validation, like we talked about earlier, that our tools or we weren't aware of.
01:07:53.394 - 01:08:14.710, Speaker C: And so essentially one of the reasons, or one of the important reasons why we at least want to report bugs is so that if the developers disagree with us, we can at least learn from them why they built the system this way, or why something that we reported maybe isn't a bug.
01:08:14.790 - 01:08:58.406, Speaker A: So there's been kind of a conversation brewing in our big telegram and CK podcast Telegram group about security. It's kind of come and gone over the last few weeks, and there was one kind of counterpoint to this, which could potentially help explain why some teams aren't reacting, which was this idea of, and this was mentioned by an auditor, by a ZK auditor, that sometimes there's these under constrained bugs that wouldn't necessarily be exploitable either because of the way governance is set up, or there's only a certain part of the stack in this case, like relayers, that would actually be able to exploit it. Have you seen any of that? Could that actually help explain sometimes why there's no reaction?
01:08:58.598 - 01:10:02.726, Speaker C: It could. So, for example, this is where I was kind of describing different parts of the system that maybe would have allowed this not to be exploitable. So, for example, in the two cases that you were just talking about, basically there's some validation that's being performed on chain that maybe we're not aware of. Or perhaps a particular proof has to be generated by a trusted entity, because maybe the ZK circuit is validating a signature or something like that, or for particular inputs. And so in that case, maybe it's okay that certain values or certain computations are not properly constrained. And so there could be reasons why an under constrained value might not actually be exploitable. And so, for example, in one of the disclosures that we made to a team about an under constrained circuit, they took it very seriously, and particularly because they were hoping to run their trusted setup suit.
01:10:02.726 - 01:10:42.694, Speaker C: And so they worked with us in order to try to figure out why this thing was under constrained. And while the circuit technically was under constrained, the signals that were actually under constrained were kind of some utility signals that they were using that actually were not necessary for the circuit to operate correctly. And so they were performing some additional computation, and it turned out that computation was unnecessary for the circuit to actually operate correctly. And so in that case, they were able to remove constraints, which is typically great for proving time, but the circuit itself, more importantly, was not constraint or under constraint.
01:10:42.822 - 01:11:06.210, Speaker A: I'm kind of curious, given you're an auditor, it sounds like you're doing the disclosures privately, responsibly, but do you ever bump up against the black hat hackers, the other hackers? Do you sort of see them around? Would you be able to spot, because you're kind of in these code bases, would you ever be able to spot other hackers?
01:11:07.510 - 01:11:33.638, Speaker C: No, because generally the black hat or hacker is only going to show up once things have been deployed. They're not going to necessarily show up there. Typically with a black hat, they actually want things with maybe bugs that they found in the source code to be deployed. That way, after deployment, they can steal funds or something like that. And so, in the process of auditing, I have not bumped up against black hats.
01:11:33.734 - 01:12:17.758, Speaker A: Okay. I always find it fascinating, sort of the motivation of the kind of good hacker here. There is the financial gain, potentially through bounties I think there can be epic cred in the community. I think if you look at the Dow hack, you look at those stories that Jordy and Griff, they're written in books. Books are written with them as protagonist type characters. I mean, this is awesome. But, yeah, I wonder, are there other things that you think could motivate the appropriate positive disclosure that would almost encourage the black hats not to wait for that vulnerability to be out in the wild?
01:12:17.954 - 01:13:29.354, Speaker C: Other than what we've talked about, it's pretty difficult because one good motivator is obviously money. And at least for motivating a black hat, really, most of the time what they're doing is they're trying to get some sort of financial gain. Sometimes they'll do something just to spread chaos or something like that because that can be fun, I guess. But really, the financial gain aspect is, at least in this space, pretty significant. Right? And so one thing about disclosing at least bugs early is someone doesn't necessarily know how much money is going to be tied up into a protocol, right? And so if they could report something to a bounty system where they know they will get x funds, whereas rather than actually exploiting the thing in production where maybe they can't quite get as many funds, then that can be a motivator. Another one is it can be difficult to get funds out of these systems. Like, you might be able to steal funds, but then you have to quickly exit.
01:13:29.354 - 01:14:40.454, Speaker C: And sometimes those exits are not very successful because I feel like people think that they found a bug and then they try it, and then all of a sudden they end up with millions of dollars and they're like, oh, now what do I do? And so that's another reason is that I guess these bounty programs are important to motivators because not only does it allow someone to kind of engage and get that money early, it also provides a more guaranteed source of funds if you report a bug. Because just because you can exploit the thing doesn't mean that you can successfully exit those funds. But at least in the context of ZK, I think the big question is going to be whether that matters. Because if everything is private and let's say they can exploit a circuit itself, then in some cases it's not obvious that something has actually been exploited or a hack has actually occurred. And so at least in this context, it's going to be interesting to see how things go forward. And I really hope that they do not go forward in a disastrous way.
01:14:40.652 - 01:14:54.700, Speaker A: Okay, now I want to ask sort of a final question on this, given the fact that you're looking at a lot of zk systems, how optimistic are you? Should we be worried, or do you think we're going to have sense?
01:14:55.230 - 01:15:31.362, Speaker C: Well, part of what we end up seeing here. So the problem is everything is being designed at a really low level. People are actually designing these constraints themselves. And I would kind of end up saying that that's very similar to actually programming in assembly. It doesn't encourage proper programming practices in some cases, and it can be quite dangerous. And so we have seen a significant number of bugs during the course of our audits. So I think I calculated this recently.
01:15:31.362 - 01:15:39.426, Speaker C: On average, in zk audits, we found three to four significant bugs per audit, on average.
01:15:39.538 - 01:15:39.970, Speaker A: Wow.
01:15:40.060 - 01:16:26.182, Speaker C: And some of them corresponded to these under constrained circuits. During the evaluation that we did on our static analyzer, we found even more in publicly available GitHub code, which, like I said, I'm not sure if it's in production, but in a lot of these cases, it's because people weren't understanding how to properly constrain particular values, because there are edge cases that they don't think about. So, for example, and I've talked about this in a couple of conferences, if you think about something like division, you know that you can't actually divide by zero, but you can't really express division in, I don't think, any of these constraint systems. So instead, you have to say, like, rather than a divided by B is equal to n, you have to say n times B is equal to a.
01:16:26.316 - 01:16:27.094, Speaker A: Okay.
01:16:27.292 - 01:17:43.474, Speaker C: However, if this is trying to constrain a division, you also have to consider the case where B can't be zero. And that's something that people often miss, because it's not really something that you think about very frequently. And so that was surprisingly, one of the major bugs that we ended up finding in these systems is people not understanding how to properly constrain the semantics of the language that they were trying to, or that they were expressing these constraints for. And so for that reason, what I'm hoping going forward is earlier we kind of talked about these high level languages, where maybe you only have to perform the verification once. I think that at least going forward, what I'm hoping to see is more people making use out of these languages, like Alio Mina, lurk, risk zero, things like that, where they can express their computation and then let the language itself deal with the actual constraints. Because as long as the language team or the people developing that language do their job properly, you only have to check that once. Yeah, or I guess as things upgrade multiple times.
01:17:43.512 - 01:17:54.274, Speaker A: But really, but just on the person writing, it could be like depending on those checks being made, right, hopefully those.
01:17:54.472 - 01:18:59.590, Speaker C: People developing the languages, and I've met with quite a few of them, and they're all very intelligent and stuff like that. And so you leave the difficult part up to the experts and then have them vetted very thoroughly in order to bring broader safety. Because really the problem that we have right now is in terms of the safety guarantees everywhere. You have to trust everyone, you've got to trust the developers, you've got to trust the proving system. Whereas things would be a whole lot better if you were able to kind of design things in a more, I guess, modular way where only one part has to deal with the constraints and stuff like that. The reason why that might not happen, or that people would still design in languages other than that, though, would likely be in order to improve the proving times, because not every application is going to be amenable to these languages, which will likely have a larger overhead.
01:19:00.750 - 01:19:20.718, Speaker A: Cool. Well, on that note, I want to say a big thank you, John, for coming on the show and sharing with us sort of how formal verification and ZK can work together a little bit about your journey, Veradece's work, and kind of the landscape of zk security disclosures. Yeah, I really appreciate it.
01:19:20.804 - 01:19:22.590, Speaker C: Yeah, no problem. Thanks for having me.
01:19:22.660 - 01:19:29.470, Speaker A: I want to say a big thank you to the podcast team, Rachel, Henrik and Tanya, and to our listeners. Thanks for listening.

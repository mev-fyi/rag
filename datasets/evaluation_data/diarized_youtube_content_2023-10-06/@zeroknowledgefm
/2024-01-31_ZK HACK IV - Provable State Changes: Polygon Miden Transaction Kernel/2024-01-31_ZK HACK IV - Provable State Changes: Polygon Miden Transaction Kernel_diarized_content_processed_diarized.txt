00:00:05.820 - 00:00:52.332, Speaker A: Hello everyone. We try to apply the same style of the seeker hack design to our polygon design. Basically, today we want to talk about the maiden transaction kernel. And it is a program that runs in the maiden VM, as you will see. And so for that it might be a very cool real world example of a program running in KVM, creating proofs how Bob and has designed it basically, and how it's used in our rollup. So yeah, stay tuned. Basically, a very quick rundown is that the mind transaction kernel proves state changes.
00:00:52.332 - 00:01:19.668, Speaker A: That's its goal. And this session and workshop will have three parts. First, we will talk about the mind VM. The mind VM executes programs. Most of you probably will know the mind VM already and creates execution proofs while running these programs. And in that we talk about vms versus dkvms as risk zero did last time. Maybe we can add a flavor.
00:01:19.668 - 00:02:33.340, Speaker A: We talk a little bit, or Bob and will talk about the MindVM design and HowVM programs look like in our Mazm language. And then we talk about what MITN transactions are, and we redefine what a transaction is basically to accommodate our goals, like we want to have client side proving. And so I will explain how transactions are used in the rollup, how we redefine that, and how we use accounts and nodes in maiden. And then everything is set basically to talk about the transaction kernel itself, which is a program executing these transactions inside the maiden VM, and in doing so creating proofs. So we will talk about transaction program, the design of it, what are the inputs, the outputs, the four phases or sections of the program, and what do we do with the proof? And then we show a bit of code and let's see, answer hopefully lots of questions. Then I will just hand over to you verbin.
00:02:34.320 - 00:03:09.690, Speaker B: Yes. Hey everyone, very excited to be here. And as Amin said, we'll go through these three sections, and then each section will have like A-Q-A if people want to ask questions about that specific section. But the first part is really about what is my NVM. And I think a lot of this, some of this will be repetitive for some people here because there's only so many ways you can describe what a ZK virtual machine is. But I think, as Dominic said, we'll have a few interesting things to share here as well. So let's start with a very basic question.
00:03:09.690 - 00:04:04.524, Speaker B: What is the ZK virtual machine? And to take a step back, what is a virtual machine or machine computation in general? And usually we think about even also say it's a state machine, something that takes some initial state, and a program applies this program to the initial state and outputs a final state. And a lot of virtual machines or regular computers work in the same way. Now, ZK virtual machines added a few twists here. First, as part of the executing the program, we also want to generate the proof. And this proof is important because we want to make sure that we can verify the execution much faster than we can actually execute the program. So this proof attests to the correct execution. So basically you don't need to reexecute the program to get from initial state to final state.
00:04:04.524 - 00:04:52.860, Speaker B: You can just verify that given this program, this initial state and the final state, that everything was executed correctly. And this is what this proof is for. Another thing that we get with a virtual ZK virtual machine is that we are able to provide the witness, or depends on. There are different ways to call it secret inputs, something that the verifier of the execution doesn't need to know about. So you kind of can say, okay, there is some secret data that I'm supplying to the VM when it executes and when James approved, but the verifier doesn't know about this and doesn't need to know about this to verify that transaction is executed correctly. A few examples of this witness. You could provide a signature there, and let's say VM verifies a signature, or you could provide a premium of a hash, and then you can prove that you computed the actual hash correctly, and so on and so forth.
00:04:52.860 - 00:05:29.320, Speaker B: Now, running the VM, kind of like with the initial state and full state, it requires you to provide a potential of public input. So frequently what we do is we replace the states with commitments and do this through the witness. We provide initial state and final state. So you'll see in the transaction kernel, for example, we almost never provide the actual state of the account. We only provide the hash of the account as a public input. And the actual state of the account is provided through the witness nonterministically. And the other thing we can do is do the same thing with a program as well.
00:05:29.320 - 00:06:07.380, Speaker B: So instead of providing the program in the clear, we can provide the commitment to the program. And inside the VM we provide this specific all the instructions of the program non intrustically. And then the VM does kind of like equivalence check that the things provided to the witness match the commitments. But this is a very convenient way. And again, you'll see it in the kernel. We actually do not provide the program explicitly when we're executing nodes, we just provide the commitments to those programs and things like that, and the VM figures out internally how to get the relevant code. And that code actually never needs to be shared with the verifier.
00:06:07.380 - 00:06:50.096, Speaker B: All right, let's go to the next slide. So why do we even need to do zkvms? And there is a lot of discussions of like. Okay, the other alternative being we can go with a circuit computation with specific circuit for a specific use case that we want to implement. But why do we want vms in general? So the first thing, and this is arguable because it depends also in the circuit model, you can have a compiler that compiles. But one of the nice benefits of the VM is that you don't need to learn anything about ZKP systems for cryptography. You just use it as a regular VM. You just get this extra thing in the end, like in terms of proofs, and you're able to do a few other things.
00:06:50.096 - 00:07:26.460, Speaker B: But hopefully all of this is abstracted from you. And a lot of people are already familiar with virtual machines, so that hopefully the learning curve is much lower. The other thing that is interesting is if you have a ZK virtual machine and if it's turing complete, it allows you to run any computation, so you don't need to change anything about the VM, and you can execute any program out there. This is slightly different from like a circuit computation model, where you may need to generate a new circuit for a different use case. Here we kind of say we built the VM. Once it's universal, we don't need to change anything about it. We can support any arbitrary computation.
00:07:26.460 - 00:08:35.824, Speaker B: And there is relative simplicity that comes with the VM and also an arguable point to some extent. But basically, once you've designed the VM and added the constraints and done all kind of like heavy lifting, once you don't need to do it again, hopefully because the constraints are stable, nothing changes about the VM itself. Then we use other sets of tools to kind of execute programs on the VM and those sets of tools, hopefully. We been running things on virtual machines and machines in general for longer, they're more mature and all of that stuff. So we can take advantage of existing infrastructures where you would say, if you compare it against the circuit model, for example, a specific circuit can be simpler, but if you need to generate a circuit description for every time you need to do a new program, then maybe there is extra complexity there. So vms, heavier lifting up front and a bit more complexity to reduce the complexity as you lose it. And then with the VM, you kind of get recursion not quite out of the box, but you still need to do work.
00:08:35.824 - 00:09:21.136, Speaker B: But if the VM is turing complete and can execute arbitrary programs, then it can execute the program that verifies its own execution. So this is actually the approach we've taken with MIDN, where we don't have a specific circuit to do recursion. We just have a program that executes within MIDN that can verify proof of its own execution. And this gives you basically infinite recursion. You can recurse within the VM as many times as you need. So vms are nice, but they do come with drawbacks, especially if we compare them against circuit computation. One of the main drawbacks is that because they're a general, there is an overhead associated with this, and you can argue what is the overhead and how do you compare it.
00:09:21.136 - 00:10:12.812, Speaker B: But it could be anywhere between 510 x to maybe even 100 x, depending on what you are doing. So there is extra if you have a very small computation, you can define it very, let's say even shot 256 or blake three or whatever, that could be a relatively small circuit, while the VM circuit is large. So if you need to prove shot to 56, or if that's the only thing you need to do inside the VM, then probably you're wasting a lot of extra resources on this overhead that VM requires. Now we can optimize this. Or I guess one of the things I should mention, actually, I was talking about the other point. Could you go to the second? No, no, scroll forward. Yeah, so I was talking about the performance.
00:10:12.812 - 00:10:48.552, Speaker B: I think the first point that is mentioned here on the slide is actually about different proving systems. So you cannot do vms in all proving systems, because VM kind of implies relatively unbounded computation, meaning that at the time when the VM starts, you may not know when it will terminate, and it may not be practical to pre built different circuit sizes or different sizes of circuits for computations. So as an example, MitanVM could execute for 256 cycles, so it could execute.
00:10:48.616 - 00:10:49.230, Speaker A: For.
00:10:50.960 - 00:11:33.352, Speaker B: 32 million cycles, or even more close to a billion, not quite a billion. It can't execute for a billion cycles, but it could execute close to a billion cycles, and you would not need to change anything about the VM, and it would not require doing kind of like different setups for different circuit sizes. It will also not incur the overhead of running the computation for different circuit sizes. So if we need VM executed for 256 steps, that's what we pay for. If it executes for 8 million steps, that's what we pay for. That's a nice advantage. Now, there are different proving systems that support vms.
00:11:33.352 - 00:12:05.376, Speaker B: One of them is Starks. We use Starks, and that's one of the more efficient systems to kind of build the VM. Computations in other proving systems may be more appropriate for circuit design and faster and those. But for mime, we use starks. And then. Yeah, the point that I was actually talking about in the beginning of the slide was this performance where you get the overhead, and there are different ways to kind of minimize this overhead as well. Specifically, if you know what you're building this for, you can use acceleration circuits within the VM.
00:12:05.376 - 00:12:16.520, Speaker B: And I'll touch upon a few of this that we have in mind in VM, and that can bridge the gap between a dedicated circuit and performance and the DM performance.
00:12:19.020 - 00:12:35.840, Speaker A: Okay, I'm sorry to interrupt, but I can see that there are a bunch of questions from the audience already in the Q and a type. Maybe now before you switch to the next part, would be a nice to actually cover this, because I feel like they're related to the slide.
00:12:36.980 - 00:13:32.588, Speaker B: Let me do that. So I think the first question is, performance is five to ten x lower compared to specific circuit with implementation of shutter physics in a non ZK language. So take these numbers as like general guides, because they vary significantly between different implementations of ZK languages, zkvms and so on and so forth. In general, I would say if you have a simple computation, let's say you have a ZK language, and that creates a circuit for shutter 56, and that's the only thing it does. And you have something like midn that is very general, or maybe even like DKVM, or risk five, like what risk zero does. I would imagine that without extra acceleration, the circuit would be more than ten times faster. And this is just like speculation, because I haven't done actual benchmarking.
00:13:32.588 - 00:14:02.680, Speaker B: Maybe even closer to 100 x faster if you just do the circuit. Now, as I mentioned, we can put accelerators in the VM to bridge this gap. We can do other things. And then as complexity of the computation is increasing, I think the gap actually also shrinks to some extent. So this is one of the caveats I want to make. But again, take this all as directional benchmarking. This stuff is very difficult in figuring out what is the actual overhead is nontridial.
00:14:02.680 - 00:14:54.128, Speaker B: So the next question, can I execute an invalid operation on a regular VM. So if validators are validating all transactions, and I would say this depends on the VM design. So in some vms you want to allow people to execute a valid decoration and then you can raise an exception. This complicates the design of the VM somewhat, but for example, you don't allow division by zero. So instead of trying allowing the person to divide by zero, you would say if you try to divide by zero, we'll check for that and we'll kind of return an error within the VM. And you need mechanics for this in the VM. The other option is that you just can't prove invalid operation.
00:14:54.128 - 00:15:45.288, Speaker B: So if you try to divide by zero, you cannot generate a proof that simplifies the VM, but also raises a few questions. So at Polygon, for example, Zkedm follows the first approach where you can execute the mald operations and the VM will catch them and it will raise an error. So you can actually generate proofs for any program. In MitVM we follow the second approach where you can't prove invalid operation. And this is like difference between kind of approaches because for example we target client side proving where it is you who wants to generate a transaction proof. So you probably don't want to execute a program that you would not be able to generate a proof for. That doesn't make sense in our context.
00:15:45.288 - 00:16:19.380, Speaker B: So we decided to kind of go with this more simple design because of the kind of the different design space that we're occupying. Hopefully that answered the question. So the next question, I think the VMJs proof of transaction batches this together. I think we'll get to this later. But yes, this is how we do it. Each transaction is a separate program. This is what transaction kernel is about on the VM and then we batch them together also using different kernel.
00:16:19.380 - 00:17:03.190, Speaker B: This is a batching and block kernel. But we'll get to this later. Mitin transaction kernel is a program running in the VM. And this is like what the bulk of this talk will be about once I get through the explaining what vms are in general. So the last question here, I think how can be sure that the new state is created from the last state. I think this is the crux of why we run this in the VM as well. If the VM executes correctly, assuming there are no bugs and things like that, you can check the proof and say okay, the initial state, when we apply the desired program to it, results in the final state.
00:17:03.190 - 00:17:55.186, Speaker B: This is what we prove as ekps. And again assuming there are no bugs, this comes with it kind of like out of the box with the design, we can get into how exactly the VM works under the hood and there will be a little bit of that later on, but I'm not sure if we'll go as deep during this talk. Okay, let's go to the next slide. All right, I'm going to try to go through this quickly so we can get to the meat of the content of today's presentation. But basically once we know that we want to build a ZKVM and we decided to do that, the question is which instruction set do we want to use for this? And there are different options. So like mainstream instruction set, webassembly risk five. There is something that we want to have specifically for blockchains.
00:17:55.186 - 00:18:22.400, Speaker B: For example, EVM could be a good choice. And then last option is like we may want to design something completely new, come up with our own instruction set. These all come with their pros and cons. One of the considerations could be adding tooling. You can see like with mainstream you get a bunch of tools out of the box and ZK optimized. The new instruction set obviously has no tooling. You have to build everything yourself.
00:18:22.400 - 00:18:59.210, Speaker B: Is it designed for blockchain specifically? Mainstream instruction sets are usually, or at least so far, haven't built with blockchains in mind. And then the last one is like the last one. But there is many more considerations. But the one that we listed here is like the performance aspect. Can you design it to be very performant with an SGP circuit? In some cases the answer is maybe because it depends on which instruction set do you choose out of the mainstream? Some of them may be simpler, like x 86 is probably very difficult. Risk five is much simpler. And then if you choose your own ZK optimized instruction set, then you have full flexibility.
00:18:59.210 - 00:19:31.400, Speaker B: Okay, so let me kind of jump into the MitevM specifically so MitevM is Turing complete spark based Zk optimized virtual machine. So what it means is that we're using sparks as approving system. We can execute any arbitrary program. It is ZK optimized, meaning we're using our own instruction set. And I'll get into the reasons in a second. And this is why we're using mine and VM goals, why we want to use the slightly different instruction set. And let's say we didn't pick.
00:19:33.370 - 00:19:33.698, Speaker A: Let'S.
00:19:33.714 - 00:20:25.480, Speaker B: Say EVM instruction set that is optimized blockchains or why didn't we pick let's say risk five or webassembler, something like this. So one of the things that we want to do is, and this is very crucial to midnight design, is that we want to support client type hoops, and this entails actually a lot of different things. But the one of the more important one is that we want to support executing private and entrusted programs. And you'll see that when we talk about the transaction kernel. But basically the transaction kernel that executes the program is publicly known. Anybody can execute it, and then you can verify execution of the transaction kernel because you know exactly what it does. But as part of the transaction kernel, we also execute custom programs which we call node scripts or account interface functions, which may not be known and can do different things.
00:20:25.480 - 00:21:16.866, Speaker B: And the idea is that we need to provide a level of isolation between these programs versus the programs that are being executed, kind of like what is the kernel doing. So we don't want some malicious program to be able to interfere with the kernel. So for example, this requires building a context separation at the vm level where we actually support different execution contexts. And as you execute a node, for example, it goes to one context which doesn't have access to the kernel memory anymore, so it can't modify it. And other things where you go and execute, let's say call an account and then a node does not have the ability to write directly into account storage. It all has to go through account interface methods and so on and so forth. And this is all doable relatively easily in a public context.
00:21:16.866 - 00:22:12.498, Speaker B: When you know exactly what the programs are doing, you can check them ahead of time. But in a private context, when you want to execute something client side and you don't even want to reveal what you're executing, this presents a bit more challenges than this. At least our approach has been to handle this through a custom instruction set that is specifically tailored for this use case. And then the second point or second reason why we're doing a specific instruction set. And I think this is kind of like an important part, because not only do we want to do this client side, but we also want to make it efficient because we want to eventually be able to prove it on a smartphone and other places. So we've optimized MitenVM specifically for kind of this blockchain use case and more specifically for blockchains that support this client type. Proving this means like designing an instruction set or using an instruction set as just picking your trade offs in different places.
00:22:12.498 - 00:23:15.034, Speaker B: And for us, the things that are important, for example, the recursive proof verification we want to make it as we still want to do it inside the DM, but we also want to make sure that it's as efficient as possible. We've optimized hashing, so that hashing is very efficient because we will need to handle encryption. We are working optimizing encryption within the VM, so we've picked a few use cases, and this is just covered, some of them that we want to make sure the VM is very fast, so it will not be fast for some computations. For example, it will not be fast at executing an EVM transaction, or it will not be fast at executing some, let's say general purpose computation, like something that you may need for machine learning or whatever, but it will be fast for the use cases that we care about specifically for these things that you may want to do on a blockchain, like verifying cursive proofs, verifying more code tabs, encrypting data and things like that. So these are the kind of motivations for why we decided to go with this specific instruction set. Now, very quickly, MitrevM is a stack machine. There is like a push down stack.
00:23:15.034 - 00:23:41.758, Speaker B: In that way. It's similar to EVM and many other virtual machines out there. We do have read write memory that you can access, and a program can write this memory. As I mentioned previously, we have different memory contexts as well. Like every time you enter a new context, you have a kind of isolate memory. We have accelerators that accelerate specific types of computations. We call them chiplets.
00:23:41.758 - 00:24:36.630, Speaker B: So there is like a hashing chiplet, there's others, I'll go through them in a second. And then we have the whole infrastructure of how the MIGM plugs in into the host environment where you can. A big part of this is what we call an advice provider, which provides non deterministic inputs to the VM. What I mentioned in the beginning, where you provide just a hash, for example, via the stack of some data, and then the advice provider gives you the actual data and then you can kind of verify the equivalence between the two. We have event handler, debug handler, and a bunch of other things that help kind of interfacing with the VM from the host side for debugging and other purposes. Now, in terms of acceleration, to highlight a few important ones, we have range checks which allow us to do a bunch of things within the VM. This is one of the most important chiplets that allows, enables like memory accesses or U 32 operations to supporting them natively in the VM.
00:24:36.630 - 00:25:13.682, Speaker B: There is also the hashing chiplet that does a bunch of things. It does simple two to one hashes, sequential hashes. It's a mini processor that can verify merkel pass very efficiently. And this is what I meant, like when I said we optimized for specific use cases. This is like some of those optimizations. And then we also have bitwise operations and xor to make, let's say something like shaky 56 or like three more efficient. It won't be again, in mining VM, it will never be as efficient as a dedicated circuit for those.
00:25:13.682 - 00:26:15.906, Speaker B: But using these instructions that allow you to do ends and xors and other things like that natively in a VM speeds them up quite a bit. Now, this is kind of like an eye chart of how the MITN execution trace looks like there are different components to it. I will just highlight a few important ones. The first one is program decoder. So I'll go into how we if you go to the next slide, instruction decoder is the kind of main component that is responsible for taking the program or the program hash, actually. And while the VM executes, reducing or extracting the relevant program information so that the VM can execute instructions that are eventually hashed to this hash, we have the operand stack, which is basically the main processor of the VM. This is where most operations happen, like addition multiplication, pushing things onto the stack, reading things, moving things from the stack to memory, and so on and so forth.
00:26:15.906 - 00:27:23.750, Speaker B: And then we have our chiplets on the right hand side, which is what I covered just a few seconds ago that allow us to execute accelerated applications. Now, one interesting thing about MitinVM, and this is very different from most other vms that I've seen out there, is that the way we execute programs is going through this mask approach. So we have Miton assembly, and we're working on a compiler that actually will allow, already does allow, but we still work in improvements compiling rust to mitin assembly. So you would be able to write programs in rust, compile them to Miton assembly, and then execute them on the MITM. But starting with MIT assembly, one of the transformations of the first transformation we do is that we transform it into what we call the mercury abstract syntax tree on masked, and the DM actually executes this masked when it runs the program. Masked is a unique structure because it actually makes maiden not like a traditional Harvard architecture of a Neumann architecture. It's actually a different architecture where we don't have like an instruction pointer that fetches instruction for memory.
00:27:23.750 - 00:27:47.930, Speaker B: We kind of have this traversal of the mast. And Dominic, if you go to the next slide. Yeah, we can go to the next one. Yeah. So when it traverses the mask, it actually builds up the hash of this. This is a kind of Merkle's abstract syntax tree. And the properties that we get from this is that all programs are reduced to a single mask.
00:27:47.930 - 00:28:26.282, Speaker B: So it's kind of like if you want to compare it to something else, it's like a content addressable program execution where every program is reduced to it, to a hash. And you can compose programs very easily together because every node in this math tree is just a representation of a subprogram under it. Yeah, so that's what I mentioned. And then the leaves of the master are just sequential sets of instructions that have no control flow in them. So all control flow is encoded inside the tree. And then the leaves encode a non control flow based logic. The master is very convenient.
00:28:26.282 - 00:29:13.018, Speaker B: I'm actually probably going to skip this example in the interest of time, but the mass is very convenient for a number of reasons. It does introduce some complexity, quite a lot of complexity actually, in the decoder. But it is convenient because when we execute a program, we only need to kind of hash only the part that we execute. So if the program is complex, but for a given set of inputs, we execute only a branch in that program or some set of branches, then it's very efficient in that way. The other part is that we statically know what we are executing. So whenever you have a node in the map, you actually know underlying program. And that helps us, for example, in modern rollup, because accounts commit to specific programs.
00:29:13.018 - 00:29:49.660, Speaker B: So you can't change the account code, for example, or change the script hash or whatever without modifying the underlying program. And I think the last one is like the nice property of this mass structure is that you can have public programs or private programs with public preconditions and post conditions. We use that in the gender transaction kernel as well. This is one of the important properties. But yeah, mass is actually pretty cool. It does come with its own trade offs, but I think it's one of the unique aspects of Biden DM in general. All right, I think there have been some more questions.
00:29:55.610 - 00:29:57.160, Speaker A: Should I read the questions?
00:29:58.570 - 00:29:59.320, Speaker B: Sure.
00:30:00.890 - 00:30:17.210, Speaker A: If I understood, right, your Turing complete. Sorry, if I understood, you write your Turing complete. How can you have stuff like dynamic arrays, unknown loop amount, if all the mask leaves are known in advance? Or can the leaves be looped?
00:30:17.630 - 00:30:49.814, Speaker B: Yes, so the leaves can be looped. So there is actually. I'll share a link here in the chat to the description of how must works. But one of the nodes in the mast tree could be a loop node, and this node will basically repeat the execute the underlying tree as many times until the top of the stack changes from one to a zero or from zero to one, whatever. Actually from one to a zero. So it will execute the underlying master once check the stack. If the stack is one, it will execute it again.
00:30:49.814 - 00:30:58.470, Speaker B: If the stack is one, execute again. If the stack changes to zero, it will stop executing and will move on to the next assembling of this master.
00:31:00.270 - 00:31:09.020, Speaker A: Next question is like, which instruction set is being utilized here? Is it RIsC five or wasm? Apologies if you already addressed this.
00:31:10.350 - 00:31:20.366, Speaker B: Yeah, so mitin assembly is actually its own instruction set, so there is underlying instruction set. This is one of the things that.
00:31:20.388 - 00:31:20.960, Speaker A: I.
00:31:22.690 - 00:31:50.250, Speaker B: Kind of tried to explain, but basically there is like trade offs here, and we could have gone with the mainstream instruction set, but then we would not be able to optimize for things that we care about. It would come with its own pluses and minuses, and also maybe not support like private programs and client side computations as easily. So yeah, we have our own instruction set, but we're working on compilers and other things that will allow you to not to have to learn this instruction set. So you can just write program in rust and then it will execute on MidnVM.
00:31:52.510 - 00:31:58.410, Speaker A: Where can people get more information regarding the Rust MIDN assembly compiler?
00:31:59.390 - 00:32:34.706, Speaker B: We have a repo, so we'll drop a link to the repo in the chat here. It is still in fairly early stages, but we can already support compilation from rust. The way we actually do this compiler is that it compiles rust to webassembly and then it compiles webassembly to MIDN assembly. So in theory it doesn't even have to be rust in the future, although we're focusing on rust right now. So basically anything you can compile to webassembly you would be able to execute on midnight. Now there are restrictions. For example, we don't allow floating point operations because this is not the use case we are targeting, but in the programs that don't use floating point operations.
00:32:34.706 - 00:32:41.530, Speaker B: So it's basically a subset of webassembly that we can compile into MIDN assembly transparently.
00:32:44.430 - 00:32:53.070, Speaker A: Maybe I do the stack question first. Why did you decide on a stack machine as opposed to say a register machine or a pure memory machine?
00:32:53.890 - 00:33:50.074, Speaker B: Yeah, so I think there were a few considerations, and to be honest, this is not something that I can say definitively we made the right choice. I think there are pros and cons to each approach. I think one of the reasons is that for a stock machine, your instruction representation is much more concise. So basically, for a registered machine or for memory machine, your instructions are usually like 32 bits, maybe even more in some cases, but usually 32 bits around there. For a stock machine, we actually have an instruction being seven bits each. And then depending on how you define actually for memory machine, I think it's actually even more than 32 bits, because you need to provide memory offsets and things like that. But stack instructions are just seven bits in our case, and this means that we can pack like we use Goldilocks Field, 64 bit Goldilock Field, we can pack up to nine instructions into a single field element.
00:33:50.074 - 00:34:41.120, Speaker B: And so when we compute the program hash, it's actually super efficient. In a single permutation we can absorb like 72 instructions. In the best case, it doesn't always happen, but in the best case we can absorb 72 instructions, and that allows us to hash the program much more efficiently. There are other reasons for the stack, but again, it's a trade off, because stack does require you to do like stack manipulation when you execute programs, and that adds extra cycles in some cases it may be more relevant than others. In our case, for the most cases it's fine because of the way the VM is arranged, like you're doing usually other things that require a longer length. So taking extra cycles from the stack doesn't create too much trouble. But yeah, I agree, it's a trade off, and it's not always clear for which design would work best.
00:34:43.090 - 00:34:52.210, Speaker A: Can you elaborate on privacy within the mine VM, or is meant the mine roll up? Maybe? Is there privacy in the mind VM as well? Maybe the witness?
00:34:52.710 - 00:35:47.910, Speaker B: Yeah, so mitinvm privacy, there are a couple of parts to this. Some of this is the same as you would get with any ZKVM where I mentioned you can provide the witness and you don't need to provide. Like you can execute things in such a way where the verifier doesn't need to know all the inputs. But this is basically true of any ZKP or any ZKVM that supports zero knowledge, part of the proving system. The other aspect of my medium from the privacy standpoint is related to how we structure this execution context and mast. So one of them is execution context, where you can execute untrusted programs and they will not interfere with the trusted program. There is like separation at the vm level enforced by this, and this by itself doesn't create privacy, but it enables privacy in this private programs that don't affect the rest of the VM.
00:35:47.910 - 00:36:15.870, Speaker B: The other part of this is must, where you can commit to some program reveal part of the program, but not the entire program. And this could come in handy in variety of scenarios, but it is an extra thing that I think might and allows that. I have not seen in other places where you can have partial privacy in a way that some things are known but some things are not. Usually you can either conceal the program or you can reveal the full program, but not do it in kind of like selected manner.
00:36:17.410 - 00:36:31.650, Speaker A: And now there are lots of questions, or maybe people like these questions, what the differences are between the maiden VM and the ZKE EVM. And I think it is meant the virtual machine like, not the roll up. But maybe you can also clarify.
00:36:33.030 - 00:36:55.130, Speaker B: Yeah, the difference is MitnvM uses a different instruction set that is optimized for client side proving or not optimized, but is designed specifically to support client side proving EVM. Zke EVM is designed to be EVM compatible. So it uses the EVM instruction set basically so that we can, with no hassle, port existing ethereum smart contracts.
00:36:57.790 - 00:37:09.230, Speaker A: Yeah, and the difference between the two roll up designs will be in the next part. One more question. Is there any plan to support Venus for faster and efficient hashing?
00:37:11.010 - 00:38:06.850, Speaker B: This is an interesting thing. We are definitely looking into this and would like to explore this more. I think for Miten design specifically, as the way it stands now, I'm not sure there's going to be a ton of benefits to Binius, but again, this is to be explored. And the reason is one of the benefits of binius is that it allows you to reduce this embedding overhead, where if you have, let's say, a field element, but you're only using a small portion of the field element, let's say, one bit out of the entire field element, Venus allows you to really optimize and save on that. In the design of MitinvM, we actually almost don't have such situations where only a part of the field element is used. Overall, I would say probably less than 10% of the columns, or about 10% of the columns are kind of like binary, but 90% use full field elements. And again, this was part of the design, so we could realize some benefits.
00:38:06.850 - 00:38:13.010, Speaker B: But I'm not yet sure how much of the benefits we would get from venius. But it's a very interesting topic to explore.
00:38:14.470 - 00:38:19.350, Speaker A: And is there any similarity between maiden and Zike shrine?
00:38:20.410 - 00:38:25.160, Speaker B: Unfortunately I'm not super familiar so I would not be able to answer the question.
00:38:25.610 - 00:39:13.320, Speaker A: I also don't know can. And the last question is what would be the requirement as a dev to build on maiden? And maybe you mean the roll up with it and then maybe we can answer it at the very end of this presentation. Basically just check out the repo. And at the moment you need to code in Mitner assembly, which is also okay to do. And in two months we will have a compiler. Hopefully very quickly I will go to the second part. What is the militant roll up and where do we use this mind vm now? And then we talk about the transaction kernel basically.
00:39:13.320 - 00:40:48.226, Speaker A: But yeah, like what problem does the mind roll up want to solve? The problem is that blockchains today, and also some Zke evms or roll ups, they have the same problem that block producers, they execute all transactions in a block and then all other nodes need to reexecute all transactions in a block. So basically you have the problem that all nodes need to keep track of the entire state, which leads to state bloat and also to execution bloat. Like if all transactions need to be reexecuted by many nodes at the same time. And this actually is solved, as we think, with client side proofs, or when the user generates its own proof of its own state transition. And that obviously gives you privacy, which is one of the unsolved problems yet in the blockchain space. But it also gives you high throughput and even more like the more people use it in a private mode, so they prove their own state transition, the higher the throughput will be, because you can create these proofs in parallel, at least in a minute design. But our solution to this state bloat and executing bloat problem basically, or to this scalability problem of blockchains, is as we think that users generate their own proofs.
00:40:48.226 - 00:41:31.886, Speaker A: And as Bobbin said, this was one of the reasons why we designed the mitinvm as such, is that it is efficient for users to do these client side proofs and to do blockchain operations in the maiden vm. But you cannot simply use an EVM and add client side proofs to it. So you need to change quite a lot in the execution and state model. And this is what I will talk about. Now, basically maiden is inspired by the actor model, which is used for high performance databases. And you can imagine actors in the actor model as state machines within boxes. So they have a little inbox and they get messages from other actors.
00:41:31.886 - 00:42:34.630, Speaker A: And these messages, they trigger state changes. And then like a state change can result in sending out new messages to other actors. And these messages can be produced and consumed asynchronously. And it would be super nice if a blockchain, like in a blockchain, you would have the same basically then you would have this asynchronous message passing and also at the end, parallel transaction execution. And so in maiden, we implemented the actor model, such that you have accounts like, you have them at the moment in ethereum, because they are very good for smart contracts. And these accounts, they can send notes to each other and basically accounts they still like as an ethereum, they maintain state and they expose interface methods. So every account on maiden is a smart contract.
00:42:34.630 - 00:43:29.480, Speaker A: And these accounts that they send nodes to each other, these nodes can carry assets. And like in this case account, one creates a node that contains three matic and he wants that account two consumes this node and in doing so get these three matic. But we need two transactions in maiden to facilitate this asset transfer. And this is different from other blockchains. So basically we have a first transaction where this node is being created, and a second transaction where the node is being consumed and like, as opposed to ethereum, for example, where one transaction always involves at least two accounts, Alice sends something to Bob. In maiden, this is different. Every transaction always involves only one single account.
00:43:29.480 - 00:44:06.050, Speaker A: But this is how we imagine maiden in our mental model. Basically, these accounts send notes to each other, and in doing so they trigger state changes. And one state change is also that you get or you have more tokens after state change, or you have less tokens. And this little video is how we imagine these accounts communicate with each other. And accounts in maiden. Basically, as I said, they are all smart contracts. They have code and storage.
00:44:06.050 - 00:44:48.130, Speaker A: The code is like you can think of as an Ethereum smart contract. And the storage is also Ethereum. Smart contracts have the storage. And one difference is that all assets in a midnight account are stored in the account itself, again, as opposed to Ethereum, where you have only eth as associated with this account. And all the ERC 20 tokens are stored or being tracked on an ERC 20 contract. In mine, all assets are always stored in the account itself. So you don't need to change two contracts, for example, to send out or to create a node with an ESC 20 token.
00:44:48.130 - 00:45:43.250, Speaker A: And we also have two native asset types like fungible and non fungible assets on mitin, a MIT node like these messages that the account sends to each other. They have a script. And this script basically needs to be executed at node consumption. So it defines rules how this node can be consumed. And basically anyone can execute a nodes script. Like anyone who can execute this node script without failing, they can consume this node and in doing so create a proof for it, because we execute these in the transaction kernel which runs in the mine vm, as you will see. And these nodes can carry multiple assets and they also have inputs that you need to put before you execute the node script into the advice provider.
00:45:43.250 - 00:47:03.790, Speaker A: But yeah, the main point in this section is just that we needed to redefine what a transaction is in maiden in order to accommodate client side proofs. And what we want is that our accounts can create a proof of their own state transition and then do not need the information from the other accounts. So a transaction is always executed against a single account so far, and it can consume zero to 1096 nodes, I guess is the current number. And it can produce zero or around 4000 nodes in one transaction. And this mental model of a transaction which helps us to solve state load and execution bloat in the blockchain and helps us to parallelize transactions. Basically this transaction is now being executed as a program in the maiden vm. And in doing so, like for every transaction in maiden, there's always a stack proof that can easily be verified from the Miten network or at the moment in the Miten operator running in the Miten node.
00:47:03.790 - 00:48:12.190, Speaker A: Are there any questions to the very quick rundown of the maiden roll up? Then let's go to the transaction kernel. So this is what Bob and showed at the beginning, right? So we have a zero knowledge virtual machine. It has an initial state like a public input. It has a program as an input and secret input, like a witness, how we call it, and it produces a final state or a commitment to a final state and a proof. And the transaction kernel program basically looks in this image like this. So as a public input we have data and state commitments, like commitments of the account that we want to execute a transaction against, for example. And as an output we get again commitments and all the data, like the blockchain data, the account data, the node data we provide as sift inputs.
00:48:12.190 - 00:49:14.420, Speaker A: What we provide as program input basically is the whole transaction kernel program. And what we get out is a proof that can be verified by the network of this one state transition that the account wanted to prove as inputs. Basically as public inputs, we have commitments to the data. And in our case we have the block hash of the last known block, we have the account id, the initial account hash, so we can hash the whole account to reduce it to a single hash, to a commitment. And we have a commitment to the nodes that are being consumed in this transaction. And in the advice provider or secret input. We provide the last known block data, the initial account data, and the input nodes data.
00:49:14.420 - 00:50:33.870, Speaker A: And then the advice provider can always grab the necessary data and unhash these commitments and compare them. And in doing so, check that everything is correct. The transaction program itself has four phases. Like in the prologue, the kernel basically passes the transaction data and sets up the root context. That means that we have like, it puts all these, because the mynvm is a stateless virtual machine, it puts all the necessary information into different memory slots, and it checks basically that the nodes that are being consumed in this transaction are in fact somewhere in the blockchain or were already recorded in a blockchain. And if all of this is correct, like the product does a little some more things, but this is the main thing, basically. And then it starts to process the node scripts, like these scripts basically that are defined on the node, how this node can be consumed.
00:50:33.870 - 00:51:52.214, Speaker A: And each node script is then being executed in a different memory context, which I will explain in a second. In an isolated context, we can't execute either of these nodes, and if all of them are successful, like an optional transaction script is being processed, which can be used to sign the whole transaction, for example. And then in the epilogue, the fourth phase, the transaction kernel checks that certain rules are adhered, meaning that did the nons increase by at least one, and were no assets destroyed or created in a normal transaction. And then if everything is correct, it outputs commitments to the new state of the account and to the output nodes that are created in the transaction. But let's look at each of these steps one by one. So basically we have the prologue, and this is the code, as you can see. And it starts with processing the global inputs, the block data, the chain data, the account data, and the input nodes data.
00:51:52.214 - 00:52:54.410, Speaker A: And this is exactly what I said. So basically it tries step by step to unhash the inputs, like the commitments that we gave via the public input, and to authenticate the data. And if everything is correct, or it stores them then in the memory. And what it also does is it's building a single vault containing all the assets of the inputs. So it puts the account assets together with the node assets in a vault, and then it verifies that all the input nodes are present in a nodes DB, for example, in the second step here, it recomputes the block hash, like the block hash we provided via the public inputs at the beginning. And here we also provided in the advice provider all the data such that it can be recomputed by the block data. And if these don't match, then the transaction kernel execution will fail.
00:52:54.410 - 00:54:16.530, Speaker A: It also recomputes the chain root MMR to check if all the nodes are recorded in there. It also checks if it's a new account or not, like if this account that executes this transaction is already registered or not, and recomputes the current account hash or like the initial account hash, and then it authenticates the nodes, computes a node hash and a nullifier. And a nullifier is just the information for every node that we need to track if it is already consumed or not. Yes, I just answered the questions. I don't know why this is always like one question is the mitro transactions format is not EVM compatible, is that right? Could you please describe sequencing in a short term? Yeah, mitron roll up transactions are not EVM compatible. That is correct. How would you sequence them? Sequencing? You mean that we order them in a block? If so, then we have one centralized node running at the moment.
00:54:16.530 - 00:55:04.450, Speaker A: In the future we want to decentralize that as well. And in mine you have two ways how you can execute a transaction. You can execute a transaction locally or in private, and then you would only submit a transaction proof to the network. And you can also let the network execute or the network prove your transaction. And then sequencing would be more important in the network transaction case, because if not, then the proofs are being isolated in a sense. But at the end there will always be a transaction proof for every transaction, and they will then be batched together in batches and then into blocks.
00:55:05.270 - 00:55:55.006, Speaker B: Yeah, I think in my, basically, just to state what that makes it indifferent almost for a big part of transaction sequencing almost doesn't matter because all the communication is asynchronous. So one transaction is independent from another transaction involving a different account. It is dependent on the transaction involving the same account. But that's kind of like the only place where the sequencing come into becomes important. And we expect vast majority of transactions to be kind of like casually independent of each other, because you can produce a node and then when this node gets consumed is not important. It could be consumed many blocks later or maybe even a year later if needed. I guess the term sequencing could mean different things in different contexts.
00:55:55.006 - 00:56:01.960, Speaker B: In our context, if you think about just arranging transactions in the block. For most part it doesn't really matter.
00:56:02.970 - 00:56:35.854, Speaker A: But it could also mean, and it can also mean that the executing account can consume many nodes at the same time, for example. And then it could also depend how these nodes are being ordered in the transaction. Sequencing is a super interesting question in maiden, but yeah, might be too long here to answer that. Okay, I tried to catch up with the questions. A transfer requires two transactions. These transactions happen in the same block. That's the cool thing.
00:56:35.854 - 00:57:09.500, Speaker A: So they don't need to happen in the same block. So I can create one transaction and a year later or so Bobin can consume the node and then the asset transfer is complete. And yeah, that has an impact on composability, but also that might be too much, but they don't need to be in the same block. One other question, does the Mindvm employ Starks? The MindvM runs on proving libraries Winterfell, and this runs on starks. And I think at the very end.
00:57:10.270 - 00:57:32.420, Speaker B: Yeah, so we do use Starks as a proving system and currently Winterfell is Dominic pointed we will probably move to plonky three at some point down the road. But yeah, we probably will stick with starks unless investigations into benius and other things will result in. The outcome will be that it's much more performant and then we'll migrate to a different probing system.
00:57:35.030 - 00:58:34.680, Speaker A: Do I understand correctly that double spending node is avoided through the nullifiers? If so, what gives you the ordering? In case there would be a double spend of nodes? Yeah, that's exactly correct. Like double spending is like we use the same system as zcash or aztec, and the nullifier check basically happens at the block production level. So because you can do client side proofs, and these happen as synchronously, in theory, you can create a valid proof of a node that is already consumed, but you don't have the correct update yet. But you would not be able to add this proof as a valid state transition into a block at the individual level. There also will be race conditions, but you cannot do the double spending check. But this happens on the block level.
00:58:36.250 - 00:59:19.926, Speaker B: Yeah, you can maybe say that there is an element of sequencing on the block level because this is where you do the final check when the block is being created by the block producer, that any node that goes into this block hasn't been spent previously, and this involves the checking of the nullifier tree. And also any nullifiers that were created by transactions that are being put into a block get recorded in a nullifier tree. So there are a few updates that are happening at the time of block production. One of them is updating a nullifier tree. The other one is updating, let's say, account states. Because you do say that this account state changed from x to y, you may not know the actual underlying details of the account. You'd only know that hashes of the account change from x to y.
00:59:19.926 - 00:59:31.580, Speaker B: But you do need to record this at the time when the block is created that the state changed from x to y. And obviously there's checks there to make sure that if you're changing state from x to y, that the previous state was x and not zo. For example.
00:59:34.350 - 00:59:48.990, Speaker A: Another question like can the nodes contain proofs of off chain execution? If the nodes can have proofs of off chain execution, then the VM does not need to do any proving, but just verifications and recording.
00:59:52.370 - 01:00:28.250, Speaker B: In a way the nodes don't contain. Yeah, a transaction is a proof of something being executed off chain. A node itself contains a script that needs to be executed to consume a node. So there might be like some terminology alignment that is needed here. But yeah, I mean, a transaction is a proof of off chain execution that you've executed some transaction that consumed x nodes, produced x node, y nodes, and updated account z from one day to another. And that could be fully done locally by the user.
01:00:30.590 - 01:01:00.982, Speaker A: But also that might be too much for today. But there are two ways also to store nodes. And then, so in theory, the blockchain doesn't even know the node, but just like it tracks only the commitment to a node and then node execution could be like everything of the node could be completely off chain as well as executioner. Okay, next question. The first transaction is creating the node. Now the node is like Utxo. That's correct.
01:01:00.982 - 01:01:39.042, Speaker A: The second transaction will happen only when I decide to spend it or when I will want the funds to be in my account. Yes, like the second transaction can happen. We have a Utxo model. Basically we have a hybrid of account model that is being used in Ethereum and the Utxo model. This is how we track state, basically. And now I cannot read the second part of your question, but basically you can decide when you want to consume a node or like if it's a public node. Anyone can basically consume the node if the scripts allow.
01:01:39.176 - 01:02:12.940, Speaker B: So yeah, I think one cool thing to point out is that transactions can consume many nodes, and those nodes could have been created at various times. So for example, I have an account and people are sending a bunch of notes my way. I don't have to consume them right away. I could wait and consume all the incoming notes once a week or once a day, whatever I want to do. But I can execute one transaction that will consume, let's say 100 notes that have been sent to me over a week, over a period of a week. And that actually would be a more efficient way to do it. I would pay lower fees for doing that.
01:02:12.940 - 01:02:52.566, Speaker B: And there are different other models on how this could work. But this is like one of the cool things, that you are not forced to consume the nodes as soon as they are created. You can choose arbitrarily when you want to do it. And from a privacy standpoint, by the way, the nullifiers. There was a question about nullifiers, basically one of the reasons we use it to prevent double spend. But more importantly, the reason why we went with a nullifier design is very similar to its original intention, is that it breaks linkability between the produced and consumed nodes. So when you consume something and you do it, execute it locally, you actually just output a nullifier.
01:02:52.566 - 01:03:10.750, Speaker B: But whoever verifies the proof doesn't know which node you have consumed. So basically your transaction that moves consumes nodes basically says, okay, I've consumed some nodes out of the ones that exist, but it's not clear which ones exactly am I consuming. So that is fundamental to preserving privacy.
01:03:13.490 - 01:04:13.502, Speaker A: Maybe because we're already over time, but basically because the mind VM is stateless in that sense, that we need to put in all the data and the whole account at the beginning of the transaction. And then we store everything in memory and we need to define the whole memory layout. Basically for every transaction to consume a certain amount, like to be able to consume a certain amount of nodes and to be able to output a certain amount of nodes. And this is our memory layout, which I found just interesting. Like when you have this mine vm basically, and you put all the data in, then you just write it into memory in mine assembly, and then you can read that memory. But I think there's no time to show all of these. The next part, if all these checks, initial checks were happening, then we execute these node scripts in a loop.
01:04:13.502 - 01:05:29.420, Speaker A: Basically this is how Mitner assembly looks like. So we prepare the node and then there is a function that we call, didn't call, and then basically this calls, as Bobin explained before we get out a hash of a masked program, basically here on top of the stack. And with this sync call, now we can execute this script and we execute it in a new memory context. And this is because we don't want unwanted memory access of no scripts that they can somehow tamper with the account storage. So we basically have different memory contexts, and I can maybe show that that is too much. Basically this is like the kernel root context of the kernel program is where it starts. And when we are at this din call procedure or function, basically we switch into a node context and then we only have access to the top 16 stack elements, but we don't have access to the memory that we finally laid out before.
01:05:29.420 - 01:06:19.430, Speaker A: But we can always read some values via the kernel API still from the node also in the node context. And then even if we want to add assets like the node cannot do that immediately, we need to do that in a different context, in what we call an account context. Basically the account needs to expose procedures to receive assets and then the node can call them. And in a simple asset consuming node example here, for example, we already have three contexts that we need to adhere, and in every context we have our own memory layout.
01:06:19.590 - 01:07:11.900, Speaker B: And I think again to point out that this ability to handle multiple contexts at the vm level, so this is not a program that this is built into. The VM where you can create multiple contexts is, I don't want to say unique to my end, but one of the like, I don't think I've seen it anywhere else, at least not at the same level of kind of like integration. And this is super helpful for us for the things we are trying to achieve and especially like being able to instantiate the vm with different kernels that have different functionalities. We are right now covering a transaction kernel, but we also have a block kernel, for example, that is responsible for proving and validating the entire block. This is only for transactions, for example. And in that case you still use my vm, you just instantiate it with a different kernel, and that gives you almost like a brand new operating system that is running on top of the VM. It's very flexible in this way.
01:07:15.890 - 01:08:30.390, Speaker A: The transaction script is then used to sign or to authenticate a transaction. Let's skip this. And what we get out at the end on the stack, this thing in blue down there is the transaction script route. So after transaction script that we executed, we have a commitment to all the output nodes that were created and the final account hash, and together with the proof and the inputs, like only the global inputs that we provided at the beginning, like these four on the block hash account id, initial account hash and nullifier commitment, then we can already send it to the mitin operator, and the mitin operator doesn't need to know what is the actual state of the account or what were in these nodes actually to be able to verify. Again using the mitinvm and batch these transaction proofs together into batches and blocks. Yeah, we are already, over time maybe the two last questions. One question is, is this similar to resource oriented programming? I think this was about the context switchings.
01:08:31.850 - 01:09:15.060, Speaker B: I think there are some similarities. I think the closest that I can think of is like I don't know how much people are familiar with a component model and what is trying to be built at the top of webassembly. There are some similarities with the component model where components kind of are independent execution environments that interact with other components. So we actually did this before that and it's not exactly the same, but it is similar. I think this separation of context in kind of different components. In our case we have components like every time you create a new memory context, you can think about it as a different component. In this case we have like three components interacting with each other, kernel, node and account.
01:09:15.060 - 01:09:37.500, Speaker B: And they are kind of distinct and have different ways of. For example, a node cannot call a method on the account that doesn't exist, and this will be enforced by the kernel. So like you can't say if the account method does. If the account interface does not expose a method to, let's say, do something with the assets, then the node would not be able to call it just because the kernel would not allow it.
01:09:41.310 - 01:09:45.390, Speaker A: Should we answer the last question? Okay, let's wrap the last one.
01:09:45.540 - 01:09:45.902, Speaker B: Sorry.
01:09:45.956 - 01:09:55.470, Speaker A: Yeah, let's wrap the like, what kind of use cases does the MindvM aim for? What are you better or worse than some other ZK vms?
01:10:01.650 - 01:10:42.590, Speaker B: Basically what I mentioned in the beginning, we are trying to optimize MitVM is a general vm, but we're trying to optimize it for a specific rollup. And the goal of Miten roll up is to allow this private blockchain, blockchain with private smart contracts which can have more kind of parallel transaction execution and most importantly client side proofs. Like this is the use case that we're going for and it unlocks a lot of things. Privacy is one, but also you can think about running computations that are very long running and still put them on a blockchain, fairly straight manner. But yeah, MitenVM is optimized for Miten rollup and Mitinroll roll up wants to have this parallel transaction execution and private smart contracts.
01:10:43.250 - 01:10:54.010, Speaker A: Excellent. But you can check out our examples and then I think you guys sent a bunch of links in the chat, so yeah, feel free to check them out. Thank you very much, Bobin and Dominic.

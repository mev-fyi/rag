00:00:08.680 - 00:01:07.835, Speaker A: All right. Hi everyone, My name is Marcin Kosteva. I'm the CEO at raylabs and today I want to talk to you about formal verification of ZK circuits and our approach to it and how it can also enrich your development experience beyond just the ensuring security of your systems. So formal verification, what is it? How do we do it? So formal verification is the use of specialized software to reason about programs. We typically use proof assistants like Lean or coq, soon to be called ROC because of the obvious reasons. And it's already used in many critical industries. So like Airspace or Automotive, they put their most critical systems through formal verification to make sure that, well, planes don't crash.
00:01:07.835 - 00:01:46.725, Speaker A: And it's gaining some traction in ZK already. So there's been some recent, very exciting results. There's been the announcement of a collaboration between zksync and nethermind on verifying their on chain verifiers. We also did some work with worldcoin. For example, worldcoin circuits for state management are now formally verified. We know that there is no funky business going on in the circuits. The typical process is audit like, meaning the team freezes the code base, they send it off to a formal verification shop or a formal verification plus an audit shop.
00:01:46.725 - 00:02:22.495, Speaker A: They look at the code, they write some proofs, the proofs verify, we are done. My main point of this presentation is that you should do it in house and you should integrate it into your development experience. So it shouldn't be an audit, it shouldn't be a one off. It's something that you should have running on your continuous integration server. It's something that you should be thinking about all the time. And I will try to convince you that this also gives you some additional tools that are sort of missing in the current landscape. So you can get this two birds with one stone situation here.
00:02:22.495 - 00:02:58.591, Speaker A: So let's start with what a circuit really is and how it works and how do we build them. So one part of it is the weakness generator, which is a normal, well behaved program. You write some code, the code outputs some numbers. It's all deterministic, all nice. Also, all of it is irrelevant for security. So this is almost like a side helper kind of program that isn't really checked cryptographically. The thing that is checked cryptographically is the constraint system, which is a bug of equations.
00:02:58.591 - 00:04:01.435, Speaker A: And all of those equations have to be satisfied simultaneously. The weakness generator is a tool to instantiate the variables in the constraint system. And the tooling that we use typically pretends that they are the same thing, right? So if you use Circon for example, or Noir or gnar or some DSLs like this, you will write everything once and then the tool will output both the weakness generator and the constraint system. This has some problems because those are two very different paradigms, right? Like a bug of equations that do not necessarily have a unique assignment is a very different beast from a program. But obviously most of us are developers, so we are trying to make everything fit into the mold that we've been trained to work within for years. So let's look at a quick example. So binary representations, the first food gun NSDK developer encounters in their life.
00:04:01.435 - 00:04:55.111, Speaker A: So the problem is get the binary representation of a number. The witness generator is what a developer would do. So the if number on the on the output is some bit tweedly magic extracting the, extracting the if bit from the input, right? This is great, but we are working with bags of equations over finite fields. We don't really have access to fast binary operations. So what we do instead is we invert the logic and we just say I will be given a bag of numbers and I'm going to output some equations that these bug of numbers has to satisfy such that it has to be the binary representation or foreshadowing a binary representation. They are not unique, not always at least. So the constraint system is just a bunch of assertions that every output bit is really a bit.
00:04:55.111 - 00:05:40.025, Speaker A: So the number times one minus the number must be zero. So the number must be zero or one. And when you run the binary reconstruction on that array you get the original input, so that's the property. And this split is problematic, it's non deterministic. So this can lead to issues if you assume wrong things. For example, if you assume that this has a unique solution, you may have some problems. And examples of this are actually vulnerabilities I found in both Gnarc and Noir at this point, where some comparison operators assumed the uniqueness of binary representations.
00:05:40.025 - 00:06:21.931, Speaker A: And now I can prove that zero is greater than one. And it's really easy to prove that. And the other problem one pertaining to tooling is that there is no way to interact with the constraint system directly if you use any of those DSLs. The way it usually works is you just try to write tests using the weakness generator. But that sort of defeats the purpose, right? Because if I'm using the weakness generator, then I'm assuming a unique solution. So there is no way to play with the constraint system try to break it. Actually what I'm Arguing for is a sort of repl where I can just look at the constraint system and try to break it.
00:06:21.931 - 00:07:00.043, Speaker A: And I will show you how formal verification can actually give you that missing developer tool. So all of our work is happening in Lean 4, which is first of all a dependently typed functional programming language. What that means for people that are not in the programming language community. It's a functional programming language. Dependent types means you can really do a lot on type level. So like think generics, ingenerics in generics kind of stuff. It's also an interactive proof assistant, so you can write proofs about programs and about mathematical structures.
00:07:00.043 - 00:07:29.985, Speaker A: You can join the two words together very smoothly. And it's interactive. So the way you write it is I will show you later. But you get a tiny window that tells you this is what you need to prove. Then you write some incantation that will hopefully move the proof forward and you get, okay, here's your new goal. So this can really be used as a repl for theorems, a REPL for logic. And also all the proofs you write are code, which comes with all the niceties that code really has.
00:07:29.985 - 00:08:10.759, Speaker A: They are maintainable, they are collaborative, they are inspectable. So the other side of formal verification is using SMT solvers, which are really like those magical black boxes that either prove your theorem automatically or. Or they fail awfully and there is nothing you can do. In this regime, we are able to edit our proofs, we are able to nudge the prover in the right direction. So let's look into how we actually model arithmetic circuits in Lean. So first of all, we will use the proposition type. PROP is a shortcut for proposition.
00:08:10.759 - 00:08:56.065, Speaker A: So that type of logical statements, so our logical statement will become a huge proposition that needs to be proven. We also will use continuation passing style for composing different constraints, because you sometimes want to have a sort of abstraction of a function, right? So you want a subset that returns a value. We will use continuation passing style. So really, callbacks for composing larger theorems like that. And we will need two gadgets. One of them is unconstrained. And unconstrained is just using existential quantifiers to produce values out of thin air.
00:08:56.065 - 00:09:37.569, Speaker A: I'm just saying that A exists and A will satisfy the later builder, or like it will have to satisfy the continuation of the builder, the callback. But I'm not saying anything else about what A is. So this is a great abstraction for the bag of equations model, right? Because the equations do not give you assignments by themselves. They just Tell you, this has to be satisfied. And we also have an assert which will take a proposition and it will assert it. So it will just end it with the rest of the builder. Okay, let's look how we can actually use this to do something.
00:09:37.569 - 00:10:20.115, Speaker A: Let's go back to binary representations. So the first definition we have of a sub circuit is going to be unconstrained bits. So you can see on the first line I'm oh, also this is using DO notation which is like a syntactic nicety. If you are into programming languages, it's a monad. If you are not, then it's syntactic sugar to make it all nicer. So line one, I'm just producing a vector of field elements of length L out of thinner. I'm not saying anything else about it, just that and then my binary representation for F is going to be a bunch of unconstrained bits.
00:10:20.115 - 00:11:05.305, Speaker A: Oh, sorry, I also forgot to mention the second line of that function. I'm asserting that for all indices in the vector, the number is either 0 or 1. So this is the first half of the binary representation constraint system. And then binary rep, it takes a bunch of unconstrained bits and then it asserts that F. So my input to this function is the sum of is the same as the sum of this vector zipped with the vector of powers of of two. Is this definition clear? For now, I will take the silence as a yes. So we now have this.
00:11:05.305 - 00:11:42.271, Speaker A: Let's now see how assignments to the circuit correspond to proofs. So our constraint systems became theorems or became propositions. They become logical statements. Now, what does it mean to assign a circuit? It means to come up with a proof for that logical proposition for a particular set of inputs. So assignments will give rise to proofs. On the other hand, if I prove the logical statement, I know that an assignment exists. We need to be a bit careful with the notion of existence here.
00:11:42.271 - 00:12:42.015, Speaker A: So I can sometimes prove that something exists non constructively and then I cannot actually extract a weakness, right? So it's very useful that we actually have the weakness generator output by the dsl, right? Because that is the constructive lag of it. So just to give you an intuition of what I'm talking about here, let's say I have a circuit that asserts that I know of a hash collision in ketchup. I can prove non constructively just by accounting argument that this exists. Therefore this circuit definitely is assignable. Nobody knows how to actually assign it, but the assignment exists. So you need to be a bit careful when you think about it, but this doesn't compromise the security properties, it just means that you can sometimes prove properties for which you couldn't actually extract an assignment. And interactive proving is now going to be our repl for interacting with constraint systems.
00:12:42.015 - 00:13:34.283, Speaker A: How does that work? Let's go back to the example of binary representations. So I have this run circuit which takes the callback based builder. I'm instantiating my field to be numbers modulo 17. So the Prime Field FP17 and I'm going to be looking at binary representations of length five for the number one. And you can see that as soon as I type this magical by here, Lean is going to give me this pop up with my current goal. So this turn style like this sideways T, it tells me this is what you have to prove now. And now I'm going to be doing some incantations in the proof script to move this goal forward.
00:13:34.283 - 00:14:12.615, Speaker A: So the first is simplification. So what I'm doing is I'm just unfolding some definitions. SIMP stands for simplification. The name was created before it was a meme. So yeah, simplify those definitions and I get a new goal. And the new goal is there exists an A which is a Vector of, of length 5 such that for all a, they are all 0 or 1 and the sum is correct. Right? So once again rehashing, rehashing the same example now it gets automatically inserted for us by Lean.
00:14:12.615 - 00:14:53.745, Speaker A: So I can now just come up with an assignment and I can say exists, which is. I'm just going to give you the example directly and I give it a vector of 10000. That's a great binary representation for one. But now I can also be malicious here. And this is where my sort of red light should pop on. This also works. This is 18, right? And the natural number 18 or like the binary representation for 18, this is also a great binary representation for 1 if you are working module 17.
00:14:53.745 - 00:15:39.831, Speaker A: So this is how you can shoot yourself in the foot if you are not careful enough. And this I will tell you from my previous experiences that this is something that is really, really missing from most existing DSLs. So I actually found this bug in different places. For e.g. in Gnarc, it's really difficult to show them that there actually is a bug. So in order to inject the wrong witness generator, I actually had to fork the tool Mac with the witness generator and then generate a proof on the like generate a circuit, the constraint system on the original version of the tool. And then I had to Fork it.
00:15:39.831 - 00:16:06.653, Speaker A: I had to change the weakness generator and show them that I can use this forked version to actually inject something malicious. So this is much easier, right? Like I had an idea for. Okay, I can cheat here. I can just show that this idea actually works. This is a valid proof. So really we are achieving the goal of Lean becoming a REPL for constraint systems without weakness generators. So let's move on to a more involved case study.
00:16:06.653 - 00:16:47.575, Speaker A: So this comes from work we've done with Light Protocol, which is like a ZK compressor for Solana. We were auditing their circuits and they use this definition of a comparison. So assert is less. You subtract the two values, then you add two to the power 248 and then you check that the result is less than two to the power 248. This is a very good way to do a comparison because range checking a value is cheap. Comparing two values directly is not cheap. So this is like a good proxy for that.
00:16:47.575 - 00:17:39.899, Speaker A: Can you see why this works? If A is larger than B, then when I subtract, this is going to go over two to the power 248. So the only way for this to actually be smaller to 248is if this is negative right? Or infinite field, a very large field element that is close to zero from the other side. So this works great as long as all the inputs like A and B are checked to be 248 bits long. If they are too large, you get an overflow. You can actually break this. So they have to both be range checked. The client didn't really know that, but they used it for a sort of double check or like a range check.
00:17:39.899 - 00:18:07.825, Speaker A: But I'm not using that term because of the name collision for like a sandwich check. So they wanted to check if A is less than I is less than B. And A and B were values that were already publicly known. And we knew they were always going to be less to the power 248. But I was not. So my first thought got them right. Like they are using arrange check wrong.
00:18:07.825 - 00:18:33.771, Speaker A: Here I go. This is an example of assert is less, p minus 20. P is the field I'm working in. So this is a huge, huge number because this is happening on the BN254. So this is like a huge 254 bit number and I'm proving it's smaller than 10. That is definitely not what they've intended. So hooray, I got them right.
00:18:33.771 - 00:18:59.445, Speaker A: I got a very nice finding to write in the final report. It's broken. We saved you. So I'm trying to construct a counterexample for the whole thing and now I'm cooked. It's actually impossible. This thing actually works. And I can use Lean to prove that the first comparison acts as an almost range check.
00:18:59.445 - 00:19:56.405, Speaker A: So in the first comparison, if the A is already range checked and it's a bit of a weak range check for composability, later I can know that my assert is less implies the arrow is an implication that first of all A is less than B, as expected. So I don't actually have to check the right hand side parameter, I only have to check the left hand side. But I also know that the right hand side is not too big. I know it's at most a plus two to the power 248. So this is an accidental range check, almost. So I can then prove that the second range check is now safe, the second comparison. So actually the double check, if I do it twice, right? So I go assert is less low with value, and then assert is less value with high.
00:19:56.405 - 00:20:32.691, Speaker A: I actually get what I want, right? I get the semantic comparison that I really wanted. So it's not a bug, it's an ingenious optimization. It's a feature. I've proven it's a feature. But we should also discuss if it's really a good idea to have this feature in your code base, right? Like, none of it is happening in the void, this is happening in a live system. People are probably going to change it. And this reasoning that I've put forth is kind of brutal, right? Like, it all hinges on the fact that 2 to the power 248 is still far away from the size of the field.
00:20:32.691 - 00:21:06.527, Speaker A: So I still have some leeway to go over with the rain checks, and it's not going to overflow. It's very brittle. What happens if someone doesn't understand the logic and just changes it? Well, then they've introduced a vulnerability to the code base. So this is the really, really awesome part, and this is why you should have this integrated in your development workflow and not just a part of the audit. You just put it on CI. Those proofs, they get automatically checked by the Lean compiler. So you extract your circuit into this.
00:21:06.527 - 00:21:59.365, Speaker A: You prove the theorems, you check the theorems on CI. If someone changes the circuit such that the theorems do not compile anymore, the CI fails, you are safe. So, so you can really do some, some crazy optimizations, right? Like optimizations I wouldn't really be comfortable with. Normally you can do them now with formal verification because they are now magically safe and they become much less of a food gun. So yeah, the missing bit of it is you need to compile from your DSL to Lean to make all of this possible. So we've built a tiny compiler, you can take your Gnarch circuits, output equivalent Lean definitions, then you can prove things about those Lean definitions, put it all on CI. We for example, have it in production at Worldcoin, where this is exactly the workflow and this is coming to new art this year.
00:21:59.365 - 00:22:52.171, Speaker A: I'm working on the next version of this tool. So you will be able to compile newer programs into Lean and then reason about them and hopefully with some nice composability. So we will be able to hopefully build an ecosystem of formally verified libraries and then if you depend on formally verified libraries, they can expose some lemmas that you can then use in your own proving, making this all very seamless. So the full workflow is you write your sequence in the dsl, you use some compiler, if it exists, if not, maybe you create it. That would be great if this ecosystem could actually grow. You use a compiler to emit Lean definitions and then you have at it, you poke at it, you try to break it, you prove things about it, then you check everything on the CI and then you repeat it. So this is the strongest point.
00:22:52.171 - 00:23:08.855, Speaker A: Don't just do it once, actually have it be a part of your development workflow. And that is all from me. Thank you. Thank you. We have some time for questions if anyone has any.
00:23:13.525 - 00:23:42.741, Speaker B: Yeah, super interesting talk. I've been kind of learning Lean for myself, so really cool to see this use case, I wanted to ask, to what extent have you thought about automation? I know that Lean has like a way that you can like define tactics and like some things are like, especially as a noob, like hard to prove or like if you haven't worked with like mathematical proofs. So to what extent is this automatable and or like some parts automatable of making these proofs? And to what extent have you looked into that?
00:23:42.813 - 00:24:19.795, Speaker A: Yeah, so the situation is a bit different for the GNARC tooling and the Noir tooling I'm working on. So for gnarc you're mostly reasoning about mathematics at this point. So just usually in automations come into play, you just do it as you would with any other program. With Noir it gets a bit more involved because like Noir has for loops and ifs and all of that. So we actually have some automation for that. So we have like a tactic that will convert your goal from talking about Lean back to talking about mathematics again. So that's.
00:24:19.795 - 00:24:21.231, Speaker A: Okay.
00:24:21.263 - 00:24:30.115, Speaker B: So little follow up question there. So you're translating the Noir code itself into Lean, not like the outputted Acer constraints or other things.
00:24:30.775 - 00:24:31.255, Speaker A: Yes.
00:24:31.335 - 00:24:36.879, Speaker B: So you're kind of trusting the Noir compiler that it's like basically compiling things correctly.
00:24:37.007 - 00:25:07.173, Speaker A: Yes, yes, I'm totally doing that. And that's a very interesting philosophical debate that we could have. So on one hand, yeah, it would be probably safer to work with Acer, for example, directly or in case of Gnarc, to work directly with the R1Cs constraints. But that gets very unwieldy. Those are. They just get very, very big. And it's difficult to actually maintain such a proof system.
00:25:07.173 - 00:25:25.735, Speaker A: Right. You cannot easily split it into lemmas. You cannot really say that, like you cannot really prove something for a subset of the equations because you just can't see them all at once. Right. So the added structure of. I'm actually working with a structured programming language. That's very helpful for Lean.
00:25:25.735 - 00:25:27.243, Speaker A: I see.
00:25:27.299 - 00:25:28.495, Speaker B: Thanks. Thanks a lot.
00:25:31.555 - 00:26:12.207, Speaker C: I have a question on that workflow. When it's integrated into a project where you say, okay, when you change the circuit, then you see CI breaks and the proof doesn't work anymore, so you have to fix the circuit. Maybe, But I think in practice what often would happen is that the proofs can still be patched. So usually it would break if you change the circuit, but it's still correct. I don't know. So do you have any experience with that, with the workflow like patching the proofs? Do you go in and do that for your clients or is there a workflow that these projects developed for how to do that?
00:26:12.391 - 00:26:41.445, Speaker A: So if we do it ourselves, we just try to go hand in hand. And yeah, when you change something in the circuit, the proofs usually break. So it's not like the structure of the proof typically kind of resembles the structure of the circuit. So even if you do a non. Like if you do a safe change, you still have to revisit the proofs and fix them. Kind of like a test suit, right? Like very deep unit tests or maybe even worse than a test suit because you're actually depending on implementation details. But that's the only way we can do it.
00:26:41.445 - 00:27:08.375, Speaker A: So, yeah, when we do it ourselves, we try to do it at the same time for both the circuit and the proofs for other clients. For example, lite protocol. That was an audit. Audit, like process. Not really an audit but sort of one of. We come in, we write the proofs for you. It happened in August and they haven't changed the circuit since, so I don't know what's going to happen there.
00:27:08.375 - 00:27:09.195, Speaker A: Thanks.

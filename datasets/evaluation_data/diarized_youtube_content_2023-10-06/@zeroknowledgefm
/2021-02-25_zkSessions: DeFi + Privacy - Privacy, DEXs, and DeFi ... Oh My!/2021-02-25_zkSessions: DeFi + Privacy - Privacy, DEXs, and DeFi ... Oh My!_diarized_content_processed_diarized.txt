00:00:06.290 - 00:00:17.270, Speaker A: I want to welcome Guillermo back. We decided to re record this talk because as you were giving it, you had a fire alarm going. That was as.
00:00:17.340 - 00:00:18.450, Speaker B: I mean, I thought it was exciting.
00:00:18.530 - 00:00:22.918, Speaker A: Yeah, it was exciting, however, and that really gave that rave beat that we were all looking for.
00:00:23.004 - 00:00:23.986, Speaker B: It's indoors.
00:00:24.098 - 00:00:41.040, Speaker A: It's pretty loud. That's the tricky thing, is it is hard to hear you, I think, otherwise telling you, but it was actually really hard to follow, and so we thought we would just give it a go and do it again. So thanks for coming back.
00:00:41.410 - 00:00:59.558, Speaker B: No, of course. Absolutely. It's certainly a party, to say, at least. But, yeah, hopefully, as exciting as it is to have a background beat, I think it's better for everyone involved if they can actually understand something of what I'm saying, because the slides might make no sense without it, but maybe not. I don't know. I have no. Cool.
00:00:59.724 - 00:01:09.820, Speaker A: So your talk, it's going to be about privacy, dexes, and defi. Oh, my. Which I am very excited to hear again, please do take it.
00:01:12.990 - 00:02:04.010, Speaker B: This actually follows Zach's talk almost in a purposeful way. I think it's very weird, but it turns out this is quite topically relevant for exactly what Zach was saying. So I guess originally I meant this to be kind of the contentious talk over the quarter as being like, oh, yeah, we have all of these things. Sorry, here's a bunch of stuff that you can't do. But I think a better view of this talk gives you can think of the space of defi overall as a graph, right? And Zach gives, you know, in some sense, there's a region of that which can be right. And I give a region of defi which cannot be private under most privacy assumptions. And then there's going to be some remaining region which fits in neither of those two camps, which we do not know if it's either private or not private.
00:02:04.010 - 00:03:17.118, Speaker B: So the idea is kind of to show that a lot of the primitives that we use, specifically these constant function market makers, like uniswap or balancer or unstable, cannot be private in their current incarnation and actually require quite a bit of thought to make them private in ways that doesn't completely destroy either the structure of constant function market makers or, more specifically, kind of the user experience. Okay, so I guess with that, we can start. So I'll do a very quick intro to constant function market makers, and I guess, more generally, amms, but I suspect most people are pretty familiar with Uniswap, but I'm going to give a much more generic intro where it turns out that the constant function, market maker itself won't matter. It just matters that it has some trading function that describes it. So, in particular, a constant function market maker is just a contract with some reserves of coin a and coin b, and we'll call them r alpha and r beta, but the specifics don't matter too much. And then the constant market maker is defined by the trading function, or the invariant, which we will just simply call phi. Right? And phi here is just a function of the reserves a and reserves of alpha and the reserves of beta.
00:03:17.118 - 00:04:29.434, Speaker B: And in this case, as we know, traders are allowed to remove some amount of coin alpha from the reserves or beta, so long as the function of the reserves remains constant, remains equal to whatever it was previously. So, as we all know, in the case of Uniswap or constant product markets, or whatever you want to call them, essentially we have that the function of the reserve is simply the product of the reserve. So the trader can trade with the reserve in such a way that the product of the reserves previously before they traded and the product of the reserves after they're traded is equal. It's not hard to show, but essentially it means that the price of alpha versus with respect to the asset beta, et cetera, is going to be equal to the ratio of the reserves. This isn't super difficult, and we'll see exactly what this corresponds to in a second. So the price of a constant function, market maker in general, can be kind of interpreted as the slope of the trading function. So here the blue line is the hyperbola drawn, which simply says, here are all of the points at which the reserves of alpha and the reserves of beta are.
00:04:29.434 - 00:05:17.154, Speaker B: Their product is equal to, in this case, two. Right? And so we can interpret the marginal price of buying an asset as essentially being the slope of that hyperbola at every point. So in this case, if the assets have reserves alpha equal to one and reserves beta equal to two, then essentially what we're saying is that the price of alpha with respect to beta is approximately two to one. More generally speaking, this is just a geometric interpretation of what the marginal price is. And we'll use this in a second to show kind of why privacy is not possible. But the idea is pretty simple, is that we're just going to take the tangent line as the marginal price. So more generally speaking, of course, our constant function here need not just be the product, it could be something like the sum.
00:05:17.154 - 00:05:54.690, Speaker B: And here is called a constant sum market maker, or m stable as well, which implements this essentially says, look, here is the function that has to remain constant, it's the sum of the reserves. Similarly, balancer gets a little bit more complicated, and it says something like the weighted geometric mean of the reserves has to stay constant. And Kerr gets even more complicated, right, where it's something like, it's some interpolation between the constant product market or uniswap and m stable. In this case, the interpolation is kind of nonlinear. So it's a little bit more complicated than just a simple interpolation. But the idea is kind of the same. It has a simple form for its function, phi.
00:05:54.690 - 00:06:42.398, Speaker B: The point here, though, is that the specifics of the individual functions don't matter. It simply matters that we can write an amm as its trading function. And the trading function has some properties, one of which is that the tangent of that graph that it draws is going to be equal to the market, to the marginal price of one asset with respect to another. So we can now finally get on to the more important question, which is, can we make it private? So here's the bad news. Sorry, I'm going to get this out of the way, but the answer is no. Well, more specifically, the answer is no, without actually implementing a bunch of major changes. So even if you have a pretty weak right, you're kind of screwed.
00:06:42.398 - 00:07:11.226, Speaker B: Sorry, I'm just the bearer of bad news here. I don't make the rules. The rules were made a few years ago when Hayden started Uniswap, and this is what the rules tell us. So we're going to consider an adversary in this case, eve. And Eve is not going to be allowed to access any external balances, right? So she cannot access the CFMM reserve. She can't access anything about CFMM, but she can read public data. So for example, she can query the CFMM and ask what the marginal price right now is.
00:07:11.226 - 00:08:02.800, Speaker B: And of course, check if a trade is feasible. This is kind of just normal UI stuff that says, look, I can go to Uniswap and I can see is the trade that I'm proposing feasible? And similarly, how much will that trade cost me? We'll also assume, of course, that she can interact with the CFMM contract in some way, in this case by checking if a trade is feasible. And she can potentially also kind of make a trade if necessary. And we'll assume that the CFMM trading function is actually known. So in the case of Uniswap, for example, we're just assuming that we know that the trades have to be such that the product of the reserves is equal to a constant, or whatever it may be. And here, Eve, our eavesdropper, simply wants to know Alice's trade. So here, Alice makes a trade, and Eve is kind of eavesdropping without knowledge of the exact trade, but she's looking to reconstruct what Alice did there.
00:08:02.800 - 00:08:40.314, Speaker B: So here's the result. If Eve happens to know when Alice trades, then, sorry, it's game over. You don't really get a choice on that. And the reason why is because Eve will know the price of the asset before Alice traded and after Alice traded. Right. And it turns out just, even if she just knows, also the existence of any one non zero trade that's feasible, this is going to give a very simple system of equations that eve can solve in order to exactly reconstruct Alice's trade. The thing actually that's kind of interesting about that is you might think that, oh, of course, you're given the marginal price, so that gives you a lot of information.
00:08:40.314 - 00:09:18.130, Speaker B: But it turns out, even if the marginal price isn't revealed, this is still really bad, because Eve can essentially approximate it by querying ever smaller trades. If you remember from calculus, right, the slope is defined as you take two points and you slowly make them closer to each other. What's the slope of that line? So here, the tangent hyperplane, which we care about is going to be the price of the asset at the current reserves R. Right? And so here's what she does. She takes a trade of size four, then afterwards takes a trade of size two. Then she's a trade of size one, choose trade of size 0.4, and so on and so forth.
00:09:18.130 - 00:10:08.822, Speaker B: And she can kind of approximate arbitrarily, well, what the price of the asset will be given. Just that she can check whether a trade is feasible or not. And even if she couldn't just check, if she has to perform a trade, she could still use it to approximate the marginal price of the asset. So, of course, this is all the bad news. There are some good news, and there are a few solutions that we can kind of take a chance at here. So what we're going to do is we're going to look at kind of where the proof fails, what does the proof assume, which kind of ends up screwing us in the end, and then see if we can somehow change the classic constant function, market makers or unisop or whatever, in such a way that the proof fails. So one example is that we assume that there's no randomness in our query, right? So the things that we see are the true things.
00:10:08.822 - 00:10:43.700, Speaker B: They aren't just like the true things with some noise. And the other thing that is really, really important is that Eve knows when Alice traded. This turns out to be, it seems like an unreasonable assumption, but it turns out to be very useful for kind of ensuring the solvency of a bunch of decentralized finance systems. But we want to look super into that, actually, with the knowledge of hindsight. Turun actually talks about it in the discussion section. So I'm going to use the knowledge of hindsight, or I guess in this case, what do you call it? The prescient knowledge or something like that. Knowledge of the future.
00:10:43.700 - 00:11:19.660, Speaker B: Yeah, foresight. Thank you. So foresight is 2020. Okay, so if we start with the first part, essentially it says, look, I can add noise to any one of Eve's or Alice's queries, right? So we're going to add randomness to the price that's reported by CFMM, or add randomness to what trades are accepted, or I guess, the values at which trades are accepted. So this will prevent Eve from guessing the exact marginal price. Right. And it turns out if you're kind of careful about it, you can show that if you choose the noise in the right way, then Eve cannot know the true price change.
00:11:19.660 - 00:11:56.386, Speaker B: There's a bit of a problem, though, and essentially the downside is that the noise that you need to add is approximately of the size of the trade that Alice makes. This could be very bad, right? Because at some point, someone's going to end up losing. If, for example, your noise says the price is actually lower than it should be, then the lps end up losing. Or if it's more expensive than it should be, then the agents end up losing. So this could end up actually being potentially very expensive for both traders or lps, again, because it's, roughly speaking, proportional to the trade size that we want to hide. Another thing you could do is you could change the order of the different orders. The order of the different orders.
00:11:56.386 - 00:12:30.130, Speaker B: That's a weird thing. But anyway, so we can batch the orders to the centralized exchange, and then if we just batch the orders and execute them all at once, then it prevents Eve from knowing what trade is. Alice's specifically. This is a few downsides. One is, it's important that the batch trade is much larger than Alice's trade, right? Because then, otherwise, Eve knows that most of the trade was Alice's in the first place, and so she can obviously reconstruct that. And the other problem is that it can be very slow in practice. If you need some amount of time to aggregate all the trays into one big chunk and then afterwards execute it.
00:12:30.130 - 00:13:20.226, Speaker B: This is potentially bad for price discovery or a bunch of other possibilities. So kind of the conclusion in general speaking is that privacy is really damn hard, right? Kind of. More specifically, what you get out of this is that the current implementations of CFMMs, as they are right now, just cannot be private. You can't just hide all the quantities that are available to CFMMs and then be like, okay, cool, we're done. Another problem is that we've talked about CFMM specifically, but the proof applies in many, many cases. Whenever you know the price impact function of a given automated market maker, decentralized exchange, or whatever defi primitive you want, you can essentially use the same argument to have Eve be able to tell apart Alice's trade. So there are some reasonable solutions, of course, right? And kind of one of them is this weird notion where you can add noise to the price.
00:13:20.226 - 00:14:03.658, Speaker B: That has its downsides, but of course it has its upside that it's private. And then similarly we can batch orders in the decks or whatever it is. And that also gives you kind of a reasonable thing, but with a slightly different trade off than just adding noise. And kind of the question that I want to pose very generally to the community is maybe there actually are better mechanisms. Maybe CFMMs, as they are right now, are just like simply not the best thing for privacy. Maybe there's slightly better implementations of CFMMs which kind of do a combination of a bunch of things that mostly preserve privacy in ways that don't degrade the user experience. This is totally not clear to me, and this is an obviously open research question, and all of these terms have even yet to be defined in any way that's reasonable.
00:14:03.658 - 00:14:35.814, Speaker B: But it is an interesting thing to think about and kind of finally, I would acknowledge the people you should blame in case that this presentation has either any typos was completely, entirely wrong, and it's true. And Alex, who were supposed to check it, I think they did check it, and in fact they got some messages about it. But my point is, you shouldn't blame me, you should blame them if you find some error in the presentation. And I want to give a huge shout out to the ZK sessions team, including Anna, for having put this whole thing together and for having me rerecord this after, for whatever reason, there was a fire alarm test going on right outside of my apartment.
00:14:35.942 - 00:14:48.560, Speaker A: Amazing. Very cool. Thank you so much for the re recording. What we'll do now is we'll probably cut it together with the actual questions that were taken from the day.
00:14:48.930 - 00:14:49.710, Speaker B: Sounds great.
00:14:49.780 - 00:14:53.330, Speaker A: So, yeah, I guess we'll do a little cut now. Thanks.
00:14:53.400 - 00:14:54.610, Speaker B: Sounds phenomenal.
00:14:55.510 - 00:15:00.610, Speaker A: Mikara asked, would differential privacy help with relaxing some of these results?
00:15:01.510 - 00:15:28.622, Speaker B: So, yes. So differential privacy will help. And this is kind of what I meant when I was describing the fact that you could add noise to the marginal price, or add noise to kind of what a reasonable, or what reasonable a feasible trade would be. So if you add noise there, it's kind of going to be much harder, obviously, for Eve to reconstruct the exact quantities because she's inverting some problem that now has noise in the input data. So it's going to have noise in the output data. I think that. Cool.
00:15:28.622 - 00:15:30.080, Speaker B: Hopefully that answers the question.
00:15:32.450 - 00:15:38.000, Speaker A: Shumo asked, do you think that the CFMM is here to stay?
00:15:39.330 - 00:16:36.100, Speaker B: Fingers crossed. I mean, it would be kind of interesting if it was. So CFMM seemed to meet kind of this weird niche in between order books, which are the classical, there a bunch of crazy papers published in the people won Nobel prizes over all of it and all this stuff. But hopefully CFMs are here to stay, because in a lot of ways they're much simpler, A, to analyze and B, to actually kind of run. So hopefully that makes some sense. And I suspect they will be, and maybe not in this incantation or in this instance of CFMMs, but in the near future, they hopefully move to potentially slightly more complicated CFMMs, where you tune your CFMM to specific circumstances, or you might add slightly more complicated components that make it perform better in practice. Potentially maybe not less impermanent losses, the wrong thing, but kind of less of the bad properties people have and more of the good properties that people.
00:16:36.100 - 00:16:45.560, Speaker B: So I guess there's a question here by Rahoul, which might be good to go ahead.
00:16:46.010 - 00:16:57.414, Speaker A: No, I think this is about the age of the attendees. I don't know if that's super relevant. Was there a different question? There's one. Privacy. Yeah. What does it mean?
00:16:57.452 - 00:17:25.646, Speaker B: So what is the french privacy? So here's a silly thought experiment. Differential privacy is you give a bunch of people a survey and you don't want to know. What you want is you only care about the average statistics. You only care about, roughly speaking, I think some people have roughly answered this, but you only care about the average price, for example, or you only care about the average of people's ages. Right. But you don't want to know any one person's age because it's bad for you. It's a liability for you to know any individual person's age.
00:17:25.646 - 00:18:06.560, Speaker B: So what you do is you tell everyone, here's a deal. I'm going to give you a coin and you're going to flip it, right? And if you flip it to whatever, let's say, heads or something like that, then you're going to just give me a uniformly random age between zero and 100. Right? If you don't flip, it should be gaussian, but let's assume uniform. Right? So if you flip heads, you should do that. If you flip tails, you should report your true age. And the idea then is that it's very hard for you to tell apart the people who were truly reporting their age from the people who were not truly reporting their age. Right.
00:18:06.560 - 00:18:38.870, Speaker B: Of course, there's always some information leak, so to speak. Right. But the point is how likely you can control how much information is leaked by any one person by kind of controlling how the distribution. How someone reports the distribution based on whether they got heads or tails. So the idea is. Sorry, here's the deal with information is if you report anything truthful, you're always going to be leaking information. The idea here is you can leak just enough information that you know what you want to know without knowing anything very specific about any one person with high probability.
00:18:40.570 - 00:18:44.930, Speaker A: Yeah, that's great. Thanks, everybody, for the great questions. Bye.

00:00:12.020 - 00:00:17.140, Speaker A: Hey, everyone. I'm here with elite podcaster Anna Rose.
00:00:17.220 - 00:00:17.560, Speaker B: Hi.
00:00:17.630 - 00:00:36.908, Speaker A: And the two of us are going to talk to Ariel Gabizon. He was an early team member at Zcash, accomplished researcher, co author, and creator of Plonk, and current team member at Aztec.
00:00:37.084 - 00:00:37.856, Speaker C: Exactly.
00:00:38.038 - 00:00:38.672, Speaker A: Welcome.
00:00:38.806 - 00:00:41.380, Speaker C: Yeah, thanks. Nice to be here.
00:00:41.530 - 00:00:43.188, Speaker A: Yeah, thanks for taking the time.
00:00:43.274 - 00:00:49.430, Speaker B: Ariel, what are you up to today? These days, how would you describe your role in what you.
00:00:53.820 - 00:02:00.716, Speaker C: Do? A bit of. I mean, I guess it's in the spectrum of art research, like trying to push the limits of ZK snarks further, which today, I would say, has a lot to do with lookup techniques, like trying to really be able to work with the classical, which relates to being able to work with the regular primitives, signatures, encryptions, not just snark friendly ones. And all the way to reviewing prs looking for bugs at a high level, I would say it's the question of how do you write snark software securely and more generally, decentralized defi systems, which we see every two weeks getting hacked for hundreds of millions of dollars. How do you write code like that? So those are the kind of things that occupy me.
00:02:00.818 - 00:02:04.584, Speaker B: And you do that at Aztec? Yeah, right now, when did you join?
00:02:04.712 - 00:02:33.540, Speaker C: I joined Aztec. It was January 2020. Oh, wow. Yeah, basically, I was at Ccash for a few years, then protocol labs, and sort of when I met Zach and we came up with plonk, I felt that sort of that collaboration is where I do my best work.
00:02:33.690 - 00:02:41.370, Speaker B: Awesome. Let's talk origin story of plonk. So you're the co author with Zach, and there's another author as.
00:02:41.820 - 00:03:22.740, Speaker C: Yeah. Juan Chobutaru. Yeah. So basically what happened was that I met Zach at this event, this zero knowledge seminar of Binary District in London, and he asked me a bunch of questions that I didn't really know the answer to or understand. But he asked me one question that was easy to me because I saw very similar techniques in sort of the stark world that I was in working with Ellie.
00:03:23.880 - 00:03:26.660, Speaker A: Was that using the Lagrange basis?
00:03:27.480 - 00:04:04.772, Speaker C: Yeah. I mean, the question he asked me was, how do you say you have two sort of vectors or polynomials? How do you check that? One is a shift of another. And. Exactly. The point is, when you go to Lagrange basis, the shift operation becomes very simple. It's just multiplying by a generator. And I wasn't aware of the time.
00:04:04.772 - 00:04:56.790, Speaker C: This had to do with Zach digging very deeply into the sonic, the last section of the sonic paper. Who knows? Maybe he's the one person who fully understood it. And one reason that section is complicated is because they try to do a so called grand product argument in monomial base. And, yeah, that becomes much simpler in Lagrange base. So that was one element of Planck being born. Yeah. Actually, if I could go back a little earlier or go a little higher level and talk a little about sort of snark history.
00:04:56.790 - 00:06:20.930, Speaker C: Yeah, so I guess a little of snark history. So, basically, one very important tool in making snarks is this idea of doing operations on encrypted or hidden values. And one main reason why that's useful is that the prover that is trying to cheat, he himself doesn't know this value, so he sort of can't adapt his strategy to that specific value. But the big limitation with this approach is that we have very limited ability to do operations on sort of encrypted or hidden values. We can, in a sense, only do degree two operations using elliptic curve pairings. So, as a tangent, a great area of research is how to extend pairings to higher degree maps. And then this GGPR work, how I view it is it said, well, if we arithmetize things using these qaps that were then sort of dubbed r one, CsS degree two is good enough for us.
00:06:20.930 - 00:07:40.650, Speaker C: And this sort of started a multi year saga where people were perfecting the GGR approach, and that led to this grot 16 paper, which sort of like, this is the best thing you can do with this approach, but sort of what's interesting, but then also at the same time that these works were being created, GGPR. So there were a few things happening in parallel. There was, of course, bitcoin coming in 2009, and there was the beginning of sort of practical snarks with GGPR in 2012. And the reason these two sort of histories interact is that we start having relatively practical snarks. And at the same time with bitcoin, we started having a very urgent need for technologies like ZK snarks. So we had suddenly this urgent need for privacy, and sort of, we had this GGPR approach that was becoming very dominant. So that was the approach that was being used.
00:07:40.650 - 00:07:53.850, Speaker C: But then exactly when snarks were coming into practice, this issue of the trusted setup became a huge practical issue.
00:07:56.300 - 00:08:02.448, Speaker B: When it lived in the realm of theory three. When you actually have to do it.
00:08:02.534 - 00:08:51.250, Speaker C: Yeah. Then it doesn't matter. Or a little more nuanced, you could say, in a theory, it's interesting, like some trusted setup versus no trusted setup. But when these things got into the realm of practicality, what the setup looks like became suddenly a very important question. And with the launch of Zcash, people started to notice that, oh, okay. If this setup was what's called both universal and updatable, meaning we do it once for all programs, and there's no need for someone to keep his secret well protected for long periods of time and keep participating for can just be someone participates for 20 minutes, and he's out, and we can replace him with anyone else. It doesn't matter.
00:08:51.250 - 00:08:59.196, Speaker C: So this gave a lot of motivation to the question of universality and updatability of the setup.
00:08:59.308 - 00:09:19.876, Speaker A: Well, I can imagine that you felt that need very acutely because you discovered a very serious vulnerability in zcash. And my understanding is the team effectively had to keep it quiet, and I'm sure was maybe a little bit nervous that it was going to be exploited for the eight months that it took to run a new, trusted setup.
00:09:19.908 - 00:09:46.960, Speaker C: It was eight, nine months. Yeah. For most of which that only four. Even inside the team, it was only four people who knew about it. And there were a lot of funny anecdotes. So the transcript from the setup could be used to exploit. So we took it offline, and then we got people complaining.
00:09:46.960 - 00:09:50.652, Speaker C: What happened with the transcript of the setup?
00:09:50.716 - 00:09:51.490, Speaker B: Oh, my.
00:09:53.220 - 00:10:30.604, Speaker C: Yeah. And I remember Sean saying. So Sean was like saying, okay, I have it at home, I'll upload it soon. And then he just stopped answering slack or checking slack so he wouldn't have to answer questions about it. So there were a lot of. But also, even before just seeing when we did the first set up with six people, even with six people, you need someone for, like, 48 hours or whatever to sleep with their computer or drive through Canada with their computer, light.
00:10:30.642 - 00:10:32.290, Speaker B: It on fire at the end.
00:10:32.980 - 00:11:34.468, Speaker C: Yeah. So that gave a lot of motivation to these questions of universality and updatability. And so suddenly, ultimately, that actually made people notice this work that was actually there from 2010, this Kate Zavarucha Goldberg work. It's interesting that was actually there already from 2010. And so then when it was finally used in the sonic paper, they used it to get this universality and updatability, but just, I guess, from sort of momentum, they were using this arithmetization from previous papers that was a little hard to work with. And sort of, for me, the pre birth story of plonk is actually Mary Mallor. She showed me, or us from Zcash, this KZG paper.
00:11:34.468 - 00:12:42.420, Speaker C: And after I thought about it for a few weeks, I was like, okay, so, actually, we don't have to just use this and keep doing everything else the way we've been doing it the last few years. This polynomial commitment scheme means we suddenly have a lot more freedom than we have in the r one cs approach. So, for this sort of higher component of the snark, this what people are now calling the IOP or polynomial op, I suddenly realized after seeing the Kate polynomial commitment scheme that, okay, actually, the design space now is much larger than it was when we were constrained to these r one cs from the GGPR approach. And so I was starting to think, okay, what is the simplest sort of polynomial iop you can do when you're not limited by degree? Two equations? And that also is sort of part of the birth or pre birth story of plunk.
00:12:42.500 - 00:12:43.080, Speaker B: Cool.
00:12:43.230 - 00:13:17.460, Speaker A: Well, it's sort of ironic, right? Because a lot of people coming into learning about zero knowledge proofs. When I did, like, 2017, 2018, we thought that r one Cs was, like, fundamental, and that was sort of this basic building block of ZK systems. But I believe the arithmetization used or the technique used in plunk was from bear groth, and it had predated. I mean, the permutation argument, I think, had predated rwandcs.
00:13:18.520 - 00:14:04.592, Speaker C: Well, I would say it's a combination of the basic protocol there is from a Bayer Grott, but it's a simpler instantiation of it using univaried polynomials and Lagrange basis that. I mean, in hindsight, it's extremely simple. You don't really need to know about it. But the reason it came to me is because of working, I guess, in the stark world with Ellie Benson at his lab, where there this sort of idea of using a generator to jump from one point to its neighbor. It's like, all the time. It's extremely all the time in starks.
00:14:04.656 - 00:14:43.280, Speaker A: Because with air, you just care so much about accessing the next and the produce rows. Yes, that's interesting. I remember being, because Planck came out at about the same time as Marlin, and so my co founder at the time, Daniel, immediately latched onto plonk, and I was like, still in r one Cs world. But I think that plank just has so many advantages, and it's actually a much better model for thinking about and, like, a more natural model for thinking about arithmetic circuits, especially with custom gates.
00:14:45.300 - 00:15:00.500, Speaker C: Yeah. Again, it's just not limited by this degree two, because there's no reason for that limitation when you're basing your design on a polynomial commitment scheme.
00:15:00.920 - 00:15:13.930, Speaker B: So you wrote the Planck paper was published, and Aztec, definitely. Did you immediately start on an implementation then, or maybe not you, but, like, engineers here?
00:15:14.460 - 00:15:19.116, Speaker C: Well, Zach implemented it, but since then.
00:15:19.138 - 00:15:34.876, Speaker B: I guess the question I want to ask is, since then, Planck has evolved into these variations with amazing names, I think are mostly turboplanka. Turboplanclunk, a lot of them. I heard there was an octoplanca.
00:15:35.068 - 00:15:37.090, Speaker C: Okay, that's new to me.
00:15:37.700 - 00:15:39.650, Speaker B: Isn't there a plankish now?
00:15:41.000 - 00:15:44.336, Speaker C: Yeah, I think it's, like, plonk.
00:15:44.368 - 00:15:50.208, Speaker A: Like, yeah, general term for anything that has, like, plank arithmetization with custom gates.
00:15:50.304 - 00:16:06.540, Speaker B: Wild, but talk like, what has that been like? And almost like, maybe from your starting point, what's been interesting or novel that either you discovered or that other people discovered ways to change this thing you created?
00:16:11.120 - 00:16:19.280, Speaker C: Well, one very interesting thing that was discovered was the ability to use lookup tables.
00:16:22.580 - 00:16:25.504, Speaker B: Which team or who kind of. Was that you.
00:16:25.702 - 00:16:51.640, Speaker C: Well, the first time lookup tables were used was. Well, I don't know if it was the first time we saw it, it was in this paper called aria by a lot of authors from UCL. But pluckup was sort of a more efficient way to do lookups.
00:16:54.780 - 00:17:08.690, Speaker B: I think. We did want to find out from you what's next as, like, what are you working on today in terms of plonk and what directions do you maybe want to see it go?
00:17:14.980 - 00:18:39.150, Speaker C: So the one question that's very much on my mind now, and I don't know if to say it's just about plonk, but, yeah, I would say better techniques for using lookup tables. I think if and when the techniques for lookup table improve by even just, like, a half order of magnitude from what they are now, it'll cause a big pivot, because one pivot. And so now there's a lot of focus on. Emphasis on snark friendly functions, like, what functions can we arithmetize efficiently? So if lookup tables become their use, becomes efficient enough, all that won't be as needed or as motivated, I would say. And together with that, all this sort of game of how to most efficiently arithmetize things, finding all these little optimizations and minimizing the number of equations or a lot of that might go away. If lookup techniques become a little better.
00:18:40.000 - 00:18:52.690, Speaker B: Is there any work that you would see as comparable in terms of impact? Or maybe it might not be from the plunk ecosystem, but that's happening elsewhere that is exciting to you or that you think could influence it?
00:18:53.300 - 00:19:08.420, Speaker C: Well, this recent calc paper I think it made the first big jump in. Exactly. Sort of what I was interested in improving lookup techniques since Plokup.
00:19:08.760 - 00:19:15.930, Speaker B: Isn't it though, only able to deal with r one cs? Can it also be applied to.
00:19:17.100 - 00:19:23.080, Speaker C: It's not specific to r one cs.
00:19:23.740 - 00:19:27.724, Speaker A: It does rely on pairings and bilinearity, I think.
00:19:27.762 - 00:19:30.190, Speaker C: Right. Yeah.
00:19:33.120 - 00:19:38.800, Speaker A: We'Re interested in it, but in the fried setting, I don't think it's as applicable.
00:19:40.020 - 00:20:32.850, Speaker C: Yeah, right. This is sort of an interesting. You have some companies, or, I don't know, I'd say you guys are sort of in the middle, but you have at least one company making a very strong bet on stark techniques. And if. Yeah, so calc is. I'd say it's the first paper where sort of the use of pairing is extremely inherent for efficiency, as opposed to just using it to get a polynomial commitment scheme where you can say, okay, I have a fry substitute. Yeah, it's interesting to see how that will go.
00:20:34.820 - 00:20:48.470, Speaker A: Do you sort of see any kind of. Are there things sort of, or areas that are kind of on your radar as far as improving lookup efficiency beyond calc, or are you just sort of.
00:20:49.880 - 00:21:05.668, Speaker C: For me right now, looking at caulk related ideas? A lot of my focus is there. What else? Yeah, honestly, that's where a lot of my focus is right now.
00:21:05.774 - 00:21:24.416, Speaker B: Cool. Nice arnel, thanks so much. Thanks for having me, and thanks for sharing with us this story of Planck, and hopefully that helps to give a bit of context to what folks are learning through this series. Nice.
00:21:24.518 - 00:21:25.170, Speaker C: Sure.
00:21:26.340 - 00:21:31.504, Speaker B: We still need to sign off. We need to figure something out from.
00:21:31.542 - 00:21:39.710, Speaker A: Me and elite podcaster Anna Rose. Thank you for watching, and until next time, great. Cool.

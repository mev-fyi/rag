00:00:00.170 - 00:00:50.422, Speaker A: What we're going to touch is, as Anna said, some of the motivations for privacy and essentially what concerns users have a kind of big picture of how privacy works, which I call from a kind of more holistic perspective about multiple layers of the blockchain. And if we have time, we won't go deep into Nim, but we'll sort of explain some of the motivation behind what we're doing at Nim and how that could possibly help Cosmos in the future. So let me just get back to here. Let's wait one sec. Okay. So first thing is, let's think about mean. I think an important question is, does anyone even care about what privacy is? So there's surprisingly little, at least published usability studies.
00:00:50.422 - 00:01:29.030, Speaker A: I hope all of you great cosmos projects are actually talking to your users. But what little we have says that actually people are interested in privacy, but they're very concerned, at least over bitcoin, which is all we have data on. So about a third of the people do believe bitcoin is anonymous, which is completely crazy. But that's, again, talking to nontechnical users. That's why many of them are using it. And another big section, about half don't think it's anonymous, but believe it can be used anonymously. However, the vast majority of users, 80% of this study, believe it's possible to follow their transactions.
00:01:29.030 - 00:02:19.846, Speaker A: And even a quarter, which is actually quite. I was quite surprised that it's pretty large, have tried to use bitcoin over Tor. The essential concern is bitcoin users and cryptocurrency users in general are using cryptocurrency in part because they believe it's private, and they are very concerned about not being private. And then there's like a whole other set of users. So this was a kind of collection of random bitcoin users. My background, which I'm going to overview briefly, is that we also looked into why people are using things like signal. Why do people are concerned about privacy in general? So we did a large number of interviews with various users, including people in Syria who are fighting ISIS, and had all these sort of confusions over signal versus WhatsApp versus text messages.
00:02:19.846 - 00:04:14.570, Speaker A: People involved in the iranian revolution, which 2009, which didn't work out very well, and generally everyone was really concerned about privacy. But there was also a lot of concerns that they needed things to be usable, and that slogans like use signal, use tours, simply doesn't make sense for lots of people in different countries because it's impossible to download them due to sanctions on the play store, or they don't find them particularly usable. And so we did like a very large study of why people, which we call high risk users, these are people that aren't just using privacy to attempt to hide their cryptocurrency transactions, but actually using privacy enhanced tools because they're afraid of some form of government repression, either theoretically, such as done in civil society with EFF, or in practice, such as people on the ground in Russia, Ukraine, various countries in the Middle east, and developers. And, you know, you can read the whole study. It's referenced at the bottom, but effectively, the take home disconnect was take home message is there is a huge disconnect, and a lot of people in the audience are developers between the properties desired by developers and what users believe, those properties that the software delivering. Actually, particularly, this particularly came out when we had interviewed people who could suffer short term, concrete physical harm, such as being imprisoned or tortured due to security and privacy failures, versus people primarily in the United States and Europe who don't necessarily suffer that in the short term, although obviously with Trump and whatnot, who knows? Things sort of looked like they were going that direction in the quote, unquote, west as well. And the general feeling which we even got, this is actually a quote from someone in, said, you know, we really didn't have any concerns about security, but then people started disappearing.
00:04:14.570 - 00:05:11.978, Speaker A: And then the essential role of the study was that people have a lot of concerns over server seizures. But this is very important. There was a huge concern, particularly among high risk users. So these are people who are most likely to be hurt or killed due to failures in metadata collection and being able to use things pseudonymously. And they were pretty irritated that most tools that they were trying to use didn't support these use cases. You can see, actually there's much more concern from these users about privacy than there is about things like decentralization, like how many different nodes are running. And people were particularly concerned about their device being seized, which we often assume is safe in the west, and that people did all sorts of crazy things to hide their contact list and prepare for house searches.
00:05:11.978 - 00:05:51.646, Speaker A: And that again, everyone really liked things like Tor, and people wanted to use tort and other tools to hide to prevent metadata collection. But even developers were super confused. And this is where I'm going to kind of take the rest of the talk. So we talked to many developers. I think this is a developer of a german secure messaging app, or maybe it's somebody from rise up, I forget. But eventually some of them basically would say stuff like, oh, well, don't worry, we're not logging anything. And if we're not logging anything, then we're not collecting metadata, and therefore, it's private, and that's wrong.
00:05:51.646 - 00:06:14.002, Speaker A: Right. So I think it's important. Can everyone still see the screen sharing properly? Yes. Good. Okay. So I think it's important that there's obviously this kind of looming concern about privacy, both from bitcoin users and from human rights activists, all sorts of people. But the problem is, no one really has a good grasp on what privacy is.
00:06:14.002 - 00:06:52.206, Speaker A: Right. And the reason is there's not a clear definition. In fact, what you have is you have diverse traditions of privacy. So, primarily, honestly coming from not computer science historically, but from the legal sphere. So the concept of modern concept of privacy has developed in the United States comes from this desire to be not photographed by Samuel Warren and Lewis Brandeis, and the right to privacy from this desire to escape the paparazzi, to have some personal, individual space which is not public. And in Europe, things took a totally different direction. Right.
00:06:52.206 - 00:07:52.254, Speaker A: So Europe obviously had the Holocaust, as the book, IBM, the Holocaust, wonderful book, details data processing, even in early stages in the 1940s and 30s, was used to help enable the Holocaust. So after World War II, there was a lot of concern over mass data processing, how to prevent, maybe not mass data collection, but at least regulate and prevent abuse. And this led to a more constitutional framework, which is more about discrimination, but has all privacy aspects for the General Data Protection regulation. And so we have these very different legal traditions and very different feelings of privacy. So, as we saw earlier in the user study, some people believe being private, simply the right to use a pseudonym, not use your real name. Other people believe it's the right to Remy, reveal partially, or have multiple personalities, and other people want to reveal absolutely nothing. So the way to maybe think about this in a bit more of a healthy fashion is sort of say, well, there's a spectrum of privacy.
00:07:52.254 - 00:08:34.154, Speaker A: On one hand, you're being absolutely anonymous, and on another hand, you're totally identified with your real name, and there's a sort of spectrum in between. And so we're going to deep dive a bit on what this spectrum means. This is a classic work that I think everyone should read. It was circulated for about ten years before officially published, and it tries to say, well, what is really being anonymous? And it comes down to this kind of quite technical definition, not mathematical, but at least technical, insofar as that is a bit precise by Feitzman, called unlinkability. So, unlinkability is, within any given system that does data processing, there are a number of items. Let's assume you're an attacker. You're interested in some of these items.
00:08:34.154 - 00:09:20.702, Speaker A: They're called items of interest. And if you observe an item and you want to link it to a user or to another item, you can link it all sorts of stuff. The way you define a linkability is that after observing the item, I can't link it to any other items. And that's kind of abstract, but actually does kind of technically hit the nail on the head, so to speak. And so then we can think about maybe historically, what kinds of unlinked ability are useful. So one big problem a lot of the early cipherpunks had was Scientology would go after them. They would publish something about Xenu or whatever on cipherpunks or some Usenet archive, and then some church would go after them and say, you should take this down.
00:09:20.702 - 00:09:45.014, Speaker A: And so people really wanted to send email anonymously. And so one way to think about what does it mean to send anonymous emails? Actually, there's two kinds of different anonymous emails. And you could think about this in terms of unlinkability. You have sender unlinkability, where any particular message is not linkable to the sender. So this means I can send the email anonymously. So you don't know my name, but you can receive an email from me. Of course, it's maybe hard to send one back, and that's a whole separate technical problem.
00:09:45.014 - 00:10:29.446, Speaker A: But you can see that sender unlinkability is one thing, and you also have this thing called receiver recipient unlinkability, where the actual, I would like to send a message out, but I don't want to know who receives it. So maybe I'm sending out an emergency call for help and I'm okay, or let's say I'm okay if anyone receives it who's an authorized medic, but I don't really want to know which medic received it. That's a bit of a contrived example. But you can imagine this is very different than sender and linkability, and you may want both. And what you actually end up having is this kind of more complex and nuanced view of privacy, where you have things like unlinkability, but you also have other things. At least, I see in the blockchain space, often kind of mixed up with unlinkability. Right.
00:10:29.446 - 00:10:56.890, Speaker A: So you see unobservability, for example. Unobservability simply means that the state of items of interest are indistinguishable because they're all sort of the same type. So this could be done. For example, if I'm interested in seeing if you're observing when you're online or when you're offline. And let's say I send fake traffic, so it hides the real traffic. This makes it a bit unobservable when I'm sending my real traffic. So that's unobservability.
00:10:56.890 - 00:12:03.310, Speaker A: Then you have even another property, which I think a lot of people in the blockchain space are interested in, which is very hard to achieve, which is undetectability. Can I even tell if you're using a system at all? Right, and so this, for example, would be something that's useful for censorship resistant, not in the kind of blockchain way of saying, well, how many nodes do I have? If node goes down, is there a trusted third party? Is my system censored? But more saying, hey, I would like for it not even be known that I'm using Tor. I don't even be known that I'm browsing through checking my email. I would like people not even know I'm using the Internet at all. And so these things are typically accomplished through signal, through domain fronting, which tries to hide the fact you're using signal by pretending only Amazon or Google altercation proxy, which tries to disguise, for example, one kind of web browsing, as another kind of more innocent web browsing. And this is actually historically, when people say censorship resistance, sometimes they actually mean undetectability and not lack of trusted third parties. So you can see it gets kind of complicated, right? Privacy.
00:12:03.310 - 00:12:53.566, Speaker A: Actually, there's different kinds of unlinkability. And the next obvious question is, how do I measure unlinkability? How can I say that one system or one kind of system is more unlinkable than another? And I think there's kind of two definitions which people should know. One is the obvious intuitive one, which is the anonymity set. So this is the total number of users a given item of interest or message can be linked to. And there's a kind of obvious upper bound here, right? So unless your system is actually undetectable, it's not larger than the number of people that use the system, right? So if Tor has 2 million daily users, obviously, Nami said a tor at best would be around 2 million, though the circuits are much smaller. So in reality it's much, much smaller. Same with a cryptocurrency transaction.
00:12:53.566 - 00:13:41.522, Speaker A: Let's say I'm using samurai wallet or whatever, and I'mixing some transactions or tornado cash. And I think tornado cash even measures this on their web page. You can say, well, how many other cryptocurrency transactions am I mixing with? Is it ten people? Is the 100 right? So is it 1000? Is it 10,000? That's my anonymous set. But there's another really useful measurement, which is called entropy. Right? So entropy is a bit better because the fact of the matter is, anonymous sets are not a great measurement because they're sort of timeless. And adversaries observe privacy enhanced systems, blockchains or secure messaging apps, or web browsing, like tor, over time. Right? So they could say, if I'm doing a traffic analysis, let's say I'm the NSA, copying all your traffic down.
00:13:41.522 - 00:14:25.902, Speaker A: I'm going to try to correlate stuff, and this changes every time I observe a message. I may learn a little bit more about you. So entropy is a very good way to sort of say, given a new usage of the system by a new user, given a number of users, is the system essentially, do I learn anything? If everything appears, could be equally likely uniformly random that I don't learn anything. So it's a high entropy system. A low entropy system is obviously revealing something about users. You can do all these nice per measurement messages. It's very old work that's referenced there from Denisus and Diaz has a similar paper on information theoretic metrics for is where this tends to be a little bit different than how cryptographers think about things.
00:14:25.902 - 00:14:59.818, Speaker A: But I think it's a very useful way for real world systems, because real world systems, and this is kind of my second big point before we delve into the weeds a bit, real world systems, the Internet is a great real world system. So you have this thing called the OSI model. And the Internet, you can imagine, has layers. There's bits, there's the Ethernet, what goes through the cable. There's the Mac address, there's the IP address. There's applications on top of this, which could be, for example, monitoring you via cookies. And these are on different layers in the system.
00:14:59.818 - 00:16:02.506, Speaker A: And packets are composed of, frames are composed of bits, and packets give you essentially data transfer, which gives you applications. And the important thing to remember is that within any given technical system, there's multiple layers. And a leak in one layer of abstraction essentially can lead to the elimination of privacy on the rest of the layers. Right? So these are often what you call side channel tags, right? So the one that a lot of cryptographers think about is, am I releasing, by maybe processing the key for so long, some time, information does that time information leak, anything about my key. But there's also much more simpler models where it's like, well, is even using the system sending this much traffic, for example, through a VPN, does the timing and volume of those packets reveal anything about me? And the answer is usually yes. So privacy is very hard because you have all these different layers and you have different layers in any blockchain system. So layer zero, your kind of UDP or TCP IP stack, your associated networking choices there for your kind of peer to peer broadcast.
00:16:02.506 - 00:17:14.034, Speaker A: Then you have your layer one, bitcoin and cosmos, your atom, your tendermint chain, what's stored on chain. It could even include smart contracts, a layer two, which are often just other chains, quote unquote side chains, which are really just kind of layer ones or zk roll ups or these sort of things. But you also can imagine payment channels, all these auxiliary services, and finally at the top there's application. So when you're building a privacy enhanced application, you have to kind of think, well, can I build on top of a privacy enhanced layer two and a layer one? So for example, could I use Cosmos and tendermint as my underlying blockchain? And then even with Tindermint Cosmos, what happens on the network level can leaks the network level lead to even if I'm using all the wonderful privacy tech on layer one, does that hurt me? And that's why privacy is so hard, because it's not easily reducible to a zero knowledge proof or cryptographic, often very fragile. Cryptographic primitive is really this kind of like holistic multilevel system. And it's very hard for most people to think in multiple layered way, including myself. And so then the problem is you have all of these different choices even in a single layer.
00:17:14.034 - 00:17:46.814, Speaker A: So I think everyone already knows this. I'm going to go through it pretty quickly. But again, when bitcoin and cryptocurrency started, the obvious thing to do is you say, oh, I want to hide my amount. So we just need addition. So you just can use something very similar, like an additive homomorphic encryption scheme like Pali. And this is liquid coin join, samurai wasabi, even mimble wimble is basically just a slight variation on this to be less interactive. But these all have really large packet sizes and you don't really get too much flexibility in what you can do, right? You can basically do addition with leveled homophryption.
00:17:46.814 - 00:18:19.718, Speaker A: You can't really do exponentiation stuff. And then the next kind of weird world was the world of Monero and now mobile coin, we kind of add some secure enclaves on top, but you essentially boil down to ring signatures. But again, your anonymity set is kind of limited to the number of people in your ring signature. Right. So this is not a great technique either. And so I guess the latest and greatest, which I'm not going to really go into, but which other people will, is zero knowledge proofs, which your anomy set will then equal all the users, ideally all the users that have ever used the system in that particular version. That would be wonderful.
00:18:19.718 - 00:18:57.926, Speaker A: And that's what's aiming, people aiming at a zcash, some primitive stuff like tornado cash, which is more of a mixer. So small nominee sets compared to zcash. And also new work on Ethereum, like Aztec. And I'm not, I think on the Cosmos level, it's still kind of open season for figuring out what zero knowledge techniques work best on Cosmos. But great thing about Cosmos is it's so flexible and you don't have these terrible pairing gas costs. So hopefully we can get zero knowledge proofs working on Cosmos. But I think what's interesting is that I do want to just point out, and this kind of motivates nim, and I'll try to wrap up here in about ten minutes, is that all of.
00:18:57.926 - 00:19:53.478, Speaker A: No matter, I don't really care if you're using a zero notch proof system like a ZK stark or some newer ZK snarks. One trusted setup like plonk, as opposed to per circuit trusted setup. Regardless, doesn't matter, because on some level, if you go back to the layer cake, you're still dependent on layer zero, which is the peer to peer networking level, and all the peer to peer solutions in the kind of cryptocurrency space, there's a vast variety of them. They are all not so secure and often broken in their own unique and wonderful way, which I kind of overview here. And therefore, you kind of also want to separate these levels. Right? So we have concrete attacks. Aaron Tramer has a kind of new one here in 2020 where even if you're using, let's say, gross 16 ZK snark on chain.
00:19:53.478 - 00:20:30.114, Speaker A: That's wonderful. But network level data can still be used as a side channel to de anonymize the on chain level. And people say, well, is this really realistic? Likely. So we have some examples from 2015 that chain analysis was doing this on a large scale in the bitcoin, in the bitcoin network. So bitcoin is like 10,000 nodes back then. In 2015, it was probably a few thousand. But regardless, ranked a few thousand full nodes and observing peer to peer traffic, you can get a large enough grasp that you can more or less get most transactions through observe a huge percentage of transactions.
00:20:30.114 - 00:20:57.214, Speaker A: And that was definitely possible with bitcoin. And you look at smaller networks. I forget how many full nodes zcash has, but I haven't actually get that number from that community. But it's a few hundred, right? So it's really easy to observe and I would assume I don't really know how many, quote unquote cosmos full nodes are there. Most networks are pretty small. So again, observing these peer to peer networks is easy. And so it's great that the validators are producing technology like sentry nodes and stuff, try to prevent this.
00:20:57.214 - 00:21:52.158, Speaker A: But fact of the matter is, passive adversaries that just observe your network are still very powerful. And so zcash mentions, the authors of the paper are quite intelligent. They say, well, look, we really need to look at this kind of layer zero technology. We need to use something like a tor, even a mixnet. The problem you kind of have with a lot of these technologies, there's kind of a joke in the early days of Internet that your server is always kind of insecure. So people really focused on using TLS, and that using TLS was like using an armored car to deliver messages between two homeless people living on benches, because it was just so easy to penetrate servers. And using ZK snarks on blockchains, that's some peer to peer protection, are kind of like armored cars is kind of the reverse problem.
00:21:52.158 - 00:22:36.846, Speaker A: Communicating via paper need to, I kind of want to just emphasize this, that you have to really focus on all the levels. And if you don't build on a good networking stack, you are effectively kind of building on a castle on sand. And I think I covered that. So one way to do this, I'm not going to really go into Nim per se. I'm going to kind of give a little bit of background on one way to tackle this stuff, which is a mixnet proposed by David Chom. And it's a really wonderful and easy to read paper. And this sort of stuff is not complicated, right? So a lot of zero knowledge proof cryptography, I think, is much more complicated fiat shamir, secret sharing than what we're doing.
00:22:36.846 - 00:23:16.566, Speaker A: There's no, for example, polynomials. What you basically sort of say is, hey, if I were going to hide a message, how would I hide it? And the way you hide a message is you encrypt it, but then you basically collect a bunch of them, you mix them up, and it's a little bit like an on chain mixer. You randomly permute them and you send them in a different order. And there's many variations on how to do this. This is the classical chami and batch Mitsnet, which is elixir, where you basically the mix nodes use the messages, goes through mixes, comes out. And this technique is really nice because from a cryptographic perspective, you can do some provability over it. So there's that wonderful paper by Chaido sedal on a universal composability treatment of mixednets.
00:23:16.566 - 00:24:08.314, Speaker A: A little bit complicated, but does show you can apply formal methods to mixnets. But the problem with mixednets is that obviously if you look at that technique, sorry, go up again, there's obviously a problem here, right? Because if I'm sending a bunch of messages to mixer, and I'm not just sending like a few cryptocurrency transactions, but I'm sending bytes and bytes and bytes of packages, the capacity is going to be limited by the weakest mixed net, the lowest capacity mixed node. So that's obviously a problem. And people also didn't like mixednets because it was unclear if they could scale really well, and doesn't seem obvious how chamannet scale. So people kind of moved a different design called crowds. This is actually very similar to a more recent design called Dandelion. Essentially it's the same design, and the intuition is quite great.
00:24:08.314 - 00:24:39.480, Speaker A: Again, it's like back to anonymous sets. You can only be anonymous in a crowd. Anonymous routing requires you go through these multiple hops. But the problem is, how do you trust the people that are forwarding your traffic? And if you can't trust them, you get these attacks, they can capture your route, they can gain information. This is called a predecessor attack. And so the main result of crowds was that this is actually much harder than it appears, and that crowds is kind of well known, broken. So from crowds came the Tor design.
00:24:39.480 - 00:25:28.926, Speaker A: And Tor basically does something similar. Crowds ships you through a bunch of peer to peer relays with a lot of the attacks kind of being a little bit controlled by a director authority system and other great techniques. Tor added, and most of the decentralized VPNs we've seen, Orchid Sentinel, they're just kind of weird versions of Tor. But the fact of the matter is, even Tor is vulnerable to some kind of traffic analysis, because obviously it's first in, first out on your packets, so they're not mixing them like Chom would mix them, and therefore you can de anonymize those packets via their timing and volume information. At least in closed world. Experiments by Quantitao like deep learning gives you 95% identifiability, which is pretty bad. And I think, regardless, I'm not going to go nim.
00:25:28.926 - 00:26:17.906, Speaker A: Dave's going to do that later. But Nim tries to develop a way to scale chami and mixnets and add fake cover traffic to get some of those nice unobservability properties. But what I do want to end on is, okay, so we just said, well, look, there's all these different anonymous layer zero solutions. There's all these different awesome, anonymous privacy enhanced layer one solutions. Do users care? Can users using this tech? And the challenge I want to leave everyone with is the answer, I believe, is currently no. Right? So you have all these different kinds of observers, people that can just read the blockchain, people that can read all the traffic, so you can define these different threat models. And what we did is we did a sort of large scale study of about 60 users, because again, talking to users is the way you understand what they're trying to do.
00:26:17.906 - 00:27:17.778, Speaker A: And I really emphasize this, want the cosmos community to do more of this. And we just said, well, can anyone buy anything anonymously with zcash? And if you can buy something anonymously with zcash, can you do it using kind of TorVPN or some form of layer zero protection? So we did this study. It's like most cryptocurrency studies, a little bit bizarrely diverse, definitely skewed towards white dudes, but more people from Asian Africa than you would expect, and mostly kind of beginners, but people who think they're interesting. You discover cryptocurrency user studies, everyone thinks they're an expert, which is kind of the reverse of what you have in normal usability studies. And we got people to install the zcash wallet, which actually people did decently good at. While most people could install the wallet because it's just kind of a button or two, people did have trouble distinguishing the Z address from a T address. This is a shielded or private address from a non private or public address.
00:27:17.778 - 00:28:06.870, Speaker A: So this led to some issues. Hilariously, privacy advocates that hate Google often had issues installing the software, and some users would give up due to slow synchronization issues. But the main thing we discover is that, honestly, when you use privacy tech, there is often this kind of contradiction in development where you say, well, should it be optional? So if you say users can turn on and should be on by default. So for example, signal wants all messages to be encrypted and secure by default, and Zcash, it's more of like an optional thing, at least in these older wallets like Zecwall. I think that's moving more towards being on by default. But the fact anything where user has to kind of understand if something is on or not leaves the yacht, lots of usability issues. And then of course we try to get the users to install Tor.
00:28:06.870 - 00:29:02.340, Speaker A: That was super exciting for them. And users in general were a bit more successful installing Tor than wallets, but they had some trouble with the binaries and trouble understanding what IP addresses were, and then only a very this is then they had to buy something, and only about one, four people had trouble determining if the privacy was optional, if it's on or off, how the two things work together. And so basically only the result is only one quarter of users could actually get real network level and wallet level privacy on top of zcast. So I do think we can do better. That's the challenge for the audience here, and I have a minute or two maybe to answer questions. This is very different than your classical blockchain kind of zk talk, but I do think some sort of broad overview would be useful. Thanks a lot.

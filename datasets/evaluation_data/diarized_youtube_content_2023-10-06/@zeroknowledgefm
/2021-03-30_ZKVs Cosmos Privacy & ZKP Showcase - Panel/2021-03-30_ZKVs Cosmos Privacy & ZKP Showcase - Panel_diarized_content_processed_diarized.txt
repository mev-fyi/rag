00:00:04.940 - 00:00:05.490, Speaker A: Cool.
00:00:07.460 - 00:00:48.108, Speaker B: So what I want to do with this panel is, because there was so many, and sunny just joined when you can, I'll bring you on. There were so many questions that didn't quite get asked. We kind of pushed through this. So I kind of wanted to start this off with a few questions to each of you about the projects. I want to start with you, Chris, because the enema part, I couldn't hear exactly how it's working with IBC or pools. I kind of got that it was know, moving the funds around and there's a private way, but I was hoping you could just give a little bit of a connection point there, maybe take a second to do that.
00:00:48.194 - 00:01:24.168, Speaker C: Absolutely. So in sort of the basic case, Noma functions as blockchain running on tendermint. We're working at rust for the SDK with a multi asset shield pool. So an instantiation of our extended version of ECC sapling circuit, which supports shielded, fully shielded transfers using standard like notes and commitments adjusted to also shield the asset denomination. So this means that there is a logical shielded pool on Inova, which all assets can elect to share, including fungible and non fungible tokens. Anything that can be represented as a.
00:01:24.174 - 00:01:40.350, Speaker B: Combination of each domination. Do you picture there being kind of like an lp token type thing happening on each of these chains? Or how is the liquidity provided? Or is that too early possible?
00:01:41.440 - 00:02:44.460, Speaker C: I'm not sure. The research area, which I guess I'm most interested in, or which to me remains most open, is in balancing the security isolation or fault isolation provided by IBC with the desire to have cross chain price. So the technical implementation of cross chain shielded transfers is not that difficult. But the tricky thing is that it changes what kind of fault isolation you can get, because IBC provides fault isolation. So prevent some other malicious chain from inflating your token by tracking what the incoming and outgoing supply is. So each chain, for any chain which speaks IBC, any other chain which it's talking to using ICS 20, has a balance, basically. And when I send tokens from my chain from Enoma, say, to the cosmos hub, I track that, and if the cosmos hub ever tries to send back more, I will reject the transaction.
00:02:44.460 - 00:04:14.836, Speaker C: That's all well and good and works just fine, and provides fault isolation in the sense that no other users of that token on my chain are subject to risks, only users who send it over to this particular chain. So the inflation is prevented by tracking supply, but as soon as you shield the transfers, then suddenly that information is gone, because shielding the transfers so what do you do? It's also complex, just sort of implementation wise, because you're trying to track this kind of aggregate statistic across transactions, namely the total value in or out, which is sort of like design wise, pretty incompatible with the way the sampling circuit works, because it's not tracking any kind of state which is cross user dependent. So if you want to do like addition and private, then you need home warp addition or something. You need to connect that to the circuit, and that will get very complex very quickly. Although, and even in principle, you can't track it exactly, because if you track it exactly, then just by looking at the difference, if the value is public by the difference in the amount, you would know what the value of the transfer was by subtraction. So there's some balance, maybe, of tracking the supply, so you can provide fault isolation, but tracking it within some error margin, and then you have privacy, except there's this sort of bound on what the total value transferred in some unit of time was. And maybe that's sufficiently, maybe that's like a balance to be achieved.
00:04:14.836 - 00:04:16.016, Speaker C: I'm not sure where.
00:04:16.198 - 00:04:21.280, Speaker B: So would we say that it's still a work in progress? Or like, do you have the solution?
00:04:21.700 - 00:04:39.180, Speaker C: So this problem is not specific to anoma at all. It's general to anyone who wants to do, it's general to the sort of ecosystem of IBC connect change at large, insofar as we all want to share our privacy sets, because the more the better, but we also want to isolate.
00:04:39.200 - 00:05:09.660, Speaker B: Our faults because the fewer understood makes sense. What's so cool about these three presentations, by the way, is how they kind of targeted very different parts of the cosmos stack. And I really like that. I want to kind of move on to Henry. You had sort of presented this for anyone who's just seen the panel, this panel, and didn't actually see the talks, there's this idea of private validation. I had this leftover question. You kind of have a completely new thinking about that in order to keep delegations private.
00:05:09.660 - 00:05:26.980, Speaker B: But you talked about this cap like it being at the unbonding point, some sort of cap gain happening. But what was that based on? Would that be time spent or amount in? Because if it's amount in, wouldn't it reveal what you're trying to hide?
00:05:27.900 - 00:07:04.320, Speaker D: Yeah, so I guess there's sort of two parts to that question, if I'm understanding it correctly. The first part is, how does the reward amount on unbonding or undelegation work? And then the second part is, how do you avoid some kind of linkability between delegations and undelegations, right? So the way that the reward system works is that in every epoch, all of the bonded stake is inflated by a factor of one plus the reward rate relative to all of the unbonded stake. And then for each validator, some portion of that inflation is captured by the validator as a commission and some portion accrues to the delegation holders. And the exchange rate is perfectly accounting for all of that cumulative inflation. Or it's actually not necessarily inflate. It depends on which sort of side of this you're picking as your reference asset, which I think is also pretty interesting. Like one perspective you can have is either you have bonded stakeholders are being compensated for taking on some risk, right? That's corresponding to choosing the unbonded stake as the reference token, or you could choose the bonded stake as the reference token.
00:07:04.320 - 00:08:26.560, Speaker D: And from that perspective, people who don't bond and don't take on any risk are penalized for not doing so, right? So that's this kind of equivalence. But there is a problem with potential linkability, where if I see that there's some bonding amount and then there's some unbonding amount, and I know that there's particular relations between those things, can I work through all the possible combinations of epochs and figure out whether there's like a known ratio and do a correlation? And the solution to that is that actually because all of the consensus weights are only updated per epoch, you don't actually need to declare publicly how much you're bonding. You only need to have the kind of net flow into a particular validator's delegation pool be public. And so the solution is that when you do a bonding transaction, you would encrypt the bonded amount to all of the current validators. And then in the last block of that epoch they aggregate all of the bonding transactions and then decrypt only the net flow.
00:08:28.180 - 00:08:29.216, Speaker B: Got it.
00:08:29.398 - 00:09:09.310, Speaker D: There's still maybe some correlation, like maybe you're the only person who bonded in that exact epoch to that validator, but that's sort of like this. There's some stuff you could do to mitigate that, like maybe you get client software to bond in different chunks, or maybe people are bonding to a bunch of different validators. Or maybe you build the system and then it's successful, and then it has users. And then if you have a lot of users, then ideally you have a big enough anonymity set. If you make a privacy tool that has users, then there's no design that you can do that will fix that.
00:09:10.400 - 00:09:31.910, Speaker B: All right. I'm going to move on to Dave's project. I know Sonny, you and Sonny have been switching places, but given that I'm going to ask a question about the presentation, then maybe it does make sense that you're here and it's actually generally about the project. Do you feel like the work that you're doing right now is really specific to Cosmos? Or could that actually be also used for Ethereum and Erc twenty s?
00:09:34.040 - 00:09:52.616, Speaker A: I think social decryption is a great solution for mempal privacy for anywhere where you can have this sort of BFT setting. So cosmos kind of natural because there's tendermint base layer. ETH and ETH two don't actually have this very naturally. ETH two has this design goal where if there's only one validator that's live, the change would keep proceeding.
00:09:52.808 - 00:09:53.212, Speaker B: Okay.
00:09:53.266 - 00:10:15.904, Speaker A: You don't actually have a threshold that you can rely on. So what you could do is you could maybe have threshold encryption where the threshold can be delayed. This then reintroduces some med opportunity. But for roll ups you can do a multi validator roll up situation. And this works great. Be directly applied there.
00:10:16.102 - 00:10:20.244, Speaker B: Nice. All right, now you get safety in that.
00:10:20.282 - 00:10:21.076, Speaker C: Hold on, hold on.
00:10:21.098 - 00:10:57.836, Speaker E: You get safety in that context of a roll up, but you don't get the roll up. Slideness guarantees. It's just like a pedantic thing. This is an interesting, I think, question for the Ethereum community is going to be the argument for roll ups is you have both the safety and liveness properties of the underlying chain for most roll ups. And if you were to add something like threshold decryption, you could get safety properties from, let's say tendermint, but you wouldn't have the liveness properties of the underlying chain.
00:10:57.868 - 00:10:59.360, Speaker C: Like the roll up could get stuck.
00:10:59.860 - 00:11:26.970, Speaker A: It doesn't depend on your model of like, do you have transactions be posted on l one first, or do you have them be given to a sequencer and then batch updated on the L1? You could have the sequencer network still come to consensus and just keep doing batch updates to L1. I think it still works out there. You just block on the liveness of L1 eventually after you've proceeded by some amount.
00:11:29.260 - 00:11:50.848, Speaker B: So I want to now kind of take it more into a general context. This is a bit back to you, Zucky. Do you think that there is a business case for privacy on like, I want to bring it back to that. We've now seen these three really fascinating examples of using privacy in these different ways. I don't know if I fully business. So that's what I want to throw to you.
00:11:51.014 - 00:13:08.810, Speaker E: I guess the biggest core observation is without privacy, value is being extracted from users, right? That's the core observation is behind all of these protocols, it's like when you are transacting in public on Ethereum, value is being transferred from you to another party. Usually that party is miners like front running bots, that kind of stuff, right? And that value capture is. And so the proof of stake world is maybe we start socializing among the validators, set more of that value capture, and it's like game, theoretically a fair playing field for that value capture to be distributed more evenly. And you see that in things like the gravity Dex design, where you have these batches of transactions that are computed, that's the proof of stake world. But in order to actually get to the point where the users of the system keep all the value, you actually have to get to the privacy world. And that's the clearest business case for privacy, right? The clearest business case for privacy is users keep more of the value.
00:13:11.500 - 00:13:37.910, Speaker B: I mean, Henry, you kind of mentioned that as mean. I think we all actually thought about this, this idea of making sure that these incentives are aligned. Do you think that there's a certain place that the alignment should happen first? This question goes to anyone here. Does it need to start from the top? Should it be in that consensus level, or can it be lower down?
00:13:38.280 - 00:15:12.332, Speaker D: Well, I guess one thing about privacy that is important to understand is this idea of kind of multiplicative decreases in anonymity sets. So if you think of privacy as being about really control of information disclosure, then it's more clear why that's important, because when people are transacting, ideally they would like to disclose or control what they're disclosing. But each sort of piece of information that is disclosed ends up having a kind of multiplicative impact on the amount of privacy that they're going to have overall. Right. If you leak one bit over here and you leak another bit over here and a third bit over there, then instead of being three times smaller, you're actually two to the three times smaller, you're eight times smaller. And so the kind of fundamental incentive or benefit to putting privacy into base layers as deep as possible is that it gives you this kind of substrate that you can then build other things on top of. And if you have that substrate, then a lot of things become a lot easier.
00:15:12.332 - 00:15:19.904, Speaker D: So, for example, in the case of trying to have privacy preserving swaps.
00:15:19.952 - 00:15:20.308, Speaker C: Right.
00:15:20.394 - 00:15:50.636, Speaker D: There's this paper that came out recently about privacy and constant function market makers, where effectively all of the information in the trades and the prices is also in the function. And so you can't really hide one without hiding the other. And the conclusion of that paper is like, oh, well, this means that privacy for these CFMMs is impossible, but in.
00:15:50.658 - 00:16:00.672, Speaker B: That model, not exactly that there's mitigations that were proposed, but. Yeah, I know what you mean. It makes it hard.
00:16:00.806 - 00:16:01.696, Speaker A: Yeah, right.
00:16:01.798 - 00:16:45.760, Speaker D: If you're starting from like, oh, well, we can precisely identify that this transaction was made by this person and the amount is tried to be protected, but then we can recover it from this other information. Well, if you had built that on top of this kind of like private foundation, where all of these transactions are kind of recycling the same anonymity set and breaking linkability, then it's much easier to solve. So the deeper that you build the privacy into the system, the easier it is to have more private features on top of that foundation.
00:16:47.780 - 00:17:05.934, Speaker B: That makes sense. There's a question here Jonathan asked, can you talk about programmability with privacy? And I guess that could actually go to anyone. Oh, you go ahead.
00:17:06.052 - 00:17:37.418, Speaker A: Oh sure. I guess this is asking kind of about maybe the unisoft example Henry's talking about where you have this contract on chain and you want to have private data go into it and get some private output. You have this fundamental problem that you need the state update to be public. And so this is the problem with know. When I do a trade against Uniswap, everyone needs to know what's the remaining reserves on both sides. So you can infer, then you can back infer what was the transaction data for uniswap. It pretty good.
00:17:37.418 - 00:18:17.906, Speaker A: Some things you could imagine. It's many to one. So you can, given the public state update, it's one of these transaction types, but you can still get privacy here, where privacy then means maybe two different things, bringing in context. One is that who did the action is private. So this would be like a zcash style fee payer system. Or if you don't have privacy built in very deeply, you have to do some other trade offs, like Henry was mentioning, that you have to go. One thing is like you can do the aztec batch transaction thing, which then grows complex.
00:18:17.906 - 00:18:35.850, Speaker A: It gives you less privacy guarantees because it's not built in into the L1. And the second thing you can do, which is like you could hope to hide your transaction until it's finalized, which is often what people may want for trading, and it's MeV resistance stuff like memple privacy.
00:18:38.370 - 00:18:49.646, Speaker B: Sunny. I think I can add sunny in can. I think Sunny just joined. Yes. Okay, good. Hey, did you want to jump in and say something on this?
00:18:49.828 - 00:18:50.266, Speaker D: Nope.
00:18:50.298 - 00:18:51.770, Speaker A: Dave covered it perfectly.
00:18:51.930 - 00:19:22.460, Speaker B: Okay, great. I wondered, is there. Are there parts mean. I don't know if it's parts of IBC, parts of certain parts of any stack that are missing that make it. I mean, we talked about the rust versus go, but is there anything else that we could even maybe encourage the audience or the community to start working on that maybe a lot of people feel is missing? Yes. Oh, I think, Zach, you just had to, I guess. Okay.
00:19:22.990 - 00:20:09.180, Speaker A: One question, like, had in my mind, I've been one of his answers to is, are there approaches to cross chain privacy where two different chains can share the same anonymity set, but efficiently? And so I don't think anyone's worked. No one's working this, to my knowledge. And the only idea we've seen a bit discussed is you can hope that you have both chains share a nullifier set. If you're thinking zcash style, where Zcash is nullifiers and you kind of do some, you make tokens and code what chain they can be spent on, and you have all nullifiers go under some cross chain agreement protocol. But I don't know if there's other ideas. I think there's a huge design space open here that should be.
00:20:12.110 - 00:20:30.640, Speaker B: Mean. Henry, you were. I know previously you were working on sort of like a pegged zone, right? Like, this idea of having one zone dedicated to know it doesn't solve the problem that you just highlighted. But would that also be like if that existed? Does that open up something? Is that something that people should aspire to?
00:20:31.490 - 00:21:52.342, Speaker D: I don't think that would really solve the problem, because in that model, you still know the actual transfers were still public. I think to the point that Chris made earlier about this tension between kind of, like, fault attribution and privacy that seems pretty fundamental to me. If you don't want to reveal specific amounts that are moving between chains, then you can no longer know about specific amounts that are moving between chains, and that's the problem. So you might be able to build something, for instance, that kind of, like, interpolated between those two extremes. So you could potentially build some kind of a batch value transfer. Know, people would kind of queue value to be moved over IBC, and then the entire batch would be moved kind of all at once. And then you sacrifice attribution within that batch for privacy.
00:21:52.342 - 00:22:36.650, Speaker D: And the kind of length and size of the batch has user implications for how long they have to wait for finality. Because if I'm a user and I want to move funds between two zones, I kind of don't want to have ach on the blockchain where I have to wait three days for it to settle. That is kind of sad. And I think people are used to the idea that, especially in a system like cosmos where you have finality, I think people are used to the idea. I make a transaction 10 seconds later, I'm sure that it's been committed to the chain.
00:22:36.990 - 00:22:39.450, Speaker A: Yeah, I think there's.
00:22:41.070 - 00:22:41.980, Speaker B: Go ahead.
00:22:43.950 - 00:22:49.246, Speaker C: All right, well, you can come out. I was excited to hear what you have to say.
00:22:49.348 - 00:22:49.950, Speaker A: Okay.
00:22:50.100 - 00:23:42.394, Speaker C: I was just going to mention that I think one part of the trade off, or the tension, which is particularly tricky, is that the IBC security model is dependent on this concept of value flow in time. So if you think about some kind of potential attempt at misbehavior or attempt at byzantine subversion and double spending across an IBC channel, that's happening in time. And IBC itself is composed of several layers of defense. So the initial layer of defense is just like if you have less than a third Byzantine, you have all of the guarantees of the light client algorithm. Light client algorithm is secure, your chain doesn't fork, and you're all good. But even if that fails, IBC has secondary layers of defense. And those secondary layers of defense work by detecting misbehavior.
00:23:42.394 - 00:24:35.630, Speaker C: So cases where faults are attributable, even though it's like more than a third, potentially that is faulted, but attributable from the perspective of another chain, because the other chain has their own consensus, so they haven't lost their ability to come to agreement on what happened. So they can still see that, oh, a fault happened. Like, I should start treating this IPC connection accordingly. And the way in which they learn about that fault, however, is dependent on processes which are happening in time, in time which is asynchronous across these chains. So it's dependent on the submission of misbehavior, evidence of evidence about what the validators actually signed, which in this case was, like, wrong, or a violation of the protocol somehow to the other chains which are interested because they're running like clients and speaking IBC. And that evidence submission happens is something that's a function of. A function of, like when stuff gets gossiped over the network and who could do things so fast.
00:24:35.630 - 00:25:27.214, Speaker C: And because of that, in order to contain the faults you want to contain the flow of time, or, sorry, the flow of value over time. Because as I at this other chain, I want to know that, oh, if some fault happens, it's attributable, and some information is like some misapproves consisting of signatures of the validators over whatever they did which was wrong, gets necessarily exists somewhere, and I want to have time to learn about it, but for too much value is floating on my chain. But then that also has tension potentially with certain kinds of privacy schemes based on batching, insofar as batching might involve like sending one IBC packet which does the whole batch at once, and that whole batch at once could then be timed by the validator set, which is attempting to misbehave so that they could move a lot of value at once. So it's a really tricky tension, because. Go ahead.
00:25:27.252 - 00:25:48.520, Speaker A: I think this tension is that we can use state litty proofs for the flow rate. You could snark properties you want guaranteed about flow rates between chains. And then as a chain is connecting to you, I can get guarantees that I can get my flow rate guarantees even with privacy being added in here.
00:25:50.410 - 00:25:58.010, Speaker C: But how do you do the addition? I mean, you want to keep the state, right of the flow.
00:25:59.150 - 00:26:14.394, Speaker A: Okay, maybe. Yeah, I have an invariant that you did not mint more of these tokens that were IBC'd. An invariant total sum.
00:26:14.442 - 00:26:15.038, Speaker C: Right.
00:26:15.204 - 00:26:18.350, Speaker A: Like all these IBC lock tokens weren't inflated.
00:26:21.410 - 00:26:27.938, Speaker C: Maybe. But then it sounds to me like you need that kind of proof, like, over the whole state machine. Yes. Okay.
00:26:28.104 - 00:26:37.718, Speaker A: I think you just need it for the state route, for the IBC state routes and anything that goes in and out of the IBC state route, not the rest of the.
00:26:37.884 - 00:27:12.066, Speaker C: Yes. If you logically isolate the part of the state machine responsible for executing IBC and then have state validity proofs over that, that helps. Yes, but I still don't see. So if shielded transfers are happening there, how do you have, you still need to compose somehow the amounts of the shielded transfers and add them together without revealing what they are?
00:27:12.248 - 00:27:18.900, Speaker A: Yeah, I guess we would need some sort of sum invariant that the sum of transactions in and out.
00:27:19.990 - 00:27:21.138, Speaker C: The other problem is that these are.
00:27:21.144 - 00:27:22.510, Speaker D: Not like, necessarily, I mean, this is.
00:27:22.520 - 00:27:39.930, Speaker C: Like maybe a more approachable problem. But the, say, trusted setups used for xero knowledge proof schemes, or even the xero knowledge proof schemes themselves, are also not necessarily something that's going to be agreed upon by different chains in the cosmos ecosystem. In terms of what counts as secure.
00:27:40.990 - 00:27:53.040, Speaker B: Is there a preferred ZK construction so far in cosmos, is it sort of deferring to snarks, or is there any particular circuit that people are using more? Do you.
00:27:56.770 - 00:28:42.286, Speaker C: Mean? In my opinion, the best documented and specified zero knowledge circuit in the world is still ECC sapling, and that's what we've built on top of for the masp. So in terms of shielded trip, and I think that's, as I understand, penumbra is also basically an extension and lots of additions to that design that solves a very particular problem. It doesn't solve other problems. So to solve other problems, you need other circuits. In terms of serenology proof scheme, I don't know if there's one which is specific to cosmos, halo two and like plonk and plookup are kind of, sort of converging towards the same point in the design space, which is indicative, at least to me, that that's a natural direction. It probably will result in some kind of common standard, but it hasn't exactly happened yet.
00:28:42.468 - 00:29:04.360, Speaker B: Got it. Somebody asked a question here asking us to kind of throw back to this go versus rust debate in zk land and Cosmos. Zucky's not on here now, but he's the one who brought it up. Maybe you all have opinions or thoughts on that, given that you're working with these.
00:29:07.050 - 00:29:31.946, Speaker A: My thoughts are that I see no issue with just using rust for and then doing static linking or dynamic linking to get your nice performance for rust cryptography. And go. I think reimplementing is like a not great strategy, though. There is now a great Golang snark library for some of the popular schemes from consensus called gurvy.
00:29:31.978 - 00:29:33.550, Speaker B: I heard about that, yeah.
00:29:33.700 - 00:29:40.826, Speaker A: But I still have a preference for just because of standardization.
00:29:41.018 - 00:29:51.220, Speaker B: Do you then want to see Cosmos head move more towards rust generally? Would it be nicer if you didn't have to make that connection point? Or is it just so irrelevant it doesn't matter?
00:29:53.590 - 00:30:03.960, Speaker A: Well, maybe I'm prematurely because I have not written the bindings ever myself, but I feel know we can automate a lot of the binding difficulties. Henry probably knows a lot more here than I do.
00:30:05.790 - 00:31:06.090, Speaker D: I don't really know anything specific to the cosmos parts or actually really about the kind of mechanics of doing complex bindings. I do know that most of the people who I know personally who have attempted to do some kind of go related FFI that wasn't Seago have not had a super fun time of it go as like a design decision that they made. It's very special. It has this cool mechanic for doing stack handling and everything, and that provides benefits for go, but it means that it's less straightforward to do, kind of like in process interop.
00:31:09.650 - 00:31:10.542, Speaker B: Got it.
00:31:10.676 - 00:31:44.390, Speaker C: So I'm happy to go down a limb here, and I think we should just move towards Rust. I think in most aspects, rust is a better language for building blockchains. It loses to go a little bit in terms of usability and familiarity and, like, ease of working across a very large code base, especially if people are using a lot of macros or non ennematic rust. But it wins a lot in performance, in degree of error checking and type checking, which the compiler can provide, of course, integration to cryptography libraries, and also concurrency.
00:31:46.590 - 00:31:52.300, Speaker B: I want to finish what you were about to say. No, I was about to change. So, yeah, sorry.
00:31:52.910 - 00:32:17.650, Speaker C: There's also informal systems, has, I think, a long term strategy. Hopefully it hasn't changed. I don't want to misquote them, but to eventually work on template and rust. There are already, of course, ABCI bindings, and we're slowly moving towards maybe there will be like two parallel ecosystems, maybe there will be bindings in between them, and people can mix and match components. But I do think it's worthwhile to pursue a long term rust.
00:32:19.830 - 00:32:20.798, Speaker B: Go ahead.
00:32:20.984 - 00:33:27.340, Speaker D: One thing that I would just finally note is the kind of benefit of having a more powerful type system that lets you express these more complex invariants. The obvious benefit of that is, okay, now we have this system that we're trying to design and has all this complex behavior, and we can encode it all into the type system and have the compiler check it for it. Great, wonderful. But the kind of under discussed kind of downside risk of that is that doing that kind of encoding state invariance into the type system is actually a kind of nontrivial skill that people need to learn. And I think that's part of the kind of learning curve of effectively using rust. And if you don't do it well, then you can end up with this kind of cemented spaghetti code that's completely impossible to change because you've encoded all the wrong invariants into your code. That I think is a.
00:33:29.310 - 00:33:55.860, Speaker B: To. Since Sunny's on here and we haven't heard from him yet, I hope you don't mind. I want to ask you a little bit about, and I don't know if you're thinking a lot about this, but where you would maybe like to see privacy in cosmos. I know you and Dave, you've been exploring a few different spots of using zero knowledge proofs right now you're doing this presentation was on the threshold cryptography, but I want to hear from you what maybe else is on the horizon or what you'd love to see.
00:33:56.950 - 00:34:46.180, Speaker F: Yeah, so obviously there's the threshold. I try to think of it from a very practical standpoint of what's the highest value use case. And we're building a product called Osmosis, which is a Dex platform for Cosmos. And I'm approaching from a very practical standpoint of what is the features that people want to see and start from talking to people. The one that people wanted the most was the front running prevention, which is what we started with. The next piece that we want is, I think Dave mentioned it earlier, but this very practical idea of, you know, getting everything working in a fully private system is not really what, it's a nice end goal, but it's probably not the way to get right. And like, you actually do want a lot of things that are public.
00:34:46.180 - 00:35:44.360, Speaker F: It turns out people actually don't like dark pools as much. People want to see the order book or they want to see the amm pools and things like this. And so having systems where it allows people to. The simple solution that we were like, hey, the easy v one for this is just having a shielded pool which assets can come in and out of and try to, it's not going to give you the full level of privacy. There's all these sorts of things you could do to reverse engineer figuring out what's happening. But if you're making it harder, at least, and giving the tools that allows people to make it as easy as possible for people to shield as much as they can, I think that's at least the first pretty good step. I think that's what people care about most.
00:35:44.360 - 00:36:05.466, Speaker F: I've talked to a lot of traders, and they're like people who traditionally trade on market makers on centralized exchanges. One of the reasons that they actually don't want to market make on decentralized exchanges and stuff is that we're literally leaking our trading strategies. Their goal is not to compete against state level actors here.
00:36:05.488 - 00:36:05.674, Speaker D: Right.
00:36:05.712 - 00:36:23.554, Speaker F: They're just trying to hide against other traders from copying them. And really what they care about is hiding on the scale of couple of minutes because they just don't want people copying their trades in the next couple of minutes. And so this is kind of like the more practical stance that we're trying to take.
00:36:23.672 - 00:37:21.380, Speaker B: It's so interesting because I'm hearing that not only here, but in a lot of ecosystems is this like there's two privacies. I mean, this is fairly obvious, but there's the privacy for the individual of the business from their competition, or just like random people, and then there's privacy from the analytics and the governments and all of that. And that's different. And I know that if you're talking about a trading context, then, yeah, I think it's mostly just to be able to keep your strategies to be your own and not have to share those. But I wonder. It's so funny, because I feel like there are also different camps of folks who would worry that if you only focus on the light privacy, that deeper lack of privacy will come bite you in the ass so much worse. Like the state actor, and we have one on the call, but two at least.
00:37:21.380 - 00:37:44.922, Speaker B: But it is interesting to see how these, when we talk about incentives, there also are no incentives right now for private style like Dexes, who want privacy to necessarily offer that full level of privacy, and the incentive is not built for that. Henry, you put your hand up as a counter. So what is your thinking?
00:37:45.056 - 00:38:45.440, Speaker D: No, I did a thumbs up. So I agree. I would self describe as that person who thinks that trying to draw this distinction is going to come around and bite everyone in the ass in ten years. I think that one of the trends that you can see in technology, and surveillance technology in particular, is that over time, the cost of having some capability comes down. So if you think about the way that online advertising works, it's actually structurally quite similar to the kind of program that you would need to monitor everyone's web browsing activity. But it's just done by all these random companies. And there's people like chainalysis, right.
00:38:45.440 - 00:39:49.534, Speaker D: Often in the community, people sort of lump in chain analysis with the feds. But chain analysis is just a company, right? They obviously do a lot of contracting with state actors or spy agencies or whatever, but there's no fundamental reason to think that there is a kind of hard line that will last into the future. There's kind of an evolving landscape of, on the one hand, you have privacy capabilities and there's a kind of marginal cost to effort, or how much privacy you're getting for how much effort you're taking to use this tool. And then on the other side, you have this kind of spectrum of surveillance and monitoring technologies. And that landscape is not fixed. It changes over time. But the terrain that is being contested there is fixed.
00:39:49.534 - 00:39:59.830, Speaker D: So you only actually get movement in the direction of de anonymization. You can't retroactively boost your privacy.
00:40:00.730 - 00:40:23.760, Speaker B: But that's what I'm wondering about specific to cosmos, like bringing it back to this particular ecosystem. Do we know what the sentiment of the cosmos ecosystem is towards privacy? Is this an ecosystem that is thinking like that, or is it an ecosystem that wants this to actually be very free flowing, very transparent in the.
00:40:24.530 - 00:40:37.460, Speaker A: So I don't know about now, but at least I remember in tenderman office we had heavy debates about this. You might remember Chris and Sonny, where some people really wanted the hub to never have privacy, and a lot of us wanted to have privacy a little bit.
00:40:38.150 - 00:40:38.946, Speaker F: Oh, I don't know.
00:40:38.968 - 00:40:41.670, Speaker A: I was not very much at the hub. Let's get lots of it.
00:40:41.820 - 00:40:43.222, Speaker B: Let's get lots of it.
00:40:43.356 - 00:41:37.000, Speaker C: Yeah, there certainly are. In applying privacy to particular aspects of blockchains, there are dangers that don't surface when applying it to other aspects. So I think private proof of stake is interesting and has compelling advantages and also has potential dangers insofar as it makes it much harder as a user to ascertain what the security of the system you're using actually is. And maybe there are ways to mitigate that. And maybe a good counterargument to what I just said is that users can't ascertain what the security of the system they're actually using is anyways, because validators identities are difficult to discern and potentially all we can really do is incentive design. And it makes more sense to focus on things like correlated slashing than worrying about whether the validator's identities are public or not. I'm sympathetic to that argument, but it's not clear to me.
00:41:37.000 - 00:41:45.080, Speaker C: It's still conceptually rather hazy as to what that trade space looks like.
00:41:45.770 - 00:42:02.350, Speaker F: Another one is voting. Right? Like governance voting. I think that was one of the topics for the cosmos hub, which is like, do we want governance voting to be private? And I think I was on the stance where probably not. I mean, I want reputational harm done for malicious voting.
00:42:04.290 - 00:42:19.700, Speaker A: Staking derivative design. Sorry, private staking designs I've seen with delegation. I guess not. I've seen Henry's talk introduces derivative tokens, which is actually a huge change to the underlying staking model security. You've removed this unbonding period stuff.
00:42:21.050 - 00:42:24.818, Speaker D: I didn't mention it in the talk, but there is an unbonding queue.
00:42:24.914 - 00:42:25.766, Speaker A: Oh, never mind.
00:42:25.868 - 00:42:26.520, Speaker B: Perfect.
00:42:28.330 - 00:42:29.560, Speaker A: I take that back.
00:42:32.810 - 00:42:36.940, Speaker D: You don't get like instant settlement on that. Sorry, I should have been more.
00:42:39.950 - 00:42:49.514, Speaker B: Oh, Tony just actually added to this a little bit for the voting idea. Give validators the ability to prove how they voted, but don't force them to. That would be cool. This is the comment.
00:42:49.642 - 00:43:21.990, Speaker D: Well, it kind of seems like there's a potential distinction that you might want to do between validator votes and delegator votes. So if the setup is that validators are voting on behalf of their delegators as a kind of a default vote, and the validators are the ones participating in consensus, I think it does kind of make sense to say, like, validators have accountability and delegators have privacy.
00:43:25.710 - 00:43:26.074, Speaker B: But.
00:43:26.112 - 00:43:29.420, Speaker D: Maybe that's just because, sorry.
00:43:31.230 - 00:43:53.460, Speaker A: We should extend that to liquid democracy as well. Not just dollars can delegate to, but anyone can be delegated to. Whoever is like, your delegate should maybe should be public, but all the constituents can override privately with the nonsense that being constituents to that entity. I thought of not leaking your address.
00:43:55.030 - 00:45:00.242, Speaker D: Trying to build some kind of liquid democracy style delegation of stakeholder voting, but the thing that I got stuck on is, ideally, you would want the voting to be split out into a kind of separate capability. So for people who aren't super familiar with sapling, there's this cool, crazy hierarchy of all these different keys that are involved. There's not just one key, and each key corresponds to kind of a different capability of something you can do to that, whether that's like spend it or view it or whatever. So maybe you could try to do something like having like a governance sub key that would allow you to only do voting. But if the voting mechanism is kind of piggybacking on spending notes, you have a challenge where the person you delegate authority to do the voting to might not create a new note for you to keep your balance.
00:45:00.306 - 00:45:00.630, Speaker C: Right.
00:45:00.700 - 00:46:00.010, Speaker D: So you'd have to have some kind of constraining that they did the voting correctly. And that's tricky, but I think that would be really cool. And we could just build it. Well, one of the problems with trying to do a liquid democracy style system is that if the idea is that you're going to implement this kind of like delegated voting for democratic decision making, and we're going to hook that into kind of like an existing democratic institution that we have, then you have to get everybody on board first before you can even build and test the system. I think that kind of ties into one of the things that's so exciting about the blockchain space is that you have people basically speed running every single possible coordination mechanism design that you could ever imagine. Like, sure, let's just build it, see what happens.
00:46:00.080 - 00:46:00.966, Speaker B: And then they blow.
00:46:01.078 - 00:46:01.910, Speaker D: Maybe it'll.
00:46:02.070 - 00:46:27.650, Speaker B: Yeah, it's kind of cool. All right, we have three minutes left. I don't know if there's any other questions from the audience, from the folks there. John gave an example of this delegated context and privacy in a link there. But yeah, if anyone has any other questions or if any of you want to say anything else about this topic of privacy, Cosmos.
00:46:31.270 - 00:47:27.698, Speaker F: I think one thing to be like that's interesting is I think one of the major projects right now in cosmos ecosystem is the secret network. And I think they take a very interesting approach where they kind of forego all this cryptographic stuff and it's like, you know what, let's just use the simplest possible way to get this done and just using SGX. And I think in Dave's talk we talked about we're not super big fans of SGX, but at the same time it's for depending on your use case. I think it is actually quite a know, I think it solves some people's use cases and in fact I think it note is actually underselling themselves. I think the interesting side of them is not the privacy. Yeah, because I think the privacy isn't the interesting part. I think it's really, it's like hey, it's a replacement to an MPC.
00:47:27.698 - 00:47:58.240, Speaker F: Anything you need MPC for is hey, you can just use this secret network thing. SGX is like such a hack, but it's know if you're okay with the intel safety model like trust in intel. The other problem with SGX is that there's an availability problem to. Right, like I can just shut off my server that's running my Intel SGX. But secret network kind of solves the availability problem for SGXs by creating a distributed SGX which know I think that's a useful thing to have.
00:47:58.770 - 00:48:12.626, Speaker A: Well it's not useful for the goal of privacy, for Private Henry's point, like for private state, this is maybe one of the worst things you do if you want long term security since it.
00:48:12.648 - 00:48:42.320, Speaker F: Depends on what your use case. Right. Like I can totally see there being some users who find value in the level of privacy that secret offers that I think no other production system offers at the moment. I think Secret Network currently provides capabilities that no other production level system provides. Even if it's not the best level of privacy you're going to get, it's better than not having that capability at all.
00:48:44.930 - 00:49:16.442, Speaker B: Bringing this up, by the way, just made the chat blow up with lots of opinions. So actually this might be a great moment to sort of thank all of you for coming on and talking, coming to this event. I'm saying, coming on like I'm still doing a podcast. Thank you for coming to this event and for sharing all of this. We're actually going to break out now into a set up where we can go to the sessions and create our own sessions. So we're going to just create another one of these. I'm going to create one, but I would love it if you will.
00:49:16.442 - 00:49:48.482, Speaker B: Also, all of you here create new sessions so that people can actually engage and have this conversation continue. But big thank you to everybody. This was a very fascinating event. I feel like I'm coming away with a better sense of what's kind of possible, what the issues are. And we're going to definitely be creating a report or some sort of blog post about what we've learned today. And we're also going to have a forum that we're going to share with a few people to try to get some ideas around what other people are thinking. So, yeah, I'm going to shut this down.
00:49:48.482 - 00:49:54.660, Speaker B: I think if you all want to bounce out of here, I think it shuts it down and we'll head over to sessions. Thanks, everyone.
00:49:55.190 - 00:49:55.680, Speaker C: Thank you.

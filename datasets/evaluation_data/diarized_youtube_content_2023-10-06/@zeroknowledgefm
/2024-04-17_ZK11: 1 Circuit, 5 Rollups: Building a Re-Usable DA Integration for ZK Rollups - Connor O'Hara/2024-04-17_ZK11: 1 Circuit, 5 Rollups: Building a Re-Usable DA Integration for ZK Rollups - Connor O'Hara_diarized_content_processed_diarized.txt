00:00:07.560 - 00:01:12.524, Speaker A: My name is Connor and I'm an engineer and I work for Celestia. Celestia is a layer one blockchain which is minimal and modular, and it can be used in a variety of different ways. Some of the ways you might see Celestia used are for sovereign rollups which are kind of like app chains or regular roll ups which settle on some settlement layer. Or the most popular use case celestiums which are when you use Celestia data availability for a l two, that settles on Ethereum. This is currently the number one user of the Celestia block space, and it's also what this talk is going to be mostly focus on. The title of the talk is building a reusable ZK powered data availability integration for ZK rollups. Well, I guess just for any kind of roll up, but this talk most mainly about ZK rollups.
00:01:12.524 - 00:02:20.575, Speaker A: And while everybody here probably is already familiar with the concepts of rollups and data availability for the sake of completeness, I think it makes sense to quickly go over what these things are and how they work. So rollups were originally conceived as a way to scale a lower throughput blockchain. They were originally conceived as scaling solutions for Ethereum. And the general gist of how it works is you have a a high throughput blockchain which produces big blocks with many, many transactions from users, and it will post its headers and a ZK proof to a lower throughput blockchain. Ethereum is the main example of this, and that's a way to scale it. It gives you a trust minimized bridge from a low throughput chain to a high throughput chain as a scaling solution. To go more into detail about how a ZK rollup works, you have your circuit which proves the correctness of a state transition, the Zkrollup, basically a big old state machine.
00:02:20.575 - 00:03:38.200, Speaker A: And what goes into the private inputs are transactions from users and then whatever other intermediate witness data that you need to prove the correctness of the state transition. And then the public inputs shared between the prover and the verifier are commitments to the old state and the new state, or something like that. I'm being very vague and general because they vary quite a bit in what exactly it uses for the private inputs and the public inputs. So you have your roll up block producer, and your roll up block producer produces a big block for the roll up. Then it generates a validity proof for the correctness of that, and hands the new header and the validity proof over to the verifier, which in the case of an l, two runs on the EVM in a settlement smart contract. And once the verifier has the header and the ZK proof, he knows it's valid, right? Wrong. If all the verifier does is look at the header and the ZK proof, there's a way that he can still be tricked, which is if the rollup block producer gives him a header and a proof for a block that doesn't exist.
00:03:38.200 - 00:04:45.410, Speaker A: For a block that he deleted right after he created it and didn't share with anyone. In other words, if the data is unavailable, so the verifier would be left wondering whether or not a block exists that corresponds to the header and proof that he's looking at. So we call this data availability. The verifier needs some way to validate the availability of the data for the roll up block that he's looking at now. What exactly is the data that needs to be available? So remember the circuit for the Zk rollup, and remember its private inputs. Some subset of the private inputs are necessary to reconstruct the state and produce the next state transition, or for users to be able to withdraw their balances, et cetera. We call this the pub data, the subset of the private inputs which needs to be available, or rather that the verifier for which the verifier needs to validate availability.
00:04:45.410 - 00:05:19.372, Speaker A: We call pub data. This term I borrowed from zksync. I believe they're the first people to have come up with the term pub data. Thank you zksync, for coining that useful term. And there's three ways which we see data availability being validated in practice. First is the old Ethereum way using call data. The second is the new Ethereum way using the blob space, which was given to us in EIP 4844 as part of the den koon upgrade.
00:05:19.372 - 00:06:35.344, Speaker A: And then the third way is with celestiums, the roll ups which opt to use celestia da instead of l, one da for one reason or another, possibly increased throughput or decreased cost or something or other. So let's get into it. We're gonna go through how each of these ways work quickly in practice. So for the ethereum way, prior to EIP 4844, back when all the Zk rollups were using call data, what you would do is you would have the circuit compute a commitment to the pub data and then add that commitment as a public input. So the way that this is done is it usually just takes a linear keck hash of the pub data. So the state deltas, for example, is usually what the Zk rollups require in the DA, and so the circuit will actually just hash them using kecack, because that is an EVM friendly hash function. And then when the roll up block producer goes to settle the roll up block on ethereum, of course, he posts the l two block header and the l two state transition proof, and the EVM will verify that.
00:06:35.344 - 00:08:00.384, Speaker A: But also it takes the whole pub data, dumps it into the EVM, then the EVM hashes the pub data, and then verifies that the hash of the pub data that it computed in the EVM matches the one that it got from the block producer's proof with public inputs. This is pretty well documented in Zksync's docs as well as in a blog post by scroll. If anyone is curious about how data availability is done in ZK rollups, I'll let you scan that for another second. All right, but everything changed with the Den Koon upgrade, and now Ethereum has given us a bunch of extra blob space to use for DA to massively increase the capacity of these roll ups. But yeah, so the way it does this is it exposes this new API where you can send a so called blob carrying transaction, and that lets you get a 130 1 kb blob. And that goes into the block. It goes into a special part of the block called the Blob space, but you can't access the contents of the blob from inside the EVM.
00:08:00.384 - 00:09:01.374, Speaker A: Rather, you can only access the KZG commitment to the blob in the EVM. But as it turns out, that is sufficient to verify proofs about the blob, which is all we really need. When ZQ rollups go to integrate 4844, they have to do it quite a bit differently than the old call data way that I explained in the previous slide with the KecAc hash. Now what they do is they add the KZG commitment as a public input. But unlike with the previous way where we recompute the KCAC hash in circuit, you cannot recompute the KZG commitment for the blob in circuit, because that would be a whole bunch of non native multiscaler multiplications, and it's basically completely infeasible. Luckily, we can do it non deterministically. So this technique I first saw mentioned by Vitalik on the ETH forum post in about 2020.
00:09:01.374 - 00:09:51.764, Speaker A: And the general idea is you'll put the KCG commitment in as a public input. And then you'll verify it with this clever, non deterministic fiaschmir trick, where you compute a challenge point by hashing the blob with its KZG commitment. And then you evaluate the. Well, you take the blob and you interpret it as a polynomial in evaluation form. And then you use the barycentric formula to evaluate the blob's corresponding polynomial at this challenge point. And then you take the challenge point, and you also add that as a public input. And then you have the prover compute a opening proof from the challenge point to the KZG commitment.
00:09:51.764 - 00:10:35.064, Speaker A: And then the verifier then has to check that as a little bit of extra work. But it's very, very light. Verifying a KZG opening is very, very lightweight, and it's generally a much better trade off than doing anything crazy on the prover side, especially when all this non native arithmetic is used. So yeah, that's how the ZK rollups are starting to integrate. 4844 and a bunch of them have already done this zksync and scroll. As far as I know, they both have code for this. But what if 4844 is still not enough throughput for you, or it costs too much or something or other, and you want to use celestial on your l two, which is a.
00:10:35.064 - 00:11:50.944, Speaker A: Like I said before, the most popular way that Celestia is currently being used. So to understand how we adapt the Zk rollups to use Celestia dA, we first need to go into how Celestia works a little bit under the hood. So Celestia has giant blocks, and it takes blob transactions from users. And then for each block of Celestia, it breaks each blob up into 512 byte shares, and then it lays the shares out in a erasure, codes them into a bigger two d square, and then it takes merkle roots of each individual row and column and basically kind of unrolls the whole square and creates this giant merkle tree, which the root, we call the data root. And the dataroot gets signed by the validators as part of the header. And we relay this onto different chains, notably Ethereum. So Ethereum has all the celestial blocks, signed data roots as part of its state, and we call this the Blob stream bridge.
00:11:50.944 - 00:13:00.824, Speaker A: Now that we have, now that you're given the data routes in the Ethereum state, you can just add the Celestia data route as a public input to your circuit, and then you don't even need to prove a commitment, you can just go straight to inclusion and prove that your pub data is included. It is a bunch of SHA 256 hashes. So it's a little bit not ZK friendly, but they're getting pretty good at those these days. But wait, this talk is building a reusable ZK powered DA integration, not rip up the prover side code and rewrite the contract for a bunch of different languages and proof systems. So we want to build this integration in a way that modifies the roll up as little as possible. We don't want to have to rip apart polygon, Starknet, Aztec Scroll, Zksync. We would like to integrate them without needing to do too much modifications, especially to the prover side contracts.
00:13:00.824 - 00:14:00.602, Speaker A: And what modifications we do need to make. Try to keep them on the verifier side, where it's generally a lot easier to change them to do integrations. So we keep the ZK rollup circuit the way it is, and we build a new circuit for the integration. And this circuit is pretty simple. All it does is it takes the pub data from the roll up and it adds the Celestia dataroot as a public input, and it proves that that blob is included in the dataroot and that it has the same commitment that the ZK rollup was already working with before. A nice thing about 4844 is that 4844 gives the roll ups a standard commitment to use that we can very easily hook into. Back when they were doing call data based DA integrations, they did it differently.
00:14:00.602 - 00:14:39.636, Speaker A: Some of them were doing linear KK hash. Some of them might have been doing Sha, some of them may have been doing merkle trees or various other ways to commit to it. With 4844, they're all going to do KZG. And so it's one thing that we can reuse. All right, and a quick detour on circuit development. Step one, before building a circuit, try it in a ZKVM and see if it's fast enough, which we did, and it's certainly fast enough. So our blob inclusion proofs run really, really fast in SP one and RISC zero.
00:14:39.636 - 00:15:29.750, Speaker A: And now there's jolt, which came out yesterday. So I'm looking forward to try to run it in that as well. And yeah, there was already rust code for all the types and merkle trees that our blob inclusion proofs use. And both SP one and Risc zero provide forks of the rust Sha two crate, which are patched to have cryptographic accelerator for the hash function. And so getting this to work was extremely easy. And we were really impressed with the performance. And it's faster than the l two block proving time, so the whole system will not be bottlenecked by the DA integration and the DA integration can run, can start proving in parallel while the l two block is being proved.
00:15:29.750 - 00:15:47.454, Speaker A: So we feel no need to go in hand. Optimize a table for a starc to do this when the ZKe vms work so nicely. And that is about it. So happy to start taking questions.
00:15:57.734 - 00:16:03.914, Speaker B: Yeah, thanks Kenor. Make sure you ask for the mic. Can you come in the front to ask you questions so that it's recorded?
00:16:06.454 - 00:16:14.714, Speaker C: Hi, thank you very much for the very good presentation. I have a question about the pub data. What is the size of pub data and is it all stored in the EVM contract?
00:16:17.174 - 00:16:18.982, Speaker A: What was the part about the EVM contract?
00:16:19.158 - 00:16:26.714, Speaker C: The settlement contract on the roll up? Not on the roll up, on the ethereum. The web data ending in the Ethereum. Right. As input.
00:16:27.334 - 00:17:05.404, Speaker A: So it varies in size. And with EIP 4844, all the blobs are a fixed size of 131 kb. So I think what we're seeing in practice right now, correct me if I'm wrong, is that they're not full rollups are getting blobs and then not filling them all the way up. But theoretically, if there's more transactions from the users, they might need multiple blobs. And then there's. Right now there's a limit per block on how many blobs there can be per each Ethereum block. And then before with the call data, I'm not sure, I'm not sure what the limit was or what the.
00:17:05.404 - 00:17:11.528, Speaker A: Like if you, if you're allowed to take up a whole block, ethereum block with call data or not. That's a good question.
00:17:11.656 - 00:17:26.873, Speaker C: Okay. And yeah. What happens actually, if the, the block actually surpasses the blob size and it cannot be posted on chain, what will happen? I mean, it's committed on the layer two and eventually it has to go to layer one. So what am I missing here?
00:17:26.993 - 00:17:38.533, Speaker A: Well, you know, the roll up needs to be aware of what the max blob size is and it shouldn't produce a block that can't fit.
00:17:39.153 - 00:17:42.813, Speaker C: Yes, but all the roll ups are racing for blob space, right?
00:17:43.764 - 00:17:44.924, Speaker A: That's true, yeah.
00:17:45.084 - 00:17:50.464, Speaker C: So it's not something that they can calculate ongoing or is it?
00:17:51.124 - 00:18:12.674, Speaker A: Well, I mean, like what a roll up can do is a roll up can say, we're going to use one blob of 131. Once they create a full block, they just keep trying to get it into the l one. And if the l one is congested, then it has to wait or start fighting with the other ones, and then you're just out of throughput. Then the l one is just needs to scale more.
00:18:15.174 - 00:18:17.114, Speaker C: Okay. I say thank you very much.
00:18:26.894 - 00:18:48.644, Speaker D: Hey, Connor, when we were talking about the circuits, you're telling us you could have a different circuit that will only verify the blob and will not integrate in the other circuit. I noticed there was an arrow there that actually had the commitment being committed by the original circuit. I was wondering if the challenge point has to be included in the original roll up circuit or if there's a way around that.
00:18:49.224 - 00:19:11.544, Speaker A: Oh, that's a good question. Well, I mean, I tried to draw the arrows so that the challenge point and the KZG commitment go into both, but I don't know. It's a little bit frustrating to use the drawing tool. I think that both circuits need to have the challenge point and the KCG commitment. Maybe there's some way around it. I'm not quite sure.
00:19:12.604 - 00:19:17.384, Speaker D: So, if I wanted to integrate this right now, I would have to change the Zkrollapp circuit to commit to that.
00:19:19.324 - 00:19:58.204, Speaker A: Well, so we don't actually have the. We only have the blob inclusion proof, the celestial blob inclusion part side of the circuit done at the moment. And this is first going to ship. Not with KZG. This is going to ship first with a call data based one. We're going to try this first with Polygon and Polygon Hermes, which still does the Keckac hash. And the KZG side of it is kind of more of a long term roadmap to make it universal and reusable.
00:19:59.384 - 00:20:00.164, Speaker D: Cool.
00:20:14.344 - 00:20:22.764, Speaker E: Hey, yeah, so, just a quick clarification here. So, the ZK rollup circuit is from the roll up itself, and then the other two circuits are celestia circuits. Correct?
00:20:22.864 - 00:20:49.008, Speaker A: Oh, yeah. I should have said more about that. So, the DA integration circuit is for the celestial integration. And this one here, the outer verifier. This is kind of, like, very abstract and vague. So you could have the integration circuit and the ZK rollup circuit get verified directly by the EVM. And then you would have the EVM verifying two ZK proofs.
00:20:49.008 - 00:21:13.244, Speaker A: In practice, though, the ZK rollups all have some sort of outermost proof that wraps some sort of inner proof. Like, for polygon Hermes, they take a stark, and they wrap it with groth 16. And what would be more gas efficient is to actually just verify the integration and compare the public inputs in that circuit rather than doing two in the EVM.
00:21:15.444 - 00:21:29.292, Speaker E: Okay, thanks. And so I guess the point though is that the ZK roll up circuit, you've modified that as little as possible. So basically you've just added this challenge point and a little bit of stuff into there, and everything else is outside the circuit or overlaid over the roll up circuit.
00:21:29.348 - 00:21:37.504, Speaker A: Yeah, I mean, if the roll up is already integrating 4844, then they already have the challenge point and the KZG commitment, and we just will hook into that with our circuit.
00:21:48.704 - 00:22:01.844, Speaker D: I wanted to ask, have you tried benchmarking the price difference in us dollars of using celestia against using dank sharding? Since it came out about two weeks ago.
00:22:03.624 - 00:22:07.458, Speaker A: I don't have the figure. I don't know the figure off the top of my head, unfortunately.
00:22:07.576 - 00:22:08.234, Speaker C: It.
00:22:37.634 - 00:22:44.414, Speaker D: Like what is fundamentally changes if the l two is not ZK rollup another type of role?
00:22:45.074 - 00:23:45.274, Speaker A: Yeah, that's a good question. So we have done celestial integrations with two different optimistic roll ups, and for both of them we had to rip apart the code and deeply, deeply, surgically insert celestia stuff into op stack and arbitrum orbit. But theoretically, if the optimistic roll up uses 4844, we could generalize this into a generalized 4844 compatibility layer, which is sort of like long term roadmap, where we would have a bunch of KCG commitments in the Ethereum state, and then proofs that those are included in the corresponding celestial data route. And then the optimistic roll up could just modify their verifier a little bit to just look into that API, rather than us needing to rip them apart as well. So it is possible to generalize this tech for optimistic role offs as well.
00:23:46.294 - 00:23:47.274, Speaker C: Thank you.
00:23:53.174 - 00:24:04.764, Speaker F: Initially you said you are using a matrix to put the data in a matrix. What's the reason for that? And why not use a cube or higher dimension storing it?
00:24:06.184 - 00:24:38.374, Speaker A: Why don't we use a cube? That's a good question. Sometimes I wonder, why don't we use a line? But it's the erasure coding. It has to do with the way that celestia allows light nodes to verify data availability using the sampling mechanism, which I didn't want to bore you all with because it's been discussed on zero knowledge podcast in about four different episodes. I highly recommend you listen to them though, if you're interested, because it is very cool.
00:24:50.494 - 00:25:04.474, Speaker B: Sometime I come, sometime I come, and then there are specials we have time for. One last question. If you were shy up until now, you can still speak up okay, we have one here.
00:25:04.854 - 00:25:22.142, Speaker C: Maybe one last question that. Okay, so what is the problem with the blobscriptions? I heard something that the blob space became like a racing condition, like an open market and auction based because of some project. If you want just to comment on that. I have no idea. I've just read some articles, to be honest.
00:25:22.158 - 00:25:59.792, Speaker A: Yeah, sure. No, yeah, that is true. So the first few days of the Den Koon upgrade, blobs were really, really affordable. And so the transaction fees on all the l two s were super low. But if some resource is free, then people are going to start using it and bidding it up. And there was an inscriptions project, which is just inscriptions is just basically just wasting block space for fun and just paying money for fun to put random stuff on the chain. And very quickly, those people got ahold of the blobs and they pumped up the price a lot.
00:25:59.792 - 00:26:21.440, Speaker A: It was going to happen anyway because we think these things will be used and we think there will be demand for block space. So the blobs were going to go up in price eventually. There was going to be some contention. This is just accelerating the inevitable. And, yeah, I mean, thankfully, there's lots of capacity. They're going to add more blobs. There's going to be full dank sharding.
00:26:21.440 - 00:26:22.884, Speaker A: And there's also Celestia.
00:26:24.144 - 00:26:25.044, Speaker C: Thank you.
00:26:36.104 - 00:26:37.684, Speaker B: Okay. Thank you, Kunal.

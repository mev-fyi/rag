00:00:05.640 - 00:00:54.151, Speaker A: Welcome to Zero Knowledge. I'm your host Anna Rose. In this podcast we will be exploring the latest in Zero Knowledge research and the decentralized web as well as new paradigms that promise to change the way we interact and transact online. This week Tarun and I chat with Andrew Miller. We cover his previous work on consensus, ZK and MPC and then switch to the focus of his current work TEES or Trusted Execution Environments. We map his evolving opinion on TES and why he sees them as an optimal solution to many blockchain challenges. Now, before we kick off, I want to remind you about ZK Summit 12 happening in Lisbon on October 8th.
00:00:54.151 - 00:01:17.915, Speaker A: Our one day ZK focused event is where you can learn about cutting edge research, new ZK paradigms and products, and the math and cryptographic techniques that are giving us epic efficiency gains. In the realm of zk, space is limited and there's an application process for early bird tickets. I've added the link in the show notes. Be sure to apply and see you there. Now Tanya will share a little bit about this week's sponsors.
00:01:19.015 - 00:02:01.665, Speaker B: Aelio is a new layer 1 blockchain that achieves the programmability of Ethereum, the the privacy of zcash and the scalability of a rollup driven by a mission for a truly secure Internet. A LEO has interwoven Zero Knowledge proofs into every facet of their stack, resulting in a vertically integrated Layer one blockchain that's unparalleled in its approach. AELIO is ZK by design. Dive into their programming language LEO and see what permissionless development looks like, offering boundless opportunities for developers and innovators to build ZK apps. This is an invitation to be part of a transformational ZK journey. Dive deeper and discover more about ailyo@ailyo.org GeValot is the first decentralized proving layer.
00:02:01.665 - 00:02:44.575, Speaker B: With GeVilot, users can generate and verify proofs using any proof system. For any use case, you can use one of the default provers from projects like Aztec, Starknet and Polygon, or you can deploy your own. Gevilot is on a mission to dramatically decrease the cost of proving by aggregating proving workloads from across the industry to better utilize underlying hardware while not compromising on performance. Gevilot is offering priority access to ZK podcast listeners, so if you would like to start using high performance proving infrastructure for free, go register on gevalot.com and write ZK podcasts in the note field of the registration form. So thanks again Gevalot and Now, here's our episode.
00:02:48.245 - 00:02:52.741, Speaker A: Today. Tarun and I are here with Andrew Miller. Welcome to the show, Andrew.
00:02:52.853 - 00:02:55.813, Speaker C: Hey there. Thanks so much for having me. Glad we can finally do this.
00:02:55.909 - 00:02:57.357, Speaker A: Totally. And hey, Tarun.
00:02:57.461 - 00:02:59.573, Speaker D: Yo. Excited to be back?
00:02:59.749 - 00:03:26.217, Speaker A: Yeah. So, Andrew, you are one of those guests that I've been trying to get on the show for a very long time. I put the word out a few years ago through friends trying to reach you. I didn't at the time, but I'm very, very happy that I got a chance to actually run into you about a month ago. Like, we were on a panel you couldn't get. I was like, hey, would you be up for coming on the show? And you said, yes. And I'm so glad that you're here.
00:03:26.217 - 00:04:00.027, Speaker A: I know that for today's episode, we're going to be primarily talking about teas and your work on that kind of topic. But before we go into that, I'd love to go back in time a little bit and look at some of the earlier work in your career. As I was doing a bit of research, I saw that you had worked on early papers with Joe Binneau and Ed Felton and I know some other authors. I just saw a lot of your work intersecting with previous guests on this show. Let's go back to maybe that point. Let's start there. What were you working on back then? What were the problems that were very exciting to you?
00:04:00.131 - 00:04:51.775, Speaker C: Oh, wow. Yeah. I mean, so just prior to starting to work with Arvind Narayanan and then Jobanot and Ed Felton on, we did this textbook together and an early systemization of Knowledge. Right before that, I had been kind of pivoting my original grad school career in VR and graphics and 3D stuff, but just got totally down the rabbit hole of bitcoin and especially reading like the old consensus papers and BFT papers and talking on the bitcoin dev IRC channel and all of that. So my first interest there was really trying to do consensus BFT models of Bitcoin, understand it from a BFT protocols perspective. And I had been doing this, posting a lot on Bitcoin forum and on their IRC channel. Also talking with other academics was known by that I think I ended up responding to.
00:04:51.775 - 00:05:29.727, Speaker C: It was Arvind who initiated this. He said he's trying to work on this survey paper and it's on bitcoin cryptocurrencies. Anyone interested in helping just join from the public or academia or whatever. So I signed up and I started to get really interested in What I would say is bridging the gap of academia in industry, which at the time, and really how I would frame that project with them is we had seen this trend of research papers that you're either reinventing or just talking about bitcoin things. And then everyone in bitcoin world is furious that, oh, you're not citing our mailing list post from the other week or, you know, following art. We've already gamed through the, you know, consequences of these tech choices.
00:05:29.831 - 00:05:33.595, Speaker D: The Greg Maxwell invented everything before you did argument.
00:05:33.675 - 00:06:06.945, Speaker C: Yeah, that's a Matt Green tweet. Right? You know, every good idea under the sun has been invented years ago and just thoroughly refuted in the Bitcoin Talk forum. And so, yeah, we tried to do the survey paper that would, you know, bring us all into alignment there and had a bunch of, I think events we hosted with cryptocurrency devs at the time. And did it work? I absolutely think it worked. There's now quite a lot of, you know, there's a strong pipeline of this was before all of the professor coins, if nothing else. So, okay, there's I think now a very, you know, high bandwidth bridge between academia and the Web3 industry.
00:06:07.065 - 00:06:13.049, Speaker A: So you were working before this on like media, video stuff, like video encoding. What did you just say?
00:06:13.137 - 00:06:32.519, Speaker C: Oh, augmented reality. I had a really cool project as my master's project on the Microsoft Kinect, you know, the 3D scanner. So you would do real time scanning of Duplo blocks as you would build them and then instructions for how to follow along would pop out on a remote side on a projector thing. So it was OpenGL graphics, matrices kind of stuff.
00:06:32.607 - 00:06:34.815, Speaker A: Were you in computer science doing this?
00:06:34.895 - 00:06:36.119, Speaker C: Was computer science, yeah.
00:06:36.167 - 00:06:37.055, Speaker A: Oh, it was okay.
00:06:37.135 - 00:06:38.575, Speaker C: Yeah. This was at Central Florida.
00:06:38.655 - 00:06:45.663, Speaker A: Is there any point where anything you learned from that comes back into play in what you've been working on ever since?
00:06:45.799 - 00:06:58.519, Speaker C: Oh, wow, that's kind of a tough question. Maybe. I mean, what's ever on my mind about that is just I really like changed my behavior and personality almost entirely before there. I was a terrible grad student the first time around.
00:06:58.607 - 00:06:58.919, Speaker A: Okay.
00:06:58.967 - 00:07:27.667, Speaker C: I only like doing my own programming and I didn't like reading papers or talking to anyone. I just wanted to wait it out until joining a game company or something. But then when I pivoted to crypto, I switched hard and I was then really interested in understanding the old papers and kind of this connection to historical efforts and did a much better intentional job of socializing the research and trying to do that. So that ended up a lot more fun the second time around. But it's like I got a second go at grad school.
00:07:27.811 - 00:07:36.655, Speaker A: Nice. But why do you think that is? What was it about this topic or this community at the moment that you joined it that got you so excited?
00:07:36.775 - 00:07:58.679, Speaker C: I guess at the time I felt this really strong sense of mission. I had this sense that was like, I've got this opportunity. I'm already in grad school and supposed to be doing this. And this is such an important movement. It has all of this potential. I was really into free software and I guess libertarian principles at the time. I think I had wanted at some point to be an Electronic Frontier foundation lawyer.
00:07:58.679 - 00:08:26.771, Speaker C: That was like another career path I was trying to pick for myself. So it's like, this is the way to contribute. This is really important. At the time, I felt that just by being an academic and working on Bitcoin, I would be bringing it to the mainstream or getting the right people's attention to look at it for the right reasons. And I kind of figured it would just crash. But still, I could carve out a little theory niche where a new look on BFT protocols and that would be interesting enough for one career start.
00:08:26.883 - 00:08:29.535, Speaker A: Cool. How old were you when you got into this?
00:08:30.005 - 00:09:00.385, Speaker C: How old? It would have been 2011 that I started my kind of pivotal. I kind of dropped all of my tasks and got away with it, but just spent the whole year and a half reading these BFT papers and posting. And then in 2013, I transferred to UMD and that was when I really started my grad school, you know, over again, fully. It was like high energy. I showed up with like, printouts of all my bitcoin talk forum posts, and it was like, these are the, you know, topics and directions I want to turn into, you know, research papers. And, you know, largely got to do that.
00:09:00.685 - 00:09:06.741, Speaker D: My first experience of your work from that time, ish, was the nippo pose.
00:09:06.813 - 00:09:07.677, Speaker C: Nippopause.
00:09:07.821 - 00:09:38.121, Speaker D: Nippopause. I guess, like when you were reading the forum posts and then kind of congealing things into research, was your goal more to be computational anthropologist, or was your goal of that era? Or was your initial goal to, like, find something new? Because, like, I kind of feel like I've seen both of your writing styles of like, I guess I'd call Internet anthropologist versus the kind of pure new type of stuff. And I'm just kind of curious, as you kind of did that transition, how you kind of balance those two goals.
00:09:38.273 - 00:09:53.137, Speaker C: That's a fun question too. Yeah. I viewed it as a balance. I viewed that as two facets. I love the computational anthropology viewpoint. I picked up a lot of that from Nick Szabo too. That was a lot of his style of writing posts about the historical context and also these new things.
00:09:53.137 - 00:10:29.239, Speaker C: Maybe I viewed him as like a role model, like that. Definitely part of it. But oh, I wanted to, I wanted to break, you know, a new thing somehow I think I ended up falling into, you know, the path of what I would do is I don't feel I've been right on the cusp of a new thing so much, but I think I've done great at scavenging, you know, old bits or overlooked bits and, you know, finding something useful to attach them then. So I think that's where I get my. I feel I'm being adequately innovative and enjoy it. But yeah, I like the anthropology and explaining the, the context and ecosystem view of it. I think something along those lines also is.
00:10:29.239 - 00:11:21.287, Speaker C: I've gotten to see now several times a new academic field get the bitcoin bug and dive in and be absorbed by this. The financial cryptography crowd were some of the first and so computer security and that kind of subfield in computer security, those were the first to take it over. And I think then the cryptography world with zero knowledge proofs came next. And it wasn't till later that the formal methods community had their turn with the smart contracts and then proper distributed systems came over. There's probably some other subfields that have gone along those, but that's always been fun to see. And bringing the anthropology message a little bit is always helpful in doing those because you say here's this long rich of open problems that have been tried really hard from all the viewpoints available from this community and that that's clearly been appealing to all these different fields.
00:11:21.391 - 00:11:46.349, Speaker A: I'm curious the. Because at some point you also moved into ZK and I don't know if what happened in between sort of that work of at first describing blockchains and doing these polls and surveys, as you called it, all the way to. Yeah, your involvement in zk. Like, was it because ZK entered the fray that you then noticed it or had you kind of found it yourself before that?
00:11:46.437 - 00:12:17.689, Speaker C: Oh no, I definitely hadn't find it. I mean, right when I got to University of Maryland, I think I got to meet Matt Green and Ian and Christina who had been doing the zcash paper and everyone was talking about snarks at the time. I mean, I got there with my I want to work on BFT and authenticated data structures and proofs of work. And zero knowledge proofs are about to become the big deal. This was like the Pinocchio or GGPR paper. Right. Where out then? So all the cryptographers there were excited about this and the Zero Cash paper had already explained how to do this.
00:12:17.777 - 00:12:18.049, Speaker A: Nice.
00:12:18.097 - 00:13:06.691, Speaker C: And I think the main project that I worked there, that to me really set myself on the direction that as we'll talk about has been a fairly continuous direction since then was this Hawk paper. So it's saying Zero Cash is already showing how to use Zero knowledge proofs for transfers, which is what Bitcoin is capable of. But we can think about all of these smart contract applications, whether it's from early Bitcoin script at the time or, you know, Ethereum had been maybe on its way when we started. Like we knew of Ethereum, even though it might not have been out yet when we started thinking about Hawk. But we want to do auctions and other, you know, more interesting applications with private data of some kind. And so that was the scope of that project. Like how do we glue smart contracts together with zero knowledge proofs and get some kind of, you know, privacy auction and other applications on the way?
00:13:06.783 - 00:13:07.979, Speaker A: That is so early.
00:13:08.067 - 00:13:08.715, Speaker D: What year was that?
00:13:08.755 - 00:13:10.538, Speaker A: 2014, 2016 or something?
00:13:10.630 - 00:13:14.339, Speaker C: Yeah, 2015 I think is when the print for Hawk might have been.
00:13:14.467 - 00:13:20.523, Speaker A: Yeah. And at this point, so Ethereum is live, I think, but in its very early stages.
00:13:20.619 - 00:13:20.979, Speaker C: Yeah.
00:13:21.027 - 00:13:34.341, Speaker A: What you created with Hawk though, was it like a rebuilding of a smart contract platform from scratch, like with a UTXO model and snarks, or was it like actually in any way referencing what Ethereum had done?
00:13:34.483 - 00:14:14.759, Speaker C: Oh, it was such a nice hack. Definitely not the first thing you described of like a deep rewrite. It is what I would call a mashup. Like we call it a language, but it's really just here's your partition of code that's solidity, here's your just partition of code that is a C program and then we just carve out the C program, pass it into the Pinocchio compiler. So that was the first ZK front end that was available at the time. And then wrap the resulting circuit within a utility circuit that adds the commitments and the snark friendly encryption and hash functions and so on. At the time we didn't have snark friendly hash functions, so it was just SHA2 the expensive way, so it was slow and AES encryption the slow way, so it was slow.
00:14:14.759 - 00:14:20.855, Speaker C: Now, of course, we'd use like Jubjub and Rescue or Mimsy or one of those Poseidon. Yeah, exactly.
00:14:20.975 - 00:14:27.463, Speaker A: It's funny. It's also, it's coming out around the same time or like even a little bit before Groth 16 or any of the modern Snark systems.
00:14:27.519 - 00:14:28.895, Speaker C: That's right. We had Pinocchio then.
00:14:28.975 - 00:14:34.825, Speaker A: Yeah. Wow. Is that the first work you do where you actually start to work with zk?
00:14:35.365 - 00:14:42.825, Speaker C: Yeah, exactly. That was the first time using ZK and doing anything privacy centric that way or confidential the other way.
00:14:43.285 - 00:15:25.793, Speaker D: One quick question, just philosophically, a lot of the focus in the bitcoin talk forums was the early days of just either improving throughput or I think about the scaling Bitcoin conferences prior to 2016 there was like a bit more of a focus on privacy versus scaling. Whereas I'd say the Ethereum ecosystem, you know, Vitalik would maybe not agree with my characterization, but I'd say the empirical data is that Ethereum cares a lot more about scaling than ever really cared about privacy. And so I just am kind of curious how you kind of synthesize all the kind of privacy versus scaling trade offs and then ended up writing something like Hawk or Nippoc.
00:15:25.849 - 00:15:26.689, Speaker C: Nippopals.
00:15:26.817 - 00:15:47.765, Speaker D: Nippopals, sorry, Nippopal, by the way, it stands for non interactive proof of proof of work. Andrew can correct me, but I view it as personally just like a way of doing a snark of proof of work without. It's like a way of just proving that a set of proof of works existed without having to do the calculation to verify.
00:15:48.275 - 00:16:14.267, Speaker C: Yeah, that's exactly right. I had a bunch of unhinged and you know, didn't quite solve the problem posts on Bitcoin. Talk about this. Yeah, it's just so you describe. If it's too expensive to do a snark proof or you just don't have snarks available at the time, then this is like a sampling based alternative to that but with the same goals. And that would be a useful component within a light client or a better SPV client or a smart contract based light client. So that was the intent of it at a time.
00:16:14.267 - 00:16:56.593, Speaker C: I guess that's pretty interesting. I mean, so I think that I have been detached mostly from the scaling efforts. So I helped later with this scaling Bitcoin position paper that was like the merger of a bunch of already separate late measurement studies that Gun Surrey and Christian Decker, the Swiss team, were working on. I guess I had been kind of caught up in the drama of the bitcoin scaling Debates, but not really picked aside or dug into it other than wanting to do that measurement approach. I definitely cared about asymptotics of consensus protocols and those are about your cost and overhead as a function of N the number of nodes in your network. But I guess I would take that on as really just a technical, very abstract, very academic goal. That's the target.
00:16:56.593 - 00:17:08.769, Speaker C: Let's go make an algorithm that beats that goal. I don't know that I really conceived of that as helping the scalability effort that way so much. To me, the most salient trade off was much more privacy versus expressiveness.
00:17:08.937 - 00:17:15.081, Speaker D: Don't tell 2017 ICO papers that statement you just said, that's awesome.
00:17:15.233 - 00:17:15.513, Speaker A: Yeah.
00:17:15.529 - 00:18:13.229, Speaker C: So to me it's the expressivity versus privacy trade off is the more interesting one. I was very into the idea of what Ethereum wanted to do with more generalizability and you read the old Nick Szabo papers and it's clearly about this general computing and we'll build these agoric market structures and whole new conceptualization of a world that has this tool in it for coordination. So obviously programmability is the way to go explore with that. So I was really interested in seeing smart contracts go. I think I had wanted to do something like that prior to hearing about Ethereum because it was in the early satoshi, the deleted pages of code from Satoshi's Bitcoin was a poker and a marketplace and all of these extra features that were carved out because that didn't fit into the bitcoin that worked and was launchable. But it was always part of the zeitgeist, part of the grander set of things that are possible. I'm on the side of exposing foot guns to developers.
00:18:13.229 - 00:18:49.119, Speaker C: I'd much rather see the open ended exploration. The fact that solidity is a dangerous language doesn't make me want to say stop using Solidity, only use Bitcoin script. So I'm way more on wanting to accelerate what the smart contract developers, permissionless innovators have in their toolbox to work with. And so to me, privacy was just one thing that okay, we see kind of the pattern, we see how to add Ethereum on top of Bitcoin. It's still a blockchain, it's still a proof of work, whatever. It's still just operating on transparent data. So adding confidential computing of some kind to it was what I cared about the most.
00:18:49.247 - 00:18:56.679, Speaker A: What other involvement did you have at the time in the ZK world though? Because I feel like were you not part of the Zcash group. At some point I was part of.
00:18:56.687 - 00:19:14.073, Speaker C: The zcash group, but I don't think I've made technical contributions to zcash so much. Definitely worked on the Hawk paper, but that didn't turn into a, you know, a thing that hit the real world, per se. So, I mean, I helped with early zcash governance and participating and maybe explaining some things. Definitely was a participant in the trusted setup.
00:19:14.169 - 00:19:17.281, Speaker A: Yeah, the first one. You mean the six person one?
00:19:17.353 - 00:19:29.645, Speaker C: Yeah, I was in the six person one. Back then, a trusted setup took, you know, 24 hours and you had to sleep on a mattress next to your desktop computer and then hit it with a sledgehammer when you were done. The next one was a lot simpler.
00:19:30.025 - 00:19:32.457, Speaker A: You were not the one who went into the woods, though, were you?
00:19:32.561 - 00:19:34.005, Speaker C: No, I wasn't in the woods.
00:19:34.545 - 00:19:39.585, Speaker A: I feel like one of the participants drove to Canada into the woods.
00:19:39.665 - 00:19:48.121, Speaker C: You're thinking of Peter Todd driving his desert bus with his thing and using satellite Internet to do his rounds, drive across the tundra or something.
00:19:48.193 - 00:20:00.375, Speaker A: Yeah, that's crazy. You were part of that, though. So you're part of this early Z cash, but you feel like you weren't actually active on the research front. You were just sort of like looking more on the spirit of the project, I guess.
00:20:00.535 - 00:20:24.287, Speaker C: Yeah, I'd say that was right. And I've been picking technical battles for sure. Just they're more in the lines of. Yeah, the smart contract layer, which I guess I would even say I hope someday, you know, ends up being available for zcash to use. But it makes sense that zcash is more on the conservative only. Add safe features, put a very high, you know, allocate all the points towards safety and reliability of, you know, doing those EK proofs in the smaller scope the right way. Yeah.
00:20:24.287 - 00:20:40.015, Speaker C: And as we get into TES and these extra things that take other trust assumptions. I like the idea of not enshrining extra trust assumptions into a protocol, but I love the idea of making them available as things that can just attach to the side and provide some value, even when not enshrined.
00:20:40.135 - 00:20:54.401, Speaker A: I'm kind of curious at the time that you were part of doing that early zcash stuff, though, how you felt about tes. I know a lot of this episode is going to be about that work, the more recent stuff, but did you have an opinion at the time?
00:20:54.513 - 00:21:22.717, Speaker C: So my exposure to TEES was from reading Richard Stallman posts about them. And the first applications of TEES were for drm, which if you're Precise is digital restrictions management. Their only use is to keep users from being able to use their laptops fully. So they were in the context of the opposition against general purpose computing. And so they're horrible. Like avoid them. They're going to lock you out of your operating system.
00:21:22.717 - 00:21:35.813, Speaker C: Not like you edit the OS or anything like that. Terrible. So I hated them. I would hate them for years to come after that. So it really wasn't until maybe 2019 or 2020 that I started really paying any attention to them in a positive way.
00:21:35.869 - 00:22:22.003, Speaker D: I was just laughing because anytime Stallman shows up, it's like, which person are you getting this time? But I guess one question, if I think back to that era of your research, there was, you know, the honey badger type of stuff. Like maybe a little later there was sort of more of a focus on classical consensus algorithm improvement. Let's Fast forward to 2024. You know, I still go to conferences where I see a ton of new consensus protocol papers. I have very strong opinions about the answer to the question that I'm going to ask you. But you know, where do you see consensus research in 2024 versus 2016, 2018, when it was like felt like every week there was like five new papers that had some actual improvement.
00:22:22.139 - 00:22:53.033, Speaker C: Yeah, it's different now. I don't have a super sharp answer because I would say that largely after. I didn't keep going with consensus in depth after Honey Badger bft. So I followed it kind of at a distance. I mean, the whole switch to pipelined bft, I wish I had thought of that and worked on that kind of version at the time. So I love that Honey Badger BFT kind of kicked off this resurgence of asynchronous BFT protocols, which is the most interesting setting for consensus. And the idea that you could have pipelining for asynchronous protocols is quite exciting.
00:22:53.033 - 00:23:30.205, Speaker C: It's so interesting that, I mean, consensus in distributed systems looked like a solved field. They started to have these papers. I wasn't like deep in this community, but from what I could see from reading like the conference forwards or keynotes, they started to talk about it a way I had seen people talk in academic VR, which is like our field seems stagnant and solved. What are we going to switch to doing next? Like, we've already set our lower bounds and met them all. You know, what's left to do? And so to me, well, bitcoin opens up this whole new assumptions change. Like now you no longer can rely on a pki. You don't know who the anonymous participants are.
00:23:30.205 - 00:24:22.091, Speaker C: So you need something else like a resource limit to open up proof of work or incentive stakes. And that just changes this whole perspective, opens up a whole new room for that community to grow into. And what I would characterize as happening now in consensus is the idea of having not all of it's like many viewpoints, but one system. You bring your own set of assumptions. You have many different groups of users of the same system that have different threat assumptions and whichever ones the assumptions that they base on are justified. They get a secure use of the system and someone whose threshold was set inappropriately low, maybe there's a setting where they have a double spend or are kicked off the network, fail to get liveness but everyone else keeps going. So this is either subjectivity or suddenly enough forgetting the right phrase.
00:24:22.091 - 00:25:01.809, Speaker C: Heterogeneous trust assumptions or flexible BFTs. Maybe you know the name of that. So in other words, if you don't just have one set of assumptions and okay, we can maybe find a new set of assumptions and that pivots it, now we can just have fine nuanced multilayer assumptions and that opens up a lot of possibility. I think you see this in the high performance APTOs and SUI and MIST in kind of things where you've got like a very fast pipelined fast path and a reasonable like secondary path and then some worst case. And that's kind of like your switch from synchronous to asynchronous operation. And I think that's how I would characterize the direction consensus has opened now.
00:25:01.977 - 00:25:55.829, Speaker D: Yeah, I mean I feel like from that era there was this whole. There was, I think maybe it was a little before its time, but something like Thunder was all about this fast and slow path separation which you know is common in most database design or really any non crypto thing. You tend to find that type of thing. I think the thing that's weird to me is that I remember when I first got excited by reading consensus papers. I always felt like there was a real improvement that occurred in a lot of papers in Hot Stuff. I shrunk the number of rounds decidedly or I shrunk the bandwidth required per round intenderment. I have kind of very clean formulation of PBFT that's almost cleaner than the original formulation in some ways.
00:25:55.829 - 00:26:24.921, Speaker D: But then I read these papers with the heterogeneous trust assumptions where it's like, okay, you want to be optimistic, you only need 20% honest. Oh, okay, no, I need worst case 50% whatever. I feel like there's a Little bit of moving deck chairs on the Titanic. It's like the thing is going to crash anyway. And people have already been built these things. They're not going to build 10 more code bases of the same form, given how hard it is to test these code bases. So I feel like consensus research has really lost its way.
00:26:24.921 - 00:26:26.833, Speaker D: That's like me as an outside observer.
00:26:26.889 - 00:26:28.161, Speaker C: It'S lost its way again.
00:26:28.273 - 00:26:33.273, Speaker D: Lost its way again. Yes, that's true. Lost its way again. Again. There's a very key word there.
00:26:33.409 - 00:26:43.761, Speaker A: Or is this a new stagnation? Is that sort of what you mean? Is this stagnation similar to what you had experienced before the bitcoin blockchain kind of new paradigm showed up?
00:26:43.953 - 00:27:10.779, Speaker C: Yeah, I guess that's what I would say. I mean, yeah, I don't have the best answers here. I guess that is the natural flow of things. Once the big changes are solved for a while, until there's a whole new paradigm that shifts everyone around a bit, you get more what you call pejoratively incremental research papers that optimize something, but it's in a trade off with others. So not a slam dunk. Or it's small improvements but not a. Or it's improving the less important thing.
00:27:10.779 - 00:27:28.539, Speaker C: Like it's making your non fast path faster. So you know, how do you sell the backup case performance? It's too hard to sell. So I would say maybe, yeah, you could be right. But if so that's only if any field will come up with something different to do. I would bet on consensus doing so.
00:27:28.627 - 00:27:34.913, Speaker D: Over T or zk where like they change the asynchronous model in some more fundamental way.
00:27:34.969 - 00:27:42.913, Speaker C: Yeah, that's a good question. Is ZK being saturated at this point yet? Or still has, you know, just as a technical and cryptography field still further to go. I'm not sure I have a good answer.
00:27:43.049 - 00:28:26.089, Speaker A: I actually just recently did a talk on the history of ZK in the last six years, seven years, and I was going through like each year and what kind of research was being published and what it meant. And 2019, 2020, if you look at the frequency of like incredibly important work being published, it's very, very high and I think it's the highest our space ever saw for proving systems. Or a brand new technique like lookup tables were introduced, folding schemes are introduced for the first time. You really see this compression and so much excitement. Somebody coined in late 2019 like Snarktember, Snarktober, you know. But then the next year we had Even more research. So we had to do it again the next year.
00:28:26.137 - 00:28:54.059, Speaker C: That's got to have been Micarah's name for it. I remember that it was. But what's also, what's also so notable to me about this is that to me is the success story of that academic to industry bridge, because that stands out as what are traditionally those are huge technical contributions that get cited and are regarded as breakthroughs. And those came from industry in a field that is primarily those kind of contributions come from the universities. So that's the coolest story for me there.
00:28:54.187 - 00:29:49.369, Speaker A: Yeah. That said though, just to continue on that story to today, nowadays there are works that are coming out. I think there are still like in 2024 there's like at least two works that have created somewhat of a paradigm shift, but not as much so far. In 2023, maybe Binius has like a slightly similar vibe, maybe Jolt, but then there's two. Whereas like really in 2019, 2020, every one of the systems that's coming out, I mean I went through the list and it was kind of wild. In that two year period, there's about like 14 works that were really, really influential and changed something and some of them completely changed it that we're not seeing at the same frequency. On the research side where I think ZK is today, it's just on the use case side and where you apply these systems is where it's very, very exciting.
00:29:49.369 - 00:30:11.747, Speaker A: Yeah, I want to dive more into the TE stuff though. So we talked a little bit about what you had initially felt about it or where you were coming from. But you started to produce some work on it. This paper delegatee came out in 2018. Tell me a little bit about that. Did you continue with that work or did you just do this one off? How did you get back to it?
00:30:11.851 - 00:30:42.875, Speaker C: Yeah, so tes were around at the time. I mean for me the kind of thing in between is multiparty computation. So it became clear that you reach a wall with what we can do for hawk. HAWK just use zero knowledge proofs and then standard blockchain stuff. But it was really unsatisfying because the auction application has this auctioneer who sees all of your failed bids. So you don't get any post trade privacy or failed bid privacy. And there's a paragraph in the end of it that's like you could instantiate this manager party with multiparty computation.
00:30:42.875 - 00:31:02.329, Speaker C: But I didn't know how to use that at the time. And so it was clear that re Jules especially and I guess Dawn Song at the time were doing a bunch of SGX related projects like Town Crier was I think the hot thing from Ari's lab around that time. That must be 2017 or 2018. I'm actually not exactly sure.
00:31:02.497 - 00:31:07.805, Speaker D: I think I remember that because I just remembered all the chainlink Marines shilling it for a while.
00:31:08.505 - 00:31:40.817, Speaker C: Yeah, that's right. So I was aware that those to me are two alternatives of ways of getting around the thing that the zero knowledge proofs alone have this limit. So with the zero knowledge proofs there's a witness, a prover has to know the witness the secret data to make the proof of it. So it's good at showing facts about data that you already have and that can already in a utxo. And by adding commitments and public key encryption you can build these. Cool. You know zcash works like this and you know the commit and reveal kind of partial solution to an auction with Hawk works like that.
00:31:40.817 - 00:32:11.269, Speaker C: But if you really want to compute on private data, you don't really have alternatives. So there's either multiparty computation where it's secret shared data and you compute on that. And that was the path that I bet hard on and kept working on for three years or so as the way around that. And I kind of, you know, I was still in the SGX sucks. And the whole concept of tpms and trusted hardware is bad and bad for users and bad for freedom. So I really just tuned it out. But Town Crier of course was like a SGX based Oracle.
00:32:11.269 - 00:32:57.285, Speaker C: So it would have this access to sensitive data like it is watching alongside your TLS connection when you log into some website. And it can make then a proof using this remote attestation feature which is a lot like a ZK proof. And this is a lot like something you could do now with ZK TLS or TLS notary, these kind of things. But it can make for example, you know, a summary of what was in your bank account. And so it's like an Oracle and it can even be an Oracle that does some computing and filtering on it. So that was their paper and it was really pretty cool. We wouldn't try to do something like that with pure mpc because when we started trying to do MPC based computing on private data, so difficult to use the frameworks and so performance slow that we would work on very stylized like a simple automated market maker.
00:32:57.285 - 00:33:04.125, Speaker C: That's like an automated market maker but you don't see the size of the liquidity pool. So it's kind of A dark pool proceeding in batches.
00:33:04.245 - 00:33:06.341, Speaker D: This was the paper you did with Mukhera, right?
00:33:06.413 - 00:33:37.179, Speaker C: Yeah, that's right. Ratel and MPC as a sidechain, which we worked on for nearly three years, that was a tough grind of a paper, in part because the MPC was difficult to work with. And I compressed this to be able to talk more about tes. But I kind of reached the conclusion that, well, really what did it for me is this notion of a collusion attack. So I could kind of see that, okay, performance is an issue. Even when we try to do data sets, databases will need oblivious RAM inside the mpc. So it's going to continuous be a difficulty.
00:33:37.179 - 00:34:22.081, Speaker C: But in a way, even if we fixed all the performance issues, it would still be so unsatisfying because we have to pick end nodes to be our NPC set. And the collusion risk is that it's secret shared data. So, yeah, you can do a computation on the secret shared data and only reconstruct the final output for everyone to see. But if those nodes wanted to, they could just work together and collude and just combine their shares and decrypt everything, all the intermediate values, all the original inputs, and you can't even get them to prove to you they haven't done that. And you can't ask them whether they've done that and get anything. Confidence inspiring as an answer. So I could grind it out further and keep chipping away at the performance challenges and the programmability challenges, but that would then be the biggest brick wall.
00:34:22.081 - 00:34:58.062, Speaker C: And that was when I started to accept that TEs are necessary and even if the MPC works, you'd still want tes too. And that's kind of my modern framing of it. And I could go back to then. The things that had passed me aside were that Towncrier paper I helped with delegatee, which is a lot like Towncryer but with write access as well. So the TEE can then send messages to an account you've authorized on your behalf. And that opens up all of these kind of weird opportunities that I think are fun to talk about, like turning Web2 accounts into rental offerings. It's kind of a strange, surprising thing you can do with those.
00:34:58.062 - 00:35:18.877, Speaker C: And then the Akitan paper came out, which I helped with a little bit that turned into Oasis. That was like 2018. But I still was angry about TES. Like my only help on that paper was like race condition in the blockchain, like upload, download bit. I still hated the TEs at that point. So yeah, I Kept at it for a couple years on MPC then.
00:35:18.981 - 00:35:46.477, Speaker A: So the MPC though, you just at some point realize the limitations were too great or the work would just be grinding almost trying to create an environment that MPC wasn't necessarily suitable for yet, or maybe will ever be. So you kind of went for a te, but do you still see it as an intermediate solution or intermediary solution where you're like, we're going to use it for now, we will replace it, but there's nothing yet that can do better, or do you think it will always be part of the stack?
00:35:46.661 - 00:36:40.053, Speaker C: That's a perfect question. I think that's maybe the most important question for these because yeah, if it were just a matter of work and make performance, I would probably prefer to grind it out and keep chugging away at that. No, in a world where cryptography, even the very fancy cryptography, let alone fhe, but even other things like full on obfuscation of some flavor and witness encryption, that kind of, you know, even beyond fhe future crypto stack, even in the, you know, dreams of cryptographers, if all the cryptography does what it can, it still doesn't get rid of the need for something like trusted hardware that can have statefulness like you need. You fundamentally need some irreversible right, and there's just no cryptography protocol that gives you an irreversible right that needs to come from something external. Maybe it doesn't have to be trusted hardware, but that's the only thing in my mind that seems to fit there.
00:36:40.189 - 00:37:35.603, Speaker D: I guess, like, yeah, I think you're always a couple years ahead of me historically, except in defi. And I would say that I came around to a very similar realization. Not that I don't think that there'll be a lot of cool things built with ZK VMs, but I do think there's a lot of applications where people just want to try something and do it quickly and they also don't want to have all their data public in a blockchain initially and they're willing to make the trade off with the hardware. Because if I think about people who are using 90% of people who are using mobile wallets arguably are making the same trade off hardware wise. Right. They're using face ID and whatever attestation that is in a TE and their phone or their computer. I feel like the new users of crypto, the difference between TE and not TE is like zero to them to some extent.
00:37:35.603 - 00:38:39.437, Speaker D: And so I think if people are already on the user interface side Making that compromise so that the end user doesn't effectively oblivious that then it's sort of clear that hey look, maybe augmenting existing contracts with tes, doing this credential matching, doing kind of the TLS type of stuff. It just feels like it's probably going to be more impactful to the end user if you're willing to make those assumptions. I think obviously roll ups are a place where yeah, it makes a ton of sense to be zk, right. The input is just public anyway and everyone's already agreed on the input. So it's like. But I feel like there is this whole world of things where I think it's interesting that people from MEV land came into TE as kind of out of necessity being the mother of all innovation versus sort of like endogenously thinking of as a solution. So I'm just kind of curious now that you've had a few years of conversion into the gospel of the the enclave.
00:38:39.437 - 00:39:02.345, Speaker D: I was trying to figure out if I could make some type of pun with conclave and enclave, but it wasn't quite close enough. But what are the things you think that are easier than what you expected? What are things are harder? What do you view the trade offs as? Cause you've written code in all of these different systems so you have a high level overview.
00:39:02.685 - 00:39:49.867, Speaker C: Yeah, maybe just building on what you were just saying. I have two visions in mind. One is what I think is going to happen right now and the other is what I think should happen or is like the architectural ideal to build towards. To me the ideal to build towards is in the future we will have multiparty computation nodes doing the decryption step for fhe. And these nodes to prevent that collusion risk there will be an NPC of them doing the decryption, but they will run in trusted hardware that prevent those nodes from colluding or doing decryption on anything that they shouldn't. And then hopefully at those point, because it's just decryption, it's not bottlenecked on their performance of those we wouldn't be having to use SGX or something from one of two manufacturers. We'd be able to use some blockchain, native verify.
00:39:49.867 - 00:40:19.853, Speaker C: Don't trust TE alternative that come from. You know, I can't say how to do that, but maybe the kind of people that were doing bitcoin ASICS and now are doing Snark accelerators if they work on TEs next, maybe that'll be a way. We don't even have to take the Centralized, trusted, manufacturer, part of the story of TES for granted. So to me that's very clearly the long term goal to technically strive towards. But exactly what you said as just a market pragmatist. Now this isn't what I'm trying to make happen. This is just the observation I think is inevitable.
00:40:19.853 - 00:41:03.347, Speaker C: I'd push against it if I could, but people are going to take TES as a shortcut. No matter how easy the ZK proofs get, I think it's going to be easier to make the equivalent, run it in ATEE and use the remote attestation as a substitute in lieu of a ZK proof. It's just faster, cheaper, probably going to turn out easier to develop. And even if I would discourage it, I think people are just going to take it as a development shortcut. And I think you can see that in L2s. Even with optimism, that might take finishing the fault proofs as a deferred thing. I can imagine you design a multiprover system, we've got ZK proofs and tee, but obviously you can ship the TE1, you know, maybe faster, easier and better performance.
00:41:03.347 - 00:41:50.885, Speaker C: So even when I don't want that, I think that's likely the first appeal that people are going to see that's going to make this catch on the other thing, that's what I would say was easier. Really this is about the first thing that made it easy for me to swing into this. Not just from a research perspective, but I think I started to pick up an arbitrage opportunity. I guess you would say maybe this is the only one I've picked up on. But I started to realize that all those FUD posts, you know, I wasn't the only one who ate up that anti DRM message about tees and then also like the vulnerability sequence message of them as well. But the knee jerk reactions the FUD people would say in reply comments and you know, even companies working on TES just wouldn't talk about it. Turns out there are a lot of companies that have been working on these for a long time and just mostly being quiet because it's negative PR to even bring it up.
00:41:50.885 - 00:42:31.557, Speaker C: I started to realize that the responses weren't that defensible. They were leaving open too many easy, you know, answers to counter them. And a large part of this maybe we talk about in a moment is like, you know, software mitigations that aren't, it's not entirely. You're just given this world of tees and you know, you're completely at their whim they're kind of, you know, crude technical tools like a ZK backend. And it's up to, you know, us blockchain integrators, you know, what to do with it and how to work around it. So realizing that the anti T FUD campaign had swung too far in the wrong direction or in the extreme direction, I think just left them open for clumsy psyops that I was in the right mood to bring.
00:42:31.701 - 00:42:59.955, Speaker D: So I also would say, I think there's the pragmatic cypherpunk approach, which is how I would kind of term what you're saying, and then there's the pragmatic capitalist approach, which I will describe as the following, which is the sheer amount of investment everyone thinks about. Hey, there's been all this investment in ZK proving, people building hardware, whatever, is still probably on the order of 1% of the investment in TES overall.
00:43:01.335 - 00:43:05.103, Speaker C: Outside of crypto, you're including like the development costs of intel and amd?
00:43:05.199 - 00:44:12.889, Speaker D: Yeah, the Nvidia. Yeah, exactly. Intel's development costs plus Nvidia's, plus Apple's acquisitions of all the hardware companies they bought for their TEs. And there's actually a much bigger driver of TE performance than anything crypto can really match, which is, you know, if I look at the fact that people want to do inference for AI in TES because like they're afraid of people stealing their weights or like hacking, you know, a lot of the espionage stuff has basically made some of the model operators start to do inference and offer inference in enclaves that is going to just incentivize much faster hardware development than anything else, I think, just like simply by the pure sheer amount of dollars and people involved. And so that, you know, if you think about AI as riding the coattails of crypto, in some ways in that GPU performance got better because people started mining. And so then we started making these like, you know, kind of low energy, high RAM throughput GPUs versus the pure graphics card GPUs. And so, yeah, disclaimer, disclosure, whatever.
00:44:12.889 - 00:44:19.644, Speaker D: I mean, I used to be a CUDA developer, like in 2014 and 15 when it was deeply disgusting to use NVCC.
00:44:19.719 - 00:44:23.707, Speaker C: But I did a lot of OpenCL when I was in graphics.
00:44:23.891 - 00:44:31.443, Speaker D: Yeah, yeah, I did a lot of like protein folding stuff. And I unfortunately had the misfortune of dealing with the stuff back then.
00:44:31.579 - 00:45:01.995, Speaker C: You're bringing up the, you know, the momentum of this. I think that's totally important. And it's almost like, I mean, I'm treating this like something I've discovered in a way, these tes to use, maybe the way, you know, people pick up ZK proofs. But I mean these are products, right? And you know, they're made to be used this way. And looking at it, it's so interesting the way that these are delivered. I haven't been able to wrap my mind full around all the strategic consequences of this, but how's that for a distribution strategy? Surprise. All of your server chips just have TE in them.
00:45:01.995 - 00:45:34.575, Speaker C: It's not a matter of are people going to pay enough for the extra T add on. It's just like your servers have this. They're already there when you choose to open the SDK and use it. And when you see it from that lens, it's almost just seems inevitable or obvious in some way. This isn't going away. The fact that AMD and Intel have kind of converged on the same, you know, virtual machine approach to enclaves with TDX and SEV SNP as their, you know, mode of working. It seems like this is just going to be an expected default that yeah, every cloud machine has this kind of capability.
00:45:34.575 - 00:45:59.793, Speaker C: Anything running a modern, you know, compute card for doing inference or training just obviously is going to do its best to provide you this protected environment. Who wouldn't want, you know, the confidential compute checkbox in those? So I can't really view outside of my kind of crypto viewpoint of this. But that's just the momentum of that far exceeds. And that's exactly what you're saying, right? That's far exceeding just the scope of what we want from them.
00:45:59.929 - 00:46:37.969, Speaker D: And I think a more a nice sort of charitable interpretation is crypto helped GPUs get a lot cheaper and better 2012 to 2018. In that time that enabled people to do a lot of architectural experimentation in AI much more cheaply. Everything from Gans to Transformers and all the other architectures in the middle. And now crypto gets to ride the coattails of AI putting TEs and everything. Because I really do think that will drive tes a hundred times more than crypto probably. And it'll be in every device.
00:46:38.017 - 00:46:39.249, Speaker C: That's a great point. Love it.
00:46:39.337 - 00:47:09.703, Speaker A: I want to just ask about some of the. What was happening in the industry over the last few years nts, because you sort of hinted at this where like they started to pop up in things back in 2018, to me TES were SGX and Intel. It was sort of synonymous. But since then I feel like they've popped up in all these other places. Has that changed something as well. I know it wasn't only intel, but at least like when I learned about it, that was intel sgx. That was the text standard.
00:47:09.799 - 00:47:14.919, Speaker C: Yeah, I mean this question is about like what are the companies using it or about what are the other tes. More.
00:47:15.007 - 00:47:18.495, Speaker A: Yeah, just sort of what's the history of that kind of being added?
00:47:18.615 - 00:48:10.081, Speaker C: I mean the ones that I was aware of the most, I was aware of Oasis that was built by Don Song and co authors out of that Ekiden paper. I started to follow Secret Network really well, maybe one of the things that was then most inspiring for me was just seeing what they did with private NFTs. I was pretty down on their privacy tokens, especially coming from the zcash world. I thought their claims were overstated and then had technical beef to pick on. Kind of nitpick decisions, but those are all fixable still. It's like I kind of favor the ZK proofs for this long term privacy, but there were a bunch of things that they've done that were really cool applications that to me is like, yes, this is what I want to see innovators doing with an extra tool in the toolbox. So they have right click resistant NFTs that have private metadata that only the owner of the NFT can see.
00:48:10.081 - 00:49:00.197, Speaker C: So right clicking is, you know, a public chain NFTs problem on a chain with, you know, sufficiently versatile confidential data, you can have this whole other world where there's actually like, you know, property worth protecting that way. And the other one that I found so interesting was, well, they had a couple versions of a Uniswap clone. If you take a Uniswap and you just run the Uniswap clone in a confidential smart contracts, it automatically is like a dark pool that one block at a time does a batch, but you don't see the individual trades and failed trades you don't see at all. And then the even more interesting one was their compound clone, siennalend. So if you just take compound structure and run it in the confidential world, what you get is this snipe resistance. It's like you still have accounts. Accounts have different portfolios of collateral depending on the price changes reported by an oracle.
00:49:00.197 - 00:49:34.341, Speaker C: An account can go insolvent or not. And if it's over, you know, overexposed to one kind of collateral, then that makes it risky to a change in that collateral. But here you keep your portfolio positions hidden. The rule is that if they are in fact liquidatable, then it discloses the portfolio accounts because that's what liquidators need to see, but what you're immune to is sniping where someone can see, oh, you're overextending, exposed to this one token and I can move the price on that one token and that would tip over your whole, you know, collateral health. So that's what you get with like a one line change to the, you know, compound code. I'm oversimplifying a little, but that's essentially, you know, what you get.
00:49:34.453 - 00:50:01.513, Speaker A: Just to go back to my initial question because I actually wasn't necessarily talking about companies that used TEs, but rather hardware companies that had TEs all of a sudden in them. As I understand it, in the Last few years TEs have popped up in more places, right? Like there's more chips that are more products, more companies that are actually. I don't know if Apple always had tes, maybe it did back then too, but I feel like, yeah, it just sort of becomes more ubiquitous.
00:50:01.649 - 00:51:05.635, Speaker C: Not all TEs are the same. And I mean I would describe there's a handful of features that are most appealing to us as web3blockchain people trying to build a cool decentralized system using the tees and then not all of them are fit for it. And I think actually some of the ones like in mobile phones, I don't know to what degree they actually are suitable for what we would want to do with them. What's great about S and the others in that class I think is true of the h1 hundreds and the amd ones as well is like they're user programmable so there's no like OEM that has to insert those. A lot of TEs are like for IoT devices but then it's about and there's even remote attestation, but it's about from the admin controller to the devices out in the field in customers houses. Can you know that you're providing your cloud service to your own device because you built it from your own OEM assembler And it's only two parties like remote attestation, but the person who set the device out there is also the same one who's the relying party trying to be convinced of it. And so I think that to some degree a lot of the most widely used tees are of that more constrained kind.
00:51:05.635 - 00:52:08.743, Speaker C: You may be able to use the TE but only with the Play Store or Apple Store's help in some way. And so what's really interesting about this at the processor level is really once it's left the processor company, it's largely out of their control. There's absolutely a layer of opaqueness to this that makes it hard to say we fully trust that intel can't touch it. There's an obvious attack surface where if they wanted to have a backdoor they could, if they wanted to sign a fake remote attestation certificate for a spy enclave that could join networks but not actually protect anything, they obviously could. But at least they do have the structure that by design the processor is out of their direct control once it leaves the factory. I think it's actually really interesting what you have in this cloud environment where like an Azure SGX based server is somehow a little bit of separation of duties between intel and Azure, like Azure are operating it. And what you hope is that if it turns out that there's an undervolting attack, that someone with a physical attack lab could be squeezing some data out of it.
00:52:08.743 - 00:52:36.379, Speaker C: Azure is promising not to do that. They have it in their ordinary racks. They're treating their customers with respect, they're at least claiming that. So it's kind of like the, you know, locks make good neighbors. Even if it's not a perfect control. It does seem like a meaningful separation of duties. Like intel would have to, you know, not follow their own design and Azure would have to help them make use of it to break something and you know, and then back to like if they would do this for bulk surveillance over privacy data, maybe that's as difficult.
00:52:36.379 - 00:53:14.525, Speaker C: But then for an MEV application where like Flashbots says well we mainly just need this for like 20 seconds of mev time negotiating over this private data, even if they could do this nation state level attack or colluding attack, they're not going to burn revealing that capability and embarrassing themselves in front of their enterprise customers just to skim MEV for however long they can. So I mean that kind of answers why I'm excited about Flashbots for that. It's a narrower use case where at least this should be able to do it. If it can't work for this use case then the harder long term privacy cases don't have a shot.
00:53:14.825 - 00:54:09.495, Speaker D: So another thing I would add here, which I think is actually quite important and I think a thing people in crypto sometimes are cultured to not think about is that there's a sort of natural time value of privacy. Like some applications actually do need persistent privacy or at least non manipulable in the sense of like a succinct proof, tamper proofness forever. Right? So like a roll up needs to have all the proofs that it's been valid to be right forever as it's still operating. On the other hand, something like Dex order flow in a block before the block is finalized is only a few minutes, you know, at most say it takes to finalize that you actually need the privacy for, because after that it doesn't matter if anyone knows. It's not like they can front run it afterwards. It's like it's already confirmed, already executed. You can't really replay the transaction either.
00:54:09.495 - 00:55:03.253, Speaker D: So it's kind of it's done. And this notion of like ephemeral privacy or privacy that's like just in time around certain events is very important to have in a lot of applications you don't actually need. I don't need face ID to give me privacy of my picture forever. I actually need it for the small time it has to use to validate and then it deletes it. And so I think there is a very important piece of thinking about the cost of privacy versus the duration of privacy. Imagine you have like two axes and you're comparing like how much does it cost for this type of privacy versus how long do I need the privacy for? And there's some applications where you're willing to pay a very huge cost because you need a long time where either the privacy or succinctness properties need to be true. Roll ups being one where I basically would say time is infinite or very long.
00:55:03.253 - 00:56:06.521, Speaker D: Right? But MEV, on the other hand of this spectrum is like very short. And the question is, what are the things that are in the middle? I think the things that are in the middle, the only things I've seen so far have really been like the AI type of stuff where it's like, I don't want you to know my queries that I made for a while, but after many of them you might be able to statistically aggregate something and say something about it. But immediately I don't want you to know. And for some amount of time I don't want you to know. And I'm not sure what the crypto applications are. The finance stuff is very short duration privacy for the most part, you can argue maybe lending and a couple of things do have a little longer duration, but even then it's quite unlikely. And then roll ups are infinite duration, but what is the middle? And I think the thing about ZK, VMs and TEs is they're both hoping to find something in that middle, but they might end up finding it from different directions, right? Like te's might go from like the very low duration to something in the middle and ZK VMs will go from something very long duration to something in the middle, but they might never meet.
00:56:06.521 - 00:56:17.807, Speaker D: They might just be in their own world. And that's why I think this idea that they're like competing and everyone fudging each other on Twitter is like, anyway, sorry, that's my hobby horse on the.
00:56:18.001 - 00:56:48.515, Speaker C: No, that's interesting. And you've identified. That's a hypothesis. In the middle, they either overlap, there's some applications that are juicy and you can afford to do ZK for them. And a TE is appropriate as well for the short termness of it. But maybe it's the case they don't overlap and there's juicy applications that are too sensitive to trust the TEs on their own, but they're also too performance or something to forget for the ZK to be a good fit for it. And maybe that's where you're saying the AI applications do fit in.
00:56:48.515 - 00:56:50.699, Speaker C: Yeah, I don't have a good answer, but that's a nice question.
00:56:50.867 - 00:57:19.175, Speaker A: I feel like we should jump very much now into the mevt. I know we've touched on it, but the work that you've been doing, I think it would be great for us to understand exactly what your involvement has been and kind of your current work around the topic. I actually asked you before this episode, like, are you part of Flashbots? Like, I don't, I don't. I see you at talks sometimes. Your name is like, there's Flashbots under your name. So I'm like confused. So yeah, maybe you can just share.
00:57:19.255 - 00:57:58.065, Speaker C: Yeah, I'm a mate at flashbots and I've been helping with a couple of other projects on the side as well. Cool cycles especially and still have some university things that I'm doing. Yeah. And I kind of hop around and hop on lots of projects generally anyway. But the role that I've been playing I think has been fairly consistent for a while and I can describe it, you know, well enough. But largely my interest has been on not only promoting the use of tes, like helping people counter what I think are the wrong arguments against it and maybe accept that using it's important. But I'm really interested in bringing more clarity on how to use it and especially to identify what is the tech debt or what are the pitfalls that software developers need to know.
00:57:58.065 - 00:58:24.291, Speaker C: I generally take this attitude that we can do a lot. We're powerful infra engineers, the Web3 ecosystem broadly. We don't let the complexity of zero knowledge proofs stop us from figuring out how to use them very well. So there's a lot of pitfalls in working with tes. You have to prevent side channels. Those are very nuanced because you have to pick what threat model you want and then also choose which mitigations you apply. For those.
00:58:24.291 - 00:58:58.071, Speaker C: You have to do things like preventing replay attacks, which generally involves making use of the blockchain. It's really interesting how blockchains NT is are complementary, maybe in the same way. Our conversation was just about how ZK and TES are complementary. It's definitely true of consensus protocols and blockchains and TEs as well. You can't have one without the other. And one of the most important design patterns is to have a light client for a blockchain network inside an enclave program. That's how you have the enclave, the tee, locked into the blockchain and only doing what the blockchain says.
00:58:58.071 - 00:59:37.971, Speaker C: It's like you use the blockchain for a control plane and a TEE as the CO processor to do the work of that. So the main thing I've contributed to at Flashbots is the Sura project, which is like a tutorial mode. It's in a way just going back to the Akitan paper and speedrunning it. That's how we framed it because it's similar in what it does to save and Oasis and Secret Network. But it's meant to do so in an absolute minimal amount of code. I think our core thing of it was like a 2000 lines on top of all the packages that we import to use it. So it's just basically meant to help get everyone on the same page on like, what are the pitfalls that can go wrong? What do you need to do to connect these, you know, properly how to think about what the security goals are.
00:59:37.971 - 00:59:56.859, Speaker C: And it goes back to that same, you know, motivating example from the Hawk paper of it's a sealed bid auction where you want to provide failed bid privacy even for the losing bid. So you can't just do commit and reveal. And it's Hawk, except the manager only runs in a TEE and it uses the remote attestation instead of where Hawk used as EK proof.
00:59:56.907 - 01:00:30.945, Speaker A: You sort of already talked a little bit about something from like web2, the TLS notary. How does this, like, I realize it might be not exactly what you're working on right now, but I didn't quite understand how TEs factor into that. Like, I know some ZK focused projects that are playing with the TLS notary concept of bringing Web2 like web pages for making proofs about the web on a blockchain, sort of almost becoming a bit of an oracle for like the real world or something. Yeah. How did TE's get used in this way?
01:00:31.025 - 01:00:36.177, Speaker C: I mean, if you don't mind, can you give me like your one sentence description of how it works in the ZK version of that?
01:00:36.241 - 01:01:24.719, Speaker A: Well, I would probably not be the perfect person to explain it, but as far as I understand you create a ZKP of some state of a website. So if you were trying to prove like I don't know, that your bank statement says something on a website, that you'd be able to create a proof that you'd write on chain, I'm probably totally butchering it. And really one of these teams should say it better. I mean another one would be, and this one I understand a little bit better would be like zke email, which is where you're actually taking the format of an email. So say in an email. I mean the best example here is like Venmo sends you your balance or something that has just been transferred to you. You could create a proof about that amount about that email template that you could then write unchained and you have.
01:01:24.727 - 01:01:28.663, Speaker C: A proof about a signature from it essentially that's giving you this authenticity of it.
01:01:28.719 - 01:01:33.999, Speaker A: Yeah, you create a signature out of it almost like it's just an email. It's like just a plain text email.
01:01:34.087 - 01:02:22.431, Speaker C: I mean the only nitpick or I think the biggest just challenge of why it's not trivial to do this with tls. You can't just make a zero knowledge proof about what you saw is that there's this deniability issue with TLS where like it's a Diffie Hellman key. So like you once if you're at one of the parties in the session, you can pretend you're making messages on behalf of the other party as a session. So just because I make a proof of what I saw on a TLS session, I could also make a fake proof of what I saw because I have the same key that the server had to make that. So you just have to work around this. And this is why these systems are a little more complex. There's either like a relay in between, like a proxy in the middle or like the deco project I guess was another Ari Jules one that I know a bit that's like a secret shared version of that.
01:02:22.431 - 01:03:06.821, Speaker C: So that's the technical problem that you have to get around. You can get around one of these handful of ways and having a proxy in the middle reading the TLS session that it has the little key and it proves that it's not doing that and you get to still see the output of the TLS session but you don't have that key that would make it possible to spoof. That's how you go about using TE as a substitute for that. So it can be used as a substitute for it. But do the ZK version if you can. But to me what's super exciting about this is that idea of having write access. So zk, TLS and all of those are good for login and for read access to an account but being able to actually actually encumber the right access of either the.
01:03:06.821 - 01:03:47.323, Speaker C: It's called like encumbrance and this is also a later Ari Jules paper with Mahimna, other of his students and James Austin's worked on follow up things of this like delegatee is always about putting a session into a te. Now you can sell off this access to it. You can also do encumbrance of the root account. It's like you go through the forgot password transfer account flow but now you recover your password into a tee. So now you don't have the password to the account, only the TE has a password to it. And it comes with whatever are its constraints on under what conditions it's allowed to write and then it can still be following a thing from the blockchain to do it. We made this demo.
01:03:47.323 - 01:04:31.105, Speaker C: Now I say we, but this is especially Xinyuan from Flashbots and Ryan MacArthur who's an Ethereum foundation grantee. They made this Twitter encumbrance app or Twitter delegation app is better precisely called Teleport best. And it basically is you put a write session authorized into the tee. But what the TE enforces more narrow than what Twitter auth says is that you only get to post once. So it's like you make a one time use link that lets anyone you give the link to post from your Twitter account but just once. And I think you attach an LLM filter to it as well as like a little sanitizer. So to the Twitter auth, all Twitter auth has is read access or read write access.
01:04:31.105 - 01:04:35.449, Speaker C: Yeah, but like read's not enough and read write indefinitely is way too strong.
01:04:35.497 - 01:04:36.001, Speaker A: It's too much.
01:04:36.033 - 01:04:51.503, Speaker C: Yeah, Read write anything, delete posts, unfollow people, change your profile photo. So it's the tee that's saying you're giving it as Twitter. As far as Twitter's Concerned you're oversharing but it is enforcing that. It's only going to stick to the policy of one time use per policy only.
01:04:51.609 - 01:05:09.283, Speaker A: I see what you're saying though. It's true that in all of the ZK TLS stuff that I've seen, it's read, it's read and then you do something with it on chain. But what you're saying is you're actually, well you're delegating the access to the TE and then it can do stuff with limitations that's programmable.
01:05:09.419 - 01:05:09.859, Speaker C: Exactly.
01:05:09.907 - 01:05:13.091, Speaker A: Yeah. Beyond the application itself. That's really interesting.
01:05:13.283 - 01:05:44.545, Speaker C: And you can always sort of web 3 your way around the first problem through over collateralization. Right. Like if all you have is this read oracle, but you want to say like I promise I will send whatever message through my email that the blockchain contract tells me to do. You could always set up slashing. Like I have to show my ZK TLS proof to the contract that I did send the email that I said I would and if I don't it slashes me. The only drawback there is just the complexity and cost of using over collateralization that way. So yeah, this is like an alternative to that.
01:05:44.545 - 01:05:47.755, Speaker C: It's like a proactive guarantee over write access.
01:05:47.915 - 01:05:52.715, Speaker A: I hadn't actually thought about that at all. So this is a new concept for me.
01:05:52.835 - 01:06:28.443, Speaker D: You know, we actually have talked a little bit about, I think when you think about MEV from this kind of lens of hey, you only need privacy in a short term sense, you know, other parts of defi and kind of transactions on chain do need longer term privacy. And I went to this talk which I admittedly really didn't understand because I do find these peer to peer credit networks very hard to understand who would use personally. But I think I heard this concept of liquefaction. So maybe it would be great to kind of understand what that is and how to think about that.
01:06:28.619 - 01:07:11.219, Speaker C: Let me explain liquefaction in terms of how it relates to this delegation and encumbrance story. First of all, there's reasons you would want to discourage this delegation. It's a little bit of a controversial topic, even what to do because it somehow, you know, changing the rules of authorization, you know, beyond what the original account provider is already providing. There's many cases where you would like not to support this kind of fractionalizing. Like vote buying is a place where you don't want a secondary market popping up on, you know, into your vote buying ability. So liquefaction is the name for taking like, you know, the soulbound token approach that's just based on EOA accounts. I'm making this distinction because Soulbound also has like the social recovery notion.
01:07:11.219 - 01:07:53.677, Speaker C: And I kind of mean, I mean to invoke the simpler version that's just like you don't want a smart contract to hold this airdrop token. So you only give airdrops to, you know, raw addresses where you think, well, because it's an externally owned account, it's a real person on the other end of it. Liquefaction is what you get when you ignore that and you actually have your airdrop key is itself inside of a text, which means that you can later put an auction on top of it or fractionalize. I think this was in the case of if you have a cryptokitty some NFT where it's supposed to be one person owns it, no fractionalizing. You can fractionalize it out from under them by doing this TEE based encumbrance trick. And that's the kind of key notion of that liquefaction paper.
01:07:53.781 - 01:08:02.491, Speaker A: Do you need that though? You would need this if it was soul bound. If it wasn't transferable, I guess. Or if it couldn't be incorporated into a smart contract itself somehow.
01:08:02.643 - 01:08:16.323, Speaker C: Yeah, exactly. It kind of fits into a cat and mouse game in a way of trying to thwart or enable from outside this kind of secondary market ability or redelegation ability.
01:08:16.499 - 01:08:46.791, Speaker D: Thanks for describing that. I think I'd heard that during kind of a talk about cycles or I heard the term for the first time. And I think maybe it would be great to talk a little bit about cycles, especially since it's, you know, a very different TE application. And I think one that perhaps also people in ZK land would find interesting because like, you know, there's things like ZK P2P, but this is sort of a different version of commerce between people.
01:08:46.943 - 01:09:09.528, Speaker C: Yeah. So the cycles project's been something. I've been helping out with the TE stuff for around a year now. This is a project led by Ethan Buckman from Cosmos Informal Systems, of course. And it's almost an accounting or a real world economics thing. It's backed by blockchain and TEE and this cryptography approach. But the intended use of it is not really within Web3.
01:09:09.528 - 01:09:57.959, Speaker C: It's really for real world businesses. And the idea is something like. He does a much better job of explaining the overall structure of this. But I like this idea of a credit network where we have credit and debt relationships that are expressed in some way and that we might do something peer to peer involving these. The most interesting credit graph of this kind is like the trade credit in the form of all of the invoices between just business to businesses, all of the account invoices that are due somewhere between now and the end of the month. These are all essentially uncollateralized credit between the companies who are the accounts receivable and accounts payable for that. And the key idea is that if you just imagine this graph, it's like a direct graph, people have to load into the cash system to actually do the paying their invoices.
01:09:57.959 - 01:10:48.605, Speaker C: They have to load cash into the system that's expensive and has some capital costs of working with cash to do that. If you had this global eye view of everyone's account information, you would identify these opportunities for cyclic flow, which is iou you owe me, we have third parties in between us. If we just all agree to deduct from our contracts to each other this amount, we never have to touch the banking system yet we will have successfully cleared our debt and don't have to pay the cost of. It's that much capital of cash that is displaced because it would otherwise have to be circulating. Now it doesn't have to circulate, we just atomically clear that. But this is sensitive business information. So even when it's in accounting software, QuickBooks or whatever, they're not trying to merge this and have a global eye view of everyone's competitive business information.
01:10:48.605 - 01:11:30.615, Speaker C: This isn't a world that is just by default everything public on the blockchain, they're actually safeguarded by default. And so the plan is to do a combination of ZK proofs for integrity guarantees and the trusted hardware for the computing this graph flow finding algorithm. Like what's the most amount that we can clear this way which requires a graph algorithm over all of the sensitive data. But no one person has all of that sensitive data. So it's just like to me it fits in. It's just another instance of this. Instead of computing the auction on top of the batch of sensitive bids contributed by every user here it's you compute the clearing solution by computing on the encrypted invoices submitted by every user.
01:11:30.615 - 01:12:01.995, Speaker C: And then the significance of the TE is because this is in more of a latency is okay the this is like a batch operation actually the security of we don't just want to rely on the TEE to prove no one's going to be short told not to pay. But then it's a big problem that they didn't. So we would use a zero knowledge proof for the integrity guarantees that everything's atomic, you net out to zero or better while using the trusted hardware as a backup integrity. So multiprover. But then that's also providing the privacy over all that data.
01:12:02.115 - 01:12:12.491, Speaker A: Interesting. So here the TE really does provide privacy. So that's the thing that's obfuscating the actual information. ZK here is only being used for just verifying the correctness.
01:12:12.603 - 01:12:14.531, Speaker C: Yeah, exactly. Verifying the correctness. Yeah.
01:12:14.603 - 01:12:24.667, Speaker A: That's cool. Is this a business solution then? Is this really for businesses or is this for individuals who are like exchanging funds among friends? Like what kind of use case?
01:12:24.771 - 01:13:14.243, Speaker C: So interesting. I mean, I came into this with a bunch of excitement around the P2P angle. Like I want to see the output of this be that, you know, we're so good at now managing debt, once we're enlightened by this concept and toolbox that we actually now want to form, you know, trust relationships or credit relationships with, you know, friend and family and in some way even use the zero knowledge in privacy as like a bankruptcy guarantee, like to prevent, you know, squabbles from exceeding the value of them in the first place. But what I've been convinced is that maybe that's still in scope for like a longer term thing that I'm excited about. But the businesses, there's no hypothetical about it. Businesses can benefit this from already and this latent graph of all of these obligations is already existent. It's just a matter of having a reason to import it and mechanism to do so and do something useful with it.
01:13:14.379 - 01:13:23.651, Speaker A: Where do cycles live? Is it in an ecosystem? Does it touch the blockchain? Actually, because what you just described is tes.
01:13:23.723 - 01:13:52.125, Speaker C: But this comes from the Cosmos world. I would say it fits into the Cosmos ecosystem especially. You could imagine there's a cycles chain that is an app chain to do that. One element of this TE sidecar, TE co processor approach is you can attach it anywhere. So I like the idea that it could launch on an existing public chain. It's the TE bits that would be new and added, but it could use Neutron or one of these Cosmos ones. But the way things go in Cosmos, it's most plausible that there'd simply be a cycles chain.
01:13:52.285 - 01:14:22.567, Speaker A: Okay. And that makes sense given that Ethan's involved in it. So cool. So, Andrew, thanks so much for coming on the show, sharing with us your history, working on consensus and then ZK a little bit and tease and kind of at first maybe not being into them. And then why you got really into them. I think that's really helpful for us all to understand. I think our community especially is pretty still anti teas, and so I think it's good to hear your perspective on it.
01:14:22.567 - 01:14:29.151, Speaker A: Also, thanks for sharing sort of these newer ways that we're seeing teas being experimented with. Yeah, thanks so much.
01:14:29.223 - 01:14:32.015, Speaker C: Thank you. This has been a blast of a conversation. Glad we can do it.
01:14:32.095 - 01:14:32.383, Speaker A: Nice.
01:14:32.439 - 01:14:33.023, Speaker D: Thanks, everyone.
01:14:33.119 - 01:14:40.655, Speaker A: Cool. I want to say thank you to the podcast team, Rachel, Henrik, Tanya and Jonas, and to our listeners. Thanks for listening.

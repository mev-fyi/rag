00:00:07.850 - 00:00:38.482, Speaker A: All right, cool. Hi, everyone. I'll get going then. Thank you. It's such a pleasure to be here, being able to talk about what we'd be doing at Aztec with you all, which is confidential digital assets on Ethereum. We are a privacy solution for, for the Ethereum main net that enables developers and individuals to create private digital assets, confidential digital assets and confidential zero knowledge dapps that interact with these assets just like you within the rc 20 token. At least that's the vision.
00:00:38.482 - 00:01:27.030, Speaker A: So I was going to go quickly over what I'm going to try achieving this talk, which is kind of explaining what we think needs to happen to actually put confidential transactions to work on Ethereum. Wait, I didn't do that, did I? I'm Zach. I'm the CTO of Aztech. Yeah. So we're a team based in London that are focused around building this privacy solution for Ethereum as a protocol layer for L1. Fundamentally what we believe is that Ethereum and public blockchains in general can't really achieve their true potential unless you can represent value on layer one confidentially. If the fundamental representation of value is private, then it opens up an enormous number of potential use cases that currently can't be explored.
00:01:27.030 - 00:02:34.800, Speaker A: Like almost all of traditional finance and traditional financial services kind of require privacy by default, which is one of the reasons why you don't see a large proliferation of things like mortgages, corporate bonds, syndicated loans on blockchain. One of the key blockers is privacy, and we're trying to solve that in a generic capacity. So for the agenda, what on earth needs to happen for that to actually be a reality? How do we get an l one solution that enables individuals, users, developers to create private digital assets without having to be literate in zero cryptography. And that feeds into the cryptography engine standard. What the hell that is, because that helps us achieve that, how we create our efficient range proofs. And then finally going into a little bit about our confidential token standard and the roadmap and what you can do to get actually start to develop with these things. So before I go ahead, how many people here are interested in creating private tokens, private assets on Ethereum or Dapps that zero knowledge dapps that interact with private assets? How many people have actually done so? Yeah, here's the problem.
00:02:34.800 - 00:03:22.410, Speaker A: So this stuff is hard, really damn hard for a lot of reasons that you have to handle a proliferation of secret keys. Usually it's very hard to create these application specific proofs. You need to be quite literate in ZK starks or ZK starks or sigma protocols. As you know, crypto, there's no standardization. So if you make a solution, it's not going to be compatible with other people's solutions. You've got to deal with trusted setups sometimes, and then you have to deal with long, pre hardened, difficult proof constructions, which present a massive UX challenge for browser based app and expensive pre verification, which is expensive. How do we bridge the gap between the technical vision and reality? How do we make this stuff actually workable? So step one, what do we want? What do we actually want? We need to like, because Xenon's truth can be used for a lot of things, and they have a habit of getting conflated a lot, but they are quite distinct, and they need their own solutions.
00:03:22.410 - 00:04:24.510, Speaker A: Private transactions, scaling solutions, publicly verifiable private computation, they're all extremely important for fully developing the Ethereum ecosystem, for blockchain ecosystems. What we at Aztec are focusing on is that confidential transactions layer being able to represent the fundamental unit of value on layer one privately in an encrypted way, being able to transfer it, having a common standard so that this can be applied universally. So the building blocks for a confidential ecosystem are, in my opinion, what you need is you need customizable confidential transaction semantics. If you're building an application specific side chain, it's absolutely fine to do like batch validation of transactions. You can process 10,000 transactions on the side chain as a batch uses a case snark, or as a case stark proof to validate the correctness of that computation. However, for actual, the fundamental representation of value, the actual digital asset itself, you have edge cases. You always have edge cases in the real world, where the actual specific semantics of your transaction are different.
00:04:24.510 - 00:05:12.026, Speaker A: One example would be if, for regulatory reasons, you need to make sure that no trader has more than 10% of the supply of your private asset, or if you have some kind of minimum trade threshold, or you have some kind of compliance like group signature scheming, you need to prove that you've been KYC anonymously, and so you need individuality. However, you also need interoperability. So these are somewhat orthogonal to one another. You need to be able to have confidential assets, private assets that all conform to a common standard like ERC 20, so that you can actually communicate, they can communicate with one another. You can transfer tokens, zero knowledge notes to and from these assets via smart contracts. You can actually start to create meaningful DAP ecosystems. And also for that you need a single common reference string.
00:05:12.026 - 00:05:53.302, Speaker A: Basically, you can't have multiple trusted setups. Because then as a DAP builder, you need to make an opinionated guess at which assets and dapps you have trusted setups that you trust and which ones don't. If everyone just uses one trusted setup, I mean, ideally zero, but just one, then you get rid of that problem. And obviously you need developer friendly tools. Right now these are mostly completely absent, not due to a lack of ambition or talent, but just because there's hardly any resources in this space. And right now the tooling is extremely difficult to use, even for people that are quite proficient in this stuff. And then finally you need efficient proof construction and verification.
00:05:53.302 - 00:06:34.906, Speaker A: On the proof side for good ux, if you're building a Dap in the browser and you need to construct your knowledge proofs, you don't want that to take two minutes and you want it to be able to be done on hardware, wallets and for verification. Obviously, gas is money and it needs to be cheap. So how do we forge these building blocks? First of all, a family of zero knowledge proofs that share this common reference string basically define a set of proofs that individually perform certain kind of discrete parts of business logic. Like for example, an interest rate payment, an interest rate proof so you can prove like this value is x percent of this value, or a basic joint split transaction, which I'll go to in a minute, but basically have these kind.
00:06:34.928 - 00:06:35.500, Speaker B: Of.
00:06:37.230 - 00:07:22.630, Speaker A: A modular proof system where you can kind of pick and choose proofs off the shelf to define the specific semantics of your individual asset and a shared suite of validation contracts. So we're calling the cryptography engine. This is extremely important, and I'll get to that in the next slide. But one of the things you can do with this is it means you abstract away the zero knowledge validation part from this smart contract you're building. You can use somebody else's libraries, somebody who's experienced in this stuff that actually has a lot of technical expertise. And it means that these assets are forward compatible. Because if you have a digital asset, a private asset that subscribes to the cryptography engine, then if that cryptography engine adds new proofs over time that do more interesting and innovative things, your asset, if you choose to be, will be automatically forward compatible with those new proofs, which is obviously quite valuable.
00:07:22.630 - 00:08:17.750, Speaker A: Specifically, as this industry is changing so much, probably in five years time, we'll have an enormous plethora of zero technologies that we don't have at that moment. And it will be very nice if the assets built today are forwards compatible with those. And then finally you need a confidential token standard to tie this all together. So a way of building a confidential asset that has a common interface, a common standard so that you can have interoperability, incompatibility. And then finally some really good crypto dev tools that abstract away all the nitty gritty of actually making zero knowledge proofs, just in the same way you can do web3 s sign transaction that makes a new DSA signature. You don't need to know about the mechanics of how that actually happens, you just need to know that you need a private key and a message. So I want to go into how you transfer value privately on Ethereum, at least how we do it, which is through these balancing relationships formed out of joint split statements.
00:08:17.750 - 00:09:04.074, Speaker A: So these are not like these have been around for a while. I think Zcash originally piloted them where basically you just have some input notes. Notes are like ux to objects on bitcoin, except the values are encrypted and you prove that the sum of the values of your input notes is equal to the sum of the values of your output notes. And then if you serve this proof, you prove this successfully, then a smart contract can destroy the input notes in its state registry and create the output notes. And that smart contract knows that you've not double spent, but it has absolutely no idea about what's inside those notes, which is of course the whole point. And then one extra addition is, sorry, 1 second is if there is a deficit in this balancing relationship, you can fill up that deficit with public tokens. So imagine your output notes are worth 20 and your input notes are worth ten.
00:09:04.074 - 00:09:41.894, Speaker A: That means you want to extract ten more value than you get put in. And so if you make that shortfall in tokens, then you're basically converting ten tokens into a zero and large note form. That's how you get the value into and out of our crypto system. On chain notes are public, so the existence of a note is public and the owner of a note is public. This was a deliberate design decision to improve compatibility between different private assets. We have a stealth address protocol that can be used to make that the owner of a notes completely meaningless. But the existence of a note is there and then the private data is its value.
00:09:41.894 - 00:10:25.650, Speaker A: And then you have a viewing key and a spending key. We kept these keys deliberately distinct. You need the viewing key to construct the designers proofs and decrypt the note. And you need the spending key to actually authorize transfer's value, which is valuable because that means then you can give viewing keys to relays. You can then construct proofs on your behalf, but you can very strictly define what those proofs can produce through signing with your spending key. And this really helps for extremely much more complicated zero protocols, where having a relayer in the mix would really help if there is that kind of entity that you would trust with a viewing key. So to put it all together, this is an example of a bilateral swap using the aztec protocol, EIC 1723 and 1724 standards.
00:10:25.650 - 00:11:08.210, Speaker A: I'm going to try and go through this. This is from our protocol specification, which is in its draft release. It's the link to it later. Basically what this is a bilateral exchange of encrypted value between two digital assets that have no knowledge of each other's existence. Effectively, the caller will have a proof, will have a valid zero knowledge proof of a bilateral swap between these, you know, two actors are trading notes from two different assets, and we have a Zk DAP. So imagine this is an exchange Dap that actually its job is to perform these swaps, it process orders. What this thing will do is it'll talk to the cryptography engine, the asset cryptography engine, ACE, to validate this bilateral swap proof.
00:11:08.210 - 00:11:50.814, Speaker A: Once validated, the cryptography engine will spit out a two transfer instructions. And this is one of the key things about the cryptography engine is it takes abstract arcane zeros, proofs as inputs, and it spits out transfer instructions as outputs that conform to a common standard. So now, once that ZK depth has its two transfer instructions which say, destroy these notes, make these notes. What it can do is it can then send those transfer instructions to the relative zero knowledge assets. And now what happens when a zero knowledge asset receives this transfer instruction? Well, it has absolutely no idea about that DAP. It doesn't know what it is. It could be a smart contract, it could be a person, it could be somebody tapping Morse code into a TCP IP connection to manipulate a blockchain node has no idea.
00:11:50.814 - 00:12:31.190, Speaker A: But it does know about the cryptography engine. It subscribed to that. So it can query the cryptography engine and go, hey, I've received this instruction. Is this a valid instruction? Where did this come from in the cryptography engine? Go, yes, actually, that instruction satisfies a balancing relationship from a bilateral swap proof. And AcE can do that just like automatically, because it validated that proof previously. And this is the real strength of the system, because it means that both these two Zk assets, they don't need to validate their own zero knowledge proofs, because it's already happened in the bilateral swap proof. Normally, traditionally, all one of these assets would have to validate a zoo knowledge proof according to their own custom individual semantics, which would mean three zoo knowledge proofs, which would be ridiculously expensive.
00:12:31.190 - 00:13:21.210, Speaker A: But with this one, you only need one because they're all listening to the same cryptography engine. That cryptography engine will then, once it's affirmed that a balancing relationship holds, that that asset then can then do its own permissioning checks, do we have the right signatures, do we have the right approvals, blah blah blah. And then it can issue the transfer instruction back to the cryptography engine, which will update the relevant note registry, destroying and creating the relevant notes. The reason why the cryptography engine controls the note registry instead of the asset is because that means this cryptography engine could provide a cast iron guarantee of the correctness of the state of every note registry. That there has been no double spending in any note registry. That the only way to add or change or manipulate notes is through balancing relationships. This is extremely important in the long term because it means that you can denominate 10 knowledge asset as a percentage of another note of another asset.
00:13:21.210 - 00:13:52.920, Speaker A: You can say like these notes are worth x percent of the notes in this note registry. And you know that because the second note registry has no double spending. That's a legitimate thing you can do. This is a bit abstract, I can talk about after in questions, but that's one of the fundamental reasons why we can do dividend payments, interest rate payments through aztec percentage payments, and zero knowledge. And then once that's all done, control flow will feed back down to the ZK Dap. I know this might look a bit complicated. That's because it is.
00:13:52.920 - 00:14:38.706, Speaker A: This is a multilateral transfer of encrypted value being mediated and validated by a public blockchain. But the thing is, this exists, it works, and it's practical. Like this entire flow will cost you, run you about at the moment, 750,000 gas, and when some erps come and stream, that cost will get crushed down and compared to more like to other kinds of zero preming technologies. If everything had its own protocols, its own zero proof semantics, this type of flow would blow through the block gas limit quite easily. So I did mention that efficient range proof. The whole reason why these zero knowledge proofs can happen like this system can happen is because we have our zero knowledge protocols are efficient to verify because of this range proof. So I want to see.
00:14:38.706 - 00:15:27.640, Speaker A: I don't have a lot of time. I'm going to try and go into it a little bit, if that's all right, because this is, after all, the zero knowledge cryptography conference. Our range proof is built on fundamentally a polynomial commitment scheme. Normally, polynomial commitment schemes are extremely powerful in xerological cryptography because it means you can very efficiently prove very complicated relationships. Specifically, the thing about polynomials, when expressed over a finite field, so, like a group of integers modulo at large prime and evaluated in the curve, is, well, for two scalars in this finite field, the difference between the scalars will perfectly divide the difference between that polynomial evaluated at those two scalars. That seems a bit abstract. What's the point? Well, it means that.
00:15:27.640 - 00:16:14.370, Speaker A: Hang on. If you take this relationship, let's call it new, you can always compute this, even if y is a secret created during a trusted setup. Even if you do not know what y is, you can still compute the coefficients of the polynomial that is required. And then, when expressed over elliptical curve, if you're given the correct points, you can then reconstruct the polynomial over elliptic curve and prove that, yes, you have a commitment to the polynomial. This is valuable because what if you construct your polynomial so that if you commit to an integer which is within the range of your range proof, it evaluates to zero. This is really important because then you get this relationship. Now, mu becomes this.
00:16:14.370 - 00:16:38.538, Speaker A: Just phi, this expression, polynomial value over y divided by one minus k. And so when you juggle the mass, rearrange it, you get to this equation, and you can express this over a letter curve using bilinear pairings, where. Sorry, I'm using exponential notation. G is the generator in the first group. G two is the generator in the second, like, larger pairing group. So you can just multiply these together. Basically, nu times y equals the polynomial of age of y multiplied by nu times k.
00:16:38.538 - 00:17:11.986, Speaker A: Why is this important? Because if you satisfy that relationship, then you committed to that polynomial where the evaluation polynomial is zero. Because otherwise, if it wasn't zero, you'd have an extra term in here that isn't there, and you can construct your crypto system so that it is impossible to sneak that term in. And I'll get into that in a little bit. So trust the setup I mentioned. Trusted setup. We do have a trusted setup. You have to basically evaluate that polynomial over a secret y that nobody knows.
00:17:11.986 - 00:17:52.258, Speaker A: This actually is extremely similar to Zkash's powers of tau ceremony, to the point where we can actually use phase one of Z. Cash's powers of tau ceremony. So you have these powers, and then you can use those powers to construct these polynomial equations expressed over. Let's basically, you can figure out, very efficiently, figure out the coefficients of these polynomials and compute them. That's Phi expressed over y. And then what you can do is you can take this thing, this, divided by this, you can coefficiently compute the polynomial coefficients for that and compute those polynomials. Why is that important? Because now if you select, imagine that's in a database, because it is.
00:17:52.258 - 00:19:13.434, Speaker A: If you select one of these new values and you check that if you multiply this by k and then add it to the polynomial plus y. So this is, this is, I'm going to flip this around. If this is equal to the base point you pick from your database paired with the trust is set up public key like g two to the y. If these match, then you have a commitment to an integer where that integer is in the valid range of the range. Proof. And you cannot satisfy that equation without that being the case, unless a, you know why, or b, you've solved one of the discrete logarithm problems that so much of elliptic curve cryptography is based around to kind of get to the end of this. How do you actually use that to make a commitment function? How do I commit to an integer in a way that it means it's encrypted and it has the cryptographic properties of being computationally binding, which means if I commit to an integer, when I open the commitment, I can only open it to that integer, I can't open it to something else and information threat of hiding, which means that nobody, if I give somebody my commitment, they can't figure out what I've committed to, they can't figure out what the integer is.
00:19:13.434 - 00:20:10.746, Speaker A: Well, first of all, we need some randomness, obviously, because you need to randomize this stuff. But then what you do is you just pick the trusted, if you want to commit to an integer, you pick the relevant point out of the trusted setup database, multiply it by that randomness a, that's one of your points. Gamma sigma is then gamma multiplied by k added together with h, which is the polynomial evaluated over y multiplied by a. And if you expand all of that out, which I don't have time for, I'm afraid, into these pairing equations, you get back to that polynomial commitment function, and this can be treated like a pedestal. Commitment h can be treated like a generator because it has a factor of y in it, which means that you cannot map between gamma and h or h and sigma or h and the generator point g, because every single one of those mappings has a coefficient of y in it, and you don't know what y is, because it was just ideally destroyed during the setup. And that's how we get an extremely efficient range proof. Our range proof.
00:20:10.746 - 00:21:09.886, Speaker A: All you have to do is, step one, use a sigma protocol to prove in zero knowledge that you can open aztec commitment. And then step two is just do this bilinear pairing check. So if you consider a single protocol that opens a pedison commitment, the only difference is this bilinear pairing check. And one of the extra strengths of the aztec protocol is the right hand side of these pairing equations. Those arguments, they're constant, and they're always constant for every single asset note, which means if you have multiple ASIC notes in a proof, you can create a linear combination of the asset commitments, each multiplied by a random variable, and then use that in one pairing check. Basically, you can condense an arbitrary number of aztec range proofs down to one pairing check and a signal protocol to prove you can open the aztec net, which is extremely powerful because pairings are expensive. So you can use this in conjunction with sigma protocols to prove algebraic relationships directly expressed in the kind of exponential elliptic curve.
00:21:09.886 - 00:21:36.746, Speaker A: And that's what we use for our joint split balancing relationships, balanced for swap interest rate payments, blah, blah, blah. And you can expand this to create quite reasonably expressive proof statements. There is a limit to how far you can go, but there is always this compromise between interoperability and customizability. The more custom you get, the less interoperable you get. So we've tried to find a balance between the two. So this is our cryptography engine standard. These are the proofs that are in kind of our v version 1.0.
00:21:36.746 - 00:22:03.346, Speaker A: So you have that bilateral swap joint split. We have a partial order filling proof on the way. We'll get to that if people request it. We're focusing more on our tooling at the moment and then some utility proofs for those customizable transaction somatics. And right now, today, those are the gas costs, which seem it is 800,000 gas. But, sorry, this is a tortology. It's also.
00:22:03.346 - 00:22:43.182, Speaker A: It's 800,000 gas. Like, this is actually practical. You can do this today, and sure, it'll run you, like, $0.30, but, my God, it's actually possible you can actually create today confidential digital assets using the asset protocol and have them, and actually have confidential settlements between different kinds of private assets, which is not something which has really been talked about much, but I think one of the key strengths of Ethereum is that it is a settlements layer. And once you have private settlements, then that opens up an enormous spectrum of use cases which can't currently exist, and then commenting. Finally, also with our ER 1724, our confidential token standards. So this interface looks very ideally quite similar to an ERC 20 has confidential approved and confidential transfer and confidential transfer from.
00:22:43.182 - 00:23:26.350, Speaker A: But the idea is we extract away all the cryptography into these kind of like these bytes, aztec proof variables basically you use our aztec proof construction APIs to say make me a proof. Here are the input notes that I have, and here are the apple notes I want, boom, you get your proof, you can feed it into the smart contract, you don't need to deal with the fuzzy mechanics of what's happening inside. And then this is all culminating in our aztec monorepo. So this is where all our code is, this is where the guts of Aztec is. And if you want to play around with ASIC, start working on building convincing assets. This is where to go. Astec JS is our proof construction library protocol contains our smart contract templates for our cryptography engine and example ER 1724 contracts.
00:23:26.350 - 00:24:16.450, Speaker A: And if you want to get your hands stuck in with developing private assets, well, I mean me and my colleague Paul, we're here today, so if you really want to ask us any questions, please, by all means do so. Paul also wrote an example in our medium publication of how to get started with asset, how to make a confidential digital asset. And this morning we published our draft specification of our V 1.0 protocol at our GitHub repository. So those are the places to go if you want to start looking into Assec. Finally, because I'm almost out of time, the roadmap for asset 1.0. So NaQ one, which is like about now, but we're like a couple of days behind track because we pushed our security order forward, MVP cryptography engine, deployed the testnets, our complete proof construction API, and this kind of optimized electric curve smart contract, something called vs trudle.
00:24:16.450 - 00:25:02.394, Speaker A: Basically it does what one of the pre compiles do does, but a little bit faster, get that deployed to cover costs down by 20%. Q two, finish our trusted setup, our multiparty computation, we can collaborate with the people who also need this, people using ZK snarks on Ethereum, they need to do exactly the same trusted setup as us. So there's an enormous scope of collaboration there. And then formal verification or actual smart contracts and cryptography entry, because my God, if there was ever a need for formal verification it is when you're validating bespoke custom zero knowledge cryptography. And so we tend to do that, I should also add all our cryptographic protocols. We have formal soundless boosts to them, so, like, mathematically, they are completely secure as long as you can trust discrete logarithm assumptions. So we just wanted to make sure that the code is an expression of the mathematics.
00:25:02.394 - 00:26:03.330, Speaker A: And then Q three release our production grade main net release. Well, thank you very much. I've been Zach, and it's been a real pleasure. Thank you. So the user needs to have an exchange of notes so that basically they have to, like, as an automaker and order taker, they both have notes they want, some notes they need at the moment. Our binary swap proof does use a relayer for efficiency reasons, but we also have a, I mean, sorry, we've a bit constrained on resources, but we also have, like, another proof, which doesn't require the relay, which is just a bit more expensive. And so we're definitely getting that into our main net production release, where basically you have two users, they both say, here's a note I want, here's a note I need.
00:26:03.330 - 00:26:39.084, Speaker A: There's anonymous proof to do the transfer. Both users do that side their side of the proof, and then the crypto commissioner kind of like validates them both in a batch, which can be, is a bit more efficient than doing them individually. And that will then spit out the swap orders. Yes, the relayer would be. Absolutely. The relayer will be trusted with the viewing keys and trusted, but not like splurging the viewing keys and revealing who runs notes and what they're worth. Yes, it is possible.
00:26:39.084 - 00:27:04.592, Speaker A: The multiparty computation protocol, which we've not really explored at the moment, just because it's quite gas intensive and it's quite like the UX is really bad because you basically have two users that have to kind of eke ever closer towards matching me. I might have an order for 58, maybe I have an order for 48. What do you have? And going through successive rounds is an absolute pain in the neck. So, I mean, if there's demand for it, we'll build it. Absolutely. But right now we're focusing on more simpler primitives.
00:27:04.656 - 00:27:06.036, Speaker B: Do the maker and taker have to.
00:27:06.058 - 00:27:52.100, Speaker A: Interact in any way, shape or form with each other or not? Once an order is matched? No, they don't. They basically either two ways. One, they use the kind of like, exactly what you do in that situation is you construct a digital signature saying, I want to sell. I want to sell ten at this price, and here's the viewing key. So then what the relay would do once they've matched the proof. They construct the general's proof, but then the smart contract would check the signatures and check, hey, is the output of this proof equal to what these signatures asked for? And that's how. So, yeah, from the order creator, order taker, maker's perspective, it's completely non directive once they've given that data to the relay.
00:27:53.720 - 00:28:01.976, Speaker B: So does the maker have to do something else? If they offer, like, want to sell 20, but they only sell ten, do they have to do something?
00:28:02.078 - 00:28:24.670, Speaker A: Now that's where my partial order fillings and almost proof comes in. But we've just been a bit too busy with the core protocol stuff. But that's definitely going the engine, because partial order filling it can be done, I think is really cool, and it's important. Cool. Right. One last question. Okay.
00:28:25.040 - 00:28:31.408, Speaker B: How does this batch validation work? So how does this get triggered and where does it happen?
00:28:31.574 - 00:28:57.992, Speaker A: So do you mean with that, when I talked earlier about like, that would be a specific, actual zero knowledge proof type. So the idea is you can add different proofs to the cryptography engine. They all have like an identifier which describes what they do and what you'd add one. Basically every single zero proof has its own validator smart contract. So you'd add one that actually validates aztec proofs in a batch, and that's how you'd process it.
00:28:58.046 - 00:29:05.800, Speaker B: Then people provide to the cryptographic engine their proof, and then in the batch they get validated.
00:29:06.220 - 00:29:22.524, Speaker A: So, yeah, what you have to do is you'd have to have people like somebody, but either somebody or smart contract, accumulate a bunch of proofs and then go to the cryptography and go, here, I'd like to, here's the input to this proof id, this batch validation proof. Please validate it. Pardon?
00:29:22.652 - 00:29:24.450, Speaker B: Who's doing this call?
00:29:24.900 - 00:30:01.004, Speaker A: So that's very context dependent, isn't it? For two people doing a trade, either them or a coordinator, a relayer type person would be validating the batch. I do want to just narrow down what I mean by batch. This is not, as it currently stands, a scaling solution. You batch validation, it is more efficient at validating individual asset proofs, but it still does grow linearly. So it's small batches, only more for like Ux convenience and a slight gas optimization than an actual, any kind of scaling solution. Cool. Well, thank you very much.
00:30:01.004 - 00:30:02.220, Speaker A: It's been a pleasure.

00:00:07.130 - 00:00:32.898, Speaker A: Welcome to Zero Knowledge, a podcast where we talk about the latest in zero knowledge research and the decentralized web. The show is hosted by me, Anna, and me Frederick. This week we're sitting with Alex Gluchovsky from Matter Labs. Welcome to the show, Alex.
00:00:32.994 - 00:00:34.114, Speaker B: Hi, Anna. Hi, Frederick.
00:00:34.162 - 00:00:36.386, Speaker C: Hey, thanks. Welcome. Welcome back, I suppose.
00:00:36.498 - 00:00:45.818, Speaker A: Yeah. So Alex has been on the show before. Actually, last time you were on the show was Alex and Alex from Matter Labs, your colleague Alex Vlasoff was also here.
00:00:45.904 - 00:00:46.586, Speaker B: True.
00:00:46.768 - 00:01:25.320, Speaker A: I think it's definitely worth listening to that episode before this one because we're not going to spend so much time on kind of you and matter and roll up and a lot of the sort of basis. But that said, I think we will do a quick kind of summary of what we had talked about in the previous episode. So, yeah, last time we spoke, we talked about Matterlabs work on a version of ZK Rollup. I remember you described ZK Rollup as sort of an overarching category of constructions and you guys were working on yours. So I'm very curious to hear what's new since then.
00:01:26.010 - 00:01:56.870, Speaker B: So EZK Rollup is actually a name of the architectural approach to scaling blockchains. And we were working on the specific implementation of ZK Rollup for Ethereum, and we made quite some progress over the last year. We had to review our approach, our particular architecture, make some pivots, changes, and it eventually led us to the full scale version of the vision, which we call Zksync.
00:01:56.970 - 00:02:02.334, Speaker A: So originally you had had this idea for something called Franklin. Is Franklin now ZK sync?
00:02:02.382 - 00:02:04.302, Speaker B: Yes, that's the name incarnation.
00:02:04.366 - 00:02:16.200, Speaker A: Okay, so not only did the architecture change, but the name changed as well. Got it. So then I guess the question is, what then is ZK sync? Exactly.
00:02:16.810 - 00:03:16.506, Speaker B: Well, ZK sync is the completion of the vision. So it's what we call, this is the full package of how scaling will work on L2 blockchain to have all the useful properties we want from a scaling system. So we want high throughput, we want trustless security without relying on any assumptions. But we also want some properties which will make scaling useful in the context of mass user adoption. And if we talk about mass user adoption, we are speaking about people who are used to services in online banking, in web ecommerce, which are very different from what we have right now in blockchain. The things are fast, things have instant confirmations. People take their privacy for granted, or at least they don't assume that all their transactions are going to be visible to all their friends and relatives and so on.
00:03:16.506 - 00:03:30.346, Speaker B: So we want all these things to be the part of the package. And this required some more trade offs and more additions than just a pure roll up. And this is what crystallized as Zksync.
00:03:30.538 - 00:03:58.040, Speaker C: Is this at all related to syncing of a blockchain in the way that we typically call it? Like there's warp sync or fast sync? And I've seen Zksync being mentioned in the context of replacing those. Is that the case at all? Or is it more like reinventing the whole system, and that's how you avoid having those things in the first place?
00:03:58.590 - 00:04:30.226, Speaker B: Well, that's just a way for us to emphasize the importance of being fast for instant confirmations, for just sync and with the transactions you want to make. So it has less to do with syncing the blockchain. In fact, Zksync is very light, client friendly, so the users will not need any heavy computational or bandwidth capacities to be able to verify Zksync transactions and be absolutely sure that they are correct.
00:04:30.328 - 00:04:43.480, Speaker C: So this is similar to the approach that maybe sello or coda takes, that you get a snark that tells you you are on the right chain, and this is the state route that you can trust, basically.
00:04:43.850 - 00:05:17.650, Speaker B: Exactly. This is similar to those approaches, because with ZK snarks, with ZK zero knowledge proofs, in general, 160 knowledge proofs, we can have a very short proof that everything is correct. We don't have to verify the completeness of the entire blockchain, because we are a L2 solution. So we always rely on the security of underlying layer one. And if layer one is ethereum or polka dot, then you still have to do all the work necessary to verify that chain. So we cannot replace that. But everything on top is very succinct and easy to check.
00:05:17.800 - 00:05:25.380, Speaker A: I actually have a question about your question, Frederick. Warp sync, aren't those things that, isn't that something that happens more on, like, layer one?
00:05:25.690 - 00:06:03.570, Speaker C: Yes. Well, I mean, it's something that syncs layer one, yes. But whether or not it happens on layer one, like Warp sync, is not an official Ethereum protocol, so it's L2 in that sense. It's not officially part of the Ethereum spec, and it's passing a state snapshot around on the PTP network. But this is a massive now, like, ten gig snapshot or something, and it's heavy to pass around. Passing around just a snark instead would be a lot easier.
00:06:04.310 - 00:06:32.570, Speaker A: Also, I realize I just used L2 potentially incorrectly. I know that from our show that we did with Dan Bonet, he redefined sort of the layers, and I've actually heard it redefined a few different ways. So there's like layer one, layer 1.5, L2, layer three. Where do you think, I realize these are changing templates of how to think about these projects, but where do you think Zk sync is?
00:06:32.720 - 00:06:36.346, Speaker B: Well, I have a strong opinion that this is a layer 1.5.
00:06:36.448 - 00:06:36.858, Speaker A: Okay.
00:06:36.944 - 00:06:56.580, Speaker B: Because you actually don't add additional layers of security on a system, you still let all the transactions verify being verified by layer one. So it's essentially an extension of layer one. It's not quite layer one, L2, but it's not layer one either. So we put it in between.
00:06:57.030 - 00:07:10.230, Speaker A: What exactly is it? Is it a library? Is it a piece of software? This is actually something I've never fully gotten. Also about roll up. Like, is it a spec? Is it a set of rules?
00:07:10.570 - 00:07:37.726, Speaker B: So it's a protocol. It's going to be a platform. You can think about it as an extension of the basic blockchain. So from the user's point of view, it will be very similar to just using the underlying blockchain. So let's speak about Ethereum. On Ethereum, you have some accounts, you have transactions, you have code which you can put on these accounts and make them smart contracts. And all of these things will be possible on Zksync, just going to be a separate address space.
00:07:37.726 - 00:08:16.710, Speaker B: So from the component point of view, ezksync is a separate network of nodes which generate blocks which hold the state, because somebody has to store the state off chain if it's not being stored on layer one, which connects to the layer one network and broadcasts some transactions to make the state transitions. But apart from that, it leaves a separate life. And this is why we will have a token to govern the participation of the validators of this separate network.
00:08:16.790 - 00:08:26.720, Speaker A: Got it? That was actually my next question was like, does it have its own token? And you just mentioned validators. Will it have a validator community as well?
00:08:27.810 - 00:09:23.182, Speaker B: We will have a governing body as a smart contract of some kind, where you use your tokens to vote and you use your tokens to participate. So you will need to get some tokens in order to be part of this community, because we cannot make it permissionless since we need to govern the way the blocks are being produced, the sequence of the blocks, but we cannot make it permissioned either, because then it's going to be a centralized system and it's very important that the system remains censorship resistant. And to be censorship resistant, you need anybody to be able to participate. In order to balance these challenges, we introduce token. But this token is not going to be something users, the end users have to deal with, because we don't want to introduce any friction on the end users. For end users, it's going to be completely transparent. They use just the same way they are used with normal blockchains.
00:09:23.246 - 00:09:42.038, Speaker C: You mentioned the participants of this network are responsible for data availability, like storing this data, this state somewhere, if it's not on layer one. Is this an incentivized action then? Is that incentivized by those tokens or why would they store that?
00:09:42.204 - 00:10:13.422, Speaker B: Well, we need to generate blocks quickly and confirm transactions quickly. And for this, the validators need to keep the complete state in some place which they can quickly access. And this is of course an incentivized action, because the validators earn fees from operating the nodes. But the end users can always query the validators to get their state. Or if the validators are not cooperative, they can always revert to the full archive of the underlying layer one blockchain.
00:10:13.566 - 00:10:25.646, Speaker C: Right? So it is incentivized, but not as a separate entity. You can just join the network as a state store, you join there as a validator and get incentivized.
00:10:25.758 - 00:10:46.970, Speaker B: We try to keep the number of roles low for now we only have two roles, the validators themselves who produce the blocks. And we also want to introduce guardians who will be something like incentivized. Full node users only have one purpose, to check that the validators do not perform censorship.
00:10:48.430 - 00:10:49.414, Speaker A: Like a fisherman.
00:10:49.462 - 00:10:51.242, Speaker C: Yeah, what we call fishermen.
00:10:51.386 - 00:10:52.830, Speaker B: Something like a fisherman.
00:10:56.930 - 00:11:03.410, Speaker A: Is this all an ERC 20 built on Ethereum? Is this a standalone blockchain?
00:11:04.310 - 00:11:14.398, Speaker B: So this is a standalone blockchain, but we will be able to bring all ERC 20 tokens onto it and seamlessly.
00:11:14.574 - 00:11:21.634, Speaker A: Transact because you actually have to bring. How do you do that? What is that then? Is it a. Well, all the tokens of Ethereum?
00:11:21.762 - 00:11:45.218, Speaker B: No, it lives on Ethereum. We have a smart contract on Ethereum. So in order to have some funds in the ZK sync, you first have to move them from Ethereum to the smart contract. Then they appear magically on your account in Zksync, and then you can transact inside ZK sync. And while you're transacting, they just remain on the same smart contract being parked and controlled by Zksync.
00:11:45.334 - 00:11:47.326, Speaker A: Is this like a bridge to somewhere else?
00:11:47.348 - 00:12:10.018, Speaker C: Yeah, I was going to say let's break down the magic a little bit. How do you build the blockchain, not fork of Ethereum in the sense of forking the network, but fork of the geth code base? Or is it something that you built from scratch? And yeah, is it bridged? Or how do you actually confirm that those tokens exist on that account on Ethereum?
00:12:10.114 - 00:12:49.060, Speaker B: Well, that's very simple. We have the smart contract, which holds all the funds, and the smart contract also holds the state. The state, or commitment to the state. So the merkle rule of the state, and the state keeps the track of all the balances in ZK sync. So whenever we have a change in ZK sync, we just submit a transaction to Ethereum and change the state and update this merkel root of the state. So the state and all movements of all assets are constantly being tracked by Ethereum itself. We can always go back to Ethereum and prove that we have certain account in certain balance in certain account.
00:12:49.060 - 00:13:14.010, Speaker B: It requires a separate blockchain to have all the different transactions being compressed into separate blocks. And we post a single state change per block on Ethereum, while the block can contain thousands of transactions.
00:13:14.990 - 00:13:34.046, Speaker A: And I remember what we talked about in the last episode, because I remember thinking, well, that's so weird. If you're still writing so much to the main chain, where do you actually find savings? And I think what you had described was it wasn't in storage, it was rather in the transaction call data or something.
00:13:34.148 - 00:14:18.510, Speaker B: Exactly. So in order for us to keep the state correct, we actually do not need to publish anything. We just rely on the magic of zero knowledge proofs, and we submit a short proof that this new root hash is a correct representation of some state. However, in this case, the users will have to rely entirely on the validators who keep the state in order to know what's going on, because the validators can withhold the delta, the new changes. And then despite the root hash being correct, nobody will be able to prove that they own some assets in this hash. This is what we abuse the layer one for. We just broadcast the data through the transaction input on layer one.
00:14:18.510 - 00:14:30.740, Speaker B: This way we make it available to all the full nodes, full archives, and to all the users who want to listen or who want to retrieve this data later. This is just a recovery mechanism for data.
00:14:31.350 - 00:14:40.326, Speaker A: Going back to that question, though, what is that blockchain you sort of had suggested it might be like the geth code base fork. What is it?
00:14:40.348 - 00:14:58.634, Speaker B: Maybe it's a separate node written from scratch in rust, which holds the state and which has a separate network which exchanges blocks and transactions. And then we come to consensus, what's going to be the next block? And then this block is being broadcast to the layer one.
00:14:58.752 - 00:15:10.480, Speaker A: Was there something special in the way you built that? Could you strip out a lot of the other things that normally would go into building a node or.
00:15:12.950 - 00:15:43.530, Speaker C: Yeah, I'm also always curious about why people make the engineering choices that they make. And I think why build from scratch is a valid point when there are already a bunch of nodes out there or frameworks even now for building blockchain. So it's always curious to hear why people build from scratch or do what they want to do. But I think it's cool to have done that. But I'm sure it's a lot of work too, no?
00:15:43.600 - 00:16:12.690, Speaker B: Well, of course we're going to reuse the components. So for now we don't have the complete implementation of the decentralized nodes. We focused on the most complex and difficult part, which is zero knowledge proofs, the circuit, the data availability, the interaction with the blockchain, the decentralization is something we're still working on. And of course we use ready components. So we're not going to write our own peer to peer layer, we're not going to write our own consensus mechanism and so on.
00:16:12.760 - 00:16:26.530, Speaker A: Yeah, I guess I wondered if, because zero knowledge proofs and ZK snarks are at the heart of it. Did you have to keep that in mind in the building of this part, or is like you just mentioned, a circuit designer circuit. What is it? What would it be in the node?
00:16:26.610 - 00:17:13.670, Speaker B: Well, the circuit is what we call the program, which converts to zero knowledge proofs. This is the arithmetic circuit or algebraic circuit. And every time we produce a new block, we have to produce the zero knowledge proof of our circuit, which proves that the state transitional is correct. So of course we have to take this into account. Apart from that, the consensus and peer to peer network part is not that much different from other blockchains. We just make different trade offs based on some properties. For example, in layer one blockchains, your highest priority is security and decentralization.
00:17:13.670 - 00:17:43.206, Speaker B: So you take certain choices there and you want to make sure that consensus mechanism you use is secure. If you use proof of stake, then you solve all the subtleties of proof of stake, such as nothing stake and long range attacks and so on. In our case, we can rely on layer one already existing for arbitrating different situations, so we place much less security on our consensus.
00:17:43.338 - 00:18:04.310, Speaker C: It's a valid point though. I know exactly what you mean, because we have the same discussion in Polkadot, where pair chains are just responsible for their censorship resistance, essentially. And that is a much simpler thing to secure than layer one. Like the relay chain.
00:18:05.130 - 00:18:58.630, Speaker B: Precisely. We just take use of the ability to contact the layer one and to do some operations there and to punish the misbehaving validators there. So our design choices are correspondingly less difficult. But also, because we solve censorship resistance in a different way, we can have a higher requirements to validators concerning their resources. So the mass layer ones, blockchains, such as Ethereum or Polkadot, and similar ones need to make sure that the users can run full nodes which operate smoothly under low resource requirements on ordinary laptops of users. We don't need that because our users all use lite clients, and our fishermen or guardians can only monitor a fraction of transactions. They don't have to monitor all of them.
00:18:58.630 - 00:19:12.470, Speaker B: It's much easier for us. That's why to say, okay, all the validators have to have powerful servers, especially because they need to generate zero knowledge proofs which are computationally intensive anyway. So these are just different trade offs.
00:19:12.630 - 00:19:19.422, Speaker A: You just mentioned that if there was any sort of, I don't know if you said conflict or if there's any issue, resolution would happen on the main.
00:19:19.476 - 00:19:39.240, Speaker B: Chain in terms of proof of stake, because it's going to be a proof of stake for the validators. So whenever they have double spend or double signing attacks, we can always resolve this on layer one instead of trying to build a complex consensus protocol which resolves it in itself.
00:19:41.130 - 00:19:43.270, Speaker A: How would the main chain know that?
00:19:43.420 - 00:19:54.202, Speaker B: See, if there is an equification and some validators signed two conflicting branches of a blockchain, you can always present both signatures to them until later on.
00:19:54.256 - 00:19:55.754, Speaker A: Okay. You'd present them both to the main.
00:19:55.792 - 00:20:07.646, Speaker B: Chain for a pure proof of stake blockchain, where you have to resolve situation on the blockchain itself. It's a bit difficult, because now you have to prove which of these two branches is actually the correct one.
00:20:07.828 - 00:20:12.014, Speaker A: What would happen if they both presented us to the main chain? What happens?
00:20:12.132 - 00:20:16.158, Speaker B: Well, then you would slash the validators who perform equation.
00:20:16.334 - 00:20:20.370, Speaker A: But how do you know, how would you know which one is right?
00:20:20.520 - 00:20:47.654, Speaker B: Well, it depends on the rules, how you're supposed to follow the rules. So, for example, we have certain sequence in which leaders ought to be elected. Then we know that this leader is the right one. But essentially we can just unroll all the changes by equivocating actors and continue from the previous state, which is known to be valid.
00:20:47.782 - 00:20:59.902, Speaker C: Is this where you imagine that guardians play a role in binding these things and reporting them to the main chain and submitting those transactions, or will actually.
00:20:59.956 - 00:22:08.690, Speaker B: Not really, because in our case it's really, really simple. The consensus on ZK sync is only needed to decide what's going to be the next block. Once we have the supermajority of signatures for the next block, anybody from the validators can submit it to Ethereum or to the layer one which we're using. And then if this block is being mined, then this is going to be the next block, because the correctness of the block itself is secured by zero knowledge pros. So you only need to make sure that there is no double spend. So whatever block has been pushed and was mined on layer one is fine. We only need guardians to make sure that there are no transactions which are being distributed by users which are not being included in blocks for a long time, because that would mean that we have a case of censorship if we have a lot of capacity, and we assume that we will have a lot of capacity because of our high throughput volumes of thousands of tps, there is no reason for validators not to include these transactions.
00:22:08.690 - 00:22:20.294, Speaker B: So we can then subjectively assume that there is a censorship going on. And then the guardians who notice this can stop voting for the validators who engage in this activity.
00:22:20.342 - 00:22:36.206, Speaker C: So essentially, going back to the conflict resolution, if there is an equivocation, there's two blocks produced, they're both submitted to the Ethereum network. Ethereum then decides which one is correct and to include and rejects the other one.
00:22:36.308 - 00:23:27.840, Speaker B: Exactly. And we don't care, we don't care which one wins. What's important for end users is that they get their money back. So the way the consensus is being used is whenever you submit a transaction, you're going to get a receipt from the validators who promise you to include this transaction in the next block. And this receipt is going to be signed by two third of the validating stake. And now if we have an equivocation, then you are eligible for compensation for this transaction, which we can always attribute to malicious validators. And we can always make sure that there is enough validators attribution to pay you back from the security deposit, which is going to be huge.
00:23:27.840 - 00:24:33.860, Speaker B: So of course you always have the risk that there is a run on the security deposit and the validators created a lot of fake transactions, but then they're going to lose a lot of stake without having any profit from it. So it's very similar to double spending attacks on proof of work blockchains, which are always possible if you spend enough money, but it's just so against the incentives of any rational actors that it's unlikely to happen. You can always quantify it and say, okay, to revert last ten blocks of bitcoin or ethereum, you have to spend this much money. Now, if the entire volume of the transactions throughout this period is much less than the amount of money you need to spend on a double spend attack, then it's very unlikely to happen. It can only happen if you have some state actors who are trying to mess up with the blockchain. But it's an entirely different story.
00:24:36.010 - 00:24:41.350, Speaker A: Who would be a validator for a Zksync? Who are these actors?
00:24:42.330 - 00:25:19.070, Speaker B: Anybody can become a validator who has enough resources to generate the proofs which is actually solvable because you can do it in the cloud. So you can always rent out capacities on Amazon, Digitalocean, any other cloud provider, and you just need to purchase some tokens which are going to be available in a completely permissionless setting because they're going to be sold on automated auction as well as from other players. And you just stake those tokens and you can become a validator. You get a slot to produce your blocks.
00:25:19.150 - 00:25:28.486, Speaker A: Will there be like, are you planning on doing sort of delegated proof of stake as well? Is this a simpler proof of stake that you're thinking about?
00:25:28.668 - 00:25:40.540, Speaker B: We will have something like delegated proof of stake with guardians because the Guardians will delegate their votes to the validators who they think are honest.
00:25:41.390 - 00:25:41.914, Speaker A: Got it.
00:25:41.952 - 00:26:39.698, Speaker B: And interesting thing about guardians is that they do not need to secure ultra. Hardly their nodes. The guardians can run their nodes on ordinary laptops which are unsecured or on any cloud instance, because there is no slashing conditions for them, because they can never incur harm to the blockchain. The validators will be solely responsible for the security bond from which the transaction, receipts, compensations are being covered. So the only thing guardians decide is just who is going to be the next validator. And the worst thing which can happen if all of the guardians or majority of the guardians are being hacked is that the chain will stop for a while until these guys hold out their private keys from cold storage and change the hotkeys on the nodes.
00:26:39.894 - 00:26:56.046, Speaker C: I suppose if all of the Guardians delegate to a validator, that is, or a set of validators that are censoring, then they can essentially ensure that the network keeps censoring. That's sort of the worst case, basically.
00:26:56.148 - 00:26:59.540, Speaker B: The Guardian not performing their job. Absolutely correct, yes.
00:27:00.390 - 00:27:23.082, Speaker C: Before we go to talk a little bit about what you've actually built and what you're planning on building. I want to go back a little bit to what you have built. So it sounds like you've built essentially the state transition function for your chain. And you said, yeah, we will reuse networking, consensus, whatever, from something else. Do you already have in mind what that something else is?
00:27:23.216 - 00:27:59.060, Speaker B: Well, yes, we are considering three options. Substrate is one and the components from substrate tendermint because it's the only proof of stake blockchain which is currently in operation. And we know from real life that it works. And then hot stuff from Facebook because it's optimized for the use case which we actually have. It has the low latency, it's tolerable to increasing of latency of the actors. But we actually assume that the validators are going to be powerful just as Facebook assumes it for their.
00:28:00.310 - 00:28:12.278, Speaker C: Would you with hot know you still need to solve networking and everything else, all the other packages. Is there a thing that packages hot stuff already maybe like something that I'm.
00:28:12.294 - 00:28:13.558, Speaker A: Not aware, like an SDK?
00:28:13.654 - 00:28:47.560, Speaker B: Yeah, I think they offer some stuff, but we can always also replace the components so we can go for lip to p. And we're building on the rust stack because we believe that rust is the most superior language for security applications as of today. And we prefer packages which have been built in rust and which actually have been tried in production because otherwise we are on the risk of doing a lot of debugging of course on ready code.
00:28:48.090 - 00:29:02.790, Speaker A: So one of the things that you are sort of billing ZK sync as is a very ux friendly or like it having a focus on Ux. What does that mean actually in this context?
00:29:02.870 - 00:29:46.070, Speaker B: That means first of all that whatever we design, we always have the end user interaction in mind. So we imagine how the users are going to actually use it in some specific circumstances and then we work our way back from there to see how we need to design the software API and the user interface to match these needs. So for example, you want, I don't know, you take the case where users want to buy something online, they just want to press one button, confirm and it's bought and they have immediate confirmation. It's really simple, but it's hard to build a system which will actually fulfill this promise.
00:29:46.410 - 00:30:06.522, Speaker A: But I think when I hear the word ux, I think like user experience, like user in this context is not like the person pressing the button, are they? I realize they might be using something that's built on zksync, but Cksync is not the final connection point to the user.
00:30:06.666 - 00:30:34.520, Speaker B: This is correct, but we're thinking from the end user perspective and then we think all through these layers. If we want this user experience for the end users, what API should we offer to the developers who can build this application? And what should be the SDK looking like? And if we have those APIs, what should be the consensus be looking like in order to be able to support them and so on. So we going all the way back step by step.
00:30:34.890 - 00:30:42.140, Speaker A: Do you also care about developer experience in this case though, because I've heard these sort of defined as slightly different.
00:30:42.750 - 00:31:17.560, Speaker B: Absolutely. We're very inspired by companies like Stripe and Twilio and a bunch of other Silicon Valley companies who have this thing that their stuff just works. As a developer you can rely on them, you just open the documentation and you know that you're going to be able to find whatever function you need. You're just going to try it out and it immediately will work. And this is our very important priority in our development lifecycle to make it like this, that we're going to be no bullshit company which offers stuff which just works.
00:31:18.250 - 00:31:53.578, Speaker C: I think you have a point in the split of UX and Devex might not be completely clear from a layer one or layer 1.5 perspective where is an end user really going to use this thing. But I think if I was building with Ux in mind in layer one, I would mean it to be like I'm building something so that someone else can build something with good ux. And if I'm building with devex in mind, then it's like so that someone else actually can build something with good ux.
00:31:53.754 - 00:31:55.234, Speaker A: The tools are there to do it.
00:31:55.272 - 00:31:59.362, Speaker C: That they are able to do that with reasonable time and experience.
00:31:59.496 - 00:32:09.830, Speaker A: And here it sounds like UX. Like the core UX benefit here is speed, just the ability to very quickly transact and know that things are working correctly.
00:32:11.130 - 00:32:16.710, Speaker B: This is correct. Additionally to this, we want expressivity.
00:32:17.470 - 00:32:18.438, Speaker A: Expressivity.
00:32:18.534 - 00:32:36.778, Speaker B: Well, this is more developer experience stuff, but we want developers to be able to build interesting applications which users actually want. So it's not enough to just have transfers. You want smart contracts and you want them in some, you want interaction between the smart contracts.
00:32:36.794 - 00:32:47.390, Speaker A: And so actually that leads to another question then. If you build on Zk sync, do you build fully on ZK sync or do you build on ethereum? Where do you deploy a smart contract?
00:32:47.470 - 00:32:48.914, Speaker B: You would deploy it on Zk sync there.
00:32:48.952 - 00:32:51.954, Speaker A: Oh really? Okay. It's a smart contract platform at the same time.
00:32:51.992 - 00:32:52.980, Speaker B: Yes, of course.
00:32:54.470 - 00:32:56.982, Speaker A: For some reason that didn't occur to me before this.
00:32:57.116 - 00:33:26.330, Speaker B: Okay, well, that's the functionality we're still working on, but we're going to release the framework for writing zero knowledge proofs, which will eventually be supporting smart contracts this month. It's called sync framework, and it's a rust like language for defining zero knowledge compatible programs. It's essentially a subset of rust.
00:33:26.690 - 00:33:30.906, Speaker C: I guess the question is, what does that compile to? Does it compile to r one cs?
00:33:31.018 - 00:33:38.114, Speaker B: No, it will compile to a virtual machine, which then can produce r one cs, and then which can also interpret the code.
00:33:38.232 - 00:33:38.900, Speaker C: Interesting.
00:33:39.830 - 00:34:10.358, Speaker B: So our goal here was to build some programming environment which allows anybody to create zero knowledge compatible programs without having to understand the nuances of r one Cs programming, and so that they can build these programs in an efficient way without having to do a lot of jungling and dealing with branches and some complicated stuff which r one cs limitations impose on you.
00:34:10.464 - 00:34:30.638, Speaker A: So before we move on to talking a little bit more about the actual snark construction, I had sort of one last question about Cksync, and that is, is there a reintroduction of a plasma like economic game or economic mechanism in the writing onto the chain?
00:34:30.814 - 00:35:15.694, Speaker B: So we don't need any challenge games, because we are not relying on fraud proofs. In ZK sync being based on ZK roll up architecture, we have proofs of validity. So every transaction included in the block is being verified by layer one. The only exception to this rule is the transactions in the fly, which have not yet been included, but we want them to be instantly confirmed to the users. So for this we use so called transaction receipts, where the operators just make a promise. I promise to include this transaction on the next block. So this promise is of course less strong than the validity proof.
00:35:15.694 - 00:36:05.970, Speaker B: Once we have the transaction included in the block and the zero knowledge proofs generated, which takes approximately ten minutes, or it will probably go down with the better provers and better proving hardware. But for now it's approximately ten minutes. So during this time you can use your transaction receipt to rely on it and say, okay, I trust the validators to include it, and if they don't, then I have to go on the main chain and challenge them and claim my compensation, or at least claim damage to them and slash their security deposit. But of course it only works for smaller amounts. If you're about to receive $1 million, you're probably just going to wait ten minutes, still faster than bitcoin, and then you can be completely sure with guarantees backed by the layer one itself.
00:36:06.040 - 00:36:34.890, Speaker C: So tying into the discussion about smart contracts, I think next natural question there is. Well, we know if we have an r one CS circuit that gets compiled into a ZKP that usually, depending on the snark, needs a trusted setup. So the question is, does then every smart contract need its own trusted setup, or do you have some sort of universal setup in your snarks?
00:36:35.230 - 00:37:36.160, Speaker B: Well, we have several different contracts which emerged last year, some with universal snarks, with universal trusted setup, which just needs to be done once for all circuits, some others which do not require trusted setup at all. So the example of universal snark is plonk and Marlin. Examples of completely trustless setup is starks and redshift, which we created last year. The trade offs are always in the context of proof sizes. So the trustless versions tend to be much larger in proof sizes than the ones which have trusted setup, which essentially compresses information in some way. So we rely on this external common reference string as a sort of dictionary and information. Theoretically we can somehow outsource information over there.
00:37:36.690 - 00:37:46.814, Speaker A: You just mentioned this term redshift. This is your start, actually, your snark. What is it? Is it a snark or a stark? You just kind of put it in the same category.
00:37:46.862 - 00:38:39.838, Speaker B: It has been a discussion on terminology between the great minds in the space. So I'm going to follow the Ellie Benson's approach and say, okay, snark is succinct, non interactive argument of knowledge, which is a greater term which encompasses all of the systems. A succinct means that it's exponentially less computation to verify the proof than to make the proof, or even to naively compute the computation. Starks are succeed transparent arguments of knowledge which could strictly speaking apply to redshift as well, because that's what it is, it's transparent. But starks are traditionally being reserved for fry based starks, something starkware is building. So we probably are better off just calling a redshift a transparent snark.
00:38:39.934 - 00:38:40.580, Speaker A: Amazing.
00:38:41.910 - 00:38:50.230, Speaker C: It seems to be the trend in other things as well. We were talking to fractal and they also called their thing a snark, not a stark, despite being transparent.
00:38:51.130 - 00:38:57.494, Speaker A: So then what is redshift and where does it come from? What do you take from to build this?
00:38:57.692 - 00:39:26.126, Speaker B: So redshift is a r one cs by snark. See, it's a snark which takes r one cs written circuit or program as input, and can generate proofs in a transparent way. It is derived from proof systems which are based on polynomial commitments, where we replace the polynomial commitments from pairing based constructs with the one which is based on Fry.
00:39:26.318 - 00:39:27.982, Speaker A: Wait, you do use fry?
00:39:28.126 - 00:39:29.780, Speaker B: We do use fry in the.
00:39:30.150 - 00:39:36.580, Speaker A: Okay, but then wouldn't that then make it a stark according to your definition just before.
00:39:37.210 - 00:39:44.518, Speaker B: Well, Starks is just a very specific name for a very succinct construct which is not r one cs based.
00:39:44.604 - 00:39:45.094, Speaker A: I see.
00:39:45.132 - 00:40:35.974, Speaker B: And we want to avoid confusion for people who heard of those terms and have certain understanding of starks. Redshift uses r one cs based arithmetization, whereas starks have a very specific approach to arithmetization, for which we don't have yet many convenient tools, and they are still being developed, which are potentially much more powerful. But it's just very difficult to build them as of right now and will be probably too difficult to build them in the coming years. Whereas for Redshift, we can just take any existing r one CS circuits and gadget libraries and construct proofs, or import existing circuits and construct proofs for that?
00:40:36.012 - 00:40:46.650, Speaker A: You just sort of mentioned before a few different snark constructions, like plonk and Marlin. Are those also ancestors of what you're doing, or is your ancestor an earlier snark?
00:40:46.990 - 00:40:53.402, Speaker B: So redshift is a transformation. We can take any proof system which is based on polynomial commitments.
00:40:53.466 - 00:40:54.094, Speaker A: Oh, I see. Okay.
00:40:54.132 - 00:40:59.440, Speaker B: Such as plonk or Marlin, and make a transparent version out of it.
00:41:00.210 - 00:41:09.442, Speaker A: I'm trying to picture if it's dealing with a comparable problem that, like supersonics dealt with, but maybe in a different way.
00:41:09.576 - 00:41:40.902, Speaker B: Supersonic is essentially the same idea where the polynomial commitment from pairings is replaced by polynomial commitment on class groups. So it has a different set of trade offs. Our estimate is that supersonic is going to be difficult to use in the context of Ethereum blockchain, for example, because it's going to be more expensive to verify the proofs on Ethereum.
00:41:40.966 - 00:42:03.570, Speaker A: I see. So it sort of falls into the same category. But you built redshift specifically for this use case, which is building on Ethereum. You're always using Ethereum one x as your main chain, and so everything has to sort of. It's a baseline. Yes. Okay, so this is a new construction that you've made.
00:42:03.570 - 00:42:12.390, Speaker A: You've specked out, I guess. Are you for sure going to use it, or is this like, you wanted to put this out there, and it might be one of the things that you use.
00:42:12.540 - 00:42:43.674, Speaker B: We are certain we're going to use it, and there is a reason for this, namely, since we are not relying on pairings it's much easier for us to create recursive proofs, so we can embed verification of other circuits into a compound circuit for a block. So, for example, we can verify that each of our thousand transactions executed some smart contract correctly.
00:42:43.802 - 00:43:16.380, Speaker A: This is is. I know in the episode that we did with Isaac, I actually asked the question, and I realized in the edit that I don't know if it was totally understood. I had asked about, like, batching versus recursion, but then I realized that batching is also something you can do in a snark. And by batching, I meant batching transactions and not batching. I actually don't know what you batch in a snark, but you batch something else. It's like a technique. So there was these two things.
00:43:16.380 - 00:43:26.490, Speaker A: And what I'm wondering is, could you potentially then do both? You could do this, like batching in a recursion way, but also batching transactions.
00:43:26.570 - 00:44:03.690, Speaker B: This is actually a very good question, and we are doing both. So, on the top level, we have the batching, where we have a lot of transactions which are put inside one snark, which means that the snark just grows in size. We have more and more and more constraints. We have thousand times more constraints than is required for just one transaction. But then recursion means that on every single piece of it, we can verify something more which goes underneath. So, yeah, we're using both approaches. Right? We batch verify many transactions.
00:44:04.350 - 00:44:11.530, Speaker A: I did expect to go, I didn't realize that that was a property of redshift, that it also enabled recursion.
00:44:11.610 - 00:44:13.402, Speaker B: It just makes recursion more efficient.
00:44:13.466 - 00:44:13.790, Speaker A: Okay.
00:44:13.860 - 00:44:52.860, Speaker B: Because you can still do it with pairing based constructs like plonk or GRA 16 even. But it just requires this very specific loops of elliptic curves, which can be computed efficiently, and we only know a few of them, and they are much less efficient than the curves, which are fast, which are being used in current version of roll ups. That makes everything just much more slower and more expensive. Whereas with redshift, we can have infinite recursion at just the normal cost.
00:44:53.310 - 00:44:58.490, Speaker C: How does it compare to fractal does sound very similar. Recursive, transparent.
00:44:59.150 - 00:45:01.642, Speaker A: You can fit in plonk or marlin.
00:45:01.786 - 00:45:44.982, Speaker B: The difference to redshift is we can have a heterogeneous circuit, which does different things and then still verifies efficiently. So to be able to say which is going to be more efficient for structured circuits, we would need to do the benchmarks. Fractal might be somewhat faster, but we just have to verify this but for us, it's important to have the ability to construct heterogeneous circuits at least as a second level of recursion, because we want people to be able to write programs or smart contracts which perform different things, not necessarily repetition of the same operation.
00:45:45.046 - 00:46:04.526, Speaker C: Many times you already mentioned the proof computation time, and that it's roughly ten minutes in the current setting. But what are the other properties of this system? What's the proof size? What's the verification time? What does this actually mean in terms of throughput for the system?
00:46:04.708 - 00:46:51.678, Speaker B: So I have to make a short correction. Ten minutes is the time since you submit a transaction until it's been included in Ethereum block. So the actual proving time is going to be much less okay. And we expect, with the growing efficiency of the provers and potentially using some GPU or other hardware acceleration, we expect these times to go well under 1 minute eventually, yeah. So for now, the proof sizes of redshift are in the scale of some kilobytes. The work is still going on, so you can find some preliminary numbers in the paper on Eprint, but we are working hardly on optimizing this as well. Cool.
00:46:51.764 - 00:47:27.594, Speaker C: So another thing that I'm curious about is using snarks. It sounds like you're only using snarks as a sort of performance thing. It's a scaling solution, not necessarily a privacy solution. But what are the privacy preserving properties of this system? If you publish a smart contract, is everyone aware of what that smart contract is? Of what functions in that contract people are calling is everything transparent? Or what are the privacy preserving properties, if any?
00:47:27.712 - 00:48:14.038, Speaker B: So for now, we're focusing completely on the scalability aspect of Zksync, because it's much more important to get a lot of people to use it first before you can benefit from any privacy preserving properties. With privacy, you always want huge anonymity set. If your anonymity set is, as Vitalik Butarian puts it, if your anonymity set is medium, you actually have a small anonymity set. And if your anonymity set is small, you actually have anonymity set of one. So you actually want a lot of people first to be on the platform. Then you can add some privacy in order to make it meaningful. It also needs a lot more of computational resources.
00:48:14.038 - 00:48:50.114, Speaker B: And this is the second reason why we want to focus on scalability first, to optimize approvers, to make sure that things are really, really fast so that the cost is negligible. And then we can easily increase it by a factor of ten. And nobody's going to notice. But this is a very essential part of the vision of ZK sync to eventually offer privacy. And it's going to be going very gradually. So we will first add privacy for payments, not for smart contracts, which is much more difficult. Then further research is required to make smart contracts privacy preserving.
00:48:50.114 - 00:49:37.634, Speaker B: There are approaches like Zegsi, but they require a very different way of thinking about smart contracts from the developers, which is going to create another. It's going to just raise the barrier for entry for developers slightly higher, which we want to avoid in the beginning. But eventually we believe in privacy owned by default in Zksync, because anything else introduces a lot of friction for end users. And our goal is from the beginning to be a very user centric and UX centric platform. So things must be very simple. You don't want your private transactions to be a lot more complicated and cumbersome than normal transactions. And we know that some friction will have to be introduced.
00:49:37.634 - 00:49:55.850, Speaker B: But if you have different layers, so for example, if you have to use some mixers additionally to your normal operation, this is going to be very inconvenient and lowers your anonymity set further down. So we think that it has to be part of the basic features.
00:49:56.190 - 00:50:15.346, Speaker A: I mean, we talked with Aztec about the fact that they were planning on at least exploring this idea of building private smart contracts, offering sort of function privacy in the same way that sexy would. But in a smart contract construct. In your case, could you use that?
00:50:15.448 - 00:51:08.130, Speaker B: Absolutely. So I think that with smart contracts being separate entities, essentially separate, different Dapps using different types of smart contracts, we can perfectly combine them. We can have public smart contracts for things like DeFi, for example, where you need some transparency, and transparency is more important. And you can have smart contracts from something like what Artstech is building for different things, for users who want to make private arrangements within themselves or engage in some dark trading and so on, I think this is going to be much less of an issue. It's just the basic privacy for your personal finance has to be preserved at the platform layer. Everything else can be layer three in our case.
00:51:08.200 - 00:51:26.950, Speaker A: I got one question from a listener, Mikara, also known as bad crypto bitch on Twitter, and she asked the question, how much TPS does Zksync provide in both a test environment and production ready or close to it environment?
00:51:27.530 - 00:52:11.414, Speaker B: Well, we had a test last year on Ethereum in production, which produced 100 tps, and it was limited by the amount of funds we were ready to waste on this test because it just was very expensive. In our case, the bottleneck is Ethereum gas fees, not the zero knowledge proof production or the full node verification. So we had tests where we run very expensive, very large circuits, and they clearly show that we can do like up to 10,000 transactions per second. But we are limited by what we can publish on Ethereum as a part of roll up.
00:52:11.452 - 00:52:17.010, Speaker A: Does that mean like in a test environment you actually can get more because you're not necessarily working directly with the main chain?
00:52:17.090 - 00:52:57.406, Speaker B: We can get more if we increase the gas block limit of ethereum. So because of this, we can exactly tell what our throughput limit is going to be. So for simple transfers, it's slightly above 2000 transactions per second. If we used the entire Ethereum blockchain, obviously there are some other transactions on ethereum as well. So probably half of this capacity is realistic. But even if we get to hundreds of transactions per second, it's going to be comparable to levels of Paypal. So PayPal handles or handled last year or something like 200 or 300 transactions per second.
00:52:57.406 - 00:53:01.110, Speaker B: So if we get to those levels, we're going to be in a very good position.
00:53:01.180 - 00:53:22.174, Speaker A: Already, so far, everything we've been talking about has been like ETH one x and building on top of that. What does ETH two, or, I don't know, these other kind of sharded or multichain paradigms coming out. What does that mean for what you're building?
00:53:22.372 - 00:53:39.540, Speaker B: It actually doesn't change a single bit. The only thing might be different is that the gas cost will go down. Maybe not. We'll have to see. So from the architectural standpoint, everything remains absolutely the same.
00:53:40.870 - 00:53:42.098, Speaker A: This is eth two.
00:53:42.184 - 00:53:43.570, Speaker B: This is ETH two, yes.
00:53:43.720 - 00:54:02.474, Speaker A: What about. Are you also looking at building? Will Zk sync also be usable on Cosmos, or with a Cosmos zone, or with a polkadot pair chain, or with, I don't know what the other words are for the other protocols out there, these are the ones I talk about the most.
00:54:02.592 - 00:54:44.738, Speaker B: It's perfectly possible to build ZK sync on other blockchains rather than Ethereum, and we're actually looking into them. We just want to see the concrete use case first. We're focused on building something which can be used immediately today and launching as soon as possible. And once we see the demand on other chains, we will totally support them. Because the cost of switching the layer one chain is relatively low, we just need to rewrite the smart contract part. But we don't have to change anything in the protocol part, in the nodes, apart from the interaction with layer one, it's an easy switch.
00:54:44.834 - 00:54:47.302, Speaker A: It would never be a shard, though, would it?
00:54:47.436 - 00:55:11.902, Speaker B: In itself, Ethereum 2.0 has something called execution environments, which sounds rather similar to what we are doing because it's a separate execution environment for different type of transactions. But we have to see the final designs, and I would rather abstain from commanding until we have something which actually can be tested and we see and understand what it is.
00:55:11.956 - 00:55:12.462, Speaker A: Got it?
00:55:12.516 - 00:55:12.686, Speaker B: Yeah.
00:55:12.708 - 00:56:01.742, Speaker C: It's become kind of questionable what a shard in Ethereum even is, because now they're talking about these execution environments. They live on the. They live across shards, it lives on the beacon chain, but then they're executed in some weird, like, spiraling fashion and autobalanced, maybe. And it's kind of hard to even define what a shard is at that point, but I think it's in a sharded system. I think it's perfectly reasonable to think that there is a shard or like the equivalent of the capacity of one shard being taken up by a roll up system of some sort. And that seems like the perfect fit, actually, that if you want really fast transactions or this kind of structure, you go to this shard and you do that there.
00:56:01.796 - 00:56:07.054, Speaker A: So I think we've reached the end of the interview. I'm out of questions. I don't know about if you have any questions.
00:56:07.252 - 00:56:08.446, Speaker C: Not really, no.
00:56:08.548 - 00:56:13.918, Speaker A: I think we've covered a lot of ground. So thank you so much, Alex, for coming back on the show.
00:56:14.084 - 00:56:15.602, Speaker B: Thank you, guys. It was pleasure.
00:56:15.746 - 00:56:16.534, Speaker C: Thank you very much.
00:56:16.572 - 00:56:18.738, Speaker A: And to our listeners, thanks for listening.
00:56:18.834 - 00:56:19.490, Speaker C: Thanks for listening.

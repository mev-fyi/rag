00:00:06.330 - 00:01:10.866, Speaker A: Welcome to Zero Knowledge, a podcast where we explore the latest in blockchain technology and the decentralized web. The show is hosted by me, Anna, and me, Frederick. This week I speak with Ellie Ben Sasson about the latest at Starkware Industries, the booming zero knowledge research space, and the origin of new mathematical ideas. Before we start, I want to let you know about an event that we are going to be hosting next month. On October 26, we're hosting the fourth edition of the Zero Knowledge Summit. This is happening right before the San Francisco blockchain week and about two weeks after Devcon, we're going to be bringing together the latest research and ideas around zero knowledge proofs, ZK snarks, universal trusted setups, and all the new research that's coming out about how to make that more versatile and efficient. We're going to be talking about starks, bulletproofs and way more.
00:01:10.866 - 00:01:57.966, Speaker A: In this edition we will be looking at zero knowledge for privacy, zero knowledge for scalability, as well as scratching the surface of an emerging use case that is zero knowledge proofs for interoperability. Applications to attend are currently open, so please apply today. I will add the link in our show notes. Just note there are limited spots and the event is highly technical. We will be prioritizing the researchers and devs already working in the space, but get your application in early for a better chance of getting a ticket if you don't get a spot, don't worry, we will be filming it and sharing it on our YouTube channel, which is a thing which you may not know, but yeah, check out our YouTube channel. I'll also add the link to that in our show notes. You can keep an eye on our Twitter account at zero Knowledge FM for more details about the event, or join in the conversation with our community on Telegram.
00:01:57.966 - 00:02:15.074, Speaker A: So very much looking forward to this edition. Hope to see you there. So now here's our interview with Eli Benzeson from Starkware. So today I'm sitting down with Ellie Benzeson from Starkware. Welcome to the show again, Ellie.
00:02:15.122 - 00:02:17.174, Speaker B: Thank you. Thank you for having me again.
00:02:17.292 - 00:02:35.950, Speaker A: So this is the second time that Ellie is on the show. We did an episode in January where we actually talked about Starkware, Starks, and about Ellie's background and how he got into it. So this is a bit of a catch up, I guess, maybe to start off what's happened since we last spoke.
00:02:36.930 - 00:03:21.866, Speaker B: Wow. So a lot has happened. Starquare now has a product that we're very happy with, which is going to be a scalability engine for trading and for settlement we'll be launching it hopefully early 2020 at the latest. We're also advancing on our Stark friendly hash selection, which is a project we promised the Ethereum foundation to lead. And there is so much going on in our team in terms of science and engineering, a lot of fun.
00:03:21.968 - 00:03:36.514, Speaker A: So this interview is coming off the back of the Starkware sessions and the Starks 101 workshop here in Tel Aviv. I want to talk maybe just to kick off about that. So what were those and why did you decide to do an event like that?
00:03:36.712 - 00:04:37.058, Speaker B: Yeah, so we had two events. The first one was Stark 101. It was a hands on workshop where folks came in, sat with a Jupyter notebook that our team created, led by one of our engineers, Shield, and they came out with a full blown stark prover for a very specific computation. The reason we did this is we want to educate about the beauty of starks. And this was aimed at developers and programmers. The following day we held Starkwear sessions where there were two main themes. The first one was how do ZK Starks fit in the larger ecosystem of proof systems and cryptography and blockchains? And the second theme was applications.
00:04:37.058 - 00:04:49.446, Speaker B: How does Starkware and its products fit into the larger ecosystem of blockchains? And what is the value proposition of our system and others?
00:04:49.628 - 00:05:05.838, Speaker A: All right, so let's talk about the updates from Starquare. You mentioned a few of them, but let's go a little deeper into them. The first one, as I understand, is the scalability, the Dex work that you've done, have you actually released a Dex of your own?
00:05:05.924 - 00:06:30.330, Speaker B: We have not released a decks of our own and we view ourselves more as technology providers for back end of existing exchanges, both centralized exchanges and decentralized ones. So we would like to provide engines that at the first stage do things like settlement at scale. Earlier this year, around July, we announced and released our Alpha Starkdex. This was a joint project with Zero X in which we displayed a scaling up of settling 1000 trades in each batch at a sustained rate of ten tpS, ten transactions per second. And now what we're doing, and this will be released on main net by early 2020, is we are building settlement engines at scale for non custodial trading that will be backend engines used by custodial exchanges that want to enlarge their liquidity pool and offer it also to traders that don't want to hand custody over to them. So this is the next step along that project of Stark Exchange. We're working already with multiple exchanges.
00:06:30.330 - 00:06:44.666, Speaker B: Famously, Coinbase has announced already that they're working with us on this and allowing their liquidity pool also to non custodial traders. So that's the news on stark exchange.
00:06:44.778 - 00:06:57.710, Speaker A: Okay, let's talk then next about the Ethereum grant and the hash function work that you're doing. And it's interesting, when we had you on before, I know that we mentioned the grant, but I don't know that we actually went into what was in the grant.
00:06:57.790 - 00:06:58.082, Speaker B: Right.
00:06:58.136 - 00:06:59.870, Speaker A: And so that might be good to clarify.
00:06:59.950 - 00:07:40.654, Speaker B: Okay. Yeah. So the Ethereum foundation granted us a sizable grant at the time. It was the largest that they granted. The goal of this grant was to provide the Ethereum foundation and its developer ecosystem with very efficient provers and verifiers for starks for repeated invocations of a hash function. And one of the main goals of this grant was to recommend to the Ethereum Foundation a stark friendly hash. At first we thought that we'll just scan the list of existing hash functions and select one of them.
00:07:40.654 - 00:08:38.170, Speaker B: But quickly we realized that there's a better way that would be better for the community, which is to actually solicit new constructions of hash functions that optimize the parameters needed for them to be stark friendly. And by now, we have already two new suggestions that can be added to one pre existing one, which is Mimsi. And we funded, again with funds from the grant that we received. We funded both of these efforts. We also funded a crypt analytic effort to understand these new constructions from the point of view of algebraic crypt analysis and Grebner basis algorithms, which are very relevant and important to these new constructions. And we're progressing along. So the next main step is going to be we're convening a committee of experts in symmetric crypto analysis led by Professor Anne Canto.
00:08:38.170 - 00:09:00.090, Speaker B: It will be held in Paris mid November. This committee will examine the various constructions and recommend by early 2020, the one stark friendly hash. And then we have, Starker has roughly half a year to code it up, write an efficient prover and verifier, run audits on it, and then release the code to the Ethereum foundation.
00:09:00.830 - 00:09:12.160, Speaker A: When doing this, kind of like finding a new hash, would that automatically work within the current Ethereum construction, or would you need to do something to actually enable that?
00:09:13.650 - 00:09:49.322, Speaker B: Some of the hash constructions would work pretty well already on the existing Ethereum framework. And for instance, we actually are running now a stark friendly hash challenge where there are a bunch of smart contracts that pay out ether to those who find a collision in some of these candidates. So, by the way, just as it was very funny that exactly as the session on the stark friendly hash function selection was going on, we were alerted that the very first collision in one of these challenges was found.
00:09:49.376 - 00:09:49.978, Speaker A: Oh cool.
00:09:50.064 - 00:10:41.506, Speaker B: And one ether will be handed out to the solver or the first finder of this collision. So the smart contracts that we wrote for this competition are already existing as smart contracts on Ethereum. Now, there are other constructions, especially those that are based on binary fields, that are much harder to implement over Ethereum right now. But I'm guessing that the Ethereum foundation, once there is a selected stark friendly hash, the Ethereum foundation probably will want to consider doing some consensus change to allow a pre compile for it, or add it to the existing hashes that it already allows, like ketchup. But this is know not part of our project. This is up to the Ethereum foundation to decide afterwards.
00:10:41.698 - 00:10:47.638, Speaker A: How do you define what a like what are you looking for? How do you choose between hash functions?
00:10:47.814 - 00:11:40.982, Speaker B: That's a great question. As always, the most important aspect would of course be security, because if the hash function isn't really collision resistant or doesn't look suitorandom enough, then it's no use. But having said that, there are some very specific algebraic parameters that you would like to minimize if you're interested in making it stark friendly. And those parameters, if I had to summarize them, they would be about making so suppose you want to implement your hash using an arithmetic circuit. An arithmetic circuit is a sequence of operations that allows only things like additions, multiplications, divisions. What you want to do is minimize the number of operations that take the input to the output. Right? A hash takes an input and then produces an output.
00:11:40.982 - 00:12:21.082, Speaker B: So if you have two hash functions and one of them has 1000 operations, and the other one has 100 operations, the second one would be more stark friendly than the first. It's slightly more complicated than that, but this is roughly the idea of it. The problem is that as you decrease the number of arithmetic operations, you're also maybe compromising security, because maybe it's just too simple a function. For instance, if you just take the two inputs and multiply them, then that's not a good hash function. You probably want to do a whole bunch of operations. So that's the tension between maintaining security and minimizing the number of operations needed to compute it.
00:12:21.136 - 00:12:24.118, Speaker A: When you minimize the number of operations, does it make it faster?
00:12:24.214 - 00:12:57.170, Speaker B: Yes, it makes it faster, definitely. It makes proving statements about it more efficient, which is one of the main goals of being stark friendly. At the same time, it makes it more susceptible to all kinds of attacks, and the most potent ones seem to be the ones that are based on algebraic geometry and things called Grebner basis and algebraic crypt analysis. Those are the ones that are new and most threatening to this kind of minimization effort.
00:12:57.250 - 00:13:08.390, Speaker A: I'm curious, where is most of the hash function research happening? Like, where is that? Is it in other fields? Is it in the field of cryptography in various universities?
00:13:08.890 - 00:13:37.838, Speaker B: That's a great question, and I learned a lot as I was going into this project, because my upbringing is not as one of these experts. I come from a very different field of computer science. So within cryptography, so I learned there's a sub branch that would be described as symmetric cryptography, as opposed to asymmetric cryptography, public key cryptography, RSA, diffie, Helma, and that sort of stuff, which is.
00:13:37.844 - 00:13:41.038, Speaker A: Very algebraic and number theoretic, that lives in the asymmetric.
00:13:41.134 - 00:14:21.038, Speaker B: Right. That's the asymmetric world. A lot of number theory, a lot of elliptic curves, that kind of stuff. Now, within the symmetric key cryptography, where you have things like AES and you have the hashes and a bunch of digital signatures as well, post quantum ones and so on, there's a very vibrant community, I should say. I realized that I learned that most of it is in western Europe. So Paris, Belgium, Germany, Luxembourg, those places. It's a very hot topic, and a lot of the experts reside there.
00:14:21.124 - 00:14:25.410, Speaker A: And these are in the cryptography departments of universities, or are they in industry.
00:14:27.270 - 00:14:38.310, Speaker B: More so in academia, but also some of them consult or go back and forth or also are in industry.
00:14:39.050 - 00:14:55.158, Speaker A: I'm just wondering, the call out to an open source community looking for hashes, are you also pinging the people in the university, or are they already aware of this? Are they already kind of participating in a lot of these ecosystems?
00:14:55.334 - 00:15:47.580, Speaker B: The people we reached out to are the kinds that are already doing this for a living for a very long time. So one of the first teams, I guess the very first team we contracted is the Kosic team at Lloyven in Belgium that is led by Vincent Raymond, who is actually one of the co inventors of the AES symmetric cipher. And his team is. So in particular, Siemen de Houghe and Tome Rashur have led this effort of suggesting one of the. And this whole community of researchers, they engage often in a lot of competitions about selecting and building new hash functions and new ciphers. I learned that that's a lot of what they do, and so this is not new to them. Cool work.
00:15:49.890 - 00:16:00.160, Speaker A: Who do they usually work with. They're not exclusively working with blockchain stuff, I imagine. What world is that?
00:16:00.610 - 00:16:51.278, Speaker B: I think, and I may be wrong here, I hope my friend symmetric cryptographers will forgive me if I'm making huge errors here, but I think that often, first of all, a lot of industries often need various, let's say, low consumption, new hash functions or signature schemes or ciphers. There are a lot of government solicitations coming out from NIST and various other international standardization bodies. So I think a lot of those are routinely interacting with them. And you could say that the Ethereum foundation could be thought also as one such, or it will be. I mean, any blockchain governance is also a standardization body for this particular blockchain. So it's kind of in the same ballpark of the stuff they've been doing already.
00:16:51.444 - 00:17:03.518, Speaker A: Cool. Yeah. So going back to the actual project, because this competition, this is about finding a collision. So almost like breaking a hash.
00:17:03.614 - 00:17:03.970, Speaker B: Yes.
00:17:04.040 - 00:17:10.710, Speaker A: But the other side is this evaluation. How far are you? Do you have a favorite?
00:17:11.210 - 00:17:39.322, Speaker B: No, I don't have a favorite. We at Starcore want to be agnostic. We hope that it will be secure. That's very important. The worst thing that could happen is if something is selected and then actually a lot of stuff is built using it and trusting its security, and then a lot of economic value is already sort of hinged to it. And then someone says, oops, here's a collision or here's a bug. That would be very unfortunate.
00:17:39.322 - 00:17:46.430, Speaker B: So it's very important that we remain agnostic as to who wins.
00:17:46.950 - 00:17:55.038, Speaker A: But will there be one hash function at the end of this? That is, there will be at least one, definitely, but there may be a basket of hash functions.
00:17:55.134 - 00:18:43.570, Speaker B: Yeah, I'm guessing that what will happen is that the experts, when they convene in mid November, we're sort of sit and really try to kick the tires of these things and sort of pull and push and try all kinds of attacks. And it's a bit of an art, like understanding what works or what makes you comfortable or less. And it's an art I only observe from the outside. It's not something that I practice in or have intuition about, which is why others are going to be selecting it. So I think they'll end up by saying, I mean, there could be a few outcomes. They could come out and say, look, all of them look pretty safe to us. So then it's basically up to Starkword to find which one is the most efficient in terms of its stark complexity.
00:18:43.570 - 00:18:56.040, Speaker B: It could also be that they will come out and say, look, here's one or two that we think are far safer based on a whole variety of reasons, and then we'll probably build those.
00:18:56.490 - 00:18:59.058, Speaker A: So what's next for Starkware?
00:18:59.154 - 00:19:57.274, Speaker B: So Starquare is a bit of a unique creature in blockchain space. We are a for profit company. Nevertheless, what we deal with can be viewed as part of something that could be infrastructure and there are not too many other companies like us. So we're constantly thinking about what next. So right now we're very, very happy with our first business model, which is prover as a service, which means we're releasing a verifier on chain that verifies the evolution of a very scalable system. And we keep the prover, the super efficient provers, closed sourced and run a service that we offer to exchanges that work with us. We're very happy with exploring this business model and we hope to get our customers using it early 2020.
00:19:57.274 - 00:21:10.274, Speaker B: Beyond that, immediate steps are going to be to validate this business model, to enlarge the capabilities of the stark exchange system, to sign up more customers. So those of you listening out there, if you're running an exchange and you expect significant volume in non custodial trading, please reach us out to us. We also want to enlarge the same proverbs mechanism to things like payment systems. We can scale up to tens of thousands of payments being verified within a single Ethereum block today and we'd very much like to work with payment providers and payment processors to offer this functionality, also under the proverbs of service model. Later on, we're exploring how to engage the developer community a bit more and offer what we call b so business to developer tools so that we can have a more vibrant community of developers that use starks and build their own statements and systems. And I guess that's pretty much what's right now on our mind.
00:21:10.392 - 00:21:31.514, Speaker A: What kind of future? Like, the company you just sort of mentioned, it's a for profit company. What do you imagine it evolving into? Like, have you looked at a lot of those companies that work around open source? Do you see yourself becoming like, I don't know, like a service provider for an open source protocol? How do you envision this company?
00:21:31.712 - 00:22:15.490, Speaker B: Wow, that's a really. Yeah. Making predictions is very hard, especially concerning the future. Let's see, what can I comfortably say and not eat my hat in a few years. We very much believe that starks are going to be used in a whole lot of places, in blockchains first and then also in the financial ecosystem at large. In the end, and we very much believe and will strive to be one of the main providers of this technology. Now, the way we might end up, let's say, in five years time or maybe ten years time, we could be something like this is very long range.
00:22:15.490 - 00:23:35.680, Speaker B: We could end up being something like Nvidia or Intel, where we sell hardware and we sort of release a whole lot of tools that make working with this hardware very efficient. That's one long term option. We could be the analog of some cloud provider or service provider that basically runs these big servers for super efficient proving and also releases and supports a vibrant open source community that develops other things. And those comfortable building their own proving systems and so on will work without us. That's a second option, a third option. And this sort of ties into what blockchain governance might decide would be to partner somehow with existing blockchains to offer this infrastructure at a more lower level in return for some form of, I'd say at least limited exclusivity or something. So this model that is used in infrastructure building, called the bot model build, operate, transfer, which is often used when governments and countries build bridges or other things, comes to mind.
00:23:35.680 - 00:24:37.074, Speaker B: This is not only about Starcore, this is in general about how do blockchains want to foster a thriving private sector that builds infrastructure. So think about wallets. I would like to see blockchains coming to wallet providers and saying, let's now run an auction for, we need three wallet providers that will be sort of open sourced over the next five years. And the winners, based on price and quality and whatnot, will be given sort of a license to offer their software, and they will get maybe rewarded as part of the mining reward of the process. And after this period, the governance will find a new system or run a new auction. I think this would benefit the ecosystem. So that's another option that maybe we become part of the infrastructure layer in some place or other.
00:24:37.192 - 00:24:59.580, Speaker A: Okay, so now what I'd really like to touch on is something you brought up in your presentation at starkware sessions. And that was about sort of the, we're all noticing this, but this explosion of new papers, new protocol ideas, kind of new angles to solve some of the problems that zero knowledge proofs are trying to solve. What do you make of this?
00:25:00.370 - 00:26:01.482, Speaker B: So I think this is great news for the whole space. We called it the cambrian explosion of zkps because cambrian explosion was this era in geology or the history of the earth, where all of a sudden from this primordial soup of microbes. Within a very short period of time, a huge number of animals and plants emerged about half a billion years ago. So zkps and proof systems in general have been around theoretically since the 80s, mid eighty s, ever since this amazing discovery by Goldwasser and Mikhailian Rakov in 1985. And they've been the playground of theoretical cryptographers for a very long time. Starting a few years ago, about five or so, they started being deployed, and now there's this boom, there's big explosion.
00:26:01.546 - 00:26:05.134, Speaker A: And it's like in the last month it's gotten pretty wild.
00:26:05.262 - 00:26:14.386, Speaker B: Yeah, a lot of papers are coming out and announcements, so it's terrific. That's really great.
00:26:14.488 - 00:26:40.486, Speaker A: Being somebody who comes from academia, when you see a new paper, is it such that you release a paper into the world and then there are dedicated researchers who really know this stuff, who go into it? Or is it kind of like if it's popular enough, you're going to get some attention? I'm just wondering how that works, because obviously in universities it's really formalized.
00:26:40.678 - 00:27:30.422, Speaker B: Things have changed, even in universities. So when I started doing my research 25 years ago, even though the Internet was around, you didn't have archives where you can just upload papers. So the process was very structured, maybe too structured, meaning that the only way for your paper to be known was for it to be published in some journal or in a conference proceedings. For that to happen, you had to send it again, there were no archives just to upload it, so you had to send it. And then it went through a peer review process which was far from perfect in both false positive and false negative. So sometimes it admitted papers that were later found to have bugs in them. And the other way around, sometimes really amazing papers were not accepted.
00:27:30.422 - 00:27:38.026, Speaker B: For instance, a very famous example is that the very first paper on zero knowledge proofs was rejected, I think, from three conferences till it was published.
00:27:38.058 - 00:27:41.886, Speaker A: Was that the one in 1985? Is that why there's one in 1989?
00:27:41.988 - 00:28:44.066, Speaker B: Well, no, that's the sort of the journal version of it. But what happened? And this paper famously won a bunch of awards, including the Turing award and the Ghetto award. Again, the peer review process always had and always will have some false positives and false negatives. This was, let's say, up to 20 years ago. Now, with the abundance of online publishing venues, what happens is that you just need to write something up and you can immediately post it. An extreme case of this that everyone saw was clearly problematic is, of course, the notion of a white paper that comes along with an ICO of some shitcoin, right? So there might be even some mathematical formulas in it, but this is clearly not something you want to do anything with. So now, with this abundance of immediate publishing venues, there is of course, this.
00:28:44.066 - 00:28:49.234, Speaker B: On the one side, it's really, really good because you can immediately get your ideas out there.
00:28:49.272 - 00:28:53.714, Speaker A: For instance, more people, I guess, can get their ideas out there. You don't have to be part of some institution.
00:28:53.842 - 00:29:46.918, Speaker B: Even this guy, who no one heard about by the name of Satoshi Nakamoto can just publish a paper that happens to be pretty important. There is also, of course, the danger that comes with it, that you might just very quickly associate a lot of credibility to a paper that is in PDF format and you can print and maybe even has formulas in it. So I think it's a better way that we now can publish things immediately. And peer review was never perfect, but we should at the very least make sure that the T's are crossed and I's are dotted and have some experts look at papers and sort of opine on them and ensure that have another set of eyes on the ball so that things don't fall or break.
00:29:47.004 - 00:29:58.780, Speaker A: With so many new papers and ideas and acronyms coming at us, what is the danger? And maybe how should we navigate this?
00:30:00.050 - 00:31:29.590, Speaker B: I would say that, okay, the abundance of new ideas and new acronyms is actually very good, but we should proceed with caution. So I think what I mean, let science move at its pace, which should be as fast or as slow as science and scientists move. Let the scientists have enough time to sort of cross the t's, dot the I's, feel comfortable with what they're publishing. Let the scientific community have its time to look at things and peer review it and evaluate it, and proceed with caution, especially if you want to. We're all eager to have the latest and greatest technology at our disposal when it comes to things that are based on cryptography, an advanced one at that. You really have to sort of balance that with the desire to future proof your system, and not just be out there as quickly as possible, but be sure that you are preserving your customers or your users assets for the longest possible time in the safest possible way.
00:31:29.660 - 00:31:37.290, Speaker A: It sounds like it comes down to trust. It's the long term trust of the system that you should be aiming for and not first market.
00:31:37.440 - 00:32:05.380, Speaker B: Yes, the long term trust, the soundness of the foundations. We should always remember we're building an infrastructure that will have trillions of dollars of value flowing on it. It's far more important to be sure that the foundations are solid than to make it as fast as possible or have it out there as fast as possible.
00:32:05.990 - 00:32:42.590, Speaker A: Cool. So I'm really glad that we talked about that because we are experiencing right at this moment an explosion as mentioned. So in the last month or two months, it's just like, it's awesome. But there are new papers dropping from really established teams and kind of introducing all these new ways to think about these problems. In your presentation at the starkware sessions event the other day, you actually outlined, you helped me at least map out what's going on. Like, where do those different protocols live. So how would you break down this landscape?
00:32:43.270 - 00:34:06.940, Speaker B: Okay, so the categories I was referring to are related to the basic cryptographic assumptions that underlie the different zkps that we see emerging. And there are three types of such assumptions. The newest and the one that was deployed, for instance, in zcash comes from this family of knowledge of exponent assumptions, which is a cryptographic assumption that started being used in the oughts and gets redefined and with some new variants of it, with almost every new paper. The second family of constructions, which relies on assumptions that are a bit older, those are constructions based on elliptic curve discrete log problem. I guess the most famous one from this family is the bulletproof system that's deployed in Monero. And these cryptographic assumptions go back to the aught and the third family, to which starks belong, along with other systems such as Aurora, Ligero and Zikabu, to mention a few, relies on the cryptographic assumption of a collision resistant hash. And this assumption has been around since the mid 1970s.
00:34:06.940 - 00:34:35.998, Speaker B: And the reason I was talking about these three different categories of proof systems relates to their future proofness, because the more fundamental a cryptographic assumption is used and the longer it's been around and the more other stuff that is tied to it, the safer it is considered. So knowledge of exponent assumptions have an economy of roughly half a billion dollars.
00:34:36.104 - 00:34:44.230, Speaker A: The zcash system, what else is in there? What other kind of protocols are in the knowledge of exponent so systems that.
00:34:44.300 - 00:34:55.946, Speaker B: We know of by now that require such assumptions are things like sonic and Planck. Those are very recent constructions. They require knowledge of exponent assumptions and.
00:34:55.968 - 00:34:57.978, Speaker A: Snarks, do they fall in there as well?
00:34:58.144 - 00:35:21.506, Speaker B: Yeah, the snarks used by zcash. Yes. Snark has also a more general definition that can incorporate other things. But usually when people talk about snarks, they refer to the ones in zcash. Snarks, sonic and plank come from this family. Okay, so this is a rather recent family. It has roughly half a billion dollar worth of an economy around it.
00:35:21.506 - 00:36:13.650, Speaker B: If you look at the elliptic curve discrete log problem, it has in it things like bulletproof and possibly halo and supersonic, depending. When I say possibly, it's because the exact cryptographic assumptions are not quite completely spelled out in all of these things. But it looks like it requires only elliptic curve discrete log and pairings as well. And these assumptions go back a little bit further to the, again, 20 years earlier or so, and there's a bit more of an economy built on them. Things like certain forms of SSL, key exchange and identity based cryptography, and then the third family to which our stark system. So just like snark, starks are a bigger definition, but they're typically associated with a very particular implementation. So I'm referring to that.
00:36:13.650 - 00:36:38.298, Speaker B: So it uses hashes, which have been around since the very early days of cryptography, the mid seventy s, and basically all of ecommerce and all of the Internet infrastructure security relies on at least such an assumption. So that's why we at Starquart think this is the safest and most future proof ready system.
00:36:38.384 - 00:36:45.200, Speaker A: Do these distinctions have anything to do with being post quantum secure? Or is that a different category? Completely.
00:36:45.970 - 00:38:10.102, Speaker B: So it's known since the breakthrough of Peter Shore that quantum computers can break the discrete log problem. And if you can break the discrete log problem, you can break things like halo and bulletproofs and these systems, and you can also break the knowledge of exponent assumptions used by the snarks and sonic and Planck. So if you have a quantum computer, then the two newer families sort of fall down. That's one of the aspects of having a system that is more future proof. As long as you have a hash function that is post quantum secure, then there's at least hope for these other family of systems based on interactive oracle proofs and similar things. And very recently there's a very beautiful paper by Alessandro Chiesa, who's also one of our, is my co founder at Starquare, and two colleagues on actually proving that in certain models, the quantum random oracle model, these systems are actually safe even when you compose them into a non interactive proof. So there's even some theoretical substantiation of having families based on collision resistant hashes being safe to quantum computers.
00:38:10.246 - 00:38:16.826, Speaker A: But that's interesting. So it's like the older cryptography can go further into the future.
00:38:17.008 - 00:38:17.740, Speaker B: Yeah.
00:38:18.190 - 00:38:21.040, Speaker A: Why is that? That seems strange. No.
00:38:21.970 - 00:39:29.070, Speaker B: So from a sort of history of science point of view, what happened was that it initially seemed to some that systems based on those older techniques are not as efficient. And people looked for newer ways to get efficient systems, so they looked also at newer cryptographic assumptions. I think the work that started this was a beautiful paper by two of my colleagues from Technion, Yuvali Shai and Eal Kushilevic, along with Rafael Estrovsky from UCLA, who basically said, look, if we use things known as additive homomorphic encryption, we can sort of bypass the gnarly parts of the other kind of efficient systems. And because of that, you have these newer systems that have more exotic and newer cryptographic assumptions that are also prone to quantum computers. But what people have not noticed, or now noticing a bit more, was that actually we've been making a lot of progress along the earlier kind of route and getting the most efficient systems there that also happen to be post quantum secure.
00:39:29.230 - 00:39:41.554, Speaker A: There must be so much being shared between these systems, too, like as much as we're outlining them as three unique types of zero knowledge, just in terms of techniques, I imagine there's a lot of sharing.
00:39:41.682 - 00:40:19.170, Speaker B: Definitely. All of these systems, all of the efficient proof systems use this beautiful technique called arithmetization. It was invented in the early eighty s by the great Alexander Rasborov, an amazing theoretical computer scientist, and used to prove circuit lower bounds and computational complexity, and later were transitioned into the area of proof systems in this beautiful paper by Lund, Karloff, Fortnau and Nissan.
00:40:19.510 - 00:40:21.938, Speaker A: I think Ariel Gavizon mentioned this one.
00:40:22.024 - 00:41:00.106, Speaker B: Yes, definitely. Well, a lot of people mention it. Right. It's a very important paper that used arithmetization in a new context of generating efficient proof systems. So all of the systems in all of the three trees use some form of arithmetization. And arithmetization is this process of converting a problem about computation into a problem about low degree polynomials. And then the differences are, how do you actually know that your prover is using low degree polynomials? And here is where the three trees grow and use different techniques.
00:41:00.218 - 00:41:09.262, Speaker A: I see. Do you force something into that format, or is it more of a test as to whether or not it is already in that format?
00:41:09.406 - 00:42:20.630, Speaker B: That's a great question, and I think the answer to that. So do you force your prover to use a low degree polynomial, or do you allow her to do anything but then sort of check whether it is a low degree polynomial? The answer to this is exactly what distinguishes the oldest tree from the two newer ones. Because in the oldest tree, the one built on hash functions. The way the system works is you tell the prover, look you can use whatever you want, but be aware that we will test and check whether what you're using is really a low degree polynomial and that only requires hashes. Whereas in the two newer versions, the one that use elliptic curves and knowledge of exponents, what happens is that there is a bunch of parameters or keys that are used in order to force the prover to necessarily use only a low degree polynomial. The difference between the different trees and ways you get zero knowledge is the difference between. Do you allow anything and then check it, or force the prover to use only a very particular kind of representation?
00:42:20.710 - 00:43:01.442, Speaker A: That's an interesting way to think about it in this. So you mentioned new or ideas from the permeated all of these groups, but are there other. I think I asked you this on the last episode as well, the last one we did together. But I'm curious if maybe there's new info here, since we're deeper in it. But are there other places, or are you seeing some kind of techniques coming from other worlds, possibly outside of the cryptography, used for zero knowledge that are actually entering in and being used across these different types of zero knowledge?
00:43:01.586 - 00:43:54.582, Speaker B: Well, all the time, you have new ideas coming in, typically from other fields of mathematics. So, for instance, one theme that we already explored in theoretical works, but hasn't really made its way into implementations yet, is the use of generalizations of low degree polynomials. Things known as algebraic geometry codes, or GOPA codes, that have some advantages. So there's a bunch of works that I and my co authors have written about the advantages of these things. But they're not yet deployed in any practical setting. I think what we're currently starting to see, and some of the talks we had at the stargoer sessions were already exploring this. Is, for instance, taking techniques from the collision resistant hash world.
00:43:54.582 - 00:44:07.226, Speaker B: Things like fry and deep fry. That allow you to check if something is a low degree polynomial. And then importing them into the world of these other systems that use discrete log and so on and so forth.
00:44:07.248 - 00:44:07.930, Speaker A: The newer ones?
00:44:08.000 - 00:44:17.920, Speaker B: Yeah, the newer ones. And I'm sure we'll see a lot more of this sort of moving between different areas and incorporating ideas from one area into the other.
00:44:18.610 - 00:44:35.262, Speaker A: I think it was through the Starkware 101 workshop or through conversations after, where I learned that there was some technique that was taken from ffts, from fast failure transformations. And that was incorporated into Fry. Yes, let's actually define Fry.
00:44:35.406 - 00:45:05.546, Speaker B: So, Fry. Let's open the acronym first. So the f is fast, r is reed Solomon, which is this family of codes that uses low degree polynomials. And the I stands for IOP of proximity. IOP is this model in the post quantum secure, collision resistant, hash based zkps live. So Fry stands for fast read Solomon IOP.
00:45:05.658 - 00:45:07.626, Speaker A: And it is in stark constructions.
00:45:07.738 - 00:45:08.398, Speaker B: Yes.
00:45:08.564 - 00:45:10.714, Speaker A: What's its purpose in the construction?
00:45:10.842 - 00:45:55.754, Speaker B: It is exactly the way we answer your question about how do we know that some function is low degree. So it is the technique by which we let someone say, here is a Merkel tree that its leaves. If you open them up, they will be an evaluation of a low degree polynomial, which is the only thing we need in order to get all of the zero knowledge proof systems. That's all we need. We need to know that the prover is using one low degree polynomial in his answers. So fry is a way to check efficiently if someone has actually done this or if they're cheating.
00:45:55.882 - 00:46:05.902, Speaker A: And it uses this technique from ffts, though. And that's like a. I mean, I know, fast forward transformations from music, signal processing.
00:46:05.966 - 00:46:06.242, Speaker B: Right.
00:46:06.296 - 00:46:08.740, Speaker A: So, very different part of.
00:46:10.870 - 00:46:48.880, Speaker B: I always say, okay, I had the fortune of teaching the FFT in many courses. And the first thing I say about it is the following. That there are these concepts in math, that their power and beauty is in having so many different interpretations and ways of using them. So one of them is things like a matrix or a linear transformation. It is such a powerful thing. Another one is determinant, which is, it has so many interpretations and meanings, and you can generalize it in so many ways. Another one is derivative of a function.
00:46:48.880 - 00:47:30.502, Speaker B: At first, you learn that it is this angle. Then you learn that it is this linear transformation with a whole bunch of properties. And it goes on and on. So the Fourier transform is yet another one of those amazing and magical concepts that has so many different ways of viewing it and using it. So it's definitely used in signal processing. And it's taught as this way to move from one representation to the other, from a time based representation into a frequency based one. But it also has huge generalizations to number theory and group theory and analytic functional analysis and a whole bunch of things.
00:47:30.502 - 00:48:10.498, Speaker B: And in particular, it is also a concept that is used, essentially, in all of these proof systems. There will be an FFT somewhere that does something pretty efficiently, and it's needed. So in the snarks used in zcash and in Sonic and in plonk and in other systems, you will have ffts lurking around. What's new about Fry is that it sort of starts doing an FFT, but then it sort of speeds it up, which actually makes the fry protocol even faster than an FFT in terms of its asymptotic running time. And it achieves a slightly different goal of knowing that a function is indeed low degree.
00:48:10.674 - 00:48:18.042, Speaker A: Is Fry something that came out of starquare industry research? Or is that something from academia? Where is Fry from?
00:48:18.096 - 00:48:43.874, Speaker B: So the fry paper has four co authors. One of them is myself, Ido Bentov, Inon Khorich, and Michael Reaptiv. It was published when we were all in academia. And what has come out of Starqueware by now is this improvement on it called deep fry, which is a great.
00:48:43.912 - 00:48:45.060, Speaker A: Name, by the way.
00:48:45.530 - 00:49:16.122, Speaker B: Yeah, I agree. Credit goes to our two co authors, who are also scientific advisors to starquare. Professors Shubangi Saraf and Swastikoparti. I don't know which one of them came up with the name, but we agreed that it's a great name. And also, Leo Goldberg from Starquare. Together with me, we're four co authors of this new paper. I just want to say that I believe that someday someone will find an improvement.
00:49:16.122 - 00:49:25.358, Speaker B: And I already know what the name will be. It must be a stir fry. Because if we have fry and deep fry must be stir fry.
00:49:25.454 - 00:49:33.058, Speaker A: Nice. Cool. What does deep fry do exactly? So, I don't think we said that, actually.
00:49:33.144 - 00:49:37.590, Speaker B: Well, instead of frying something, it does puts it in a lot of oil.
00:49:38.730 - 00:49:40.182, Speaker A: You take away the pan.
00:49:40.316 - 00:49:55.642, Speaker B: Yeah, exactly. No, but jokes aside, what deep fry does is the title of the paper talks about deep fry sampling outside the box.
00:49:55.776 - 00:49:56.266, Speaker A: Okay?
00:49:56.368 - 00:50:49.914, Speaker B: Which. What happens with, let's say with fry is you start with a merkel tree or a commitment to some function that just as sort of a table of evaluations, let's say there's one entry for the function's value at the zero. At the zero, one. At the zero, two, let's say up to the zero, 1000. So we have this big table. This table might look big, but there are way more entries in the world than just those thousand entries. So previously in Fry, all the queries that we ever did when we were sort of checking whether this is a good low degree polynomial were always to this domain, to this, let's say, 1000 entries that the prover committed to with deep fry, we sort of go outside the box and we suddenly start making queries about, let's say, what is the value of this function at the 0.1
00:50:49.914 - 00:50:52.166, Speaker B: million which isn't inside the table?
00:50:52.278 - 00:50:52.810, Speaker A: Oh, wow.
00:50:52.880 - 00:51:01.470, Speaker B: And this is the main idea that goes into it. And then we incorporate the answers in way that make the system far more efficient and have better security.
00:51:01.620 - 00:51:12.800, Speaker A: What would you call, like, what's comparable, that technique? Is there anything else that you could say does stuff like that? Where does that idea come from? Even this idea of sampling outside?
00:51:14.610 - 00:51:26.680, Speaker B: I. I don't know. I mean, comes from where all ideas come from, right? I don't know where they come from. Yeah, that's a really good question.
00:51:29.050 - 00:51:30.474, Speaker A: Should we look it up?
00:51:30.672 - 00:51:32.938, Speaker B: No, probably some.
00:51:33.024 - 00:51:34.790, Speaker A: Is there a word for that technique?
00:51:34.950 - 00:51:51.214, Speaker B: Well, we call it deep. That's domain extending. So we extend the domain. So it's domain extending for eliminating pretenders. But, look, we needed the word deep somehow. We just needed to open the acronym. No, we do extend the domain, and it does eliminate pretenders in a way that I won't go into.
00:51:51.214 - 00:52:28.602, Speaker B: It has to do with things called list decoding or pruning. A list of contenders. No, but I think the question you're asking about is, where do new mathematical ideas come from? I confess I don't know of too many places where this kind of idea was seen before. I'm sure there might be areas, but I'm not aware of them. This particular. I mean, I always go back to this beautiful paper by Henri Poncare, where he sort of muses on the nature of mathematical creativity. It's a must read.
00:52:28.602 - 00:52:29.690, Speaker B: Everyone must read it.
00:52:29.760 - 00:52:30.906, Speaker A: What's the name of the paper?
00:52:31.008 - 00:53:39.390, Speaker B: I think it's called? First of all, it was written in French, but I know the english translation. And the title is, I think it is on the nature of mathematical creativity. So, in Ripon corresp, in addition to being this amazing mathematician and the founder of ergodic theory and other things, also know not all mathematicians can sort of take a step back and talk about the process of mathematical creativity. But he was this rare genius that was also very articulate about it. And he has this beautiful paper that, you know, every time I read it, I get goosebumps because it resonates so much. For instance, he talks about this process where he comes to a problem, and he sits for two weeks and thinks about it, and he's working very diligently and very hard, like sitting at his desk 8 hours a day, but he's making no progress. And then he goes on some vacation or something, and he's crossing a bridge.
00:53:39.390 - 00:54:41.046, Speaker B: And as he crosses the bridge, like thinking about nothing, suddenly he sees it, right? It's like this solution emerges, and the minute it emerges, he doesn't need to write it even he sees it in its entirety and completely understands it. And then he says, okay, now I just need to write it down, but he sees it completely. And then he asks, what happened here? And he says, well, look, the two weeks I spent on it were not a waste of time. I would never have had this revelation had I not spent that time. But what happened in between, I don't know. The best description is, I mean, maybe you have this process where you're feeding your subconscious with all of this work, and then your subconscious sort of connects all kinds of things, and then at some point, it sort of floats up back to your consciousness, and then you suddenly see something totally that you had no idea that you could see.
00:54:41.148 - 00:54:51.002, Speaker A: I almost imagine it like, you walk down various paths, and even though they might seem far away, you're eventually defining a map. I don't know if that's in any way.
00:54:51.136 - 00:55:24.194, Speaker B: It's all about exploring. There's this unknown space. I mean, that's science, right? It's exploring this unknown space. Now, in mathematics, this unknown space is very abstract, but it is this unknown world, and you're sort of walking and exploring your complete darkness. And as you're doing. So, the amazing thing is that I guess your subconscious is some faculty of your brain is doing stuff you're unaware of, and then all of a sudden, sometimes you suddenly see stuff. That's the best answer I can give to, where do ideas come from?
00:55:24.232 - 00:55:39.526, Speaker A: I love it. That's so good. So I want to say thank you so much for coming back on the Zero Knowledge podcast and talking to me about all of this. I wish Frederick had been here. Unfortunately, this was a bit of a spontaneous interview. Please do come back again.
00:55:39.628 - 00:55:44.680, Speaker B: Thank you. I gladly. And thank you so much for tolerating me yet again.
00:55:46.170 - 00:55:49.110, Speaker A: And to our listeners, thanks for listening.

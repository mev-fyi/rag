00:00:06.650 - 00:00:18.990, Speaker A: Welcome to Zero Knowledge, a podcast where we explore the latest in blockchain technology and the decentralized web. The show is hosted by me, Anna and me Frederick.
00:00:25.210 - 00:00:35.720, Speaker B: You in this episode we sit down with Martin Lunfeld to discuss formal verification, what it is and what frameworks are normally used, as well as where it fits in the blockchain world.
00:00:44.030 - 00:01:30.418, Speaker A: Thank you to this week's sponsor, the Web Three foundation. The Web Three foundation has announced a series of grants to fund development on substrate and polka Dot. If you are a group or individual contributor looking to build bridges to other chains, substrate runtime modules, or an exciting new pair chain, this could be an interesting funding option. You can find out more about the areas of interests on grants Web three foundation the criteria is it must be open source and approximately a three month work time frame. For more about this program, check out the blog post we have linked in the show notes thank you again, Web Three foundation. And now here's our interview with Martin Lundfal. So today we're going to be talking about formal verification with Martin Lunfell.
00:01:30.418 - 00:01:32.330, Speaker A: Hi Martin, welcome to the show.
00:01:32.400 - 00:01:33.818, Speaker C: Hey, I'm glad to be on the.
00:01:33.824 - 00:01:38.906, Speaker A: Show, and I'm currently on a call not with one Swede, but with two. Frederick is here too.
00:01:39.088 - 00:01:42.806, Speaker B: Hey, the blockchain industries are being overrun by Swedes.
00:01:42.838 - 00:01:45.210, Speaker D: We are dominating all power to the Swedes.
00:01:45.370 - 00:02:07.480, Speaker A: So formal verification as a topic was requested by our audience. Actually, when we put out a call earlier this year for topics, it came up more than once. We ourselves had talked about covering this, and we're really happy to have you on, Martin, to help us navigate this. What would we call it? The sort of future of security.
00:02:08.090 - 00:02:21.866, Speaker C: I've been describing it as the road to complete verification, but that's also a bit sensationalist. So that's either a very long and winding road or a very narrow sense of complete security.
00:02:22.048 - 00:03:07.810, Speaker B: I think we should start off with some form of primer on formal verification because it's this topic that's kind of mystical, undefined in a lot of people's eyes, seems magical in a lot of people's eyes, but it's also this thing that people tend to quote a lot around. If you have security problems, just do formal verification and you're done and you'll never have a security issue in your life again. But obviously that's not true. And this is like a huge field that's been around for many, many years, long before blockchains existed. And I'm curious as well to hear how you got into formal verification yourself. So maybe we can start just there and then dig into a bit more on what it is.
00:03:07.900 - 00:04:09.260, Speaker C: Sure. So I started getting into all of this by studying mathematics. The school at which I was studying at Stockholm University, there's a fairly strong logic department, and the logic is very computer science y, one might say. There's a lot of type theory. I studied with some great professors that really got me into proof assistants and writing mathematical proofs in computer languages, where the proof assistant, or the interactive environment with which you interact, is checking the validity of your proofs as you write them, which, on the one hand, is like an extremely way too detailed process because computers are very bad at understanding math, so you really have to spell everything out to them. So a lot of the time you end up proving trivial statements with a lot of effort. But it gave me a nice understanding of how we can really understand mathematics from a computer science perspective, or sort of the interaction between the two.
00:04:09.260 - 00:05:13.634, Speaker C: And so I actually wanted to have an original project. This was supposed to be my bachelor thesis. I wanted to write like a proof market. So if you would define the rules of mathematics in a computer language, so really, like the foundations of logic, you would be able to do this sort of proof checking, and if you were to implement it on chain, then you would be able to have statements that you want people to write the proof of. And you could also attach a bounty to that proof. So you could take your favorite unproved conjecture and you could attach a bounty to it and see if anybody would come up with the proof. I ended up not doing that because implementing the rules of mathematics in the EVM was kind of cumbersome, and I decided to sort of pursue different things.
00:05:13.634 - 00:05:30.498, Speaker C: That's how I got interested in really doing formal mathematics in the first place. And then verifying programs came naturally as I saw the demand for that, as all blockchain contracts started to get hacked.
00:05:30.594 - 00:05:43.770, Speaker A: Had you just been into blockchain on the side, like you were studying something else? From what I understood, and then you just sort of ended up there. But was it like a hobby that became a focus, or did you learn about it at school?
00:05:43.920 - 00:06:08.690, Speaker C: No, I learned about it through different means, just hearing about it from friends and getting more and more involved. But actually, as I was studying, it was a fair degree of separation between the mathematics I was studying and the blockchain stuff that I was learning at the site. And I was trying to unify them. And I think I eventually have, like right now with the work that I'm doing. But as I was studying, they were more separated.
00:06:09.030 - 00:06:33.146, Speaker B: The first time I came across formal verification myself was, I think it was a good way into learning Haskell. And once you start learning Haskell, you kind of go off on this tangent of formal verification and learning cock and Isabelle and Idris and everything else, and dependent types, and these are all sort of interlinked things. And I think the first proof that.
00:06:33.168 - 00:06:35.706, Speaker D: I saw was that this array was.
00:06:35.728 - 00:06:52.474, Speaker B: A fixed length throughout the entire program. And it's like, yeah, okay, sure, but not super impressive. But then I think the second proof I probably saw was like that a red black tree was correctly constructed, and that was a bit more mind blowing.
00:06:52.522 - 00:06:56.210, Speaker D: That was actually like, yeah, that's actually powerful.
00:06:56.710 - 00:07:05.074, Speaker B: What was the first proof that you saw or wrote yourself, and which one was the one that sort of made.
00:07:05.112 - 00:07:06.278, Speaker D: It click for you?
00:07:06.444 - 00:07:42.846, Speaker C: That's a good question. That's really nice. I think the first proof that I wrote was about real numbers defined in a sort of finitest way. So defining real numbers as a sequence of converging rational numbers, I was proving that you can equip these real numbers with an equality, and that actually is an equivalence relation. So I was proving the symmetric and transitive and reflexive part of that relation. So it wasn't very computer science or program oriented. It was more of a pure math thing.
00:07:42.948 - 00:07:54.878, Speaker A: Frederick, you just mentioned that Haskell kind of led you to formal, and I might be off here, but rust has a lot of sort of checking. Is that in any way related?
00:07:55.054 - 00:08:54.882, Speaker B: Yeah, I mean, it depends on how you view things. I would say just from an engineering point of view, something like Python doesn't have a type system. You have no guarantees that anything does anything at all. Then you move into something like C, and you have types like an int, and you're guaranteed that this is an int, that this thing will always be an int. And then the further up the type system stack you go, the closer you get to something that is formal verification, in my naive understanding of it, because you get to a point where eventually you have this whole system in the type system, in the sort of compiler, in the verifier of the program that these properties hold. But something like Haskell still has an extremely like, you can't actually prove almost anything compared to something like K framework.
00:08:54.946 - 00:08:57.334, Speaker D: Which we'll talk about later, where K.
00:08:57.372 - 00:09:19.854, Speaker B: Framework is this whole framework, and you make these huge specifications of what it is your program is supposed to be doing, and you can view it in some way, at least like I said, in my naive view of it as a type system. And so once you go down that path of wanting to learn more and better type systems, it kind of leads you into formal verification, or at least.
00:09:19.892 - 00:09:20.878, Speaker D: It did for me.
00:09:21.044 - 00:10:20.078, Speaker C: Yeah, that really illustrates the two different approaches to formal verification or to getting assurances about your programs, where the one is, as you said, where you have strong type systems that give you guarantees. If your program just compiles, then you know that it's going to behave in a certain way and are not going to violate certain invariants. And the other one is where you have another language or another framework in which you plug in your program that you have written, and you can state properties about that, but you're not necessarily stating the properties in the typing language of the system. You're rather putting it inside a framework where you can make claims about the nature of this program. And this is sort of following along a tradition with core logic and pre and post conditions and stuff like that. And that has been a little bit separated. This is also, model checking is also in this category.
00:10:20.078 - 00:11:19.766, Speaker C: I would say that is a different flavor or at least a different heuristic to getting assurances than the strong type systems. But just while we're talking about type systems, there's one thing that I think should be mentioned, which is what you were getting at Frederick before, and also if we were talking about rust, which is the curry Howard correspondence, or this paradigm of types as propositions, and this is a correspondence that is really strong in the cases where the type system is very developed. And if your type system is rich enough, such as dependent types, then it really becomes the case that there's a direct correspondence between the types of your programs and the programs themselves as the correspondence between the statement. So, like a mathematical theorem and its proofs. And then if you have linear types in rust, you can sort of understand them in different ways.
00:11:19.868 - 00:11:32.378, Speaker A: We haven't exactly defined formal verification yet, I feel. So why don't we do that? I think it might make sense to just like, if you were to summarize what it is in a sentence, what is it?
00:11:32.544 - 00:12:08.390, Speaker C: I would define formal verification as the stating of mathematical properties about programs and their proofs. So proofs of those claims that you make about the programs, well, that's the act of maybe verifying code in general. And then if you want to do formal verification, then that means that you are not writing these proofs down in English or in a latex document. You're actually writing them down in another formal language.
00:12:09.210 - 00:12:15.810, Speaker A: Is there a specific language that formal verification usually uses, or can it be all sorts of languages.
00:12:15.890 - 00:12:31.578, Speaker C: So generally, I would say that it uses the language of mathematics, and there are different flavors and different implementations of the language of mathematics. And people have very strong opinions about which ones are good implementations or which ones are true mathematics.
00:12:31.754 - 00:12:39.790, Speaker A: What does that mean? I'm trying to picture what that is. For example, where do you do your work? Where is it?
00:12:39.940 - 00:13:33.642, Speaker C: So, since my work is using the k framework, I'm writing my proofs as statements in the K language, and this language can be understood mathematically. It's grounded in a theory of rewriting, or rewriting logic, it's called, and you can use, like we mentioned earlier, proof assistants like Cock or Isabel or Agda, and they have a more direct translation of mathematics. It's like writing mathematics directly. Of course, you can also just write out proofs in plain English or in a nice PDF form, or just explain it to somebody else. It really just depends on the type of rigor that you're after, usually. I mean, mathematicians don't spend their time, or at least not most of their time, writing down their proofs in any formal system. They write it down in English or explain them to each other.
00:13:33.642 - 00:14:17.290, Speaker C: And that is an acceptable level of rigor. In most cases, that is way nicer and more digestible than to see any formal proof of it. But then, when it comes to proving properties of programs from a mathematical perspective, the claims are not that interesting. It's not like we're learning new things about some general nature of reality. Instead, I would say that we're making very precise and involved claims about the nature of our programs that are mainly interesting to the people who will be running those programs. The methodology of writing proofs is not very interesting either. So it's something that can be done by a computer very easily.
00:14:17.290 - 00:14:23.486, Speaker C: A lot of it looks a lot like brute force. You just explore a bunch of execution paths.
00:14:23.598 - 00:15:21.060, Speaker B: I would say that you can correct me if I'm wrong here, but a simplistic view of it is you write down a spec, your proof of what properties you want to prove in some fashion. And this depends on what you're writing your proof in. So, for a simple example, let's say you have an ERC 20 contract. The thing that you want to prove is the total balance will not change. Posts deploy, so there will never be more or less tokens than this number. How you write that rule down, like, that's a simple rule to express in English, but you can express that in code, or you can express it in various ways, depending on which framework you're using. Then you plug your actual contract into that in some way, again, depending on what framework you're actually using.
00:15:21.060 - 00:15:40.682, Speaker B: And it does this code exploration or symbolic execution, or just brute forces every possible input and says, okay, your program is holding this rule, this contract is now proven according to this spec.
00:15:40.816 - 00:16:28.998, Speaker C: Yeah, and I think while we're talking about that, it's important to highlight that formal verification is really just as powerful as the claims that you're making about your programs. I mean, of course you can formally verify that a program is doing nothing more than returning an error for every input, or that it's always returning zero, or that it merely exists. These are all formally verified claims that you can make about the program, but they might not be the interesting ones that you're after. And finding the interesting claims is the creative part. Writing the specs and really understanding what it is that you think this program should do and what it means for it to behave correctly is the interesting part. And then the verification part is an exercise to the reader.
00:16:29.174 - 00:17:24.106, Speaker B: And I think, yeah, when it comes to real world programs, and this is where things get difficult, is if you want to formally prove a networking protocol. There are so many variables that are involved in correctness of a networking protocol, just like including latencies and timings, and how routers behave in this system and how the backbone of the ISP is behaving. There's so many things that is even beyond your control that you couldn't really prove the entire system. So then it comes down to the engineer writing the proofs or the verification of like, what are we trying to actually prove? What's important in our particular application, you very rarely get like a complete proof of an entire program, maybe. And I think this is why in.
00:17:24.128 - 00:17:33.760, Speaker D: The smart contract world it becomes a lot more interesting because the programs become a lot smaller and it's much more likely that we can have a proof of everything that we care about.
00:17:34.210 - 00:17:54.894, Speaker C: Absolutely. Especially if we're talking about something like an ERC 20. We have like five methods, maybe, and all of the methods mainly do one thing. There's a couple of corner cases that we need to take care of, such as what happens when you transfer to yourself and stuff like this. But really it's much more feasible to verify than something like a networking protocol.
00:17:55.022 - 00:18:08.546, Speaker A: This almost sounds then like when you start working on a project, you must have to work very closely with the people who've written the smart contract. Obviously it's simple, but you need to get inside all of their intention.
00:18:08.658 - 00:18:55.142, Speaker C: Yeah, and this is extremely difficult, especially with some development methodologies. If you think about scrum, it's very much about just write something and figure out what it's supposed to do later. And this is how a lot of programmers work. They just have a vague idea of what they need to do, and then they write something and they sort of guess that what they have written is doing, or I should say that their intention is forming as they are writing the program. So it becomes kind of difficult to understand what the platonic ideal of the program should be. So, yeah, you definitely need to work closely with the developers and try to understand what they meant to do, what they've done, and how those things might change over time.
00:18:55.196 - 00:20:16.354, Speaker D: And this depends very much on the team, and I'd even say ties very closely into the language, discussion of how someone has written something in what language, and there are different styles in different languages. There's this great talk by Connor McBride, who's a professor, I can't remember where that's called. Is a type a life buoy or a lamp? And he writes this program in Agda on stage. And the general point of the talk is to advocate type driven development instead of this kind of do something and then figure out whether it's correct or not. And he implements something relatively simple, but he writes out the types first, and then in agdot you have this nice property that you can generate parts of your program from the types. So he basically writes a fully defined type, and then the entire program, the entire implementation of that program, can be auto generated, because there is only one possible way to write a program that fits this type. And so you kind of get into this interesting mix of where you're stating your intention up front instead of post fact.
00:20:16.354 - 00:20:30.866, Speaker D: And yeah, I really hope that we can move the programming world, especially in the smart contract side, towards this, rather than I'm just going to write something and see if it works. And I'll only ever test a happy path.
00:20:31.058 - 00:20:31.798, Speaker C: Absolutely.
00:20:31.964 - 00:20:35.400, Speaker A: So are you calling the end of scrum? What's going on?
00:20:35.930 - 00:20:39.580, Speaker D: Well, at parody, we called it a long time ago.
00:20:40.830 - 00:21:13.074, Speaker C: I don't know the names of these fancy development methodologies. I can't remember who it was that said this. I think it was Dejkstra, maybe, who talked a little bit about verifying properties of programs. He said that you should sit down and think hard about what you think that your program should do. So I would say that this is kind of in contrast with move fast and break things. It's really all about trying to figure out what the hell you're doing before you start doing it. Rather than figuring that out at some.
00:21:13.112 - 00:21:31.050, Speaker A: Point along the way, do you come into conflict with the styles of some of the groups that you're working with? Because you are coming much more from this academic space and looking for that sort of documentation first or like that clarity first.
00:21:31.200 - 00:22:02.018, Speaker C: I mean, it's definitely a different way of looking at what programming is and how to do it, as opposed to a lot of programmers. It takes me a long time, or it has taken me a long time, and I'm still learning to become a good programmer. I mean, this isn't something that comes automatic just because you know some mathematics. So when I work with people that I think of as real programmers, I don't really know if I consider myself to be a real programmer yet. It's a very nice trade off and exchange of how to do things and how to think about things.
00:22:02.104 - 00:22:30.566, Speaker A: Now that we've defined formal verification, I'm curious why it's necessary. Obviously it fits into the security theme that we've talked about, but why is it really necessary to do formal verification? And I also want to ask if you have any examples of vulnerabilities that maybe could have been caught, things that actually did go down that you think could have been saved by something like formal verification.
00:22:30.758 - 00:23:14.300, Speaker C: Yeah. So I think, first of all, there's a great value in just writing specs. A lot of people keep iterating on this. But if you are just writing a program and never write down your intention for what this program should do, then as somebody coming in, as a security researcher, it's almost impossible to say whether the program is correctly written or not, because in a sense, you've only provided the program. So if the program is also the spec, then of course it's correct. By triviality, writing specs help. And actually just the act of writing a spec will make you realize oftentimes a lot of errors and things that you haven't thought about.
00:23:14.300 - 00:24:14.218, Speaker C: And then when it comes to what sort of bugs you can catch with this, then there's really just a matter of how much effort you're willing to put into the formal verification. A lot of the common bugs that people have encountered in Ethereum and the history of Ethereum and stuff like the Dow hack can now easily be caught by automated tools that check for a certain type of vulnerability in your code or a certain pattern that is deemed to be insecure. What formal verification does or really like a complete, exhaustive specification of your program that you are able to verify, is not only giving you this positive experience of, or maybe negative experience of finding bugs, pointing out where there are bugs, but also giving you assurance that there is not a bug in the program, that you have been able to say everything that the program does and to show that in all cases it matches the specification.
00:24:14.394 - 00:25:04.974, Speaker D: I would say that the difference and sort of what kinds of bugs you can find. If we take the Dow hack as an example, it happened, and then there were a million linting tools that said don't do this. So after it happened, it was brought into all the tooling to say you shouldn't do this. And now all future contracts are safe from this particular pattern if they run all the tools, but these tools, they wouldn't have caught it the first time it happened. So if they had written a formal specification saying that there can be no reentrancy in this contract, however you would go about writing that. I'm sure that would be quite complicated. But if you actually did that, you would have assurance when you actually deployed it that it wouldn't have this going into it.
00:25:04.974 - 00:25:37.206, Speaker D: So it's sort of do you let this bug happen to one person first and then kind of catch it in every case after? Or do you write your spec up front and say, within some intention, I want to be assured against this particular thing happening? If you don't even know that this type of thing is a thing that can happen, then it's pretty hard to write a spec about it as well. So I don't know. It's knowledge exploration versus post testing when you already know what can go wrong.
00:25:37.308 - 00:25:57.754, Speaker A: This kind of harkens back to what we were talking about earlier on about this magic or this perceived magic, that formal verification will fix everything. But it sounds like if you don't know what the vulnerability could potentially be, then you would possibly have a hard time using this tool to find it or to find out if you're vulnerable.
00:25:57.882 - 00:26:38.662, Speaker C: Yeah, it comes back to what I was saying before in what you're actually verifying. And if you're at this scenario where you're not trying to verify that a particular property holds, you just want what people normally understand as formal verification, which is that they say that the contract should be bug free. So if a contract should be bug free, then that means that you need to define its behavior in all possible ways that the program can be executed. And that means specifying the entire nature of a program. And for small programs this is easy to do, and for large programs it's almost impossible. Well, it's never impossible. Actually, in the general case it is impossible.
00:26:38.662 - 00:26:48.400, Speaker C: But for most real applications, things are actually finitely describable. Certainly most of the contracts that we interact with.
00:26:49.010 - 00:26:56.130, Speaker D: Actually, in the EVM model, this is a common misconception. EVM is not turing complete because there is a gas limit.
00:26:56.550 - 00:27:43.838, Speaker C: Yeah. So as long as a block has a finite gas limit to it, then you're not turn complete. But a lot of people don't even deal with gas when they do formal verification. So when it comes to comparing different approaches to formal verification, it always starts with the semantics of the language in which your programs are written. So in order to verify programs that are written in the EVM, we need a formal semantics of the ethereum virtual machine. And luckily, the EVM is kind of small, at least if you compare it to other possible languages in which you can write programs that you might want to verify. But it's kind of erratic, and gas complicates things a lot.
00:27:43.838 - 00:28:02.642, Speaker C: So what a lot of people do is to not specify the gas behavior of the EVM, and then you actually have a turing complete machine. That's sort of weird that you can do a bunch of crazy stuff with. What is really nice about the K framework is that they have a complete semantics that also deals with gas.
00:28:02.706 - 00:28:23.502, Speaker D: So I guess that brings us into the K framework, and this is something we've mentioned here and there on the podcast before. There's this Kevm thing that's being talked about quite a lot, which is this specification of the EVM in the K framework. So give us an intro to the k framework. What is it?
00:28:23.556 - 00:29:17.850, Speaker C: The K framework is a language and a suite of tools that deal with definition of programming languages and analysis of those languages. So it gives you a very nice way of formally expressing what a virtual machine or a programming language does. And then it is written to be general enough that it can define any such language. It has developed a bunch of tooling around the concept of a programming language in general, and what you can do if you want to analyze a language like that. So once you've defined a programming language in K, you get almost for free a debugger for this language, an interpreter for this language, and also an ability to verify programs written in this language.
00:29:17.930 - 00:29:27.090, Speaker D: And to be clear, what's specified is not as a language, is not solidity, it's just the EVM opcodes, is that correct?
00:29:27.160 - 00:29:43.590, Speaker C: Yeah, they're actually working on specifying solidity as well. But what we're dealing with is EVM, and that also saves us from the trouble of doing any verification of the compiler, because we're only dealing with the bytecode.
00:29:44.330 - 00:29:48.042, Speaker A: Who is they? So where does K framework actually come from?
00:29:48.176 - 00:30:10.910, Speaker C: It comes from mainly researchers at University of Illinois in Urbana champagne, and then it's also being developed and worked on by runtime verification, which is a company that is closely related to the university, but it's an open source project that a lot of people are developing and contributing to around the world.
00:30:10.980 - 00:30:20.610, Speaker A: Does Cardano have some stake in this? Are they working on this? Why do I often hear Cardano and K framework used in tandem?
00:30:21.110 - 00:30:40.982, Speaker C: Mainly because Charles Hoskinson, or IOHK, we should probably say, has been giving money to runtime verification, to do formal verification work generally, but also specifically to help them develop their virtual machine for Cardano.
00:30:41.046 - 00:30:57.694, Speaker D: Cardano is doing a bunch of formal verification stuff in general, and they're going really heavily into this direction, which is they're doing some cool stuff. They've pulled in like several big Haskell names into their dev team, which is interesting.
00:30:57.812 - 00:31:03.214, Speaker C: Yeah, they just keep throwing money at researchers. That seems amazing.
00:31:03.412 - 00:31:04.702, Speaker A: Not complaining, I guess.
00:31:04.756 - 00:31:09.970, Speaker C: Definitely not. It gave us a bunch of good tooling for the K framework, so I'm very happy about that.
00:31:10.040 - 00:31:17.526, Speaker A: So K framework, the people who like it seem to like it a lot. Why do people like it so much?
00:31:17.628 - 00:32:20.246, Speaker C: Well, I like it personally, because it gives a very clear conceptual picture of what a programming language is. When you're defining a programming language in K, you're defining it in terms of three steps. I would say you specify the syntax and in a way that closely resembles how you would describe it mathematically in BNF notation, with some additional helpers to make it nice and accessible for everyone. If you want to have some binders or some parentheses or stuff like that, they give you some helpers, and then you define the configuration of your program, which you can think of the state or the world according to this program. So if you have some variables defined, maybe they live in some mapping somewhere. Or in the case of the EVM, you have storage that is relevant to execution, and you have the message sender, which is relevant to the execution. So really baking everything in the environment together under this notion of a configuration.
00:32:20.246 - 00:33:10.298, Speaker C: And then the last part that defines your language is the rewrite rules, which just tells you if you encounter a particular piece of syntax and your environment looks in a certain way, how is the environment going to get updated, and how is the whole term going to rewrite, essentially? And so that's one of the things that I think is quite nice about it, that as a language, it's aesthetically pleasing, but perhaps more so from a practical perspective is the fact that it's written in such a general way that it's very easy to experiment with writing new languages and understanding programming languages and comparing them to each other in a setting where they're all defined in the same way, and then you get all of these analysis tools for them.
00:33:10.384 - 00:33:29.882, Speaker D: That's the main thing that I keep hearing is the tooling around it is just so different and larger than any other thing that exists. Like if you write some proof in cock, for instance, which is I guess the most common one academically at least that's my impression.
00:33:30.026 - 00:33:32.030, Speaker B: You don't really get anything other than.
00:33:32.100 - 00:33:57.126, Speaker D: This proof, and there's not much there other than just this program. Whereas with the K framework you can generate these compilers, debuggers and docs, and just generally making it pleasant and ergonomic to use k framework. So that's like a common thing that I hear is all of the tooling around it just makes the whole experience much better.
00:33:57.228 - 00:34:39.720, Speaker C: Yeah. The fact that they are pursuing generality first makes it really interesting and appealing to a large crowd of people, especially if you have some sort of niche programming language like the EVM that you want to analyze. The way that people usually do formal verification is that they write a bunch of specific tooling for the particular language that they are interested in. And you get a lot of advantages by doing that, mainly performance, because you're tailoring the methodology and proof heuristics for the domain that you're trying to target. But having this level of generality is certainly very interesting as well.
00:34:40.090 - 00:34:55.318, Speaker A: You sort of mentioned before that you're, and I don't know if I fully understood it, but can you actually analyze different languages because you have to see them through this lens? Do you start to see nuances in them? Do you learn something about them in that comparison?
00:34:55.414 - 00:35:18.162, Speaker C: Yeah, I think so. You learn a lot about what different languages can do, how they deal with concurrency or nondeterminism. You can compare them to each other in quite a nice way. Now this is not necessarily what you do when you're doing formal verification, but if you're a programming language enthusiast, then this is super nice.
00:35:18.296 - 00:35:28.150, Speaker A: So we just spoke a lot about the K framework, but there are actually other frameworks or other products that you can use to do formal verification.
00:35:28.650 - 00:36:12.414, Speaker C: Yeah, really. In order to start doing these verification efforts, you need to define the operational semantics of the EVM, as I mentioned before, and there it's all about having completeness. And one of the nice things about K is that it is complete and passes all of the VM tests and general state tests that make it as expressive as an ethereum client. It's basically a client without the networking layer. It is as complete as any client. And then there are some efforts to defining the semantics of the EVM, and Cock and Isabel and Hull. Yuichi was doing a lot of this work when he was still at the foundation, and he isn't anymore.
00:36:12.414 - 00:36:41.530, Speaker C: But I think others are picking up that work. And Manticore is also approaching completeness. I don't know where they're at right now, but yeah, a lot of people are doing different efforts, and I think that's a good thing. It's just that for now, if you actually want to start verifying contracts and want to have a complete behavior, complete specification of behavior, then I think the K framework is really the most comprehensive one.
00:36:41.680 - 00:36:49.920, Speaker A: Is there anything else that you would consider an alternative to K? I guess people can make their own for their specific program.
00:36:50.290 - 00:37:26.550, Speaker C: Yeah, and people are. I mean, there's a bunch of efforts being done everywhere, especially academics, that are using their methods of formal verification that they have applied to many fields throughout the decades and are now realizing that blockchains are a thing and that a lot of people are craving what they have spent decades perfecting. And so now they're adapting their tools to target the EVM. Many of those tools aren't really out in the open or free software and open source. It's kind of hard for us to work with them, both practically and philosophically.
00:37:26.630 - 00:38:19.770, Speaker D: I think that's an interesting thing that I've seen similar things where a lot of quote unquote newcomers to this space. Now, who wants to build tools around blockchain? They don't necessarily want to build blockchains themselves, but build tools around it. Their first instinct is to set up a company and have a proprietary product that they sell licenses to. And it's a very different kind of feel and different vibe to how things normally work in the blockchain world. Like, I was talking to one company that was doing exactly this for formal verification. I asked, what of this is open source, and how can we verify things? And I even asked, how does this work? And they wouldn't tell me because that's their secret sauce. They came with a pretty big claim of like, we can verify any such thing in super low time.
00:38:19.770 - 00:38:38.094, Speaker D: You can basically do it automatically on deployment. It's like, okay, it sounds cool, but how does it work? Can't tell you. And it's like, yeah, that's a bit weird for the space. I think they have some adjustment to do before that really kicks in, or, I don't know, maybe we have to adjust more things being proprietary.
00:38:38.222 - 00:39:00.620, Speaker C: Yeah, this has tended to happen to me a lot. Also lately when I'm speaking about formal verification at different conferences, people come up to me and they're like, hey, we're also doing formal verification, let's talk. And then I try to talk to them and want to exchange some methods and ideas, and really what they want to do is sell me formal verification as a service. And that's not that interesting to me.
00:39:01.470 - 00:39:38.706, Speaker A: So going back to what we were talking about before, I'm just trying to really get my head around what formal verification, and specifically like this K framework is, because I think when we talked about it just before, it was like, as I understand it, what you would do is you'd write a program or you'd write a spec, you'd do an implementation, you'd use this language to map it, and then you'd run tests on it, and then at some point it does become sort of final, and then you feel very, very confident that this thing will work. But the actual formal verification, it's not a product and it's a method.
00:39:38.898 - 00:40:07.950, Speaker C: Well, I would say that the actual verification is a proof that's the result of it. If I were to say the type signature of formal verification, I would say that the inputs are the operational semantics of the language in which you're writing your program, the specification of what your program should do, and then the implementation of this program, and then the output is a proof that the implementation matches the specification.
00:40:08.930 - 00:41:02.990, Speaker D: So K framework, for instance, is a suite of tools and a language to let you write down the specification and run the proof. And all these other tools that also exist, their languages or their specification frameworks only, or they're verification only. Like you can have symbolic execution, or you can try to do an exhaustive search type of execution. And it might not actually be a proof that comes out, but like you said, a confidence interval. But in a proper formal verification suite, they're kind of different and live in the same space. That's why I think this topic as a whole is so complicated to people and they don't know what is in there or what is not in there. But I think the definition you gave is perfect.
00:41:03.060 - 00:41:14.290, Speaker A: One, formal verification is also being used, as I understand in other fields, it's not blockchain specific, so where is it really big? What kind of applications do you see it in the world?
00:41:14.440 - 00:41:48.462, Speaker C: So it's quite big in areas where there's a lot of stake and you get one chance of getting things right. So this is the aerospace industry and airplanes and trains and some hardware components that might be super critical for a nuclear warhead. I don't know, a power plant. If there is a lot at stake, and if you can't just fix bugs in production, then usually people are using formal methods to ensure properties of code.
00:41:48.596 - 00:42:16.326, Speaker D: Something that I've seen it pop up quite a lot around is things like databases, where people start working on formal verification of the correctness of PostgreSQL, because basically every database in the world now runs PostgreSQL. So we want to have some assurance that it's not randomly deleting data, for instance. But I've seen AWS, Amazon Web Services.
00:42:16.428 - 00:42:17.882, Speaker B: They started doing a bunch of stuff.
00:42:17.936 - 00:43:07.400, Speaker D: Back in 2014 in TLA plus. So they've been creating formal specifications of the S three simple storage service, like high level protocol. But they've also done it for some of their databases and their networking stuff to guarantee that you can't talk between VPCs. They have a bunch of ASICs to do networking. They're doing a lot of stuff and a lot of very cool stuff, and they're formally verifying a lot of it as well. So it just leads to a more reliable service, and that's kind of why they're doing it. They want to try to guarantee uptime, and also if they actually have a network breach between different customers, that's devastating to their whole idea.
00:43:07.400 - 00:43:12.522, Speaker D: I'm seeing more of it, and I think we'll continue to see more and more of it.
00:43:12.576 - 00:44:13.046, Speaker C: Yeah, I think it also develops as people understand programming generally better. And this is something that is, of course, continuously worked upon by computer scientists and mathematicians to try to understand what formal languages are and how to understand them and what properties we're interested in verifying around them and develop tooling around that. I think historically there has been quite a large disconnect in the theoretical side and the practical side. A lot of people come up with really beautiful and elegant series for how to state properties of your programs, and they end up not being that practical. And then conversely, people write a lot of really practical ways of finding a lot of weird behaviors in their program, but then in the worst case, those methods can even be unsound because they don't have a rigorous theoretical footing.
00:44:13.158 - 00:44:23.300, Speaker A: We haven't yet really talked about the projects that you're actually working on and what it means to be a researcher in this space. So maybe you can share a little bit about that. What do you do every day?
00:44:24.150 - 00:45:35.014, Speaker C: So I've mainly been working on something called Klab, which can be understood as a debugger to proofs that you write in the K framework. So it allows you to know where your proofs go wrong. But it's also a little bit like a symbolic debugger for the EVM, and it's been tailored very much to our needs of verifying smart contracts in practice. And it also has a convenience for writing specifications of smart contracts. If we think of the K framework as a very general framework for analyzing programming languages in general, we can think of Klab, at least so far as taking the K framework and optimizing and providing some nice features in order to actually apply it to the verification of smart contracts. And that has all been developed in the effort of verifying the next iteration of the maker smart contracts. And so we're doing two things.
00:45:35.014 - 00:45:41.062, Speaker C: We're developing the tooling around that, and we're also writing the actual proofs for those smart contracts.
00:45:41.126 - 00:45:43.738, Speaker D: What are those smart contracts written in?
00:45:43.904 - 00:46:26.946, Speaker C: We actually have right now two implementations. We have an implementation in solidity and in solidity assembly. Over the course of the design phase of these contracts, there was a lot of different languages that were experimented with, and even writing handcrafted EVM bytecode was explored at some point. Or developing our own computer language that compiles down to the EVM that was called sick. That had a very interesting way of very concisely stating how storage should be updated. But now everything is being done in solidity. The main implementation.
00:46:26.946 - 00:46:39.606, Speaker C: I'm also experimenting a little bit with Huff. It's very nice. I think if we can write smart contracts in Huff and formally verify them, because then we should have really high assurances and really efficient gas costs.
00:46:39.798 - 00:46:41.980, Speaker A: Huff, how do you spell that?
00:46:42.350 - 00:46:51.646, Speaker C: H U f f. It's written by the aztec protocol guys. It's like a nerdy EVM type of hobby program.
00:46:51.828 - 00:47:06.450, Speaker D: For some reason. I thought that maker was doing some contracts in LL, but I can't remember who it is that's doing like a major thing in LL, which is admittedly a very OD choice.
00:47:07.190 - 00:47:09.742, Speaker C: Yeah. Weren't the ENs contracts written in Ll?
00:47:09.816 - 00:47:11.190, Speaker D: That might be it.
00:47:11.260 - 00:47:20.410, Speaker A: I had heard that the maker code, again, non Dev here, but I had heard that it was written in very OD language. Is there something special about their code?
00:47:20.560 - 00:48:13.958, Speaker C: Yeah, a lot of people really dislike the variable names, but so I think there are many various experiments that the development team has undertaking in order to really understand the core of what the contracts are and what they should do. So there's been a lot of experiments in different languages and different ways to express the platonic ideal of what maker should be. And now throughout that exploration, there's been a really nice design that has come out of it, a really minimal set of functions that really capture the essence of the behavior. And now the actual implementation of those essential design components are being done in solidity, plain old solidity with some interesting variable names.
00:48:14.054 - 00:48:52.758, Speaker D: I remember at one point a long time ago, someone wrote an EVM backend for Idris, and it was really nice to write smart contracts in because you had all the dependent types and you could do a bunch of cool stuff and get sort of halfway to formal verification by just writing your program in this. The problem was that the compiler output, something so grossly inefficient that even an ERC 20 contract would fill up a whole block or something, wasn't viable. But in your view, what would an ideal smart contract programming language look like?
00:48:52.844 - 00:49:55.302, Speaker C: That's a very interesting question, and first of all, it would be nice if we move away from the EVM and don't have to worry about this as a compile target. So already at WASM, things get considerably nicer, and it's more realistic to do any of these nice things. Then I think we should have some notions that have apparently become quite important for smart contracts as quite low level primitive notions of a language like linearity. In storage variables. For example, if you have a number at a location and you want this number to represent a value, then you should have really careful ways in which you can actually change this number so that the quantity remains the same. And there are some interesting projects that are working towards this. I think something that I discovered recently that I think is a super interesting smart contracting language is called TXVM.
00:49:55.302 - 00:50:23.234, Speaker C: Or there's actually now a confidential implementation called ZKVM. It's by the people that developed interstellar that seems to have at a very base level, object capabilities. So really rigorous tools by which you can specify who can access certain variables and the ways in which you manage authority, and then also notions of linearity baked in at a low level.
00:50:23.352 - 00:50:34.018, Speaker D: So a language with linear types in an OCAP model, probably with dependent types as well, and I would add pure by default.
00:50:34.114 - 00:51:13.970, Speaker C: Yeah, that'd be nice. I mean, if at least we're interested in the behavior of programs, all of those things make it really easy to reason about. Then again, I've recently developed more sympathy for imperative programming because it's so much easier to reason about the resources that they use. And if we're dealing with a system where resources are something that you can try to attack somebody by using up their resources, then it's really convenient to have languages or virtual machines where the resource usages comes out fairly directly.
00:51:14.310 - 00:51:59.460, Speaker D: I think this is an interesting, I don't see a lot of conversation around resource optimization from a compiler level. So I mean, obviously there are compiler optimizations, but there are optimizations that look like general compiler optimizations. But when we're dealing with smart contracts, we can do whole program analysis. We can take the entire program, evaluate its weak at normal form, and decide in a lambda calculus what this thing actually is. Haskell is like a terrible performance wise, obviously same thing with Idris. And why you can't just put a backend like an EVM backend on it, because it's made for a generic platform, it's not made for smart contracts and whole program analysis. I don't know.
00:51:59.460 - 00:52:21.850, Speaker D: It's an interesting thing. It's something I think a lot of us, obviously, as we move into WaSm world, we will need a new high level language as well. And both Ethereum and every other project is moving to waSm. So it'd be nice if we could have one shared vision of what a good high level language for a smart contract would be.
00:52:21.920 - 00:52:40.382, Speaker C: Yeah, definitely. We just need a language where we can analyze the resource usage, the behavior of it, and we want OCap and we want dependent types and we want everything. This is like a utopian language that we all have been trying to figure.
00:52:40.436 - 00:52:44.158, Speaker D: Out and also looks like JavaScript.
00:52:44.334 - 00:52:50.500, Speaker C: Yeah, that everybody can use without enwriting bug free code. This is the project.
00:52:52.230 - 00:53:08.510, Speaker A: Formal verification, as I understand it, fits somewhere in the security stack. There's a number of different ways that you will check code. Formal verification is one of them. Do you think that there are times where it's being used where you think it's a little bit overkill, where it's unnecessary?
00:53:08.690 - 00:53:36.270, Speaker C: Yeah, I think if there's not that much at stake, then maybe formal verification is overkill. When it comes to the methodology of assuring the correctness of programs. You catch a lot of things with tests or these automated tools. It's really just if you want the highest level of rigor and actually want this proof that your program always does as it is intended, instead of just figuring out whether it might sometimes fail.
00:53:36.350 - 00:53:59.654, Speaker A: Do sometimes people do it prematurely? Because I imagine if you've designed this spec and you've mapped this out and then you're running these tests and then something changes. You have to go and do it again. Or are you always kind of building alongside a project? Should the formal verification be there from the start or from the middle, or does it come at the end?
00:53:59.772 - 00:54:31.470, Speaker C: I think the specification should definitely be there from the start. I think you should, as you are writing your program, also say what you intend for it to do. And then maybe you shouldn't start trying to formally verify that the implementation actually does that because you haven't figured out the complete architecture yet. But I think writing specifications also help a lot in the design. So that's definitely something that you can do. But then maybe the verification can come at a later stage once things start solidifying.
00:54:31.550 - 00:54:39.222, Speaker A: Is it something that's continual or does it only happen? I picture this being a process, not something you do one time.
00:54:39.356 - 00:55:15.810, Speaker C: Well, for smart contracts, if you have immutable code, then you can definitely have some properties that you expect to always hold. There might be other properties that can change during the course of the lifetime of the contract there. You may have to continue to do it. Yeah, I feel like in the blockchain space there's a lot more of one time perfecting things or trying to make things as good as possible. And then once you need to update things, or if you ever do, then that is almost seen as a complete new variant of the whole system rather than an upgrade.
00:55:16.230 - 00:55:18.446, Speaker A: What's the future of formal verification?
00:55:18.638 - 00:56:01.230, Speaker C: So specifically for Ethereum, it's going to be very exciting. Once we transition to WASM. There are a couple of people, I'm sort of monitoring the whole thing and not that closely involved working on implementing WASM in K. So that would be to wasm as KVM is to the EVM. I'm going to call it kwasm. And if anybody is interested in helping out and doing this, then this is a good point of entry. And once you have that, you'll be able to apply the same methods that we're using right now to verify EVM programs, to verify EVM 2.0
00:56:01.230 - 00:56:41.310, Speaker C: or WASM programs. And this is of course nice because it's not only even Ethereum specific, this would be able to verify programs that are in Webassembly for any purpose. And then there would need to be some tinkering to make sure that we can actually verify smart contracts written in WASM because that will also look slightly different than just pure waSm. So that's one thing. And then in general, we are always working on the tooling around everything optimizing backends, switching out parts and rewriting everything. In Haskell, that's generally the methodology.
00:56:41.650 - 00:56:46.320, Speaker A: Who is we? Is it you at maker, or is it a larger community?
00:56:47.890 - 00:56:53.306, Speaker C: When I say we in this context, I mean open source and free software developers.
00:56:53.498 - 00:56:56.260, Speaker A: What's a formal verification crew like?
00:56:59.430 - 00:57:23.980, Speaker C: It's people. Well, that's a good question. They're very precise and are very good at arguing for their cases. They share some tendencies with mathematicians, and some tendencies of mathematicians that I really enjoy is that they sometimes take a really long time to think about what they want to say before they say it.
00:57:24.670 - 00:57:50.130, Speaker D: One thought or curiosity I just had is when you talk about KeVM and Kwasm and all of these things existing, you've defined the operational semantics. Can you use that to then formally verify the interpreter? So, can we get formal verifications of the parity EVM implementation and the Geth EVM implementation?
00:57:51.990 - 00:58:15.050, Speaker C: Not really. That would be if we wanted to verify the clients, then we would need to instead work with the operational semantics of the language that this client is written in. Of course we can do other things like run test suites together and make sure that we get the same result. But I wouldn't call this formal verification.
00:58:15.550 - 00:58:26.400, Speaker D: Right. And the platform they're targeting is everything, so it's kind of hard. Like it's arm and x 86 64 and everything else.
00:58:27.810 - 00:59:26.882, Speaker C: Yeah, but you can already say quite a few things about programs written in C plus plus or in Python, or in JavaScript, just by trying to understand the language as it is defined, rather than the implementation of this language in some lower level machine code. So it would be feasible. And sometimes this is something that we joke about when we speak about verifying EVM bytecode, that we should really not be verifying EVM bytecode as according to KVM or to the yellow paper, we should be verifying EVM bytecode as it is being evaluated by the clients. So that means that we should have a model of rust and the parity clients, and how the parity clients interprets EVM in order to really understand how parity clients will react to a certain smart contract. But actually we just assume that they are reasonable in some sense.
00:59:27.016 - 00:59:33.250, Speaker D: Yeah, I think that's an okay basic assumption, but it does happen every once in a while that there are disagreements.
00:59:33.750 - 01:00:22.430, Speaker C: So there's actually a little bit of a movement right now in trying to make kvm into the canonical spec defining EVM so that the KVM would replace the yellow paper. Sometimes people refer also to the KVM as the jello paper for some reason that I don't really understand. I think this is a great movement, because really, whenever I wonder something about the EVM, it's a lot easier to look it up in the K definition of the Ethereum semantics than read it in the yellow paper. And also the yellow paper has sort of drifted into this void where sort of unclear who maintains it. Yoichi had a huge part in maintaining the yellow paper, and now it's not that frequently updated.
01:00:22.510 - 01:00:58.960, Speaker D: Yeah, the difference is, like, the yellow paper is specified in English, KVM is specified in K. It will appeal differently to different people. I think we should have both. I'm sort of torn on creating. Yeah, maybe there should be one canonical thing that we all trust, and then update the other things after that. But I feel that it is important to have an english prose definition of it as well, but it needs to be maintained, and that just hasn't happened in the past. And I know one guy, parody stepped up to try to maintain it, but I don't know if he actually has time.
01:00:58.960 - 01:01:25.590, Speaker D: It's difficult to find someone who's actually willing to put in that kind of grunt work. And there's been proposals as well, that every EIP that modifies the EVM has to come with the updates to all the specs and all the sort of things to actually be accepted. I think that's almost the way to go. Put it on the EIP creator to do the maintenance.
01:01:26.090 - 01:02:04.366, Speaker C: Yeah, I think a lot would be gained just from a major rewrites of the yellow paper to make it more accessible or more readable generally. I mean, it is good because it is very specific, but it really could have been written a lot nicer and still be as specific and still be as clear. Yeah, I do see the value of also having an english specification or a latex specification and a bunch of formulas. And it's kind of hard to say what should be the official or the canonical spec. I don't know who has the authority to endorse.
01:02:04.398 - 01:02:09.798, Speaker D: I don't think there necessarily needs to be one. But all of them need to agree in some way.
01:02:09.964 - 01:02:10.726, Speaker C: Yes.
01:02:10.908 - 01:02:16.390, Speaker A: Could you go backwards? Could you go from K framework interpretation to English?
01:02:16.730 - 01:02:35.566, Speaker C: Yeah, you could do this. The K spec is actually written in a literate style, so it's a big markdown document with some code blobs. It is actually quite readable already in a lot of English already.
01:02:35.748 - 01:02:42.718, Speaker A: So I want to say thank you for coming on the show and helping us to explore this topic. What do you recommend people do if.
01:02:42.724 - 01:03:01.814, Speaker C: They want to get involved so one thing that they can do is to get on the forum that I hang out with. If they want to talk to me specifically, which is Daphub chat. And if you want to read need more about KVM or the K framework, then I can provide some links for sure.
01:03:01.852 - 01:03:02.994, Speaker A: We'll put them in the show notes.
01:03:03.042 - 01:03:03.846, Speaker C: Yeah, cool.
01:03:03.948 - 01:03:04.790, Speaker B: Thank you very much.
01:03:04.860 - 01:03:05.638, Speaker C: Thank you, guys.
01:03:05.724 - 01:03:08.082, Speaker D: And to our listeners, thanks for listening.
01:03:08.146 - 01:03:08.770, Speaker A: Thanks for listening.

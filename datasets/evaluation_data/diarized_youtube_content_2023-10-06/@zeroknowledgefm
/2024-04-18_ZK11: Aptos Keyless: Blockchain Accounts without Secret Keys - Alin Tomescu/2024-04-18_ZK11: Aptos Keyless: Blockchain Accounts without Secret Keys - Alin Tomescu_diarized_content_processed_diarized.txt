00:00:08.400 - 00:00:40.736, Speaker A: So, my name is Aline, I'm the head of cryptography at Aptos Labs. And today I want to tell you about Aptos Keyless accounts, which are blockchain accounts that avoid the use of secret keys. And what they base their security on is a traditional web two account, like your Google account or your Facebook account or your Apple account. So let's get started. But before we do, I want to say this is joint work with the core team at Aptos Labs, the core keyless team. Michael and Rex should be in the audience and you can meet them today. Michael designed our circuit.
00:00:40.736 - 00:01:18.164, Speaker A: Rex audited it and worked on the prover service and also the broader Aptos Labs team and the folks at Geometry Research, some of them in the audience right here, who helped us secure the ZK circuit. So what is a keyless account? Well, it's just the way I think about it. Your blockchain account is your Google account. There are no user managed secret keys. And as a result you get many goodies, which I'm going to mention throughout the talk. And in this talk, when I say Google, I want you to think Facebook, I want you to think GitHub or any OpenID connect provider or OIDC provider. But for simplicity, I'm just going to say Google.
00:01:18.164 - 00:01:54.644, Speaker A: So why do this? Why enable keyless account? The short answer is we want to onboard the next 1 billion users. We don't think this is going to happen if every time a user enters a space, they have to write down 24 words and put them somewhere more safely and lose them and then never engage with the space again. So if we're going to get people in the space, we need to find a way for them to join the space very easily. So if you think about the current user experience of using a dapp or a web3 application, you have to install a wallet. What the hell is a wallet? Users are very confused. They have to write down this mnemonic. This is very cumbersome.
00:01:54.644 - 00:02:24.228, Speaker A: It's very easy for them to lose this mnemonic and lose their money. They have to deal with transaction prompts. What the hell is a transaction prompt? Most users don't know, and it's very painful to move your device, to move your account from your laptop to your mobile phone to your tablet. So what we want is kind of the opposite. We still want wallets, but we want the possibility of being wallet less. We want users to directly sign up for the app without installing extra software. We don't want users to write down mnemonics.
00:02:24.228 - 00:02:53.264, Speaker A: That's just painful. Nonetheless, we still want the account to be very hard to lose, and we'd like to avoid transaction prompts if possible. And we'd also like for things to work across device. Additionally, we might also want other goodies, like we might want KYC via the OIDC provider. We might want to be able to send transactions directly to an email address. That would be great. So that's what I'm going to tell you about in this talk, how to enable all these things.
00:02:53.264 - 00:03:35.084, Speaker A: So how do keyless accounts work? At a really high level, there's four things I want to say here. So first, a keyless account, its address is derived from two things, your email address and the application id of the wallet or the dapp you're using. So that means these accounts are app specific. So they're associated with a Dapp like Dapp XYZ, or they're associated with a wallet like metamask. And this is what prevents a malicious website like Medium.com from stealing your keyless account associated with Dapp XYZ. The fact that you have this Dapp specific binding, and this is also what allows for wallet list dapps.
00:03:35.084 - 00:04:04.360, Speaker A: The fact that we have this binding. Now a keyless transaction signature. The way this works is it's really the same thing as an OpenID connect signature from the provider. And really it's a zero knowledge proof of knowledge of such a signature for privacy reasons. And the signature from Google is over a couple of things, the transaction hash, your email address and the application id. And lastly, we add a splash of zero knowledge for privacy. So we want to hide a couple of things.
00:04:04.360 - 00:04:45.214, Speaker A: We want to hide the email address and the application id from the chain, from the full nodes, validators, everybody. But we also want to hide transactions from Google. We don't want Google to be able to track which email addresses are associated with each blockchain addresses and which transactions are associated with an email address. So at a high level, this is the picture. Next, I want to go a little bit deeper and actually show you some details. So let's start with the OpenID Connect protocol and how applications register in this protocol in order to get a client id, a so called client id. So if you have an application like Median.com
00:04:45.214 - 00:05:14.950, Speaker A: or Dapp XYZ, you go on the Google Cloud console, for example, and you register it in there. And at the end of this sort of map process, you get a so called client id. So this will be the application identifier that I mentioned before, which is committed in your address, and it's also signed by Google when it signs your transaction. Right. So that's the first step. So now that the application is registered, let's see how kind of OpenID connect flow works. So you're all familiar with this because you've all used websites that asked you to sign in with Google.
00:05:14.950 - 00:05:56.784, Speaker A: So this is what happens when you use those websites. You go to the app and the app displays to you this prompt by redirecting you to Google and in the URL that the app redirects you with, you actually have a few parameters in there. So you have this client id that I mentioned before, which is the identity of the application. And very, very importantly, the application can specify any arbitrary data to Google. And what Google will do when you sign in with your cookies is it'll send the app this signature. And the signature will be over three things. Your email address that you successfully logged in with the app's identity, and this arbitrary data that the app included.
00:05:56.784 - 00:06:24.034, Speaker A: Right. And this, of course, this arbitrary data here will be very important because guess what? That arbitrary data will be a transaction. And this is how we're going to get Google to sign your transactions for you. And this is how we're going to make the account be keyless. And what's worth emphasizing here also is that this is a digital signature, right? So this is publicly verifiable. So anyone who has Google's public key can take the signature and verify it. So now here's a couple of observations.
00:06:24.034 - 00:07:14.262, Speaker A: What if this third party verifier is a blockchain? And what if the application is a wallet or a Dapp? And what if the data being signed is a transaction, right? Then you're basically looking at the keyless picture. If you get one thing from the stock, it's this slide. This is basically 90% of the picture. The next part of the talk, I'm going to refine it a little bit since we're going to need to deal with privacy. The way it works is your wallet will sign you in and then you want to send a transaction for your address, and you will include this OIDC signature from Google together with the application id and your email address. So far, this is not privacy preserving. We're going to fix it in a second.
00:07:14.262 - 00:07:57.454, Speaker A: And you can send this to the blockchain validators. And what the blockchain validators can do is they can verify the signature like I showed you before, because they have your email address, they have the client id, and they have the transaction. And additionally they're going to match that the address you included in the transaction is indeed associated with the account in the signature. Right? So they're going to verify, for example, the addresses, the hash of the email address and the client id, right? So far so good. But there's a problem. You are revealing in plain text your email address and the application id, and in particular the email address is very worrisome. But even the client id could be problematic if you reveal it because it leaks which applications are doing what.
00:07:57.454 - 00:09:05.601, Speaker A: So we gotta fix that. And obviously the very trivial fix is to just throw a zero knowledge proof at it, right? So instead of giving all of this secret witness like the client id and the signature and the user email, we're going to move it inside of a zero knowledge proof and we're going to do all of the work inside the zero knowledge relation here. So this is a zero knowledge proof of knowledge of an OIDC signature and an email address and a client id such that the OIDC signature verifies over the public input public key and over the public transaction input, right, and such that the public address input is derived from the secret email address and the secret client id. So from the blockchain validator's perspective, all they see is an address and a transaction and Google's public key. And this proof assures them that there is an OIDC signature over the email address inside the blockchain address. Right, and the client id and over the public transaction. Okay, so this is again a very, you know, it looks very simple when you put it on the slide.
00:09:05.601 - 00:09:25.846, Speaker A: It's very hard to implement, but it's a very simple change. You just throw a zero knowledge proof at things. This is what we like to do in this community anyway. Good. So there are some complications with the zero knowledge proof. It takes I think about 30 seconds to compute in the browser. So if we're going to use this for our users, it's going to be very bad ux.
00:09:25.846 - 00:10:07.854, Speaker A: So we'd like to speed it up. So we have to rely on a prover service which is going to make the computation of the zero knowledge proof much faster. We can compute it in under 2 seconds, but it's going to have some privacy implications and we can talk about those later because in particular the prover service will learn the secret witness or learn the email address and the client id. Nonetheless, I should say it's very important to emphasize here that the prover service cannot steal your funds. I'll describe that in a second as well. Nonetheless, there's still more problems left. So as you can see here, Alice has to compute one ZKP per transaction and the blockchain has to verify one ZKP per transaction.
00:10:07.854 - 00:10:37.854, Speaker A: So we don't like that for performance reasons. So the way to fix that is using a layer of indirection. That's every problem in computer science can be solved with a layer of indirection. So what Alice is going to do is she's going to generate an ephemeral key pair. Let's see. Right, I have an ephemeral key pair here, Esk and an EPK. And next, what we're going to do is instead of signing the transaction, we will give Google this EPK to sign.
00:10:37.854 - 00:11:05.868, Speaker A: And in the transaction signature we will include an ephemeral signature over the transaction under this Esk. Right. And then the blockchain validators can simply verify this ephemeral signature. So we've added a layer of indirection. So now you can think of the ZKP as a certificate for this ephemeral public key. And the transactions are signed by the ephemeral public key. And this signature verification is in plain text.
00:11:05.868 - 00:11:25.974, Speaker A: Right. The validator see an ephemeral public key and a signature on the transaction. There's no privacy loss there. And notice that although there is a key here, these keys are ephemeral. You can lose them, it doesn't matter if you lose them. You sign back in, you generate a new Esk and Google will gladly sign it for you. So they're not sensitive from a loss perspective.
00:11:25.974 - 00:11:53.672, Speaker A: And for those of you who are familiar, this keeper can actually be a Webauthn passkey keeper. So this way you can actually be very secure that it won't, it won't be stolen. Right. If it's backed up in your iPhone's enclave, let's say. Still we have more problems. The address that is stored on chain is a function over the email address and the client id. So it obviously leaks.
00:11:53.672 - 00:12:20.728, Speaker A: An attacker can brute force your email address and the client id and tell who you are on chain. So we want to fix that too. And the very simple fix there is to just make the address be a commitment rather than a hash of the email address. Right? So we're going to use a blinding factor for that. We call this blinding factor a pepper. These are just random bits. Now if we did this naively, the user would have to pick those bits and remember them.
00:12:20.728 - 00:13:01.442, Speaker A: And if the user loses those bits, then they can no longer access their account. So that would defeat the purpose of this whole approach because the whole point is we want to avoid storing long term secrets. So instead what we're going to do is we're going to have a pepper service that's going to help users remember their pepper. So the way this will work is the pepper service will evaluate a verifiable unpredictable function over the email address and the client id and that defines the pepper in the blockchain address associated with these two. And this actually makes the pepper service a very simple service. It just has to store a 32 byte VUF key like a BlS key. And it's also very easy to decentralize.
00:13:01.442 - 00:14:01.314, Speaker A: So you can have a decentralized pepper service with 20 servers that just computes a threshold signature for the user to get the user the pepper. And of course there's an access control issue because the pepper service better not give my pepper to somebody else, it better only give it to me. And the way we actually guarantee access control is also via the OpenID connect protocol because the pepper service can actually verify these signatures from Google before giving you your pepper. So that's the good news about the pepper service. And right now the pepper service is not privacy preserving, but we can actually make it privacy reserving as well. So the pepper service could in principle receive a zero knowledge proof of knowledge of an OIDC signature and a blinded hash of the email address and the client id and evaluate the BLS signature over that blinded hash so that it doesn't even learn which user it's computing the pepper for. We haven't done that yet, but that's planned for the future.
00:14:01.314 - 00:14:33.604, Speaker A: Good. So next step is one last tiny detail is that Google will actually see this EPK here in the nonce. Right. And if it can see this EPK, then it can track transactions on chain. So now it knows which user is doing which transactions. This is also a very trivial fix. Instead of putting the EPK in the OpenID connect signature, we're going to put a commitment to the EPK using some different blinding factor r which is part of the secret witness of the ZKP.
00:14:33.604 - 00:15:05.916, Speaker A: And basically we're done. That's the design. This is it. So if you get a second thing from this talk, it's this picture right here, which is the complete privacy preserving story with the pepper service and the prover service for performance. All right, for the next part of the talk I just want to mention some things about our implementation. So when we built this, because this is a layer one primitive, right. We are putting these kind of keyless signature on our transactions.
00:15:05.916 - 00:15:35.264, Speaker A: We have some pretty aggressive performance goals. So we want the verification time of such a keyless transaction to be very small, and also the proof size, the ZKP, to be very small. In particular. This is kind of stringent if you think about it, because if an attacker puts bad zkps in your transactions, you have no recourse like you're going to get dosed. Because if the ZKP fails to verify, there's no account that you can charge gas to. There's nothing you can do. So you really have to make the implementation fast.
00:15:35.264 - 00:16:19.034, Speaker A: So our only choice was to do grot 16 over a fast curve of BN 254 and to implement the relation. In grot 16 we use circum we have 1.3 million r one cs constraints, and our code is actually public. We invite you to look at it, we invite you to build over it. It's in a way very related to the ZKE email work that you've seen before, and some previous work on verifying jwts in snarks. And what's interesting about our circuit is that we have some new polynomial based protocols for doing substring matching in a circuit which is otherwise very complicated to do and very expensive to do, I should say. So this is what helps us achieve a small number of constraints.
00:16:19.034 - 00:17:01.360, Speaker A: We did an NPC ceremony for the circuit, we used potion, fixed a couple of bugs in it, and we had 140 participants over the duration of one week. And our prover service is implemented via a hardened version of Rapidsnark, which is a c code base. It's really fast. The only thing faster than rapid snark that I could find is maybe GNarC, but I couldn't manage yet to benchmark our circuit in gnarc because we have to take our circumcircuit and put it in gnarc. If any of you know anything about that, please talk to me. Our pepper service is just a rust based service that uses bls to evaluate the peppermint. And that's it, that's our implementation.
00:17:01.360 - 00:17:39.474, Speaker A: So to conclude the talk, I think UX is key for blockchains and Goodux is keyless. So open source code base please take a look at our rust validator code at our repo, at our MPC trusted ceremony and prover service. I think n pepper service are all public. We have a test deployment active on the Aptos blockchain. This is deployed in Devnet and in Testnet, and will be coming to mainnet pretty soon. It's also already been used in the Aptos random hack where we've seen a few projects build on top of it. So that's very exciting.
00:17:39.474 - 00:18:10.566, Speaker A: And if you want the nitty gritty details and all of the security implications and details, you can find them in an Aptos improvement proposal that I wrote. There's a pr open. There's a couple of more things to address there. Future work. I think this kind of approach raises some interesting questions about what kind of OIDC providers would you be willing to trust with your blockchain accounts. So this approach is not to say that all users should use it. It's probably for 90% of users who are novice.
00:18:10.566 - 00:18:48.764, Speaker A: Right. But even for those users, maybe Google is not the right choice. So maybe there's an opportunity here to think about identity providers for blockchain users. And maybe there's even a business space in that. We want to try and move the pepper service on top of the validator so that it's as secure as our validators as well as making it privacy preserving. We also want to try to potentially move the trusted setup on top of our validators so we can easily bug fix and upgrade our circuit, or ideally move to a universal snark that meets our performance goals. And obviously we want to work on faster proving to eliminate the prover service.
00:18:48.764 - 00:19:18.714, Speaker A: And there's a lot of cool features that I did not get to discuss. I'll leave them here for you. And also a lot of nuance and details. In particular, this ephemeral public key that I mentioned actually has an expiration date. It doesn't live indefinitely and there's implications around DAPP specific accounts that you have to deal with. And there's implication around wallet list Dapps that you have to deal with. And just this JSOn web token stuff, this openID signature format and how we deal with it in our application.
00:19:18.714 - 00:19:24.434, Speaker A: But that's it. Thank you so much for your attention and would love to get lots of questions.
00:19:28.454 - 00:19:34.034, Speaker B: Thank you. Do we have any questions? There's a microphone. Do you know the system by now? Okay.
00:19:36.614 - 00:19:45.544, Speaker A: It'S coming up. All right, fantastic. Thanks. Great talk. I had a question about malleability and whether it's an issue here. So. Great.
00:19:45.544 - 00:19:59.036, Speaker A: So there was the intuition. I'll wait for the slides. Yeah. Can I get the slides back? Yeah. Malleability was actually, I think, in the list of it was. Sorry, I blanked to the point and I apologize. Yeah.
00:19:59.036 - 00:20:28.638, Speaker A: So we deal with it in a very simple way. We get non malleability by signing the proof with the ephemeral secret key, which is a non malleable signature as well. That's how we got non malleable. And yeah, we were worried about it. In principle, all of our transaction signatures are non malleable because we don't want people to worry about malleability. So this solves the problem of malleability of the grot 16 because the ephemeral signature itself is non malleable. And then there's just grot 16.
00:20:28.638 - 00:20:39.594, Speaker A: And then you have to be careful that other things like metadata next to the ZKP and the ephemeral signature is not malleable. As far as we know, it's not. But if you want to take a look at our code. Thanks. Thanks for the answers.
00:20:41.394 - 00:20:51.214, Speaker B: Okay, any other questions? Yes. In the back there's a microphone down on the chair. Just press the button.
00:20:54.794 - 00:20:56.134, Speaker A: Sometimes they don't work.
00:20:56.594 - 00:21:08.124, Speaker C: Now you can hear. Okay, so I wanted to ask what's your censorship resistance model? And more specifically, what's the fallback in case the signature provider goes down or doesn't want to provide the signature for a specific user?
00:21:08.864 - 00:21:10.040, Speaker A: I couldn't hear you very well.
00:21:10.072 - 00:21:12.776, Speaker B: Could you put the mic, can you put here?
00:21:12.840 - 00:21:26.976, Speaker C: Is it better? Okay, so I'm going again. What's your censorship resistance model? And to be more specific, censorship. What's the fallback in case the signature provider doesn't want to provide the signature specific user or anyone else?
00:21:27.120 - 00:21:42.754, Speaker A: Yeah, that's a very good question. So there's a few ways to deal with that. So at a fundamental level, you want to pick OIDC providers that you have recovery mechanisms for in case they stop playing ball.
00:21:44.414 - 00:22:01.342, Speaker C: That doesn't answer the question though, because any provider can go down any day. So if I have an account in an app using a keyless model, that means if the signing provider goes down for any reason or doesn't want to give a signature for my user, for example, that means that I lose everything.
00:22:01.478 - 00:22:23.542, Speaker A: Yeah. Correct. So if you have a bad provider, that's bad for you. You don't pick bad providers, you would pick really trustworthy providers. I think the only risk here is that the provider probably says, look, I don't want to have to do anything with blockchain applications. So any client id that is a wallet or a Dapp, I'm just not going to provide signatures for. And in that case, you need a recovery mechanism for your users.
00:22:23.542 - 00:22:50.796, Speaker A: And there's two things that we can imagine doing. One thing is we can use, for example, the ZKe email approach to recover your account if you've been to their talk. So basically you can send an email from your Google account which has a signature from Google and that email can authorize a key rotation for your keyless account. So that would be okay. It would be kind of user unfriendly, but in principle it would give you back access to your funds. Another way would be to have a recovery service. So a recovery service with its own client id that users log into.
00:22:50.796 - 00:23:19.078, Speaker A: And the only thing this recovery service does is it rotates your key. So maybe Google stops playing ball, but it allows this recovery service to help users recover. So those are two things that you can do. And in general, that's what I mean by Uanto, IDC providers that admit recovery mechanisms. So let's say you use Twitter, you could use a public tweet to rotate your account to a new public key if you had an HTTP oracle on chain. Right. That's another recovery mechanism for another provider.
00:23:19.078 - 00:23:23.514, Speaker A: I hope that answers your question, but I'm happy. Yeah, we can also talk after.
00:23:24.254 - 00:23:33.074, Speaker B: There's a microphone on the ground. Do you see it should be red light.
00:23:38.174 - 00:24:10.238, Speaker A: Yeah, sometimes they don't work. Okay, thank you. So you have mentioned that you are using proving service in your application, correct? Is it trustworthy or to which degree is it trustworthy? I suppose I fail to emphasize that. Not sure what happened with my slides. It's trustless. So if you think about it, the prover service gets this OIDC signature over an EPK, right. It doesn't know the associated Esk to sign transactions with.
00:24:10.238 - 00:24:39.440, Speaker A: So the prover service simply, you know, you lose privacy with respect to the prover service. But there's ways to deal with that. You can MPC the prover service and in fact, snarks like grot 16 admit very efficient MPC protocols. But you know, that's the only problem. Privacy, which is addressable. Stealing your account is impossible because the proofer service doesn't have the ESk and it cannot get a new IDC signature over an EPK whose esk it knows. Right? Does that make sense? Yeah.
00:24:39.440 - 00:24:40.324, Speaker A: Thank you.
00:24:43.064 - 00:24:57.384, Speaker B: Any other questions with the front? Okay, we have time for a couple questions. I'll just take this one. Does the pepper service generate the peppers or stores them too?
00:24:57.504 - 00:25:16.956, Speaker A: Yeah. Good. So I mentioned in the talk that the pepper service is using a verifiable, unpredictable function to generate a pepper given an email address and a client ID by simply evaluating a VOF over them. An example of a VUF is a deterministic signature scheme like BLS.
00:25:17.100 - 00:25:20.944, Speaker B: Why couldn't users do that themselves? Is it too expensive for everyone?
00:25:21.404 - 00:25:24.492, Speaker A: Well, they would have to remember it if they did it that themselves.
00:25:24.588 - 00:25:26.824, Speaker B: So it does store it or generates.
00:25:27.444 - 00:25:39.488, Speaker A: It only stores the secret key of the VUF. So that's 32 bytes. And from that secret key and an email address and a client id, it can derive the pepper without ever having to store it.
00:25:39.636 - 00:25:43.404, Speaker B: But what happens if the pepper service fails?
00:25:43.784 - 00:26:03.680, Speaker A: If the pepper service fails, then users are locked out of their account if they don't have their pepper. Right. So it's very easy to mitigate against that. So one way is for users to back up their peppers if they're paranoid. But we don't like that. Another way is to actually decentralize the pepper service and make sure the key is never lost. What you want to ensure is that the secret key of the pepper service is not lost.
00:26:03.680 - 00:26:24.454, Speaker A: Now maybe, you know, the top 2% of users might just generate their own peppers and they won't use the pepper service. I don't think that's realistic for 90% of users, but some subset of users might want to. In general, we're not very worried about the secret key of the pepper service getting lost because it's really easy to protect the key for getting lost.
00:26:24.794 - 00:26:31.254, Speaker B: Ok, thanks. So many questions. It's good thing your presentation was shorter.
00:26:33.144 - 00:26:45.656, Speaker D: I just wanted to connect to what was saying the person before. So you say that the prover, you have kind of no privacy to the prover, but then since the secret key is in your possession, then you know, we cannot cheat in reality.
00:26:45.760 - 00:26:46.064, Speaker A: Gross.
00:26:46.104 - 00:26:58.024, Speaker D: 16 proofs can be, are malleable in itself. So the prover can re randomize them to embed tagging information in the proof itself and then the user will sign and will go. So.
00:27:00.964 - 00:27:05.940, Speaker A: 1 second, let me just. Okay. You're saying a malicious proverb.
00:27:06.052 - 00:27:15.500, Speaker D: Yeah, because if the malicious prover has access to the email address, it can somehow embed it embed via randomizing the proof and until some bytes match, like grinding through proof. Yeah.
00:27:15.572 - 00:27:31.406, Speaker A: And that's a really interesting. Yeah, I like that. That's interesting. I would say the way to mitigate against that is probably the same way you would mitigate against the privacy issue by NPC and the prover service, which would fix that. But yeah, actually we haven't considered that. I really like it. Thanks a lot.
00:27:31.470 - 00:27:32.238, Speaker D: We can discuss later.
00:27:32.286 - 00:27:37.994, Speaker B: Yeah, did we have another question here? Cool. I think that's.
00:27:40.054 - 00:28:17.846, Speaker A: Hi, can you derive public address from email address? Like if I want to send some funds to someone who hasn't used the service. Correct. So what you could do if you wanted to send funds to someone that isn't signed up is you could derive an address for them. So let's say you want to send funds to Alice on some wallet or some pay application. Like let's call it pay to email, right? So pay to email has a client id, you know it and you know Alice's email. And then you just pick a pepper for Alice, you pick it for her, you pick random 256 bits and then you email Alice. Hey Alice, I send you funds.
00:28:17.846 - 00:28:57.080, Speaker A: Here's the pepper for your address. Alice can rederive the same address and can sign in with Google into the application and obtain an OpenID signature, engage the prover service, get a ZKP, and as a result get access to those funds. But the only difference in this case is that you're not using the pepper service. Alice is simply using the pepper that Bob picked to pay her. Is the pepper choose by Bob or just Bob initiated the pepper service? No, it would be chosen by Bob would probably be the best way to do it. But you could also imagine that the pay to email application could. When I say chosen by Bob is really by that application.
00:28:57.080 - 00:29:23.866, Speaker A: Right. And then that application would email Alice with the pepper. Or maybe you would create a link and embed the pepper in the link. And Bob can't use this pepper to gain an advantage of this account. No. So remember that there's two things you need to access this keyless account for Alice. You will need the pepper because you will need to do the address match.
00:29:23.866 - 00:29:32.134, Speaker A: But you're also going to need an OIDC signature from Google and Bob is not going to be able to get that OIDC signature because he doesn't control Alice's Google account.
00:29:36.954 - 00:29:42.090, Speaker B: Okay, I think that's all we have time for. So thank you so much. Aline, another round of applause please.
00:29:42.242 - 00:29:43.474, Speaker A: Thank you so much for the questions.

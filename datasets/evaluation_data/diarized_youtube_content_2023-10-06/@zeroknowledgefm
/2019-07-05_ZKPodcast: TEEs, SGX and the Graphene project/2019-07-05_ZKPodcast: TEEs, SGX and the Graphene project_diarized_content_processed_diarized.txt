00:00:06.330 - 00:00:18.750, Speaker A: Welcome to Zero Knowledge, a podcast where we explore the latest in blockchain technology and the decentralized web. The show is hosted by me Anna and me Frederick.
00:00:26.730 - 00:01:23.430, Speaker B: In this episode, we sit down with Lukash from Golem and Chai Cha from Texas A M to talk about trusted execution environments and the graphene project. Before we start, we want to say thank you to this week's sponsor. Apograph Apigraph is a project that's built an extensive collection of open access research papers on cryptography, distributed computing systems, and blockchain. The team behind apograph see the high price put on the world's best research as a hindrance to scientific progress. And so their platform is designed to break down barriers, reward researchers, and promote open science. They start by offering unique content from technical conferences and course material from leading universities. Through an integration with their orchid registry, contributors can develop and establish a professional profile based on their entire body of work on a single platform.
00:01:23.430 - 00:01:39.930, Speaker B: If you're a researcher who would be interested in such a system, find out more at welcome apograph IO, or check out the link in our show notes to a curated list of cryptocurrency course materials. Thanks again to apograph and now our episode with the guys behind Graphene.
00:01:43.250 - 00:02:11.062, Speaker A: So today we're going to have a conversation about tees. This has come up, I think, a couple times on the podcast, but we've never really delved into it. And today we have two guests who can really help us do that. First, we have Lukesh, who is the R D lead at Gollum. And we also have Chai che, who is an assistant professor at Texas a M university and was the original researcher and author of the graphene paper, which is something we're going to talk about as well. Hi, guys.
00:02:11.196 - 00:02:11.542, Speaker C: Hi.
00:02:11.596 - 00:02:12.150, Speaker A: Hello.
00:02:12.300 - 00:02:13.046, Speaker D: Hey.
00:02:13.228 - 00:02:26.842, Speaker A: And of course, we have. I mean, that was a very brief intro. I think it would be really great to hear a little bit more about what you guys are up to, what you're working on, and maybe a little bit about your background. Lukesh, why don't we start with you?
00:02:26.976 - 00:03:28.302, Speaker D: I'm a leader of R D team in Golem, and also I am a product owner of a graphene team in Golem. Also, my priority interest is research and tes and moving Golem into the innovative areas like tes, which is, I think, very great. And in future it will be a very popular area for many users. I'm a a phd. My interest is very theoretical, but as a professional job, I'm a developer for too many years in Golem. We are starting to create a decentralized marketplace when people can share their unspert power to others, and other people can access the external power source of computational power in order to empower the application.
00:03:28.436 - 00:03:46.318, Speaker A: Cool. I think as we continue our conversation, we're going to find out a little bit more why the work of Golem sort of led you to experimenting with tes and wanting to work on it. But I think first we should hear a little bit from chai. Chai, can you quickly tell us who you are and how you got into this space?
00:03:46.504 - 00:04:23.950, Speaker C: Right now I'm an assistant professor in Texas m University. I just started teaching this year. I've been doing research in mostly an operating system area and security area. So one habit of mine is basically I like to dig really deep into the system. So if I look at application, and then I could have solved the problem, I go into deeper and deeper. So that's why I really find things like hardware, especially security hardware like tee, really fascinating because it was sort of solving a problem for the fundamentals. And so my history with Tee is we started working on graphing project.
00:04:23.950 - 00:04:43.190, Speaker C: And graphing turned out to be a really good fit with tee. So at the time there is sort of a conversation like, hey, we should start doing te. And intel was really interested in this technology. And so I said, okay, why don't I just go there and do an internship? And it turned out that's where all, everything started.
00:04:43.340 - 00:04:55.898, Speaker B: So I think before we dig any deeper into this episode, we should start out by defining what a te actually is. So maybe first and foremost, what does Tee stand for?
00:04:56.064 - 00:05:46.950, Speaker C: I think TE in general would stand for trusted execution environment. It's usually describing a hardware that's designed for bootstrapping your trust. So when you put an application on the platform, you don't necessarily trust the platform, you want something to help you start with that trust, and that is that hardware. And it actually has a very long history. It start with things like trust processing model TPM, and it also start with other kind of environment. For example, ARM has their things called trust zone, which is basically environment that you isolate your application away from other application, and also a trust operating system. Basically the whole technology has growed until we hit a point where have things like withdraw to not trust anything beside your application and your hardware, which is the birth of SGX.
00:05:46.950 - 00:06:00.510, Speaker C: And there's also a few technologies coming out after SGX, including Arm, AMD. They all have their own version of it. There's also open source version from RisFi right now. And basically this is a trend that's going on.
00:06:00.580 - 00:06:12.322, Speaker B: What would the use case be for? Like you mentioned, these early projects like tpms, what were they used for and what are the use cases that have demanded that this scales up?
00:06:12.456 - 00:06:21.014, Speaker C: So usually I'll separate into two domain. One is on the desktop or on a personal computer, or what we say in the client end.
00:06:21.052 - 00:06:21.542, Speaker D: Right?
00:06:21.676 - 00:06:53.334, Speaker C: Usually you want to start some execution that's really sensitive. For example, one very common example is the digital rights management. Let's say you have some kind of video that is copyrighted, you want to ship it to user's machine, client's machine, you want to encrypt it and send it there. You have this key that you want to protect. Then you can use these either TPMs or SgX to make sure this enclave was shifted to a platform that is secure, that would not leak your secret.
00:06:53.402 - 00:07:03.102, Speaker A: That's an amazing example. You just mentioned SGX a lot. We haven't really defined that. We've defined tees. So SGX, that's a type of tee.
00:07:03.166 - 00:07:38.474, Speaker C: So SGX is definitely one type of te. It's basically introducing a technology, what we call hardware enclave. So the idea of enclave is, if you heard this word enclave is basically, usually we say a cultural enclave is an area where people live in and they were isolated from the rest of the world. So the same thing as hardware enclave as you run some program on your computer and that was completely isolated from the rest of the computer. So you don't have to worry about operating system being compromised or other I O device being. It's actually very strong guarantees of security. So SGX's step was software guard.
00:07:38.474 - 00:07:51.490, Speaker C: Extension is an extension that come out recent intel cpu. If you have like ifi I seven cpu is likely you already have it, you should check it out, you probably have it. And if you turn it on, you can use this technology to protect your application.
00:07:51.640 - 00:07:56.542, Speaker A: And this comes out of the intel research group. Where does it come out of? Within intel.
00:07:56.606 - 00:08:20.490, Speaker C: It actually has a very long history internally. I believe they have developed this thing for ten years already. So they have some very long time to make sure this is good. It's correct, it's secure and they put it out there. And this is now in their product line right now you can actually get them. It's off the shelf. There's still some cpu doesn't have it yet for some of the I five, I'm sorry, the e five, the more server class cpu doesn't have it yet.
00:08:20.490 - 00:08:21.918, Speaker C: They probably will have it in the future.
00:08:22.004 - 00:09:09.270, Speaker B: I think one tee, or particularly the term enclave, is something most people have heard about in the context of Apple iPhones. So iPhones all have enclaves, or the newer models, and they use them to store like fingerprints and your face id, sensory data and all that kind of stuff. So it isn't reachable from the rest of the operating system. You can't install an app that steals your fingerprint stuff like this, but that's very different. Like they have a specific chip that is this enclave and it's not connected to the cpu. How does that compare? Is intel just kind of mashing these two things together? Or is there some benefit, like additional benefit to having the enclave connected to the cpu?
00:09:09.430 - 00:09:50.326, Speaker D: I think we clarify that enclave as a software and SGX, and rather refers to hardware difference is tremendous, right? Because such chips like in Apple gives you only one functionality. Enclaves as a software, as a part of application that can be run on your computer, gives you opportunity to write your custom applications. The benefits are absolutely unlimited. I mean, almost everything you can do with your own application, the values that this application brings to your customers can be achieved also with enclaves and with FGX.
00:09:50.438 - 00:09:50.906, Speaker C: Right.
00:09:51.008 - 00:09:58.170, Speaker D: So the difference is like two different words. It's a specific purpose.
00:09:58.670 - 00:10:46.186, Speaker C: Yeah, I partially do agree with Lucas. There is definitely different use cases and different application interfaces. How do you programming them? I think there's actually a deeper security argument in terms of do you have everything inside one processor, one cpu? Or you have these coprocessor models, like you have a separate chip or separate processor. For example, in the Arm trust cell model, they actually have another cpu was handling it. And that was deeply related with the kind of problem where you want better performance. You want to have regular program, like the program you run every day to run in this enclave, or you want to basically spend the effort of reprogramming everything and have everything just running on this little chip. And there is this argument there for the trade off between the security and.
00:10:46.208 - 00:10:57.246, Speaker A: Usability, from what I understand. Would you still call what is on Apple on these Apple phones? Is it still an enclave? Is that still a te or is that something else? That's a te.
00:10:57.428 - 00:10:58.958, Speaker C: It would be a te, yes, but.
00:10:58.964 - 00:11:01.966, Speaker A: It'S like a simple one, I guess. It's like it has one purpose or.
00:11:01.988 - 00:11:03.774, Speaker B: It'S like only special purpose one.
00:11:03.812 - 00:11:04.734, Speaker C: Yeah, that's right.
00:11:04.852 - 00:11:14.546, Speaker A: And the SGX, the intel's SGX, from what I understand, is you can actually run some of your application within it. Or do you run all of your application within this?
00:11:14.728 - 00:11:53.850, Speaker C: Well, that is actually a really interesting question. Also kind of debate that we always go in with right now in the academy domain is do you want to take the whole application in there, or you want to just rewrite part of your application, or you want to partition one of the applications? That depends on what is your security model. Do you want to reduce your risk of your program being attacked? Because things like te, they are not silver bullet, they don't solve all the problems. If you have a vulnerable software, you could still have problems, security issues. So you do want to consider which one you want to trust and you want, which part of you want to put into this PE environment.
00:11:54.010 - 00:12:06.198, Speaker A: What does it actually protect against? Is the idea here that if you had a bug or something running on your cpu that was malicious, it couldn't affect that? Is it just to save it from other things that cpus can do?
00:12:06.284 - 00:12:47.534, Speaker C: So it usually was protected against one very strong attacker as the host attacker. So imagine your operating system is compromised, or even worse, your byluz is compromised, or even the whole hardware is compromised. Like I am the administrator, I have ss two, the machine physically, and I can change a lot of things. For example, if we talk really extremely, there are attack, like for example row hammer attack or something like I can steal data directly from the I O buses or your memory buses. SGXs, these kind of things could actually protect you from all these kind of attack, potentially because they encrypt everything, encryptable data when they are sending out of the cpu.
00:12:47.662 - 00:12:54.660, Speaker A: As a host, can I even access my own SGX? Is it sort of like it even protects it from me?
00:12:55.110 - 00:13:02.518, Speaker C: You're supposed to see just encrypted data on DRAM and you are not supposed to see anything out of it.
00:13:02.604 - 00:14:12.398, Speaker D: To answer this question, to solve this problem, I think we need to better understand what SGX gives to the users. What is the value of Tes in general? And at the beginning, Chacha gave a very good example. I will give another example. Consider this, in the most countries, the law prohibits to send sensitive medical data to cloud providers and store this data on clouds and make any computations transformation modifications of this data in external clouds. This is made for very concrete reasons. Imagine this, that cloud providers enables SGX on their machines. And what some company or institute, state institute do is take this medical data, encrypt it and send it to the cloud provider, to the cloud and store it in the cloud in the encrypted form.
00:14:12.398 - 00:14:27.154, Speaker D: The cloud provider. Any administrator cannot access this data, but this institute or any company can perform any computation or modification remotely on this data.
00:14:27.272 - 00:14:27.986, Speaker C: Right.
00:14:28.168 - 00:15:14.930, Speaker D: So who benefits from this solution? The cloud provider does not have any direct benefits from this. The end users who are accessing services provided by cloud are benefitors, right? The direct benefitor does not use SGX directly in this use case particle, but he is using external SGX. So what is in the farfetch step benefit for end user? It is ability to access external power, computational power and storage without losing confidentiality and privacy.
00:15:15.350 - 00:15:15.954, Speaker C: Right.
00:15:16.072 - 00:15:34.694, Speaker D: And that is the benefits. So if Anna is asking what do I have when I enable SGX on my computer? It's pretty complicated because in this use case that I have described, the benefitor is external user, right?
00:15:34.812 - 00:15:37.634, Speaker A: Is the SGX just the place where the encryption happens?
00:15:37.772 - 00:16:10.558, Speaker D: Yeah, I think that should be quite obvious that in contradiction to this chip installed on Apple. Maybe I'm wrong, I don't know details. The SGX has maybe not direct ability, but in some form it has ability to connect to external users. So it gives lots of possibilities, opportunities, it enables lots of use cases. And this is the power of tes and SGX.
00:16:10.654 - 00:16:40.942, Speaker B: I want to dig into one final question just on kind of clarifying how SGX or any other TE actually works. And so you already mentioned you have encrypted data on ram, on disk, whatever, send this to the TE and you get some encrypted data back out. But for this to be trusted there also has to be some proof or some verification that this computation has been done correctly. What does that output look like? What does the proof look like that comes out of this thing?
00:16:40.996 - 00:17:44.390, Speaker D: Your question is a very good question. It's a fundamental question and lots of people ask this question. These SGX chips has sealed private keys inside hardware and they are used to secure communication with this SGX. The most difficult step is how can external user, the end user or even a collocated application that is going to employ enclaves know that it is speaking with an enclave? How can it know it is speaking with trusted component? It boils down to attestation process. At the moment it is solved this way that Intel's provide services that can confirm that you are speaking with hardware real SGX. It is very high level view, not getting into the details.
00:17:44.490 - 00:18:00.630, Speaker B: So is it sort of like almost like a certificate authority thing that intel knows what keys it has on its processors and you have to reach out to intel to say that they attest to the correct results or how does this work?
00:18:00.780 - 00:18:27.358, Speaker C: So I'll extend on what Lucas was really first of all, it's really up to SGX's or other te will have different implementation. But eventually all boiled down is these platform need to give you identity. They need to prove that this is a real hardware, this is a good hardware. This is not a hardware that was simulated or emulated by the attackers. Right. That is fundamentally you want to provide. Right.
00:18:27.358 - 00:18:57.746, Speaker C: And so for example for intel, what they do is they have this master key or master secret was placed inside your cpu. And because they have the hold of all these secrets, they can use that to verify that your hardware is correct. Some other platform might use different things they want to do. For example, TPM might use more close to what the certificate system you have been using. But mostly they are using these crypto techniques like the public key infrastructures and those kind of things to make sure your platform is secure.
00:18:57.858 - 00:19:02.230, Speaker A: But by this definition, what you just said, it sounds like you have to really trust intel.
00:19:02.310 - 00:19:02.746, Speaker C: Absolutely.
00:19:02.848 - 00:19:10.502, Speaker A: Like are they publishing anything? Are they sharing any of this publicly where you can actually verify it yourself? Or is it like a trade secret?
00:19:10.646 - 00:19:45.766, Speaker C: They used to be that you do have to ask intel all the time to verify everything. Recently they have become more open on this. So they have do something called DCaP which allows vendors, for example, let's say you have a cloud vendors, you could absolutely build your own attication server to verify these secrets on their own. So you don't have to always go back to intel and do all these things. Right. They do sort of moving, unfortunately, they move really slowly, but they do sort of move forward instead of making it more public and more open.
00:19:45.868 - 00:20:33.138, Speaker A: Because I think, yeah, if that isn't shared, I mean, at least our community, we always hear this. It's like the reason we prefer open source is you can check it, you can see what it is, you can run it yourself, you can make sure that it's running correctly. When you're dealing with sort of a black box, like, trust us, we have all the keys, we keep them really safe. I promise. It's hard, I don't know. And I guess this is their response in a way, their attempt to start opening it up. You sort of just mentioned there that it's like their work with vendors or their work with other, I guess, software setups where it's not like an individual would interact with an SGX ever, but there are teams or groups that want to use these setups for some purpose.
00:20:33.138 - 00:20:46.458, Speaker A: And they work with intel I guess, to do it. So they have this back and forth, they have this ability to do an. Is this where this is kind of where graphene comes in too, right? In this space.
00:20:46.624 - 00:21:16.434, Speaker C: Yeah, that's right. So remember I mentioned about the desktop usage. So using SGXs on like a client's machine or usage machine, right. There's another model or another use cases is basically using, that means the cloud. And the idea of this is basically you have some application you want to inside cloud. Do you want to trust the whole cloud completely or just want to trust one machine, one cpu inside the cloud. And so if you can basically reduce the trust of inside cloud, that would be much better.
00:21:16.434 - 00:21:59.330, Speaker C: So there's a lot of cloud vendors are really interested in this direction. Probably not Amazon. I haven't heard Amazon do anything about it. But like for example Microsoft Azure or IBM or Alibaba cloud, these cloud vendors are starting to get into building their own, also Google has their own version of te as well. I have to say that they're actually basically putting together these technology and said okay, we want to have these kind of hardware uncle environment to protect your applications, right? And so that just sort of give a space of framework like graphene because well to be honest, users are a lot of times lazy. They don't want to port application into this platform. And what the role of graphing is basically very simple.
00:21:59.330 - 00:22:12.262, Speaker C: You have application running outside enclave. You can use this framework to move inside Enclave and run it as it is. And we're basically solving this, trying to solve this security problem and compatibility problem for application.
00:22:12.396 - 00:22:27.558, Speaker A: What was it like before? Maybe describe a little bit like what is this set up now or before now. And how does this change? Because it sounds like, are you sort of an enabler? You're sort of like allowing that movement easier.
00:22:27.654 - 00:23:11.994, Speaker C: Yeah. So the idea of SGX, it used to be the cases where you have to reprogram everything, right? Well, not necessarily reprogram every line of code, but you do have to take a part of code. You have to rethink about the security problem because you have to build an interface between enclave and non enclave code. And you basically have to rebuild, basically take your system and say, all right, I'm going to take this part, secure it and put it inside enclave. So there is this difficulty of implementing any SGX program. I can give you a really good example in Berkeley. I've got undergrad students come to me and complain to me saying, oh, we're trying to get SGX working, but it takes us like a month or something just to figure out how to do this thing.
00:23:11.994 - 00:23:28.462, Speaker C: It's really complicated. And partially graphing is to say, no, you don't have to do these things, we do it for you, but you just take a program and we got to move it into enclave. And also we want to make sure it's secure. And that's actually a very important thing. If you are not secure, it's not compatible at all.
00:23:28.516 - 00:23:46.198, Speaker A: Why was Gollum like, what was Gollum's role in this? So Gollum, as you described before, you guys want to do kind of computation. And actually from what I've always understood Gollum doing is sort of like marketplace for off chain computation. So what's the relationship here?
00:23:46.284 - 00:25:35.014, Speaker D: This is a very direct relation to graphene and to SGX and tes in general, because it is for many users, for many potential customers of Gon network who will be willing to use this network as power consumers, they are not willing to share their data input or output data like a large video company, movie company wouldn't like to share a new movie, any fragments, any pieces of this new movie to anyone because it is very value. So we recognize that it is a very huge market for confidential computations and it was very natural for us to think about employing SGX. But as Chacha said, it's very challenging to write from the scratch a new SGX application or an airplane maybe SGX application is not a very good phrase, but to employ AZX in your application, right. We needed a tool to grab an application and run it in AZ just like this. And it turned out that graphene is the way we should go. So we get involved in this and since then we are very happily cooperating with Chachand, Don and Intel improving the graphene and getting back to the beginning. It is the answer for the confidentiality call and huge step towards very demanding customers.
00:25:35.212 - 00:25:51.094, Speaker B: I have two questions actually. One is related to graphene, the other is kind of going back a little bit to Tes. But first on the graphene thing, are you explicitly trying to target more than SGX or is it like an SGX specific solution?
00:25:51.222 - 00:26:45.050, Speaker C: So I would know in general we always trying to target more platforms. So fundamentally graphing is supposed to be a very thin layer that trying to solve compatibility problem and secure isolation problem for application on as many platform as possible. For example, a lot of time you run into problem what if I want to run a Linux application on Windows or Windows application on Linux and you have this interface compatibility problem. And the way to solve it usually is you build a very thin layer to translate these interfaces from one to another. And graphing is supposed to be this ultimate interface or a translation layer that reconcile everything. But of course it's not there yet, but our goal is basically make it easy to pour to everything. And SGX has always been one of our golden example because it was really, how do I put it, exotic.
00:26:45.050 - 00:27:24.710, Speaker C: It's not the same as anything other platform you've ever seen. And mainly because now you take these interfaces and you flip the security model upside down. You used to trust operating system, now you don't trust it anymore. How do you even use the system API, how do you open a file? How do you even locate some memory that become a very big issues and you need to make sure all these interface are secure. And so that's why we kind of believe if you can solve the problem with SGX, you probably would solve the problem of a lot of other platforms as well. So we're basically using another example of a push hour research goal. And who knows, maybe eventually we do need a layer to solve a new hardware.
00:27:24.710 - 00:27:38.446, Speaker C: There's always going to be new hardware platform that coming out, a new operation platform coming out. What if we actually need something to run some old application we wanted? Well, Graphene will come to rescue and help you solve this problem.
00:27:38.548 - 00:27:47.074, Speaker B: Did golem look at other platforms before deciding, or did you just know like SGX is the furthest along? This is what we want to shoot for from the get go.
00:27:47.192 - 00:28:41.362, Speaker D: As Chacha said, I agree with him that it will be great to see some competitions in this. It is very healthy for everyone. As usual, competition is very healthy. And I think the graphene is able to adopt different solutions for different tes, and this is the way how it should be. But there is another view of this, because we do not have at the hand ready to use other solutions for tes other than SGX. There are, but not with this scale. And at the moment the scale matters, right? So it is absolutely natural that our interest is in Intel's SGX and we are thinking very strong about it.
00:28:41.362 - 00:28:54.486, Speaker D: But getting back to the beginning, it would be nice and I hope it will happen, but other tas will appear and will be for our use. And the graphene I think will be ready to adopt it.
00:28:54.508 - 00:29:40.790, Speaker C: As far as to know, there are definitely a lot of te was coming out for. AmD has their own version, it's called Sev arm, I believe. I'm not sure whether it's on market yet, but they're building this thing called Crypto island, which is basically trust zone plus hardware encrypting facility that help you solve this kind of problem. And so they're all doing these kind of things. One thing I'll say is I do think they have become cautious right now because they want to make sure they're doing things exactly right. Do not have vulnerability. As we can see, there weren't a lot of vulnerability on this kind of platform and it usually make people doubt the security of this platform a little bit and that's why they're being careful about right now.
00:29:40.790 - 00:29:43.670, Speaker C: So we will see, but it's probably going to take a while.
00:29:43.820 - 00:30:32.790, Speaker B: We want to get back to that topic a little bit. But before we do, I wanted to ask a sort of general question on tes that popped into my head as you were talking about use cases. Let's say you have this use case where you're running in the cloud, you want to upload some data, transfer that to a te, decrypt it, run your computation and then encrypt it again and get it back out. So if I'm decrypting inside the SGX, I have to supply my decryption key to the SGX environment. And how do I do that if I don't have direct access to the machine? How do I transfer that over the wire? Like how does it go through Amazon's center or whoever's center and getting to the SGX without revealing my key?
00:30:32.860 - 00:31:13.762, Speaker D: It is solved in a different direction, opposite direction. The SGX is generating the pair of keys, asymmetric keys, to communicate. And it is very easy to give you to the end user the public key. So any data that you encrypt with this public key can be only deciphered by this enclave. All you need to know is that this public key comes from real AZX, right? This is the part of actual attestation process, right?
00:31:13.896 - 00:31:14.580, Speaker B: Yeah.
00:31:16.230 - 00:31:20.920, Speaker D: And there is Intel's attestation service involved in this.
00:31:21.370 - 00:31:48.000, Speaker B: So that makes sense. So essentially I ask the SGX environment, hey, please generate me a key pair. You get the public key back along with an attestation from intel saying yes, this is a key actually generated by an SGX environment. I encrypt my data with that public key, upload it and then it runs through the SGX. How do I decrypt it when I get it back?
00:31:48.370 - 00:32:42.490, Speaker D: It is much more complicated than this. All right, it's not so easy, but okay, I will try this way. First thing that we can do after receiving the public key communication key to the enclave, all I do, I am generating a symmetric key for a phishing encryption. I encrypt this symmetric key and encrypt with public key communication. Public key generated by an enclave. And I send this encrypted key to the enclave, only enclave is able to decrypt it. So at the end I and the enclave holds the symmetric key that is used for a Farfer communication.
00:32:42.490 - 00:32:54.738, Speaker D: And in the next steps, in the following communication. This semantic key is used for communication, right. And it is very simplified description of the whole process.
00:32:54.904 - 00:33:14.330, Speaker B: But instead of. Yeah, what you're saying is instead of just me encrypting the data with a key, I got, I encrypt the data and the key that I want to decrypt with and send all of that over, and then when I get it all back, I still have that key and so I can decrypt it because the SGX encrypted it with that key that I gave it. That makes sense. Thank you.
00:33:14.400 - 00:33:47.154, Speaker C: This process is actually called secure provisioning. And we usually said decante is pretty much useless if you don't do provisioning, because you do need to move some secret data from a remote machine to your local machine to process them. Otherwise it doesn't really make sense to run any kind of security. And so of course these kind of provisioning, the shipping data needs to be on a secure channel. And what Lucas was just describing is basically how they build a security channel. It's actually not too much different from things like HTTPs that you build like a Tos or SSL connection. It's the same thing.
00:33:47.154 - 00:33:55.478, Speaker C: You do the key exchange. You use either a secret key over private key to encrypt your data and then you send it the other way. It's pretty much that.
00:33:55.564 - 00:34:10.330, Speaker A: Is there any in that sort of encryption, de encryption, like what you're just describing? Are there any other tools that are being used? Maybe tools we've already mentioned, things like fully homomorphic encryption or mpcs or is there anything else?
00:34:10.480 - 00:34:39.974, Speaker C: Right, that's an interesting question. So fundamental research perspective, there's a lot of people actually sort of saying trying to use hard uncle is to replace homo warfare encryptions or replace multi party computing. Idea is basically because you have this environment that everybody could all trust. You don't have to do these step like extra crypto step to make sure your data is secure. You can just move the data to the platform, decrypt it and process them. So actually make a lot of things a lot easier. Make these things.
00:34:39.974 - 00:34:47.390, Speaker C: Well, it's actually not as secure of these things, of course, but it sort of replace it and make it much faster, much more efficient.
00:34:47.490 - 00:35:30.850, Speaker A: That actually leads to another question, which is exactly that like tees are often compared to fully homomorphic encryption or even like Zk snark kind of check in points. And I remember in an episode we did on npcs, we mentioned this, and tes seem so different and yet they're often lumped together. When we put the question out, I put a question out on Twitter sort of about tees, and I definitely got some feedback from people. Maybe half of them were like, oh, this is an interesting, cool thing. And then half of them were like, you cannot trust them. Why would you even talk about it? So how do they hold up to the fhe MPC or like the ZK snark paradigm?
00:35:31.010 - 00:36:17.234, Speaker C: Yeah, I mean, I would like to hear if there's other different perspective on the industry for. But. So from the academy perspective, we usually said there's two different approach, right? There was the mathematical approach. Basically you solve everything, solve the security problem by math, by using something that you can prove. You can verify in the algorithm level and you can look at, for example, MPC and you can verify, oh, this is secure. Another way is secure by implementation, right? By engineering, you have a hardware or some kind of operating system, hypervisor, label, whatever you do, and you trust the implementation of that, and that bootstrap your security. And I would say it's not really about which one is more secure.
00:36:17.234 - 00:36:49.738, Speaker C: It's more like they have different challenges. So you're secured by crypto, you got the challenges of efficiency and whether they might be attacked at the algorithm level. When you look at CPU, SGX, they have hardware attack, software attack, these kind of things where you have to solve with another level. And so it's all about, do you want to choose? Do you want to pick, what do you trust? Like I said, fundamentally, do you want to trust cpu vendor doing their job properly and design these hardware securely?
00:36:49.754 - 00:36:58.862, Speaker A: And so that's sort of the trade off, right? It's sort of like, do you trust the group who have created the hardware to not have a backdoor, or do you trust the math?
00:36:58.926 - 00:37:09.430, Speaker C: That's exactly the kind of the secret charging rail software right now. And it's actually not complete solve, as you can see, or look into these kind of problems and see.
00:37:09.580 - 00:37:21.238, Speaker B: Yeah, you mentioned that there has been vulnerabilities discovered in STX. What kind of vulnerabilities are those and how have they been patched? How does the platform recover from those?
00:37:21.324 - 00:38:20.882, Speaker C: So I think, first of all, there's always a software level vulnerability, and these are not new, right? It's the same kind of vulnerability you see in server or desktop application, for example, like hop reading bugs open. So the kind of same thing could happen in uncle as well. And especially you have very strong attackers who have control of your operating system. On the other hand, at higher level we also see things like side channel problems where essentially you are sharing your cpu core with other process or other operating system. Now they could see a lot of information being leaked through your shared resources. And based on that, well now we also have however vulnerability that based on either speculated executions or memory protection, bypassing things like Spectre and mail down bugs, there's actually one that come out last year, what we call foreshadow bugs. It's basically a meltdown kind of type of vulnerability that can apply to SGX.
00:38:20.882 - 00:38:47.734, Speaker C: And this is kind of a big thing when you see this thing. They potentially could leak these master secrets that have been generated by Intel CPU that verify your platform. And as you can see, if you leak that secret, then you're gone. The security is basically ruined. And so you do have to either solve this problem or patch your hardware to solve this problem. And that is unfortunately the reality of this technology.
00:38:47.932 - 00:39:40.246, Speaker B: Yeah, so with a lot of the normal intel bugs that we've heard about, there are various fixes of like compile it with this flag to turn off that feature. Or like the latest one I think they say turn off hyperthreading and you don't have this problem. Which is. Yeah, you don't have much choice, but hopefully they fix that in the next generation. Then you can sort of work around it, even if you have to wait for the next generation cpus to have it actually fixed. It's an interesting thing to think about what could go wrong, both on a social level, like what happens if intel leaks data on their end so that anyone can attest to anything? Or what happens on the hardware level. Something I'm super curious about is how tamper proof are tees, because you have these super involved attacks being described by people.
00:39:40.246 - 00:40:15.826, Speaker B: When you have hardware access. You dump your whole computer in liquid nitrogen and then you freeze the ram and then you can read off the ram, you can detach it from your computer, read off what the ram had, post fact circumvent all of these shutdown barrier tricks, really. You have cool exotic attacks like that. Like what happens with those kinds of attacks in a te environment. What if I delid my cpu and look at it with electron scanning microscope or whatever?
00:40:15.928 - 00:40:50.890, Speaker C: Exactly. So I think in general the assumption is it's relatively difficult. I wouldn't say completely impossible, but it's almost close to impossible that you can open a cpu and look into it, because everything is at a scale of nanometers and you pretty much couldn't really see anything. And that is also kind of moving the direction of DRAM. You actually couldn't really open dram and look into it if it has been really down to nanometer level. But I've heard different story as well. Some people could say some cpu potentially could drill a hole on it and look into it.
00:40:50.890 - 00:41:13.042, Speaker C: Probably not East Intel CPU, but more like the other kind of cpu could actually do that. But in general, our belief is hoping the cpu packages is really secure and cannot be tampered with. But this is an interesting question. And whether the technology I believe is even if people could do that, it's probably really expensive. And so it's kind of question whether it's worth it to actually do that.
00:41:13.096 - 00:42:08.486, Speaker A: That's kind of amazing, that idea. And so I think one of the critiques seems to be like, you just described this sort of human factor, the social factor. But I guess the big question is like, are any of the other paradigms ready? If math, if cryptography and cryptographic concepts can do the same thing or can securely do the same thing, why would you even use a te? Why would you use SGX? And I'm curious what you guys think, because I'm sure you're coming into contact with that. Do you feel like tease and SGX, it's the thing you do right now, because the math isn't there, because the cryptographic stuff isn't there. This makes sense today, or is this like, actually, this is going to be something that will be a long standing solution and is useful for specific use cases, whereas the other stuff could be useful for something else at the moment.
00:42:08.588 - 00:42:45.410, Speaker D: For today. I get in touch with Snark recently, and I have some thoughts about it. I listened to their solution, to their approach using zero knowledge proofs, and I think it's very great approach. It's lots of maps, you don't have to trust anyone. It's tremendous, great. And I think it is a very good approach. When you have a very little data that are very sensitive, like transactions, it's a tiny data with a big value.
00:42:45.410 - 00:43:51.718, Speaker D: And then you can use zero knowledge proofs for such a data. From my point of view, when I have gigabytes of data to consume, to make computation, and to output gigabytes of data using zero note proof, as it is today, is no go for it. So performance is a key indicator for me, speaking as a golem, right? Because at the end, what matters at the end. At the end, there's an end user who wants a service with a particle factors like privacy enabled, like confidentiality of his data. And the answer is SGX for it. I hope that some future zero knowledge proofs will have enough speed to perform some computations to be also used as a service for remote computations. But for today, I think they are doomed to processing valid data with a huge value.
00:43:51.804 - 00:44:04.326, Speaker A: That sort of answers the question, right? That there are certain use cases where even today, these other paradigms, NPCs, FHS, snarks, starks would be more useful. But what you've described here is that if you're doing like massive computation, they're.
00:44:04.358 - 00:45:04.150, Speaker B: Just not fast enough, just speed wise. They're in such different worlds. But the process, the development, the research, it progresses pretty quickly on the crypto side. But even then you're dealing with a separate problem, which is what Graphene is trying to address, right? Like, how do you take an existing program and run that? There is no one even trying to think about that in the snark or fhe world, where it's just not on the table at the moment, it doesn't exist, whereas taking an existing program, I mean, in Golem's case, if you want to, the purpose of the platform is to sell general purpose computation. It's not to know. I have to spend six months writing my snark circuit before being able to do anything. So even if snarks were fast to compute, having that lead time to write your program as a snark circuit is already the showstopper.
00:45:04.150 - 00:45:26.242, Speaker B: You want to be able to take whatever our blender application and render something. Then you need to take that software off the shelf and be able to run it. I guess with graphene that becomes a possibility. And in the crypto world, it's not even considered at the moment. So maybe in a hundred years we'll be there, but we'll see, I guess.
00:45:26.296 - 00:45:44.458, Speaker A: Yeah, that's interesting. Yeah, I think that really helps to kind of pinpoint what graphene is doing, too. I have another question about graphene in general, which was like, we are using the Golem use case here, but is it for all applications? Is it crypto specific? I'm imagining it's more SGX specific.
00:45:44.624 - 00:46:00.894, Speaker C: I guess your questions would be about what kind of application you want to run and what kind of platform you want to run on top of it. Right. SGX is one of the platform we want to run, but we want to run different application, different platform, and more.
00:46:00.932 - 00:46:04.446, Speaker A: Different kind of hardware, different tees, basically.
00:46:04.628 - 00:46:22.566, Speaker C: Exactly. Different tee will be really good. We will hope in the future we're running on arm or running on AMD. That would be really awesome for the application. I think it's hard to make every application run for sure. Of course we try to be general purpose, but it's really hard to have all the application running. Right.
00:46:22.566 - 00:46:51.162, Speaker C: Crypto of course is definitely. Or any kind of computation intensive workload will be really good example. Of course there are things that are more I o intensive or more administration kind of types, things maybe we don't really have to run them on top of it. For example, you don't want to run configuration panels inside enclave. You don't have to do that. There's a lot of application you don't want to run inside this environment.
00:46:51.226 - 00:46:57.106, Speaker B: I assume there's some relatively major restrictions, like you can't access the network and things like that.
00:46:57.208 - 00:47:13.282, Speaker C: Yeah, I mean you could actually use SSIO, but you do have to add protection to it. Usually we call this behavior what we call shield because it's building some kind of protection to it. There's end to end protect your network payloads or end to end protect your disk.
00:47:13.346 - 00:47:14.374, Speaker B: I see, yeah.
00:47:14.492 - 00:47:40.926, Speaker A: My only last questions are a little bit about this backdoor. And a lot of the cryptographers that we've spoken to would also. That seems to be the one thing that very much worries them, the human factor. This idea of like somewhere there could be political pressure or some pressure put on a company or an organization to add a backdoor that nobody knows about. And I wonder what you think of that. Is that something that you, is it.
00:47:40.948 - 00:47:45.438, Speaker B: A legitimate concern or is it overblown in your opinion?
00:47:45.534 - 00:49:10.958, Speaker D: You are comparing it to zero knowledge proofs where it is a mathematical proof that you cannot read the data. Right. Because there is no backdoors and there is an opportunity for a manufacturer of the SGX or other ts to provide some backdoors or flows or anything like that, for number of reasons, like political reasons, internal politics reasons and control or anything like this. As far as I understand your question. Right, your question boils down to why do you trust intel? And the answer is I don't think that we trust intel very much. I hope that the intel is very matured and responsible company and they can predict the effect of providing any backdoors or anything like this in their products. But looking for the future, right, maybe there will be more tes on the market and the competition will change the whole technology, how we look at it, how we employ it, how we are using it.
00:49:10.958 - 00:50:10.078, Speaker D: What are our expectation to these technologies? Right. As you said, in this space, human factor plays very strong role. And of course men think can happen if it is happening right now or if it will happen in the future. Actually, I don't know. All I know, we are developing very, very good technology despite any flows of hardware solutions, right. And we are delivering quite good solution for users, for developers, for companies who would like to develop applications and provide services based on the confidentiality, privacy and anything connected with this to end users. I think that is our position for this aspect of the HGX and TS in general.
00:50:10.164 - 00:50:11.242, Speaker A: What do you think, Cheche?
00:50:11.306 - 00:50:50.038, Speaker C: I guess I will kind of sort of say it's kind of. Okay. Okay, this is my. So like I said earlier, if you are doing a different approach, you basically face different challenges. So if you are going with approach of securing by engineering, you're basically facing like you need to make sure everything was done properly, from design to manufacturing, to shipping, to what we call supply chain problem to selling them, to people, installing them, everything. You wanted it to be completely secure. And of course there's going to be doubts about if we can actually make sure all these steps are taken properly.
00:50:50.038 - 00:52:13.250, Speaker C: There are these kind of issues. For example, last year there's the Bloomberg reports about this big hack, about their chipping in jeopardy. So of course I don't think there is a hard evidence of that yet. But technically this is something that's feasible, right? So of course from the perspective we do want to have this process be open, we want to make it transparent to see how are these chip being manufactured, how are they being shipped, where have they come from? We want to know this information before we actually run any secret on top of it. But in general, I would say maybe actually my perspective, I think for a lot of either software vendor or service vendor, it's acceptable because from the economy perspective, they could understand how do you secure a manufacturing process, how do you secure shipping process, how do you secure the supply chain problem? It might be actually easier to understand than the way that crypto work or zero knowledge proof work or multiparty computing work. So somehow, of course there is the risk of it, but this is a risk they can control, they can understand, and they could minimize. And so somehow that's why this turned out to be a more optimal, ideal approach for the industry.
00:52:13.250 - 00:52:14.182, Speaker C: That's what I believe.
00:52:14.236 - 00:52:53.202, Speaker B: So I feel like there's two things to think about here, or like two arguments to make here. One is intel has more at stake than I do, which is true for most cases, if intel gets corrupted and fucks things up, they will lose more than I will. And so it's okay. And I think that's a fine argument actually up to a certain limit. Like at some point, if we're talking about the entire bitcoin blockchain in 50 years from now, then maybe that isn't the case. But who knows? The other argument is we can actually make this better. So SGX is where it is right now.
00:52:53.202 - 00:53:01.670, Speaker B: You have to trust intel, but if they open up more, or if a competitor comes onto the market is more open, there's things to mitigate that risk, right?
00:53:01.740 - 00:53:55.654, Speaker D: Yeah, it is a very good point. Because if we look how many users is using SGX and Tes right now, if they're using it directly or indirectly, we should say that we are on a very early stage. Right. Anna said something about open source and I liked it and I remember it because open source comparing to a closed source is very well tested because it has lots of users and the code is open for reviews. And SGX, there are very few users, some developers. But I think the tes in general are the future for many services, for many applications. And with the time it will be more and more solutions, better and better tested, and the whole landscape of Tes will change.
00:53:55.772 - 00:53:57.702, Speaker A: Maybe they'll be more and more open too.
00:53:57.756 - 00:53:58.360, Speaker D: Yeah.
00:53:58.890 - 00:54:16.782, Speaker A: I just want to say thank you so much for coming on the show and going kind of covering this landscape with us and sharing kind of how you guys got into it, why you're doing what you're doing and the ins and outs of the tee world. Yeah, this is really, really informative. So thank you.
00:54:16.916 - 00:54:17.518, Speaker D: Thank you.
00:54:17.604 - 00:54:19.070, Speaker C: Yeah, thank you for having us.
00:54:19.140 - 00:54:21.162, Speaker A: And to our listeners, thanks for listening.
00:54:21.226 - 00:54:21.850, Speaker B: Thanks for listening.

00:00:07.200 - 00:00:38.324, Speaker A: All right. Welcome everybody. 430 time for some security. So originally this talk was called full stack Dapp security. But as I was engaging with the material and diving deeper, I got back and back to hey, like we kind of know about all the techniques and security. Right? There's been so many talks about the types of testing, unit testing, fast testing, mutation testing, symbolic execution. I feel like the techniques are mostly known at this stage.
00:00:38.324 - 00:01:19.362, Speaker A: But if we all know about this stuff, then why do hacks and exploits still happen at such large scale? Right? And I believe at least a part of the answer is culture. And that's why I want to focus a bit about how you can define or redefine your culture in a project to ensure hacks happen less frequently. My name is Philip. I work for a company called Mentor Labs. We're a platform to launch decentralized stablecoins and EVM blockchains. We're the company behind the Celo stablecoins such as the Celo dollar, CUSD, or Celo Euro. And we just recently launched kenyan shillings.
00:01:19.362 - 00:02:01.604, Speaker A: We're trying to launch local currencies. Problem, goal and solution. So problem. You've probably all seen a version of this around when you've been following crypto in any capacity. And I want to pull your attention a little bit to the unaudited and audited text behind the project names because I think the first intuition is, yeah, didn't get an audit. Therefore they were hacked. But then on the other hand, you have seven out of ten at least many of them they actually had an audit and they still made it to the top of the rec leaderboard.
00:02:01.604 - 00:02:26.150, Speaker A: So an audit is good, but it's not enough. Don't get me wrong. I think it's really good how deeply we value and have enshrined audits in crypto and in defi. Like coming from a web two background, nobody was thinking about getting an audit for launching a back end update. Right. Even in banks I've worked in. But in crypto I think we're already doing a pretty good job at that.
00:02:26.150 - 00:02:51.014, Speaker A: But there's other things. So audits are manual, they're slow, they're very expensive. They don't cover all attack vectors by far. There's an incentive problem. Right. If any of you got an audit you know that you have to pay regardless of the result. So the auditors aren't, are incentivized by reputation I guess, but not necessarily financially.
00:02:51.014 - 00:03:43.004, Speaker A: And it's a one time activity. Typically you do it one time and have that sense of false security that we covered our basis, we got an audit or two, we're done. In reality, attack vectors are constantly evolving and the landscape's constantly changing, be that an ethereum hard fork or solidity update, a new smart contract, a new type of technique like a flash loan, that you might have not thought about doing the original design and thought that you got. So the goal is we want to make the lives of attackers really hard. Their attackers are humans. Many humans are lazy because we want to conserve energy, right? So if somebody gives us a hard time, we're more likely to maybe move on and go do other things. So it's all about driving up the cost of the attack and removing low hanging fruit.
00:03:43.004 - 00:04:12.688, Speaker A: We want to continuously improve security. Think agile. It's not a one stop thing, but every sprint or every iteration, we're trying to improve our processes and the same stance we should adopt to security and security culture. Specifically. The solution I propose is a strong security culture. And it sounds a bit fuzzy, right? Like what is culture? I have that on the next slide. We want to enshrine a proactive security posture.
00:04:12.688 - 00:04:59.898, Speaker A: For me, that means we have people with strong security mindset using secure processes to produce secure technology. That's number one, then a culture where we want to prevent and detect attacks early and then respond swiftly if unexplored does happen. And lastly, we want to stack as many swiss cheese layers as we can, right, extracting from that to make this a bit easier to think about. There's three mental models. They're already kind of hidden on this page here. One is people, processes, technology, prevent, detect, respond, and swiss cheese layers. So PPT, it's a framework that's been commonly used in it since the 1960s.
00:04:59.898 - 00:05:47.744, Speaker A: I believe you can think of these as the pillars of your protocol. You have people, you have processes together, you produce technology, and then there's different phases during the lifecycle of your protocol. You can either be in, prevent, before, during or after an attack, I guess. Lastly, swiss cheese layers. You probably all have seen swiss cheese in your life, but if you don't remember, they have holes in them and one layer might not be enough good protection against some exploits but not others. But if you layer another slice on top, that will cover some of the holes in the first one and for the next one too. And at some point you have so many slices in your stack.
00:05:47.744 - 00:06:32.234, Speaker A: Thanks to chat GPT for this gorgeous rendering of an impossible to eat cheese sandwich that will become not impossible, but very, very hard to penetrate. And I'm going to use this PPT people process technology framework now, to look at what you can do to create a more security aware culture. It all begins with onboarding. You join a project or somebody joins your team, and that's a teachable moment. There's a phrase I picked up on a children's education book. I have a four year old daughter and I try to teach things, but very often it's just not the right moment. So it will just bounce off her brain.
00:06:32.234 - 00:07:17.130, Speaker A: But there are very few moments that are teachable where she's ready to receive a lesson and I believe, apply to teams. This is the same thing with onboarding. We have this one moment where people are very willing to accept new ways of working or to learn about how they should behave in the context of my protocol project. And it's very important to not waste that famous saying goes, you never get a second chance to make a first impression. And everyone has a security culture. Either it's explicit or implicit. Right? Like, you should make sure that yours is explicit, because otherwise, well, a, you're not in control, and b, very likely you're missing some things.
00:07:17.130 - 00:08:23.894, Speaker A: The important thing is to think about it and also to only write down the things you actually believe. Because, again, referring back to the techniques, we know all about this, right? Same as we on the surface, rationally, we know OPSEC, what we should do, what we should not do, at least 95% of it. But the difference is in actually making it real in a lived context in your project. And one anecdote from my personal experience. Many years ago, I was joining a project as a consultant, and there's always an onboarding phase where you learn about the security culture of that team you're joining, right? And they had this long Google Doc of it policy and use hardware yubikeys for everything and full disk encryption and very comprehensive. But it all broke down an hour in when I asked a colleague, I had some problem with setting up my Yubikey, I believe, and I asked him, hey, how does this work? How do you log in? And he just looked at me. This policy, nobody gives a damn about it.
00:08:23.894 - 00:08:58.208, Speaker A: Didn't say that. But that was the reaction. And then, poof. Your culture basically is gone around security. So it's very important that you actually rather do a little bit less. But the things that you do write down and teach during onboarding of how to behave, make them explicit. So the takeaway that new joiners to your team or to your project to get is, wow, they actually take security seriously here, because everyone, again, knows many things about security.
00:08:58.208 - 00:09:51.568, Speaker A: But it's another thing to take it seriously and to see other people behave that way. Access controls share credentials on a need to know basis. I'm mentioning this because I feel this is a bit at odds sometimes with the culture of defi that I guess we all like, otherwise we wouldn't be here, where it's very transparent and open and encouraging of sharing. And I do love all these aspects too, but I have experienced that a few times that this kind of translates to. Yeah, I mean, everyone should be able to deploy. We're all equal, right? Everyone should be able to deploy to the front end to production or have the deployer key and some Env file unencrypted on a local machine, which, let's be honest, many of us still do. And I think this is wrong in this context.
00:09:51.568 - 00:10:43.814, Speaker A: I mean, I think there's misguided openness here. I think there's some elements we should actually take from the old school enterprise world that we should restrict production and deploy access to as few people as possible. There's nothing to do with. We don't trust each other. It's just a security hygiene practice that it just takes one person to have a bad USP stick or a man in the middle attack at a conference on the wifi to be compromised and everything's compromised. So ask yourself, who has access to your deployer key? Who can deploy your front end to production? And do all of these people actually need to do it? And figure out with your team of how you can develop healthy culture here. Few quick notes on social engineering.
00:10:43.814 - 00:11:26.438, Speaker A: Probably all have seen the version of this. If you've been active on Twitter or discord, or anywhere where scammers and phishers abound, quick rehash of some popular techniques. Spear phishing, Google phishing. When somebody pushes their own website to the top of the Google search results with a small typo. Discord Telegram, Twitter just this week, coincidentally just this week, two of these things happened when I was writing this talk, discord of Linnea got exploited. These are screenshots from my phone. And this regularly happens, right, Linnea very big l two project backed by consensus.
00:11:26.438 - 00:12:17.722, Speaker A: Fracs Finance one of the biggest DeFi projects. They take security seriously for their smart contracts. But maybe there's a lesson there that again, security is much broader than just writing goods solution. One technique that's popular in more traditional context is security awareness training. You can think of it as an anti phishing vaccine to help build a security conscious culture. And especially as engineers, I feel like we all sometimes have this misguided belief that we know, and we've been in tech for a while, it can't happen to us, right? And 99% of the time it doesn't. I feel like I have very finely tuned spam filter in my mind, but it's still occasionally, it only needs to fail once.
00:12:17.722 - 00:12:43.430, Speaker A: Right. And to keep that filter sharp and current. Same as Apple and Google update their spam filters. I think we also need to constantly update our spam filters in our mind. And there are studies that show that it can lower phishing susceptibility by up to 80%. Do it regularly, especially for people can deploy or have access to sensitive stuff. And most of the big tech companies have courses on this now.
00:12:43.430 - 00:13:31.894, Speaker A: And it's really, it's training, right? You get some have to identify, is this phishing or not? And it teaches you a lot. And I think that's something that I haven't seen used anywhere in crypto yet, but it's quite commonly used in traditional finance or even also in web two projects. So from training in general people to training developers specifically, I think sharpen your blade, it's important. And again, it comes back to culture. There's so many courses and stuff that we can do. I have a few listed underneath this, but the key points, bootcamps, past hacks, capture the flag exercises. But the really key point again, is that we need to make time for training in our culture.
00:13:31.894 - 00:13:46.724, Speaker A: How many onboarding documents have I seen where it was like, yeah, and in our company, we make time for training and then in reality, it usually doesn't happen or it always relies on the team members proactively asking for it.

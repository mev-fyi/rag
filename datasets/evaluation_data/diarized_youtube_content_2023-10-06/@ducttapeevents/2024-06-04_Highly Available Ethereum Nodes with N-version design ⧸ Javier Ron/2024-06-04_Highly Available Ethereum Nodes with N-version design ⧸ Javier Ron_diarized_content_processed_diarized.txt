00:00:09.440 - 00:01:01.858, Speaker A: Well, hello and thanks for the nice introduction. So I'll be talking about this research paper that we published last year. It's about highly available blockchain nodes with inversion design, but the prototype that we made was entirely based on Ethereum's execution client. So I guess I can skip this slide because of a really nice introduction. So what's the problem that we are trying to solve when we say, okay, let's build a highly available piece of software, a highly available client, and it's that software fails all the time. Unfortunately, we live in a not unfortunately, fortunately, we live in a world where software allows us to do very much interesting and very much easy things. But you can see that software just fails all the time.
00:01:01.858 - 00:01:46.800, Speaker A: And it's a bit of a mess sometimes. And this happens a lot because of bugs in the code or not even in your own code. They can be bugs in your supply chain, bugs in your operating system, hardware failures. It goes up to the physical limit where you cannot control when and where your software will fail. So blockchains, of course, are software. And these are some extracts from a pretty nice report done by the Ethereum community about the reasons why Ethereum execution clients fail. And you see that there is no real consensus here.
00:01:46.800 - 00:03:24.442, Speaker A: So most of the fails are bugs and random corruptions and taking a step back. So even blockchain infrastructure fails, we have seen large players of the blockchain infrastructure having large outages, which is not nice for services that depend on this infrastructure. So as a summary of the problem we're trying to address, software fails and you cannot be 100% sure that you software, and in this case, your blockchain nodes or your blockchain infrastructure will be working correctly 100% of the time. So it is our, it is our goal to harden this infrastructure with a focus on availability. All right, so let's move on to this end version design that we, that we propose. So let's start with a normal approach of if you were like app developer, which you want to run your own node, to deploy your own web3 app, you run your node, you connect to it, but then you upgrade the version of the node, and then you have a bug in job, and then your service cannot work. So, all right, let's say that you are a little bit more cautious, and then that you connect to a service that has several nodes, but these other nodes that are not yours have, let's say the same implementation.
00:03:24.442 - 00:04:53.844, Speaker A: Let's say if it's Ethereum, they're all geth, right? And then there's a transaction that comes from the network that breaks all geth clients. And then again, your service, your application doesn't work right, then it's where it comes, this idea of inversion design. So it's decades old idea, proposed in the seventies by this person whose name I cannot pronounce. And it says that you should design software systems in a way that you design only the spec, and then you can implement this spec differently, several versions, several times, but using different technology, different teams. Much like it happens with Ethereum's execution layer and consensus layer, right? So then what we propose is that you could run some sort of this type of nodes, right? Where you have soup nodes, where these nodes have different implementations. If there's the error that I mentioned earlier about upgrading it, then your application will still have access to the chain. And then if there's some error with the other one, then there's a higher probability that your own application will have access to this chain.
00:04:53.844 - 00:06:04.238, Speaker A: One of the difference about this design is that it should go through a proxy or a broker of some sorts that has some design, some decision power on where to redirect these calls or the traffic from the external application. All right, so past the design. So we want, we kind of know that Ethereum's client diversity works. We've seen it working, but there is no academic data on how well does it work. Like we want numbers, we want percentages, we want hard data. And in this case, we implemented this prototype using the four major execution clients of Ethereum, and we deployed it sort of like this. Right? So these versions are a bit outdated because we did this experiment last year, so we could do it again to see how much it has improved or not.
00:06:04.238 - 00:07:20.464, Speaker A: So, yeah, but, okay, let's go to the experimental part of the talk. So first we want to find out a baseline. Okay, if we are saying that inversion design is the key to reliability, then we have to decide, we have to measure how different is the behavior of the different ethereum clients. So to do this, we want to measure how they react to unstable execution environments. And to do this, we measure the ethereum clients I mentioned before with 20 realistic fault injection models. These faulty injection models were based on operating system errors that we inject directly into the running processes, and we only care about one metric, the availability of their rpcs. So we spawn an application that will read, it will make requests through JSON RPC to these clients that are being actively injected with operating system faults.
00:07:20.464 - 00:08:25.240, Speaker A: A little bit on how we inject these faults. So we put layer of this injector layer on top of the OS, so that our process does not make requests directly to the OS, to the operating system, to read from disk or read from network or read from memory. So it goes through the injector, and then the injector decides if these calls succeed or these calls fail, and with which error they will fail. And with this we can simulate this hardware failures operating system box. All right, so this is what I just told you. So this is the design for this first question that we have, and we measure the availability. All right, so what's the result of that? So here's a table with lots of numbers that at plain sight don't make much sense, but if you look a bit closer, so here in these red squares, I've highlighted some unique behavior of different clients.
00:08:25.240 - 00:09:14.514, Speaker A: So this is an aggregation over all the errors that were produced during the experiment. And this is the count of how many times this error occurred. So you can see that for Vesu here, this error, invalid character response that was present in the calling client to ethereum node appeared almost 300,000 times, while in the other clients it didn't appear. And then we have some overlap of behavior. That's also true, they are not perfectly distinct. More numbers here. This is an aggregation of RPC.
00:09:14.514 - 00:10:00.844, Speaker A: We have in this column the RPC method name. And here the numbers mean how much, how available they were under fault injection. And each column it corresponds either to client. So we have all the four clients and the three most impactful fault injection models. So remember that we have 20 fault injection models. So these are the three most impactful. So the same thing here, we can see that there is different availability scores, so these clients do not behave similarly, are different by design.
00:10:00.844 - 00:11:00.614, Speaker A: Another interesting finding here is that given this fault injection models, the standard deviation over the different RPC calls is very low. So if we just measure the availability of one RPC to keep working, so we can generalize to the other RPC endpoints, because the standard deviation is very low. So you can see that these columns have roughly the same numbers in each column. All right, so to summarize that first part, how different the ethereum clients react to unstable execution environments. So a bit differently, actually a lot differently. And the important thing here is that these errors that we see are non coincidental, so that we can actually build this prototype that I mentioned in the beginning. So it will be worth to build.
00:11:00.614 - 00:12:00.090, Speaker A: Second question that we want to address, how much is the availability of eternal clients affected under unstable execution environments? So here we de aggregate the data a little bit more, so we want to see the data for each fault model, for each client, and I also want to qualify a little better what availability means. So either, so traditionally we say, okay, the RPC point is available or it's not. But sometimes under fault injection, the RPC point, the RPC endpoint is available, but it's returning bad data, it's returning old data or even garbage. Right. So this is what we call as degraded availability. Another huge table. So here we can see that again, the nodes, the client implementations behave very differently.
00:12:00.090 - 00:12:57.856, Speaker A: So we can see here that get is very good at maintaining availability. Sorry for most of the fall injection models, but actually when you take the most aggressive fault injection models, which are the last ones, BeSu is the one that has better availability. So that's interesting. Another interesting finding is that even though Aragon and get share a lot, they have a lot in common. The errors are still different in terms of availability. So you have different availability scores, and then, well, never mind, it didn't perform so well in our test, so it starts degrading a little bit fast with the first fault injection models. So in summary, these are the averages of the drops in availability that we saw when we injected these 20 volts models, right? Yeah.
00:12:57.856 - 00:14:11.576, Speaker A: So we can say that availability deteriorates noticeably, but it depends what kind of errors you're injecting and which client you're injecting them. All right, so we go back to our prototype, to our end version prototype, and we want to measure, like, is it worth it to build this thing, to have several nodes running at the same time as your, you know, as your entry point to reading data on the chain? And we do the same. Right. We deploy this conversion node with the, with the added fault injection models for each, the fault injection modules for each client. So in each of these clients, we will be injecting simultaneously faults, these operating system faults that will make network calls, fail discretes, fail memory allocation fail. We also measure the impact on availability, like I said, but we don't take this huge prototype and measure it. What we do is we first test with two simultaneous clients, and then all possible combinations of two clients.
00:14:11.576 - 00:15:04.296, Speaker A: Like what happens if we use get and Bessu, gethermind, Bessug, nethermind, right. All possible combinations, and then we move on to three with three implementations, all three possible, all n, three possible implementations. And then we move to the full implementation, which is using the four clients, more tables, more numbers, more data. And here, what I want to focus here is that there is lots of improvement. So we can see that even from using two different models, like already, that you have an average of 0.94%, 94% available using the same faults as we used for single clients. And then you can see that for n equals four, then the unavailability almost disappears.
00:15:04.296 - 00:16:02.934, Speaker A: So you still have a little bit of degraded availability, but almost 100% of times you can access and can read data from a chain. So the question here is, what is the cost of this? So if I am running my own nodes, or if I am service provider running nodes, like how much does it cost me? It scales linearly. So it's not that the cost is not trivial, the cost is not trivial, it's linear, but it doesn't scale trivially as well. So you can have combinations that are more efficient for RaM consumption, or you can have combinations that are more efficient for disk consumption, which is a problem. Right. Ethereum execution clients take lots and lots of disk. So to finish, compared to single implementation clients.
00:16:02.934 - 00:16:39.584, Speaker A: And with these specific fault injection models that we tried, we can take the availability from the highest performing Ethereum execution client up to. Yeah, so up to. Which was 91.1% to 98.4%, which is quite a huge jump in availability, unavailability almost fully suppressed. And the trade offs are kind of linear. So as expected, but they're not so easy to read.
00:16:39.584 - 00:17:52.396, Speaker A: All right, so that was it. So yeah, ethereum clients behave very differently, they fail very differently, and you can use them to create your more resilient nodes with this leveraging, this diversity, this non coincidental behavior under fault, under fault injection, under unstable execution. Yeah, actually fun fact, I run a lot of my execution loads, so I don't want to run this much nodes again, it was a lot of time and network consumption, so 660 synchronized from scratch. So it was quite a bit of work. So a little bit of future work. So we like diversity, software diversity at our team. So one of the things that we're looking at right now is we only have four implementations, right? But maybe we can have more, maybe even if the degree of diversity is a little bit smaller.
00:17:52.396 - 00:19:01.164, Speaker A: What happens if you take one function of your program and diversify that function? So you could just technically have a different implementation that you can leverage to build a sort of system like this. So we're looking into that. This is automatic and verifiably correct software diversification. Another thing that we are looking into is moving the client diversity incentives on chain. So right now we have some reliability incentives given slashing on the consensus layer. We don't want to, to have a supermajority but it's mostly about we should do this. But what if we incentivize this with on chain rewards, something like slashing or some reward of some kind that if you run a minority client, then you can actually earn a little bit more of stake or get slash less severely.
00:19:01.164 - 00:19:16.744, Speaker A: Things like that. All right, so this was a talk about highly available Ethereum nodes in reality and with software diversity, with client diversity. So if you have any questions. Thank you.
00:19:17.044 - 00:19:36.462, Speaker B: Thank you so much. Please, a round of applause for Javier and his fantastic talk. Thank you so much. Right, ladies and gentlemen, any questions from the audience? And by the way, props up to you supporting your friend from the front row. I love that. It's a good community. Yes, sir, you'll have the microphone with you in a second.
00:19:36.462 - 00:19:37.314, Speaker B: Thank you.
00:19:42.974 - 00:19:59.618, Speaker C: Hi, thanks for the talk. Just a quick question. In terms of the faults that you were intercepting at an OS level, was it only faults that were requiring a reread or rewrite to memory, or did you simulate any more catastrophic failures as communicated by the hardware or kernel?
00:19:59.746 - 00:20:45.794, Speaker A: Yeah. So how we selected the faults was a little bit more complicated than what I presented. So first the thing we do is we monitor all system calls, and then we kind of record the error rate of how often do they fail? Because they fail a lot. So these re reads, they happen a lot. Network failures, they happen a lot, but they're handled well by the libraries or even by application code, but sometimes they're not. And this is like when we inject failures, what we do is that we amplify this normal error rate that we have. And this is for all calls that happen for a specific client.
00:20:45.794 - 00:20:47.186, Speaker A: Yep.
00:20:47.370 - 00:20:48.818, Speaker B: Thank you. Please.
00:20:48.906 - 00:20:49.202, Speaker A: Right.
00:20:49.258 - 00:21:16.904, Speaker D: So in default injection modules, for example. So I understand, you intercept system calls and you will return errors statistically. For example, the read example you showed. But do you also have time based injections, like, for example, read that succeeds, but takes a random delay before doing so, which in a threaded environment could result in different causality graph or packets received in the wrong order.
00:21:17.884 - 00:21:46.764, Speaker A: Yeah, I understand perfectly what you mean, but no, we didn't test that, so we only changed the error code. But it is a great fault model. Messing around with the concurrency of the threads is a very good fault model. You can actually check if you have no deadlocks, if you have no simultaneous reads, simultaneous writes things like that, which is very good. I should look into it. Thank you. Thank you.
00:21:46.924 - 00:21:47.700, Speaker D: Great talk.
00:21:47.812 - 00:21:48.388, Speaker A: Thank you.
00:21:48.476 - 00:22:25.014, Speaker B: Thank you very much. Anyone else would like a question from the audience? No? Okay, I've got one. Mine's much more high level. It's absolutely mind boggling what you've achieved. And congratulations to you and your colleagues, at least in the Czech Republic, blockchain hasn't even been registered at some of the technical universities. I'm curious when it comes to things like technological traffic transfer, working with the private sphere, whether you can make certain recommendations to concrete companies or concrete communities, and how that kind of interaction between the academics and the entrepreneurs is basically coming along in this very kind of fresh new community.
00:22:25.874 - 00:23:08.488, Speaker A: Yeah, so I'd like to say that. So we're very open to collaborations. So, yeah, you can just contact me or the university directly or colleagues. My supervisor very active in the crypto space and, yeah, we're very open to collaborations. We don't move as fast maybe as, you know, as startups or companies that have lots of money, but we're there, we want to contribute and we want to contribute the way we know how, with hard data, with facts, that we can spend two weeks, three weeks looking at a table with a lot of numbers and try to get some insight from there, and then that can be helpful for everyone.
00:23:08.656 - 00:23:27.384, Speaker B: The tough but rewarding world of academia. Thanks to people like Javier, we can take blockchain to the stratosphere. Thank you so much for your inspiring talk. Give him one more round of applause, please, and I'll see you very shortly with it. Another talk on this fantastic main stage. See you soon.

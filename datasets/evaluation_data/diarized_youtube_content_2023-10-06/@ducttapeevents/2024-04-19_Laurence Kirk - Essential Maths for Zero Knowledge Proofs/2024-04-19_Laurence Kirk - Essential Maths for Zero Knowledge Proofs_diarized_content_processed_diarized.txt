00:00:00.240 - 00:00:12.954, Speaker A: Thank you. Hey, everyone. I hope you're all having a good day. If you've brought your lunch in, hope you're enjoying that. So today's talk. Oh, it's gone blank. Well, there will be a QR code.
00:00:12.954 - 00:00:39.470, Speaker A: There we go. So there's a QR code so you can get the slides for this one thing. I've done this talk before, so quite often I don't get to the end, which is a shame because I do like to, to share all this information. If I, if people, if I don't go to the end or if people want more, I'm more than happy to set up another session online. So I've got some contact details. Yeah, there. If you.
00:00:39.470 - 00:01:22.754, Speaker A: So if you want to know more, please join our discord server or dm me by some means or other. And if you want to see this again online, I can set that up. So just let me know. So yeah, there's contact details, so please use those if you would like to. All right, so what this talk is aimed for is for people who are new to the idea or new to zero knowledge proofs, new to the maths behind zero knowledge proofs, it can be quite a daunting topic. And there's a lot of terminology. If you start to read articles about zero knowledge proofs, there's lots of terminology that you may not be familiar with, lots of areas that you may not have come across before, and it can be quite daunting.
00:01:22.754 - 00:02:03.534, Speaker A: Now, my belief is that this area is accessible to people. It can be explained to people. People can understand it to some extent and can get some insight into how these things work. And so that's what I'm going to try to help you with today by giving you some of the background math, some of the background terminology. So you can then read articles, you can look at zero knowledge proofs and get more insight into how they work. Some good quotes here from some people working in the area. This stuff is hard, I accept that, but it can be explained to some extent.
00:02:03.534 - 00:02:31.252, Speaker A: Please do ask questions. If I'm not explaining this well, I really do want you to be able to understand this. My advice though, is don't try to understand everything at once. There's lots to take in, so take it at your own pace. Certainly get familiar with the terminology. This is one of the things that I found perhaps confusing when I initially started looking in this area. There was suddenly all these new symbols and terminology that I hadn't come across.
00:02:31.252 - 00:03:11.070, Speaker A: And when I actually dig into the area and look at what these means I found out, sorry, looked at what these mean. I found out that these weren't such difficult concepts after all. It was just that they were new to me at the time. So what I hope I can do is by introducing you to these, is to give you an idea of what they're about, and that will help you understand zero knowledge. Also a good idea is to try to chunk some of these topics and some of these areas. One of the problems I found with the articles and the literature in this area is that often they jump in and do a kind of a depth first approach. They'll go in and go into a huge amount of detail straight away.
00:03:11.070 - 00:03:59.784, Speaker A: And that's really hard to follow. What I find is easier to follow is if you take a look, a sort of high level look at the overall process, and then gradually work your way down and chunk areas. And maybe if there's an area that is confusing or you don't understand, we'll accept that and just treat that on its own as a little black box or something like that, and then come back to that later. Okay, so that's the approach. So let's look at some of the terminology we're going to cover. So when people started developing zero knowledge proofs, and I mean, this goes for cryptography as well, I guess what we've tended to do is to restrict ourselves to very specific sets of numbers. And the reason is that these are easier to work with.
00:03:59.784 - 00:04:41.954, Speaker A: This makes our life a lot easier. And so pretty much when we're talking about zero knowledge proofs, when we're doing the math, when we're doing the operations, we're talking about operations being done on integers. And for those you get this z symbol with the double slash. Of course, there are other types of numbers as well. The ones that you will be using day to day will go to be more like the real numbers, but with general proofs, we've restricted what we are working on, and this makes our lives easier, gives us easier representations. And in fact, what we do as well is we build our maths around things called finite fields. And I'll explain what they are in a moment.
00:04:41.954 - 00:05:21.276, Speaker A: And you will see some of these symbols like the Z with the asterisk and the Pl. I'll explain what that means, but you'll see this quite a lot and it's not difficult to understand, but if you've not come across it before, is going to be a little confusing. All right, so another thing we do when we're doing operations is we use modular arithmetic. And I'm guessing that a lot of you here are maybe developers, and so you've probably come across these kind of operations. The idea that we're more interested in the remainder when we do our operation. And yeah, I'm sure you've used the mod operator in various languages, sometimes called clock arithmetic as well. It's just.
00:05:21.276 - 00:05:57.836, Speaker A: Yeah, we're interested in the remainder. So we're interested here in the. I guess that's the minute hand or something rather than the hour hand, but yeah, so we use that because we work on sets of numbers that have a maximum number, so we need the ability to wrap around. And so we're working within a fixed set. Okay, now, one topic of maths that you probably didn't do at school is group theory, and it's not particularly conceptually that difficult, I don't think. But it's probably, you just probably never come across this. But this is.
00:05:57.836 - 00:06:35.274, Speaker A: We do need to understand this a little bit. We do need to know some of the terminology that is involved here. And the way I like to approach this is to think, well, the mathematicians and the cryptographers have just. They're using this because it gives some useful properties to the numbers that were we have. And what they've done is they've just chosen some sets of numbers and some operations because that works, because that makes their lives easier, because it means we can do things with those. And if you take this pretty much at face value, then I think it's easier to follow what's going on. So the idea behind a group is you take some set of elements.
00:06:35.274 - 00:07:24.156, Speaker A: In our case, we're going to be using numbers. It doesn't have to be numbers, I guess, but we are going to be taking numbers and we take some operation. And in this case, I've represented that as a dot. And then we say that given this particular set we've chosen and this particular operation we've chosen, we can regard this as a group if it follows certain properties, if it has certain features, and those are the features I've got here, I'm not going to go through all of them because we don't have a great deal of time. But some of the important ones, the first one, for example, closure. This makes sense because we've chosen our set of elements that we're interested in, that we're going to be using, and we've got our operation and we're going to be doing operations on these elements. Now we want closure so that every operation we do on any element is always going to give us a result that is, in our set of elements.
00:07:24.156 - 00:07:54.120, Speaker A: We don't want something that is going to be outside the set of elements. We want it all to be nicely self contained. So I think that makes sense. It's sensible to be able to do that. Other things we need to know about the idea of an identity element. So the easiest way to think of this is if you think about some operations that you're familiar with. So, for example, if you think about addition, an identity element for addition will be zero, because if you add zero to an element, you just get the same element again.
00:07:54.120 - 00:08:30.756, Speaker A: So it's, again, simple concepts, but just terminology you might not have seen. And then the inverse element. This is the idea that if you take one element in our set, there's always going to be an inverse for that element. So that when you combine these using this operation, we get back to the identity element. So if we're talking about addition, then, and you're thinking of, say, some positive integer, then a negative integer of the same value would be the inverse for that. So. Yeah, and that's just more terminology, of course.
00:08:30.756 - 00:09:18.086, Speaker A: We've chosen this group of elements. It could be that there's actually a smaller group within that set, or a smaller set of elements within that bigger set that is also a group, and that's called a subgroup. And then we also have this idea that there's a possibility that this group could be cyclic as well. So this means that we can start with some element that we call a generator, and then we can repeatedly do operations, and this will take us through all of the elements within the group. Okay, now, if we extend that, we get the idea of fields, and the example I'm going to give here is to say that we're going to have two operations. We're going to have addition and multiplication. But again, we start off with some set of numbers, a set that is going to be useful for us.
00:09:18.086 - 00:09:57.592, Speaker A: But now we have two operations. But again, what we do is we say, well, if we have this set of elements and we have these operations, then it's going to be a field. If certain properties apply, it has certain features, and they're very similar to what we had before. So you can see we've got things like the identity element, and we've got things like inverses. Now let me see if it's on the next slide. Yeah. One potential problem or difficulty, I guess, with this, when you think about multiplication, is that if we think of multiplication, we tend to think, well, if we think about an inverse, we would think be thinking about division.
00:09:57.592 - 00:10:45.264, Speaker A: Because we typically sort of see that as the opposite of multiplication. But the problem that we find, if we're using finite fields or if we're using fields and they are fields of integers, we have to be careful with division because if you divide some integers, you might get an integer, but you might get something that is not an integer which would be outside our set. So the inverse under multiplication is a little bit more problematic. It's more difficult to find, but there is a way to find that, and I'll explain how to do that in a second. Typically we talk about finite fields. So we're going to have a set of elements that has a maximum number and we use modular arithmetic. So if we go past that number, we're just going to start again at the beginning.
00:10:45.264 - 00:11:30.044, Speaker A: Quite often this maximum number is going to be a prime. And if you look at the finite fields underlying a lot of the zero knowledge proof technology and things like elliptic curves, you will see that they have a maximum number that is a prime and that these are relatively large numbers. And the other terminology, you might come across the order of the field. That's just the number of elements that we have in our field. Okay, so again, we have things like generators in finite fields. So really this is an extension of a group. We're getting the same types of things happening that we have in a group.
00:11:30.044 - 00:12:09.104, Speaker A: And if we have a generator, this means that we can do some operations, such as if we using multiplication, we can repeatedly multiply, and then this will take us through all of the elements within our group. So a useful property to have. And this is used in the way that zero knowledge proofs are constructed. There's an example there, a nice simple example to show you. So we have a group, we've decided just to take five elements. So 01234 so they are integers. If you look at some of the operations, you can see that we can use modular arithmetic.
00:12:09.104 - 00:12:58.766, Speaker A: So it gives the answers there when you do multiplication. And then also we can work out some of the generators as well. So if you start with two, that can generate all of the elements within the group or within the field, similarly with three as well. Okay, all right, so that's just a little terminology about groups and fields. But when we're doing, certainly finite fields form the basis of when we're building zero knowledge proving systems. I'll just talk a little bit about complexity theory because this is useful. Well, it's really where zero knowledge proofs came from, or part of it, but also it's useful when we want to look at different proving systems and to compare them and decide which ones are feasible or not.
00:12:58.766 - 00:14:08.910, Speaker A: We often use some ideas from complexity theory. I'm not going to go through all of this again, because there's perhaps more than we need, but I'll just mention some aspects of it. So complexity theory itself is a very interesting area of computer science or maths, and it's all about looking at problems and trying to get see if we can group problems together that are similar in some way and seeing whether we can classify problems. And what we typically do is we look at a problem and we look at how easy it is to find a solution to that problem, particularly in terms of the size of the problem. And so if we take the very famous example of the traveling salesman problem, that is a problem where we have a route that a salesman is taking between various cities, and we want to know whether that is the most efficient route that the salesman could take. Now, when I talk about that example, you could say that the size of the problem is determined by the number of cities that are involved. And if you have a small number of cities, then it is a relatively easy thing to solve.
00:14:08.910 - 00:14:54.392, Speaker A: It's relatively easy to make a decision about whether you've got the optimal route or not. So if you've only got three cities, that's not going to be hard to solve. But as you increase the number of cities, as you increase the size of the input to this problem, then it very quickly becomes much more difficult to find a solution, and it will take you much more time to find a solution. And in complexity theory, we measure things. We usually talk about the time complexity, but we could also talk about the space complexity, which really relates to how much memory you would use in a computer if you were trying to solve this. But yeah, we're usually talking about the time complexity. And what we find when we look at these types of problems is they do indeed fall into a number of categories.
00:14:54.392 - 00:15:58.286, Speaker A: They have certain similarities. But really what way we're going to use it is to be thinking about how the time taken to solve a problem, or actually often we're talking about given a solution, how quickly can we verify that solution? And we want to look at that in relation to the size of the problem. So in relation to the input, how, how does the time taken to a verifier solution, how quickly does that grow? Because that gives us an idea of the efficiency or that the feasibility of one of our proving systems. And the, it's not a great. Yeah, so one classification of these, these types of problems is is called the p class or polynomial class. And what this means is that when we have one of these problems, in the worst case, it's going to increase according to some polynomial of n, where n is the size of the input. So if it was the, we're talking about the number of cities, then that's what n would be.
00:15:58.286 - 00:16:47.436, Speaker A: And even though that might sound like that is quite large, actually, this is seen as quite a feasible thing. So we're talking about the time taken to solve or to verify a solution maybe is proportional to n to the k, where k is probably some reasonably small value, but some constant. And that is the polynomial class of problems. And if your problem falls into that class, that's seen as being tractable, that's seen as being feasible to solve, and we, that's what we would like. These are the types of problems we want to work with. The way that we tend to talk about these problems is we term them in terms of a decision problem where we say it's going to be give it a yes or no answer. That's just the way they decided to do things.
00:16:47.436 - 00:17:24.532, Speaker A: But the classes that we get are shown here. Now, the reason we've got two diagrams is there's an open problem in maths, whether one of these classes, p, is equivalent to another one of these classes, np. And this is an open problem. If you know the answer, there's a very large prize waiting for you and fame and fortune, but at the moment it seems that they are probably not equal. I think the consensus is, but it is still open. So our class of problems p, these are the ones that are solvable in polynomial time. And then the other classes that we have, these are shown here.
00:17:24.532 - 00:18:09.164, Speaker A: I'm not going to go through all of them. The interesting one mainly is the NP class. So these are seen as being more difficult. But particularly what we are interested in is these class of problems are ones where it could take a long time for us to find a solution, but to verify that solution, we can do that in polynomial time. So the solution can be verified in polynomial time. And this oddly enough, or maybe not oddly, but this ties in very nicely with zero knowledge proofs, because with zero knowledge proofs, one of the things, what we're trying to do is we start off with some computation. For example, we create a proof of that and then we want to verify that proof, and we want to make this efficient, we want that to be feasible.
00:18:09.164 - 00:19:25.274, Speaker A: And so we like this idea that we have something that can be verified in a small amount of time and in fact, there is a relationship between these types of problems, the NP problems and zero knowledge proofs. If you want an example of this type of problem, you can think of this one I was showing here where if you imagine you've got some encrypted piece of text, if you try to decrypt that just by guessing the encryption key, that would take you a long time and you just have to just brute force the key really, and guess at that. But once you've got the key, if you want to verify that you've got the correct key, you can do that very quickly because you can just use that key to decrypt the text and it should come out as something sensible. So the verification can be done in a short time even though the solution is going to take you much longer. I won't go through the other ones. They are interesting, but we don't really need to know too much about those. One useful thing to know, I don't know if I've got this here, is that there is a relationship between problems in NP and zero knowledge proofs in that you can create a zero knowledge proof from problems that are in the NP class.
00:19:25.274 - 00:20:23.888, Speaker A: The other, the article quoted there, the other thing that I just mentioned at the bottom here, another class where we have the IP class, the interactive proof class. This is really the basis of where zero knowledge proofs came from because they were thinking about how we create mathematical proofs. And typically that would be you would go through a number of steps and then at the final step you would have the thing you were trying to prove. And if you can get there correctly, then there's your proof. And what some people started to do was to say, what if we make this interactive? What if we say we're going to go through some steps, we're going to have someone that's going to interact with us, and maybe that person who's interacted with us is going to have some going to be able to use randomness as well and ask us questions about our proof. And it's going to be more of an interactive process. And that really is the basis of where we started with zero knowledge proofs.
00:20:23.888 - 00:21:11.588, Speaker A: And there's some very good videos explaining all of this. So there's a link to that there. Okay, how am I doing four now, why we need to know this particularly where it becomes particularly useful is we have some notation for representing the complexity, and this is the big O notation. And so with the big O notation what you're doing is saying in the worst case, how does the time taken either to solve the problem or to verify the problem. How does that change according to the size of the input and the size of the input we're usually representing by nice. And so you will see things like this, we will have big o of n squared. That means that as n increases, the time taken to find a solution or time taken to verify a solution will change according to n squared.
00:21:11.588 - 00:22:20.744, Speaker A: And so this is the terminology, this is the notation that we use to compare proving systems and to try to decide whether they are feasible or not. And if you think about the way that n could change, obviously, if it's according to root n, that's going to be better than if it's changing according to, say, n cubed, something like that. And this table is rather old, I'm afraid. But it is quite useful because it shows, admittedly a few years ago, the complexity, or it gives you a comparison of different types of proving systems. So at the time, there were really sort of three main families, I guess, of proving systems. We had the snarks, the starks and bulletproofs. And if I take the second row, sorry, the third row down there, if we look at the size of a proof when we're generating a zero knowledge proof, if you do that in one of the original snark systems, what this means, we've got big o of one, which means that no matter how big our input is, the size of the proof is constant, which is a great result.
00:22:20.744 - 00:22:47.804, Speaker A: That's what we want our proof sizes to be as small as possible. So that works very nicely for snarks, but for stocks, it doesn't work quite so well. Obviously, it changes according to the size of the input, but that gives you an idea. This is what we use. This is the terminology we use when we're comparing different types of proving systems. But this is a little bit out of date, so don't take it. Yeah, perhaps look at a more updated version.
00:22:47.804 - 00:23:24.894, Speaker A: So that's a little bit about some notation and about complexity and how we can compare systems. Another mathematical object that we use a lot is very useful, are elliptic curves. There's actually a talk about elliptic curves, I think, just after this one, so I'd advise you to follow that. But these are curves. They follow a kind of formula, similar kind of formula. But what's nice about them is they actually have, if you look at the points on these curves, they can form a group. So they have some very nice properties.
00:23:24.894 - 00:24:20.248, Speaker A: And elliptic curves have really been the, have been the basis of a lot of the types of cryptography. And for example, signature schemes that we have used, and they are then quite nice compared to other types of signature schemes you get, because they, they require much smaller keys for the same level of security. Now, yeah, I said they form a group. The points on the curve form a group, which means if you do an operation on the points on the curve, then the result of that will also be a point on the same curve. But we are restricted on which operations we can do. Now, you will often see them represented like this. And this shows a sort of geometric representation of doing some operation on some points on the curve.
00:24:20.248 - 00:25:18.930, Speaker A: So you've got, we're doing some operation on P and Q, and that is going to give us the point r. But the point is that whatever points we choose and whatever operation we do, the result is always going to be on the curve. And the cryptographers, they will choose the equations for these curves, to give them things, to give them curves that are going to be useful, are going to be quite efficient. So they choose them. And different projects, you will see they have different named curves, as you can see here, some of the names of them, these have just been chosen because they work quite well. Maybe they're quite efficient when they're being used. I probably don't need to say much about this, but the scale of multiplication, this is just a way that we can easily do sort of extend the operation, because if we don't have the multiplication operation, we can instead just do repeated additions.
00:25:18.930 - 00:26:15.856, Speaker A: And that will give us the same as doing a multiplication if you do that a certain number of times. Okay, roots of unity is something else. You may, another term you may come across, and this is to do with a, when we have the points on our curve, we also include a special point, which is this point at infinity. And we just have this property that for particular points on the curve, if you effectively multiply them doing that by repeated additional, if you do that and you get the result one, then these are called then a root of unity. So you will see this terminology as well. That's where it comes from. Okay, so, yeah, that's the visualization you often see, actually, if you, this, sorry, this one is drawn over the real numbers.
00:26:15.856 - 00:26:43.274, Speaker A: Okay. And that gives a nice visualization if you actually do it in the kind of underlying fields that we are going to use. If you do it in a finite field where we're doing modular arithmetic, you actually get something like this. So this one is in a field or over a field, mod 191. And if you, and it's using integers only if you plot that, that's what an elliptic curve looks like. But you know, it's not as nice to look at. So people tend not to show that.
00:26:43.274 - 00:27:25.704, Speaker A: All right, is that okay so far? All right, I'm getting some nodes. That's good. Okay, so other terminology, you will see there's a process called pairing. And this is, it can be, I guess it's quite complex, but it is something that is useful when we are for some types of, well, proving systems or some aspects of systems called polynomial commitments. We need to be able to do this process ball pairing. And it all comes back to the ideas of being able to do things as groups. And this gives us some special property, this gives us some kind of shortcuts when we can do them.
00:27:25.704 - 00:28:42.142, Speaker A: So if you've chosen your groups in a certain way, if you've got the right types of elliptic curves, then we can have this property where we can do this pairing, which means that we have, so here we've got g one, g two and, and gt. So these are three groups. So these could be three groups, each of which is formed by the points on an elliptic curve. And if we have, if we can do pairing on these curves, then what we're doing is some operation between groups g one and g two, which are going to give us the group gt. The final group there, there's a couple of properties they have which we don't really need to say much about. But the, well, the final one is useful because if we've got the correct elliptic curves, if pairing is going to work for them, then this gives us some useful properties. So you get for the different points within the different groups, we can then write out equations like this and things like at the end there where you're adding points, but you can change from the additions there into some multiplications.
00:28:42.142 - 00:29:24.504, Speaker A: And this again is just some background information really that is useful if you see pairing. People are doing this because they want to be able to do these sort of operations on the points on the group because that's going to be useful. Okay. Now if you start looking at zero knowledge proving systems, what you will find is that pretty much everything revolves around polynomials, which is good in a sense, because polynomials are things that you've probably come across before. You've probably had some experience with at school. You've probably used polynomials, you've tried to solve polynomials. And these are quite remarkable objects.
00:29:24.504 - 00:30:34.596, Speaker A: One great thing about them is that they can, they can do, they can hold a great deal of information and with zero knowledge proving systems. What we're often what often we do is we will have a prover who is trying to make some claim, and this claim will get transformed. It may be some computation, or it may just be that they're trying to say they know some numbers, but that claim will get transformed into different formats. But what we do is we transform it into polynomials. And the reason we do that is that polynomials have all sorts of useful properties, which means we can manipulate them and draw all sorts of conclusions about them quite easily, and they can hold a great deal of information. And that's what this quote from Vitalik is talking about, saying that, yeah, if you have a polynomial, even though they look simple, with that kind of equation, they can actually hold a great deal of information. But of course, when we're doing this in real world, zero knowledge proving systems, we have polynomials that are much bigger than that, and maybe there would be a million terms or something like that.
00:30:34.596 - 00:31:43.394, Speaker A: So they can be quite large in that sense, but still they can hold a lot of information. And then, particularly if we start to build up relations between polynomials, the details we've got here, these capital a, b and c here, if we can write an equation down like that, then that is an incredibly powerful thing that we have, because that means for any value of x that we choose, we can, this equation is going to hold. So you can say things like that. And what we'll see is that the process of doing or verifying proofs often comes down to being able to easily evaluate polynomials, but also to generalize about the polynomials that we have. It's also useful that polynomial manipulation is quite easy. So multiplying them, etcetera, is quite nice, and we can divide them quite easily. Although when you get big polynomials, there are special techniques that you can use as well.
00:31:43.394 - 00:32:28.474, Speaker A: One technique you will see is this process of breaking a polynomial down into smaller polynomials. And this relies upon the fact that you have this thing called the root of a polynomial. So you've probably come across this, you probably use these or done these at school, you've tried to find a root. What it means is that the root of a polynomial is the value of x, if that's the variable for your polynomial, where the polynomial evaluates to zero. And if you can find that. So here I'm saying the particular point at which this polynomial p, evaluates to zero is r. And if I know that, then I can rewrite my polynomial p in this term of, I can bring out this extra term, x minus r, and multiply that by another polynomial.
00:32:28.474 - 00:33:46.522, Speaker A: But it's a polynomial of smaller degrees, a slightly simpler polynomial. And this technique is used quite widely, and you can build up this quite a lot with zero knowledge proofs. Now, one of the really fundamental parts of proofs is this lemma here, which is saying that different polynomials are different at most points. And this really goes to the heart of why polynomials are useful in that we can easily make, we can easily check on them, we can easily decide whether two polynomials are equal. And as a starting point for understanding zero knowledge proving systems, you can think that maybe the prover is going to encode their claim in a polynomial, and then they're going to give this to the verifier, and the verifier is going to check whether this matches a kind of an ideal polynomial. Now, there's lots of, that's inaccurate in all sorts of ways, but as a starting point, we can think of something like that. And why polynomials are useful is that the verifier can very easily check whether the polynomial they've been given is in fact the one that they want is in fact correct or not.
00:33:46.522 - 00:34:28.144, Speaker A: And because what we would like is a prover to be, to be passing their proof to the verifier, and the verifier to be able to make decision very quickly whether that proof is correct. Maybe just doing a few, a handful of checks on the polynomial to see if it's correct. Now. And that's why this lemma is particularly useful. You can see it visually in this kind of thing. So we've got two polynomials that are different and they intersect at one point, but for most points, you can choose they are different. So if I gave you the evaluations of the blue and the green polynomial at different points, you could see that they are different.
00:34:28.144 - 00:35:20.474, Speaker A: And if you wanted to do that with a minimum number of checks, and you just started picking points at random, well, you probably would find they're different. The chance of you picking the point where they intersect is fairly low. And this is particularly true when we talk about the types of fields that we use and the types of numbers, the sets of numbers we use for zero knowledge proving systems, because the order of those is going to be things like two to the 250. So if I pick a number at random and I evaluate polynomials there, the chance of them intersecting if they are in fact different, is very low. And that gives us a bound. When we're looking at our zero knowledge proofs, that gives us a bound on how likely it is that we will accept an incorrect proof. Okay, but I have missed a lot of things out there.
00:35:20.474 - 00:36:05.890, Speaker A: Particularly when I say about the prover sending a polynomial to the verifier, this is wrong in all sorts of ways. It's wrong partly because of the zero knowledge aspect, because the prover wouldn't actually want the verifier to have all this information. They're wanting to keep some inputs to the proof secret, so they really wouldn't want to send all of the information to the verifier, in case the verifier could somehow reverse engineer that and find out the secret information. Also, in terms of what is called succinctness, we don't want that, because we want a very small amount of information to be passed to the verifier. And when the verifier is checking something, for example, imagine I've done a computation. This is a long running computation. It took ten years to run.
00:36:05.890 - 00:36:51.910, Speaker A: But at the end of it, I create a proof that that computation is correct. Now, if I pass that proof to a verifier, I don't want the verification time for that proof also to be ten years, because there would be no point in that. They might as well just rerun the computation. What I want and what we get is the fact that we can verify that within, say, milliseconds. And so this concept of succinctness, the idea that the work that the verifier has to do is going to be much smaller than the original computation, or that when we're passing information to the verifier, we don't want to pass too much. That is very much at the heart of the types of proving systems we want to build. So, in fact, the approver doesn't really send the whole polynomial to the verifier.
00:36:51.910 - 00:37:31.622, Speaker A: What they do send are commitments to the polynomial. But before I go into that, I'll just mention some points about representations of polynomials. So when you look at something like that, in fact, if we go back here to the original equation, we've got, this is, this is called maybe the coefficient form of a polynomial. We've got, you know, the coefficients of various powers of x. So that's one representation. If you wanted to write out a polynomial, that's one way you could write it. The other way you can describe it, though, is by giving the points of the evaluations of that polynomial.
00:37:31.622 - 00:38:09.998, Speaker A: So these are the red dots on this diagram. So either of these is equivalent, and we have means to move between the two representations. So if we have our coefficient form, and we want to move to the point form, we can evaluate the polynomial at various values of x. If we want to go in the other direction, if we have the points and we want to know the coefficients, we do a process called interpolation. And one way of doing that, excuse me, is called, is lagrangian interpolation. But it's a way we can move between those two representations. Okay, which is what that says.
00:38:09.998 - 00:39:06.776, Speaker A: Okay, so how do we use these in zero knowledge? So, yeah, this is the process I spoke about. Generally, we get the idea that the, the prover is using polynomials in some way, giving these to a verifier. The verifier, when you're thinking about these systems, think about the motivations of the prover and the verifier. So the prover wants their proof to be accepted, and they don't want to give the verifier secret information. The verifier is suspicious, and they think that the prover may be cheating, and so they want to satisfy themselves that that proof is correct and the prover isn't actually cheating. And so the verifier, they will get some information, some representation of a polynomial, maybe, and they will want to check this. And one of the aspects of polynomials that is useful is that we can do checks.
00:39:06.776 - 00:40:29.494, Speaker A: What we do is we pick a random value from this big field that we're using, this big finite field, and we say to the proverbial, evaluate your polynomial at that point, and then tell me the result. And this makes it very difficult for the prover to cheat because they don't know in advance what value the verifier is going to choose for this. So even if they craft their polynomial in a certain way, that would work for a few points, but wouldn't be true in general, then they're likely to be found out because the verifier is going to be giving them these random points from a massive range. And so it's going to make difficult for the prover to cheat that also, I spoke earlier, this idea that the verifier has this idealized idea of what the answer should be, actually, I mean, this varies with different systems, but it's more the case that they have an idea of relationships between polynomials. They don't know exactly what the polynomial, the prover is going to send. That polynomial has secret information in it. So it makes sense that the verifier couldn't know exactly what that is going to be, but they would know certain properties of that polynomial, or more specifically, certain properties about a group of polynomials that the prover is sending over, some relations between those polynomials and the verifier can then do these checks.
00:40:29.494 - 00:41:21.106, Speaker A: They can do evaluations on these polynomials and then see if the properties that they're expecting still hold. And from that, they can make a decision about whether the information the prover has sent is correct or not. And so you get things like, and I'm sorry, this has gone over two slides, but you get things like relationships of polynomials, like you've got at the bottom there, where you've got two polynomials being multiplied together. And so what the verifier can do is to check that this is the case. I can divide them. And see, when you divide these polynomials, does this produce a polynomial in itself, or is there some remainder? And if there's some remainder, this is not an exact division, and therefore, there is something wrong with what the approver has sent. Okay, now, I said that we don't send the whole polynomial.
00:41:21.106 - 00:42:01.200, Speaker A: And with this, you know, there's good reasons for that, partly for to, we don't want to send too much information to the verifier, also because, sorry. We don't want to send secret information to the verifier, also because we don't want the information to be too large. And so a better approach is to send a commitment to a polynomial. Now you've probably come across the idea of commitment schemes more generally with things like hash functions, where you can take some kind of input, a message, something like that, and commit to that. You put this through a hash function, you get a result. And because hash functions are collision resistant, that means that gives you a commitment to that specific value. No other value would give you the same result.
00:42:01.200 - 00:42:55.664, Speaker A: And similarly with polynomial commitment schemes, it's a way that we can commit to a polynomial. And so when we have the process in zero knowledge proving systems, with the prover and the verifier interacting, what we can do at the start is to say to the prover, okay, I want you to commit to a polynomial or a set of polynomials, and once they've committed to that, they can't then change their mind. And when the interaction is going on and the verifier is saying, okay, evaluate your polynomial at these points that I've chosen at random. The prover can't then go back and take a different polynomial or craft their polynomial in a different way. They've committed to a certain polynomial at that point. The other useful thing is that with these, these types of schemes is that it gives a compact representation of the polynomial as well. And it means we're not having to pass a huge amount of information.
00:42:55.664 - 00:43:52.324, Speaker A: If you had to pass a polynomial with 10 million terms, that would be a lot to send to the verifier. Instead, if we can pass some commitment to it, a much smaller amount, then that's going to help. And because of the properties of polynomials and the. This idea that we can put them together and build these powerful relations and equations with them, that will be true for any value of x, we can really generalize. So, if we have something like this equation here, the p of z times q of z, et cetera, if we know that that holds for a particular value of z, one that we've chosen at random, then we can generalize that and say, well, it's overwhelmingly likely that's going to hold for any value that I come up with. So this really helps the verifier when they're trying to make a decision about the correctness of what the prover is telling them. Okay.
00:43:52.324 - 00:44:27.464, Speaker A: And, yeah, generally, the schemes. Commitment schemes have two nice properties. There's the binding property, which is making sure that we are committing to an exact thing because it's collision resistance. So we know that they are committed to an exact polynomial. And then also the hiding property, there's some obfuscation going on, so that when the. The verifier interacts with this commitment scheme, they're not finding out too many details about the polynomial itself. Maybe they're just getting the evaluations of that polynomial at certain points that they're asking for.
00:44:27.464 - 00:45:11.404, Speaker A: There are different types of commitment schemes available, and, really, these have very much shaped the. The families of proving systems. So, as you can see here on the left hand side, we've got things following the fry scheme, which is really the family of Starks. And then we've got, on the other side, we've got the KZG, which is planck, and a lot of other snark based systems, which rely on pairing. So that's why we need to know about pairing. And there are other ones as well, but these are the basics. And these polynomial commitment schemes really form the heart of our proving systems.
00:45:11.404 - 00:45:46.796, Speaker A: These slides are from the study group, which is quite useful, but they show how some of these different things relate to each other. Just do this very quickly. So, the ones on the left there, the hash function. That is the fry sort of basis. Fry based schemes. And you can see that they have all sorts of useful properties that some of the other types of polynomial commitment schemes don't necessarily have. But then, if you look at the proof size, et cetera, the pairing groups.
00:45:46.796 - 00:46:09.372, Speaker A: So things like KZG they do give you better proof sizes. So you can look at these different comparisons, and that may help you decide what types of proving systems you want. It also, you can talk about the security, but I don't just go into that. Is that okay? So far I've gone very quickly through that. Yeah, go on. Have a question? Yeah, go on.
00:46:09.548 - 00:46:21.344, Speaker B: Yeah. At the beginning of the presentation, you did a summary of bulletproofs, and you mentioned, can you explain what is.
00:46:22.304 - 00:46:41.284, Speaker A: So this. Yeah, this is really just saying, according to the size of the input, if that's n, then the time taken is going to rely on maybe the log of n, which is better than n, because that's going to be smaller, or maybe some polynomial involving the log of n. So that's what.
00:46:43.784 - 00:46:44.724, Speaker C: Thank you.
00:46:46.264 - 00:46:46.640, Speaker A: Yeah.
00:46:46.672 - 00:47:29.726, Speaker C: So, yeah, thanks for the presentation, by the way. Really good. And I wanted to ask about the, you said that if the verifier picks a random point and evaluates a polynomial at that point, gets the result, and then asks the prover to verify that same polynomial at that same point, and then the verifier compares the results, and if they're true, then most likely, with a high degree of probability, the polynomials are equal. Right. So the question is, if that interaction can be, then further, is it like, as simple as taking that interaction and applying fiat chimere transformation and you get a snark? That's it. Or it's more complex than that.
00:47:29.830 - 00:48:06.976, Speaker A: So, yeah, thanks for the question. So, yeah, the idea is the interaction between the prover and the verifier. The verifier is going to be asking the prover some. Some questions about their claim, whether that's represented by a polynomial or a polynomial commitment scheme. But they will have some way of then making a decision about that and saying that we've evaluated maybe this polynomial commitment scheme at certain points, maybe this set of polynomials, and the relation between those, when we divide these, for example, that works out as to what I expect. So I'm happy with that. And then you mentioned the Fiat Shamir heuristic.
00:48:06.976 - 00:48:56.354, Speaker A: And what that is about is the fact, even though when we're understanding zero knowledge proofs, it's useful to think of the interaction in the real world, we don't want that interaction, because what we really want is just the prover to send a proof to the verifier and the verifier to do a decision there and then maybe because it's a contract. And so that's where we use fear Shamir. And what that does is it's a verifiable mechanism by which we take all that interaction, we effectively squash it down, and we actually get the prover to do it. So we say, okay, what the verifier is doing is producing some random points. Now, that's not really special, as long as those points really are random. So what we can do is we can get the prover to choose those points and then do the evaluations and do the whole thing, and then send that to the verifier. But of course, you say, well, the prover's going to cheat.
00:48:56.354 - 00:49:35.384, Speaker A: They're going to choose some different points, which is why it needs to be verifiable. So you need some scheme by which the prover will produce these points, these random points, which is verifiably random, and which the verifier is going to accept. And that's what fear Shamir allows us to do. We start off with, effectively, some seed or some starting point, and then we can do things like use a hash function to produce randomness. And the verifier can check that that's been done correctly. They can check that, given that starting point, these random points were really random, and so they will be happy. But it means that the verifier doesn't have to do so much.
00:49:35.384 - 00:50:00.204, Speaker A: It's just a one off thing, and the prover is actually picking the points and creating the proof, etcetera, from that. It also is good for the prover because it means they are happy that the verifier isn't doing something malicious, because they're really doing all the work. So it has that advantage as well. Is that okay? All right, cool. I'm going to skip this next bit. These just.
00:50:00.904 - 00:50:01.664, Speaker B: Sorry.
00:50:01.824 - 00:50:03.152, Speaker A: Oh, sorry. Go.
00:50:03.328 - 00:50:14.164, Speaker B: I had a question. Can verifier craft those points to try to extract the secret information from the prover?
00:50:14.464 - 00:50:42.514, Speaker A: Yeah, good point. So, yeah, this is what the prover really wants to avoid. It doesn't want the verifier to be able to reverse engineer this thing. And this is what, this is helped by polynomial commitment schemes, which act as a kind of a black box. And so the polynomial commitment scheme is there. The prover commits to some polynomials and then provides details of this. This is built into this polynomial commitment scheme.
00:50:42.514 - 00:51:02.764, Speaker A: And then the verifier can ask for evaluations of the polynomial at certain points. But that's all they get back. They don't find out the coefficients of the polynomial or any other details. There is this hiding aspect. That means they'll get back some evaluations. That point you know, they say 0.99. What does this evaluate to? And it evaluates to eleven, but that's all they find out.
00:51:02.764 - 00:51:30.522, Speaker A: So they can't use that to then reverse engineer. And also the number of queries they will do is relatively limited. They will probably do a hand, or if it was interaction, they would only do a handful of queries. So there wouldn't be enough to do any kind of statistical analysis either. And then we have Fergus mere. So the prover is doing all this anyway, and doing this, picking these points. So again, it makes it so the verifier can't do anything, anything bad like that.
00:51:30.522 - 00:51:49.392, Speaker A: Okay. All right, so I'm pretty much out of time. I was gonna see if there's anything. Okay, maybe I'll just finish here. There's more I could go through, but I think it's just going to confusing. If you've got any questions, then please do ask. Here are some more resources if you would like them.
00:51:49.392 - 00:52:05.084, Speaker A: And as I said before, if you want an extended version of this, and you want me to do this online, I'd be happy to do that. So just let me know. Just dm me about that. But if there's any more questions, please do ask. I think we've got a couple of minutes. Sorry, are you heading for dks? Yes, I am.
00:52:06.904 - 00:52:08.568, Speaker B: Awesome. Thanks a lot, Lawrence.
00:52:08.696 - 00:52:09.444, Speaker A: Pleasure.
00:52:13.784 - 00:52:43.044, Speaker B: So, do we have more questions in the audience? Yeah. Let me come over to you. Yeah, yeah. The recording, actually, I was told to what would be some frameworks which can be used to build on this math. Like, for example, we have circom Zk snar js. Right. What all you would ask beginners to start with, which frameworks are better? Like Socrates was one long ago.
00:52:43.344 - 00:53:15.702, Speaker A: So, yeah, there's lots of different frameworks that you can use. If you're a developer, you're going to be writing, you're going to be using some DSL that you're then going to. That's going to be turned into, or transformed into polynomials as part of the scheme. So you mentioned circum. That's one of the older ones. It's very good because they have lots of libraries, they've got lots of things, gadgets already written for you. What we're seeing more recently is a lot of the proving systems are basing the DSL on rust like syntax and semantics.
00:53:15.702 - 00:53:43.754, Speaker A: So we've got Chiro, we've got noir coming out, we've got RIsc Zero, which is rust anyway, so this makes, if you already know Rust, this really helps you with those so there's quite a choice. I think. If you're unsure and maybe, you know, Ros, then I would go for one of those. But there are other ones as well. We've got Mina, which is based on typescript. Yeah, there's quite a choice. But if you're looking at the DSL, those are the ones I would recommend.
00:53:43.754 - 00:54:02.214, Speaker A: All right, thank you. Can you just talk for a second about measuring space complexity? Space complexity, because you said measure time complexity is pretty simple, but, yeah, I don't know much about that because people just tend to think in terms of time. So I don't have anything specific about. I'm sorry about that.
00:54:04.034 - 00:54:09.294, Speaker B: Any more questions? One more.
00:54:18.394 - 00:54:41.694, Speaker C: Yeah, so you mentioned that I forgot the number, that elliptic curve number with 128 bits of security curve 25 519. And is it, is it 120, how is that calculated? Is it like. Because it's over the prime field of some prime number to the 128 degree or so.
00:54:42.314 - 00:54:58.254, Speaker A: This 128 business security is kind of a standard that people use generally. It just really is. Gives you an idea, if you're brute forcing something, how many operations you would need to do that. I don't know how they've come up with that for this particular curve, though, I'm afraid.
00:54:58.594 - 00:55:14.930, Speaker C: But like, in general. So when you say like the polynomial over a finite field of like certain finite field, then you're referring to the coefficients of that polynomial being taken from the finite field.
00:55:15.042 - 00:55:41.708, Speaker A: It's really just an estimation, I think, of how, how much would, how many times, how many operations you would need to do to try to brute force something. So, for example, with these types of operations, if you try to go in the other direction, which you shouldn't be able to do, and this is the basis of the public private key pair, then how many operations would you need on average to do that? But I'm sorry, I don't have the details of that.
00:55:41.796 - 00:55:42.584, Speaker C: Thank you.
00:55:45.284 - 00:55:57.564, Speaker B: Awesome. So it doesn't seem like there's any further questions. Thanks so much, Laurence. And we'll be back at 25 past with the topic on static analysis in ids. Thanks a lot, everyone.

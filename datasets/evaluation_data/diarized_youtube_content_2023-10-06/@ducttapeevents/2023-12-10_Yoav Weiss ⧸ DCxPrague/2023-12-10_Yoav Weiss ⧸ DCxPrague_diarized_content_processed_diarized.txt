00:00:01.280 - 00:00:46.508, Speaker A: Right. Can you hear me? Yeah. Right. So today I'm going to talk about account abstraction, but not as usual about use cases, but focus on censorship, resistance and why it is harder with account abstraction. So in order to understand this, we need to think what is an account? And one way to look at an account is the entity that can operate on chain, that can operate on chain directly without any intermediaries. An EOA satisfies this requirement. With an EOA and externally owned account, you can sign the transaction, you send it to a mempool and it gets included.
00:00:46.508 - 00:01:53.312, Speaker A: A smart contract wallet unfortunately doesn't satisfy this requirement and you cannot use it directly on chain. You need the help of another account of an EOA in order to operate it. And this creates a big UX problem because we are not going to be able to bring the next billion users that we like to talk about if we need them, to keep two funded accounts, one for gas, one for everything else, and to sign each transaction twice, once for the gas payment and once for the actual transaction. What can we do? So the common approach until ERC 4337 was to use a centralized relayer. And chances are that if you are using a non 4037 smart account, that you are using such a centralized relay. The way these relays work is by sending what's called a meta transaction. Basically, the user signs a transaction that cannot be used on chain directly.
00:01:53.312 - 00:03:27.368, Speaker A: It sends a transaction to a, sends a transaction to a relay, the relay signs the transaction with an EOA that is funded, it's owned by the relay, by the relay operator, puts it on chain. Then this meta transaction gets peeled off by the smart contract wallet, which handles the transaction and then reimburses the relay. And now this approach works. But clearly it's not great for censorship resistance because I mean, it works as long as it works, but what happens if, for example, the company that runs the relay goes bust, so they stop paying their Amazon bill and suddenly you're trying to transact to your account and it doesn't go through. So there may be a liveness issue, or maybe the server gets attacked, someone attempts to do a denial of service against the server at the worst possible time for you, and that's exactly when it's going to happen, because it's not random. Then the server operator could also extract Mev because they get to delay your transactions when there is price action in order to front on you with 100% success, because you cannot win a race against the server you're interacting with. So there's issues, and of course the plain old simple censorship, because the server is operated by a human and humans can be coerced.
00:03:27.368 - 00:04:22.840, Speaker A: So someone might get the server to censor you at the worst possible time. Or there's just the privacy issue where the server keeps logs, so it knows your IP address, which is associated with your real identity, and it sees your transactions and you don't know who they are sharing it with. So we need a better approach. Now the naive solution would be let's have many servers, let's say run multiple servers, but that's not really decentralized, because if these servers are operated by the same entity, then they are going to censor you together. They're going to go down together. So the next logical step would be let's make it a decentralized and incentivized network, which is what we did a few years ago with the GSN, the gas station network. So there's a network of relays that get paid to do the work.
00:04:22.840 - 00:05:02.544, Speaker A: It's permissionless, anyone can join and you can use it, and you can use it to send meta transactions. However, there's a catch when using this to manage a smart account. What if the account behaves inconsistently? Maybe it's not deterministic. So when the server, when the relay sees the transaction, it looks like it's going to reimburse it to pay it, but when you put it on chain it actually doesn't. It detects that it is now running on chain and it doesn't pay. So the relay can lose money. And we need to mitigate this, we need to mitigate this risk.
00:05:02.544 - 00:05:47.704, Speaker A: There are several mitigations that may seem possible, but each of them actually hurts censorship resistance. For example, we could have, so we could keep a white list of known account implementations. So the server only agrees to serve these accounts that it knows are not going to Griffith. But then who gets to decide which account implementations are legitimate and which ones should not be served? So that's not a great approach. Another one is to whitelist users. Let's have the users open a username with a captcha or something. Open a username on the server, and if a user misbehaves and doesn't pay even just once, you stop serving that user.
00:05:47.704 - 00:06:20.664, Speaker A: So that works, but it's a permission system. And if you can block a user for not paying, then you can also block the user for other reasons. So we are back to the censorship problem. Or you could just try to keep a reputation for accounts don't require users. But if an account doesn't pay, then you stop serving it. That approach doesn't work because of a lack of civil resistance. Anyone can spin up any number of accounts and keep griefing the server until it's out of funds.
00:06:20.664 - 00:07:08.986, Speaker A: So the server might try to be clever to, to simulate the transaction, make sure that it pays, and then use something like flashbots, send it to the flashbot relay, and ask the relay to only include it if it pays, if it doesn't, if it really pays the fee. So that would work until someone is determined to attack it. But when someone does want to censor it, they're going to flood it with non deterministic transactions that are going to not pay on chain. And flashbots will spend a lot of cpu simulating it, but never. But these transactions will never be included. After a while, flashbots will block this relay and we are back to square one. So clearly we need a better approach.
00:07:08.986 - 00:07:57.044, Speaker A: We need an approach that takes these things into account. Otherwise we end up either with a vulnerable network, or with one that is permissioned and cannot, and cannot offer a censorship resistance. So ELC 4337 aims exactly to solve this problem. It focuses on fully abstracting the account without compromising on a censorship resistance. So there are no centralized components. There are no centralized components, and nothing is permissioned in the system. And because it's a full account abstraction, it means that the validation is actually an EVM byte code getting executed, which opens up many attack vectors that we need to address.
00:07:57.044 - 00:09:09.678, Speaker A: So what does the protocol need to achieve in order to solve this? First of all, we need it to be permissionless for bundlers. Anyone should be able to add bundlers to the mempool, and these bundles should be able to offer their services, but not to do anything bad to the user operations, and we need it to be permissionless for users. Any user should be able to propagate something into the mempool, and no one should be able to censor it. We need to ensure that bundlers get compensated for the work, as long as they do it correctly, and they cannot be griefed, because if they can be griefed, then if they can be grieved, they will lose money, they will go down, and we will not have a network. And we need to protect the entire network against denial of service attacks, which can be surprisingly easy to perform against such a network. First of all, what we needed to do, how do we achieve this? The one thing we had to do first is to split the transaction to two phases. We have a validation phase and execution phase.
00:09:09.678 - 00:09:53.254, Speaker A: In validation you have. So in validation you could have a separate gas limit. So let's say you have a 5 million gas transaction that would be very expensive to simulate, but you can limit it. You can say that it has a validation gas of only 200k, which means that the amount of cpu you have to spend simulating the transaction to decide whether it's, whether you should include it, is very limited. So the cpu impact, the cpu impact per transaction is much lower this way. Then we need to also make sure the transaction is deterministic. If it's valid in simulation, it needs to also be valid on chain.
00:09:53.254 - 00:10:47.044, Speaker A: That means that we cannot allow environment access, such as block number during validation. You can use any opcode you like during execution, but certain opcodes should not be used during validation and you really don't need them. I mean, you don't need to look at a block number to validate your signature. So otherwise you could have a transaction that you could have an account that is for example, valid during even blocks and invalid during odd blocks. So now someone could propagate a transaction to the mempool that is currently valid because the last block was an even one. But then when someone tries to include it on chain in the next block, which is odd, it's going to revert. So we prevent that by not accepting the transaction if it accesses the block number, even if it would currently be valid.
00:10:47.044 - 00:11:32.390, Speaker A: So we have a list of these environment opcodes that are banned. Another problem we had to deal with is mass invalidation. That means performing a denial of service attack against the entire network by sending a very large number of transactions that are valid. So they do get propagated, but then invalidate all of them by front running them with one transaction. That makes a state change, making them all invalid on chain. So that would keep all the nodes constantly busy doing unpaid work and unable to perform any paid work. So to prevent that, we needed to enforce certain storage rules, such as the account should not.
00:11:32.390 - 00:12:51.608, Speaker A: During validation, the account can access its own storage or storage associated with its address, such as mapping of this address in other contracts, but it cannot access anything associated with other accounts. So this means that in order to invalidate n transactions, you need to write, to actually write on chain to n slots, and that's extremely expensive. So this attack doesn't scale. Then we also need to make sure that if a transaction is valid alone, it is also valid on chain together with other transactions in the same bundle, because otherwise someone could produce a transaction that invalidates another transaction. Now we already established in the previous rule that transactions that validations cannot during validation transactions cannot access the storage associated with another account, so validations cannot invalidate each other. However, execution can. So if, for example, we had a transaction that we have transaction one, which during its execution modifies a state that transaction two, validation we look at, and then transaction one can invalidate transaction two.
00:12:51.608 - 00:13:34.496, Speaker A: So this would make it very hard to build a valid block, or to build a valid bundle. To prevent that, we perform all the validations before any execution. So the validations cannot invalidate each other. And by the time any execution runs, all the accounts already agreed to pay for the gas. So now if they're going to mess with each other, they could revert each other's transaction, but still they pay the Gaz, so the network is safe against this denial of service. Now, there are some global entities in the system, such as paymasters. A global entity means that the entity could be used in the context of multiple accounts at the same time.
00:13:34.496 - 00:14:38.974, Speaker A: For example, a paymaster sponsoring the transactions of multiple accounts during the same bundle. But this means that if it is allowed to access its own storage, it could keep a flag to detect that it's running in a bundle, that it gets called twice, and then invalidate the bundle. Since we cannot fully prevent this attack, we had to also add an enforcement through a reputation. So if it causes so if a paymaster, if such an entity causes a lot of validation, then it will get throttled by the mempool, so nodes will stop propagating and serving it. But it wouldn't work if we don't have Sibyl resistance, because then someone can keep deploying more and more of these entities. So introduce staking. Now, it's not classical staking in the sense that you cannot get slashed, but it has an unstake delay, so it serves as civil resistance if you get throttled.
00:14:38.974 - 00:15:43.766, Speaker A: If a paymaster gets throttled and it wants to deploy with a new address, it has to either wait for the unstake delay in order to restake, or it needs to stake an additional amount. So to sustain the attack, you need to keep staking more and more funds, which makes it not scale. So I think for the sake of time, I'm going to skip some other attacks. But as you can see, we had to cover numerous attack vectors and try to reach to a minimum set of restrictions during validation to keep everything permissionless and still safe against attacks. Right, I'm skipping a bit, but. So why do all the bundlers need to implement exactly the same protection? Technically, you could have slightly different rules that still achieve the same level of protection. So the reason to have this as a standout where everyone enforce the same rules, is related to another form of Dos against the network.
00:15:43.766 - 00:16:51.648, Speaker A: Because let's say if you wanted to dos this peer to peer network, and remember it's permissionless, you could set a node that keeps spamming other nodes, sending them a lot of invalid transactions that all use the maximum allowed validation gas, and then say, no, it's not valid, and then you could keep the network busy. So we need to prevent that. And the way nodes handle it is if they receive a transaction that is valid, the transactions are always propagated together with the block hash they were validated against. And if as a node you receive a transaction, you see that it's invalid. When simulated against the same state, the same block hash, it means that someone is trying to dose you, because there is no legitimate reason for it not to be valid. So in that case, you treat it as a spammer and you block it. Now, what happens if we have slightly different implementations of the rules in different bundlers? What would happen is the bundler, someone would propagate a transaction that is valid for some, but invalid for others.
00:16:51.648 - 00:17:35.744, Speaker A: So they would treat each other as spammers, disconnect from each other, and we end up with a lot of small fragmented mempools instead of one big mempool. Is that a problem? So it is, especially if you think about censorship resistance, because each such mempool is small, it has less nodes. So the less nodes you have in the mempool, the easier it is to censor you. It becomes much more centralized. We also lose the robustness of the multi client approach, because ELC 4337 took the same approach as Ethereum, where we have multiple clients. We have multiple bundler implementations with different programming languages. So it's unlikely that the same bug will exist everywhere.
00:17:35.744 - 00:18:43.114, Speaker A: But if each implementation has its own rules, then we are going to end up with a mempool per implementation. So now a single software bug could take down an entire mempool, and the users will not be able to propagate it. And we also lose economic security, because now each mempool only has a small subset of all the available transactions, so it cannot construct the most profitable bundle, which means that there is less incentive to participate in it, so you get less participants. So to prevent this, we need to have multiple implementations of the bundler, but only compatible ones. And Ethereum needed to deal with the same problem and found solution for it, because Ethereum has multiple clients, but it has very clear specs of how they should behave. And we have a lot of testing, we have a reference implementation, we have compatibility tests, we perform fuzzing to try to detect cases where it would break consensus. So ELC 457 takes exactly the same approach.
00:18:43.114 - 00:19:28.246, Speaker A: We have specs for the rules, we have a reference implementation, we have compatibility tests, and once the peer to peer network is up, we're going to fuss the hell out of it. So to conclude, we see that it's really easy to design an account obstruction protocol if you don't care about account obstruction. But once you start thinking about it and going down the rabbit hole of decentralization, it becomes infinitely harder. And that's why it took us a couple of years to get it right, and hopefully we did. Now, smart account developers, wallet developers generally don't care about censorship resistant. They could even use a centralized RPC. They don't care about it, they only care about user features.
00:19:28.246 - 00:20:01.396, Speaker A: And that's okay because they're a product. As a product, they're building a product. When you're building a product, you care about user features. You don't think about worst case scenario that your users don't care about until it happens. So in order to get censorship resistance, they could just use an SDK that makes full use of ELC 4337 and then they get censorship resistance for free. But this free censorship resistance actually is provided by the bundlers. So it only works if you are using a compatible bundler, which unfortunately not all bundlers at the moment are.
00:20:01.396 - 00:20:29.664, Speaker A: So if you are going to run a bundler, you should pick one from the list. There's a list that gets generated by the tests and it shows you which ones pass the test. So you should choose one that is compatible, and then soon when the mempool, the peer to peer network, comes up, it will be able to participate and get the full benefit of it. Right. And do we still have time for questions or are we done? We can do one question.
00:20:34.844 - 00:21:09.564, Speaker B: Thanks. Thanks for the presentation. In one of the middle slides, you mentioned there that the validators should not be using all the opcodes, specifically those which are relevant to the environment. Right, and you specifically mentioned the block id or block number opcodes. Right. I guess that you could also count the timestamp opcode in the environment set of the opcodes. The timestamp is often used in approvals or in whatever which is related to the timeframe.
00:21:09.564 - 00:21:17.764, Speaker B: There is quite a significant application usage of the timestamp. How would you reflect this?
00:21:18.704 - 00:22:03.394, Speaker A: Excellent question. We also had to think about it in the first version. Two years ago we didn't and you couldn't check the timestamp because if you could check the timestamp, then you could create non deterministic behavior. Then we realized that the validation function could return a time range, so you don't need to check the time. Instead, the return value for the validation function says ok, it's valid if the time range is between this and that. So now you can implement any logic you like, but instead of checking the timestamp, you return the timestamp that you expect. So now you cannot use it for non deterministic behavior, but you can use it to implement any time based validation.
00:22:03.394 - 00:22:07.814, Speaker A: Right. Thank you very much.

00:00:12.320 - 00:00:27.376, Speaker A: Okay. Welcome, everybody. Like, this will be. If you don't know, this will be the longest slot we have at ifPrac. So I guess the organizer think this is very interesting topic as we are the only one with the 55 minutes. Yeah. My name is Tibor.
00:00:27.376 - 00:00:51.524, Speaker A: I'm the CEO and co founder of Mya ZK, where we focus on hardware acceleration, how to make proving faster cheaper. Also, like, we call it custom firmware for GPU's. And, yeah, I will be joined today with the great lineup of the expert in their own work. And, yeah, I have Martin from Zirkut, Thomas from Rockoendra, and Pedro from Aztec, and I will let our panelists reintroduce themselves.
00:00:53.084 - 00:01:12.660, Speaker B: Awesome. Thank you, Tibor. So, as Tibor said, my name is Martin. I'm from Xurkit. Xurkit is a zero knowledge roll up. So, for the purposes of this panel, we are actually producers, but also very much consumers of zero knowledge proofs. About me, I'm a technical co founder at Circuit.
00:01:12.660 - 00:01:33.454, Speaker B: I have a PhD in algorithms and complexity. So not really the background in cryptography, but now I work in zero knowledge circuits. I have a rich background in blockchain industry. I've been in the space since 2017 or 2018, starting as a security researcher. Eventually, I became a roll up developer. So, yeah, nice to be here. Thank you.
00:01:34.634 - 00:01:58.004, Speaker C: Hello, Thomas from Rockaway X. I'm currently head of the infra division. In our company, we are running the most efficient Ethereum validator according to rated network. We are also running some Solana validators. And now we are exploring the space of ZK, basically providing the hardware in the most efficient way.
00:02:00.304 - 00:02:19.040, Speaker D: Hello, I'm Zeppietro. I'm a Devrel engineer at Aztec Labs. We are encrypting ethereum. Basically, that's what we do. It's an l two private. L two. On Ethereum, you can have both private and public transactions, both private and public state, and you can do really, really cool stuff for that.
00:02:19.040 - 00:02:27.084, Speaker D: And, yeah, obviously, it involves a lot of proofing. So this panel is quite interesting for us. Nice to be here.
00:02:29.944 - 00:02:55.764, Speaker A: Okay, so the topic of this panel is actually, like ZK proof infrastructure. Overhyped or underutilized. It's kind of clickbait topic, I would say. So, hopefully, at the end, we will be able to tell if it's over hybridized. But, okay, I will start with basically, Martin, if you could explain the ZK proof chain. And also, what does it actually mean? Like ZK infrastructure, in your own view, and also from the ZK side.
00:02:57.624 - 00:03:58.894, Speaker B: All right, so the zero knowledge proof supply chain is essentially the entire pipeline. Everything that happens between some kind of an application knowing that it requires a zero knowledge proof and that zero knowledge proof being submitted to the verifying entity that is consuming that zero knowledge proof. So in the setting of a zero knowledge rollup, we use zero knowledge rollups for scaling and for convincing the verifier, which in our case is a smart contract on the l one, that we have correctly executed the transition function stipulated by the EVM machine. So circuit has a sequencer. Sequencer organizes transactions into the block. We are waiting for a whole bunch of blocks to show up. Eventually we take the state route and the ZK proof for US certifies that that state route was obtained properly and that state route is submitted to the verifier on chain.
00:03:58.894 - 00:04:25.984, Speaker B: What it specifically means for circuit is that we have some kind of zero knowledge circuits that specify the logic of the EVM that we are running on our blockchain. And those zero knowledge circuits operate under the hood. We are running the machines or we are running the software that generates those provers and we are currently doing it internally. But I'm sure that we will get to that topic.
00:04:26.964 - 00:04:27.484, Speaker C: Yeah.
00:04:27.564 - 00:04:46.234, Speaker A: Ok, so Martin was basically describing ZK proof chain for the ZK four scaling as the ZKL two. But Pedro, you are from the ZKZK overlap like you are leveraging ZK for privacy. So how does like proof supply chain looks like for the Aztec?
00:04:50.134 - 00:05:42.404, Speaker D: It's complicated. Yeah, basically it's different from usual in the sense that we, some proofs are made by the client. So when you make a private transaction, that transaction is actually run by you as a user on your phone, mobile or like desktop, whatever. And that proof will be rolled up and will be sent, will be verified and together with the rest of the public, the public proofing. So there's two sides. On one hand we want proofs that can be very easily recursive and fast on a phone. On the other hand we want proofs that can do this scaling and can actually up as many transactions as possible into a root roll up that will go on l one.
00:05:42.404 - 00:06:32.698, Speaker D: That's the biggest difference. And that's the thing that we care about. The kind of ZK that we do is actually zero knowledge. So we are actually hiding some properties, we are hiding some, we are keeping retaining this privacy and at the same time we also want the scalability. While with other proving systems that are mostly aimed at scaling, they don't necessarily keep the zero knowledge part. So I would say it's mostly like the succinctness part of the snark or the stark more than actually the privacy, privacy parts. So yeah, that's basically where we are with the proving both on the client and on the server.
00:06:32.698 - 00:06:52.844, Speaker D: And definitely this kind of proving marketplaces, those are just the way that the sequencer can actually offload the proving into other parties. This is in our proposal for what we call the sidecar, which involves this kind of marketplace.
00:06:53.464 - 00:07:17.022, Speaker A: Yeah, perfect. We will get to the ZK marketplaces, because this is my favorite topic. When I was preparing for this panel, I counted like six different ZK marketplaces. But we currently have just five big ZK rows deployed on Mainnet. So it's interesting to see how more ZK marketplaces than rollups. But a question for you, Tomash. You are basically on the other side of the ZK supply chain.
00:07:17.022 - 00:07:28.206, Speaker A: Those two guys are representing the consumers. They are in need of the ZK robots. But you are the one who can provide as you are operating the infrastructure. So how does the ZK supply chain looks like from your view?
00:07:28.390 - 00:08:22.754, Speaker C: From my view, basically it all starts with electricity. You need to have electricity, and then you need to have a hardware which can start counting whatever nonsense these guys prepared for us to count. I'm just joking. So yeah, basically for us it means to be able to be fast and also like cheap, because like as of today, the costs are pretty high. So what is my mission and my team is to basically to build the most efficient prover for this market, more efficient prover like setup, let's say for the marketplace itself. So we can be like pretty competitive and also like the users in the end will pay less for the whole stack. So basically what we are doing, because we are like bare metal operators, so we own the hardware and we can touch the hardware and play with it.
00:08:22.754 - 00:08:38.774, Speaker C: So what we have basically achieved, we have gained maximum performance out of the hardware. So everything is running pretty smoothly. And now we are waiting for those marketplaces to go live and gain traction to show how cheap it can be.
00:08:39.673 - 00:09:04.133, Speaker A: Okay, so we talk a lot about, like we mentioned, ZK marketplace, but actually some projects, they are recognized as like ZK as a service. And maybe it's not clear. So like question for everybody, do you make like difference from your application? If there is a ZiR code, you too much as an infrastructure provider or from the astex side, is there any difference between ZK marketplace and approve as a service?
00:09:06.504 - 00:09:33.484, Speaker C: For us, the marketplace, that means like we have to compete and there's like multiple competitors. There are like multiple things you have to solve. When it's like a proof of service, we basically own the whole stack. So, like, we just provide a service, but the marketplace is also like a service, but there are like multiple things which is to be like, prepared or taken care of.
00:09:35.584 - 00:10:47.954, Speaker B: So when I look at ZK as a service or a marketplace, essentially in my position or in the position of circuit, we have some input for the prover, and we require a zero knowledge proof to be generated, right? So in this sense, it is actually almost equivalent whether we request this proof to be put on a marketplace and then multiple entities, you know, somehow compete for who produces the proof cheapest, fastest, whatever, and then we consume the given proof, or whether we actually request it from one service that is capable of delivering this proof. Right. There are definitely going to be some differences in terms of the qualitative delivery of the proof. Will it be cheap? Will it be delivered fast? Will it be delivered reliably? So those would be the differences. But again, for us as a consumer of that proof that we need to submit to our verifier, the bottom line is that we require the proof to be present somehow. The proof needs to come to us, and we want it as quickly as possible and as cheaply as possible. It can be achieved both via the marketplaces and ZK as a service type thing.
00:10:50.574 - 00:11:40.550, Speaker D: One thing we care about talking about this, it's about the speed and what's the impact of actually having faster and faster provers, either by hardware acceleration and whether that could actually pose a problem of centralization. And this is something that we care about. Like, I remember when I, when I remember being a Jordy Bailina talk, and he was starting to talk about transaction in terms of how much they cost. In AWS instance, I was like, oh, this costs $0.07 in it. I was like, wait, we're talking usually about gas prices, not about like the amount of dollars you need to prove something, but that's actually the cost, actual cost of running the machine. It's again, the actual electricity you need, the actual manufacturing of the chip.
00:11:40.550 - 00:12:52.904, Speaker D: If we go to FPGA or an ASics thing, you know, and so this is, this is kind of, we want that to be, obviously, it's going to be competitive, it's going to be, provers will compete to prove the most and to prove the cheapest. But we also want to avoid decentralization and to avoid that. Big companies can actually, like Nvidia or something, just starts proving and starts their own prover and just eats up all the proving space on Aztec. And that's actually poses a problem because they could halt blocks, they could just wait for their l one sequencer to stop and not accept any l two blocks until it's theirs. There's just so many things that can go wrong and can collude that we care about decentralization. So we are a bit aware about the, we all want speed, we obviously all want hardware acceleration, but this is a concern that we do have. I don't know, my fellow panelists, if this is something that crosses your mind, and how do you think these kind of things will go and actually pose a problem in the future?
00:12:53.364 - 00:13:15.626, Speaker A: Yeah. Okay. So I will most likely skip a couple of questions because you already touched on like, interesting topic, like topic. It's discussed, but it's not clear what's the answer. So the question is simple. Is there any risk associated with centralized provers as soon as it ZK, so it's sound and complete. So you cannot prove something which is not true.
00:13:15.626 - 00:13:37.534, Speaker A: And if you are able to prove it, you are able to prove the whole statement. So from this view, centralized prover, as soon as, let's say, there will be no sequence of censorship and liveness issue, is it totally okay or not to have centralized entity generating old proofs of one chain or for multiple chains?
00:13:40.814 - 00:15:25.446, Speaker B: So this question actually has multiple layers, right? The first question is, we are generating a zero knowledge proof. The user always needs to be asking, is this the zero knowledge proof that it was supposed to be generated? And that actually proves the given claim? Right? In our particular case, the claim that we require to prove is that transition function stipulated by the EVM was executed correctly. And honestly, if I implement zero knowledge circuits that prove something completely different, you know, data was seen, there was non zero amount of bytes that came as an input that can also produce zero knowledge proof. But it's not that statement that we really cared about, right? So the first point is, if you are running a centralized prover, then you probably want to open source the circuits that actually show the logic that you are proving, and then you are relying on the community to sort of be able to verify for themselves that these circuits prove what they need to prove. Now, if you wanted to run a zero knowledge roll up with a completely centralized prover, this is, this is essentially still not enough, right? Because if I unplug that machine from electricity, as to my said, that's where everything starts. If I unplug it from electricity, it will clearly not be producing zero knowledge proofs, right? But the zero knowledge roll ups, the ability to record its state routes on l one, it's fully tied to the capability of providing this zero knowledge proof. Right.
00:15:25.446 - 00:16:29.470, Speaker B: So if I lock it down, if I turn it into a centralized kind of operation, there is a good chance or there is a risk that that service will at some point go down. How this would impact the users is that the roll up, at that point, it would still be producing new blocks on l two. But if inside of those blocks there were some exits, there were some withdrawals of assets from that l two back onto l one. Those would not make it onto l one because there would be no record on l one that these exits were, that these exits happened, that these exits happened and were actually derived correctly in the state. And therefore, you would not be able to prove the presence of your withdrawal transactions in the state of l two to the bridge, to the canonical bridge provided by the roll up. And therefore, that bridge would not really these assets. So if you want to have centralized proving service, there is one more thing that you need to implement in your zero knowledge roll up, and that is called an escape hatch.
00:16:29.470 - 00:17:00.894, Speaker B: You essentially have to give your users some kind of opportunity to exit with their assets. Even though the zero knowledge proofs are currently not being produced. Right. You can think about it in multiple ways. This actually already has nothing really to do with the zero knowledge technology. You can either give the users the capability of generating that proof themselves, you can give them the inputs and you can give them the software, and they can run it on a very beefy machine and so on. But that's no longer centralized.
00:17:00.894 - 00:17:36.974, Speaker B: Right? Or you can imagine some other mechanics saying, hey, if we haven't seen a zero knowledge proof in, I don't know, 7 hours, that means that, that the service is currently unavailable, right. So some other smart contract mechanism would have to kick in that enables the users to actually say, hey, I kind of want to withdraw everything that I had on that chain. So this is what we call an escape hatch. And that would allow you to have zero knowledge roll up that operates a centralized provers and is still trustless in this sense. But again, once you adopt this path, you again have to engineer for the trustlessness.
00:17:40.714 - 00:18:18.668, Speaker D: Really, really interesting what you said about the escape hatch, because before Aztec came in, we had Aztec connect, some of you may know, and Aztec Connect was sunset. But we still run a sequencer for about a year, and now we don't run it anymore. But if you have funds locked in there, you can actually run your own sequencer. So you can use this escape hatch, and we have instructions for that and we have the code and everything. So you can actually go and run. It's going to be very expensive because you're going to pay for the whole block for you. But I mean, if you have that amount of funds you didn't withdraw in the past year, then you can do it on your own.
00:18:18.668 - 00:19:08.574, Speaker D: That's really cool because completely decentralized, we don't have a sequencer, but you can go and withdraw your funds if you have them in there. And another point, we're talking just to answer your question about the fact that the proof is a proof and you can't actually change that. First of all, it's not really true. I mean, you can actually prove something that's not correct as long as there's social consensus on this, right? And so you can always fork, but then you don't have no prover. So there's this dance between having some kind of social consensus and also having a prover for that. So you don't want a centralized prover because you don't want the chain to go in a direction that everything is fine and you can have, for example, sensory transactions in there. And so this is the special censorship.
00:19:08.574 - 00:19:28.354, Speaker D: Resistance is the biggest part of not having a centralized prover. But that said, I mean, usually people ask me, are the ZKVM safe? I mean, if the circuits are, then a proof is proof. And that's right. It's a bit like that. I don't know if circuits are safe.
00:19:30.054 - 00:19:54.914, Speaker A: Yeah, the proof is the proof, but like, let's say the circuits are enormous. Great. Like, I mean the traces, the witness generation, it's so crazy. Like you need like this crazy 96 cpu, 760 gigs of ram. I don't know, NMVe, you know, 800. Then like the proof is a proof, but not everybody can generate the proof. Do you see also like a hardware requirements problem for ZK proving like in a way of decentralizing the prover.
00:19:54.914 - 00:20:16.094, Speaker A: If not everybody can. Let's say it's kind of like Solana versus if validator. Not everybody can. I know, but I will not say it. Run the proofs for most of the ZKL tools. So what's your take on this? Does Aztec actually do something? So every joke can actually run the proverb themselves?
00:20:16.434 - 00:20:48.508, Speaker D: Yes, yes, we care about that a lot. You know, there's seems like every few years there's this ethereum killer project that just does a different iteration of increasing the block size. So why don't we just increase the block size? Yes, that's the project I'm gonna be. And that doesn't work. Like we've seen bitcoin cash tried, that didn't work. And there's many projects that are just like, oh, I mean, if you run a sequencer that has a lot of resources, maybe you can have more transactions. That's not the point.
00:20:48.508 - 00:21:52.288, Speaker D: That's just not the point. But with proof, which is different, because again, a proof is a proof, still, we care about that, we care. And so our proposals for proving systems are mostly in the sense that you can prove part of a tree, because you know how the tree looks like, the tropics are there, you made the transactions, you know how the tree looks like, you just need to prove it. And so you could, for example, commit just to a part of that, like a subtree of that merkel tree, and then commit to that and have backup, have fallbacks, have whatever, and then there is a bigger proof that commits to a bigger subtree. And so that's perfectly possible to have one proof, one root proof that's going to be verified on l one, and have multiple provers proving that proof, because proofing is not executing, you know how it should look like, you're just proving that the computation was correct. So that's perfectly possible to do on Aztec. But we don't care, we don't care.
00:21:52.288 - 00:22:11.554, Speaker D: Like our puzzles is mostly, the sequencer chooses, the sequencer can do an auction, the sequencer can decide proving themselves, the sequencer can choose. And this is very interesting because we have no opinion really about how will the proving system work.
00:22:12.254 - 00:23:01.584, Speaker A: Yeah, and we will get to your request for proposal, because this is very interesting how Aztec is building the ZK stack. But a question for you, Tomasz, you are the infrastructure provider, you are the one who says, ok, this is how the bare metal will look like I need to order 1000, I don't know, age 100. So basically, what challenges is associated with this for you? Because we have like, I mean, like each roll up has its different proving system in a sense, like at least tweaked, then we have like these zkvms. This is like totally different landscape. And I assume you want to serve the majority of the market. So like, how do you actually serve, how do you choose the hardware, like, which is right for the ZK proving? And maybe if you, our audience, would like to, you know, participate in AZK proving, are they even capable of buying such a hardware and operate it on their own?
00:23:01.924 - 00:23:31.252, Speaker C: Yeah, first, it's complicated because even all the projects are a little bit different. And all the projects are evolving. So at the beginning it was all cpu based and people were thinking, okay, let's do it on a cpu. And then there was a journey with FPGA's. Oh, let's do FPGA. So everything will be on FPGA. And it turned out FPGA's as of today are not the best way possible.
00:23:31.252 - 00:24:08.788, Speaker C: Then there was a hype of, okay, let's do GPU's. Okay, like we have found like a good gpu which is like a good performance per electricity spent, which is like Nvidia l four which is really nice card. And there are also like some projects using or telling us hey, let's buy ASIC. It's super cool. Like we have created a special processor which is optimized for ZK. I'm like, okay, cool, this sounds interesting. And like me tinkering with GPU's, it doesn't make any sense.
00:24:08.788 - 00:24:57.936, Speaker C: But then researchers came and said, okay, we will use different fields and different mathematics and that ASic is right now not usable. So for me it's, as of today, how I see it is basically like tinkering with CPU's and GPU's and finding the right balance. And basically every project needs a different ratio. And it's also changing in time. So the configuration I buy today might be useless in a year or maybe in a week. So nobody knows. And basically what we are doing is working with each project and trying to fine tune the configuration for them to work the current code, but also looking at the future.
00:24:57.936 - 00:25:41.964, Speaker C: So if they say okay, we are the ones, we are able to offload everything on GPU which everybody claims, but not everybody has really done it. So we are going slightly tend to more like optimizing the GPU's itself. And as you ask for if it's possible to like buy a machine which can generate the proofs at your home, you can buy it. You will pay like a lot of money for electricity and your wife will hate you. That happened to me because like I started with ether mining, I bought a rig and had it in my home and like she was hating me. This has to go away. So don't do it if you like your wife.
00:25:44.104 - 00:26:18.824, Speaker A: Okay, so you're basically saying like we don't know how the hardware stack should look like for to serve majority of the market, ZK market. So basically then maybe the question is like isn't it a bit too early for this like ZK as a service, ZK marketplaces, if we don't know what the underlying infrastructure and I mean hardware will look like. So it's just easier for projects. Now I'm talking about the ZKL tools, just stick with the proving inside the AWS or like a Google cloud and it will be less risky.
00:26:18.864 - 00:26:54.094, Speaker C: I would say they can if they have a lot of money and good backing from the VC's. But we have been running some benchmarks comparing our setup and AWS, and I think because of AWS is pretty generic for mostly like AI workloads. They cannot, the AWS cannot deliver the performance. So like I think it's better to find like a provider which can work with you and give you like better efficiency per dollar, I would say because that's pretty bad on AWS.
00:26:55.034 - 00:26:57.614, Speaker A: So this is mostly because AWS sucks.
00:26:59.774 - 00:27:20.714, Speaker C: I cannot tell it like this, but like for the ZK workloads it kind of sucks because the GPU's are pretty good on AWS, but the cpu's which still like most of the algorithms rely on suck.
00:27:22.334 - 00:27:33.014, Speaker A: Okay, thank you. We are in the halftime basically. So I would like to maybe give a chance to our audience if you have some question, one or two questions and. Yeah, go ahead.
00:27:36.474 - 00:28:33.124, Speaker E: Thank you. Hi, I was interested in, because you talked earlier about centralization of the provers of a proving market, or so to say for roll ups, it's basically not that much of a problem if it's because we usually do not care about this serial knowledge aspect of a serial knowledge proof, but more about the succinctness of the proof. So I think it's not that much of a problem. But would you, if you, if we go one step ahead of that and say we also care about the serial knowledge aspect, how do you think would be a prover provider handle this kind of problem? So because I have to disclose my witness to you if I want to, if I want you as my proof provider, and if I care about the serial knowledge aspect, I usually don't want to give you my witness. So would be interested in how you see this problem or is there any way to solve this?
00:28:34.144 - 00:28:35.884, Speaker C: And the problem was.
00:28:36.224 - 00:29:00.514, Speaker E: So basically if I want to compute the serial knowledge proof, and I care about the serial knowledge aspect, I need to give you my witness so that you can perform the witness extension. Or maybe I have to do the witness extension on my local device, which is for CCML for example, would be kind of expensive, and then you can compute the proof, but for that you have to learn my secret data.
00:29:04.174 - 00:29:28.904, Speaker B: Sure, you are absolutely correct. So when you care about privacy with zero knowledge roll ups, by the way, we do not do privacy as our kid, but if we wanted to, we would have to blind the inputs. Right. The fact that we would be using external party to actually produce these zero knowledge proofs. You're absolutely correct. Again, we would have to disclose those inputs to that external party that is producing the zero knowledge proofs. So that.
00:29:28.904 - 00:29:58.436, Speaker B: Yeah, so the alternate option there would be actually having the user to generate the zero knowledge proof themselves, right. They know the input. They do not want to show that input to anybody. So they can right away come with this, the zero knowledge proof, and somehow provide that proof, if the roll up is ready for that, to the roll up and say, hey, I've done something in here. This is the proof that they did. And the roll up might say, oh, okay, well, I'm going to submit it to the verifier. And if it is really the case, then there you go.
00:29:58.436 - 00:30:07.344, Speaker B: It actually goes through. But it is a valid problem when you talk about the marketplaces and about external parties. But I think that Pedro has a comment.
00:30:08.084 - 00:30:15.554, Speaker A: I just need to say this is kind of sneaky question, because those guys are from tacheo, so they want to hear like, you will do NPC and everything will be okay.
00:30:16.934 - 00:30:28.694, Speaker D: Yeah. Thank you. There are some contributions to noir. It's a great project anyway. Yeah. But as you were saying, I was jolted. But it makes perfect sense.
00:30:28.694 - 00:31:12.320, Speaker D: You always want the user to make that proof. The user could choose to hand those private inputs to the prover, and that's actually fine. I remember some time ago, we were in a hackathon, and the same hackathon were Sindri. And most people are just doing all like putting all their proofs on Sindri so they could hunt both bounties. I said, why not? I mean, it's up to you to decide on whether you want to give your private inputs to someone else to prove or not. But the fact that you have this option, that's the most important thing. Maybe it's not a big problem for you if you want to do that, but most of all, regarding that, about the fact that you have different ways, kind of different types of ZK, in a way.
00:31:12.320 - 00:31:46.408, Speaker D: I don't like to think about that. But there is also different proofing systems. For example, for scalability, people use a lot of starks, but for ZK, for zero knowledge, for privacy, people tend to use snarks. And this means also different hardware. And one of the big problems of hardware is it's kind of slow development. It's a slow development unit. You can take like two years just to design a circuit, then actually need to be, like, physically manufactured before you can test.
00:31:46.408 - 00:32:24.364, Speaker D: And the reality of proving systems is that they change every month. So there is little. It's very difficult to make, like, a proving system, like, something that magically works. And, like, you can just fit an input and it will come with a proof outside. And I think that's not what, where hardware development usually goes, they usually go on small, like ffts and small parts of the proof that actually they are used everywhere. And so it's kind of okay to have a specific circuit or ASIC or whatever to do that. But, yeah, I guess this is the biggest difference.
00:32:24.364 - 00:32:51.664, Speaker D: Maybe we need to reach this point where proving systems are standard, are standardized. We can reliably trust that this snark or this way of making the proof that we are settling for some checks or something that will settle down for a year, and then we can maybe think about having hardware for that. But that's really cool. It's a really cool question. Really cool development as well.
00:32:52.724 - 00:32:55.744, Speaker A: Thank you for the question. Do we have one more question?
00:33:00.304 - 00:33:21.444, Speaker F: Okay, thank you. How does economics look like as an infrastructure provider? Like, how do you cover your costs, like electricity and etcetera, etcetera? Is it project per project based? Or, like, can you. Can you give some rough numbers?
00:33:22.624 - 00:33:50.544, Speaker C: Rough numbers? So it's pretty capex intensive. You have to buy a lot of hardware. You need to find a good space where the electricity is cheap, or you can build your own place where you can have the data center and, yeah, then you can get much cheaper than AWS. If you fine tune all those bits and pieces, you can be much better.
00:33:51.384 - 00:34:02.724, Speaker F: That I know clouds are more expensive than in house, like, infrastructure, but how do you get paid? Like.
00:34:06.144 - 00:34:31.503, Speaker C: How do you get today? As of today, there are, like, not many paying customers as of today because we are, like, still in the face where we are, like, talking to the projects and trying to optimize it. And, like, they're like, there is, like, one deal we only have, which we are, like, currently working with. And right now we are, like, paid as, like, an it service in dollars.
00:34:32.003 - 00:34:32.419, Speaker A: Okay.
00:34:32.451 - 00:34:34.555, Speaker F: Just like usual service provider.
00:34:34.619 - 00:34:35.091, Speaker C: Yep.
00:34:35.187 - 00:34:36.503, Speaker F: Okay, thanks.
00:34:39.843 - 00:35:18.842, Speaker A: Actually, this was a great question. I have, like, prepared a couple of questions on this topic, and I think I will skip to it right now. So I will ask maybe the audience, do you have a rough idea or any idea how much the zero knowledge actually costs? How much do you have to pay to generate, like, you know, 500 swaps on? I don't know uniswap V two on ZKL 200, around $100 to prove ZKl two block. On ZKl two block 500 transaction of uniswap swaps.
00:35:19.018 - 00:35:20.094, Speaker D: Plus the gas.
00:35:20.514 - 00:35:21.058, Speaker A: Sorry.
00:35:21.146 - 00:35:22.814, Speaker D: Plus the gas for verification.
00:35:23.394 - 00:35:50.838, Speaker A: Okay, so we're getting there. No. So, okay, the question is how much does it cost to prove the block we don't get count the verification or Da. $2. $2. Okay, some other guesses. Okay, so it's a really interesting question and I don't know, but I will take what I know.
00:35:50.838 - 00:36:22.014, Speaker A: So basically the guys from the polygon they presented in Denver before IAP. Okay, so before blobs. So to transfer like 500 transactions of Uniswap swap, it costs like $1,000 for DA, this is like data availability cost and this counts for 96%. Then we have sequencing fee, which is around $0.03, which is like 3%. And then we have approver fee and this is like 0.001 free.
00:36:22.014 - 00:36:48.664, Speaker A: So this is how much they pay for running their prover actually to generate the ZK proof. So I will ask similar question. Do you think it's actually providing like proving services, you know, viable business, like can we make money similar to staking services? If it's like the proving is just 0.13% of the ZKL to block costs?
00:36:49.124 - 00:37:37.770, Speaker C: Yeah, we believe so. But definitely it will be like a much smaller market in my opinion, in the crypto space. Then like staking or like bitcoin mining, it will be definitely smaller market and the profit margins will be like definitely lower. So that's why we also optimize for efficiency. But I believe the ZK proving will not be only about scaling for l, two s and so on, but also other use cases which can like, I don't know, like ZK pass Zke email, and more like general approving for also like non crypto use cases in my opinion. Because that will be much bigger. Because it's like Vitalik said, like everything will be in the end aggregated into one proof.
00:37:37.770 - 00:37:40.974, Speaker C: So that there is basically like raised race to bottom.
00:37:41.394 - 00:37:44.014, Speaker A: Yeah, I mean, ZK is the end game, of course.
00:37:44.994 - 00:38:15.634, Speaker D: Pedro, one thing is like you mentioned, 1000k for gas for DA, that's the biggest cost. That's ridiculous. 1000k for posting. It's not even execution, it's just data. And so that's the reason why people are talking about all the DDA solutions. Because it's actually something that's cheap and it's artificially, or because when Ethereum was born, it wasn't something that we cared about. And that's the part that's just the price is wrong.
00:38:15.634 - 00:38:59.144, Speaker D: The price was wrong from the beginning because no one knew we were going to get there. But if we talk about blobs, if we talk about all these DA solutions, that will not be 1000k, so it will more together with the proving time, with the proving size and proving cost. And so from then on, if you see that there are more like if you spend like 30% in each one of these proving sequencing and DA, then yes, that's definitely just as much of a market of proving marketplaces than is for DA. It's just a matter of having more people using the network. Are there? I don't know. I think without privacy there aren't.
00:38:59.964 - 00:39:14.244, Speaker A: Yeah, maybe, Martin, you are the one who actually, you don't have to disclose the numbers. But do you think as it is right now, ZK proving can be sufficient business compared to how much you may be paying for approving?
00:39:16.264 - 00:40:36.244, Speaker B: It's complicated. So again, the question is very loaded, right? If I want to be producing these proofs myself, I have to be running these provers, and that doesn't come for free, right? I need to have some people who make sure that these provers are running the machines at some point. If I run on bare metal, I mean they become obsolete, they burn whatever I need to replace hardware. And the question is do I want to be dealing with that or do I want to be developing my roll up? So I think that there is space for ZK proving. Once these marketplaces come online, once we have such services widely available, it will actually become much more simpler for people to develop zero knowledge rollups. Because you know, if you right now imagine the situation of a roll up operator that wants to run the proving centrally, you develop your circuits and then, you know, as we discussed earlier, I think Tibor mentioned the specs of the machines, then you have to, you know, obtain those high spec machines with what, 400 gigs, 800 gigs of ram, you know, very expensive GPU's and so on. Once you start using the marketplaces, you actually completely offload that problem to the services that are hooked up to the marketplaces or to the services themselves.
00:40:36.244 - 00:41:12.824, Speaker B: Right? So it really depends how much of the troubles you want to deal with yourself as the roll up or as the consumer of the proofs. And you know, less troubles, shorter time to market, right? So I think that there is definitely some opportunity. How large that opportunity is, that really depends. I know that circuit produces blocks every 2 seconds, so in some sense the amount of proving that we have to do. It's capped. The block has specific capacity, one block comes every 2 seconds. Well, this is actually not going to go up unless we reconfigure the chain.
00:41:12.824 - 00:41:26.804, Speaker B: So we have, let's say capped amount of business that we can give to these marketplaces. And if, you know, then the amount of business and the size of the market really depends on the number of projects that require such a service.
00:41:28.184 - 00:41:36.244, Speaker C: Maybe a question for you guys, do you need like a redundancy in generating those proofs or you are just okay with like one provider?
00:41:39.424 - 00:42:23.912, Speaker B: Yes. So again, I mentioned it earlier, if we do not have a zero knowledge proof available, we are not able to roll the state up. It really depends on how you architect the roll up. If you do not have your escape hatch, and even if you have your escape hatch and you do not want people to start exiting using your escape hatch, then you better have that redundancy that actually gives you a little bit more reassurance and a little bit higher availability, lower chances that your proofs will not be available at some point. So it is a valid argument and yes, it comes into the account. We actually, you know, we are proving on AWS despite their sucking. That's not my statement.
00:42:23.912 - 00:42:34.404, Speaker B: We are proving on AWS and we do not run a single prover. We do run multiple provers because of the redundancy problems. So yeah, it is a problem that needs to be thought about.
00:42:37.924 - 00:43:38.836, Speaker D: On our side. We are still in the process of developing the proofing system because it's very specific to Aztec. So we're not there yet with actually having the proverb ready for user consumer. But yeah, we still use AWS for our stuff, basically for our proving. But again, this is, we want that to be accessible for both consumer level and enterprise level. Given this kind of sidecar solution where the sequencer will choose, maybe it will auction, for example, the proving of the block they have sequence it and even the payment will go, will go maybe from the sequencer to the prover and not necessarily from the network being to the prover. And so it's up to the sequencer to decide on who is going to approve that block and he will not be posting that block.
00:43:38.836 - 00:44:20.024, Speaker D: And if there's no one posting that block, maybe there will be some kind of racing system where like the most, the fastest, whatever block comes in after a certain period of time will be as long as it's valid, will be included. And so yeah, definitely there's going to be this, but that also presents some other problems. But yeah, we wouldn't care too much. And the truth is, like most sequencers nowadays, most validators these days are on the cloud as well. So like if you shut down AWS, what's going to happen to the human network? That will be interesting.
00:44:21.224 - 00:44:54.344, Speaker A: So it looks like everybody is running in AWS. So this may be answer our question. If this infrastructure is over hybrid, underutilized, but okay, like both of you guys, like Pedro and Martin, you are on the mainnet, right? Like Mainnet, sorry, Devnet, Mainnet soon. So basically could you share maybe like do you have some plan for decentralized proving or this is not like a top priority for you because with the main at launch coming, much bigger problems than I guess, prover. So what's your take on like decentralizing prover?
00:44:55.004 - 00:45:33.928, Speaker D: It's the first priority for us because we're going to launch decentralized. So there has to be, the proving has to be decentralized. We rather wait for like next year to have something that it's actually reliable and then launch with a fully decentralized network, then launching now. And sometime we'll decentralize the proofer. Not shaming, just saying that's our goal. We also are building something that I think any other project is building. So that's also, I guess to our advantage to have the time to develop things slowly and be sure what we're doing.
00:45:33.928 - 00:45:37.944, Speaker D: But yeah, this is like top, top priority.
00:45:39.644 - 00:46:47.054, Speaker B: So I actually have the other stance. For us, it's actually not top priority. As Tibur mentioned, there is a lot more than just proving to running zero knowledge rob or l two in general. So when it comes to these type of questions, do you want to decentralize it? Do you want to offload it? It always, for us at least comes to the cost, because as an operator I have two options. It is definitely going to cost me something and I can either project that cost onto the users, meaning that the gas fees on the network will be more expensive, or I can absorb that cost saying hey, I am a company, so I have probably some sources of revenue and I can actually choose to fully or partially subsidize operations of these provers. So our stance currently is that we are actually fully comfortable operating the proverbial ourselves and fully subsidizing the cost. Hence we actually do not require that decentralization to be such a burning topic that we need to address it immediately with decentralizations of proving.
00:46:47.054 - 00:47:27.914, Speaker B: You also kind of want a little bit of maturity in your circuits. Pedro mentioned it earlier. Circuits and provers they actually change every month. Everybody is upgrading their circuits, upgrading their circuits, making sure that they are more and more efficient, because we've said this magical word zero knowledge proof here. But it's not true that a general statement or a single statement has one and only 10 knowledge proof that proves that statement. You can actually prove it, usually from multiple angles. And depending on what angle you choose and how exactly you do that, that's going to influence the computational cost that you are going to have with that.
00:47:27.914 - 00:48:08.562, Speaker B: So you will want to be at some point, or at the point where you are fairly aware of your cost, you are fairly comfortable with that, and you are saying, fine. This is fine to offload on the other entities when you come with decentralization. In our particular case, we are running Zke EvM. Again, we do require those machines that have very high spec. We do not think that there is so many of them that are available out there for the general community. So we are not putting this as top priority. Once our mainnet is out, our engineering resources are a little bit more relieved.
00:48:08.562 - 00:48:55.750, Speaker B: Then this is definitely a problem that we would like to tackle. I also kind of want to address one misconception that very often comes in the space. So very often when people say something is decentralized, the community sort of imagines that it means that it's always up and it's always running, and somebody's going to do that. That actually is not the case. The fact that you decentralize something is that you provide everybody with opportunity to perform that action. Right? But if nobody is watching, if nobody's interested, well, nobody will be proving for you. Right? So in the end, even once we decentralize, and if we decentralize, or once we decentralize, it will still be a future where we have to make sure that there is at least one entity that is providing those proofs.
00:48:55.750 - 00:49:09.154, Speaker B: Otherwise, we will not have those proofs. Right? So, in the sense, there is actually not so and so much, you know, immediate benefit from decentralization for us. And that's why it's not on the top of the roadmap.
00:49:12.774 - 00:49:41.744, Speaker A: Tomas. So I asked girls about their future, but what about you? Like, what's your take on, like, actually ZK hardware acceleration. And will the Asic hit the market? And how do you prepare for this? Because we have this, like, you know, company who is working, or like many companies working on this, and I think, like, you just bought a new hardware, it was pretty expensive, and then next day, boom, we have ZK ASIC. So what do you do actually not gonna happen.
00:49:44.044 - 00:50:47.864, Speaker C: That's a great question. There were times when I was pretty worried like, hey, we are like buying those GPU's and then like the companies come with the Asics, but I'm not worried as of today because like building the ASIC and like then manufacturing the ASIC, it takes if you are like pretty good year or two, but like look at the history, like what kind of achievements we made in two years. So like they are basically not able to cope with it and it will take some time and I don't know how long when the ecosystem and all the algorithms are stable enough that it will make sense to have an ASIC. Like it happened with bitcoin, that it's pretty standard sha. But like in the Ziki space, maybe I'm totally wrong, but I'm not seeing that in the future, like two or three years when this will happen.
00:50:48.524 - 00:51:02.784, Speaker B: So Tomasz is absolutely wrong here. He should be extremely worried about the AsICs coming out. The reason is that once they do, he's going to buy one or ten of them, he's going to put them in the kitchen and his electricity bill will go through the roof and your wife will hate you again.
00:51:04.604 - 00:51:31.804, Speaker A: Okay, we have just three, four minutes left, so let's close off with some fun questions. So basically, question to all of you, what do you think will happen first, ZK, like actually Nvidia will start working on like ZK GPU. Bitmain will shift from manufacturing AsiCs for bitcoin and start manufacturing ASics for ZK. Or actually AWS will launch ZK as a service.
00:51:33.764 - 00:51:37.624, Speaker C: In my opinion. I'm like bitmain.
00:51:39.244 - 00:51:43.024, Speaker B: My opinion is AWS will launch CK as a service.
00:51:45.444 - 00:52:18.324, Speaker D: Yeah, I'd like to be of the other opinion, but I don't, I think AWS is going to consume the whole thing. Nvidia doesn't care. Right? They are with AI already. They already have all the market for that. And bitmain, that's okay for bitcoin. I mean, they are the only ones that always win with bitcoin, so. And for AWS, it should be pretty easy for them to just have specific hardware because they have a lot of it.
00:52:18.944 - 00:52:35.324, Speaker B: So I absolutely agree with that. Right. When you look at Nvidia, they are manufacturing GPU's. We already compute a GPU. They are absolutely fine. On the other hand, that's why I answered the way I did. All these cloud providers, they have purchased these GPU's already.
00:52:35.324 - 00:52:45.324, Speaker B: So they need some load on them and running a ZK as a service that's sort of a logical use for them. So it's a viable option, in my opinion.
00:52:45.444 - 00:53:11.134, Speaker C: I totally disagree with you. Because they don't. Because they don't need a load on their GPU's. They have enough demand from AI. And in my opinion, it's too niche for them to optimize for ZK. But I agree with you. It makes sense for them to do it, but it's too small and they're occupied with other workloads.
00:53:12.034 - 00:53:21.864, Speaker A: Okay, so we can meet here in one year and see if the Nvidia is working on actually AWS ZK as a service. Thank you all for coming, and thank you, our panelists, for joining me.
00:53:32.084 - 00:53:33.324, Speaker D: Thank you, everybody.

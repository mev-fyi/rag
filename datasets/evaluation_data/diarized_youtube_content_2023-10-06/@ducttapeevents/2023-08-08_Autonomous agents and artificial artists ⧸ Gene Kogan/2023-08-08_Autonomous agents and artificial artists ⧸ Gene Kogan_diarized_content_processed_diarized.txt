00:00:00.960 - 00:01:04.104, Speaker A: Okay, hi, everybody. How does this work? Okay, so my name is Gene Kogan, and this talk is about autonomous agents and artificial artists. So I'll just quickly tell you about my background so you know where I'm coming from. I've been basically spent most of my career in machine learning in one form or another. I studied machine learning in college and then became kind of a research assistant, working on applications of machine learning to music technology, working on things like recommender systems, collaborative filtering, stuff like that. Also sort of pulling out interesting information from audio signals for applications to creative applications. You pull out the beat, the tempo of a piece of music, or the genre, or the mood characteristics, things like that, that in order to drive playlisting algorithms, stuff like that.
00:01:04.104 - 00:02:05.412, Speaker A: At the same time, I had a hobby as a generative artist. I've been using for a long time, frameworks like processing, open frameworks, Max MSP, if any of you are familiar with those things. And then these two worlds kind of started to collide around ten years ago when generative AI started to take off as a field, or what's now called generative AI. It wasn't called that back then. So I started using techniques like gans style transfer, deep dream, and in order to make interesting kinds of art. So I've had a front row seat to watching this field really, really take off over the last eight years. That image on the left is a face, if you could believe it, trained on, made from a model, a variational auto encoder, this kind of neural network that was trained on a data set of celebrity faces.
00:02:05.412 - 00:02:53.596, Speaker A: This is the state of the art in 2015, and as everybody can probably see, it's really, it's grown up very, very quickly, very fast. So we're now making realistic imagery, also video text of, you know, that well, that's very, very capable. Probably everyone here has interacted with chat GPT at some point, so the field's really exploded in popularity and interest, and so I've been kind of reacting to that lately. These used to be videos, so. But I'll just some work of mine from collections that I've made of artworks. These are actually videos that are looping, but not for today. I'm most well known for my educational work.
00:02:53.596 - 00:03:52.830, Speaker A: So I've been making these resources, kind of tutorials, code and instructional materials, book chapters, things like that, for teaching people in. In different creative professions, including artists and interaction designers and so on, basically how to adopt these materials and to use them in their own craft. And so this is a project called ML Foray and I've also been running workshops around these resources for most of the last seven, seven, eight years, including for a couple of years, is basically a full time job. So this topic of an autonomous artificial artist I really love. It's kind of been my obsession for the last few years. It sits at the confluence of multiple, completely different fields, in my opinion. So there's a computer art aspect to it, of course, and how that overlaps with artificial intelligence and machine learning.
00:03:52.830 - 00:05:12.964, Speaker A: And then there's this whole decentralization element to it, blockchains and so on, that has become intertwined. And then there's also this kind of philosophy of mind component to it, which I won't really get into much today, but is no less interesting. So questions of what is agency in the computer network, what does it mean to be autonomous? And those are all things that have really driven this topic. So from my vantage point, I've had a chance to anticipate some of the questions that are today becoming more and more prominent. So if you're a digital artist, you're basically responsible for every pixel, normally. But in AI art, this is really challenging. So it's a little bit different, because with AI generated images, you're the last step in a very, very long and complicated sequence that starts with many millions or even billions of people contributing data to this large data set, compute resources that are stretched all across the globe, you know, hundreds or even thousands of people writing the software that underpins your own software.
00:05:12.964 - 00:05:59.424, Speaker A: And so this is such a collective enterprise that it really kind of, at least to me, it really challenges conventional pre existing notions of authorship and attribution. Copyright, of course, is a big issue now. You know, copyright, as far as I can tell, really wants a single person, or at best an organization to be responsible for or attributable to one of these models or an image that came out of it. But really in AI generated art, there's so much more, obviously. And so I've been really interested in questions that arise from that. So around 2016, I became acquainted with the art Dao idea. Maybe some of you have seen this.
00:05:59.424 - 00:07:04.596, Speaker A: Basically a couple people who are now friends of mine, Trent McConaughey and Simon de la Riviere, started theorizing about this idea of a smart contract that would create, autonomously, put it on the blockchain and sell it, and then, you know, use the proceeds to pay for itself, to pay for its own computation. And I was really attracted to, really inspired by this idea. It really completed, I think, an idea that had already kind of come from artificial intelligence circles. Lots of artists had been playing around with this idea of personhood or lifeness to their creations, thinking like, can we make programs that would really seem to people to be completely have their own agency and their own autonomy? And this was. But they were, in my opinion, kind of lacking this autonomy character. And I think the art Dao idea really completed it. And I thought, for my part, I would try to kind of merge these two traditions together into a single cohesive idea.
00:07:04.596 - 00:08:32.454, Speaker A: And I wrote an article about this in 2019, artists in the cloud, where I introduced the Abraham project, which was basically the idea of taking an art dao at its core and placing in the center a generative model. So an AI generative model, and decentralizing all of the aspects of its training and operation in order to really make it, you know, kind of have this autonomy. I should mention that around this time, Daos were thought of a little bit differently, I think, than they are today. These days, I feel like DAos are kind of just like social organizations around the blockchain, but at the time, the autonomous character of them was more emphasized. And so Daos are this thing that interacts with people at the edges, and this was kind of trying to make a system that would collectively convert everyone's intelligence, everyone's imagination, into unique and original art. And I published a paper and a workshop poster at the Creativity workshop in Neurops, which is the big Machine Learning conference, where in the first couple of years, I really emphasized the decentralized compute. Besides for blockchains, there's a lot of interesting research kind of adjacent to machine learning, in decentralizing aspects of the machine learning process, from federated learning, which kind of decentralizes data collection, to even things that are like multiparty computation, homorphic encryption.
00:08:32.454 - 00:09:38.734, Speaker A: I think some people here have probably seen the ZKML talks, which is also kind of an adjacent topic. And those things are more for decentralizing the actual computer or creating certain kinds of privacy and security guarantees. And I emphasize that in the first couple of years while I was studying this. Now, in the meantime, the idea of autonomous agents has become much more mainstream. In just the last six months, I would say in the aftermath of chat GPT, GPT four, maybe some of you have seen these projects like Auto GPT and Baby AGI, and those are open source projects in which people are trying to take these language models and place them into larger systems which have some kind of a more autonomous character to them. So, you know, a language model is something that you'd normally think of like you go to chat GPT and you prompt it. But these are goal directed agents, which are given the goal and then just kind of continue thinking in a loop and then trying to complete certain tasks that it sets for itself in response to these goals.
00:09:38.734 - 00:10:36.798, Speaker A: So these are agents that are capable of, they use language models at every step to kind of reason about a goal, divide it into tasks, plan out those tasks, execute them with access to certain kinds of tools. So tools like searching the Internet with Google, access to data feeds and APIs, being able to make images and connect to the Internet, essentially. And I would say that right now, from having played with them, it's still very raw. They're not going to do anything really, really worthwhile for you right now. But I would say that as the base models continue to improve and this idea of how to kind of compose with language models becomes more mature, I think that this will become a really, really big area. I think everyone's going to have their own autonomous agents. Personal assistants companies will have bots that answer questions effectively, and it's something to really look out for.
00:10:36.798 - 00:11:33.750, Speaker A: There's also a paper a few weeks ago, maybe a month ago, called generative agents, which was really interesting. The researchers placed a bunch of these, I think, 20 of these autonomous agents into like a 2d game map and then simulated a little society. And so each of the agents had kind of a heartbeat and an internal monologue and some memory of itself, and would go on interacting with each other, making new memories and so on. And the researchers even reported certain kinds of emergent behaviors, how they organized a birthday party for one of the agents and had all sorts of, like, social interactions. It's really interesting stuff. Now, the generative AI world has been maturing a lot. There's a really big open source community that I'm plugged into, and so the tools just keep getting better, I think.
00:11:33.750 - 00:12:29.046, Speaker A: And there's kind of this interesting notion that all of these tools are in a single, that many of the participants in this world, we share tools, and not only shared tools, but resources, like the actual models themselves, the data sets, the compute resources, it's just this kind of large pool. And so in the sense, it almost looks like public resources, although people don't really think of them that way, but they effectively function as public goods. And for that reason, I think there's a lot of, yeah, there's a lot of interesting aspects. So actually, these slides I supposed to get rid of. But anyway, models and data sets are also getting larger, and the models are improving very fast. So there's a lot of interesting problems, I would say open, open questions and opportunities in generative AI. I already mentioned the copyright issues and attribution.
00:12:29.046 - 00:13:04.210, Speaker A: There's also this data sovereignty. Obviously, lots of people's data is involved in this. A lot of artists in particular have questions about it. And data sovereignty has always been a big issue in the blockchain world. And in generative AI, it's becoming much more of an issue because, you know, we acknowledge that these models have a lot of intrinsic value to them. And so there's really no answers to, you know, how that maybe how that incentivizes people to even contribute in the first place. Of course, machine learning is intrinsically centralizing because the compute resources are so intensive.
00:13:04.210 - 00:14:32.364, Speaker A: And so that's an issue that's presented. There's been an influx of new participants, artists and application developers and so on, who for the most part are using all of these same resources. But for now, there's really a lack of incentives for them to really coordinate with each other, because despite the fact that they're all using kind of the same models, I wrote an article a few weeks ago about an idea for creating some kind of an on chain provenance for generative AI. So if you can imagine all of these different projects using the same flavors of stable diffusion, same compute resources, to be able to publish on chain all of the creations that they make with a reference to a particular checkpoint and the input spec that made it a prompt and a random seed and so on. And the idea for this is to not just to create a standard among them, but to encourage some degree of interoperability and composability and so on. The second aspect of this is to create something that's a little bit more web3 oriented, where web3 oriented in the sense of a decentralized platform that they share. Because the first thing that we'd like to do, and this kind of brings me to Eden, is to be able to create these generative models as a service.
00:14:32.364 - 00:15:26.294, Speaker A: And many such services exist, APIs and so on, that provide uplinks to these powerful models. But all of them have the sort of generic web two problems, platform risk, of course. And so the idea with Eden is to try to create a web3 centric version of this, which uses, first of all, a decentralized identity. Your wallet is your identity, you're not an entry in our database, and also this provenance layer as well. So the first important aspect of that is that all of the data is shared and open in public. So if Eden, for example ever goes offline or stops offering these models, you can basically take all of that, fork it off and continue running your operations. All the models are open source.
00:15:26.294 - 00:16:04.814, Speaker A: You can host them elsewhere. And so really trying to create a way for these otherwise independent parties to have some kind of a commons between them. You can go to Eden Dot art and we have a couple applications that allow you to log in with your wallet and make creations. We're working on the on chain component part of this we have on the testnet, basically a provenance layer that's still kind of getting tuned and very much encourage people to get involved. So that's all I have. I have a couple minutes for questions, so thank you very much over there.
00:16:07.554 - 00:16:18.978, Speaker B: This technology obviously makes it easier to fake events, things like that. Do you have an idea of how that problem is going to be solved or if it's solvable at all?
00:16:19.106 - 00:17:04.964, Speaker A: Yeah, so the provenance aspect is very much adjacent to, for example, if you maybe caught some of the ZKML talks, trying to create ways of verifying the authenticity of images and the origin. So if you're referring to being able to trust that a piece of media came from a particular place of origin, I think those are things that really get solved by a provenance layer. Provenance doesn't have to be on chain. Lots of companies, of course, have their own different versions of this, watermarking, you know, watermarking the media and so on. For my part, I think the on chain aspect of this really helps to also preserve decentralization.
00:17:06.104 - 00:17:10.204, Speaker B: Very quick question, how long does the job title prompt engineer last?
00:17:11.664 - 00:17:52.358, Speaker A: I don't know, actually. It feels like most of these terms are very ephemeral. I think a lot of the terms will change. How long is the term blockchain lasted? I feel like people were more into that term five years ago, but it's not as though blockchains went away. I think that there will always be a skill set to learn around how to interact with computers. Whether you call it programming or prompt engineering or whatever comes after that doesn't really change the character of this. The actual technical skills are always evolving, but there's still a lot to learn and prompt engineering.
00:17:52.358 - 00:18:04.558, Speaker A: For its part, there's still a lot of very interesting. It's almost like archaeology. We're still learning about the models that we've made and what's kind of unique about them.
00:18:04.686 - 00:18:05.382, Speaker B: Thanks a lot.
00:18:05.478 - 00:18:12.314, Speaker A: Yeah, over there.
00:18:15.434 - 00:18:28.698, Speaker C: Hi, thanks for the great talk. I was wondering, if I understand correctly, Eden is a platform that's decentralized in order to have everything related to MLB, open sourced and available, right?
00:18:28.786 - 00:19:08.524, Speaker A: Yeah. And decentralization is multifaceted here, so not everything is decentralized. We use Amazon. We have, we have a bunch of GPU's that by necessity are sort of in a cloud somewhere. And so the idea is to, is to first of all decentralize as much of that as possible and to create kind of some kind of a web3 overlay on top of it. When I was doing Abraham, I was really concerned specifically about GPU sort of, or trying to make the computation happen over many computers. Now, I've sort of de emphasized that because I actually don't think it's necessarily.
00:19:08.524 - 00:19:30.524, Speaker A: There's a lot of problems you can solve without doing that first. And so for me right now, the focus is on decentralizing the data trail and the access. It's kind of web3 access layer on top of web two resources, and to make it so that all of this is reproducible. So open source is, everything is open source and forkable and so on.
00:19:31.024 - 00:19:44.528, Speaker C: I was wondering, what do you think about the centralization of the models themselves? Because those models are usually large, couple of gigabytes, right, even fine tuned ones. So do you see any potential future we can decentralize that or hosting of those models?
00:19:44.696 - 00:20:21.734, Speaker A: Well, a lot of those models are open source and licensed permissively, and so there's already an aspect in which they're just out in the open. I think the question is how they're orchestrated. I think that's at least the first question I would like to see also kind of more decentralized networks for training those models, and then perhaps even creating kind of economic models around them that incentivize creating them. So there's been a lot of ideas at that space, you know, creating interesting kind of royalty streams, encouraging remixing and so on. And I think that's a really promising area.
00:20:22.114 - 00:20:22.894, Speaker C: Thanks.
00:20:29.194 - 00:20:30.414, Speaker A: I'll get one more.
00:20:32.014 - 00:20:40.354, Speaker B: How long until video gets to the same stage that imagery is currently at? It seems like it's relatively close, actually, video.
00:20:40.734 - 00:21:19.850, Speaker A: So there are already a number of video tools. So there's a few companies that have very good text to video tools. They're certainly not as good per frame as the text to image tools. And there's also open source versions of them, which are still kind of flimsy. But if you just look at where everything was two years ago, it really feels like the pace of improvement is extremely rapid. And so I would say the text to video tools, I think you'll start to see them in this capacity in less than a year. I mean, you'll see that.
00:21:19.850 - 00:21:26.774, Speaker A: You can see them even now if you dig hard enough to the point where they're more mature. I think it'll take a little bit longer.
00:21:27.184 - 00:21:28.296, Speaker B: The name of one or two of.
00:21:28.320 - 00:21:53.202, Speaker A: Those, just so I can Runway has a very good text to video tool. I'd say that's kind of the most prominent one. And also Google has demonstrated it. I don't think they have any kind of services around it, but from a scientific standpoint, it exists. There's also incredibly good audio generation as well happening. So you'll start to see this come from music as well.
00:21:53.338 - 00:21:53.842, Speaker B: Thanks.
00:21:53.938 - 00:22:07.634, Speaker A: Yeah, yeah, yeah. Okay. I think I'm out of time, so thanks a lot for coming.

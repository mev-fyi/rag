00:00:40.314 - 00:00:58.718, Speaker A: Sorry. Oh, all right. Okay. Okay. Hello everyone. Welcome to my talk. Today.
00:00:58.718 - 00:01:43.384, Speaker A: I'm going to talk about ZKVM design trade offs and our ZkVM, which is called Valeda, the design considerations and choices that we made. And this is a joint work of eight of my incredible teammates. Yeah. And then let's start. So yesterday we released our, our Alpha DkVM and our C compiler toolchain. I just wanted to show some impressive benchmark. So on iterative Fibonacci we have up to 260 x performance improvement over alternative solutions and Om Char 256.
00:01:43.384 - 00:02:33.830, Speaker A: We have up to like 54 times faster in cpu wall clock time. And this is cpu efficiency. This is like thousands of acts of efficiency improvements over other solutions. And this talk I'm going to talk about first, why we adopted ZQ VM instead of other solutions. For example, DSL direct compilation. And then second of all, what were we thinking when we were designing Valida? So what are the criterias that we were looking at and what are the problems that we were solving? And third is our design trade offs. How are we making the trade offs to achieve such performance? And fourth is some of our design choices.
00:02:33.830 - 00:03:24.284, Speaker A: And then I'm going to show the demo and then talk about our future directions. So the first question I'm just going to skip really quick because I have a lot of slides. So what's the motivation behind zkvms? How do you prove succinctly and zero knowledge that a certain program was executed on a certain input and it had a certain output? So this is the motivations behind rebuilding ZK, I guess, in general. And the problem with this is that the learning curve, the tooling is really steep. For example, circum and a few other libraries require developers to learn new languages or they need to write handwrite circuits. It's pretty time consuming and requires certain level of expertise. And then second is the high time, space and energy cost of generating proof.
00:03:24.284 - 00:04:06.364, Speaker A: And we think that's the motivations behind this project. There are a few approaches. I listed three here, so people who tried DSL before. That includes like Cairo artworks and Sircom, and a few others. There are people who tried direct approach. Actually Anoma has a project that's been working on this direct approach, which is like compiling to functional language directly. And then there's this ISA VM approach, which is valida risk, zero sp, one polygamydin.
00:04:06.364 - 00:04:56.866, Speaker A: And we think that ISA VM approach is the future will be the dominant way developers interact with your knowledge, because it's more developer friendly, productive and it's much more secure. You don't have to audit all the circuits to make sure there's no bugs. We only need to audit the VM, formally verify it, and so it reduces the space that bugs can happen. And here we listed some limitations of existing ZK vms. So just a few. Like for example Cairo required developers to work in a familiar, unfamiliar language model. And second of all, like none of this, other ZK vms are fully open source.
00:04:56.866 - 00:05:55.234, Speaker A: I think right now SP one is open source, but most of the rpms are partially closed sourced. Therefore you can't even add sort of some optimized circuits to their libraries and stuff. And third is there are a lot of inefficiencies in other ZK vms designs. For example memory models in some vms. And most of vms are targeting like RISC five, which is instruction sets, that's targeting at hardware settings and not in ZK settings. And then the fourth is, it's very difficult to, it's not modular enough, it's very difficult to integrate advancements in ZK. So for example, right now we support small fields for a lot of other vms, one or two, it's harder for them to adopt newer techniques in cryptography.
00:05:55.234 - 00:07:12.464, Speaker A: Therefore we need a VM that's more extensible, more performant and more developer friendly. And now, just after talking about the existing problems, what are the main criteria for evaluating zkvms? There is baseline, which is like it needs to be correct, it needs to be secure and to consider a ZK to be considered ZKVM. So you measure the reliabilities of a DKVM and then the second is performance. So baseline include correctness, security and trust assumptions and performance measures. The capabilities of a DK vms. So how efficient, how energy efficient it is, how performant speed is, like how fast it is succinct, how succinct is the proof being generated and verified. And the third is developer productivity, like how easy to use the ZKVM is, which includes compiler tool chain support, whether it supports high level languages, and how easy is it to write what's the UX for using those libraries and modularity.
00:07:12.464 - 00:07:54.264, Speaker A: So like how easy it is for developers to add like a certain specialized circuits for some use cases that I want to work on. So this is our three main criteria. So just briefly talk about like what does each mean, so what does correct means? It means that the VM must execute the computation as intended. Then the proving system must satisfy its claimed security properties. And I'm just gonna skip this. Security. Security means how the tolerances of the soundness, completeness and the zero knowledge and then trust assumptions.
00:07:54.264 - 00:08:49.024, Speaker A: It means like the assumptions about the honesty of the prover and verifier to reach the conclusion that the ZkvM functions real reliably. And then, so for example that RVM uses fry PCs which has no trust assumptions, but some other Ck vms use like KCG which has trust assumptions. And then you need to do setup, trusted setup. And this is what this means. And performance, so there is a trilemma of like performance is its speed succinct efficiency. So for example, if you like, are much more performant and usually it generates like a larger proof. So I'm going to talk more about it later, but briefly go through the concept.
00:08:49.024 - 00:09:36.354, Speaker A: So speed, it means like how quickly the prover can generate proof, right? So we measure this on time clock, wall clock time, which is the time from the start to finish off the competition. And efficiency. Efficiency meets the resources consumed by the prover and it matches by user time. So for example, if you have multiple cores and if you're using five cores and it takes like 1 second. So the single core user time here is like how we measure speed is like single core cpu proof generation time. And then the efficiency is core time efficiency in space efficiency. I guess we defined this to efficiency here.
00:09:36.354 - 00:10:34.728, Speaker A: Succeedness means the size of proof generated and the complexity of verifying the proof. And it often includes the proof size and the verification time and the verification space. So like, I guess in conclusion, there are like six criteria that were mention here, which is collecting is security, trust, assumptions, speed, efficiency and succinctness. I also mentioned the easy to use perspective, but I'm not going to talk about it here. This is the process of how we built the VM from ground up, and this is providing a process flow. You have to select the base proving systems and then develop a ZkVM. So second of all, we develop a ZkVM with our own ZK friendly ISA instruction sets.
00:10:34.728 - 00:11:14.242, Speaker A: And then the instruction set is actually tailored for maximizing the efficiency of zero knowledge proving. And then third is we have to create a compiler toolchain to support high level languages. Therefore we are writing this LVM iR to our DKVM's compiler backend. And now we support C. We're going to support rust and c and solidity and other languages that has a LVM front end. And then four is right. We're also working on a hardware accelerated CKVM proving system five is like form of vacation.
00:11:14.242 - 00:13:12.674, Speaker A: So EF right now is like working on this and we're going to collaborate with a few other like form of vacation companies to work, work on this as well. So what are the design choices we have to make when you are building a ZQ VM? First of all, what instruction set architecture are you going to use? Right? And then we designed our custom ZK friendly Isa, but most of other zkvms chose lisk five sumtures, mips, I remember. And second of all, what languages support? Well, this is more at the compiler tool chain problem. And then third, should it be modular or should it be more monolithic? Fourth is what kind of arithmetization strategy should we use? Fifth is what field should the CKVM use for the arimization? And then what PCs should be we use, and then what recursive proving should be supported. If it's supported, what approach are we taking, et cetera. So providing some guidelines, this is a general flow for how is KVm works? I'm not going to talk about it, but yeah, okay, so in the second half of the talk I'm going to talk about how we sort of build this VM, and then why are we thinking about designing our own ISA? And so this is just interesting notes that we're just thinking yesterday actually. So we were discussing with my teammates that what are sort of the key paradigm shifts in instruction sets design and adoption.
00:13:12.674 - 00:13:57.688, Speaker A: And we observed that from 1960s to 2000 there is a general shift. We used to use complex instruction sets and then we're gradually moving to risk reducing section sets. And then we moved from vector processing to more scalar processing architecture. We moved from single core to multicore, removed from fixed instruction sets to more extensible and modular instruction sets. And then we moved from general purpose to more domain specific architectures such as TPU, GPU AI related chips as well. And then we also moved from power agnostic design. We used to not care about efficiency.
00:13:57.688 - 00:15:13.734, Speaker A: Now we care a lot about how energy efficient the chip is, and a few other observations. And then this is actually one of the reasons why we sort of designed our own instruction sets, is because we think that under the paradigm shift of cryptography, of trustless systems calming, we think that there needs to be a new instruction set that fit for this specific application. And that's why we designed our own instruction sets. And like a few sort of basic question we were thinking every day is like what instruction sets are more efficient to include in the ISA and to check in the star constraint system. And what are more efficient, to just exclude from the exa and eliminate from the compiler output by reducing them with a sequence of instructions. And I guess the general thinking is that the differences between ZKVM computing environment and the hardware environments are very different. And that sort of drives our sort of different ISA design decisions.
00:15:13.734 - 00:16:14.824, Speaker A: So our valida ISA is a ultra, we call this ultra risk means like ultra reduced instruction sets. We only have about like 20, I think, instructions. And it's very modular, it's very secure, friendly, and includes the following modules. It has a 32 bit LU chips and a cpu chip, a memory chip, a program chip, and an eight bit rand checker chip. This is a diagram of a basic valida VM, what it looks like, and a few like interesting points. So for example, we have two general special purpose register. We have no general purpose registers, and that's because it sort of simplifies the code generation by eliminating the need for the register to be saved and restoring the calling convention, and therefore like eliminating the need for register spilling the, the code to be emitted.
00:16:14.824 - 00:17:04.000, Speaker A: So another point is we only have two ram addressing modes and the program roam can't be addressed and there is no dedicated SP register. The calling convention uses constant size stack frames. Um. Um, right, so this is an overview of like what the VM is composed of. Um, first of all, it has an execution engine and it runs the valid program and generates the execution traces. Um, and then, uh, the prover proves the result of executing a program by, by proving this valid execution traces exist. And then the last step is verifier.
00:17:04.000 - 00:17:43.292, Speaker A: It verifies that the results of, of executing a program and given a proof of that verification. These are some parameters that we're using. I don't want to go deep into it, but we're using this bay bear field. We're going to support Merson 31 field soon as well. And the current PCs we're using is fry. We are integrating with basefold, which is authored by one of our teammates, Haras. And I'm just gonna skip this.
00:17:43.292 - 00:18:20.704, Speaker A: This is like sort of how the prover works. Some techniques of optimizing the prover. So the stark we're using is very efficient and the only expensive operations it uses is a hash function. So we use gates with degree at most three, and keeping the FFT and hashing codes as low as possible. So that's like one of the techniques. This is just giving a few examples. And the second trick is that we use a finite field that's extremely efficient.
00:18:20.704 - 00:19:15.344, Speaker A: Right now we use, as I mentioned, baby bear. We're going to support Mersen Field and this is the compiler backend. So we are writing this LvM iR to RVM compiler and this is sort of the how the LVM tool chain work. So we're writing the LVM valida backend, right? And these are all existing tool chains, right. So LVM already support C and all we're doing is to write the LVM available backend. And once that's done, it's like function completely right now. But the point is like the unlock is that we can support C, C, Rus and all the other languages that are supported by LVM.
00:19:15.344 - 00:19:54.734, Speaker A: And the implementation is fully open source. You guys can check it out at validaxyz. Valita. We also, the LVM repo is under Lita, but yeah, so it's highly customizable. I want to emphasize developers can just use the included compile time micros to generate with a little coding and then you can just add like the chips that you wanted for your own use case. And it's highly customizable. The demo.
00:19:54.734 - 00:20:16.354, Speaker A: I want to show this. Okay, so two minutes really quick. I'll skip most of part two. Hi, I'm Morgan. Oh, sorry, the audio doesn't work. Yeah, it's all right. I'll just send you guys the link, you can check it out later.
00:20:16.354 - 00:21:28.652, Speaker A: Ongoing work. So this is more in the proving system side, but we are thinking about, well, we are working on multivariate prover snarks and we're integrating with basefield and we are doing some optimizations on the fry prover. We're thinking about using circle starks and, and we're adding EVM verifier. We're working with a few companies on hardware accelerations. So this is what we're working on right now to further optimize the proving system side. And we're also building this developer interface to help developers to even more easily work with RZQvM. So this would be like a platform where you can build templates and people can use other people's templates to build their projects.
00:21:28.652 - 00:22:05.024, Speaker A: And so basically you can just pick whatever language that we support and then use somebody else like, or some app level templates. And then we also have an online ide. You'll be able to build your projects here, compile, see, right. Locally, the proven costs, whatever if that's helpful, and then deploy on a platform. Right. So on the platform you can choose like sort of the different hardware configs you want to use the proof aggregation layer you want to use and the network you want to deploy. So you want to support as many networks as possible.
00:22:05.024 - 00:22:41.644, Speaker A: So that's pretty much it. Just emphasize that Valilla is a extensible performant and developer friendly ZkvM. We just launched our alpha, so welcome everyone to try it out and give us feedback. And we're hiring, so we're hiring like a cryptography engineer, compiler engineer, and we're hiring for this innovation team, which is we wanted to do experiment on the VM and build interesting products. So if you're interested in any of these bros, let me know. And here's our contact. Thank you.
00:22:45.384 - 00:22:51.964, Speaker B: All right, that's a very wonderful talk by Ventali. I don't know if you have any question, you can raise up your hand. Okay.
00:22:56.944 - 00:23:23.860, Speaker C: Hi. Thank you. I'm curious about like I saw the benchmarks were really good on the proving side compared to like Jolt and SP one. I'm wondering especially you talked about the trilemma. What were some of the trade offs? For example, I know SP one also uses planky three stuff. So what kind of trade offs were made to improve the proving speed? And.
00:23:24.012 - 00:24:12.302, Speaker A: Yeah, I think the main difference between us and SP one is they're still using RISC V, RISC B instruction sets and we are using our own sort of designed customed instruction sets. I think that's a man differentiation. There are a lot of like the member arguments and a couple of other things are different too. But I think in the proving system side, eventually, like everyone is going to, right, it will become a commodity and everyone is going to use the most performant and advanced libraries. We are contributing to planky three and we're working on a more optimized version of Planky three. I'm not sure if maybe it's called Planky 3.5, but we're working on that as well.
00:24:12.302 - 00:24:49.794, Speaker A: So we're going to integrate with more efficient PCs called basefault. So we're doing a lot of work on the proving system as well. But I personally think that proving system wouldn't be a differentiator for any ZKVM. And every proving system is open source anyways. So I think the optimization would be, at least for us, would be from the instruction sets and the compiler would have to keep optimizing the compiler as well. So does that answer your question?
00:24:49.954 - 00:25:04.102, Speaker C: Yeah. So on the RisC V, so you're saying succinct or SP one is like a Risc five Vm, and then that compiles to LLVM, whereas you guys wrote, I guess I don't quite understand what the RisC V thing was, but I'm.
00:25:04.118 - 00:25:15.714, Speaker A: Not sure if they are compiled to LVM. But I know they're using this either RISCV or reduced risk V instruction set. Yeah, but I'm not sure about the LVM side.
00:25:16.654 - 00:25:17.434, Speaker C: Thanks.
00:25:19.414 - 00:25:21.314, Speaker B: Right, any other question?
00:25:27.474 - 00:25:30.094, Speaker D: You said right now you support c.
00:25:30.394 - 00:25:34.026, Speaker A: Yeah, right now I support c, but.
00:25:34.050 - 00:25:51.574, Speaker D: On all the charts it showed up. In any case, you go from whether c or rust, you end up with LLvM code. Right. So what needs to be done still to support rust, for example?
00:25:52.334 - 00:25:53.222, Speaker A: What? Sorry.
00:25:53.318 - 00:25:56.230, Speaker D: Because from rust you can already get this.
00:25:56.422 - 00:26:27.224, Speaker A: Oh, like. I guess we have to, like, different languages have different runtime, and there is some, like, work to do there as well. And we have to support, like, some because our valida design is different from other vms. So we have to. So, for example, bras standard library, we have to, like, sort of figure some edge cases there as well. I think that's my. I don't work on the compiler side, but I think that's like runtime, and then we have to support, like, library functions on top of it.
00:26:27.224 - 00:26:34.044, Speaker A: So we're working on sort of, for example, like ROS standard library support and a few other support. Yeah.
00:26:34.344 - 00:26:35.124, Speaker D: Thanks.
00:26:37.824 - 00:27:10.034, Speaker B: All right, any other question? Okay, that comes to the end of the talk for today, please. Can we give Vintalian an apple's, please? All right, that's the final talk for the flower stage. So by 05:00 we'll be having our closing ceremony in the root stage. So thank you, everyone, for coming to the talk, and I so much appreciate your presence. Have a good day.

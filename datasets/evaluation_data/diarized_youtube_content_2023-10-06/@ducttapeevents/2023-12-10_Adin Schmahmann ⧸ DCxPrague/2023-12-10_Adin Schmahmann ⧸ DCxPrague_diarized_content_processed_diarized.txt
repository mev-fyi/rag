00:00:03.600 - 00:01:11.124, Speaker A: Hi, thanks. Yeah, so, my name is Adin. I'm a technical lead in the IPFS shipyard group within protocol labs. So, IPfest Shipyard or the group, that's the driving force behind a lot of the IPFS tooling that you may have used. So things like the public gateways of IPfs IO and Dweb link binaries and tools like Kubo, or IPS desktop and companion, or IPS cluster libraries like Boxo and Helia that run in Go in JavaScript and helping with the underlying specifications that sort of drive these things for all the other implementations that are out there trying to make this work and building out the IPFS ecosystem. So today, ipfs based apps are either retrieved and validated with ipfs tools like some of the ones you see up there, or using public gateways run by some of the groups you see down there. And this is okay.
00:01:11.124 - 00:01:38.784, Speaker A: When we use the IPFS enabled tools, we get lots of nice properties. We can fetch the data from anybody. It gets validated, it doesn't matter. If somebody wants to lie to us, we'll find out. They won't show a bad wallet dapp to a user or something. Gateways feel less good I feel like for those of us who've used IPFs things, gateways, they feel less good. They're very convenient.
00:01:38.784 - 00:02:42.096, Speaker A: But it requires putting your trust in the companies that run these gateways or the groups that run these gateways. As we're trying to decentralize our Dapp deployments, that doesn't feel the best. So let's sort of, I guess, maybe take a step back. So an IPFS client, right? Whether you're talking about a gateway or one of these more fuller tools, there's sort of three jobs that have to happen. We have to find the data, fetch the data, and then process the data. So finding the data is things like, because we're in a content addressable system where the data could come from anybody who has it, we have to find who actually has it. So we could check the amino DHT or the IPFs public DHT and see if it's there.
00:02:42.096 - 00:03:14.724, Speaker A: We could check the IPNI system and see if it's there. We could check the nodes on our lan and see if it's there. We could ask a few peers that we know for our app, probably have the data, or we know they should have the data, unless they're offline or having some issue. We could hard code all of that, fetching the data. There's a variety of protocols. I've listed a few you could use the Bitsol protocol, which is used by a number of projects. That protocol runs over Lib P two p.
00:03:14.724 - 00:04:20.566, Speaker A: So that means you can run it then over different transports, you can run it over quiC, you can run it over TCP, you can run it over websockets, you can run it over web transport, and those are all fine. You can do HTTP requests for the graph data, so not for the JPEG or the HTML, but for the graph data underneath all of that, because IPfs moves around graphs of data. You could even take that HTTP request and route it over lib p two p because HTTP can work over streams. And there are other protocols, car mirror and Graphsync. And there are other ones that you might not think are viable here, like the BitTorrent transfer protocol, which also moves around hash link data. Then there's processing it. So in the common case ippest colon slash slash Baffy Mycoala Jpg or whatever, there's this format called Unix Fs that describes the transformation between graph and your JPEG or HTML or whatever.
00:04:20.566 - 00:05:01.094, Speaker A: So it has to do that. It has to worry about things like directory traversals. It has to handle things like oh right, if it's a directory but there's an index HTML file in it, I should load the index HTML file and do all of that. I have the Netlify redirect style directives, I have to handle all that stuff is in the processing. So all these things have to happen no matter how you do it. So maybe simpler, remember, find the stuff, fetch the stuff, process the stuff. And we have to do some of this work can be done in the browser and some of this work can be done by public infrastructure.
00:05:01.094 - 00:05:44.530, Speaker A: We can do it all ourselves, or we could do none of it ourselves. So starting here, this is the common thing you might run into. What you are really looking for is more abstractly ipfs ercid, but then it turns into this thing where you go to Dweb link and you get it from there. And now what you've done is you've asked the infrastructure to do all the jobs and you do none of the jobs. That's one way to slice it. Now maybe you're not worried about Dweb link for trust. You're like, yep, by trust.
00:05:44.530 - 00:06:49.194, Speaker A: Those guys are going to figure it out. Those IP shipyard guys aren't going to cause me problems, and we'll do our best not to, we swear. You maybe are concerned about availability. Like hmm, what if that a Dean guy finds his way to wherever the warehouse is and he trips over some wires that could be problematic. And so you're like, well, okay, instead of embedding in the URL from my JavaScript or CSS or whatnot, I'm going to use a service worker and I will intercept that request and I'll proxy it between, say, I also trust Cloudflare and I'll proxy between the two, and then I can fetch from both of them in parallel or race them against each other, or do one at a time and sort of gain some resiliency that way, but resiliency within a smaller subset of the trusted nodes. So there's this resource called public gateway Checker, which people sign up, they say, I have a gateway. And we say, okay, basically, is it online? What capabilities does it have? We don't know.
00:06:49.194 - 00:07:35.300, Speaker A: There's no assertion, no one's vetting to make sure that these guys are always returning the right data. And so when I look at this and I'm doing this multiple trusted gateways thing, I look at it and I say, which of these guys do I know and trust? And I'm willing to go with, and that's what I have to be stuck with. But what if I could broaden my base a little bit? So this is where we have a trusted, a trustless gateway API. So again, I still want the same thing, you know, IPFs, Baffy, mydap. But the plan is we are going to ask the infrastructure to do the first two jobs, find the data and fetch the data, and we are going to ask the browser to process the data. Right. This is one way that we do this.
00:07:35.300 - 00:08:00.820, Speaker A: You can even go to Dweb link and you can give it an accept header that says, I would like this thing as a car file. A car file is basically just the graph put into a container format. That's it. There's really very little fanciness. Just sort of the blocks of data lists them. Here's my CID, here's the block, here's the CID, here's the block, and that's it. And so the infrastructure is gone.
00:08:00.820 - 00:08:53.247, Speaker A: They found it. They found the data that I need for my file or my directory. I can even pass through it and it will give me the proof. Blocks of the path on the way down to my file. There are other things I haven't shown here, like you can ask for ranges of the bytes or things like that, and it will package all that data up, it'll send it to me and then I can do the processing in the browser. And now we're not trusting, we're just waiting on availability so we can go back to this list and be like, yeah, all of you are fine, why not? At this point, you're sort of just worried about availability. You're worried if DWEb link is going to be up all the time or not, or what the performance is like, or if foreverland IO is going to be better.
00:08:53.247 - 00:10:09.784, Speaker A: That's what you're worried about. You're not worried about are they going to serve me a bad dap that's going to jack all my money and send it elsewhere? Also sort of bonus points. These are cheaper and less risky to run. Not cheaper because the processing is expensive, but cheaper because they're less risky because you're not serving HTML anymore, which means, or jpegs anymore, which means that people are going to try to use you for abusive purposes less, which means you're going to have to deal with takedown notices less, which also means that hopefully you will get more of these people to choose from because they have less pain to deal with, which these people are just doing this because they want to, they want to make a public resource available. There's also a bonus here, which is that if you wanted to play around with additional uri formats, you could do this now without waiting on the infrastructure to update because you are in control of how the rendering happens. Let's see, I was going to have, ok, we'll just do it. We'll do it the way where I don't show the demo just because that way I don't have to mess around with the screens.
00:10:09.784 - 00:11:00.244, Speaker A: I could do this, I could go to a gateway. There is a new feature in curl where you can use ipfs and if you have a gateway environment variable set, it will work. But I could choose to use a gateway I don't trust. Ask for the data as a car file, pipe it to this car unpacking tool and Tada, I get the answer and you can do this and you can pipe it to ffmpeg or whatever you want. You can just go and do this. And again, there's no trust here. This thing is going to, you're going to run into problems validating the data if you do this.
00:11:00.244 - 00:11:32.564, Speaker A: I guess maybe here you'd have to be a little bit careful. You want to be actually making sure that the exact thing back is what you are getting. And I think this will probably just do a pass through with HTTP underneath. But this is the kind of thing you are sort of able to do is to validate the data. All right, what if we push this thing one step further. So now we're just going to have the infrastructure find the data and we are going to do the rest of the work. We're going to fetch the data, we're going to process the data.
00:11:32.564 - 00:12:33.260, Speaker A: So this reduces load on infrastructure because this business where you proxy all the bytes in the universe is like bad news for infra costs. So again, you get more people to run this stuff because the costs are lower. And the people who do run the infra have to give you like 429 back off errors less because it's easier for them. You can support protocols, the infra doesn't. So for example, the trustless gateway protocol, a kubo node today will serve that up. You can run a gateway node, it will, you can ask it to fetch data this way, whether over regular HTTP or HTTP over Lib P two P, but it will not internally fetch data from a node that has that protocol exposed, something we'd like to improve and fix. But in the meanwhile, you're sitting there with your browser and you're like, I don't want to wait for those Dweb linq guys to update their code and go and then update the infrastructure.
00:12:33.260 - 00:13:59.580, Speaker A: I'm just going to do it myself because as long as finding the data piece tells me that somebody else, you know, Alice has the data speaks the HTTP gateway protocol, I can just go ask her. I can skip that whole step. And I also get to save myself a hop through the infrastructure on the way because it doesn't have to go. People who have the data dweb link me, it just goes them to me. All right, so where do we go from here? So we're going to start putting up separate public infra that has different domain names for the trustless gateway and delegated routing so that you can more confidently embed those in applications without worrying about with sort of lowering the risk of what happens to those domain names because they do not carry the hazardous materials which is decoded user data. You do your best, but stuff happens. And improving the trustless gateway tooling, the thing I showed you with the piping to a car extractor is much, a lot of that works better in go.
00:13:59.580 - 00:14:55.982, Speaker A: At the moment, we have more tooling to do in JavaScript. That tool I showed you was JavaScript, but there's tooling to show it to do all the rendering work in the browser and the redirects and index HTML and all of that that needs improvement. In order to properly do this thing, the transport layer within Lib P two P has to get better and better integrated and more widely adopted across both the IPFS ecosystem and the browser ecosystem. For example, web transport support is much newer to the browser ecosystem and needs sort of more adoption there. WebRTC is being better added to more of the libidp ecosystem, and so support there will also make this easier. But the good news is you can kind of do both. You could say, I'm going to do delegated routing when I can.
00:14:55.982 - 00:16:14.254, Speaker A: And if you give me a bunch of peers, and Alice and Bob and Charlie all speak tcp, and I cannot talk tcp because the chromium and Firefox and Safari people won't let me, that's okay. So you just go back one and use these, right? So you can kind of, it's not sort of one or the other, you sort of get some mixes as you need to. Then sort of a really important one is the UX around how we put all the pieces together. So in order to really bundle this and make it easy for Dapps, this means you don't have to worry about some of the problems that are specific to jpegs and hotlinking and how they work in browsers, which we can discuss. But your dapps are like HTML, and so you can do this with service workers. But now you have to worry about updating because to some extent you want to be protected from how the updates happen. There's some UX questions for us to figure out with the community around how this works, how it is that we want to do updates that feel like the user is still in control, because that's the premise of this decentralized thing, is that we're giving the users back control of their data and their applications.
00:16:14.254 - 00:17:22.143, Speaker A: Pet names is also another nice usability thing, which is that if you go to the Uniswap website and they don't publish immutable, as far as I can tell, they don't publish a mutable link with the latest app, CID. You go to GitHub, you see the latest release, the release has the CID in there, and then you have to go punch it in. You might just want to have a pet name for it that you can operate with and just sort of register it as this is uniswap, and then choose later to update and how that works. And this was brought up actually by a discussion with some folks over at liquidy who do defi things. And they were like, yeah, both. We want to figure out how to do this because this is with our values and talking to other folks around the ecosystem. You also hear that related to the conversations this morning around regulation that this could be very useful to help us with getting over some hurdles and also doing the thing we want to do anyway.
00:17:22.143 - 00:18:59.234, Speaker A: A rare case of the regulators pushing us in a direction we want to be going. Anyhow, thanks for giving us one. Just the one, is that it? We do all that work, we get all the things, decentralized app deployment, we're all good and go home. It would be nice to do a little bit more and add resilience and trust reduction at the blockchain access layer. So if you are some ethereum daP, probably you have an ENS name, but also once you've loaded the static assets inside, you're making all these Ethereum RPC calls to infura perhaps, or alchemy. And so let's try to see if we can not do that, or at least not do that in a trusted way, like remove do roughly the same pattern that we've been doing here, which is we move from ask infura for all my data and I have no way to verify it, to maybe ask them for data that I can verify and they fetch the data for me to maybe I just ask some resource where the data is and then I find it and fetch it and process it. Right? This function ethgetproof is very, very similar to the idea of just how the trustless gateway car retrievals work.
00:18:59.234 - 00:19:46.674, Speaker A: You pass in your state and your state route, and then the query you want to execute and the data you want to get back, and it hands you back a pile of data that represents the merkel proof. And that's exactly what happens over there. You say I have a graph, it's a file, a directory or whatever, give it to me. Hand me back a merkle proof. It feels like there's a lot of overlap here, a lot of ways we can share tooling, share development, to sort of make the decentralized Dapp thing happen. So perhaps you're interested, you'd like to get involved in this with some folks who've expressed interest. You want to start up an IPFs and Dapps working group.
00:19:46.674 - 00:20:21.594, Speaker A: You have a luma event. We're planning on starting something up soon. There is tentatively a date for the first working group meeting, but more people show up. We can then do polls and then find out what time actually works for you instead of just guessing. So highly encouraged to do that. And we have a telegram channel, so join there too. I think I still have some time to try to blow through some of this, so thank you and I'll take any questions that you guys have.
00:20:27.614 - 00:21:03.084, Speaker B: Thanks for the presentation. When you showed the progress of towards more trustless solutions. And the last one. Yes, this last one. And when you compare this that you are basically asking Alice, look, I want to fetch the data from you. Did you make any comparison regarding timing delays and so on when you compare it to the previous one when it's set of the edge providers like the cloudflare is?
00:21:06.304 - 00:21:46.954, Speaker A: Yeah, so it's a good question. I think so. These are both pretty new in terms of the tooling. The APIs have been around for a little longer. The tooling getting into browsers that we can push and evaluate on this is newer. I think that with some naive setups, for reasons that may or may not be surprising, this is actually much better. And it's not because of caching, it's because you have to be really careful over here because the related to this whole like you have to have the right transports the browsers will let you use.
00:21:46.954 - 00:22:45.616, Speaker A: So at the moment the main transport that is accessible across the network is web transport. The number of nodes that have secure websockets enabled is a few large info is like a couple large infra providers should be all of them because just add a TL's cert. But it's only a couple of. And nodes that have the HTTP stuff. The HTTP endpoints exposed for serving local data as opposed to sort of let's call them recursive gateways that serve all data is lower too because that concept is newer, which means that you have these web transport nodes and you have to deal with the fact that the browsers that you can use it in, which is at the moment mostly chromium firefox is working on it. They have web transport. They just need to get the ability for us to use certificate hashes instead of cas.
00:22:45.616 - 00:23:46.496, Speaker A: So we're working on it. We're getting there, we're getting there. But if the, I think chromium, it's something like you get 64 web transport connections at a time and if you dial someone who isn't there, you have to wait for five minutes. And so if you start loading lots and lots of assets on your page and a bunch of those nodes are not dialable and you're not really careful with how you do your dials, it's going to start being really sad because you're going to get, basically your connection queue is just going to get killed. Having nothing to do with round trips or latencies or processing power. You're just going to get throttled by the browser. The good news is, while we're busy figuring out with people like what is a reasonable limit in browsers and what are good ways to manage our resources in the browser in JavaScript, we can also put more work over here.
00:23:46.496 - 00:24:35.144, Speaker A: This guy is infra, he can be a little smarter than just look up and say, oh, there are these 50 peers, here you go. It can see and be like, well, which ones seem like they're still alive? Maybe I'll put those at the top of the list. Maybe the rest, I don't know if they're alive or dead because maybe they're in China and across the great firewall and I can't tell. It could all be a lie. Right? So give you the best data you can and then let you sort of evaluate from there. And then that would help this process out a bunch of. So I think realistically, step one is let's get this thing happening everywhere, as much as we can actually validate the data, make sure no one can lie to you, give you a bad wallet.
00:24:35.144 - 00:25:12.074, Speaker A: Dap. That seems like priority number one. Next priority is let's do this. Just the order as we work our way down. Anyone else questions? All right, time around, you want to chat about this or anything else? Yeah. Let me know if you're interested in how to do this stuff. And you're like, yes, I'm really interested in how we make the Ethereum thing work so we can do the RPC calls also.
00:25:12.074 - 00:25:13.374, Speaker A: Let's chat about that.
00:25:15.484 - 00:26:17.124, Speaker B: I have additional question. I don't follow ipfs that closely, so I don't know how it progressed literally, but is there any progress or research on the pinning the stuff, meaning that narrative that says be careful, you still have a risk that you lose the access towards the data which is being uploaded somewhere. I don't mean from the infrastructure point of view like Pinata and so on, but in general this concept, whether it's being a little bit like a worker or something, in order to improve this narrative for the projects to be more so, they could predict more having reliable that something will actually stay there without the risk of the, of the censorship of the protocol pinning service or something. So the question is whether there is some research in that field.
00:26:18.744 - 00:27:26.194, Speaker A: Yeah, so I guess I'll say like frequently when I hear this question, it's in the context of other projects that are figuring out ways to incentivize like long term storage of data. And they're like, IPFS doesn't incentivize long term storage of data. And it's sort of like the wrong lens. It's sort of like HTTP doesn't incentivize the long term storage of data either. But any of these protocols that you're thinking of that do incentivize long storage of data, you can fetch that data with HTTP, right? So they're sort of like independent problems. In fact I could, because most of these things are blockchains with high confidence, you could go to any of those systems and make them ipfs things by just sort of putting, getting encodings for them, putting cids on them and then transferring them with the same protocols that you've been using anyway. Because if we go back here, what are the jobs of our ipfs client? Find it, fetch it, process it.
00:27:26.194 - 00:27:51.464, Speaker A: There's no storing here, right? Store the data, doesn't show up anywhere in the pipeline. Storing the data is the job of maybe the server side of the equation. And the server side has maybe something like store the data, advertise. I have the data, serve the data, but that's a different part of the equation. Does that make sense?
00:27:52.884 - 00:27:56.644, Speaker B: Yeah, my question is, so.
00:27:59.144 - 00:28:35.504, Speaker A: Yeah, I guess what I'm saying, yeah. So the question was, is there research on how to do sort of, you know, extremely long term storage? My answer is I think all of the other research you're thinking of that does extremely long term storage is also long term storage for this. Right? Like it's like it's sort of independent problems. It's like I'm not worrying about how to pay the servers here, I'm just trying to find and fetch and verify bytes. Okay. All right, well, thanks everybody for your time.

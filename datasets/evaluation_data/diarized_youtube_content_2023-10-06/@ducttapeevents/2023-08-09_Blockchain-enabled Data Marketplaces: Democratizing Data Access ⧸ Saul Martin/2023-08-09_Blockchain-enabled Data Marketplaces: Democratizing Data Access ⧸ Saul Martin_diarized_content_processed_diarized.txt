00:00:01.880 - 00:00:15.990, Speaker A: Mic tech. Okay, it works. Awesome. So my name is Sol Martin. Today we're going to talk about data marketplaces on chain. I am a blockchain data engineer at Nethermind within the enterprise team. Oh, ok.
00:00:15.990 - 00:01:07.766, Speaker A: Now Mike's working better. Awesome. So, but why this topic? I think in light of recent events that we've seen so far, there's raising concerns about the use and control of Data that some parties are doing right now. On that extent here, we can see two different headlines from last week, and they're a bit updated, I'm not gonna lie. And with Twitter just reduced the previously available API for researchers ready to have done similar stuff with third party and developers. Actually, for Reddit, I just read before that there's going to be a blackout tomorrow for two days in which separates are going to be private because of the usage of the data and the newest policies implemented there. So yeah, think.
00:01:07.766 - 00:02:31.756, Speaker A: But why blockchain? So I think overall blockchain, by creating an efficient and transparent marketplace, we can really help streamline data access and make it available so that we can make available individuals can access data and benefit from server data resources and potentially and hopefully also contribute to them. So in this presentation, we'll talk about first the benefits on a marketplace on chain data marketplace, the challenges, the disadvantages, which I'd like to say there are also some challenges that can be dealt with and some real work examples. So I always say, I really don't like to say this, but data is gold, not the new gold, but actually super valuable, really, not to use this expression, but it really helps to contextualize and put into situation the value of the data. It has. However, that said, the actual processes to harness the real value of data remain rather undeveloped and actually the models remain relatively centralized. So on chain data marketplaces has large amount of benefits over traditional ones, and there's largely evolve around the blockchain benefits. So one, we have transparency, security and ownership.
00:02:31.756 - 00:03:37.596, Speaker A: On the transparency side, everything is public. So blockchain by nature is a public or historical ledger in which all transactions are public, verifiable and immutable, which really can help make it so that both partners, so data sellers and data buyers, can really trust the origin of the data and the quality by itself. Then on the security side, blockchain again by definition has some cryptography features which make it that can be protected against stampering and finally ownership. So you can really give back to the owners. Data owners can really have that flexibility to essentially do as they wish with the data, meaning they can set up their fair price or not, if they choose not to do so. And on the other side, they can also help control who can access their data and into which form there's anyone that is not just put there, but that one is about and around that. New business models and industries could emerge by this.
00:03:37.596 - 00:04:24.202, Speaker A: For example, small businesses and individuals can benefit and can actually create. New industries could emerge by just doing the analyzing the data that is actually placed on these marketplaces. And one example of that is if you're a medical engineer or medical imaging PhD student and you're trying to get analysis of some tumors, you don't have many data sets available right now. If you could share those x rays anonymized, of course, then you could have your models be richer and therefore can benefit from that wealth of data. Cool. So now let's go through the challenges. So, as I mentioned before, small business individuals have it more difficult.
00:04:24.202 - 00:05:27.174, Speaker A: Why is that? That's generally because these entities, there's the lack of transparency, mainly due to many players. So for example, I don't know exactly where to access data for log level transactions of credit card users in the US. That's super valuable data set, but that's something that is not available right now, so how can we deal with it? So on that end, it's kind of a challenging environment to step in. So blockchains on chain data marketplaces actually have it difficult as well. So first, one of the first challenges, fair pricing. So there's a vast amount of data available, vast amount of data sets, so it can really become difficult to fire to find a fair price, to find a market for it. Then data quality, just the risk of low quality or false data entry, which could undermine the trustworthiness of the marketplace itself.
00:05:27.174 - 00:06:22.684, Speaker A: I think here it should be noted that using an arbitration mechanism such as Chainlink, for example, which rewards their nodes if they provide accurate information or penalizes them if they do not, could be quite valuable, although slightly different, as for example for chainlite, you might have ten sources of data for the same price for the same blockchain. Here, if you're selling your own x ray, there might be only one source of data. So that becomes tricky. And of course, we have privacy. So with increase, there are saying this increased risk to privacy. So we have to make sure that user animation is something that can be done easily. And then we have the right consensus mechanism, so that if the data needs to be dealt with and in line with GDPR laws and whatever all the privacy laws we have, then that can be done.
00:06:22.684 - 00:06:58.144, Speaker A: Then let's look at disbalances. I think briefly this lack of liquidity. So it might be difficult for you to find a buyer for your product or you as a seller or you as a buyer, find a data set that you're looking for. Then high fees, blockchains, or actually data by itself requires a lot of computing power, which can make it difficult to deal with in blockchain. And then there's a technical uplift. So this is not something for everyone. And I think this is something that needs to be tackled within the whole ecosystem by itself.
00:06:58.144 - 00:07:31.808, Speaker A: It's not only for data marketplaces. So now let's look at some on chain data marketplaces, live examples. So we have two right now. So the first one would be Deemobos and second one will be awesome protocol. So Demobas stands for decentralized marketplaces of online big analytics. This is actually a research paper by chinese university that was published I think five months ago. So they essentially, I'll go through the details later.
00:07:31.808 - 00:08:15.414, Speaker A: And then we have OSM protocol as a real world example. So this is something that is in production and you can actually interact with. So this image might be some, might look a bit cumbersome, and it is. So let's go through the steps that theoretically on this theoretical approach, data backup place would work based on these researchers. First, let's say I'm a data owner, I want to sell piece of data. The first thing I would do is choose upload this data to DSN or distributed storage network. Once that's done, smart contract will actually check if you have uploaded that data to that specific location.
00:08:15.414 - 00:08:49.470, Speaker A: How does it work? Because you actually, instead of you uploading the data to blockchain, you upload the data, access keys to the blockchain that then is ciphered and is encrypted. So first step, you upload it. Second step, the smart contract checks that you have actually uploaded and it's something that is reachable. Then you get returned the ciphertext for that. So now let's say I'm the other Persona. I want to buy that same piece of data. How does it work? First, you would need to find a place to actually look for the data.
00:08:49.470 - 00:09:50.464, Speaker A: This is something that hasn't been specified on the paper itself. Ideally you have a UI in which you can just search, but what it does mention is that they can use IPFS search capabilities to index the hash or kind of the dataset itself and the metadata. And then you'll be able to research and look for the specific dataset they're looking for. So once it's indexed, I'm as a data buyer, I can go through and buy that same data set. How does it work? So I'll just go there, pay my fees, pay the price that has been set by the data owner and I will return smart contract will return deciphered text, meaning I will just get some encrypted text with data access keys to that data. At the same time, the data owner will return to the data buyer via TL's so secure mechanism, the decryption key. So that cipher checks the access with the access key to that data.
00:09:50.464 - 00:11:06.352, Speaker A: Therefore you can actually then have access decrypted text and have access to where that data is being stored currently. So what happens if there's a bit of abuse by either the data owner or the debugger? So they have set an arbitration contract in which if necessary, or if something has gone wrong through the transaction in terms of data quality, data buyer can go and ask, well actually trigger the smart contract and then trigger a whole arbitration mechanism, which I think is like five, seven nodes that need to validate if data is actually what it used to do or. Yeah, so that's on the theoretical side. On the actual implementation, down from OSM protocol, there's two ways I've divided this ocean protocol kind of approach. So you could either serve public datasets or you could share and access private data sets. So how do we get access to public datasets? And these might include comments, ratings from decentralized apps, for example. So first, the way it works is that awesome protocol tokenizes the data access keys.
00:11:06.352 - 00:12:14.094, Speaker A: These will be called the data token and they're an RC 20 token. So once you want to access a piece of data, let's say the historical ETH prices, you'll be able to buy that for the price. If there's a price, and if there's no price, you still have to pay the fees to get it. You will retrieve the access keys where the data is located, and then you can run whatever ML AI analytics, just statistics that you want to do, or just keep the data if you want to resell that as a service, for example, you're running, I don't know, a risk indicator for a financial service, and you have as an input the historical ETH prices and as an output indicator, you'd be able to do so by just minting a new NFT. And then that would work as a sub licensing mechanism. Also, something I forgot to mention is that this data is actually, you're only serving data access keys but if the data set is small enough, you could theoretically store the data within the NFT itself. So what happens if you want to serve private asset? This is the best use case.
00:12:14.094 - 00:12:58.074, Speaker A: So that case what you would do is you have still your data token, but you have as well a new ERC 20 token. That will be an algorithm. What is an algorithm? That'll be any piece of code, any python code, Java, whatever you want to do. You put all of those together within the environment. They call it compute to data and that runs in a docker container and you will get the output or the logs of that processing job. I think this be something that might come up in a quick q and a. Is that what happens if my algorithm just prints the whole data set? I think that can be quite an abuse pattern that I could see quite frequently here.
00:12:58.074 - 00:14:02.694, Speaker A: Right now there's not an average mechanism on azure protocol. However, the data owners can actually whitelist a set of algorithms themselves, so that, you know, you can bet manually if that algorithm is actually a good one, and then it's not really abusing your data. So then let's go through real world applications like why do we, what would something like this take? Importance. So of course we have healthcare. As I mentioned before, if you want to do some medical imaging research paper, you would need some data to actually, to actually get some output. So if you want to sell your x rays, I don't know, whichever medical processes that can be done, you could eventually do so on the blockchain and then you could get paid by doing that. Financial industries mentioned before, briefly, these application prices are most probably public already.
00:14:02.694 - 00:14:45.232, Speaker A: Of course it depends on the fidelity and the granularity and all of that, the instruments that has a cost. But I think that the option here from the financial industry is that they will be able to have customized risk indicators which you can sell directly on non chain data marketplace. And then of course we have the environment. So actually I think Catalonia and Barcelona have done a proof of concept of this. So you will be able to monitor the CO2 emissions or on a given city. And for this it's similar to healthcare. So let's say you have and you put a device in your house to monitor CO2 emissions, to monitor, I don't know, the temperature.
00:14:45.232 - 00:15:36.364, Speaker A: You could tell that if you do that right now, you potentially don't have any clients because one data point is not really worth it. But if you have a full neighborhood doing that, or a full city, full country doing that, then that becomes more valuable because you have more data points and then as a conclusion, these marketplaces exist. They're a real thing. However, they can be quite challenging to be implemented, mainly because of privacy reasons. And also they're not fully decentralized right now, as you're kind of dependent on where you store the data, as you're actually only sending or storing the data and giving them the access keys to the data. So that could be stored in an s three bucket, could be stored in ipfs, could be stored filecoin, could be stored anywhere. So that's not really decentralized for some options, as I mentioned before.
00:15:36.364 - 00:15:42.084, Speaker A: But yeah, I think if the audience has any questions, be happy to answer them.
00:15:50.144 - 00:16:30.644, Speaker B: Thank you so much. Does anyone have any questions? Hey, thanks for the talk. I was wondering if you could maybe elaborate a bit more on the data aggregation part. So, as you were saying, like, if you are an individual measuring your CO2 in one household, it's not very efficient, but you could aggregate this data from multiple sources. Is there already a sort of decentralized infrastructure that helps with this aggregation so that it's not a cumbersome process where I have to contact all these different households to see if they want to give me my data?
00:16:31.584 - 00:17:24.034, Speaker A: Yeah, I guess for the environment data, there will be a bunch of different options. This is more broadly speaking, how that will work. For example, I can think of a marketplace, in a marketplace that could potentially use labels as a filtering mechanism. So let's say they have an uploader data kind of drop down on their website. Then you would select the data you want to upload, CO2 emissions, for example, and then that would be always kind of aggregated. So if you're a buyer of that data, let's say you're working for the government, trying to compute, I don't know, flood predicting floods, for example, although it's not really related to CO2. But yes, they will just be able to buy the whole data set for all individuals that have actually uploaded the data by a single click.
00:17:24.034 - 00:17:36.914, Speaker A: So yeah, it should be possible to do so. It's just the actual adoption right now is not there yet. So it's a bit difficult to do right now.
00:17:41.614 - 00:17:57.914, Speaker C: How do you prevent node operators from doing a vampire attack? Because once you have information, you can't unknow it. And so you could have a competitor protocol that does a vampire attack and just like collects its own data and collects its own.
00:17:58.774 - 00:18:33.016, Speaker A: Yeah, I think that's a risk here, because once you have the data, you have it. So it's not here yet. But anyways, I shared two examples. So one is certain private data sets and the other one is certain public datasets. For public one, we don't care for private datasets. What's been done is that you put your algorithm together with your data and then that runs separately. And something to note here is that these servers are actually centralized, so they're using AWS or azure to run those kind of compute jobs on the cloud.
00:18:33.016 - 00:18:52.544, Speaker A: So it's kind of susceptible to an attack there. Theoretically, if you bet the right algorithm, you would only get logs that this algorithm is supposed to get you. So yes, it's kind of tricky how to do that. That's why privacy and setting up all of that infrastructure is kind of valuable.

00:00:00.760 - 00:00:26.634, Speaker A: Thank you very much. Thank you very much for having me. Today I'm going to be talking about the future of digital identity. Okay, there we go. Awesome. Sorry. All right, so today I'll be talking about the future of digital identity.
00:00:26.634 - 00:01:05.044, Speaker A: I go by DC builder on X and other social media. I'm a research engineer at the World Quinton foundation, where we mostly work on building the future of privacy preserving proof of personhood. And proof of personhood is a core, integral part of digital identity. And I spend most of my day just thinking about these things and talking to people in the wider ethereum ecosystem, building these sorts of primitives. And I sort of want to introduce the topic to you and sort of where we are right now and where I see the things going in the digital identity. So I have a bunch of memes. So this is a really good one.
00:01:05.044 - 00:01:40.470, Speaker A: I want to introduce sort of like where we are at right now, the status quo of digital identity. The status quo of digital identity, essentially, is that we are working with servers. Usually all of our data is owned by companies like Google, Amazon, Meta, which essentially we interact with every day. And they leverage our data to sell their services to us. And that's how they are able to provide free sort of services. Right. And this is like, sort of core part of our digital identity, like what we do, what we interact with, how we represent it in social media, et cetera.
00:01:40.470 - 00:02:04.628, Speaker A: So currently, all of our data is owned by these companies. We sell it to them for free, and then they're able to monetize it and provide the services for free. So all of our data is on these SQL databases owned by servers. They're permissioned. Right. So if Google tomorrow bans me from my YouTube account, I lose all of my subscribers, I lose my livelihood, potentially. Eventually I can get banned for saying a specific thing on social media.
00:02:04.628 - 00:02:34.204, Speaker A: So if I voice a specific political opinion on X that is controversial, then I might get booted off the platform. There's all sorts of things that can happen. All of these systems are also not interoperable. If I'm on Google, my Google account is not interoperable with my Facebook account or with my whatever. The data is just siloed in these specific systems. It's also privacy invasive. They have access to all of our personal information, phone number, names, addresses, you name it.
00:02:34.204 - 00:03:38.874, Speaker A: And we've also seen recently that things like KYC or know your customer or know your business don't really work. Well, we've seen that, for example, the OKX exchange KYC check was passed by a generative AI model, essentially, where you're able to fake the actual check for humanness by verifying a KYC document, by just like some AI generating some image of a passport or digital identity. It's centralized. And most important of all, users don't have sovereignty. I don't own my own data, I'm not able to make decisions about my own data. And if I want to be even like a productive user of modern society, of modern services, I really need to give up all of my privacy and power within my control of my digital identity. So in recent years, we've had a whole new world of cryptographic primitives, essentially a lot of new cryptographic techniques that have enabled lots of new potential for building digital identity systems and more.
00:03:38.874 - 00:04:12.724, Speaker A: So the ones that I name here are zero knowledge cryptography. Whom of you have already heard of ZK, please raise your hand really quickly. Okay. That's actually most of the room. Okay, that's a pleasant surprise. So ZK, essentially a technology or a type of cryptography that allows you to make a proof about specific data or about structured computation. So for example, in the case of rollups or scalability, we're able to prove that the EVM executed some transactions correctly, and then nodes on a network don't have to re execute those transactions.
00:04:12.724 - 00:04:56.776, Speaker A: They can just verify zero knowledge proof in the context of digital identity, we can make proofs about our digital identity. I can prove to you that I'm over 18 without revealing to you that I'm, for example, 22. I can prove to you that I'm a czech citizen without revealing to you my passport or whatever my name or anything else. I can make selective statements without disclosing anything else that I don't want to. Fully homomorphic encryption, or fhe, is the second one, which essentially allows us to do private computation. What it allows you to do is that I can encrypt some data, some input x, and I can perform computations on the encrypted data. And when I decrypt that specific result, it's as if I performed the operation on the original input.
00:04:56.776 - 00:05:49.430, Speaker A: So essentially allows us to operate on top of ciphertext, which is something that you're not able to do on regular encryption. If you encrypt something, it's random information. You have no structure, so you cannot really compute over that. So now fhe allows us to do private compute, pretty much multi party computation, actually, many people in the audience are very familiar with MPC. Multi party computation is a way to do essentially shared computation across multiple participants in a network. Or in some form of program, and you're able to collaboratively compute some program or some process in a way where the participants don't learn the intermediate values or the original values that you're computing on top of, but they're also not able to sort, of course, the system into doing something it's not meant to. So essentially have this verifiable compute shared across multiple parties in an encrypted fashion.
00:05:49.430 - 00:07:18.844, Speaker A: And the last one is trusted execution environments, or Tesla, which essentially are these hardware chips that allow us to have some form of verifiable compute and give us sort of attestations that some compute happened correctly inside of a piece of hardware. And in this case, like a CPU or a GPU, there's a trusted execution environment, can attest to some computations or some programs running on these chips. So thanks to all of these fundamental technologies and some more on top of those, we've had a new sort of wave of applications and protocols come up with these things, and I list some of them here. Don't worry, I won't go into the details of all of these specific mechanisms, but it's sort of like a good introduction into all of the different mechanisms that have emerged in the last couple years that are useful for building all sorts of digital identity primitives and protocols. So to view a brief notion, you can see like ZKE, email, Zklogin, TL's notary proof, personnet, these elements essentially give you some notion of where data comes from. I am now able to prove to you that my data comes from my digital identity from like issued by my government, right? I can prove to you that on my id, my name is whatever, and you can actually verify signatures from the issuing entity of that data. I can prove to you that my follower count on X is whatever number, because I can verify that it comes from some API and I can verify signatures from TL's.
00:07:18.844 - 00:08:26.314, Speaker A: You're now sort of like have a notion of where data came from, and you have cryptographic trails, and you can verify these cryptographic trails and make proofs about that data, and then you can compose it and you can make computation with it. So this is sort of like what hints into the next step, which is like the pipeline for digital identity, right? How do you actually create a digital identity system that has the properties that we're sort of used in the cypherpunk types of values that we have in Ethereum? So you have this notion of data and where it comes from, or provenance proofs. You put that data into some general programmable environment. We've seen things like coprocessors. I list coprocessors in the right. Essentially there's things like risk zero sp one from succinct, or just general knowledge virtual machines like Cairo from Starknet or Starkware or any other ZKVM from scroll or Zksync or polygon. Essentially, these programmable environments allows us to make computations that are provable by default, and then we can just use other technologies to make it more seamless.
00:08:26.314 - 00:09:06.304, Speaker A: That's the second part. The second half of them, proof aggregators, allow you to compress multiple proofs into one and verify it at once. Proof marketplaces allow you to connect sort of people who post or who want to create proofs and people who want to verify them, and people who have hardware for the proofing, et cetera. Intents. How many of you have heard of intents or what it means? More or less. Okay, cool. So intents are this sort of notion of declarative programming, where the user, instead of having to do all of these actions on their own, the user can just declare the end goal, and some solver or some third party can solve this sort of task for them and provable inference or zero knowledge machine learning.
00:09:06.304 - 00:09:59.174, Speaker A: So recently, with the advent of modern AI, specifically generative AI, some models are able to sort of deduct information about your data, and you're able to be, for example, classified or judged fairly. So let's say that I have some personal information of my on chain credit history. So let's say I use deFi, so I have some on chain financial history, and that information can be somehow classified and classify me as a trustworthy or not trustworthy lender based on some machine learning model that can be provable, so everyone can be judged fairly. For example. This, in general, these sorts of technologies allows us to build the new future, the future that we envision. Usually when we're talking about the Ethereum ecosystem, we want our data to be essentially owned by us. We want all of our services for us to have control over them.
00:09:59.174 - 00:10:41.364, Speaker A: We're not owned by the products we use. We are self sovereign individuals with our own rights, with our own privacy, with our own right to privacy, and we can exercise it. And this is sort of like what these technologies enable you to do, something that is decentralized, running on top of blockchain rails, something that is self sovereign. All the data is owned by me. And I can make client side proofs with my own hardware, like with my own phone, or with my own computer and my private information never leaves my own custody. Similar to private keys, we've done the same thing with bitcoin or Ethereum and other blockchains where now money is owned by us because we custody our own keys. Therefore we are able to be dignified users of the services we have for monetary use cases.
00:10:41.364 - 00:11:16.214, Speaker A: But in terms of data, we're not there yet. All of our data still lives on some siloed server and they can sell it and they can auction it off. And now they can have various privacy leaks and different dangers and abusive behavior from companies of their users. It's also more scalable, but this also comes at a cost of overhead and complexity. It's more scalable because they're interoperable. These systems are. Now, if I have data on my own, I can use that data or decentralized social network with any other system that exists because these zero knowledge proofs are very composable.
00:11:16.214 - 00:12:15.696, Speaker A: Also, it's much easier to incentive align participants. The reason why systems are the way they are right now is because our payments processors don't really support granularity or some form of incentive alignment between our data and how that gets handled. It's much easier for companies to just have a terms of service. You just say yes and then they're able to do whatever. It's much harder to sort of figure out a way that they can incentivize us fairly for their, for our data. When it comes to content, we've seen monetization schemes like YouTube, which makes sense, or TikTok, or ad revenue that we share with our sort of users, but it still capitalizes on the user in a sort of unfair way because they can at any point just deplatform them and just completely just take away all of their livelihood or their social media friendships, or your in game assets, or whatever it may be. All of these things are part of your digital identity, but we currently don't own them.
00:12:15.696 - 00:13:05.784, Speaker A: So essentially, I want to move to a future, or I want us to collectively move to a future that is open source, collaborative, built by the community, where incentives are aligned between each participant, where it runs on crypto rails. Because now we have smart contracts that enforce the rules and we're preserving our own privacy because we own our own data. This is actually the gist of the presentation. I have a long form article I wrote last year on this, so if you want to scan the barcode and actually read more in detail what my thoughts are, I really recommend that usually whenever I give this talk, I prefer to have questions from the audience. So that's why I intentionally keep it short and a little bit brief just to give you my thoughts on where I think things should go. Essentially, what I want is this. Sorry for those words, kind of curt, but yeah.
00:13:05.784 - 00:13:40.294, Speaker A: If you have any questions or if you want to follow more about what I'm doing, what I'm thinking about, feel free to follow me on Twitter or an axebuild three r or feel free to send me a message on telegram. Same handle. And yeah, thank you for listening to my talk and I'm happy to answer any questions. Cool. Does anyone want to ask anything? Sure. We have mics that go around, I think.
00:13:45.234 - 00:14:30.712, Speaker B: Thanks a lot. It was interesting speech. I would just like to know that it's a nice idea about you owning your data and you cannot be deplatformed from centralized platforms like X or Facebook, etcetera. But what would you do about hate speech? Right? Like, what do you do if someone is being racist, antisemitic, all that kind of stuff, and you can't kind of stop that going? Because then I don't think it's so realistic as you would get a lot of backlash from the government and regulators and all these kind of people. Because at the moment, if you start posting this content on decentralized platforms, they get removed. But like this, you don't have the option if it's completely decentralized.
00:14:30.818 - 00:15:08.848, Speaker A: That's a really good question. The way that I usually think about these things is that you can censor on the client side. You can always have front ends that have some form of recommendation algorithms that just filter hate speech. And the good thing about zero knowledge cryptography is that you can prove which filter the client is using. The client can tell you, hey, I'm using a filter that censors hate speech, homophobia, or whatever you want. Like any form of sort of content filtering rules that you want to have. Like, let's say that you want to have like muted words or whatever, you can yourself set your own rule sets that you want to filter for and the general frontends that are going to be the most used ones.
00:15:08.848 - 00:16:02.450, Speaker A: So let's say that X, instead of X being like its own backend, it runs on like, I don't know, like lens or farcaster as a protocol. And it's just the front end is just called X. X itself can filter whatever, but at least they can provide you a zero knowledge proof that they're using some form of filtering algorithm and you know that they're committed and you at least see the rule set right now, you've seen that X open sourced, for example, their filtering algorithm, but you don't know which weights it's using. You cannot know which weights they're using because then people can sort of like take that and sort of game the system so that their content just gets pushed more to the top. But this is sort of like how I think about censorship, right? Like you at least can not censor on the protocol level. Anyone can say whatever, but you can filter on the client side and you can always prevent people from seeing bad things. And you can have some form of reputational system and sib resistance that if many people, or like one person says a lot of bad things, their reputation goes down.
00:16:02.450 - 00:16:32.054, Speaker A: Or people can say that this person is just saying lots of bad things. So all the people can see that, right? And it's in general is going to be demoted. And all of these things can be verifiable and trustless as opposed to just some centralized entities saying that it can be agreed upon by people and everything can be verifiably trusted. People can just see where it comes from, where the reputation comes from. And you don't have bots because you have some form of sib resistance as well. Right? So people cannot just create a new account and say the same bad things again. Yeah.
00:16:38.954 - 00:17:22.419, Speaker C: Thank you. Hey, I have a project that I was trying. It was related to intense that you said, like lending based on the documents, using AI agents and verifying if those are legit or not. So I built a POC which was using multiple AI agents like chat duty, Gemini, and there was another one. But the issue was still, even if I was using TLSN to verify the bank documents were actual and the banks and balance are legit. Even though the balance was low, the agents were still able to gaming loan because people were able to game it like I was able to game it. My cousin or brother, when they were playing, it was very easy to game it.
00:17:22.419 - 00:17:28.583, Speaker C: So do you have some experience or experiment that you have done with it and how you are able to solve it?
00:17:29.043 - 00:17:30.507, Speaker A: To solve what exactly?
00:17:30.595 - 00:17:36.583, Speaker C: So to not be able to game the agents, like, it's still very much possible to game the agents with the.
00:17:37.464 - 00:17:45.408, Speaker A: Lending applications, LLM engines, some context. Like game them how? Like, you mean service early inputs to get them to say something bad or.
00:17:45.496 - 00:17:53.844, Speaker C: Yeah, like basically in my basic poc, the issue was even though the user was not supposed to get a loan, they were able to get the loan.
00:17:54.424 - 00:17:55.352, Speaker A: To get the what?
00:17:55.448 - 00:17:56.256, Speaker C: Get a loan.
00:17:56.360 - 00:18:37.270, Speaker A: Like a loan oh, right. I mean like the way that currently we do these sort of like, like lending trustworthiness things are not necessarily generative agents. They're more like numerics based things where you have some form of decision tree or random forests or whatever. They're mostly xg boost, very simple models for making these sort of decisions. When it comes to generative agents making decisions on real time information or some form of symbolic execution, we're still far away from that. But yeah, right now it's more numerical models that you're proving. You can still consider the machine learning, but it's not necessarily like a transformer or some form of other things, at least from what I've seen.
00:18:37.270 - 00:19:06.484, Speaker A: There's companies like Noya AI that have been doing this year and is experimenting these things. There's a bunch of companies that work with ZKML, companies like Giza, Modulus or Ezekiel that work with them, and they're trying to do this provable ML, but the provable ML usually is not generative AI numerical models. So I don't know, but like to prevent gaming, I don't know yet. I don't have that much knowledge about that problem space in the I domain. So. Sorry, I'm not able to answer that.
00:19:12.344 - 00:19:25.236, Speaker D: Hey, thanks for the talk. We have all these new technologies and they kind of work, but how do we get to the adoption point from here? Everyone is used to selling their soul to Facebook, so how do we go on?
00:19:25.340 - 00:19:59.028, Speaker A: Yeah, so that's a good question. Actually, let me go back to the slides. Right. So a lot of these tools, what they allow you to do is to co opt existing systems and port information to the new system. The good thing about that is that with things like Zke email, I can make a proof about my email information. So essentially what you're able to do is like build these like web 2.5 type systems, and now you're able to do things like, hey, let's say my wallet, like my safe smart account, is now recoverable by my email or by my Google account, by my YouTube account, whatever.
00:19:59.028 - 00:20:40.894, Speaker A: You're able to port the existing systems to new rails and you're able to migrate them over with similar user experience in the beginning. And over time, as these systems just become naturally better and the use cases are naturally better, like that's where you get to mass adoption. When it comes to adoption, also, you need to just make the systems are so robust and so performant and scalable that you're actually able to support a billion people. Let's say that's my problem at world coin, for example, right? Like we have 5.5 million users that have been verified at the orb and 12 million users for the world app. But even then, like optimism Mainnet, the blockchain we're running on right now, we're already like at half capacity, right? Like we saturate like half of the optimism. Block space, pretty much more or less is owned by or consumed by Worldcoin.
00:20:40.894 - 00:21:20.168, Speaker A: So even if we want to scale to, let's say 10 million users, there's already not enough block space. So essentially we need to scale the existing systems so they're able to support more users in the first place. And then when it comes to adoption, you need to build use cases that people actually want to use. For us, the initial incentive is just the distribution of Worldcoin token grants. And it's sort of like an initial incentive, but over time, as world id has enough of a critical user base, applications that would want to leverage world id have more of an incentive because the user base is already large enough that they can target them and they can have resistance. So that's, for example, how we think about things when it comes to all of these other technologies. You have to have also some form of go to market strategy where you have some, because users are never going to care about the technology.
00:21:20.168 - 00:21:53.124, Speaker A: You have to have some use case, some actual product they want to use that is powered by these things, and it allows them to do something that weren't able to do with the traditional rails. That's the only way that you're actually going to get to mass adoption. So it's like multifault. You need to build products, better technology, better infrastructure, and then you actually need to convince thousands of people and thousands of businesses to actually move over, or you have to sell them this technology actually for it to be better. And you have to create some form of movement or some form of awareness around these things. The same with crypto. How did Ethereum get adopted? Just word of mouth, conviction.
00:21:53.124 - 00:22:15.454, Speaker A: People building use cases like Defi, NFts, etcetera, that actually made these technologies useful a lot of time, but it's the only thing that actually changes the world in a meaningful way over time. Cool. Anyone else? Okay, I think that's it. Okay, thank you very much. Take care.

00:00:00.680 - 00:00:35.684, Speaker A: Thank you so much for that introduction. Before I get started, can I just get a quick show of hands how many people are running a full node? Okay, yeah, we're doing pretty good, actually. Surprisingly enough. I think that the crowd here might be more tending towards running full nodes. I think the general, maybe users of Ethereum, probably less so. So you guys who are running full nodes probably don't need too much of an introduction of why we need to think about forgetting history. But for those of you who aren't running full nodes on a day to day basis, let me just give you a quick run through about why this is even a topic.
00:00:35.684 - 00:01:20.280, Speaker A: So today, if you take a look at what your chain database on your computer looks like for Go Ethereum, we're looking at about 761gb. This is on a freshly synced node from earlier this week. And if you run this on maybe your node at home today, that's been running for a little while, it might be a little bit larger. Post merge, we actually have to run two clients now. So not only do you have to store all of the information for your execution client, you need to store all the information for your consensus client, and that adds up to another 80 to 100gb. So in total, just to run an Ethereum node today, you need to be keeping track of 800gb to a terabyte of data. And this is kind of representative about how many nodes that we end up having on the actual network.
00:01:20.280 - 00:02:03.376, Speaker A: And so all of you that raise your hand, you kind of make up this amount, the 8600, which is kind of an order of magnitude, I think. I saw Leo's talk earlier from Codex, and he was saying that with their analysis, they've seen about 12,000 nodes in the network. So we're looking at around 10,000 people who are running Ethereum full nodes. And we would like that number to be so much bigger because the number of people who are interacting with Ethereum is in the hundreds of thousands, if not millions by now. And we would love for all of them to be able to run a full node and have this trust guarantee conferred upon them. And we generally have this hypothesis that the hardware require, as we were able to bring the hardware requirements down, we're able to increase the node count. And so that's kind of like why we're talking about how to remove the history from a client.
00:02:03.376 - 00:03:01.914, Speaker A: We want to take the hardware requirements down from maybe one or two terabytes solid state hard drive, to one day, maybe just your mobile phone, to be a full node on the Ethereum network. And so that's where we get this question that was raised a few years ago, like, maybe we don't have to have every single person store all of this information. Maybe we can have different mechanisms for storing the information and just have some of the, just have the users who are running full nodes validate blocks that are coming in. And that's represented in the Ethereum roadmap. So this is a diagram that Vitalik posted in December, I think, of last year, which was an updated one of some roadmap diagrams he's made in the past. And you can see now that actually two of the sections in the roadmap diagram are looking at how do we improve this situation with the unbounded growth of the Ethereum node? And you can see in this first one the verge. The goal of this is was talked about a lot in Guillaume's talk earlier today on vertical trees.
00:03:01.914 - 00:04:24.614, Speaker A: But we want to make it as simple and easy as possible to validate incoming blocks for the Ethereum network. And there's a lot of different mechanisms that do it. One of these things is verbal trees is a very important part, and hopefully one day we can just have a single snark that you receive over the Internet, run some mathematic computation on it, and then accept that latest block as the latest block of the Ethereum blockchain, without having to store hundreds of gigabytes in a huge state and do a lot of expensive computation. This talk is more focused on the purge, which is the aspect of looking at how can we reduce and remove the technical debt that exists in clients, and how can we try and bound how much data a client consumes on your local machine. And so I've circled this area, EIP, which is around EIP four four s, and this is kind of this original proposal about how do we actually go about deleting the history that exists in Ethereum. So this is like the motivation statement, then we need to think about, like, okay, how do we actually go about doing this? And to do that, we need to change our mindset about Ethereum. And I really like this analogy that I don't know if it was Vitalik or if Dancrad was the one who kind of initially came up with this, but we need to think about Ethereum more as a bulletin board rather than some sort of long term storage mechanism.
00:04:24.614 - 00:05:27.200, Speaker A: And the idea is that instead of relying on this for storage, we think about it as I publicly post some sort of announcement to this board, and I can have a very high guarantee that everybody who cares about Ethereum or cares about these announcements, was able to see that announcement, and that's the only guarantee that you get. And you can see this represented in some of the new proposals that are happening on Ethereum, things like EIP 4844. If you look at what the retention policy is for blobs on 4844, they're actually specified to just expire after about three months. So this is kind of where Ethereum is going. We're trying to think more about, trying to think more about being this bulletin board where you can post announcements, you can post updates to your roll ups and everybody can see them, but we won't make the guarantee that you'll always just be able to download that information from, from the Ethereum network. And so this kind of means that full validation starts to go away a little bit. And this talk isn't going to be super focused on full validation.
00:05:27.200 - 00:06:09.272, Speaker A: It's an important part. But because we moved to proof of stake last year, we've sort of given up a little bit on full validation in the first place because we have this new concept of weak subjectivity. And I implore you to go read about weak subjectivity if you're not super familiar. But basically you need to kind of come up with some recent checkpoint, some recent trusted checkpoint, kind of like a genesis in maybe the past three months or so to trust as the root of your chain. And so this makes it so that, okay, you can audit that full chain if you want to. And this is an important thing we always want to maintain, but it's a lot less important and useful. And the reality is that most people don't want to spend one and a half weeks fully syncing their node to audit all these chains.
00:06:09.272 - 00:07:12.632, Speaker A: The majority way that people come onto the network is to simply checkpoint sync their consensus client and then snap sync their execution clients to the latest state that exists. And finally, we need to bound the growth. This is an important goal, as you saw on the roadmaps of generally all of the things that can grow linearly in Ethereum. We want to bound so that whenever you start your Ethereum client, you have a really good idea about how much computation resources it's going to take, both for bandwidth in terms of network and in terms of your disk size. So this is the way that we wanted to think about it going forward. So before I talk about exactly the proposal for four four s and how we want to think about removing history, I want to make sure that we're on the same page about exactly what I talk about when I'm saying history, because I know that when I talk about this to people, even though it seems like we're on the same page, we end up kind of missing exactly what I mean by history and exactly how that compares to things like state. So the pieces of the history that I mean when I say we want to delete this stuff are specifically the consensus objects.
00:07:12.632 - 00:07:42.954, Speaker A: Things like headers, transactions, receipts, and omers. These are the actual objects that are committed to within the Ethereum protocol. And these are the things that we're trying to delete. What we're not trying to remove in this proposal are things related to the state. And in the state you have your accounts that stores your balance and your nonce, you have your storage, which stores all of the information related to your smart contracts. And then you have your smart contracts. And so these things part of the state, these are not part of the set of things we're looking to delete in this proposal.
00:07:42.954 - 00:08:47.408, Speaker A: And then one kind of overlooked aspect of the disk usage of your client is also the indexes. And in go Ethereum, we have this index which stores the transaction hash to the block number. And this sounds like a relatively lightweight thing, but in Ethereum, whenever you have hundreds of millions of transactions, this 40 byte value ends up adding up relatively quickly. And so today we've sort of created a bound where we by default, only store the information of that transaction hash to block for the last around one year. And so that's kind of bounded it to around 25 to 30gb. And we can see that if we actually look directly into, if we actually look directly into this output, this is an output of a geth sub command called Gethdbinspect. So if you're ever curious about what is the actual underlying data that's in your database, why is it so big? You can run this command and it takes 25, 30 minutes, depending on your hard drive, and it will actually spit out exactly, it'll spit out exactly how much data every aspect is using.
00:08:47.408 - 00:09:07.536, Speaker A: So we can look at this for history. History I've highlighted is green. This is exactly what we said, headers and bodies and receipts. And that in total is almost 500gb of data. That's just storing historical aspects of Ethereum. Then we have state. State takes up around 243gb.
00:09:07.536 - 00:09:41.150, Speaker A: That's your contract code, your account storage and your contract storage, and also the tri node. So we're storing this Merkle tree, and we not only have to keep track of the values, the leaves of the merkle tree, but we need to keep track of the intermediary nodes, that is another, it's hard to see here, 160gb or so. And then we have our indexes. And so like I said, this index for the transaction hash to block number, this is around 2025 28gb. And that one we are currently pruning. And so it's bound around 30gb. It's not going to increase.
00:09:41.150 - 00:10:11.762, Speaker A: And we would like to be able to do that for history as well. We would like to be able to say that whenever you start go Ethereum, the history for Go Ethereum is only going to sit around 100gb or 50gb or something like this. So this is what our goal is. By the way, the time says five minutes. Like do I only have five minutes or is it off? Okay, so for the state, the state is something we can't delete right now. We have proposals of improving the situation, but today, like the state, you have to have this to validate the block. We can't delete it.
00:10:11.762 - 00:10:32.790, Speaker A: This is extremely important. And so there's nothing that could be done. Hopefully one day we can have vertical trees to make it so that you can easily execute statelessly. But today you have to have the state history. We want to delete it. That's the goal. Unfortunately, we have this prerequisite and we want to have a robust way of retrieving that history forever.
00:10:32.790 - 00:11:20.938, Speaker A: And this is because we made this commitment early on for Ethereum that you would always be able to retrieve the history from your peers, the peer network of the Ethereum nodes, and to kind of walk back that commitment. This is not something that we take lightly. And so we're thinking really deeply about how can we move Ethereum forward and create these new guarantees that we want, where we are actually able to bound the amount of state without totally giving up on this commitment that we made, that the history is going to be retrievable. And we thought a bit about this. And so we have a few solutions. One, HTTP providers. This is extremely centralized, the simplest solution, but if you spread it out across many different providers, you start to have some resilience against people going offline or people trying to withhold data.
00:11:20.938 - 00:12:13.546, Speaker A: So in the future, hopefully that people like Infuria and Etherscan and universities and you know, maybe the Internet archive, they all are able to serve this historical Ethereum information whenever you desire it. We also want to use BitTorrent. BitTorrent is perfectly suited for sharing information this way, in this peer to peer fashion. And so it's a good compliment for having these HTTP providers that are known and centralized entities and then having a permissionless system where anybody who wants the data can go get it and share it in this peer to peer fashion. And then the portal network. And the portal network is a really exciting way of accessing historical information if you want to access it in a light manner. If you're a single user and you don't want to spend a lot of computational resources to participate, you can easily get a transaction or a historical block.
00:12:13.546 - 00:13:09.666, Speaker A: But if you want to access large batches of data, the portal network is not the best solution. You would want to directly download it via Bittorrent or HTTP or something else like that. Ok, that's how we hope to provide the data. Then the question is exactly how will this data look? And so this is this data format that I've been working on a fair bit, and I've also been working on it with Yasik from the Nimbus consensus layer team. And we've kind of come up with these two formats, one for the data that exists in ethereum before the merge, and one for the data in ethereum that exists after the merge. And the question is kind of like why separate these two things? And the main reason is that post merge you can kind of think about the consensus layer consuming the execution layer. And so it would be difficult to describe all of the information in the execution layer after the merge because it already exists within the consensus layer itself.
00:13:09.666 - 00:14:08.224, Speaker A: Because in a consensus layer block, in the beacon block, there's now the execution payload. So that actually includes everything that we need to both have the historical information for the consensus layer, the beacon chain, and the historical information for the execution layer. Also, post merge, the consensus layer has a really neat value in the beacon state called the historical roots. And the historical roots is a list of hashes, and each of those hashes represent 8192 beacon blocks. And every time you reach that threshold of you've gone through 8192 beacon blocks, then you create a historical batch and you merkelize that, and then you put it into the historical roots list. And the nice thing is that the error format follows along very closely with that. There are 8192 blocks in this era format, and given an error file and some beacon state that happens after the error file that you trust, you can actually verify the integrity of that error file.
00:14:08.224 - 00:14:50.206, Speaker A: So all of these things fit very nicely within the beacon chain and the way that the data is laid out in the consensus layer. So pre merge, we tried to follow along as closely as we could. So we've got this arrow one format, and it looks something like this and this arrow one format, instead of having historical roots that's dynamic and constantly growing, we have a static commitment. And the reason is that we're post merge. There's not going to be any more proof of work blocks that we care about. And so we can actually say these are all of the blocks that ever going to exist before that are ever going to exist in the pre merge world. And so we can actually say one commitment to match to all of those.
00:14:50.206 - 00:15:32.414, Speaker A: And it gives us this nice property that we didn't have pre merge before. If you wanted to prove something about a pre merge block, you would actually have to create a linear proof via the parent hash. So you would have some trusted block where you would say, this block right here is maybe I got from the block hash opcode. And so I trust its value. I want to prove something about a block. 10,000 blocks ago, you would have to provide 10,000 headers to recursively prove via the parent hash. Now with the error one format and this like static commitment, the static commitment is just that Merkel root over a list of blocks and you can create a logarithmic sized proof into that to prove that some block existed in the history from that static commitment.
00:15:32.414 - 00:16:44.512, Speaker A: So these are the two data formats that we've been working on, and now you're kind of like, okay, when, when can I delete this historical data? In my node, my 1 tb hard drive is running short on memory, and any day now I'm going to get kicked off the network because I cannot continue validating Ethereum. And so the progression so far has been 2021. We had EIP four, four four initially proposed, and 2022 we had Yasic working with the Nimbus team on the initial era format. Now in 2023, we've kind of come with this era one format, and together with both the era and the era one format, we finally have a full specification of all of the information that could exist in Ethereum. And we're trying now to think how can we prove out these retrieval mechanisms that we talked about? And so that's kind of the work that's going on now is we want to make it so that we're confident that the information is accessible by these retrieval mechanisms that we've proposed. And so hopefully 2024, we can finally start experimenting with pruning. And maybe the first thing that we do is just prune the data that exists pre merge.
00:16:44.512 - 00:17:22.830, Speaker A: And so that would be a good first step where we get to alleviate 300, 350gb of data that already existing clients, so I would upgrade to a two terabyte hard drive. We're not going to fit it within 1 tb right now, but it's something that's actively being worked on. That's it for my slides. I want to say thanks a lot for the organizers of ETH prog. It's been a fantastic event so far and I'm so excited to be a part of it and get to speak to you today. If you want to keep following along with the work on four four s, you can just take a look at the discussion link. If you go to the EIP's website and click go to four four s, you can read the Ethereum magicians discussion link.
00:17:22.830 - 00:18:00.484, Speaker A: That's kind of like where the latest information is being posted. If you want to follow along what's happening on Ethereum in general, not just four four s, then you can follow the ethereum PM repo. They post notes after the all core devs call and the consensus layer call. So it's a good way to quickly see what's being proposed for Ethereum and what kind of decisions are being made in terms of actually changing the core protocol. And then if you're interested in actually getting involved, you can join the Etherid discord. We talk about this stuff in the history expiry channel, and if this talk was interesting to you and you're interested in core development in general, I would take a look at the Ethereum protocol fellowship applications are due June 19. You can find this if you go to blog dot ethereum.org
00:18:00.484 - 00:18:17.244, Speaker A: or if you just Google Ethereum protocol fellowship. It's run by Mario Havel. I think he maybe gave a talk yesterday about it. It's a fantastic program. We have lots of core devs who are mentors in it, and we're seeing a lot of people who are coming through it, like actually making it into the core development space. Yep. Thanks a lot guys.
00:18:25.104 - 00:18:35.144, Speaker B: Thank you Klein for the insightful talk. We're slightly tired of time, so apologies to the audience. No room for question, but feel free to connect with speaker off the stage. Thank you.

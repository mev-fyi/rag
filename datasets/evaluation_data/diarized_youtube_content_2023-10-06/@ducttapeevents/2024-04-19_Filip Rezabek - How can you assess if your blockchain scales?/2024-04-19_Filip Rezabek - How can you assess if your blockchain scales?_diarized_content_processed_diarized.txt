00:00:00.600 - 00:00:59.712, Speaker A: Great. Hello everyone, my name is Philippe and I'll be today presenting to you our latest research regarding how can you access if your blockchain scales? So firstly, briefly, a few things about me as I was introduced. I'm a PhD student at the chair of network architectures and services. Overall, the chair expertise is going for a couple of decades already, where the main focus is on the aspects of protocol design, active passive network experiments and network security. With today's focus of the talk, I am looking into the aspects of distributed ledgers, technologies and blockchain, mainly focusing on application performance and evaluation, and also want to touch upon some aspects when it comes to the design of privacy preserving network systems. So without further ado, let's start a bit with the motivation. So as you all know, there's currently a lot of discussions regarding increasing the scalability of Ethereum, but of course it comes with a lot of additional research that we have heard throughout the run over the weekend, touching on many, many aspects.
00:00:59.712 - 00:02:43.394, Speaker A: From the perspective of our research, we are interested in the parts on ok, we see that the block size is increasing, but of course how does this behavior affect the validators? Because suddenly they have much more data, they have to process, they have to evaluate much more data within the same period of time because the consensus itself will not be really changing when it comes to the slot finality. Are the hardware specification of corresponding peers still sufficient or do we actually have to increase the hardware specification? How does it also affect the peer to peer network? Because of course, as we all know, if we have to send around more data, it means that all of the peers in the network has to have better connectivity. Do we even have to optimize the peer to peer network and other aspects when it comes to network throughput and many, many others? Of course, as you all know, there is a lot of discussions regarding all of these aspects, but what we want to do and look into is finding a way on how to actually assess these individual parts in a reproducible fashion, which I'll be talking about a bit more in detail. So in addition to that not only focusing on ethereum ecosystem, but general layer one and L2 solutions, there is a lot of noise going around with respect to marketing on how performant is your system with respect to TPS latency finality. And here you can see different values taken at who knows when for whatever period of time that later on can be sometimes summarized and put into a table, tweeted, put on a Twitter, and basically the information that is such table providing cannot be very easily verified and be fully trusted. In addition, we of course see a lot of new use cases. We covered a lot of interesting aspects when it comes to encrypting mapus, private compute, and many, many others.
00:02:43.394 - 00:03:39.120, Speaker A: That I think is definitely something that we always have to keep in mind that the blockchain never sleeps. Which basically brings me to this third point. There are many parameters when it comes to designing your corresponding blockchain and operating it, and there are also regular updates that you have to take into consideration. So always you have to have a way on actually how to assess if you introduce certain change into your system. Is the system actually going to perform the way you expect and how can you be able to, to verify it? And for that, we are introducing our structured approach that I will be covering in the second half of the talk, where we want to have a way on how to actually assess the capabilities of various blockchain solutions. Look into the individual layers of the stack in a reproducible fashion. What does it mean reproducible? So let's say if I run the experiments today, but also in a week or in a month, I should ideally be able to run the experiment, the round experiment, with the same outcomes.
00:03:39.120 - 00:04:56.760, Speaker A: And not only us in our controlled environment, but also ideally the people in the community should be able to verify that, okay, if you run it under the same conditions, we are actually able to achieve the same findings as the previous groups with respect to it. We also want to compare different architectures, right? Because as we know, there is, for example, a lot of L2 solutions, but they vary. So the aspect is actually how to find a good and stable way to actually be able to also compare them in a fair way, in a sense that you actually know when it comes to assessing such different systems, how these architectures compares and most likely collected insights. Why is it like that? And can the corresponding architecture will also improve in the future and find overall the common ground when it comes to having the base, basically, which you can later on work with and try to increase the state of the art when it comes to the future technologies. And for that, we are mainly focusing on the aspects of deployment, various systems in our local environment, where we can emulate realistic behavior that we can see from the actual real systems that are running out there. We can collect all of the data and be able to collect interesting insights when it comes to empirical studies of such systems. As we all know, blockchains are not coming out of thin air.
00:04:56.760 - 00:05:41.104, Speaker A: They're building on top of the Internet infrastructure, because all of the individual peers have to be able to communicate to each other. This is basically the corresponding blockchain stack, as I believe many of you are familiar with. We have the aspects of the peer to peer network where of course all of the peers have to talk to each other in order to disseminate data and collect interesting insights. We know that of course part of this communication on the peer to peer layer is the main focus is to share the transactions. Of course later on the blocks share the votes and other aspects. So of course this is something that you have to be taking into consideration on how scalable is your corresponding system. Later, of course, on the contentious layer you are agreeing, okay, this is the corresponding view we have, and we are getting confidence into the corresponding state over time.
00:05:41.104 - 00:06:48.188, Speaker A: And of course for most of the interesting aspects, you actually want to be able to deploy your application into the system. You end up usually paying some fees for that. And also of course the users interacting with the system also end up paying certain fees. And you want to know maybe in advance, actually how efficient is your deployed smart contract? How efficient is not only from the side of the user perspective, but also from the side of the core developer, actually, how efficient is my virtual machine that is actually executing the smart contract? And is there something that I can do to improve the performance of the virtual machine itself? Or again in the aspect of okay, if I want to actually add additional features to the system, what does it actually mean for the corresponding validators that at the end are later running the virtual machine where all of the stuff have to be verified and validated? And of course at the end we have the user clients that are basically relying on all of these aspects of the blockchain stack as an infrastructure. Just a brief refresher when it comes to scalability. In general domain, two separations is between horizontal scaling and vertical scaling. So with the horizontal scaling we are basically just adding more nodes.
00:06:48.188 - 00:07:44.084, Speaker A: And in ideal case, we would of course like to see that the performance of the system gets better. As we all know, it's not usually the case. It's rather actually we are currently happy that the system performance doesn't get worse. But this is, I think, something that is also coming down to the individual interaction of the individual layers on the blockchain stack and down. There is a lot of discussion with respect to vertical scaling when it comes to ZK rollups, that basically if you add more resources it's possible to create the proofs faster and you can actually ensure that the system can be scaling in this direction for that. Basically it's something that we always have to keep in mind when we are evaluating various systems if we are focusing on vertical or horizontal scaling. But of course, ideally we want to collect insights from both of these aspects to at least see, okay, if we add ten additional nodes, 100 additional nodes, or 1000 additional nodes, the system performance still doesn't deteriorate and stays as expected.
00:07:44.084 - 00:08:26.450, Speaker A: So considering a simple scenario that we want to briefly look into, we have to, of course we have our peer to peer network. You can have a look at it here. In this case, we have interconnected peers that basically are interacting with the corresponding chain. Of course some of them are either having the full, are basically operating as a full node. They have the whole copy of the blockchain. Some of them only maybe are relying on third party that basically is having the full copy of blockchain in order to interact with it. Of course when we are interacting with it, we can send the transactions, the blocks, and in general, of course we expect that our messages will be propagating through the system.
00:08:26.450 - 00:09:54.008, Speaker A: We of course for that have to accommodate for the part that each peer that actually sees the message and does some activity and forwards the message farther has to actually ensure that it has the right hardware specification in order to be able to do so. For that, as you know, there are always usually provided by the corresponding foundation, the minimum requirements in order to run a node. But sometimes it's a little bit unclear how did we actually get to these hardware specification? Is there a clear structure, is there a way on actually making sure that if I run my node it will actually be working properly? Does it apply only to the cpu assumptions, the RAM amount that I have? Or do we also have to consider some aspects of, for example, SSD's with respect to I o? And all of these parts basically have to be verified. And of course, more importantly, considering that the system always keeps evolving, we have to keep in mind that maybe in the future these hardware specifications will be different. There's also a lot of activities on the peer to peer network, right? Because of course we want to make sure that we are not just having, let's say some naive start topology where we exchange all of the information over a single hop that later on basically can pose as a single point of failure. So we want to have a robust peer to peer network where all of the peers can exchange the data in such a fashion using some go see protocol or some other form of unstructured or structured network algorithms. And of course we have to consider a different type of transaction.
00:09:54.008 - 00:11:22.814, Speaker A: Of course someone wants to maybe just send a typical, easy, simplest transaction. But if we consider some aspects of more complex smart contract deployments, we have to be able to handle those as well, because of course it's again, something that has to fit into the block, has to be verified and validated by the corresponding peers, and we have to be able to see if it actually is possible. And of course, a lot of discussion goes into not only keeping, let's say, the typical flow of execution and the lifecycle of the transaction, but in addition, we are adding new features, features when it comes to implementation and usage of single multi party computation, threshold cryptography, zero knowledge proofs and many, many others have to be taken into account. And other aspect is the infrastructure layer, where of course certain types of peers in the system can also provide additional types of security guarantees, using, for example, some form of hardware acceleration that of course can overall improve the system performance itself. As you can see, the scope of actually being able to assess if your blockchain scale is quite large, because it's not only a matter of a single node, a single peer. Of course you can still collect some insights from that, but you have to consider the whole deployment and all of the individual protocols that are in the system. And most importantly try to collect the information about how these individual layers interact with each other and what type of guarantees each of this corresponding layer can provide.
00:11:22.814 - 00:12:41.318, Speaker A: Touching a bit on our evaluation methodology. So basically what we want to do is we want to bring the system on the left where, let's say, talking about Ethereum, we have around six to maybe 10,000 physical peers running in the system, and we want to somehow map it to our local environment in order to be able to actually collect comparable insights in order to do so. Here on the right is just like a simplified topology of our local testbed environment, where basically we want to emulate the globally distributed blockchain networks. We want to have the options to configure various configuration parameters for the corresponding blockchain. And of course we have to consider that the system might be able to interact with other other systems as well. So for example, in case we want to deploy l two solution, we of course have to also deploy the l one solution in order to basically have the full fledged flow of interactions and guarantees offered by the corresponding l one and l two in order to collect good insights and see the overall performance of the system in such a scenario as well. When it comes to the decision, we of course could consider deploying our experiments also in cloud.
00:12:41.318 - 00:14:10.046, Speaker A: So this is actually something that we are looking into and I want to integrate it into our framework, but so far we are mainly focusing on the local deployment, where of course when it comes to local deployment, in comparison to cloud, or even using something like Testnet, you actually have much more sophisticated level of control over your system. You can play around with various parameters, you can modify the hardware specification of your corresponding peers. So let's say, going back to the figure, a single node here, maybe as it is by itself, maybe has around 64 or 128gb of ram, can be even more than that. It can maybe have around 64 virtual cpu's. It can also have very good connectivity. So as you can see, we have maybe 25 gigabit links to connect all of the individual peers, or even 100 gigabit links is of course something that we don't see early in the main end deployments, right? So we want to have a granular control on actually how to lower the specification of the individual hardware nodes using maybe some form of lightweight virtualization, and also have a granular control over the corresponding hardware stack to collect and reproduce and emulate the right state as we can see on the mainnet. And of course in combination with cloud, this could provide also interesting insights coming I would say closer to the realism aspect, because of course many of the nodes running out there are actually running in cloud deployments.
00:14:10.046 - 00:14:46.550, Speaker A: And it's also interesting to see how the cloud itself behaves and what type of individual noise it can introduce. When it comes to experiment design. Of course this is something that is important to spend a lot of time on, because if you just deploy the stuff without knowing what is the target and what type of insights you want to collect, it's a bit challenging to be able to do so. So usually you want to think of some theoretical assessment. What does it mean, theoretical assessment? It can go very deep. Depending on how much time you have. You can of course try to understand how the individual building blocks behave.
00:14:46.550 - 00:16:09.420, Speaker A: So for example, talking about ethereum, you want to understand how the content behaves, you want to understand what are the gas limits when it comes to block sizes, or actually what are the corresponding block sizes themselves. You want to later be able to model and understand, let's say the peer to peer network. Okay, if I send a transaction on either mainnet to how many peers the message gets sent to, and understand all of these individual integrity details of the corresponding protocol in order to actually design the experiments properly and later on collect valuable insights. So general separation, you can of course also split between micro benchmarking, let's say from the view of a single peer or macro benchmarking, considering basically the full fledged deployed l one in your controlled environment. And you can also of course try to play around in the form of black box or white box testing, where the main difference is that considering that we actually have the access to the code, because most of the code is open source, which is really great to collect insights, we can also modify the code for our particular experiments. But ideally due to the complexity and the way how often new versions are introduced, we rather want to take it like a black box without any need to modify the code itself and just observe the performance using external metrics and parameters. And of course touching on that, we can collect many, many metrics from the system that we can measure.
00:16:09.420 - 00:17:14.004, Speaker A: We can of course consider throughput, like when it comes to transactions per second, various types of latencies that can affect the user's experience in the corresponding system. It can also be aspect of finality, actually when the corresponding block is final and cannot be changed later on. We can of course try to play around with various hardware specifications of the individual peers to see and collect the insights about that. And of course when it comes to the parameters, we can be adding higher number of peers to the system. We can also modify the block sizes to for example, assess okay, in case ethereum in the future will have box size of 30 megabytes. How does it actually affect the performance? And try to also emulate some fault injection, because of course we want to always verify if the guarantees offered by the consensus when it comes to the byzantine fault, Lorenz is also present in the form of our environment and how the system behaves under such conditions as well. So for that, briefly touching on the design, I will just skip through it briefly.
00:17:14.004 - 00:18:40.386, Speaker A: We of course have the input where in general the idea is that you define your experiments that you later on deploy, you have your system under the test. So again, following the examples that will be, let's say your l one ethereum with maybe 300 deployed nodes that will have different amount of hardware, specific hardware allocated to the individual validator, basically going also in the heterogeneous direction of how much different providers can be out there, right? And you basically start to issue the transactions to the system and you're measuring the individual insights when it comes to the corresponding metrics that you have defined as a part of your experiment. Briefly touching here on some of the subset of supported features we actually have in our framework in our testbed. So we are quite heavily looking into trusted execution environments. We also have quite a several threshold cryptography schemes that are currently supported and that can be used and to interact with the system. We are also looking a bit together with my colleagues from the technical reserve Munich into MeV. So for that we of course want to have the full flow of ethereum deployment in our local testbed and while collecting also insights from the mainnet, actually try to emulate some form of bidding wars and see how actually the level latency, for example, can affect such bidding wars on the mainnet.
00:18:40.386 - 00:19:44.982, Speaker A: We of course want to measure different types of delays for Ethereum when it comes to the aspects of interaction with the individual clients, and we also want to, for example, modify the hardware specs. So overall this subset of the feature was also important for us to actually validate that our approach to design such a framework is viable and it can be done. Even though it takes a lot of time to actually do so and onboard new solutions into the framework, it's possible to do it and we now, I think have quite a decent way on how to assess if your blockchain scales touching on the takeaways already. Basically the main aspect is always onboarding new systems takes quite a lot of effort because each system is slightly different. But I think this is the part that is also fun because you keep learning along the way on how each system performs and behaves. We would like to in the future find a possible unification and evaluation guidelines that the community can use and possibly extend in the future to have basically a fixed baseline. Maybe also help the definition of the workloads.
00:19:44.982 - 00:20:18.784, Speaker A: And overall we believe that this is a good stepping stone towards collecting holistic overview on the interaction of the individual layers that are part of such complex systems like blockchains. In case you are interested, we also have it available as an open source. We of course have some of the latest updates still available only for us, so usually we update our public repository once we have also academic publications available. But in case you are interested to find out more, I think it already provides good insights and references to our publications and as always, happy to connect. Thank you very much.
00:20:23.334 - 00:20:37.394, Speaker B: P thank you. Very interesting presentation. Unfortunately we don't have time for a Q and A, but you can ask him any questions during the coffee break and the next session will start at 225.
00:20:37.734 - 00:20:38.174, Speaker A: Thank you.

00:00:00.200 - 00:00:17.874, Speaker A: Thank you for the warm introduction. So welcome. We're going to talk about acres today. Don't worry, I will not dance. This doesn't work. So I'll just click on the laptop. Maybe somebody can check.
00:00:17.874 - 00:00:53.660, Speaker A: So, as I mentioned before, I'm not going to dance. Don't worry. But the title is dancing with Moore's law. We're going to look at Moore's law from different angles, and I'm going to outline why this law is important for us as a society, as an economic system, and also for us especially as a project. Gordon Moore is a very famous computer scientist. He was a co founder of intel. And he said more or less that the number of transistors on a microchip would double approximately every three years, while the cost would halven.
00:00:53.660 - 00:01:50.254, Speaker A: So some of you guys probably know about this law and you never think about it, but it's actually the defining thing when you look at economic development around the world, because it enabled everything to scale up, from small businesses to the Internet itself. So it's quite fundamental looking at it this way, especially from all these wafer chips, silicones that always became smaller and more efficient. But we just looked at the performance mainly with Moore's law, and it sort of hits a boundary right now with physics. So miniaturizing all these chips further, it becomes harder and harder. And we're sort of stuck there right now, at least it seems. So maybe there will be some breakthrough there. But I think we're reaching some limitations also, the industry is sort of agreeing on that, so it's not me perpetrating this information.
00:01:50.254 - 00:02:39.008, Speaker A: So what's another perspective to look at things when it comes to the performance of compute? Essentially, we can look at performance per watt, which means that we don't just look at the pure horsepower, but we look at how efficient is it compared to how much electricity consumption we use. And this is quite important. If we look at the industry at large, we can see that there's a lot of cost pressure everywhere. That's why we have these layoffs, maybe. And also there's a lot of pressure, ecologically speaking, from the environment. We don't want to use that many resources anymore. We want to reuse stuff, we want to upcycle stuff and be more aware of that.
00:02:39.008 - 00:03:38.454, Speaker A: So opex, as I mentioned, is one of these important things. We can, and we want to significantly decrease them. And the ecological aspect, so decarbonization, also a huge and important topic at large. Now, painting our problem that we tackle directly as acurist and also many of the blockchain projects tackle is that we have this issue of 66% of the global cloud market that is very centralized. And if we look at this from a consensus perspective, that would be very bad, right? So we're already afraid of 33% with Lido, and here we're talking double that. So it's quite insane. And if you would look at all the subsidiaries and the dependencies that we have of other resellers, et cetera, I think this number is not even close to what it's really like.
00:03:38.454 - 00:04:12.414, Speaker A: What's the like? What's the effect of this centralization? So we have monopolistic pricing, we just accept it, right? If prices go up, prices go down, we have arbitrary charges. We have to check really carefully what's going on in our accounts. We have a lock in situation. Of course, from an economic perspective, if I'm an ecosystem by now, I want to lock in users. So this is what we learn at university. This is very good, because then we can extract more customer rent. So it's good for a company.
00:04:12.414 - 00:05:03.392, Speaker A: But if it's like in a monopolistic scale, this is a problem. And the second thing that I'm very passionate about is the data ownership confidentiality. So if you want to run something confidentially, you essentially are forced to set up your own data center with your own hsms. I talked to a lot of builders yesterday as well. They do that because there's no other option, because if they run it on AWS or GCP with an HSM, there is a lot of trust involved in the provider and verifying that it's done the way it should be done. I mean, that's essentially impossible unless you buy the data center yourself, which is also possible, of course, but then you need to be heavily funded. So ownership is a problem as well.
00:05:03.392 - 00:05:43.352, Speaker A: And confidentiality, not just from data address, but also data that is being computed on then accessibility. Some regions of the world they are not able to access, for example, cloud providers without the credit card. I know there's workarounds, but there's always like these arbitrageurs that sell resell for crypto, certain cloud instances. But then you have essentially no control over that instance. So that's not really feasible. You have censorship at play. These 66% decide to do a, then it will happen.
00:05:43.352 - 00:06:33.624, Speaker A: So of course we're also talking about nation states here, for example, the US centric organizations that really have a lot to say, let's put it this way. How can we change that? Our approach is that we want to leverage mobile devices because we realized it's a huge untapped opportunity. A because mobile hardware really excels and surpasses server hardware on many aspects. It's made to be run 24 7365. They have highly efficient processors, and we know from chip producers directly that in mobile phones they always use the most bleeding edge technology first. So you're always ahead of the servers. Always.
00:06:33.624 - 00:07:16.526, Speaker A: Of course, it depends on what kind of device you use. You cannot just use a ten year old Android phone. You can for certain computation, but not for maybe highly sensitive stuff. And additionally we have these special purpose chips. Probably you are all aware that you have these tpus inside, or you're not tpus and secure elements and secure enclaves, or however provider calls them outwards, and they're really optimized for the compute they execute. So this is the opportunity that we realized. Now I'm taking a step back, and since we're an ethereum conference, I guess some of you people realize what this is.
00:07:16.526 - 00:08:00.542, Speaker A: It's the blockchain dilemma, popularized by Vitalik. Don't remember the year, so you, he sort of said we can optimize for two, but optimizing for all three is really hard. Hence all the other developments. Right, we have all these L2s and CK rollups, etcetera happening, but recent research shows. So glad you're referencing this later, I forgot the reference directly. But we're extending this by adding confidentiality, because lots of problems arise without this confidentiality. Of course the naysayers are going to say, yeah, everybody's using it for money laundering.
00:08:00.542 - 00:09:09.222, Speaker A: No, we're talking about just basic privacy needs and confidential computing needs. I mean, not everyone needs to see what you're computing on. And the second thing is the effectiveness of that computation. Not every node needs to execute everything, right? So this is also an issue not just in ethereum, just in the blockchain space at large, and the efficiency of the hardware that is being underneath. So the infrastructure layer is also not really being looked at, and hence that centralization in the cloud providers. If you go look at certain big projects that have certain validator structures, everything is run in one data center, because it just doesn't work any other way. So how can we achieve then permissionless confidentiality, which I just mentioned right now, we can use most of these newer devices, they have these coprocessors, they're called so these dedicated chips, and we can, from within these chips, we can bootstrap a trusted execution environment, the trust execution environment term, I'm just using it loosely here.
00:09:09.222 - 00:09:51.064, Speaker A: I'm not going to elaborate on the terminology, but this is more or less what we do because we leverage the hardware directly and not just virtualization. And through that we can actually have it by design. So we have physically separated dedicated chips on these devices. We can verify it was that chip that executed this code at this point in time. And if something is not verifiable anymore, we can just retract and the device will not be used anymore with no leakage of any data. And we have cryptographically signed results. So this is like the why we addressed this from that perspective.
00:09:51.064 - 00:10:17.314, Speaker A: And now we're looking at some numbers since I claimed. Now let's put some proof there. As you can see, we're comparing a power edge server to a pixel seven a. The acquisition cost is like six times lower for a new device. So if you go for an old device, it's even less. Then look at the next number. CPU mark, which is like average benchmarking test for CPU's.
00:10:17.314 - 00:11:07.286, Speaker A: Even the phone is outperforming the server, which is insane. And then this is my favorite part over there. The 83 times is when you look at TPU and GPU performance, I think GPU is 50 times and TPU is 83 times. So if you have machine learning tasks, you can outperform a server by 50 to 80 in terms of factors and then in terms of cost. Also you can cut cost by 50 times because of that performance per watt that I mentioned before. Since we're highlighting more the efficiency with different architectures there, you can save a lot of cost and also energy. And you're not using hardware that was built for a specific server.
00:11:07.286 - 00:11:31.134, Speaker A: You don't need to build new hardware. You can even use old hardware. So yes, the G, I don't know why it's flowing down there. It should be up there. We can upcycle devices, so old broken device, we can take screens out of broken phones, exchange them. As long as the motherboard and the chips work. It doesn't even need to have a working battery unless you want to have it as a fallback mechanism.
00:11:31.134 - 00:12:14.538, Speaker A: And then comparing that, we have just $25. So we have it even cheaper. Depending on your supply chain. You can get it cheaper most likely, and also depending on the specific motherboard you look for. Now, we did some evaluations because we wanted to know, okay, this is all fine and nice, but is it really faster? So is it really worth it? Do all these theoretical calculations also translate to real world performance? Yes, they actually do. So we compared cloud function providers directly. So this was not just a one time run this were multiple hundreds of runs.
00:12:14.538 - 00:12:50.726, Speaker A: This is also under submission right now. It will be, I can hopefully publish this in a few days because of these great double blind processes. So we have, sorry, we have here acrist really outperforming in pure execution time. So this is without any latency. Of course if you would add latency, you have some more variance in the results, but at the end of the day it's still faster. So pure execution time of deceive of eratosthenes. So some nerd prime number developers here might know what it is.
00:12:50.726 - 00:13:46.744, Speaker A: If you ever played with some prime number generation, we did this up to 50 million times, and we also had to limit it at 50 million because some cloud functions would just not return after 75 or 100 million prime numbers. So there's also some limitations there here. Yeah, hopefully we'll put this out soon. What I'm also excited about is that we have true decentralization. That's one thing that was talked about at some point in this space, but sort of it got lost. Always when there's a bull market, I believe there's people forget about decentralization and everything is going into certain other directions. But with acrist we can actually achieve true decentralization because we have resilience in a heterogeneous mass of devices.
00:13:46.744 - 00:14:25.382, Speaker A: So we don't have not even one cloud provider with maybe ten different server configurations, but we have literally thousands of different phones. And that's pretty per se a harder attack surface because you hardly can write an exploit for, I don't know, anything. Right. You need to have some target group. So this makes it less prone as a single point of failure and denial of service risk. We support most Android devices. If you ever developed something on mobile, you know how cursed that is.
00:14:25.382 - 00:15:19.366, Speaker A: So there's so many Android devices, so many configurations, and so many like I learn every day of new devices. I didn't even know they exist, to be honest. On iOS that's a bit simpler, but also you're much more constrained. So Android actually was the perfect platform to sort of lock down a device and dedicate it to the network, whereas in iOS this is harder, but we're working on that as well. And we have true physical decentralization because we don't have just, we're not constrained to data centers, but we can actually have people building farms or just leaving them somewhere connected to 5G or Starlink or Wifi or even directly to Ethernet with a USB C port. Right? So there's a lot of possibility to actually scale this massively as of now we cover every continent. We have around 3000 devices.
00:15:19.366 - 00:15:52.956, Speaker A: Heart beating regularly. I did a talk one month ago and it was just 2000 roughly. So as you can see the growth is going strong and it's very easy onboarding. You scan a QR code, APK is being put on the device and you move on with your life. I'm going to finish on this note. I mean this statement you can do for anything, literally. But why Deepin? So more or less deepin came and we were like, oh, we realized, damn.
00:15:52.956 - 00:16:35.022, Speaker A: We are actually a deep end project. So why is it important to me? I just want to paint this very clearly because, you know, and you want to know that bottom up, the infrastructure is decentralized and you know, the keys are stored safely. It doesn't really matter what you do. At the end of the day that's crucial, right? If you don't have that down, then there's always some possibility of a detrimental failure to your network, etcetera. All right, just short picture of some farms. So people are farming our testnet token. As you can see, numbers are growing and short.
00:16:35.022 - 00:16:41.384, Speaker A: Call to action. Join the mobile cloud revolution. Thanks.
00:16:45.764 - 00:16:50.544, Speaker B: Thank you so much. Doctor Christian Kilner. Do we have any questions in the audience?
00:16:58.524 - 00:17:34.674, Speaker C: Great talk. I really liked how you added the fourth dimension to the trilemma. So I have two questions. To measure efficiency, pure physics is somehow output over input. So what would you consider the right count? Like a transaction count in blockchain can mean various things because to claim that there is a higher efficiency you somehow have to have output of transactions in the numerator and kilowatt hours produced consumed in a denumerator.
00:17:35.654 - 00:17:36.366, Speaker A: Yeah.
00:17:36.510 - 00:17:44.910, Speaker C: Second question, maybe on decentralization, I don't know if you use something like some networks use like a Nakamoto coefficient.
00:17:45.102 - 00:17:46.134, Speaker A: I didn't get that, sorry.
00:17:46.174 - 00:18:34.264, Speaker C: What, what measure would you use to calculate level of decentralization? Like some networks use something like Nakamoto coefficient. But my question is rather to. You made a point. Decentralization geographically, would you also not need to be decentralized by counterparty? If someone believes in your business, which I do, and secretly buys lots of secondhand phones, and you realize that you have a nice geographical decentralization, but it's actually Jeff Bezos who's been buying up all the old phones. So most networks you look at data center decentralization, counterparty decentralization and geographical decentralization. I'm just wondering how you would also consider all three.
00:18:34.384 - 00:18:46.056, Speaker A: Wow. Very, very structured and. Good question. Thanks. So for the first one, maybe I didn't make that clear. I definitely didn't make it clear. So the phones are used not for the consensus layer but for the execution layer.
00:18:46.056 - 00:19:29.254, Speaker A: So in there you can for example run v eight JavaScript code and whatever you do in there is by definition more efficient because you used the mobile device. Right. So that's our efficiency measure, I would say for that in terms of the blockchain layer, we use it for the matching of these jobs to the processors, which are the devices. So we have like a demand side, which is developers or people that want to run code, and the supply side which are the phones. So they provide the execution layer off chain. And of course you can do an oracle job on demand in these devices. That's sort of the architecture very easily explained.
00:19:29.254 - 00:20:18.014, Speaker A: I guess this answers the first question, because you were going towards efficiency of blockchain transactions, right? Okay, so there's not really a limit there because you just do the matching of the jobs on chain and that works quite well. And the second thing about decentralization, I completely agree and I think on buying somebody, buying a lot of phones per se is not a problem because the person cannot really tamper with the trust execution environment. And that's a security and trust assumption that we have depending on the device. So these bleeding edge new, for example, Google Pixel devices, they have huge bug bounties, and so far nobody has managed to, to get in. Of course that's the assumption. Right. So I would say that's the thing.
00:20:18.014 - 00:20:42.706, Speaker A: And also if you provide compute to the network, you still supported the growth of it because you participate in that permissionless manner. So I think that's not a huge threat per se. And the last question, I don't, can you help me with that? What was that about counterparty decentralization? Right.
00:20:42.890 - 00:21:10.326, Speaker C: I think you answered it. So what I would mean with counterparty, we run a network, actually Internet computer. And so to become a node provider you need to self identify yourself, right. And then you also, that is the counterparty one. And then you need to certify which data center you will place it in. And we obviously know which region you are in, but the counterparty is the person physically buying and owning the hardware. And you basically want to know that.
00:21:10.326 - 00:21:36.986, Speaker C: What is the probability of a number x reaching 51% control of your hardware? So that's, we mean it's a real person or entity, whoever someone needs to buy. It's a great case that you make, you make a very strong pitch that we need to rethink the type of hardware our hardware costs about $15,000 for one rack, and so six of them, you're $100,000. So it's a real person with real money writing a check.
00:21:37.170 - 00:22:02.790, Speaker A: Exactly. Okay. To that maybe the last thing. This is just a protocol and it enables everybody to also make direct deals. You can even disable the cost for your processor. And I can make off chain deals with you because I can whitelist you on the demand side as a process. Like you want to run code, whitelist your wallet and you can even pay me off chain.
00:22:02.790 - 00:22:37.844, Speaker A: You don't even need to use our protocol. You can just use the software to directly execute code. And this is exactly what projects do. They buy phones and then they run oracles on them directly without really using the token mechanism for a permissionless way. Of course you can do that, but then it's like a public cloud case, right? So I think this sort of solves that problem directly. For example, somebody in Kenya could buy 100 phones and provide like his community with compute. So thanks.
00:22:40.704 - 00:22:42.244, Speaker B: We have one more question.
00:22:43.904 - 00:22:44.804, Speaker A: Thank you.
00:22:45.184 - 00:22:58.930, Speaker D: You talked a little bit about performance and you said like, latency is also one of the things that is important. Important. I wanted to ask if you can expand on that and if there are any other performance related metrics that you thought about or you're kind of thinking.
00:22:58.962 - 00:23:39.388, Speaker A: About like now we did just this prime number generation, but we are now building like a benchmarking that is more testing different things on different servers. We also just did it locally just as a benchmark comparison. And it's like a couple hundred milliseconds less than if you run it on a processor. So there's this part of the equation and also about the latency. You can also optimize this. The larger the network grows, you can choose devices that are closer. So we're also thinking about how to add that in a way that makes sense.
00:23:39.388 - 00:23:57.324, Speaker A: Where is the processor, how close is it? And it's actually quite easy to evaluate this through just latency measurements. Right. So, yeah, I don't know if that answers the question. This is not like a final benchmark evaluation. We're still going forward there, but it's like first step.
00:24:00.104 - 00:24:03.664, Speaker B: Thank you so much. Thank you so much, Doctor Killer, thanks to the audience.

00:05:49.154 - 00:06:24.606, Speaker A: Good morning, everyone. I am Carlos. I am thankful for your presence here and we are going to start the presentations of today. And the title of this presentation that we are going to have right now is using threshold, ECDSA and Peskys as the foundation for browser based wallets. The presenter is Mister Andronikos. Andronikos is an entrepreneurial technologist who is currently a senior engineering manager at Dfinity foundation. He is leading the front facing themes for the Internet computer, including the Internet identity and OEC wallet teams.
00:06:24.606 - 00:06:48.844, Speaker A: Andrew Nichols, thank you very much for your presence here and the stage is yours. Thank you. Well, the morning slot is mine. Thank you all for coming. Yeah, it's hard to be here in 10:00 a.m. And I'll try not to. Well, I'll try to keep you awake.
00:06:48.844 - 00:07:30.854, Speaker A: So I want to talk about web wallets, or you might have heard of web wallets as well, particularly self custody web wallets. You might have heard of them as smart account wallets or account abstraction wallets. So before I start any show of hands, anyone here that has used at least once self custody web wallet or an account abstraction wallet? Two, three, four. Nice. Okay, five. And anyone here that uses account abstraction wallets regularly? Good. Okay.
00:07:30.854 - 00:08:50.756, Speaker A: All right, so I like web wallets. So before we proceed, let's do a brief taxonomy of wallets. Right? So typically users, they have to choose between user experience. Okay, so before that, like the fundamental as a wallet builder or as a wallet user, you have a choice to make, and the choice is really where the private key is going to be stored. So what we're facing is that we have, we can choose between a good user experience, for example, on the left hand side, where your private keys are going to be owned by an institution. And you have Kraken Coinbase fire blocks, and with good user experience, on the right hand side, you have your user self custodial wallets, metamask, Exodus, the Coinbase wallet argent. You can make a case that argent should really be at the center.
00:08:50.756 - 00:09:39.304, Speaker A: And here, what you are faced with as a user is that you have to download something. You have to download an app on your desktop, you have to download a mobile app. And so the user experience suffers. And I'll go more into it in later slides. Right, so this has been the situation up until maybe ten months ago or like a year ago, and then account abstraction EIP 4337 came into being and the situation has changed. So now in Ethereum, there is a rapid pace of development on web wallets and we are in the middle category now where we have the users no longer have to choose. You can get great security and great UX.
00:09:39.304 - 00:10:33.128, Speaker A: So we have already in twelve months, we have a lot of choice. We have wallets like Umbire, like Dymo, like Sol Wallet. So what is so great about web wallets? Right? Onboarding, I would say is vastly improved. I'll talk about onboarding in the next few slides. We have no reliance on desktop or mobile apps. Why is that important? This makes a big difference in locales where crypto wallets might be legal, right? And so you get stopped in the street, they set your phone and they find a mobile app in your wallet. Like this is not great.
00:10:33.128 - 00:11:25.258, Speaker A: With a web wallet, you can have an incognito browser, you can transact in crypto, you can own your assets and own can find out about it. They also work in jurisdictions where you don't have access to App Stores as well, which also is an important point. I would also argue that the speed of development really is a key differentiator in web wallets. Like web wallet development is web development. So web wallets have an ecosystem that has been in progress for 30 years with all the libraries and the thousands of people really that participate in it. Simple to test. With a web wallet, you can clone the GitHub, Repo, you run, NPM run, and suddenly you have the web wallet right there in your browser to test it.
00:11:25.258 - 00:12:19.662, Speaker A: You can extend it very easily. And I think this is really contributing to this renaissance in wallet development. I would also say that it makes composition easier. I think we are not that far away from a situation where we have component libraries just for wallets, like the same way that we have undesigned, for example, for like general UX. I think this is where the ecosystem is going. There's going to be a lot of reusability, a lot of safe components, and I think this is all great. I also want to make the case that with web wallets, security will become a UX issue.
00:12:19.662 - 00:13:41.664, Speaker A: This is a conjecture, but what I mean by that is that we have been hampered by really complicated development practice. And I think with the web wallet we can iterate very quickly on using uxs that are easy to use, safe and secure. So onboarding problems and what, why? I just want to further motivate web wallets. Right? So why are they great? Like, first of all, seed phrases. I mean, it's not hard to, you know, to consider seed phrases a problem. If any of you have seen the latest wallet connect report, 21% of users in the report, they claim to have lost access to the wallet because they lost their password and the seed phrase. And another staggering 11%, they claim to have lost access to the wallets because they were victims of phishing attacks.
00:13:41.664 - 00:14:36.104, Speaker A: So if we can do a lot better, like we're never really going to solve the problem in crypto wallets. If users, current users, are used to logging into their bank account with a face id, and then we expect them to take note of complicated seed phrases and remembering passwords so very quickly, what are the problems with seed phrases? So yes, they can be lost. They are liable to phishing attacks. They're physically vulnerable. You write them down, put them in your genes, you put your genes in your washing machine, your seed phrase is gone. And they're also prone to human error. And really the same problems exist with passwords.
00:14:36.104 - 00:15:14.584, Speaker A: Passwords disrupt the user process. They force users to remember. And if you don't really want to remember, then you use the same password with all, all the problems that this entails. Passwords are also easily forgotten and they can be easily hijacked. So, okay, so now we have web wallets. Are we done? You know, is this it? I would say that there is still some work to be done. Let's take one example.
00:15:14.584 - 00:15:55.224, Speaker A: For example, you incorporate you as a wallet builder, incorporate basket into your Ethereum smart account wallet. The signature verification for Webauthn is not natively supported by Ethereum. The p 256, you have to support P 256 in a smart contract. That smart contract is going to be expensive to run. It's also going to be error prone. There are efforts out there to have the P 256 verification as a precompile, which I think is great, but we're not there yet. As last I knew it's going to be deployed, is already deployed in polygon.
00:15:55.224 - 00:16:43.764, Speaker A: I would say. Really, for me, the biggest problem is that Ethereum account abstraction wallets rather, can only hold Ethereum. If we believe in a multi chain and a cross chain future, then we as wallet builders, we want to allow our users to hold any asset that they want. Right? And I would also say that the count abstraction has really, it has not simplified, unfortunately, gas management, it has made it a lot more complex. This is on the base layer. I think with layer twos this situation is different. And I think we're starting to see a lot of gas subsidies is really on layer two.
00:16:43.764 - 00:18:39.994, Speaker A: So in the end, I think we're going to have account abstraction wallets in layer twos where the users don't have to pay for gas. But for now, the gas management situation is complicated and the smart account wallets have to be written in solidity. That's not necessarily a bad thing. But can we do better? Can we bring, can we enlarge the ecosystem of wallet developers? Can we have smart contract wallets, the front end, the back end written in different languages? So yes, can we do better? Can we have a web wallet that is cross chain, so it can hold not only ethereum assets, but you hold bitcoin, it can hold ICP, for example, it can hold Solana, that is fully on chain. So the browser can verify that the static assets of the wallet are legit, where we avoid seed phrase and passwords, so it works with passages where we have gas subsidies, so it's effectively free to use, and where we don't have to use solidity, the ecosystem of rust developers about an order of magnitude greater than solidity. So if you can develop your wallets in say, rust or Python or typescript, then you have expanded the ecosystem. So I want to talk to you about how we do it in dfinity, where we develop a sodja's wallet called oz, where it can hold not only ethereum but ICP assets.
00:18:39.994 - 00:19:51.374, Speaker A: You can go to it right now@oise.com. And so I want to talk to you about how this is possible by using threshold signatures, some facilities on the Internet computer and then internal identity. So Internet computer first, how many of you have heard about the Internet computer? Good. So what is the Internet computer protocol is a platform that is built with and for applications. Threshold crypto. What this means is that the Internet computer, the inner workings of the ICP, of the Internet computer protocol works with threshold cryptography, but it also allows applications that are built on top of it to use it, to use threshold crypto very quickly. The ICP works with independent known providers, whether they have node machines in their own data centers like worldwide.
00:19:51.374 - 00:21:19.634, Speaker A: And it's based on the premise of sovereign hardware, much like bitcoin, for example. So there are no node machines that are hosted on big tech cloud. ICP also combines nodes in order to form FSM and very performant subnets. We have a thing that is called deterministic centralizations, where the placement of node machines in a particular subnet is controlled by a DAO. And the DAO really takes into account the node providers, the data centers, the geography jurisdiction, in order to have the heterogeneous subnet, as heterogeneous subnet as possible. So what is this complicated slide with like a lot of lines this is really there to say that you as a smart contract developer, you create a smart contract on ICP, you deploy it, it's going to go into a subnet, but the ICP provides the routing infrastructure necessary to interact with any other smart, smart contract on the ICP network. So it routes messages like across subnets.
00:21:19.634 - 00:22:30.064, Speaker A: So and here we're going into a more complicated slide. I would say the two things to remember from here is that in ICP consensus works across consensus works across threshold crypto and there is a root subnet and then we have multiple subnets and every subnet has their own public key. So what have we achieved? We have subnets with their own public key. Too many public keys. Can we do something about it? The root subnet on ICP certifies the public keys of every subnet that has been spawned. That is. So what this creates is a situation where messages on any subnet can be very easily verified.
00:22:30.064 - 00:24:32.132, Speaker A: And not only that, but a very, very light client can validate any message on the Internet computer simply by having the root public key of the root subnet and the delegation and the certificate. So that's fine. So what's the big deal with that? Right before we go into that, from the requirements that I stated, like what have we achieved so far? So yes, we have a web wallet. We haven't really explained why it is cross chain yet, but we know that it is fully on chain and it is fully on chain because with threshold cryptography we can assert that contents on the Internet computer, they are legit. So with threshold cryptography we sign the contents of the web wallet and because of the delegation from the root subnet to the other subnet, a browser can very, very quickly verify that the web wallet assets, they're verified, right? So ICP also allows, it has the reverse gas model, so developers pay for gas and you can create smart contracts on ICP in rust or python or typescript. Okay, so next I'm going to talk about threshold cryptography. So I'm not a cryptographer, but I have my, you have appeared in distributed systems, but, so I'm going to try my best to stay high level for the next couple of minutes and describe threshold cryptography.
00:24:32.132 - 00:25:47.574, Speaker A: So what is threshold cryptography? And particularly threshold ECDSA? Threshold ECDSA is a protocol that is part of the ICP chinky signature toolbox. Signatures are computed using secret shares and the privacy is never reconstructed. What this means is that every canister is a smart contract on ICP has control over unique CDSA key pair. It can request signatures on behalf of users and the corresponding private key is never revealed. And so this is a key difference between ICP and Ethereum is that con stairs on ICP they can sign transactions on behalf of authenticated users. There is some confusion really on what the stressor cryptography versus multisig. Really if we take a group, like a group setting, we say some members in Multisig situation, every member of the group, they have their own public and private key.
00:25:47.574 - 00:26:39.614, Speaker A: Then a subset of the group signs a message and then it is down to the receiving party blockchain. So in the case of bitcoin, the blockchain itself can validate multisig. In the case of like Ethereum, there is a smart contract can do that. But it is down to like a smart contract, the blockchain, to verify that the message is signed by m out of n participants. So this is in direct contrast really with threshold signature. In threshold signature, in threshold signatures there is one public key that represents a group, and then the private key is fragmented across all the members of the group. It is never reconstructed, never revealed.
00:26:39.614 - 00:27:32.834, Speaker A: And so when you sign a message with threshold cryptography, it is indistinguishable from signing a message from a particular user with a private key. And that is a key difference. Like our head of product in dfinity makes a very nice analogy, that threshold cryptography is akin to the limited liability corporation, while multisig is akin to a partnership. So here really the only thing to know is that smart contracts on ICP, they can own crypto, they can sign transactions on behalf of users. And so going back to the requirements, what do we have? Now we have a web wallet. Now we know that we can, that it can hold assets across multiple chains. So it is cross chain.
00:27:32.834 - 00:28:19.664, Speaker A: We said that it's fully on chain. We haven't really yet talked about the pasty part, but the reverse gas model is by default on ICP. And we can also call the wallet in rust and JavaScript. And the last thing I want to talk about briefly is Internet identity. So what is Internet identity? Two things really to take from it. Internet identity is another smart contract on ICP. It is controlled by a DAo, it is sold on a special subnet, and what it does, it effectively abstracts away the pain of dealing with passages.
00:28:19.664 - 00:28:58.608, Speaker A: And so it offers features like onboarding, like device management, like device recovery. And so it is used as an authentication layer and as a session management layer. And here we have completed sort of the list of requirements. So using threshold cryptography, Internet identity and some of the features of ICP. We can have a web wallet that holds crypto assets. Maybe I'll stop here. I have a.
00:28:58.608 - 00:29:32.774, Speaker A: Okay, so I have a couple of other slides that I can go quickly on. Noisy you go tooz.com. You see the landing page. If you're on your mobile, you can log into Oz with this face id. The wallet is initialized and then that's how it looks. So you can see here that you can select between Internet, computer and Ethereum mainnet and your assets are there. And any transaction that you do is going to be threshold signed either with threshold bls or threshold Lisa DSA, depending on the network that you're at.
00:29:32.774 - 00:30:06.272, Speaker A: I'm not going to go through the account setup and transacting. I want to stop here and maybe leave some time for questions. Andronicus, we thank you very much and congratulations for such a good presentation. Does anyone here have a question? We are going to take the microphone towards you. Hello. Thank you for this presentation. I would be worried about censorship.
00:30:06.272 - 00:31:26.466, Speaker A: What are your countermeasures to censorship? I mean, we know we heard a presentation on Friday that Ethereum validators are already banning transactions to mixers and in this case the account could even be frozen. So what are your countermeasures there? Yeah, and this is a difficult problem. Thanks for the question. Right now, where we rely on censorship is simply the heterogeneity of node providers on every subnet. So the DAO attempts at least to have subnets that are as diverse in terms of the organizations that own the nodes, their geographies. And so just from that we try to avoid censorship and collusion. Like both censorship and collusions are very high in our list on how to avoid, and how to prevent and avoid them.
00:31:26.466 - 00:32:46.364, Speaker A: So we don't have any other than that. This is right now the solution to have as diverse subnets as possible. We have just one last final question here. I don't know much about ICP, but maybe you can tell us if you have a way to ensure that all the parts of the private key so understand they are running on some random vms somewhere. Do you have a way to ensure that not all the parts of the key are like lending, you know, on a property of the same company or the same data center? Yeah, yeah, no, that's an excellent question. I mean, so the only thing, the only thing to say on this is that the founders of threshold cryptography work in Dfinity, you know, the people that have really led the field on threshold, on threshold cryptography, the other thing to say is that the code is open source and the protocols have been published in conferences. Right.
00:32:46.364 - 00:33:19.080, Speaker A: So like what? Really? So they're open for public scrutiny? That they do indeed. That the private key is never reconstructed. That is really the, that is really the risk, right? Yeah, I mean, if you. Yeah. So the protocols, the protocols are designed so they tolerate malicious nodes. Right. And so threshold cryptography really means that like, there is a super majority of nodes on a particular subnet.
00:33:19.080 - 00:33:40.674, Speaker A: Agree. And then they, and then they sign. So any. It can tolerate malicious nodes that are less than the super majority of nodes. Right. So if there is collusion, the supermator majority, then the game is lost, but like, it can tolerate malicious nodes. Okay, thank you very much.
00:33:40.674 - 00:34:18.710, Speaker A: And then we can conclude. Our section congratulates Andre Nikos. Thank you. So the next presentation that we're going to have right now is by Mister Ivor Georgiev. The title is demystifying account abstraction Eips. Evo is a recognized expert in web three and crypto, with extensive experience in blockchain development. As the CEO of Unbuyer Wallet, he leads a theme of skilled developers and designers in building innovative products for the blockchain space.
00:34:18.710 - 00:35:10.793, Speaker A: Ivo, we thank you very much for your presentation. And I'm here and the staging this morning is now yours because we need a minute, but we're going to be right there and we're going to continue the account obstruction warning. Perfect. All right, so good morning. I am Ivo and I'm the CEO and co founder of Unbire Wallet. And I'm going to help you demystify all the account obstruction ercs, Eips rips. We're not going to go ahead and dive into what any of those letters mean.
00:35:10.793 - 00:36:04.786, Speaker A: But all that matters is that those are proposals to improve Ethereum and EVM ecosystems, and there is millions of them. Regarding account obstruction and a quick agenda of what we're going to go through. First of all, the big picture stuff. So what are all the account obstruction improvement proposals? Then we're going to go into the biggest one, ERC 4337. Biggest one. When I say biggest one, I mean biggest one in terms of mind share and in terms of how it captured our community and how it reignited the vision of account obstruction, we're going to go into what it is not, and then we are going to do a deep dive into native account obstruction. What's the state, how are we doing in terms of native account abstraction in the EVM ecosystem and on Ethereum.
00:36:04.786 - 00:37:02.374, Speaker A: And then finally we're going to cover smart contract signatures and a few other eips that more or less help the account abstraction ecosystem, but are not directly related to account abstraction. So who are we when I say we? This presentation is brought to you by Ambire. In general, it has been a team effort. I already presented myself, but what are my credentials? Well, Ambayer spun off of ADX, and ADX was one of the first projects on Ethereum to ever deploy a smart contract wallet back in 2019. And back then, the only other smart contract wallets were parity and agnosis safe, which later turned into safe, obviously extremely successful. We also rolled out one of the first consumer centric account obstruction wallets at the end of 2021, the Ambire wallet. And it's currently a web wallet, but we're working on an extension.
00:37:02.374 - 00:38:08.006, Speaker A: We won a grant from the Ethereum foundation for building account recovery through email. So like being able to log into your Ethereum wallet with an email and a password, but while keeping a fully self custodial nature of the wallet. And finally, we created ERC 6492, which I'm going to go into later. So why is account abstraction valuable? I guess most of you already know this, but let's have a quick summary of everything so you can get onboarded much easily because you can eliminate the seed phrase. And another big point of onboarding is paying gas with non natives and paying gas with tokens. Because usually we think of this as a feature, but it's not so much as a feature as it is an ability to onboard users, because one of the main points of friction for new users is having to get ease or whatever the native currency of the robot is. So this friction of having to get ease makes people sign on to centralized exchanges, and we don't want that because people end up sticking to centralized exchanges.
00:38:08.006 - 00:39:13.434, Speaker A: We also don't want it because it really doxes your wallet. So for example, if I make a new wallet and I need ETH for gas, I'm going to ask one of my friends to send me some Eid for gas, and then I'm kind of doxed because I'm creating this relation between the two wallets. So that's not ideal. Of course, we have account recovery, like what argent did with social recovery, and a bunch of other account recovery mechanisms, as I mentioned earlier, the one we won a grant for, the one with email. And of course you have alternative signature algorithms, which is also hugely valuable because you can validate passkeys from iOS devices, you can validate web authentication from web browsers, you can use secure enclaves that are already on the devices that we have. So like, why reinvent the wheel? Why use different signature algorithms when we already have secure enclaves on our devices? And we build sort of a demo for all of those. And of course we have to ask ourselves, when is account abstraction coming? We all know that that's a painful issue.
00:39:13.434 - 00:40:11.624, Speaker A: And we already know that there's a lot of wallets on mainnet already that implement a ton of account abstraction features. Argent was one of the first ones back in 2018, they launched and they launched on Ethereum. So even back then we had account abstraction. But the purpose of all those Eaps, ERCs and et cetera is to make account abstraction more accessible and to allow it to get adopted quicker and basically to give developers better tools to build it faster and to basically make it usable. And this is a huge bubble of the entire account abstraction space. And we have EAP 29 38, which was one of the original account abstraction proposals back in 2020. It wasn't the first one, but it then evolved into this rip, which takes the best from ERC 4337 and makes it native, which is amazing.
00:40:11.624 - 00:40:39.764, Speaker A: We're going to talk about it later. There are two key takeaways from this slide. So one of the key takeaways is that none of those are competing. And that's really important because a lot of times when we think about account abstraction, we think about this ERC versus that ERC. But in reality that's just not true. You have all of those ercs which are mostly complementary to each other. Almost none of them are competing.
00:40:39.764 - 00:41:39.804, Speaker A: And sort of, they all have the same goal, but they all tackle the problems, tackle the, tackle different problems, or the same problem from a different direction in such a way that they can work together and none of those are conflicting. And the other takeaway is that we need many aspects of account obstruction to work, to make it work, basically. And the other key takeaway here is that we have a key intersection between a few eips where we need to be. So like for example, in order to have account obstruction right now in a pretty reasonable way, and to make it developer friendly, we need ERC 4337. But then to make it truly native and to make it cheap in terms of gas, we need Rip 7560. And then in order to get signatures to work, we need the ercs on the bottom. So we need everything together in order to get account abstraction going.
00:41:39.804 - 00:42:36.724, Speaker A: So yeah, none of those are competing. They are competing, however, for attention and for memes, as you might know from Twitter. So a quick recap of 4337 and the revolution of 4337 really in its essence is the fact that it doesn't require any consensus level changes. And this is something that the Ethereum community kind of realized, that if you want to make account abstraction work, you need to make it as least disruptive as possible because previous ercs arguably failed because they required way too much changes. And on a main net that's already live and it already has tons of dapps deployed, and every small change in the EVM can bring security issues, that kind of an issue. So you cannot simply change the EVM, you need to avoid this as much as possible. And ERC 4337 is the first account obstruction ERC to be entirely on the application level.
00:42:36.724 - 00:43:37.364, Speaker A: So another question that people, that people kind of get and that people sort of don't understand is, is it a standard? And the answer is really complicated. You can think of it as a standard for relayers because as I said, we had a account obstruction before it, and account obstruction was largely built on these proprietary relayers that you send a transaction like object which is also signed using some signature algorithm to that relayer. And this relayer used a new way under the hood to make the transaction confirmed on Mainnet. And the way that ERC 4337 changes that is it allows anyone to be this relayer in the form of a bundler, and it standardizes the communication between the wallet and the entity that's relaying this transaction to the actual blockchain. So that's what it does. It allows a network of boundless and as a result a public mempool. And as a result, account obstruction kind of gets the same benefits as native AOA transactions.
00:43:37.364 - 00:44:10.752, Speaker A: So what ERC 4337 is not, it's not a change in the Ethereum protocol. It does nothing to change the actual Ethereum protocol. It doesn't add new features or functionality to smart accounts. Even though a lot of the marketing material for 4.37 was related to those features that it's going to bring to Mainnet, it doesn't actually bring those features to Mainnet. It just lets developers build them easier, build them better. And that's really valuable in itself.
00:44:10.752 - 00:44:31.778, Speaker A: It's amazingly valuable. Doesn't add features, right? So it's not native aa, we covered that. And it doesn't actually do anything to standardize accounts. This is an interesting point that a lot of people have been understanding wrong. It doesn't standardize accounts in any way. It just lets bundlers and wallets talk to each other. So that's an interesting point.
00:44:31.778 - 00:45:20.970, Speaker A: Because accounts can still have different interfaces between different implementations. Like for example, safe can have one interface and umbire can have a totally different interface. And then finally, there is nothing cross chain or intents related to ERC 4337. And I'm only mentioning this, it might sound weird because I'm only mentioning it because I've heard some people make this, be confused by that point, and think that ERC 4337 is somehow related to intents. It does help account obstruction happen, so it does help intents happen because account obstruction is kind of an important step to intents. But it doesn't, it's not related to intents directly. So what are the benefits? So the biggest benefit, although that's a double edged sword, is that it inspired developers to fall in love with account abstraction.
00:45:20.970 - 00:46:02.386, Speaker A: Again, when I say a double edged sword, I tweeted about this recently. It's about the fact that many people were hyped from ERC 4337. And then when adoption didn't happen super quickly, as everyone expects in crypto, people sort of became disillusioned with the count abstraction and thought that something must be wrong with it, which isn't the case. Obviously, good things take time, but this hype train that it created sort of backfired a bit. But in general it's really good because everyone now is thinking about account abstraction. And like a couple of years ago, Dapps never thought that account that users can be contracts. And now Dapps know very well that users can be contracted.
00:46:02.386 - 00:46:59.810, Speaker A: So they built with that in mind. As I said, there is no consensus level changes, which helps a lot for everything to get done to get implemented. And the biggest point that ERC 4337 helped with is that wallets do not need to spend time to develop these proprietary and fragile relayers, which took a lot of effort to happen, basically. And obviously we have a lot of improvements in terms of censorship resistance, which is what we want. And it's standardized smart account user operations, which is, as I said, the structure of data, which is similar to EOA transaction. And finally, we have Paymasters, which is really a huge part of the standard, which is a lot of people think that paymasters are for sponsoring us. They're not necessarily for sponsoring us in someone else pays for your gas, there are for allowing gas payments to happen in many different ways.
00:46:59.810 - 00:47:49.370, Speaker A: It could be sponsored by someone, it could be sponsored by the DApp, it could even be sponsored by the network in a row up. Or it could just be paid by the user, but paid in a near c 20 token, or paid even with an NFT, let's say, or paid with a deposit that you made earlier on. So yeah, when people talk about sponsoring, they don't mean that someone else is paying it. They mean that the paymaster gives the if and then the user gives some other form of value to the paymaster. It could be just the network effect from using the Dapp. And so let's switch the topics a bit and go to native account obstruction. And there was already a talk by argent about why native account abstraction is important, and we totally supported this, but it's going to take a while for it to happen on Ethereum.
00:47:49.370 - 00:48:50.690, Speaker A: But something interesting that you may have known, or may have not known, is that Ethereum was actually meant to launch with native account obstruction. Who here knew that? Anyone? Okay, so Ethereum was meant to launch with account obstruction, but due to time constraints, they didn't ship it. And there is actually a piece of text from the original white paper here saying that there is two different account types. One of them is new way and the other one is a contract. Out of context, it's a bit tough to understand this, but basically Ethereum also meant to have contract accounts be able to initiate transactions themselves. This is the actual account abstraction feature that never happened for contracts to be able to initiate transactions. So what's the brief history? So after Ethereum, sort of when this was in this rush and didn't ship this feature, Vitalik immediately started drafting a few eips on account obstruction.
00:48:50.690 - 00:50:04.790, Speaker A: The first one was 86 and that one didn't happen. So it was kind of rewritten to 208. And back then the point was to obstruct the signature and nonce checks. So this would allow for contracts to initiate transactions, but it isn't quite the same as the, the native account abstraction that we have now. And then Vitaliko wrote a really good blog post on the challenges behind native account abstraction. And generally a lot of this was related to the current challenge that ERC 4337 has, which is how to make sure the transactions cannot be arbitrarily invalidated, right? Because like for example, imagine that there is 1000 smart contract transactions in the mempool, but unlike EOA transactions, their validity doesn't only depend on the signatures, it could depend on some contract logic, right? So like changing one storage slot in one contract can invalidate all of those thousand transactions, like in a flash, in a second. So the problem with this is that the network becomes really like really exposed to spam issues, and it's possible to just like spam millions and millions of transactions which would be considered valid in the mempool, but like in a flash they could be invalidated without any way to predict this.
00:50:04.790 - 00:51:54.548, Speaker A: So ERC 4337 solves this by introducing some storage constraints and all of the account obstruction eips ERCs have some sort of mechanism for this. And then in 2020 there was a more mature account obstruction proposal, but that didn't happen due to requiring a lot of consensus changes and having a lot of security edge cases that we couldn't possibly address on Mainnet. And then we had EAP 3074, which is really interesting, and ERP, EAC EIP, sorry, 500 three, which is complementary to this, and those two are fully, are totally different from the previous ones because they do not introduce account obstruction. They introduce an ability to, to convert eoas to contracts, which is extremely helpful for account obstruction. But it isn't account abstraction, right? So it doesn't allow us, it doesn't allow contracts to initiate transactions, but it does allow existing wallets on the main net, existing key aways to convert to account abstraction, which is really cool and it would be amazing for adoption. And those eips kind of died for a second, but they got revived recently and they got revived in a way that's really funny by having this meme war against 4337, which isn't even technically accurate, right, because there are not competing standards. But the fact that it got memed a lot means that this got revived and then finally rip 7560, which is absolutely amazing in my personal opinion, because it combines all the learnings from everything that happened before, including a lot of valuable learnings and a lot of valuable development from 4337, but makes it native, makes it enshrined into the protocol.
00:51:54.548 - 00:52:34.896, Speaker A: And why is this important? It's important because it gives us the best of all worlds and it gives us cheap gas for account obstruction transactions. Because at the moment for 437 we have an overhead of like 60,000 gas which we cannot get rid of. It's absolutely impossible. And like, for native, like just for sending is for native transactions, this would make it four times more expensive. And this rip solves this. So I meant to write something about Vitalik on the bottom, but I forgot what it is and I guess it got stuck in a draft. So anyway, so are any of those live? Absolutely not.
00:52:34.896 - 00:53:09.350, Speaker A: None of them. But we're working on it and the last one has a really big chance of becoming Clive very soon in a row up. I'm not really sure which one, but it's definitely going to happen. And there's already an implementation in Go ethereum, which is the furthest any of those eaps has ever made it. And a really important point here that I already mentioned, those two can absolutely coexist. One of them is meant, as I said, for converting QA to smart accounts, and the other one is meant for relaying transactions. Absolutely no competition, but there is a competition for attention.
00:53:09.350 - 00:53:54.290, Speaker A: Right. And finally, one of the biggest topics is signatures. So basically a lot of people think contracts cannot sign messages, and that's technically accurate. However, contracts can implement logic that states which signature is correct. So how this looks, imagine that your wallet is a contract, which is obviously the case with account abstraction. And for this smart account, a valid signature would be the signature, the elliptic curve signature for which there is an authorized signer with this contract. So the contract would keep a mapping of the valid keys.
00:53:54.290 - 00:54:31.560, Speaker A: And then if you have signed with a key which is considered valid by the contract, then it's considered a valid signature for this contract and by extension for this account. So yeah, this is how this looks in practice. And basically this is ERC 1271, the standard signature validation method for contracts. This is how the interface looks like. You can see it's almost the same as my example. I've actually flipped signature and hash, but that doesn't matter here. And another peculiarity of this standard is that it doesn't return a boolean, but it returns a magic value.
00:54:31.560 - 00:55:14.432, Speaker A: And the reason for this is that if you're validating a signature and it accidentally goes into a fallback function, that for some reason it happens to return true or one, then the signature would get accidentally validated. And that's why you don't want this. You want to return a magic value, which there is a very low chance of a contract just returning randomly. Is this a solution for contract signatures? Unfortunately, it turns out it's not. After many years it's still not adopted. And it's great. Actually, the adoption issue has been an issue of mostly convincing Dapps, but there is one big flow with it, and the flow is that you cannot validate signatures for contracts which are not deployed yet.
00:55:14.432 - 00:56:07.820, Speaker A: And that's a great technique that many account abstraction wallets did. They don't deploy your account, your account contract until you've done your first transaction, which is hugely valuable because it eliminates one step from the process and it eliminates one fee payment. And how is this solved? With ERC 6492, universal signature verification. So this is an ERC that extends 1271. It doesn't compete with it, it completely extends it and it allows for very easy verification of any type of signature, including traditional EOA signature, but also to verify a signature for a contract that isn't deployed yet. And that works basically in a kind of, in a magic way, through an ETH code which deploys a contract, but it doesn't really deploy it because it's off chain. It's a bit crazy how it works.
00:56:07.820 - 00:56:43.404, Speaker A: If you want to learn more about it, just read the ERC. It's really cool. And a lot of ercs have been replicating this magic deploy less method of calling contracts. And yeah, this ERC can verify any signature and it can also verify signatures for contracts that are not deployed yet. Therefore solving a big ux battle between counterfactual deployment and being able to verify signatures. So a quick rundown of the satellite ercs. And when I say satellite, I mean things that are not strictly account obstruction, but help account abstraction a lot.
00:56:43.404 - 00:57:20.070, Speaker A: And the first one is modular accounts. There's been two ercs. Some of them are supported by safe and Zerodev. And I think those are the first case of competing QRCs that I have on my presentation. And then you have the wallet function call. And this is really cool because it enables dapps to tell wallets to make you sign multiple actions at the same time, which is great for eliminating ERC 20 approvals. We all know how bad approvals are, and this ERC enables the ability to do exact approvals every time without having to do an actual additional signature.
00:57:20.070 - 00:58:17.198, Speaker A: And exact approvals are amazing because they cancel out automatically after you do the operation. So like imagine you do a swap, you do a swap for 100 USDT and then the approval is only for 100 USDT and it doesn't require an extra signature. So you don't really notice, is it? And there's no open approvals left to the Dapps. So there is no security risks in this. It eliminates a huge amount of security issues, as you all know. And then we have precompile for the NIST curve, which is a cryptographic curve that you have on iPhones, you have on multiple devices, and you have diamond contracts which allow building different sort of upgradable and flexible accounts. And finally, we have one thing which I think the number is not correct, but it's something that the wallet Connect team is also working on, which is the user operation bundler, which standardizes the way, or more like it allows for a way for adapt to build a user operation in a way that's compatible with the particular account.
00:58:17.198 - 00:59:01.536, Speaker A: Because I said different accounts have different interfaces, how this might look, one account may have an execute function and the other account may have an execute execute full function which takes different arguments. So this user operation builder EAP allows this to be, allows the Dapp to know which standard or which interface the wallet uses. So yeah, that's pretty much everything. It has been a lot of stuff. So I hope we have time for questions. Ivo, thank you very much for such a rich and interesting presentation. Unfortunately, due to time we are not going to open for questions right now, but Evo is pleased to help you and to attend you outside in the coffee, or even you can reach him out through LinkedIn.
00:59:01.536 - 01:00:10.188, Speaker A: Yeah, and on X and Warpcast. I'm sorry for that, but we are late on time, so thank you very much. Thank you. So the next presentation and session that we're going to have right now, it will be presented by Mister Lucas Shor. The title of his presentation is unlocking ownership, the path to an invisible web three through account abstraction. Lucas Shorn has been working in product related roles in the blockchain industry for the past six years, with the goal of making web three more accessible to the society. Lucas, good morning and we thank you very much for coming here.
01:00:10.188 - 01:00:50.136, Speaker A: And the stage is now yours. Thank you. Good morning. Maybe first, so I know a little bit how much into detail I should go. Who knows about the conduct section? The ones that don't raise the hand weren't paying attention with Evo's talk. Who knows about safe? Roughly, who uses safe here? Half cool. So I keep it very short on the introductions and then go more about the forward looking.
01:00:50.136 - 01:01:19.378, Speaker A: What excites me about the call abstraction so quickly. Shortly what are smart accounts? Which is really what we should be talking about when we talk about account abstraction. As Evo also rightfully said, smart accounts have been around for a long time. This ERC 457 is one critical component that will hopefully help with adoption. But it's something that's much bigger than this one standard. So yeah, we've got these two user accounts. One is eOas.
01:01:19.378 - 01:02:20.478, Speaker A: It's like this private key, the seed phrase that you know from a metamask account. And the other one is a smart account. And the key difference there is that they're not, they don't have like this hard coded control that are being controlled by a private key through easy to say signatures, but they are controlled through code. And that makes smart accounts powerful because that makes them programmable. So you can program new features, new security implementations in there, and it just makes them more flexible to evolve as also the Ethereum and wider digital assets ecosystem are emerging. And yeah, that's, that's the reason why you don't do PDF slides, because there was like a fancy animation there with an Ethereum logo. But anyways, so yeah, one of the things that is enabled for that is that you don't have this one key that controls your wallet, but you actually can have multiple keys as a multi signature wallet with smart account and also these can be reprogrammed.
01:02:20.478 - 01:03:13.216, Speaker A: So you might suspect that one of the keys might be compromised. And if that happens with regular EOA wallet, you would have to migrate all your assets to a new account because you would not know if that the key was compromised somewhere. But with smart account you could just rotate keys and make sure that the new key that you then set is properly generated. And also something that actually Evo tweeted yesterday a little bit about this hype that was coming up last year around the counter section with ERC 457 and it was maybe a little bit too much of a hype. To some extent it was important to get the ball rolling. We now got a bunch of projects working on account abstraction tooling. We've got entire conferences have entire tracks about the counter abstraction that's really important to get this forward.
01:03:13.216 - 01:04:21.794, Speaker A: But there is going to be this phase now where we have to look back and see, ok, this maybe is going a bit slower than we expected. There's a lot more challenges on the way than we maybe originally expected. And all the fancy things we talked about from session keys and sponsored transactions and social recovery and all these things, they're definitely non trivial and they will take quite some work. This talk also should go a little bit into what actually makes me excited and what makes me confident that we will go through this valley of disillusionment and how we get to this plateau of productivity over time so quickly. About safe this is some slide someone in the team put together. It's more like logo dropping, but it serves the purpose of showing that safe is quite flexibly used today. That ranges from Dao treasuries that run unsafe, like Avedao or venture capital funds like one cakes that use it to sort additional assets.
01:04:21.794 - 01:05:10.246, Speaker A: But it's also individuals like Vitalik Buterin himself to usually high net worth individuals, people that use high security solutions that use safe today. But it's also used quite a lot as a infrastructure for different tooling, different solutions such as Worldcoin. So the proof of personhood protocol, they actually use safe as a user account. And yeah, every worldcoin user is a safe user, although most of them probably don't know. Similarly, notice pay and Cobo are also built on safe as user accounts. It's just a little bit the size of adoption, like $124 billion in assets are currently secured through through safe. That's bigger than Robinhood, bigger than all of Defi.
01:05:10.246 - 01:06:04.224, Speaker A: Obviously this is comparing Apple to oranges, but it still shows a bit the magnitude. But what is safe actually it's on the one hand the lowest level, it's the protocol. It's the safe smart account, which has been originally created five years ago and some iterations over time. And this really brings the functionalities of smart accounts. But then to make this more accessible to users and developers, safe also is building some open source solutions on top of that. So on the one side, that's an API and SDKs that just allow developers to more easily use the safe smart account and also build on that as well. There's safe wallet, which is reference implementation, sort of like a showcase what the protocol can do, but for end users.
01:06:04.224 - 01:07:09.944, Speaker A: So surfacing some of the functionality and hopefully also triggering imagination of developers what can be done with safe smart accounts. But what we're really after is creating an ecosystem. So not actually owning the end user relationship to some extent, say for it serves their purpose just to, I said, sparkle a bit, the creativity and showcase what different user groups can benefit from safe. But in the long run we really want to focus on supporting other builders that leverage a safe smart account and optimize for different use cases and user groups. As there will never be one wallet or one asset management solution that serves all the needs of every user group. But there needs to be specialized solutions out there as they emerge. Yeah, so the base functionality which most people know about safe is the multi signature feature that's like you can set multiple private keys and a threshold and say like two out of three of these private keys need to sign in order to trigger transactions.
01:07:09.944 - 01:08:05.324, Speaker A: But very much safe is, or Multisig is like the tip of that iceberg. It's really about enabling all the different functionalities that smart accounts can enable from new signature schemes, from implementing roles and hierarchies, transaction batching, allowed denialists, all that cool stuff. And that's enabled through the modular architecture of safe. So safe is not a monolithic account, it's actually something that can be extended by developers for parties and implement new features over time. Just two key ones that safe enables is modules, modules. So you might have your primary keys, the controller count and modules bypass that key logic and can have additional ways how the account is being controlled. This can be automations, it can be different roles or permissions you give to another key, another person.
01:08:05.324 - 01:08:47.950, Speaker A: But it could also enable things like recovery systems. And then we got guards. Guards work a bit differently. They add additional validation logic on the transaction. So as you create a transaction, it needs to comply with the checks implemented by a safeguard. And these can be things like allow or deny list where you check on the transaction. Am I interacting with a certain protocol that they might not want to interact with? Actually cool things that people should be building is ways that I as a user can say I want to have all protocols I interact with being audited.
01:08:47.950 - 01:10:06.114, Speaker A: And there's actually a standard out there that allows to bring audits on chain and then you could build something that actually would check on chain if the protocol was audited and if it was not then rewarded transaction and if it was, then it goes through. Yeah, and then things that will be exciting and where we probably see more production ready solutions this year around onboarding. So I mean, one of the key challenges of crypto still today is that you might have applications people want to use, but then you need to tell them you need to download the wallet and they download the wallet and then they, they're faced with the seed phrase and you need to explain them pretty much all the things about how to securely manage private keys. And that's quite some rabbit hole. So that people understand how to backup their seed phrase in a way that they can still access it in five years, but no one else in the meantime. And some things people have been experimenting around is social login. So actually using your Google account or your Apple cloud account to log in to decentralized applications and generate a private key that's based on that, usually through MPC technology.
01:10:06.114 - 01:11:28.028, Speaker A: So it's not unique to smart accounts necessarily, because you could do social login without smart accounts, but you would want to use smart accounts because it might be a feasible solution to onboard, but over time, as people store more assets, probably it's not the best thing to rely on these solutions. And then you need a viable migration path. And that cannot be that you just move everything to a new account, but actually that you somehow reconfigure your account. So the solution would be that you use a smart account that's controlled through an MPC signer that allows for social login. And as people may require more security, they can then add another signer as a multi signature scheme, or they do a quick key rotation and switch to a hardware wallet or something. Yeah, it was interesting to see these solutions emerge, but I think what will really be properly achieving this onboarding challenge is passkeys, as this is literally like everyone that has a smartphone will have the ability to generate passkeys and it's a standard to distribute private keys. That's pushed by big players like Apple and Google, and they want to get rid of passwords themselves, so they really want to have everyone use passkeys going forward and all the devices will support it.
01:11:28.028 - 01:12:26.642, Speaker A: Maybe not the Apple TV, but at least all the phones and laptops out there. There's still some challenges around passkeys also when it comes to blind signing. As you we kind of told people over the years, you should really look what you sign with your wallets. And now we move to passkeys and they, at least so far, don't really show what you sign. But it's from a pure key distribution perspective and key generation perspective, I think, where onboarding for crypto is heading towards, and this really requires smart accounts because eoas don't support, or like Passkeys is a private key format that's not natively supported by at least Ethereum blockchain. And you need smart accounts to enable these signature schemes. Recovery, it's a rabbit hole itself because there's so many possible recovery schemes that could be implemented.
01:12:26.642 - 01:13:38.820, Speaker A: A lot of people always say or associate smart accounts with social recovery. So you have an account, you might, might have some primary keys that you control, but then you want to have your friends and family have a backup method to recover your account. You've seen this four years ago already with argent doing something similar, still hasn't properly picked up. Remains to be seen if it will be in the future. But I think what's going to be exciting is if we have more optionality for users to define how they want to recover their accounts, because it's important. Even though you might have solved the private key generation problem with passkeys and people can actually hold their private keys on their own devices, still, there are circumstances where people want to recover their account, even worst case scenario in an inheritance case, there needs to be solutions that also address this. And yeah, what's going to be exciting? Not sure if everyone will be wanting that, but at least in my view, a lot of people that will onboard to web three will probably go for.
01:13:38.820 - 01:14:46.050, Speaker A: One of those solutions is using institutional recovery, such as a trusted entity like a bank, or just the means that onboards them to crypto in the first place. Centralized exchange, which already they trust, they already have some identification with, so they could use that as a recovery system. And so actually Signum licensed bank here in Switzerland has implemented interesting feature for smart accounts where you can bring your smart account. They do KYC, you activate them as a recoverer and then when you lose your keys, you just go back and say, hey, signum, recover my account and you need to go through KYC again. And then they change your, reconfigure your account. What's cool here is that there are some protections against Signum just going rogue and running away with all your money, both in that they can only rotate certain keys on your account. That's a protection that they cannot trigger, just transfer on the account.
01:14:46.050 - 01:15:49.554, Speaker A: And the other one is a time delay, so you can set the time lock in which the recovery needs to be triggered and afterwards it gets executed. And in that time lock you can always veto that from your primary keys. Something that maybe is a little bit less known even within the account abstraction ecosystem so far is keystore rollup that can address things like if you're regular EOA, the cool thing is that you can derive multiple accounts from the same authentication method. So you have your private key and you can actually create more accounts on your metamask wallet, for example. And these are not linked in between them, but still you can all use them easily and just derive a bunch of more. The other part is that you can actually have the same authentication mechanism used across different networks because it's very standardized. You can just have the same account also on layer twos that you have on Ethereum mainnet.
01:15:49.554 - 01:17:30.482, Speaker A: And that's a challenge with smart accounts because they are smart contracts, they're deployed as individual accounts, smart contract accounts on a network. If you want to have multiple accounts on the network with same scheme, you can do that, but it's still individual accounts. So, meaning that if you change something with one account, it doesn't automatically change the signer, the key on the other account, and especially when it then comes to cross chain. So you might have replicated your account from if you mainnet on optimism and you want to exchange your keys across these accounts, then you have also an traditional oracle problem, because this information from what's the new key on Mainnet needs to somehow go to optimism and their keystore comes into play that basically says, let's do the authentication or the, it's like singling out a password manager from your accounts. So you have your password manager which source authentication for the accounts in a separate contract, and then you have just the accounts derive this authentication from this Keystore contract, and they don't have authentication in the account itself, but just always check with the keystore contract. What's the authentication exactly? And this addresses also the key exchange topic or the syncing topic. But especially when then it comes to cross chain, there can be elegant solutions where you say this Keystore contract is not a contract on layer one, but let's actually move it into a roll up.
01:17:30.482 - 01:18:22.126, Speaker A: Not like a full EVM roll up, but something that has limited operations, that is very specialized on just securing or mapping accounts to keys in a way, and then it's much more gas efficient through that. And then you could actually use something like cost chain state proofs to go from a separate layer two and check with that keystore roll up. What's the current setup? And as it changes, it just derives the new setup from there. It's still quite challenging. How do you actually achieve this cross chain state proof? Because you need to propagate block headers across networks and it's non trivial. And it's just a balance between cost efficiency and speed and decentralization. And there's not really a perfect solution.
01:18:22.126 - 01:19:25.046, Speaker A: But that's probably where a lot of experimentation will be around this year. And I know that big players are like base or scroll, are very much committed to finding solutions there this year. Then another more niche thing, but which I also find interesting how smart accounts can provide value this year is around tradfi transition. So that's something that we've seen now in the last months is that or even in years, you can start with neo banks not supporting crypto and then you've got the users asking for crypto, which leads them to implement in custody trading. So all the crypto is actually on the balance sheet. They usually support like a few different coins that they feel confident with from a regulatory perspective. And yeah, then it has nothing to do with custody or anything, but it at least gives people exposure to that.
01:19:25.046 - 01:20:35.574, Speaker A: But then the next step is to actually open these wallets, have designated user wallets, which then allows them to off ramp and on ramp crypto to their own wallet in there. Then next step is that they have users that are asking for some niche assets, some meme coins, and they don't want to have them somehow on their balance sheet. So they enable self custody wallets. So actually have to give a key to the users and say, if you want to trade these meme coins, do that on your self custody wallet there. And then they usually realize that it's going quite to some shift from having people use a custodial solution to a complete self custody solution with a private key, which then makes them think around how can we leverage smart accounts where it kind of brings users a little bit more back into the control of the neo banks, be it as a recovery feature, for example, or just for having a bit more handholding involved. And then finally, notice, pay is going to be interesting. And I got a card here that's actually like a Visa card.
01:20:35.574 - 01:21:40.682, Speaker A: This is built on safe, so it leverages the smart account there. And the cool thing here is, compared to other crypto cards, it's not something where I off ramp my crypto and I top up some debit card, but it's actually a full safe custodial card. So all my assets are on the safe, they're on chain, and only when I pay in the supermarket. Actually off ramp is happening at, I think, one of the best off ramping fees in the industry. And that's enabled by having smart accounts that allow the user to give like a certain daily limit to gnosis pay, which is then integrated into the visa network and allows them to then avoid double spending where you pay in the supermarket and then don't repay them on chain. But you actually have this three minute period where gnosis pay can withdraw from your account before you could send out from your safe. And this is just interesting solution to allow payment providers to add value to users without actually having custody over the assets.
01:21:40.682 - 01:23:00.710, Speaker A: That's usually a problem with anyone that wants to provide financial services. Once you have custody over user assets, then it comes with all this long tail of regulation and compliance requirements that people usually don't want or just adds to the cost. Some concluding thoughts, and it's in a way a theme that is across all these use cases that are shared, is that one of the things Spydercos will be doing is fundamentally change how ownership works when it comes to crypto is so far we had this saying of not your keys, not your crypto. So people would either go full self custody and they would manage their own keys and they had no third parties involved, or they would just rely on a third party. And sometimes they get dragged and sometimes they don't. But that was the current paradigm. And I think smart accounts will fundamentally break up this dichotomy where it will be much more, there will be much more solutions that are somewhere in between in a way that like gnosis pay, where you have maybe a certain trust assumption up to a certain daily limit that goes to the network.
01:23:00.710 - 01:24:38.300, Speaker A: Something like a signal where you give certain functionality to first parties in a way that's more that's still protected, or there's some meter rights involved and so on, or some aa based solutions that neo banks will be using to handhold their users into the web three ecosystem. And yeah, with that, if you want to learn more about safe, go to safe global or ONX at safe. And I'm not sure, I think I took five minutes too long, so not sure if I can do questions. Yes, thank you. So thank you very much Lucas, for such inspiring presentation, and unfortunately we don't have time for questions right now, but we can also reach Lucas out of the room, outside or through LinkedIn. But we thank you. It so the next session we're going to have right now, the next presenter is by Mister Renaud Dubois.
01:24:38.300 - 01:25:17.154, Speaker A: The title of his presentation is even faster p 256 for on chain pesky and SGX. Henol has been cryptographer for 17 years for the defense industry and two years in the Ethereum ecosystem. He optimizes implementations for unbit and on chain systems. Henlo, thank you very much. And now the session is yours. Ok, thanks. So we are going to talk about SEGP 256 r1, which actually is the elliptic curve used in Pascis and Intel enclave SGX.
01:25:17.154 - 01:26:16.932, Speaker A: So briefly, our team, we are for former ledger innovation, we left and we just launched our company and our mantra is that there is no web two or web three, but just web and making the difference between the two vanish is our purpose. So we are currently focusing on supporting the P 100 256 on chain. We hone the fastest implementation. Actually I think that the safe module use it, Baze is working on it and some other actors. We are also working on ED 250 519 for a similar reason. It's implemented in Fido framework, which we work on, and we also have works on MPC frameworks. So among the team, Renault, I'm a cryptographer, I've been introduced.
01:26:16.932 - 01:27:09.144, Speaker A: So briefly what we did last year, we ended up finalists at East Global New York with our invisible wallet so implemented passkey on chain. We were rewarded for this open source implementation by the Retro PGF. And recently we've been granted by the atarum from condition to continue our work on ECC work and I will present some of our new results. Okay, so briefly, SECP is a non native to its era, but it's the most widely used elliptical for classical cryptography that we have in our daily lives. So when we perform TL's exchanges, some of the passports. So for instance, dutch passports use this curve. Intel enclave SSH and passkeys.
01:27:09.144 - 01:27:57.282, Speaker A: So we had two talks referring to it in the morning. Thanks to them it has been specified by NIST. So as I said, it's non native that it has to be emulated with EVM instruction in order to implement it for a smart contract or smart output. Smart accounts and being so widely used, it's a natural candidate for account abstraction. So we had this very good talk by Ivo about account abstraction. So briefly, how this invisible wallet constructed is by using icon sub section with this curve. So this means that we are able to verify the the passkey framework on chain.
01:27:57.282 - 01:29:02.086, Speaker A: So it means that using your touch id, what you are really doing is you unlock the access to the private key that is stored in the secure enclave of your smartphone, which is the most secure components of your smartphone. It's actually a secure element and the related public key is is pushed to the user of ERC 4337 as your signer. And there is a little front that translates the transaction from the Pasky API to the on chain. So this use has been described by safe sooner. And also we had this, this MPC implementation over pesky. So I will be fast. And there are also some proposal to so mainly it was written by Justin Drake on Ethereum research.
01:29:02.086 - 01:30:02.554, Speaker A: It has been implemented by scroll and Tyco. And it happens that the Intel SGX which aim to guarantee the integrity of computation executed in the enclave is secure also by this curve. It's actually live on scroll on Taiko and actually they are not using your computation, but they could save a lot of gas by doing so. If there is someone connected to scroll Taiko, I would like to speak to them. So last year we deliver this fastest implementation. So we had two results. So a straightforward result without any additional deployments which cost 200k gas and one we requiring to deploy an extra contract for each public key.
01:30:02.554 - 01:31:23.950, Speaker A: So this is expensive. It's 3 million gas, but the verification is very fast down to 60. And if you compare to all the gas you have to spend when you perform a standard ERC 46 transaction, you already have something like around two to 300k. So this makes the signature that was overwhelming before. No, it's not that expensive related to the smart acute implementation. So depending on the use we provided these two implementation improving by a large factor pre awards and everything is described on the paper written here and you have a link to the repo implementing it. So what we did since then, we, we make things better, so we make it even faster without precomputation dropping from two hundred k to one hundred and sixty, only a few amount of extra extra call data, meaning that it's not fully compatible with RIP 7212.
01:31:23.950 - 01:32:39.646, Speaker A: But another very important point that we implemented is that we make this computation generic because today we are talking about the 256. But there are so many curves and many use cases that could benefit to have a generic scalar multiplication, meaning there are for example other ecosystem as cosmos is using the ED 255, there is a curve of stacknet, there is a framework palavesta. Actually the g one group of the b n curve could also be fastened by such mechanism. So generosity is also very important property. So this is a list of proposals of eips to make evolution to ZM protocol. And we don't know if tomorrow another curve rise or pop for some very convenient system we'll have to update and push again a new EIP. So what we propose would be to implement double scalar multiplication.
01:32:39.646 - 01:33:25.484, Speaker A: I will describe it later as one extra eip. So I will try to give the insight of how the pre computation works. So we had presentation yesterday by Lawrence and Armansh on elliptic curves. I won't go into deep details, but give the idea. So basically what you do when you do a standard scalar multiplication is an algorithm called double an add, which is the equivalent of square multiply. Anyone knows about those here one. Okay, not that much.
01:33:25.484 - 01:34:30.338, Speaker A: And what we do when we compute this elliptical elliptic curve scalar multiplication, basically we only have two operations, doubling and addition. And what those implementation are performing is that instead of computing the double and add separately for each point, when we do a double scalar multiplication, so two multiplication at once we are able to mutualize some of the computations. Here what happens in blue are the double, the number of doubles, the addition are in orange and in red appears the precomputation. So for instance the last line of the table figure the high amount of pre computation we have to perform with this extra contract. And so the two new implementation we are pushing are the two green lines. So one is still compliant with 70, 212 and a bit faster. And the EIP would like to push is the second green line.
01:34:30.338 - 01:35:33.564, Speaker A: So with these 512 extra bit of data we are able to have a massive gain in gas cost. So as I said, basically ECC is easy, you have points, what you can do with them, you can add them and you can double them. Okay, so only thing is that the scalar field is huge and there are a lot of points. Okay, so basically what you perform when you want to do a double and add, so we don't have to know what elliptic curve is? For instance, if I have an object and I can just add or double hit. The way double and add works is that I will look at the exponents and for each bit, if there is a one, I will double and add the input value. If it is a zero, I will just double it. So starting from p.
01:35:33.564 - 01:36:33.074, Speaker A: So from the most significant bit, I have a zero, I double it and I have a one. So computing the five p, I double again, I add p and this is five p. You have the same example for computing seven times the value q. So 13 from q double uniting is three q double uniting, it's seven q. The idea of the Strauss chamier trick is to neutralize the doubling. So you perform only one doubling and you will perform only one addition. So now if I look at this some p plus q, I have one point of precomputation h and looking at each bit of exponents, no, if there is a one on both line, I will double and add the point h.
01:36:33.074 - 01:37:23.594, Speaker A: If it's zero, it's only a doubling, and if it's zero, one of the line, I will add p or q. So doing this, we mutualize all the doubling and we keep the same number of additions. So basically Stroschamir is nearly twice effective as performing two scalar multiplication. And for higher dimension you can have more precomputations. But this is the same principle. So just a word about isogenies, because I guess some of you have heard about the ED curve. Someone knows about ED 255? Yeah, for instance, it's used in cosmos.
01:37:23.594 - 01:38:29.828, Speaker A: It's used, actually it's part of the Fido framework. Only Yubikey is implementing it and it has a very interesting properties. It's a schnorzenecture. Scharzenectors are very more convenient to implement MPC framework more efficiently and more securely. Because ECDSI is very error prone, there will be devastating consequences lately on the gain arrow scheme. So we really hope that at some point we'll have a massive switch to the ED curve. But actually you can, using exactly the same formula as before, which is a various stress representation of the P zero zero 256, you can convert your Eduard curves to the various trust presentation, perform using this unified code, the computation, and then switch back to the ED representation.
01:38:29.828 - 01:40:11.934, Speaker A: So this means that the code that we are pushing, so adding just those ezogenes enables us to implement the ED curve. So as a conclusion, so we implemented efficient and generic ECC progressive precompile. That means that we will deliver soon all the solid code associated to those results. It will be released around the 22 April and it's gonna be audited, which was not the case of the previous FCL and it adds generic ECC capacities to the EVM. But I think it would be interesting to push this as the rip. Currently there is a very interesting rip which is called MSM, but I think that maybe if it has not been implemented it's because it's very complex because it has genericity to the elliptic curves as well as unbounding the length of input and its use is restricted to some ZK scheme, while double scalar multiplication actually enables to implement most, most of the classical authentication mechanism, ECDSA, EDDSA, eck, CDSA, et cetera. So mainly what we will try to do is to find allies in l two to push this, to avoid to switch from one rip to another when we need to switch curves.
01:40:11.934 - 01:42:14.454, Speaker A: And that concludes my talk. Thank you very much Handel, for your presentation. And we still have some minutes for some questions. Does anyone have a question here? So no questions, but later, if you come up with an idea or doubt, Hanoi is like will be reachable outside or through LinkedIn Hanoi. Thank you very much. It so the next section we're going to have here right now to be presented by Mister Gauthier and the title of his presentation is the magic of native account abstraction on Zeitsync. He's also the founder of Zankai.
01:42:14.454 - 01:42:56.564, Speaker A: Welcome to the stage and have a good presentation. The stage is now yours, everyone. A pleasure to be here. My name is Gauthier, I'm the founder of Xi Fi, and today I'm going to show you a bit what native account instruction enables on zksync. Prior to building what we've built, I used to build a Defi super app, which aggregated and simplified Defi in one unified app. We've onboarded 21,000 users, and throughout this journey we've understood the complexities of cast for new users and even existing users. And I think we've all been through this experience where you want to do something on chain and you don't have ETH in your wallet.
01:42:56.564 - 01:43:51.374, Speaker A: And basically one way to solve this would be to have a smart wallet. And before jumping in, I want to look a bit about the adoption rates of account abstraction since it came out. And as you can see, we're seeing an average of 500,000 monthly active accounts, and we can compare this to monthly active users on EVR mail two, we're seeing around 10 million active users on l two s, 40 million on EVM L one s. And this results a pretty low adoption of account abstraction, with only 1% of users actually leveraging aa. So this is due to certain drawbacks of smartwallets. The thing is that in order to deploy a smart wallet, you need gas. It's eventually, in some certain cases, can cost more in guests as well.
01:43:51.374 - 01:44:44.276, Speaker A: And users do not want to change wallets. Changing wallets like changing your home or changing your bank account, it's something that users still don't do. I think most of us here today still use an eOa, and we can see there's a lack of interoperability with different types of other Dapps. So this is translated through different flow for eoas and smart contracts account, we can eventually see that EOS cannot interact with a paymaster. And this is different on ZkSync, basically, on ZkSync there's one, it's not loading. There we go. There's one unified flow, right? So eoas and smart contracts account can interact with a unified mempool and then thus interact with the paymaster.
01:44:44.276 - 01:45:45.254, Speaker A: So basically, UA's in some ways are considered as smart wallets on Zksync. So this was nice when we discovered this, because we saw a huge opportunity on the Zksync to create a gasless experience for the whole ecosystem. But we saw that a lot of projects did not implement their own paymaster because it was complex to create, because you have to customize it, you have to create your own business logic, and sometimes you even have to audit your own paymaster. So this is where Xi Fi came up, and basically we're building a paymaster as a service which supports any custom off chain logic. And this enables us to enable users, EOA users, to pay gas with any token they hold in their wallets. It enables us to create any type of sponsorship, different use cases. For example, let's say a user is a loyal customer of our perpetex, while we can offer him a certain amount of free gasless transactions.
01:45:45.254 - 01:46:33.938, Speaker A: And all this is integratable through a simple API call, some simple API calls, which is trustys, and I'm going to show you how. So let's say you're a gaslist user wanting to interact with a dex. What will happen is that the front end will ask a new quote for the Xi Fi API. Basically, it's going to build a new Paymaster transaction. So call data is not changed, but the API, for example, will fetch the token off chains of the user. Let's say user chooses to pay gas. With USDC, we will fetch the price of that token off chain, and then we will calculate how much of that USDC we need to take from the end user in order for our paymaster to cover the gas cost of that transaction.
01:46:33.938 - 01:47:30.880, Speaker A: So basically, we reconstruct the transaction data, adding paymaster parameters, including the fee token that we will need to take for our paymaster. So basically this transaction data is sent back to the front end user can then view this transaction new quotes and then he can sign. And when he's signing, he's actually as well approving the fee token that the paymaster can take to cover the gas. So this is done in one single transaction instead of two, for example. So then the Xi five paymaster pays for that transaction and then it also receives the fee for that specific transaction. So in this scenario, we're able to create a solution where eoas can pay gas with any token they hold in their wallets. So we've built an API, anyone can integrate this, whether you're an app, you're an app, or you're a wallet provider.
01:47:30.880 - 01:48:19.974, Speaker A: And we also created a front end where you can try their products, meaning that you can do swaps and then you can pay your gas fees with any token. You can come and send tokens, paying your gas with whatever token you have in your wallets, or even do custom transactions. So let's say you're in an NFT marketplace and you want to buy an NFT. You can just take that hex data, come to our front end and then sign that transaction and pay gas with any token you have to execute that transaction. So I'm going to show you some use cases from the Zksync ecosystem, some projects we've been working with. So basically projects have two options. They can enable users to pay gas with any token, or they can sponsor fully or even like a certain percentage of specific transactions.
01:48:19.974 - 01:48:54.118, Speaker A: We've processed around 150,000 transactions in the last two months. And so this is a small demo. This is how it works on our front end. Basically you're going to choose an input token and that input token is going to be selected by default as a gas token. So as you can see, my gas fee is calculated in the input token. And as you can see here, we were running a small campaign, so you were only paying two cent of that input token as gas. And then basically all the user has to do is a simple signature.
01:48:54.118 - 01:49:32.774, Speaker A: And as I mentioned before, the paymaster paymator's input is added into that transaction. So basically it's transformed into a Paymaster transaction. So this is one way to do it. We've been working with Gravitas Zirland as well. So here you can for example on gravitas supply, borrow GRI for example. And then here the project itself decided to take his own token as a gas token and offering a discount on that gas through its own token. It's also a way that that projects can promote their own token as well or use it for gas.
01:49:32.774 - 01:50:26.744, Speaker A: This is zero land, basically you can supply and then you can choose a gas token as well. And here this is another use case where basically this is a project that came up to us and said, look, if a certain user buys above $100 of my token, basically you can fully sponsor gas for that transaction. So in this case the gas is completely free for a user buying over $100 of this token. So this is different ways of how it's implemented in the UI here. This is a dex called mutes. Basically, as you can see here, you can click on this button. Normally it's ETH that is being used as gas, but you can also choose different assets and then all your transactions will be paid in those tokens that you have chosen.
01:50:26.744 - 01:51:12.434, Speaker A: And yeah, this is also another use case. So let's say you're an NFT holder. You can get free gas on the different dapps that integrated Zi Fi. So yeah, this is a bit about how we are evolving in the ZK sync ecosystem and how basically we're enabling gastro experiences for eoas. Eventually our Rip 7560 is being discussed at the Ethereum foundation and our goal is to go multi chain. I think Starknet already has native account abstraction as well. But eventually we see a future where gas is abstracted, especially for new users.
01:51:12.434 - 01:53:20.694, Speaker A: Thank you and I hope you enjoyed it. Thank you very much Gautier, for your presentation. Does anyone have questions here? Now we have time, so no questions. Thank you very much again, congratulations. It. Oh yeah. Thank you for.
01:53:20.694 - 01:59:27.246, Speaker A: Appreciate it. Okay. Also I didn't have access to perfect, but it was supposed to be okay. Hope it is. Thank you very much. Yes, it was ten minutes, right? Yes, it. So yeah.
01:59:27.246 - 02:07:17.754, Speaker A: Can you make sure that the slides are. Is there a way to look at the slides? Because I also. I was not sure. It starts at five past. I was a little early. It starts at five past pictures first is, you know, also do not want to English. We get nervous because they point cooking, but for all the time it's someone.
02:07:17.754 - 02:08:47.634, Speaker A: I did a lot of photography too as a journalist and also with concerts, it's the first three songs. Then I kick you out. Do you have a website? Do you have a website? Yes, if you want. It's okay, but it's. It's okay. You can. That's just Instagram.
02:08:47.634 - 02:09:33.654, Speaker A: Okay, cool. I have cats too, since three days. I didn't sleep a lot, but I think even on the Instagram days there links. It's older, from my girlfriend. It was in Madrid and I got it too. Here. So it has still a little bit of chat, like maybe.
02:09:33.654 - 02:10:29.598, Speaker A: Do you have your papers? Good morning everyone again. And good morning Mikaheu and Pooja. So now we are going to have another session here. And the title, it will be presented by Pooja Olhavar and Mikahil Nicolin. And the title of their presentation is compressed to zero. The silent strings of proof of personhood. Pooja Alhavr is a lawyer, innovator and technologist.
02:10:29.598 - 02:10:54.734, Speaker A: She's a member of the Gany Plurality research group at the Allen Lab for Democracy renovation at Harvard University. And Mikahu Nikolin is founder of Idena. So welcome to the stage and I wish you a very good presentation. And now the stage is yours. Great. Thank you for that introduction. Real full house for this talk.
02:10:54.734 - 02:11:55.494, Speaker A: So generative AI raises a number of questions and anxieties. Will it replace our jobs? Can we trust what's real? How do we govern it? And some these are questions around democratic governance, economic distribution and the authenticity of information, which is essential to both well functioning markets and. And also well functioning politics like democracy. Now this has spurred the rise of proof of personhood protocols, which aims to verify unique humans, paving the way for global democratic processes, Ubi and even AI governance. Now, the ambition of these protocols is simple. Represent each unique human with a corresponding unique digital identity, one to one. Now today we want to offer a critique based off of the experience of Idena protocol and their experiment in a paper we released just a few weeks ago entitled compressed to zero.
02:11:55.494 - 02:12:41.524, Speaker A: But first, why Idena? Well, Idena was the first proof of personhood blockchain with an endogenous network of validators with a one person, one vote consensus algorithm. Moreover, they succeeded in actually filtering bots and validating humans. And moreover, they stymied this problem of account trading with unique novel mechanisms. And account trading is where participants validate their accounts and then sell them off in a black market, which is a problem which plagues many proof of personhood protocols today, including worldcoin. So Idina had solved these problems. Now I will pass the mic to my esteemed co author and founder of Ideana Protocol Misha and he will explain the experiment to you. Thanks Pooja.
02:12:41.524 - 02:13:50.784, Speaker A: So first of all, why Idina was started. Idina aimed to address the challenges of proof of stake decentralization. We all know that capital is always heavy tailed, parity distributed and large staking pools have inevitable economy of scale, which lead to the fact that solar miners are vanishing, giving the way to oligopolies. Also, Adina aimed to solve blockchain scalability problem like a blockchain scalability problem, by establishing a network decentralized network of validators with excessive number of operators and facilitating sharding with parallel transactions and asynchronous execution with parallel state machines. Every node was intended to be operated by one unique human with unique account. So various proof of person protocols establish uniqueness in different ways. Unlike Walt coin and other protocols that relies on biometric data, Adina relies on online simultaneous cognitive tests.
02:13:50.784 - 02:14:48.720, Speaker A: It's so called validation ceremonies, which happen every few weeks synchronously for all participants. So it's based on the idea that you cannot be in multiple places at the same time. And by solving the flip tests, you actually prove that you are on bot. And the flip test is a test based on the user generated story, which makes sense in one configuration and it's meaningless in another one. So, for example, you can see the left sequence of images tells a coherent story about bee sting, whereas the causality on the right side is broken. So what happened? Adina launched in 2019. Accounts steadily increased, but as the network grew on chain data began to show some suspicious patterns of transactions, sending rewards from validated accounts to the same addresses at the same time.
02:14:48.720 - 02:16:07.974, Speaker A: And this kind of coordinated one way transfers at the same time and the same wallets implied automation, which requires third party key access to the participants accounts. So either these participants were unwittingly ceded their private key to third parties, or they just never had them. By December 2021, of the users contacted us and admitted to run the largest human form in the network. So in fact, high information operators pay low information participants, like puppets, to periodically perform validation ceremony and verify their uniqueness in exchange for controlling their accounts and their private keys. So puppets were either unaware about their private keys, or they knew their private keys, but were unaware about significance of the private keys within the protocol. So puppeteering was not a traditional the jury Sibyl attack, where malicious actors could fake multiple Sibyl accounts, typically using some algorithmic bots. But it was instead, as the protocol filtered bots and authenticated flesh and blood humans, it was de facto like a Sibyl attack of humans acting as programmable bots.
02:16:07.974 - 02:16:58.003, Speaker A: So at best, puppeteers extracted some amount delta between Ubi paid by the protocol and the wages paid to workers. At worst they could just take all the rewards of the puppet accounts. But was the picture so black and white pool operators also claimed that some awakened puppet were coming back. So they were just offering a service to consensual participants and being remunerated. Earning rewards on Idina is presented with number of hassles. So you need to run your mining node, you need to exchange Idina coin to the local currency. And all these hustles could be operated by, could be coordinated by the pool operators better than participants on their own.
02:16:58.003 - 02:18:14.024, Speaker A: In short, they were cooperating and simply providing service for some of the participants. So in reality, there are two extreme possibilities and the spectrum in between. Like the same transaction pattern on chain with this one, transfer to the same wallet at the same time could indicate like both puppeteering or voluntary cooperation. And both extremes differ not in how they look like on chain, but in the distribution of information and control off chain. So in case of puppeteering, operators have more control and more information, so they know how the protocol works, they know they control the private keys and by doing that they capitalize their symmetry, information and control in exchange for minimum wage payments and maximizing their value and extracting value from the protocol payouts. In contrast, cooperation has great asymmetry of information and control. So participants know how the protocol works, they control their private keys, but find it mutually beneficial to pool resources and delegate control, including their private keys to operator and for greater rewards with economy of scale, but at the same time keeping pull operators accountable off chain.
02:18:14.024 - 02:19:34.616, Speaker A: So despite of establishing a transparent network with individuals with unique accounts, the protocol collapsed into hidden groups and hidden sub networks. These groups, whether autocratic or democratic, were competing to control over fixed economic pie. In March 2021, rather than just fighting pools and slashing the suspicious accounts, idean community agreed like voted for the fork and agreed to bring these pools out of the unquantified shadows. The on chain delegation was introduced. This delegation gave pools economic incentives, so pooled account could earn mining rewards using only one node instead of multiple nodes for every account in the pool. But what's more important, with delegation, pool operators could handle operational hassles and earn accounts rewards without needing to know the participants private keys. So the delegation succeeded in making pulse transparent.
02:19:34.616 - 02:20:52.896, Speaker A: The green area shows the network pre delegation when accounts could not be differentiated, when accounts, even if accounts were controlled by the same pool operator and after delegation, the protocol could measure the size of the pools. So as the network grew, the growth was notably among large pools, which are red and pink, while solar counts, which are blue, constituting a smaller and smaller proportion of the network. Up until the peak of the puppeteering crisis in May 2022, the percentage of the solar counts in blue shrunk from 62% to 27% of the network. Large pools had reverse trend, ballooning from 22% to 61% of the network accounts. Large pools also captured a larger share of rewards from the fixed economic by dumping the idina coin price and squeezing rewards from solar counts. So the number of pools increased, and as they run a single node, the nodes as a percentage of the network in turn significantly dropped, leading to lower loss of throughput and security. So the purpose of delegation was to make coordinated pools visible and enable pool operators to handle operational hassles without knowing the private keys of the participants accounts.
02:20:52.896 - 02:22:02.018, Speaker A: But oddly, large pools continued to show the signs of third party key access with automated simultaneous or sequential transactions like delegations, account terminations, and funneling rewards before delegation or after termination of accounts. And looking at these factors, we examined top 31 pools that had ever been delegated to more than 100 accounts in the addendum protocol history, and all these top 31 pools showed the signs of third party key access. Moreover, some pools had financial ties and as we treat them as the same entity, then these 31 pools were in fact only 23 entities. So the puppeteering crisis reached its peak in May 2022. There were only 23 entities representing less than 1% of the distant entities, controlling at least 40% of the accounts and almost half of the protocol rewards. This prompted us to change the model to sublinear identity staking, which is the combination of proof of stake and proof of personhood. But this is the subject for the further research.
02:22:02.018 - 02:22:32.536, Speaker A: Thank you. Thanks. Okay, so Misha's damning statistic on less than 1% of the entities controlling the keys of almost 40% of the network's accounts. To many in this room, to most here, this is sufficient condition for, or sufficient evidence. Puny fasci evidence for puppeteering. Not your keys, not your coins. Kind of encapsulates his perspective.
02:22:32.536 - 02:23:20.164, Speaker A: But if we were to be charitable and take the operator's perspective, the pool operator's perspective, third party key control could be a voluntary choice by high information participants, presuming they could hold account hold operators accountable off chain. However, addressing this perspective and looking at the evidence, we observed a lack of disputes and complaints, as well as a lack of marketing of pool operators that would evidence accountable custody relationships. Also, notably, the jurisdictions of the large pools, lacked rule of law. Indonesia, Russia and Egypt. And then there were, of course, other factors. There were these messages from the largest pool operators. There was a meteoric rise and fall of accounts.
02:23:20.164 - 02:23:51.144, Speaker A: So based off of this totality of facts, we concluded that the. Excuse me. We concluded that the model of one person, one vote, one reward had simply collapsed into many puppeteered sub networks. And yet our analysis was still very cursory. It excluded other large pools between 15 and 100 accounts. It also excluded family pools with less than 15 accounts. So the statistics could only get worse, not better.
02:23:51.144 - 02:25:06.318, Speaker A: So I want to kind of take a step back and talk about the major takeaways of this experiment. And again, this is the first empirical study of a proof of personhood protocol. And proof of personhood is increasingly being touted as a solution to all these problems around governance and economic distribution. The first takeaway is that by giving humans economic incentives to periodically differentiate themselves from bots, even as low as two dollars to fourteen dollars every few weeks, the Ideena protocol had actually given more informed, resourceful humans financial incentives to puppeteer less informed humans like bots. And when participants traded their time for a paycheck from more resourceful humans, they ultimately transformed a system that was intended to be one person, one vote, into one token, one vote, where plutocrats and puppeteers gained outsized influence. Now, these economies of scales for the more resourceful to exploit is not something unique to Idena, but common to all protocols, all distributed protocols. As we mentioned at the start of this talk, other protocols validate humans in different ways, for example, biometric scans.
02:25:06.318 - 02:25:54.570, Speaker A: But just because humans don't necessarily have to run their own node or do periodic cognitive tests, that doesn't mean that they don't have hassles. That means they just have a different set of hassles, which intermediaries and operators will be happy to step in and readily perform. Which takes us to takeaway four. These exploits might not always manifest as puppeteering, but can also manifest as account trading. Now, as I mentioned at the start of the talk, Idena stymied account trading through novel mechanisms, notably identity staking. But other protocols, such as Worldcoin this past summer has had documented cases of account trading. We don't know the extent to which, so account trading in protocols should not be treated as evidence of advanced mechanisms or protections.
02:25:54.570 - 02:26:56.154, Speaker A: But to the contrary, account trading may signal a lack of them and be a precursor to puppeteering. Which takes us to takeaway four. The challenge of filtering humans from bots controlling accounts can't be separated from the information challenge. Proof of personhood seeks to differentiate humans from bots, not their biases. But as Idina demonstrated, when given incentives to differentiate themselves from bots, humans also have incentives to align, control, and puppeteer other humans like bots, to amplify their biases. And it's biases or the problem of faction that we care about when we're creating systems of, excuse me, democratic governance. This information challenge will only get worse and more acute as humans integrate biologically with neural interfaces.
02:26:56.154 - 02:27:59.004, Speaker A: The distinction between filtering humans from bots and humans acting like programmable bots will blur more, if not collapse, revealing a more foundational challenge than establishing biological uniqueness, establishing the informational uniqueness of participants, or the extent to which they cluster with the same interests or biases. Now, this is not a technical problem, but a social one. De facto sibyls, or puppets, or humans acting like bots, are the natural objects of colluders or puppeteers. By extension, de facto Sibyl resistance is a mutually implicated or mirror challenge to collusion resistance. Neither can be solved independently, but both, both must be tackled simultaneously. And finally, the last takeaway here is that thwarting on chain vote buying with novel mechanisms like receipt freeness or advancements and proofs of complete knowledge. These don't actually solve for off chain vote buying into meat space, but actually may encourage it as a low cost alternative.
02:27:59.004 - 02:28:47.944, Speaker A: Recall Idena actually undermined account trading with identity staking. So the next best alternative for vote buying became off chain puppeteering or buying participants time. Similarly, when on chain vote buying and trusted execution environments become costly, we can simply expect the more resourceful to move off chain. So the idea experiment underscores the importance of thinking in terms of incentives systems, interacting systems, and most importantly, acknowledging the ties that arise from both talking and trading. In future work, we examine the relationship between incenting unique accounts and stake in a paper called entitled between zero and one. And after that, we explore social identity as a richer identity system and beyond zero one. Thank you.
02:28:47.944 - 02:29:22.916, Speaker A: Do you have time for questions? Yes. So congratulations for such an inspiring and good presentation. We thank you very much. And now we have some time for some two questions. Does anyone have a question? Okay, thank you. I will take the microphone to you. Hi.
02:29:22.916 - 02:30:11.464, Speaker A: Okay, so, first of all, it's very impressive that you had the data to do an empirical study of how these protocols work. And I wanted to ask you, what was the most surprising result that, you know, I can understand? It's not easy to model and predict human behavior. But maybe you had already an idea of how it was going to work. So what was the most surprising result from the empirical data on social coordination? And then a question for me. Would you do anything different if you could go back on the protocol knowing then what happened? Yeah, I think the most surprising result was. Sorry. Two years ago, I co authored this paper called decentralized society, and we offered a critique of proof of personhood in about two paragraphs, which basically made these points.
02:30:11.464 - 02:30:41.480, Speaker A: And then folks kind of didn't take it seriously. And I was like, all right, well, let's actually do the empirical work and, like, substantiate the claims. And I was really surprised, actually, the extent to which there was puppeteering. So we only studied, like, the top 31 pools, right? And there was, like, over 400 pools, but those 31 pools constituted, you know, about 40% of the counts. Right. And that was puppeteered. And that didn't even look at, you know, the rest of the pools.
02:30:41.480 - 02:31:29.884, Speaker A: But when you looked at kind of in the paper, we show the distribution of stake and rewards in these other pools, and they show the same pattern. So we didn't go ahead and do the chain analysis, but there's pretty much a strong indication that probably most of the network was puppeteered, though we can't claim that. So I think the breadth and depth is what was surprising to me. Yeah, there was another question, right? Yeah. If I would start the protocol again, maybe I would start it with sub general identity staking as a starting point, because we don't have much primitives in the web three space. We have only token voting, and we introduced a proof of personhood. But anyways, you should start and then see how it goes.
02:31:29.884 - 02:32:05.324, Speaker A: It's a matter of experimentation, empirical study, and let's see how it goes. Thank you. All right. Yeah. So, first of all, thanks for the presentation. And I'm wondering, how does the competitive landscape look for you? And, like, what are some of the alternatives? Because, I mean, maybe I can't discern the difference between, like, proof of personhood or proof of humanity and other things. So maybe you can summarize on that as well.
02:32:05.324 - 02:33:28.204, Speaker A: I mean, I think some proof of humanity, any kind of, like, protocol that seeks to have one person, one account, and achieve this traditional civil resistance, de jure civil resistance, is vulnerable to this critique. I think the set of tools and set of, like, representations need to be explained, and particularly representing groups and relying on a web of trust as a complement to simply verifying unique humans. If you over index and solve and create incentives to solve one aspect, like verifying biological uniqueness. And it invites this information problem where people have an incentive to control humans by controlling their information. So the best kind of remedy, and we talk about this in the paper, is actually to expand the identity space beyond simple biological representations to representing memberships of groups. So if there's an analogy, there's representing individuals, right? If you think about social coordination, there's individuals, there's communities and civil society, and then there's nation states. And proof of personhood is kind of trying to just solve this, representing individuals, sovereign individuals.
02:33:28.204 - 02:34:16.054, Speaker A: And then a lot of KYC, nation state stuff tries to offer centralized authentication. And the thing that has been largely ignored is this middle level of civil society in groups, which actually is the best protection against authoritarian or top down control, and also the anarchy of just having a bunch of sovereign individuals that aren't operating within social structures. So actually using social structures as a way to complement identity, I think, is the way to move forward. Yeah. Okay, thank you. Thank you very much, Puja and Mikahu. Thank you.
02:34:16.054 - 02:36:02.734, Speaker A: So the next presentation that we are going to have, let me see if we're on time. Yes, on time. On time. Yes, on time. Very technical. So now. Okay, thank you.
02:36:02.734 - 02:36:31.534, Speaker A: So the next presentation we're going to have right now is by Z Pedro. And the title of his presentation is bring your own execution environment or by Oee. He's a dev real engineer at IStec. So Zipedro, thank you very much. And now the stage is yours. Hello. Good morning.
02:36:31.534 - 02:37:05.052, Speaker A: How is it going? It's been great, guys. I been enjoying it a lot, a lot of technical talks and everything. So for me, it's pretty cool. I like it. I'm a Devrel engineer at aztec clubs. And today we're going to be talking a little bit about proving and about wallets and their relationship. And why is it a thing with aztec? So a little bit on our agenda.
02:37:05.052 - 02:38:01.056, Speaker A: So the first thing we're going to be talking is about wallets, just as I told you, and signers and everything else that's going on about wallets. Then we're going to be talking about naming. And actually this talk had a different naming, but yeah, it was a bit censored. No, I'm kidding. And then I'm going to be talking about proving. And what does proving mean for rustic? And why is it such a big deal? So talking about wallets, first of all, like, if I see anyone else writing wallets, I'm going to ask them if they are considering client side execution. And this is why is this important? And why, why do I talk so much about client side? Why client side? Why client side? Why? Proving why? Proving privacy.
02:38:01.056 - 02:38:27.892, Speaker A: That's why this is important. Like privacy, right? Like we need to talk about this. This is like, this is key for us. Like this is key for blockchain. And hopefully at the end of this talk I'm going to be convincing you why. So what's wrong with wallets anyway? Like why am I talking about wallets? Actually, they're fine, right? There's no problem with wallets. They're necessary.
02:38:27.892 - 02:38:57.244, Speaker A: You need to store state, you need to sign over SCCP. Two hundred fifty six k one. Somehow you need to listen to the network, you need to do something. But yeah, oh boy, they will change. They will change a lot in the next few months because wallets, as we know, they aren't fit for privacy. And let's talk about it finally. Let's talk about privacy.
02:38:57.244 - 02:39:38.724, Speaker A: First of all, you have none. You don't have, you don't have privacy. Blockchain is amazing, but everything is public. You sign, you get transaction requests, you sign them broadcast and everyone can actually trace it back to you, which is amazing, but everything is public, so there is no privacy. That's 1st 1 second one. That's not acceptable. We think that how can we be happy when we're basically building some kind of weird orwellian surveillance state where you can see everyone else? That's not something that we believe it's going to be the future of blockchain.
02:39:38.724 - 02:40:19.924, Speaker A: So we are building this privacy focused l two and everyone is talking about l two. So it's not such a big deal that it is an l two, but it's important that it's a privacy focus. So basically it allows you for programmable privacy. So you code the privacy you want and some of it can be public, some of it can be private, but it's totally up to the developer to decide. Actually, you can say even everything is public on ASIC. The protocol is fully transparent. It's just that some of that information is encrypted only to you and only you know.
02:40:19.924 - 02:41:02.274, Speaker A: And so like we use tech, we develop our own tech, we roll on our crypto, we have our own, we have our own cryptography team, we have our own research team and we actually have done this before. So we are a company with six years old. And so we have done ZK money, we have done aztec connect, and we know what we are doing. So maybe like programmable cryptography, it's not this kind of thing. That will get you the hottest person in the room. Yeah, maybe ask the knR wheel, which is our, which is our smart contract framework. You should try it one day.
02:41:02.274 - 02:41:38.554, Speaker A: So merkle trees. Merkle trees everywhere. We only talk about merkle trees because if you can prove like ownership of something, you can prove something that can be, can be recruited by you. You can prove signature verification and. Yeah, did that kind of mention private native account abstraction? That's amazing. That's something that, again, a topic for another talk. You can do complex arithmetic, you can do message passing back to l one and back to l two and all kinds of other dark magic.
02:41:38.554 - 02:42:22.994, Speaker A: Then, like, what's stopping you for committing to anything at all? Just putting on chain and just do it like that. Like just work with Utxos like you've been doing with bitcoin and everything. So we call it a node and we will happily add it to one of our many merkle trees. So this is a trait like if you are used to rust, this is a trait that implements some kind of node. It just gets, it has an amount, it has an owner, and basically you can prove it. You can decrypt it, you can read it, you can change it. So like, in short, like, you can prove, you can read your notes, you can prove your role note is nullified in an index marker tree.
02:42:22.994 - 02:43:07.948, Speaker A: You can prove that the new note is added to the pendulum merkle tree. You can prove that the new state is changing the intended way. You can prove, you can prove, you can prove, you can prove many, many, many things. But why is this such a big deal for walls? Why? Why? I haven't yet touched. Why? And let's just give you an example of how things would be if your wallet didn't have a prover inside. So you visit a website, it may be a shady website, you don't know, right? Many, many legitimate websites are actually shady, right? So it gives you an aztec address for, for your private token transfer. You send the notes you want to nullify and the ones you created.
02:43:07.948 - 02:43:31.684, Speaker A: Then it tells you, oh, sure, let me just immediately steal your info. It doesn't work like that. It can't work like this. You just can't put your private inputs in whatever form on the web. The moment you write them, they can be just stolen by someone. It doesn't work like this. It just can't work like this.
02:43:31.684 - 02:44:27.888, Speaker A: And if you want private execution, if you want your private inputs to be actually private, they need to happen client side. And what does this even mean? Well, it means that provers, people prove their own execution in their own machine. May it be their cell phone, it may be their laptop. Asset contracts are just zero knowledge circuits and it means you need to bring your own proverbs. So you can prove stuff about your own information and you need to store your own information, you need to prove your own information, you need to serve your own information in your own wallet. So as you can imagine, it's not that easy. Like the contract you are executing doesn't know which nodes you want to nullify or want to use or want to create.
02:44:27.888 - 02:45:30.560, Speaker A: It doesn't know your keeper, it doesn't know anything. Does it sound like a wallet? Now it looks like a wallet, sounds like a wallet, swims like a wallet, cracks like a wallet, but it's actually a private execution environment. So let's talk about this name, private execution environment. Like what's in a name? We need something that is for privacy, we need something that is a wallet. It needs to sign transactions, it needs to sync with an azure, it broadcasts things, it listens, it does everything that the wallet does. You need a private oracle because again, if no one on the network knows what we're trying to change, people don't know what contract are you executing, people don't know what notes are you adding. It doesn't know anything about you.
02:45:30.560 - 02:46:18.284, Speaker A: So you need to serve that information in your wallet and then it's approver because if only you know what you are executing, then obviously only you know it's in input, so only you can prove. And so you are going to have to run that in your phone because that's where people use the Internet nowadays. And so you can trust a third party. Everything needs to run on your phone. This is aztec. Something happened to some state in some contract, so you need to tell them what happened in what state, in what contract. Only you with your wallet can know this.
02:46:18.284 - 02:46:50.604, Speaker A: So we had a bit of a discussion about naming. Like naming, right? Like what is it? Like, it's an RPC server, right? It runs on your machine, it acts as an oracle, it serves your private inputs, you simulate, you prove your execution. It's an aztec RPC server. Okay, not good. Let's try another one. It's a private execution environment. It's mostly approver, it's a prover, so it stores your nodes.
02:46:50.604 - 02:47:12.948, Speaker A: It serves your nodes. It syncs with the network. It's an execution environment, it's a proverb. So now we have p instead of ours. We're getting there. So we just ran out of ideas because actually the PXE is just more than this. It's a private execution environment.
02:47:12.948 - 02:48:00.134, Speaker A: Let's just take the E and place it with an X. Now you had to teach people how to say pixie, not to say pixie or say pixie or PXE, but we know it's not a wallet software. We know it's not something, it's not actually a wallet. It's something that allows you to build your own wallet. And this is why I'm here. I want you to build the wallet of the future that comes with a pxe with this service that will allow you to execute your nodes, execute your contracts, provide your notes, provide your keys, and do that in a private manner. So that's why I'm here.
02:48:00.134 - 02:48:35.584, Speaker A: So I prove, and proving is peak self sovereignty. Proving is a cyberpunk stream. Your identity, your data, everything will be protected by strong cryptography. This is what they wanted, right? So web one was mostly about reading stuff. Web two is about reading and writing stuff. We are all here talking about web three, which is about owning stuff. And this is true, you own stuff.
02:48:35.584 - 02:49:06.324, Speaker A: And I like to say that web four is about proving. So not only you own stuff, but you also prove that you own stuff. So you don't need to tell everyone what you own. You just proved that you won when you need it. Actually, I don't even understand. How can you make a privacy protocol when you're just handing your private inputs to everyone? Honestly, I don't see. I can see.
02:49:06.324 - 02:49:36.664, Speaker A: So you need to do it yourself. So where do we go from here? Can we commit to some kind of timeline? We can't, okay. We don't know because we're breaking through unknowns. Unknowns. Everyone here is, but yeah, we're just some things we know that are possible, some things we don't even know. That's why we have a research team. And so it's difficult to commit some kind of timeline.
02:49:36.664 - 02:50:05.974, Speaker A: But you already have a developer sandbox, which is a local development network. You can go try and try your own business logic. It doesn't prove a lot. It doesn't do much actually. But this is where we are and you can try it. We are developing some kind of hard hardcore cryptography. I mean, if you're technical, you probably heard about proto Galaxy, Goblin, tonk ultra honk zero movie, all these primitives that we're building.
02:50:05.974 - 02:50:49.774, Speaker A: But basically what we need is big recursive proofs in less than 10 seconds. This is on your phone. This is our goal, this is what we want. Then we are iteratively building the other side of the aztec network, the roll up, the sequencer, the bridging, the prover network, all this parts that are needed. But the PXE, you can already try, but these components are still needed to be built. And then finally we're going to be decentralized at Mainnet. So yeah, this will happen somewhere, I guess, next year.
02:50:49.774 - 02:51:15.894, Speaker A: So if you heard local development network, this is something I need to tell you about. We call it the sandbox. And yes, you can try already. You can try your business logic. Everything is noir. So if you've written any rust, you are perfectly capable of building with noir. I didn't know any rust before I tried noir and it was just fine.
02:51:15.894 - 02:51:56.312, Speaker A: It's a nice language and yeah, you can basically get started with everything that is in there, but it doesn't run a proof yet. So if you want to get started, just follow this meme. That's basically the smallest instruction manual. But yeah, you should definitely check the docs and some links for you. This is the aztec discord, which is a very hidden link. You can maybe zoom in and join. It's a very technical discord.
02:51:56.312 - 02:52:40.418, Speaker A: So if you go there on CGM, I'm going to ban you automatically. Then you have aztec docs. This is important if you're trying the aztec development network, but also if you want to know what is the lower level concepts, if you want to learn about index, marker trees and everything, that's everything is in aztec docs. This is my ex or Twitter, formerly known as Twitter. And my telegram. If you want to talk with me, feel free to just zoom in and scan these QR codes. And let's talk about your development of a wallet.
02:52:40.418 - 02:52:55.566, Speaker A: An aztec wallet. Cool. I think we may have some questions, maybe. Yes. Zipedro, thank you very much for such an inspiring, nice presentation. We learned much from this and now we have time for some questions. Does anyone have questions? We can.
02:52:55.566 - 02:53:12.998, Speaker A: Thank you. The microphone. No questions. Okay. So if you don't have a question right now, you can also reach him through those links. And we are glad for your attention. Thank you.
02:53:12.998 - 02:59:39.548, Speaker A: Thank you again, Zipid. Thank you. It. Good morning again, everyone. Good afternoon already. Sorry. The next presentation that we are going to have right now is the title is decent centralized id for those who need it most.
02:59:39.548 - 03:00:22.154, Speaker A: It's going to be presented by. Let me open here by Mister Alexis Ivaschuk. He is the founder of Apatriot Network, a coalition of stateless individuals, communities and stateless lead organizations working on addressing statelessness in the European Union. He is also an associate member of ANS, co lead of global movement against statelessness and servers on a site advisory board of organizations lead by the forcibly displaced and statelessness. Thank you very much for your presence here. And now this stage is yours. I wish you a good presentation.
03:00:22.154 - 03:01:13.076, Speaker A: Thank you very much for the introduction. And I would like to start out with a caveat that I work in human rights field, so my presentation will be more about the social impact of blockchain. I have tried to make the presentation as accessible as possible because recognizing that I work in a different field than many participants here might be used to. So in our field, we're noticing that blockchain based solutions are already making an impact, some positive, some negative. And it's important to talk about these things and to share knowledge between our two fields. So my presentation will be about that. So I will break it down.
03:01:13.076 - 03:02:06.556, Speaker A: It's very simple. The first part of it will be framing the problem, talking about what is the problem that we have with the rise of blockchain based solutions, or lack thereof. And the second part will be focusing on solutions. What are the solutions that we can look forward to with blockchain that can help not just the most vulnerable populations in the world, like the stateless exiles, political dissidents, refugees, and so on and so on, but also everybody, because everybody is impacted by the risk of having your proof of identity being tampered with or taken away. Political winds change. Nobody can predict them. And so my family never knew we were going to end up being stateless.
03:02:06.556 - 03:02:53.266, Speaker A: We're natives to European Union, but we don't have a proper legal identity. We're not given that. And I'm not going to get into too many of these details. I will start out by framing what is the issue that we're facing. So when you think of proof of identity, proof of residence, proof of your nationality, all of these things are crucial to allowing you to exercise your rights. If you don't have a nationality, then you don't have a right to have rights. When you don't have residence, you also are lacking many rights.
03:02:53.266 - 03:03:49.654, Speaker A: So there's a big difference between the two. But for the sake of keeping things simple, we'll just term it as lack of legal identity. But obviously you can break it down into further details as to whether it's residence, nationality, citizenship, et cetera, et cetera. So the question is, the critical question is who issues your legal identity? Moreover, who owns it? If you were to open up your passports, you might be surprised to read that you're not the owner of your legal identity. I'm surprised people are surprised about that. The legal identity that you have is owned by your government to whom you belong to. And we have romanticized this whole notion of belonging, but it's quite literal.
03:03:49.654 - 03:04:48.134, Speaker A: You are owned by this government, you are something useful to this government, and in exchange for being useful, you are granted certain rights because you are granted legal identity. Now, throughout history, of course, academics have talked about various monopolies that state actors have had. So state actors are the authorities that issue your legal identification. They have absolute, complete monopoly over that. Historically, they have had absolute, complete monopoly over violence. So that's something monopoly that is talked about more, but other things like monopoly of identification, the media, data currency hasn't been talked about much. And it's very interesting that some of these centralized monopolies have begun to give way to decentralization.
03:04:48.134 - 03:05:45.794, Speaker A: This is why with cryptocurrency, we have decentralized currency. There's no one authority that issues the currency. Now, in human rights, that's already relevant. But what interests us more is the potential in decentralization of identification. When you think of centralization of power, whenever you have any absolute power given to any human institution or any human, it's a bad idea. You're going to have a lack of accountability, and you're very likely going to have abuse and corruption and misuse and just tampering. Now, in the world, there's a billion people who lack legal identification.
03:05:45.794 - 03:06:42.100, Speaker A: That number should be mind boggling. That's a statistic from the World bank. Now, I drew a little gradient there. Among these people, there's various vulnerable people in the world. So there are the stateless minorities, refugees, exiles, indigenous people, et cetera, et cetera. And it's interesting that that among all these people that lack legal identification or lack properly legal identification, because some of these people might have some form of legal identification, like a tolerated stay or temporary residence, or just a piece of paper from the police stating that they were arrested and this is their name. All of these people are extremely vulnerable based on what kind of id they hold.
03:06:42.100 - 03:07:47.730, Speaker A: Now, on the gradient with the state actors, we have the competence side. That's the perfect state actor that never discriminates, that effectively can identify all of its people that is on its territory, that is able to fairly issue identity papers after it has identified all of the people on its territory. That utopia doesn't exist. There is no country in the world that is capable of doing that, never mind actually doing that. So usually we have something in between happening, and then malay side. Unfortunately, that's, and I termed it that way on purpose because when we have state actors refuse to grant identity papers or discriminate, it's not based on any rational grounds. It's usually due to phobias like xenophobia or due to racism.
03:07:47.730 - 03:09:27.204, Speaker A: 24 countries in the world don't allow women to pass on nationality. Some countries in Europe only recently started to allow women to pass on national, like Netherlands, they only started to allow women to pass on nationality from 1985. And so that impacts heavily what kind of identity papers people will have. So whenever you have a state actor afflicted by malaise, you will have potentially have them be malicious. This is why in countries like Myanmar, we have a very authoritarian state going after its minorities, refusing to issue them proper identification and just ethnically cleansing them and trying to kill them off. So we have this gradient, and in between there's much, I want to call it mess. And so that is a problem that we're facing, and it is something that affects everybody, like I said, because various groups in the world that are currently vulnerable among many of these people are people of yesterday that were perfectly stable in their life and had an equal identity paper to that of other fellow citizens.
03:09:27.204 - 03:10:49.314, Speaker A: But in came some sort of political change. And I'll give a specific example now with Belarus, which is currently making half a million people stateless in Europe, and it's making these people stateless because four years ago, these people went out to protest against the government that people were not in agreement to the unfair elections that were done in Belarus, and the government cracked down. And so half a million of these people left the country. And since Belarus, like any other state actor, has absolute monopoly on issuing identity papers, has that centralized power, and also combined with absolute monopoly, as with any other state actor, on determining who belongs, they can easily punish their dissidents. So that's another way people become stateless. And of course, I'm talking about statelessness because I'm a specialist and statelessness. So I'm bringing up examples in that regard in regards to other vulnerable groups here, like indigenous populations in Southeast Asia, you have various indigenous nomadic people.
03:10:49.314 - 03:12:30.074, Speaker A: And so they don't get their papers because they get discriminated against because they're nomadic. Well, in Europe, we have something similar with Roma. They face a lot of discrimination because they're more mobile, they're not as settled, and there's a lot of prejudice toward them in that regard. So the point being is that current vulnerable groups are not, how do I put it? Anybody who has citizenship now, anybody who has identity papers now that doesn't secure you in the future, because any state actor cannot guarantee to you security in the future, because political winds change, different governments get elected. And it should be a disturbing thing to consider that more and more state actors are increasing, gathering of data and control, and trying to control that data. And so you have a situation where you have more centralized power becoming more powerful. And then if the ownership of that data is in the hands of a government that does not have good intentions, and nobody can guarantee what government will exist in the future, you have a serious risk factor for everybody, not just the current vulnerable groups.
03:12:30.074 - 03:13:22.744, Speaker A: And so that brings back the question of why? Why blockchain? Why are we talking about this topic? And as somebody stateless, but also being aware of how other stateless led communities, stateless led organizations, organizations are utilizing blockchain, the solutions are already here, we're already using them. It's not a question of if or how. So a simple example is that when you go to the bank, what do they ask you? Let us see your legal identification or anything else. Education, employment, freedom of movement, legal identification. And they don't care if you say, like, well, my government discriminates against me or discriminate against my mother because she was of female. They don't care to hear that story. They just need to see the identification.
03:13:22.744 - 03:14:47.706, Speaker A: And so various stateless people already recognize that, well, the bank is not allowing me to have a bank account. I can open a crypto wallet. So blockchain is being used that way. But decentralization of identification, proof of identity, and ownership of identity is a much bigger deal, because as I started out the presentation, I talked about how legal identification is a gateway to all rights. Now, it's a big question, of course, for the future as to how much acceptance there will be of blockchain based solutions, decentralized identification. But the need is clear, not just for current vulnerable groups, but for everybody, because your government may also change, whether democratically or through a coup, it doesn't matter. And we should also already draw the lessons from history, as was the case with Nazi Germany, because they have used identity, and identity stratification in a very ruthless way, and that government was elected.
03:14:47.706 - 03:15:52.204, Speaker A: So even democracy cannot prevent such things from happening. So with more and more data, there needs to be security, not just from hackers, not just from criminals. We also have to make sure that we help the state actors themselves to fulfill their one role that they have in providing security to its own citizens and their own members, because they cannot guarantee what power will actually be there in the future. So the good news is that we carry much of our id data with us. It's your face, it's your fingerprints, it's your DNA. You can adjust your identity proof in various ways. And sometimes I think about how crazy it is that in the 21st century we still carry little pieces of paper or paper booklets as proof of something as important as our legal identity.
03:15:52.204 - 03:17:19.614, Speaker A: But of course, if we have a really strong proof of identity, it's going to be very important to consider who owns it, because if all that data about you, about where you graduate, about who your parents are, about your DNA and so on and so forth, you can adjust the gradient. If that all of that data is ownership of a centralized power, are we asking for trouble? The answer is yes. So the real solution is really with decentralization. And it's exciting to see various projects come up within a previous presentation. I've noticed id knows here, but they are more about proof that you are human. But a lot can, can be tied in, or a lot of lessons can be drawn from that project in terms of one person owning one id. And there's various others like ontology and other blockchain projects that create a market of various solutions to people about exactly this topic of decentralization of identification.
03:17:19.614 - 03:19:15.206, Speaker A: So the need is really strong for us to have decentralization of identification not just for the most vulnerable populations, but for everybody in the future, but for the vulnerable populations. This is particularly the case because if you are in a situation where you get stripped of your citizenship or nationality, you need a plan B. Wouldn't it be good if there was any form of id, even if it's a weak form of id, that if you've stripped of your nationality, if you no longer can use your passport, if you can no longer show in any way that you are who you are, wouldn't it be good to have any form of decentralized id that you can use anywhere, that it's accepted as a backup plan in case you're punished for being a particular ethnic group or being part of a particular ethnic group, and so on. So to conclude, I want to say that with blockchain based solutions, there's a lot of potential good that can come out of this technology. But we already see the harm. Just like with digitalization, we see governments having a head start with all their resources, with all their connections, and of course, monopoly on violence. When they, for example, approach crypto exchanges and say, well, we're going to regulate you, you can bet that they're going to import some of their preferences and some of their biases into that regulation.
03:19:15.206 - 03:20:52.424, Speaker A: And that's an issue we're already facing. That's not a theory I've personally faced. This issue in terms of binance doesn't accept various forms of ids from vulnerable groups and various other crypto exchanges because they're just not familiar with it. What is this? And so you're left on the sideline and we see this time and time again, like in countries like Kenya, where digitalization is being driven forward, but it's the government that has being plagued by various discriminatory policies that it has in place that is influencing the technology sector to import this discrimination. So it's important to have a more equal balance intake of feedback, not just from state actor authorities top down, but also from the most vulnerable users. And that's why it's important for the blockchain sector to build these connections, to make sure that it is actually adding value to the world and not harming especially those who tend to benefit the most from technology, but also the most vulnerable in regards to the current realities of different societies and discrimination therein. So I will stop right there.
03:20:52.424 - 03:22:23.106, Speaker A: And just as a last thing, to initiate the whole advocacy campaign for better, more responsible use of blockchain, several leading groups of coalitions of stateless people and exiles and refugees combined forces and are creating what's called blockchain for human rights Advocacy Network. And the launch of it will be on April 12 here in Impact Hub Zurich. It will be about creating the connections to the blockchain sector to provide input about what is actually of value to those people who want to use the technology to access some basic human rights and to try to create a balance between such groups and of course, the state actors who have their rather strong say in the sector. And so you're most invited to attend there. And I'll stop right there. Thank you, Alexis. Thank you very much for your representation.
03:22:23.106 - 03:23:21.694, Speaker A: Very important and use of the technology and really inspiring. Congratulations. Does anyone have some question? Okay, the microphone is going toward correct, right. I can put whatever information I like on a blockchain, right? I can give a fake name, fake address, fake employment records, fake education, fake everything. I mean, who's there to attest that the information is correct? And then who determines and will be accepted? If I show you my passport, you accept that's my passport data and it's accurate because it's come from an authority that we do trust. Yeah, that's a great question, and I want to break it down into parts. So first of all, the trust and estate actor, right? That's something we were brought up from a very early age.
03:23:21.694 - 03:23:50.074, Speaker A: Trust it like you would trust a God. I would question that many state actors are committing many human rights violations. It's very hard to find a state actor who is not committing some sort of corruption or human rights violation. So there's some issues with that. There's a lot of incompetence. We've had plenty of cases in human rights where a person's file is just deleted because the bureaucrat didn't want to deal with it. We have a lot of issues in this regard, and so we want to paint a more accurate picture of what is the actual problem.
03:23:50.074 - 03:24:27.630, Speaker A: And so we should trust a responsible state actor, right? But like I said in my presentation, we have a little bit of a dilemma that with any monopoly, absolute power, no matter how responsible that actor wants to be, power corrupts. An absolute power corrupts absolutely. So we need to do this not just for the sake of ourselves. We need to do this, like I said, to help the state actors because, sorry, that's people. Right. And sure, we can create a platform, pull out of data. We're all corruptible.
03:24:27.630 - 03:24:59.780, Speaker A: We all have our own biases and influences. Yes. I guess my question to you is, what system do you put in place to ensure that whatever data I put on a blockchain that you assert should be valid as identity data is true? Because you need that data to be verified in order for it to be relied upon. Right. And I mean, we're not looking to overwrite the state actors. We're looking to create a little bit of competition, a healthy competition. And so the important.
03:24:59.780 - 03:25:44.454, Speaker A: And so the second point I was gonna go into is that, and like I mentioned in the presentation, a lot of the data for identity is actually already public, and it's something that state actors can't own or control. So not just in terms of facial recognition and so on and so forth, but even going to more abstract things like a name or your parents connection to your parents or your place of birth and date of birth. These things, for instance, are already being sort of confirmed, issued by, in some countries by hospitals. They don't have a connection to authorities. They do it themselves. Right. The hospital is an authority.
03:25:44.454 - 03:26:00.302, Speaker A: You're trusting a centralized authority. It's the hospital. Yes. In fact, it's the midwife at the hospital. Yeah. So the more competition, the better, is what we're saying. So we are for the hospitals to be independent.
03:26:00.302 - 03:26:41.538, Speaker A: You know what I mean? If they are actually a centralized public authority. If the state actor tells them, like, no, don't issue documents to such children and childhood statelessness is a huge issue right now. We can at least try to work on resolving that, right? So by encouraging hospitals to be independent of any political discrimination or biases, that's a fraction of what we can do. So it's important. But another key thing is that just like when you're learning a new language, you don't need to come up with. You don't need to learn it in its own language. You can use the old language to learn a new one.
03:26:41.538 - 03:27:20.186, Speaker A: So the same logic in terms of coming up with blockchain based solutions, a stateless person or other vulnerable person, they will have documents. And that's another reason, another way we're utilizing blockchain now, like Rohingya project, they are using it for archiving because the government wants to destroy these documents. They want these people to stop existing. But blockchain is being used to conserve these documents. Land leases and education certificates and so on. You can use all of that. I mean, the potential is mind boggling.
03:27:20.186 - 03:27:49.670, Speaker A: So it's not a question of which centralized authority should we use instead of the old ones. No. The more competition there is in creating the centralized identity, the better. And the same goes for we need to make sure, I think personally we don't have one powerful corporation creating decentralized ide that will become widespreadly used. No, it should be more like credit cards. This one doesn't work. You go to the next decentralized id that can verify you.
03:27:49.670 - 03:28:34.006, Speaker A: So competition is key. We need to make sure to avoid too much centralization of power. Does that make sense? Yeah, I completely agree with the sentiment, but I think putting it into practice sounds incredibly difficult. So if you've got Rohingya data now on a blockchain, you now need to turn that into an identity system. You then need the world to accept it. Right? So the question the world then asks is, how do we know that the data's been put on is actually true? Right? Who are the people that put it on chain? Do we know that? Do we know that the documents have been uploaded, are actually accurate and correct and relate to that person? With that name? There could be a thousand people with that same name. How do you know you put the right information relation to each? I think that the alter is.
03:28:34.006 - 03:28:47.814, Speaker A: I don't want to be polite, but I have to end the conclusion, please. I don't want to be polite, but I ask you to keep the conversation outside because we are very late for the next section, and I thank you very much for all and have a good day. Thank you, Alexis. Thank you.
03:29:25.734 - 03:29:26.674, Speaker B: Thank you.
03:29:30.754 - 03:30:23.658, Speaker A: Hello everyone. First of all, I would like to ask you to give a big applause to Carlos, who've been moderating the panels the entire morning. I'm very glad to be here. My name is Kinga Pilat and I represent women in Webfree, Switzerland. If you would like to hear more chat with me during the lunch break, during the coffee break. First of all, before we start, I would like to quickly check the energy level in the room. Let's say on the scale from one to ten, who would say your level is below five? Can you raise your hand above six? Seven? Is it nine? Is it ten? Okay, great.
03:30:23.658 - 03:30:47.926, Speaker A: And I'm sure the upcoming session will be also very energizing. So without further ado, I would like to introduce Sogol Malek, she's core developer fellow at Ethereum foundation, and she will be talking about efficient light client framework for stateless verification. The stage is yours.
03:30:48.030 - 03:31:27.112, Speaker B: Thank you so much. Hello everyone. Thanks for joining this conversation. I'm very happy to walk you through my current contribution to the core Ethereum from the stateless team and just walking you through the efficient like client for stateless verification and the VAACL three era afterwards. So I've launched this PoC last year at Devconnect in Istanbul, November 2023. So the GitHub is often working if someone is interested to have look into the source code. So let's jump into the motivation of this work.
03:31:27.112 - 03:32:19.044, Speaker B: So I wish that everyone in the room has heard that one of the biggest problem by Ethereum at the moment is like state bloat. We have seen so far the monotonous increase of block size and witness size. As you can see for example, in the picture we have seen, we have hit actually three hundred k bytes of block size just in a few past months. And obviously we would face to the other problem of overhead of if MPT with a large number of input output operations, which requires to sink a block. So the big size of thickness is required. Obviously that must be transmitted over the network per block. And as a conclusion, increasing the number of input output operations increases the block verification time as well.
03:32:19.044 - 03:33:30.680, Speaker B: As you can see also in the right hand side, the increase of number of operations increases the blocks in time which reduces actually the efficiency of doing of block verification. At the moment there are a type of different clients, or at least the client types as we are familiar with that they are full nodes, lite clients and we enter into the era, we would have stateless lite clients with cryptographic proofs. Here is a general overview of the efficiency and security of those client types. So fullnode is the most, most secure type of clients in general with the least efficiency grade. They can download and process entire transactions and store the entire state, and they demand significant resources. And they are mostly the most impractical type of clients for mobile devices. There are other type of like clients that are better integrated terms of efficiency, but maybe less secure than the full nodes.
03:33:30.680 - 03:34:26.674, Speaker B: Lcs that we are all familiar with are sort of burdening the full nodes by incrementally requesting block state. For example, each client just calls the full nodes piece by piece to gather data they want to verify. And imagine that altogether calling a full node makes a lot of burden. And also they could be more vulnerable to potential data manipulations or tampering during the verification progress. And that's the motivation that we wanted to have sort of new state like clients that have sort of cryptographic proofs with them at the end. We have sort of stateless like clients which are coming more type of those clients after the era of vehicle tries. But this work at least is to show like how that era would look like they are more efficient because they don't need any type of hash routes of the entire block headers.
03:34:26.674 - 03:35:23.296, Speaker B: And of course they are more secure due to the extra cryptographic proofs. They reducing the computational and I o requirements for transactions. They can validate transactions much efficient comparing to other types with minimal data transfer. They are ideal for low bandwidth environments like mobile phones for example. And they can also ensure the integrity of fitness data, resisting tampering and ensuring the authentic transaction validations. So what's the goal as people at EF constantly speaking about this, everyone's weak statelessness as like the most mature type of, you know, statelessness at the moment. And the state is not required to be fully validated nodes when we do have such a thing, even like it too, validators would not need to have the full state.
03:35:23.296 - 03:35:59.200, Speaker B: And it allows for protected like clients. They literally can validate single block as a fraud proof. And that's it. They don't need to do anything more. So we can means here block builders or validators still need this state. So it's not fully stateless in that content, but it means that actually dynamic state access isn't a problem anymore. So for more information on big statelessness, I would encourage you to check dank rotfe writing in this frip flow.
03:35:59.200 - 03:36:40.166, Speaker B: And the the goal of entire presentation today is to introduce you to a client that is able to verify the correctness of a block without any information, extra information expect for small type of proof that every state holding node can generate, and we call it as a witness. The witness contains the portion of state accessed by the block along with the proof of correctness. And that's like the general definition. So yeah, stateless, like client witness. There is some numbers there. I just wanted to give some insights. The size of the witness.
03:36:40.166 - 03:37:27.454, Speaker B: Actually, instead of a client just holding the state, the client holds the state roots. Witness the portion of state that are read and modified along with the proof. So just to have some idea about the numbers total state size, we can consider n typical n is two power to 30. And the k objects accessed by that block is typically like two power to ten. So the witness size we can calculate here easily is sort of number of 600 bytes. Access in practice becomes like 600 kb by block fitness. So obviously it's like the chunks plus the objects themselves that are involved.
03:37:27.454 - 03:38:20.210, Speaker B: So let's have a look on the gas estimation of these stateless blocks. So here is a general overview and calculations. So I just compared disk space and also the sort of, yeah, the gas cost for both traditional weaknesses produced so far at ethereum, and also when we just compress them even further with zika snarks. So as you can see, like the cost of average Gauss gas. Sorry, it reduces when you have like compressing your witness with the snark. And also the space that is required by snarky of witness is even less than the traditional witness. So we can save a lot of disk space as assume so.
03:38:20.210 - 03:39:11.754, Speaker B: Yeah. In terms of having even more gas friendly, kind of like clients, there are a type of different snark proofs. But actually the SHA 256 is the most inefficient hash function for the case in this example. So because, you know, comparing to other type of hashing processes, the researchers came in with the idea of using Poisson t three hashing. So it has some good reasons to do so. One is efficiently hashes to elements ideal for binolumerical trees, which they are, and facilitates cryptographic proofs and data integrity verifications. The gas cost, by the way, can also have sort of a trade off compared to vehicle tries.
03:39:11.754 - 03:40:56.576, Speaker B: It's not like the best option, just replacing the vehicle tries. It is like the intermediary solution up to the point that we can have vertical tries, but at least it is still more efficient than what it is. So it requires updating hashes from the new leaf to the root and also gas cost increases linearly with its free depth due to the hash updates. So again, it's not like the better option than vehicle tries, but at least to compare initialization cost for this type of snark involves hashing and caching zero leaves for each level, and costs unfortunately grows linearly with the depth of the the key takeaway here is that Poisson t three s are more efficient in hashing and enables scalable and secure incrementals Macl trees if you don't want to change completely the architecture of Ethereum as it is with predictable gas cost, scaling linearly with the three depths as a trade off here. So this table just shows a little bit sort of overview of the costs of this type of snark. And just to give you some sense, how much are the gas cost when you have capacity to insert values into the binary incremental merkel trees? So yeah, we are moving towards stateless Ethereum, from traditional like lanes to stateless cyclones and to record price. I just recently published sort of article on Ethereum research.
03:40:56.576 - 03:42:05.014, Speaker B: If you'd like to check it out, I just discuss it more in details and comes time to explain about EAPX, which is a proposal of mine under the supervision of Guillain Bella, the lead of vehicle Troy and Piper Miriam, the lead of portal network. And we thought that this can at least be more production ready, rather vehicle choice. Meanwhile, so I said there are diversity of light clients. So in this case when you have sort of stateless like clients, you will end up having more type of clients just running and syncing with the entire network faster. So instead of running minority clients, you will end up having multiple clients that are less expensive. We can run sort of stateless peer to peer clients and ask validators to cross validate the ZQ proof with other clients statelessly, which is the goal of this architecture design. We can also have enhancing blockchain security and efficiency.
03:42:05.014 - 03:43:13.748, Speaker B: The current progress is as follow. So you execute a bundle of transactions and compare the results with expected outcome in the block header. But in a proposed architecture you can have, you know, during the execution you can create a witness for the block and after the execution you add sort of extra step which is a cross validation of the peer to peer and you can send the witness to various clients for status for the benefit. Is that increasing the security by validating transaction across multiple clients and just because again, it's super simple and super fast to get synced within rest of the network, it increases the diversity and also ensures accuracy and integrity of the blockchain without heavy resources being used due to the cryptographic proof of CK. So this is the high level overview of the workflow. And so we actually have implemented sort of architect as a follow. So we have a chain event.
03:43:13.748 - 03:44:12.554, Speaker B: So we subscribe to the bacon chain events and whenever the block has been generated, the nodes there are responsible to generate a witness alongside with the transactions. So we subscribe and also listen to the chain events. Whenever a new block produced, then witness will be generated as well. We generate the ZK proof of the witness for each block header basically. And through the sort of protocol, communication protocol over Ethereum, we just propagated at one call to all clients that participating. So the clients that already we made them stateless are based on on Trin. Trin is sort of like client ad portal at the moment and we can have like the sort of a peer to peer communication between them to cross check the proof of the headers that every node just received recently.
03:44:12.554 - 03:45:11.758, Speaker B: So this is a screenshot of our code currently. So generating the witness and Ziki proof for a random block. It is not the most efficient block that we generated neither in terms of generation time nor in this size, but at least it's like an example of proof of concept, how it works. And then this shows the propagation progress over DisKV five protocol. So through this we are able to remove the burden from clients to just actually have sort of one call to receive all the necessary fitness data they want, instead of like clients just calling full nodes. So yeah, with that I would jump into the conclusion about talking about applications and roadmap of this work. So that can be a diverse type of applications.
03:45:11.758 - 03:46:09.492, Speaker B: Here you can have more enhanced in staking operations. For example, validators could quickly verify the set of block without need to the entire blockchain history. It can be used for example for efficient rest taking mechanisms in protocols like Eigen layer for example, which enables rest taking. The stateless like client could be very efficient by verifying the delegation of transactions and the integrity of the heuristic assets at a very short time. And last but not least, we can have new type of on the fly verifications for dapps that allows dapps to operate more efficient by reducing the need for constant synchronization with the block state. And also we can enhance the user experience and scalability. So this is the timeline for our work so far.
03:46:09.492 - 03:47:30.574, Speaker B: We have initially made a proof of concept and it just generates the ZK proof of the block header and propagates it across Trin at the moment. Trin has like 50 peer to peer clients joining the network, but obviously the more clients just joining this protocol design, the better for the ecosystem system. Of course we are going to next improving the POC with ZK generation time and of course implementing new sub network layer in portal network for storing ZK proof messages and introducing new RPC call metal to facilitate that kind of peer to peer cross check. And last but not least, we can have sort of a surface like mobile app which everyone can be a verifier and just verify the state of Ethereum in a more diverse way. And we are also exploring the synergy with protocols like Eigenfire and other staking protocols just to use this type of clients. And I really appreciate our mentors of course and other people that made this event. And thank you so much for listening.
03:47:36.514 - 03:48:00.126, Speaker A: So go. Thank you very much for all the insights. I think we have time for one question from the audience anyone? Isn't the witness generation also taking a lot of gas and also producing more time delay in block to propagate on the disk?
03:48:00.310 - 03:48:59.914, Speaker B: Obviously for the gas it makes it much efficient than it is at the moment. So generating a fitness consumes not much gas as already we just have for each transaction to be involved in a block. But in terms of delay depends on which type of ZK snark or other type of proofs you just use. As I mentioned, there is the one option, poison t three, which is the least delayed type of ZK proof generator. But obviously this is something that we can investigate in terms of ZK proofs, how we can just increase the time of proof generation, decrease the time of the proof generation and reduce the cost. Furthermore, but again, it's not the replacement of vehicle choice, it is just some intermediary step toward that. And comparing to the current solution is the best architecture we came up with.
03:48:59.914 - 03:49:19.210, Speaker B: The reason of course is like the update of each leaf whenever the transactions just are changed from one state to another. So obviously this one would not be that efficient in terms of gas and everything else, just to reproduce your ZK after each transaction state change.
03:49:19.402 - 03:49:23.882, Speaker A: One additional question on top of it, what is the witness size now?
03:49:24.058 - 03:49:40.124, Speaker B: The witness size at the moment I guess is about 30k, sorry, 60 kb, which we produced here. But it's not obviously like the best option. It's a poc.
03:49:41.624 - 03:49:43.144, Speaker A: Amazing. Thank you again.
03:49:43.264 - 03:49:45.484, Speaker B: Sure, I appreciate you. Thank you.
03:49:49.864 - 03:50:46.594, Speaker A: Next up we have Philippe Rezabek. He's a PhD student at the Technical University of Munich in the area of system security. Philippe will talk about methods to assess blockchain scalability. Please give him a warm applause. Great. Hello everyone, my name is Philippe and I'll be today presenting to you our latest research regarding how can you assess if your blockchain scales. So firstly, briefly, a few things about me as I was introduced.
03:50:46.594 - 03:51:56.194, Speaker A: I'm a PhD student at the chair of network Architectures and services. Overall, the chair expertise is going for a couple of decades already, where the main focus is on the aspects of protocol design, active passive network experiments, and network security. With today's focus of the talk, I am looking into the aspects of distributed ledgers, technologies and blockchain, mainly focusing on application performance and evaluation, and also want to touch upon some aspects when it comes to the design of privacy preserving network systems. So without further ado, let's start a bit with the motivation. As you all know, there's currently a lot of discussions regarding increasing the scalability of Ethereum, but of course it comes with a lot of additional research that we have heard throughout the run of the weekend, touching on many, many aspects. From the perspective of our research, we are interested in the parts on okay, we see that the block size is increasing, but of course, how does this behavior affect the validators? Because suddenly they have much more data. They have to process, they have to evaluate much more data within the same period of time because the consensus itself will not be really changing when it comes to the slot finality.
03:51:56.194 - 03:53:22.576, Speaker A: Are the hardware specification of corresponding peers still sufficient or do we actually have to increase the hardware specification? How does it also affect the peer to peer network? Because of course, as we all know, if you have to send around more data, it means that all of the peers in the network have to have better connectivity. Do we maybe even have to optimize the peer to peer network and other aspects when it comes to network throughput and many, many others? Of course, as you all know, there is a lot of discussions regarding all of these aspects, but what we want to do and look into is finding a way on how to actually assess these individual parts in a reproducible fashion, which I'll be talking about a bit more in detail. So in addition to that, not only focusing on ethereum ecosystem, but general layer one and layer two solutions, there is a lot of noise going around with respect to marketing on how performant is your system with respect to TPS latency finality. And here you can see different values taken at who knows when for whatever period of time that later on can be sometimes summarized and put into a table, tweeted, put on a Twitter, and basically the information that is such table providing cannot be very easily verified and be fully trusted. In addition, we of course see a lot of new use cases. We covered a lot of interesting aspects when it comes to encrypting mailboost, private compute and many, many others. That I think is definitely something that we always have to keep in mind that the blockchain never sleeps.
03:53:22.576 - 03:54:33.884, Speaker A: Which basically brings me to this third point. There are many parameters when it comes to designing your corresponding blockchain and operating it, and there are also regular updates that you have to take into consideration. So always you have to have a way on actually how to assess if you introduce certain change into your system, is the system actually going to perform the way you expect and how can you be able to verify it? And for that, we are introducing our structured approach that I will be covering in the second half of the talk, where we want to have a way on how to actually assess the capabilities of various blockchain solutions. Look into the individual layers of the stack in a reproducible fashion. What does it mean reproducible? So let's say if I run the experiments today, but also in a week or in a month, I should ideally be able to run the experiment with it with the same outcomes. And not only us in our controlled environment, but also ideally the people in the community should be able to verify that, okay, if you run it under the same conditions, we are actually able to achieve to the same findings as the previous groups. With respect to that, we also want to compare different architectures, because as we know, there is, for example, a lot of layer two solutions, but they vary.
03:54:33.884 - 03:55:51.734, Speaker A: So the aspect is actually how to find a good and stable way to actually be able to also compare them in a fair way, in the sense that you actually know when it comes to assessing such different systems, how these architectures compares and most likely collected insights. Why is it like that? And can the corresponding architecture be also improved in the future and find overall the common ground when it comes to having the base, basically, which you can later on work with and try to increase the state of the art when it comes to the future technologies? And for that, we are mainly focusing on the aspects of deploying various systems in our local environment, where we can emulate realistic behavior that we can see from the actual real systems that are running out there. We can collect all of the data and be able to collect interesting insights when it comes to empirical studies of such systems. As we all know, blockchains are not coming out of thin air. They are building on top of the Internet infrastructure, because all of the individual peers have to be able to communicate to each other. This is basically the corresponding blockchain stack, as I believe many of you are familiar with. We have the aspects of the peer to peer network where of course all of the peers have to talk to each other in order to disseminate the data and collect interesting insights.
03:55:51.734 - 03:56:24.150, Speaker A: We know that of course part of this communication on the peer to peer layer is the main focus is to share the transactions. Of course later on the blocks share the votes and other aspects. So of course this is something that you have to be taking into consideration on how scalable is your corresponding system. Later, of course, on the consensus layer, you are agreeing. Okay, this is the corresponding view we have, and we are gaining confidence into the corresponding state over time. And of course for most of the interesting aspects, you actually want to be able to deploy your application into the system. You end up usually paying some fees for that.
03:56:24.150 - 03:57:30.728, Speaker A: And also of course the users interacting with the system also end up paying certain fees. And you want to know maybe in advance, actually how efficient is your deployed smart contract? How efficient is not only from the side of the user perspective, but also from the side of the core developer, actually how efficient is my virtual machine that is actually executing the smart contract? And is there something that I can do to improve the performance of the virtual machine itself? Or again in the aspect of okay, if I want to actually add additional features to the system, what does it actually mean for the corresponding validators that at the end are later running the virtual machine where all of the stuff have to be verified and validated? And of course at the end we have the user clients that are basically relying on all of these aspects of the blockchain stack as an infrastructure. Just a brief refresher when it comes to scalability. In general domain, two separations is between horizontal scaling and vertical scaling. So with horizontal scaling we are basically just adding more nodes. And in ideal case we will of course like to see that the performance of the system gets better. As we all know, it's not usually the case.
03:57:30.728 - 03:58:28.534, Speaker A: It's rather actually we are currently happy that the system performance doesn't get worse. But this is, I think, something that is also coming down to the individual interaction of the individual layers on the blockchain stack and down. There's a lot of discussion with respect to vertical scaling when it comes to ZK roll ups, that basically if you add more resources it's possible to create the proofs faster and you can actually ensure that the system can be scaling in this direction for that. Basically it's something that we always have to keep in mind when we are evaluating various systems if we are focusing on vertical or horizontal scaling. But of course, ideally we want to collect insights from both of these aspects to at least see, okay, if we add ten additional nodes, 100 additional nodes, or 1000 additional nodes, the system performance still doesn't and stays as expected. So considering a simple scenario that we want to briefly look into, we have to, of course we have our peer to peer network. You can have a look at it here.
03:58:28.534 - 03:59:48.758, Speaker A: In this case, we have interconnected peers that basically are interacting with the corresponding chain. Of course some of them are either having the full, are basically operating as a full node, they have the whole copy of the blockchain. Some of them only maybe are relying on third party that basically is having the full copy of blockchain in order to interact with it. Of course when we are interacting with it, we can send the transactions, the blocks, and in general, of course we expect that our messages will be propagating through the system. We of course for that have to accommodate for the part that each peer that actually sees the message and does some activity and forwards the message farther has to actually ensure that it has the right hardware specification in order to be able to do so. For that, as you know, there are always usually provided by the corresponding foundation, the minimum requirements in order to run a node. But sometimes it's a little bit unclear how did we actually get to these hardware specification? Is there a clear structure? Is there a way on actually making sure that if I run my node it will actually be working properly? Does it apply only to the CPU assumptions, the ram amount that I have? Or do we also have to consider some aspects of, for example, SSD's with respect to I o, and all of these parts basically have to be verified.
03:59:48.758 - 04:01:11.124, Speaker A: And of course, more importantly, considering that the system always keeps evolving, we have to keep in mind that maybe in the future these hardware specifications will be different. There's also a lot of activities on the peer to peer, because of course we want to make sure that we are not just having, let's say some naive start topology where we exchange all of the information over a single hop that later on basically can pose as a single point of failure. So we want to have a robust peer to peer network where all of the peers can exchange the data in such a fashion using some go see protocol or some other form of unstructured or structured network algorithms. Of course we have to consider a different type of transaction, right, of course, someone wants to maybe just send a typical, easy, simplest transaction. But if we consider some aspects of more complex smart contract deployments, we have to be able to handle those as well, because of course it's again, something that has to fit into the block, has to be verified and validated by the corresponding peers, and we have to be able to see if it actually is possible. And of course, a lot of discussion going into not only keeping, let's say the typical flow of execution and the lifecycle of the transaction, but in addition, they are adding new features when it comes to implementation and usage of single multi party computation. Threshold cryptography, zero knowledge proofs and many, many others have to be taken into account.
04:01:11.124 - 04:02:39.600, Speaker A: And other aspect is the infrastructure layer, where of course certain types of peers in the system can also provide additional types of security guarantees, using, for example, some form of hardware acceleration that of course can overall improve the system performance itself. So as you can see, the scope of actually being able to assess if your blockchain scale is quite large, because it's not only a matter of a single node, a single peer, of course you can still collect some insights from that, but you have to consider the whole deployment and all of the individual protocols that are in the system. And most importantly try to collect the information about how these individual layers interact with each other and what type of guarantees each of this corresponding layer can provide. Touching a bit on our evaluation methodology. So basically what we want to do is we want to bring the system on the left where, let's say, talking about Ethereum, we have around six to maybe 10,000 physical peers running in the system, and we want to somehow map it to our local environment in order to be able to actually collect comparable insights in order to do so. Here on the right is just like a simplified topology of our local testbed environment, where basically we want to emulate the globally distributed blockchain networks. We want to have the options to configure various configuration parameters for the corresponding blockchain.
04:02:39.600 - 04:03:53.978, Speaker A: And of course we have to consider that the system might be able to interact with other systems as well. So for example, in case we want to deploy l two solution, we of course have to also deploy the l one solution in order to basically have the full fledged flow of interactions and guarantees offered by the corresponding l one and l two in order to call good insights and see the overall performance of the system in such a scenario as well. When it comes to the decision, we of course could consider deploying our experiments also in cloud. So this is actually something that we are looking into, and I want to integrate it into our framework. But so far we are mainly focusing on the local deployment, where of course when it comes to local deployment, in comparison into cloud, or even using something like Testnet, you actually have much more sophisticated level of control over your system. You can play around with various parameters, you can modify the hardware specification of your corresponding peers. So let's say going back to the figure, a single node here, maybe as it is by itself, maybe has around 64 or 128gb of ram, can be even more than that.
04:03:53.978 - 04:05:08.482, Speaker A: It can maybe have around 64 virtual cpu's. It can also have very good connectivity. So as you can see, we have maybe 25 gigabit links to connect all of the individual peers, or even 100 gigabit links, which is of course something that we don't see early in the main deployments, right? So we want to have a granular control on actually how to lower the specification of the individual hardware, hardware nodes using maybe some form of lightweight virtualization, and also have a granular control over the corresponding hardware stack to collect and reproduce and emulate the right state as we can see on the mainnet. And of course in combination with cloud, this could provide also interesting insights coming I would say closer to the realism aspect, because of course many of the nodes running out there are actually running in cloud deployments. And it's also interesting to see how the cloud itself behaves and what type of individual noise it can introduce. When it comes to experiment design. Of course this is something that is important to spend a lot of time on, because if you just deploy the stuff without knowing what is the target and what type of insights you want to collect, it's a little bit challenging to be able to do so.
04:05:08.482 - 04:05:53.350, Speaker A: So usually you want to think of some theoretical assessment. What does it mean? Theoretical assessment? It can go very deep. Depending on how much time you have. You can of course try to understand how the individual building blocks behave. So for example, talking about ethereum, you want to understand how the content behaves, you want to understand what are the gas limits when it comes to block sizes or actually what are the corresponding block sizes themselves. You want to later be able to model and understand, let's say the peer to peer network. Okay, if I send a transaction on either mainnet to how many peers the message gets sent to, and understand all of these individual integrity details over the corresponding protocol in order to actually design the experiments properly and later on collect valuable insights.
04:05:53.350 - 04:07:08.418, Speaker A: So general separation, you can of course also split between micro benchmarking. Let's say from the view of a single peer or macro benchmarking, considering based basically do on full fledged deployed l one in your controlled environment. And you can also of course try to play around in the form of black box or white box testing, where the main difference is that considering that we actually have the access to the code, because most of the code is open source, which is really great to collect insights, we can also modify the code for our particular experiments, but ideally due to the complexity and the way how often new versions are introduced, we rather want to take it like a black box without any need to modify the code itself and just observe the performance using external metrics and parameters. And of course touching on that, we can collect many, many metrics from the system that we can measure. We can of course consider throughput like when it comes to transactions per second, various types of latencies that can affect the users experience in the corresponding system. It can also be aspect of finality, actually, when the corresponding block is final and cannot be changed later on. We can of course try to play around with various hardware specifications of the individual peers to see and collect the insights about that.
04:07:08.418 - 04:08:36.362, Speaker A: And of course when it comes to the parameters, we can be adding higher number of peers to the system. We can also modify the block sizes to, for example, assets. Okay, in case ethereum in the future will have box size of 30 megabytes, how does it actually affect the performance? And try to also emulate some fault injection, because of course we want to always verify if the guarantees offered by the consensus when it comes to the byzantine fault tolerance is also present in the form of our environment and how the system behaves under such conditions as well. So for that, briefly touching on the design, I will just skip through it briefly. We of course have the input where in general the idea is that you define your experiments that you later on deploy, you have your system under the test. So again, following the examples that will be, let's say your l one ethereum with maybe 300 deployed nodes that will have different amount of hardware, specific hardware allocated to the individual validator, basically going also in the heterogeneous direction of how much different providers can be out there, right? And you basically start to issue the transactions to the system and you're measuring the individual insights when it comes to the corresponding metrics that you have defined as a part of your experiment. Briefly touching here on some of the subset of supported features we actually have in our framework and our testbed.
04:08:36.362 - 04:09:37.578, Speaker A: So we are quite heavily looking into trusted execution environments. We also have quite a several threshold cryptography schemes that are currently supported and that can be used and to interact with the system. We are also looking a bit together with my colleagues from the technical reserve Munich into MeV. So for that we of course want to have the full flow of Ethereum. The deployment in our local testbed and while collecting also insights from the mainnet, actually try to emulate some form of bidding wars and see how actually the latency, for example, can affect such bidding wars on the mainnet. We of course want to measure different types of delays for ethereum when it comes to the aspects of interaction with the individual clients, and we also want to, for example, modify the hardware specs. So overall, this subset of the feature was also important for us to actually validate that our approach to design such a framework is viable and it can be done.
04:09:37.578 - 04:10:34.514, Speaker A: Even though it takes a lot of time to actually do so and onboard new solutions into the framework, it's possible to do it and we now, I think have quite a decent way on how to assess if your blockchain scales touching on the takeaways already. Basically the main aspect is always onboarding new systems takes quite a lot of effort because each system is slightly different. But I think this is the part that is also fun because you keep learning along the way on how each system performs and behaves. We would like to in the future find possible unification and evaluation guidelines that the community can use and possibly extend in the future to have basically a fixed baseline. Maybe also help with definition of the workloads. And overall we believe that this is a good stepping stone towards collecting holistic overview on the interaction of the individual layers that are part of such complex systems like blockchains. In case you are interested, we also have it available as an open source.
04:10:34.514 - 04:29:10.270, Speaker A: We of course have some of the latest updates still available only for us, so usually we update our public repository once we have also academic publication available. But in case you are interested to find out more, I think it already provides good insights and references to our publications and as always happy to connect. Thank you very much pd thank you. Very interesting presentation. Unfortunately we don't have time for a Q and a, but you can ask him any questions during the coffee break and the next session will start start at 225. Thank you. It it it it it it it it hello everyone, just a quick announcement.
04:29:10.270 - 04:40:29.584, Speaker A: Since the next speaker won't be able to join you have extra ten minutes. So if you want to go back and still have a coffee or chat, please feel free to do so. It welcome back everyone. I hope the coffee kicked in and you're energized. So next, our next speaker is Pietro Carta. He's blockchain security engineer at chain security. His specialization are smart contract audits in solidity and VYPR.
04:40:29.584 - 04:41:01.764, Speaker A: Let's give Pietro a warm applause. Thank you. This stage is yours. Hello. So I will talk about this reentrancing Cancun hard fork, the curious case of EIP 1153. So, transient storage chain security is a smart contract audits firm. We represent many of the main protocols on Ethereum.
04:41:01.764 - 04:41:45.704, Speaker A: I'm a blockchain security engineer at chain security. I have many years of experience in cybersecurity. I've been auditing curve VYPR, compiler, conic, yearn, and I found critical life bugs on multiple protocols. So I will give a quick recap about what Cancun does. I will present an overview over execution context messaging. So how different execution context of the same contract talk to each other. I will present how transient storage works, and then I will talk about this new reentrancy vector which is introduced by transient storage.
04:41:45.704 - 04:42:38.210, Speaker A: So the Cancun hard fork was activated on the 13 March 2024, exactly one month ago, and it contains a bunch of new eips that change the protocol for once. We've got the beacon block root in the EVM. That means we can access the consensus chain from the execution chain. We've got blobs. So this one and this one are for blobs. We've got memory copy, opcode, we finally get rid of self destruct. And finally we have transient storage opcodes.
04:42:38.210 - 04:43:45.754, Speaker A: So I will talk quickly about how the data layout was before Cancun. So within an instance of the ethereum virtual machine, you had the stack, the memory which you can write to, the code is immutable. You've got the account storage, which has the data storage of a contractor program counter gas available. Not represented here, but also present are call data and return data. These are all the data locations that are present within a smart contract execution. So let's say we have two contracts, c and a and c a, which calls c again. So now we've got a first execution context, c one and a second execution context, c two, all within the c contract.
04:43:45.754 - 04:44:49.688, Speaker A: How can we communicate information from this execution context to this execution context? So it's the same contract, but we cannot use memory, because when you call a contract, even if it's already executing within the call stack, the memory will be new, it will be a new instance. So we cannot write data in memory to communicate between the two. To execution contexts. That would have been convenient, because memory is very cheap to access and to write to. We can use cold data, maybe so c one can pass a message to a which passes this message to c two. This can work if a is a trusted contract, so we know what it does and we trust it. But if a is controlled by the user, it can do whatever it wants, and it can lie about the message it received from c one and back to c two.
04:44:49.688 - 04:45:37.494, Speaker A: So call data can work, but not always. And finally, we can use storage. So basically, c one writes to its own storage and c two reads from its own storage. And since they're the same contract, they share it and they can message this way. This is what happened until Cancun, but it's expensive. So the cost of one S store is between 2900 gas and 20,000 gas, depending on whether the slot is warm or if it's been written to already. Most of these can actually be refunded if we reset the slot to its original value at the end of the execution.
04:45:37.494 - 04:46:29.790, Speaker A: But the refunds are limited by the total amount of gas you are spending in one transaction. So a refund can only be up to 20% of the gas spent. So this is why transient storage has been introduced. EIP 1153 introduces these two new opcodes, tload and destore, and they behave. They claim to behave exactly like storage, except that they are reset at the end of a transaction. So now c one can t store and c two can t load, and the value that's been stored in c one is retrieved in c two. And this happens within one transaction.
04:46:29.790 - 04:47:32.566, Speaker A: At the end of the transaction, the value that's been stored is deleted. It's reset back to zero, and tload and t store cost both 100 gas so much less than s store. One example of how we can use these transient storage opcodes is to implement reengineering guards. In this case, the execution context messaging would be that c one says to lock while calling out, and c two reads the current state, which is locked. So re entrancy guards are implemented like this using traditional storage. So lock is a storage variable. It's initialized to not entered, which is one, and the non re engine modifier will simply check that lock is not entered, and then it will set it to entered.
04:47:32.566 - 04:48:26.428, Speaker A: It will execute the body of a function and then set it back to not entered. Now why we use one and two is specific of how s store costs. So if you write a positive value in a slot that's zero, that costs 20,000 gas if you write a value in a slot that's non zero, that costs 5000 gas because the slot is already initialized. So that's why we use one and not zero for not entered. Anyway, this was the current state of re entrancy blocks and we've. So how much does this cost? We've got one s load, which is cold. It's taken from storage and it's not been accessed yet.
04:48:26.428 - 04:49:17.084, Speaker A: So this is 2100 gas. Then we've got cold s store, which costs 2900 gas. And then we've got, when we reset back the lock, we've got a warm s store which is 100 gas. So in total we've got 5100 gas spent, but we get 2800 gas in refund from the resetting of the lock. So if we are using the full refund, it's only 2300 gas. So this is the minimum cost of our reentrancy lock using trains in storage. We don't have it in solidity yet, I think, but we can use it in assembly.
04:49:17.084 - 04:49:58.964, Speaker A: And so this is pretty much the same logic. We check that it's non set, we check that it's zero, we set it to one, we execute the code, and then we set it back to zero. And now the cost is very easy to calculate. Just 100 for the first t load, 100 for the second t store and 100 for the 30 store. And this ends up being 300 gas, plus the overhead of everything, of course. So this is like three cents of a dollar in today's price. Pretty much.
04:49:58.964 - 04:50:44.934, Speaker A: These would be like thirty cents of a dollar or something like that. So it's quite an improvement. Now we know what transient storage does and how it works. Let's forget about reentrancy guard and talk about reentrances. I've got a contract here which uses normal storage, not transient storage. It's got a deposit function in which you can increase the balance of the message sender by sending some ether. And then there's a withdraw function which transfer to the message sender its balance and then resets its balance to zero.
04:50:44.934 - 04:51:25.430, Speaker A: So can you spot the problem? Yeah. Yeah. Well, it was a trick question. Actually. There is no problem because transfer only transferred 2300 gas and this is not enough to recall withdraw again. Calling withdraw will cost 100 for the message code. And then you will not be able to set the balance of the sender to zero again in the inner core.
04:51:25.430 - 04:53:32.894, Speaker A: Because even if it costs only 100 because it's a warm storage slot, maybe when you've got less than 2300 gas in your execution context, you cannot use s store. And this is an addition to the EVM that was introduced with a Constantinople hard fork because initially a storage was always 5000 gas and so you could never write to storage in a send or transfer reentrancy. So this was a safe operation with a Constantinople hard fork, the cost of storage was changed and it was lowered and it was in the least case it was 900 gas, I think, which was kind of an oversight because now you could use send and transfer functions to re enter contracts. So this was detected actually by a colleague of mine back in 2019. The Constantinople hard fork was delayed one month because this bug was just detected a few days before the upgrade. So in low gas, when you have got low gas in your context, you cannot have a reengine, see? And this is to preserve the safety of transfer and send with this Constantinople upgrade. So what changes with EIP 1153? Well, the difference is that now EIP 1153, so tstore and tload this store doesn't implement this safeguard.
04:53:32.894 - 04:54:31.422, Speaker A: If you've got less than 2300 gas, you can still destore. So the send and transfer functions are now no longer safe if you use them in a contract that uses transient storage. They're not inherently safe, but can still be safe. So I've got an example here which has a balance field, it's still a vault, it has a balance field and a temporary allowance. Temporary allowance is a transient mapping. We can deposit by sending some ether to this contract and we can temporary approve, which means we make an approval which only lasts for this transaction. And this is highlighted as a use case of EIP 1153 because usually when you make an approval you don't want it to last a long time, you just want to do some operations with it.
04:54:31.422 - 04:55:50.784, Speaker A: So temporary approvals could be an application of transient storage and then we've got withdraw all temporary approval from. And this uses the send function and again it sets the temporary, it decreases the balance by the temporary allowance. So what can happen here is that I call withdrawaltemp from, which sends me my balance, I can do from whatever approval I have. And in this send function I re enter temporary approve, set it to zero, and then my balance is decreased by zero. But I've already sent the ether to myself, so now we can use send for this reentrancy. I've got a second example, it's a bit more complicated, but it reflects some code that was in Euler v one, which is actual code in production, which the code of Euler uses storage, it's safe. This one uses transient storage.
04:55:50.784 - 04:56:44.488, Speaker A: It's more efficient, therefore, but it allows this reentrancy, so we can defend against re entrances. But now functions such as send and transfer have to be double checked. If you are using transient storage, what happens here is that we've got a deferred liquidity check option. This is a vault that can do operation. And if we enable the deferred liquidity check, our balance can become negative, which is sometimes useful if you want to do. We want to chain operations such that at the end of chain of operations we have a positive balance. But at some point the balance might become negative.
04:56:44.488 - 04:58:13.834, Speaker A: This is a way to implement flash loans. And so just translating this code from s store to tstore, we have now the option in this send to reenter the withdraw function and send ourselves our balance twice. So, in conclusion, transient storage implements data locations which have the lifespan of a single transaction. It's mostly equivalent in behavior to storage operations. They both cost only 100 gas in every case. But differently than storage operations, t store will work during address transfer, even if the gas left is less than 2300. There's an additional caveat with transient storage is that if we go back to the example of a reentrancy lock here, we might think since this is reset to zero anyway, at the end of a transaction, we might want to drop this additional t store at the end.
04:58:13.834 - 04:59:01.482, Speaker A: Because anyway we are locking, we are executing our function. And then since the transaction is ending, this thing will be reset to zero anyway. So we can save 100 gas with this. This can be tempting, but it breaks composability of contracts. So if you want to execute multiple times a contract sequentially, not during a reentrancy, this will no longer be possible. So it will break multicols, it will break batching operations, it will break account extractions such as EIP 4337. So this is a caveat of tstore.
04:59:01.482 - 04:59:51.078, Speaker A: You should always reset back to the intended value and not let the transaction expiration do it. And operations that we thought would be safe, such as send and transfer, or contracts that we thought to be safe because they only use send and transfer, might not be safe anymore if your contract that uses them uses transient storage. Thank you very much. Thank you very much, Pietro, for this insight, insightful presentation. We have about six minutes left, so let's open the floor for questions. Thank you. Hi.
04:59:51.078 - 05:00:59.438, Speaker A: Yeah, thanks for the presentation. Really interesting. So just to recap, the smart contracts that have been previously not vulnerable to reentrancy now with Dankune, are still not vulnerable, right? Unless it's like, unless that contract is taken and redeployed with additional functionality of accessing the transient storage. Am I understanding it correctly? Yeah, exactly. So contracts that are currently deployed are safe because they don't use the transient storage option. Basically, new contracts which use transient storage have to be careful around transfer and send. Okay, so if I have a code for the smart contract that has been deployed and in the past, I know it's been safe, if I go and add transient storage functionality, I should account for the reentrancy and go over the code to see if any of the functions are now, have been exposed to that vulnerability.
05:00:59.438 - 05:01:40.244, Speaker A: Right? Exactly. If you optimize your existing contract by using transient storage, you should reevaluate its security. Okay, thank you. Any other questions? I guess I can ask another one. Yeah. So with, with Dankeon, the transient storage, is there any, I mean, with the next update of, I believe, 64 blobs being added, whatever that's called. Dank sharding, right? Yeah.
05:01:40.244 - 05:02:13.496, Speaker A: Do you think, do you see additional vulnerabilities as far as, like, transient storage when it's expanded to that many blobs, or is it gonna be just. No, I, I don't think that touches the transient storage subject. The blobs and the blobs are really accessible from execution only through the block root blob hashes. And, I mean, this is safe. It's not something that's touched. Yeah. Oh, because in the consensus is that.
05:02:13.496 - 05:02:51.632, Speaker A: Because in the consensus, the EVM execution cannot really access the blobs. That's why it shouldn't be an issue for the smart contract. Well, you can kind of access it in the smart contract by getting a proof of what's in the blob, but it's not related to transient storage. And it's also. No, it's. Okay. So the main reason it says it's read only, you will not write to it from the execution layer.
05:02:51.632 - 05:03:48.724, Speaker A: So the problem here is you can write in transfer, send reentrancy. Thanks. Okay. One more question, please. Yes, I remember there was some discussion or some people that wanted to implement the resetting of transient storage at the call level rather than at the transaction level. So what do you think about that? So at the call level, it would have introduced a concept of a call stack of contracts, which. So the transient storage would only pertain to the calls under my execution and not up from me.
05:03:48.724 - 05:04:30.004, Speaker A: I thought it was probably a cleaner implementation, but probably it adds a lot to the execution nodes. And I think this is also valid. All right, thank you. Very much. Thanks a lot. Now it's my pleasure to introduce Benjamin Klorman. By day, Benjamin works in university hospitals lab developing pioneering medical products and solutions.
05:04:30.004 - 05:05:39.802, Speaker A: By night, he tackles complexities of DeFi and web three. Today, Benjamin will talk about fighting sibils and fraud. Please put your hands together to Benjamin. So, hello, welcome everybody, to my talk about Sibyl and fraud. Just a question in the start, does anybody know what a susieble is? Yeah, you know you want to say it. Yeah, exactly. This is the thing.
05:05:39.802 - 05:06:24.494, Speaker A: So it's a thing that someone uses a computer network to get around the reputation, and one individual creates more individuals than he have. And this is a sentence also from Gitcoin. And there's a very nice image of what it shows. Like, you have this alt accounts, bots, whatever they do, and this is kind of a Siebel attack. And this happened also before in the web two. So I think everybody knows, also like a voting system where some of your friends say, hey, I'm here in this competition, can you vote for? And the people have like, computer at work, computer at home, their mobile phone. So they use kind of the three things to vote on the system.
05:06:24.494 - 05:07:14.852, Speaker A: And what we have here is a very nice example from Spotify. Spotify was farmed out in 2015, where someone created 500 accounts free. Spotify uploaded his own tracks to Spotify, and by this he gained $5,000 per month just playing his own tracks with his own sybils. The thing is here with the web two, this data is not accessible for us. So this can only be solved by Spotify itself if they know which IP is belonging to them. And this comes now into web three. In web three, this is civil attacks, sweetening the financial stability, fostering fraud can happen, mark.
05:07:14.852 - 05:08:24.014, Speaker A: Manipulation, eroding trust in the ecosystem. I mean, we have these pillars of decentralized finance where we want to have a fair governance system, and especially also with airdrops, incentives and all stuff like this, you take away somehow this fair, claiming rewards from other people, people and someone gaining more than he has. This is also a very nice example where a developer made his own token. He split this into 70 wallets, and it's increased somehow, even the TVL, the user activity, and so on. We will also come later into this again, but we see here directly, he has 50% of his own tokens, distribution bit into 70 wallets. So everybody, when someone bought this token, he sold it. So what is a Sibyl? In detail, we have three different kinds of sibyl that we can cluster it's a human, it's a bot or nowadays there are kind of apps, especially on telegram, they are really known nowadays.
05:08:24.014 - 05:08:55.264, Speaker A: So a human symbol is mostly that you do this interaction by yourself. A bot is mostly written with a script. And these new apps, they are a little bit more smarter than bots, because they have also kind of an algorithm behind. So they are not showing completely. Exactly timestamps. Here is an example of a human. He withdraw from binance, he stay and then spread it over 30 wallets to, to be part in this airdrop.
05:08:55.264 - 05:09:48.900, Speaker A: This is a bot we see here that he sends like in nearly every 20 blocks or ten blocks new transaction. And also the transaction amount was exactly the same. This was an example from gitcoin from quadratic founding. So he tried to go under the quadratic founding there. Now we come into some airdrops, aptos. This is a layer one from ex Facebook employees, this kind of libra where they had this project, and Aptos made an, I would say, quite easy airdrop to farm out, because they had this test net, and everybody who minted there, his NFT got reward. So they didn't have any Sybil checks on this.
05:09:48.900 - 05:10:25.062, Speaker A: And it ended up that 65% of the tokens directly was going into Sybil wallets. One wallet had like nearly 200,000 tokens. And what happened here with Aptos was a selling pressure. So when the first big Sibyl started to sell, the price dropped from, from $15 down to $13. And then more and more people were also selling it, and it crashed down to $6.7. Next we have arbitrum. Arbitrum was kind of smart.
05:10:25.062 - 05:11:00.890, Speaker A: They checked already and made a good Sibyl check. But what Arbitrum didn't look into was other layer twos or other layer ones. So they only checked their data on Ethereum, Mainnet and on Arbitrum. So if I would have made my sibyls on optimism and bridge back to Arbitrum, I would not be detected. So 20% of the tokens ended up as well in Sibyl wallets. Next we have optimism. Optimism has a little bit another way, how they made the airdrop.
05:11:00.890 - 05:11:49.314, Speaker A: They had this kind of four airdrops. So the first one was for the first users of the Mainnet, the second one was for the active users of the mainnet. And every time when you even take part in the governance, so you keep your tokens inside, you get a multiplier. And this is something where they try to achieve this incentive spread much better, because so there's also not this kind of massive selling pressure. And also they use the community and ask if they know some Sybils. So at the end they removed from 70,000 addresses, 40 million optimism tokens, before they spread it out. Hop the bridge, hop.
05:11:49.314 - 05:12:48.826, Speaker A: They pioneered some kind of Sybil hunter program. This data is also still available on, on GitHub, and arbitrum, for example, used exactly this list to filter out also Sybils. This has a good side, but also can be a bad side, because CoNNExt tried to make the same like Hop. What was happened with CONNEXT, that the people was making so many reports that the Team was overwhelmed by their submissions. And not only this, there was one civil attaCker, he sent it to 30,000 wallets. Of the 65,000 wallets which been around, he sent a small amount of Ito, or even just one cent. And so there was a lot of sybil hunter, they put it in these addresses and say, like there's a sybil and there's a sybil, but at the end, this was not a sybil, this, this was just a SyBIl attacker.
05:12:48.826 - 05:14:22.054, Speaker A: And SOmeone was using disperser and dispersed quite small amounts, and this gives all the connections. And also what was later there, there was this kind of rumor that sybil hunters have been also sybils by themselves. So now comes the question, who verifies the verifier? This address was on the hop positive list, and what this guy was doing, he send his ens to a new address and then he come as a Sybil hunter. So I'm coming now into some methods, an example how you can trace back sibyls, this can be done by, this is very good example, same central exchange deposit address, then flytrap, which is my own technology, we can use a gas detection, cross chain bridges, token transfers, so directly on chain transactions, time timestamps, the wallet age, chain interactions, transaction amounts, contract interactions, and bulk transfers from dispersers. So what we see here is a deposit of two people in the same central exchange of bybit. So it is very clear that it's the same person, two wallets, the same person, because who else using the same deposit address. And also what you can see here is a withdrawal from a central exchange.
05:14:22.054 - 05:15:13.372, Speaker A: But this needs more factors to calculate in. So we for example, see here, this person was using avalanche on the 1 April to the same time, the wallet h, at the same time he had the same interactions. And also when we look deeper, he had also the same contract interactions. So by saying this, you could even say, tracing back that it's from the central exchange with the same person. Here's this flytrap that I explained. This is an example from a solidly fork. So there was also an airdrop and someone made 70 wallets as well and grabbed a lot of these airdrops incentives from this solidity frog.
05:15:13.372 - 05:15:50.474, Speaker A: And especially when we speak about solidly, there's also kind of a voting mechanism behind that you vote for the next incentives. So this could be even they are manipulated if you gain a lot of power over airdrops. Here we have the gas and transaction amount. This is exactly the same bot that I explained before. So here he sends it every time like $10 to Gitcoin. And also what we see here, it's exactly the same gas price every time, 90 grand. So he spots even rating that he is going to exactly 90 degrees.
05:15:50.474 - 05:16:25.424, Speaker A: And this can be traced back. Here we have an example of a crosstrain bridge. So this guy was farming out the crosstrain. He sent it over lifi some tokens to another wallet and then next month he got the money back. He used also some other protocols and then he sent out the money to another address. And this is kind of a chain link transfer, what we also see like here. So he sends it also like forwarding.
05:16:25.424 - 05:17:12.138, Speaker A: This is also here we have a bulk transfer and then he used also kind of this chain link transfers. And this is an example from Galcse where someone farmed out also an airdrop and he used several wallets. And we also see that there was a question about, I think Pancakeswap was an incentive from Pancakeswap. So we can even trace back about the contract interaction. This is another chain link token transfer. This is lately happened on base. Base also had this kind of galaxy competition where you can earn points if you buy an NFT and then you claim your points.
05:17:12.138 - 05:18:00.574, Speaker A: And this guy was very smart, he bought just one NFT, send it to next wallet, then he claimed the points there, send it to the next wallet, claimed another point there. And so he only buys one nft. And this is not the thinking about this incentives that you buy with every wallet, one NFT. And so he came around the system quite easy. Meanwhile Galaxy, after I informed them about this, they have now a code behind also algorithm where they detect direct transfers and cut them out. Also what can do is developing your own contracts and your own tools. Here we have a guy, he is called, called Yuri.
05:18:00.574 - 05:18:43.754, Speaker A: He used exactly this on Galxa that he farmed out very smart over a script that he used here. And also what he did on base, he was creating his own dispersal contract. So he was not using dispersal or bulk transfer apps. He created his own contract and dispersed small amount of ETA in 2000 wallets. And from this 2000 wallets he also created some more contracts. So yes I think he ended up with 3000 wallets right now on base where he has small amounts of data inside. And he tried also to hope that it will be an airdrop on base.
05:18:43.754 - 05:19:52.404, Speaker A: So how we trace this all back? Mostly it happened with SQL querying like dune analytics, footprint, nonzen flip side. But also there are kind of really special apps around like Scopescan. This image before that I showed was for example from Scopescan, this one. So you can see directly on Scopescan where the people send money to and you can even see directed clusterings. Then we have also trusterlabs, Arkham and bubble maps. Bubble maps is specific about also tokens developers to find out if they have sub wallets where they send a token tool which I showed in the start. And Fortor Forta is kind of a monitoring system and they also have a new technology where you can kind of program machine learning insight and a fast detection.
05:19:52.404 - 05:21:02.974, Speaker A: And what's also around is the open data community. This is kind of a discord group a dao where they come together and build this kind of legos like SQL queries specific to detect sibyls and frauds. They were founded out of a gitcoin and get some bounties from gitcoin and grants and meanwhile they are also working very hard with arbitram together. So now the question how to solve this? And this is a massive question because at the end we can only increase economy cost like asking for a stake, get something around that they earn less that they put in. Like I think Tina, there was also some people that say oh we have so small airdrop and the gas fee is too high to claim this airdrop. So that's the thing. If you don't there have 100 wallets, in the end spend more money to claim the airdrop than you get analytics, which is my point, really crucial because at the end you can solve this really only by analytics, by live channel tracking.
05:21:02.974 - 05:22:11.118, Speaker A: There's also human verification, but I mean also there captures and all the stuff you can still go around if you have a good bot for this. Also KYC could be something, but still a lot of users don't like KYC and this gives a hard barrier the future. Maybe there's some kind of zero, zero knowledge technology that you have your decentralized id, something like Gitcoin already has. But even then there's no 100% sure that you really can detect everybody. And I mean, even with KYC, we see what happened lately, that some people were using AI to faking new identities, passports, and going to central exchanges and making accounts there. So even this stuff with AI, there's a disc branch between. Now I'm coming also to an example from digital identity at the centerless identity.
05:22:11.118 - 05:23:21.740, Speaker A: So this is a guy who was on Gitcoin and even Gitcoin later came back to me and asked, are you really sure about this finding? So this guy has a gitcoin passport with a score of 33. And he even created sub wallets with a score of 16, which in my opinion is even quite high because I have only a Gitcoin score of 22. So even there with his sibyls, he was that good that he created Twitter accounts, discord, Facebook, Gmail. And so he get this kind of reputation like a human. So any questions around? Thank you very much. Any questions from the audience? The best Sibyl attack that ever happened? Yeah, yeah, that's a good question. I mean, there was no, nowadays a guy on zinc, I think this was probably one of the best, smartest one because he created his own token.
05:23:21.740 - 05:23:59.496, Speaker A: I mean, when we look at how incentive will be distributed, arbitrum had this kind of where they say you need like five contract interactions you have to bridge into the network, etcetera. So this guy on ZK sync, he was really smart. He created his own token, he claimed with 20,000 wallets, his airdrop, he created his own Dex, which is not accessible for us all. He swept there, he swept back. He used a bridge with all these 20,000 wallets. So this is quite smart. I mean, if he would be smarter, then he would even use some other technology.
05:23:59.496 - 05:24:59.370, Speaker A: But you can also connect with me if you're also in this field of research, and then we can speak. But I mean, it's always a little bit tricky to say what is the best civil attack, because it's also now live streaming and everybody can see this and say, ah, this is a good idea. I will. What motivates you to stay on the light side? Sorry? What motivates you to stay on the, the research side versus the attacker side? What state we are. Why are you a civil researcher and not a civil attacker? Why? I'm a researcher, not a civil attacker. I mean, the thing is, when you want to think about this, then you must think like a black. But somehow I don't want to undergo the pillars of decentralized finance and this is saying we want to have a fair distribution of airdrops and everything.
05:24:59.370 - 05:25:28.006, Speaker A: So, yeah, I could be a black hat. I could do everything. I mean, everybody in this room probably has knowledge to be more black than white, but why should I use it? I mean, it's still unfair. And I'm more really interested in really deep cases, and I really like to discover this. Hi. Yeah, thanks for the presentation. Really interesting.
05:25:28.006 - 05:26:41.754, Speaker A: So, as an addition to this previous question, how do you. Obviously, we all agree that it's unethical to create thousands of bots and chase the airdrops if there's any strategy to counter that. For example, if we look at traditional platforms like Hackerone, where we would target the same hackers, but name them as ethical hackers to see if we can use their resources to give them bounties, and if there's something specific for this Sybil strategy to. Are you searching for one of the slides where I probably missed this? So, for example, hop was using exactly this. So when you was taking part in hop, from every symbol that you detected, you get, I think it was 50% of the tokens you get directly paid out. I think it was 10%. And the rest of this 30% was staying into a contract.
05:26:41.754 - 05:27:20.614, Speaker A: Also, Connext had the same like this. Every Sybil that you detected, you get 25% from the Sybil from what they were legible to claim. You mean like if you found someone who was doing it or if you detected vulner? Yeah, if I found someone. Yeah. Yeah. But I mean, there's always kind of how you know that it's really a Sybil hunter, or is it even an own Sybil that he reports his own addresses? I mean, this is. This can be also then the issue, because exactly this.
05:27:20.614 - 05:27:50.846, Speaker A: Unfortunately, the data from Connext was removed. But I would really love into this rumor what happens lately there, because at the end, he could even say his own wallets to save this 25%. Then instead of getting zero, take the cut, but kind of turn on the ethical side of this. Sorry. Well, I mean. Yeah. All right.
05:27:50.846 - 05:28:47.942, Speaker A: Thank you. Yeah, thanks for the great talk. I have a question. For the first slides you presented, you showed some airdrops and you said, okay, 20% went to Sibyls for arbitrum, for examples. How do you get this number? So this number is not really 100% sure, but I also made some post mortem analysis, and lately there was also from arbitrum doe a grant where they now do a post mortem analysis, but this 20%, I would say, quite accurate. And this is also something that other researchers found out. This is kind of what I say, like here, this kind of flight trap that you look later after claiming where this model money flows into.
05:28:47.942 - 05:29:21.562, Speaker A: Like especially when someone claims with 100 wallets there are some, sorry to say, stupid guys, they send it directly to one wallet and then you have all this connection there and see, oh, 100 wallets send all their claimed airdrop into one wallet and this is how you can get these numbers around. So it's a lower bound because if someone was smart and didn't do this, then you wouldn't detect them. Right. Sorry. If someone did not send all their funds into a single wallet then maybe it would be. You wouldn't. Yeah, yeah, yeah.
05:29:21.562 - 05:29:33.810, Speaker A: But. Yeah, makes sense. Thanks. Okay. Thank you very much. We are running out of time, but in 1 hour during the networking session, you can ask Benjamin more questions. Thank you very much.
05:29:33.810 - 05:30:29.210, Speaker A: Again, big round of applause to Benjamin. Thanks. We need 1 minute or two minutes to set up the new presentation. So maybe in the meantime, this is the third day of the conference. Would any of you like to share a couple of highlights, what you liked? Impressions can be very short. Just, you know, one, two sentences. Are we good? Perfect.
05:30:29.210 - 05:31:17.796, Speaker A: So now it's my pleasure to introduce Kirill, who describes himself as ethereum ecosystem enjoyer. He will be shedding the light on how the evolution of blockchain explorers contributed to meeting the needs of the web. Three users, the stage is yours. Thank you. Hi everyone, my name is Kirill. I work as an engineer and the head of protocol research at Bloxcroud. So today we wanted to talk about basically what people are using block explorers for, what people need block explorers for, and what's happening within the ethereum ecosystem with all this dark forest of layer twos, data availability, account abstractions and so on.
05:31:17.796 - 05:32:30.930, Speaker A: So if you haven't heard about Block Scout before, Blog Scout is an open source platform for building EVM compatible block explorers for EVM compatible chains. So it's the most widely used block Explorer open source block Explorer on the market. So, yeah, let's start first with understanding why people, as users, as an end users, actually need block Explorer and what they are using it for. So the main goal of an end users, as we see it, is probably that you want to get this simple, free and transparent access to the real time and historical data related to their own accounts, their own addresses, their own transactions as well. They want to get access to this data in regards of everybody else. And so being able to monitor all these actions that are happening on chain, then the next big requirement is everything that's related to the visualization and interpretation of this raw blockchain data. So probably only advanced developers are able to deeply understand what's going on if they take a look at what's coming in and out of the JSON RPC or something like that.
05:32:30.930 - 05:33:53.234, Speaker A: So part of the goal of the block explorer is to visualize this data into, interpret it in some way that's clearly and simply understandable by the users. And then the last point is somehow related to security. So for example, with the recent accident with the backdoor at the XZ compression Utilities library, we have definitely seen, and now can understand how important it is for the security of the whole open source space that someone is actually paying attention to what's going on in this open source. And open platforms and blockchains are very similar in this sort. So if nobody is kind of looking at what's happening in different smart contracts, nobody is monitoring them, nobody have access to simply view what stuff is going on in some particular smart contract, it really becomes a big problem in terms of security as well. So as I said, the main challenge here is probably just to find a way how to convert and interpret something as raw and as complex as the results coming in and out of JSON RPC. So here for example, is the example of transaction received for some transaction only, Ethereum mainnet.
05:33:53.234 - 05:34:40.550, Speaker A: So we need to find a way how to display this data in a way that's simple and easy to understand for Ethereum users. So that was from the client perspective, from the user perspective. Now what's going on from the change perspective. So what we've seen recently is this exploding growth of the number of networks and number of layer one, layer twos that I go that are launching every day. Basically with all of this roll up as a service platforms, it's now as easy to launch your own roll up, and it can be done as quickly as like in a few minutes, in a few hours, and it's not much difficult even if you are doing it on your own. So all of these roll up stacks today have a very good documentation and it's really easy to launch a rollup. All of this is open source.
05:34:40.550 - 05:35:43.354, Speaker A: And the problem here is that such an approach, such a velocity of launching new chains does not work well with any proprietary technology. So you won't be able to launch proprietary Explorer for the roll up you just launched in a few hours, just because it will take a lot of time, it will take a lot of money as well. Another approach might be building an in house Explorer, which is also not something that most of the team can afford due to the time and cost restrictions. So here what we are trying to do is we are trying to build an open source alternative which is feature rich and can be used to quickly and easily launch the block explorers for your roll ups in a couple of minutes as well. So as of today, the Bloxhowt is the most widely used Explorer for the EVM networks. So it's completely open source, it's compatible with the EVM on layer one and most of the layer two s. It has a lot of different modules to account for these customizations on different chains.
05:35:43.354 - 05:36:40.666, Speaker A: They can be turned off and on the different platforms. So it's also kind of a plug and play approach here. So yeah, it's easy to install and launch. It can be done for free, it can be done with us as a hosting service and a lot of different roll up as a service or similar providers also provide some services in bundled packages or separately for hosting and explorer for whatever chain you're using them for. So for the past couple of months in Bloxcard, we've been hardly working on adding enhanced support for different roll ups. We have looked into researching support on different app chains and the customizations required for them. We have taken a look at research and support, different views for data availability, account abstraction, some nice enhancements for the life of the developers in regards to contract verification.
05:36:40.666 - 05:37:47.656, Speaker A: So that's what we're going to talk a little bit further down the line. So let's start with the first with the customizations for the layer tools and layer threes and layer fours and whatever. So right now we have these four major families of roll ups that everyone is basically using. So that's a nice thing that although we have these hundreds and thousands different roll ups, only a few families have been actively used so far. We've completed the full support for the op stack and the Polygon CDK, and the support for the remaining major two players such as Zksync Stack and the Arbitrum Nitro, which powers the arbitrum chains and the orbit chains that are launched on top of arbitrum. So this support is coming fairly soon as well. So the support for the layer two, layer three roll up on our block explorer means typically that we have some custom views and indexers for the displaying the deposits and withdrawals that are happening on the native bridge.
05:37:47.656 - 05:39:11.144, Speaker A: It has also something to do with the indexing of the transaction batches, and that's something that typically the chain developers use to monitor the health of the entire network so that all the batches have been submitted in time. The bloxcode is also able to track the status of those batches, how they are submitted on layer one when they they are verified, in case it's a Zk roll up then they are. So the block scout is also tracking the status of these batches at different stages. And yeah, the last thing is just it also requires some sort of maintenance to keeping up with all these l two spec changes. Just to give you an example, in the recent couple of months, optimism already underwent a couple of major hard works, one of them related to some internal optimizations and then the second one related with the migration to the EAP 4844 and the next one will enable fault proofs which also affects how the things are working under the hood. So another interesting idea we have about blog explorers is that we believe that block explorers should not only be a read only platform, but it also should be an interactive explorer and an interactive platform for different types of users. So we have this nice interface for interacting with the smart contracts.
05:39:11.144 - 05:40:28.688, Speaker A: Basically you can interact, read and write to the smart contracts if their source code is verified, if it was verified on some other network and we are able to match the bytecode or extract the ABI methods by some other means, then we also build this dapp marketplace inside bloxcode. So it also helps a lot on the especially low level chains there that people can use the bloxcard as a way to discover different dapps that are available on this particular network. And it's not only about discovering these dapps, but most of the dapps can be actually used in the same tab. So the people don't need to open any website so they can launch the dapp directly within the bloxcout and it will be opened within the iframe and the wallet will pass through and automatically connect to the same wallet you've used to connect to the bloxcout. So another thing that's related to the layer two indexing is the support for different data availability solutions. So here with the bloxcout we are trying to build some synergy. In a way boxcals for different layers are organized so that it kind of resembles this hierarchical nature of the roll ups themselves.
05:40:28.688 - 05:41:38.554, Speaker A: So we don't have an explorer for data availability solution which are launched below the Ethereum mainnet, but then we do have an explorer for the Ethereum mainnet and then in this explorer we also index the data availability from the Ethereum consensus layer and display these blobs. And then for all the block scouts that are built on top of Ethereum, Mainnet or some other layer ones, they're using the underlying level including block scout, and they will ability to index all of this data, batches, transaction batches and so on. So just a nice example for how we index the blobs from the main net. So with the recent Benkun harp work, we've also added this support for the blobs view. So you can for any blob transaction, see and access this blob data forever, which is also stored in the blox cloud. And then we went an additional extra mile within interpreting this data as well. So if we are able to detect that the data submitted within the blob is not just some arbitrary binary data, but it's an image or a text, we also will try to detect coded.
05:41:38.554 - 05:42:32.134, Speaker A: So that's just some fun stuff to do. And yeah, as it turned out, submitting actually some image or meaningful information within the blob is not just as easy as putting this binary data within the blob content. So because there are some restrictions on the, on this content. So in fact, each blob is required to be a number of very large numbers below a certain limit. So if you want to submit an arbitrary image, let's say within the block, some bit level and byte level manipulations are required. So you need to split the file in different chunks, left byte them with necessary amount of zeros, and then group them back and reassemble as blobs. And only then you will be able to submit them as a valid blobs on chain.
05:42:32.134 - 05:43:36.854, Speaker A: Yeah. Then the next big topic within the blog scout is the support for the account abstraction. So the goal of the, and the general narrative of this account abstraction within the ethereum is that all the ecosystem participants are trying to simplify and reduce the complexity for the end users. They are trying to reduce the complexity of managing their own seed phrases, managing private keys, managing the complexities of gas prices, transaction resents and so on. But this all works very well. But when you try to access the account abstraction operation or transaction where your operation was included into within the general, the traditional block explorers, you are not able to understand basically anything because, well, the complexity for the end user is decreased at the same time it's in increased on the lower level within all of these batches. And so if you open the transaction as is in the blog Explorer, you won't be able to understand very much of it.
05:43:36.854 - 05:45:09.054, Speaker A: So in blogscout we also attempted to create this view for the meta transactions, which are user operations submitted as part of the ERC 400 337. And as of now, the Blox cloud stack also provides this standalone opt in account obstruction indexer, which can be launched for any chain that does use this ERC standard. And so yeah, the way it works is that it's a separate service that's responsible for indexing all of the events and the stuff that's going on with the official entry point contracts on all of these chains and then the blocks out API and the rest of the stacks built on top of it. Yeah, just to give you an example about this increase in complexity within this particular ERC, typically one of the most acquired thing you want to understand about your operation is just what contract has been called and what method was called. So this information generally helps you understand if some tokens were transferred, if you deposited to some protocol and stuff like that. So for that in regular transaction, it's enough just to decode the top layer of the transaction and you will directly see what contract was called and what method, and already you will be able to reason about it somehow. But then when you are performing some kind of operation within the user operation, according to the CRC, it's actually deeply hidden on like three layers deep.
05:45:09.054 - 05:46:04.984, Speaker A: And so if you need to decode this call data and to actually understand what's going on, you need to manually go through these three levels. And so it would be nice if the blog explorers would be able to do it using the predictable ABI selectors, which are the same for most of the user operation as of today. And so yeah, that's just an example how the user expression can be displayed within blox cloud. So it looks fairly similar to the general transaction use. So you don't see any complexity within these bundles. Although this user operation is probably part of the bigger bundle, it was submitted by different party, you've still been able to access and see all of the fields that were directly decoded from this user operation. And then we also displayed the token transfers and rollogs just relevant for this particular operation so you don't get any information that is irrelevant to your particular action.
05:46:04.984 - 05:47:46.720, Speaker A: And then the last thing I want to talk about and mention is the efforts we are trying to apply in the field of simplifying the life of smart contract developers. So a big problem within the smart contract developers world is this pain of verifying different contracts on different channels. So it's always been a problem and so for a long time in Bloxcalt we had this feature called Block Scout by CodedB, which basically allowed verified contracts to be shared across different instances instantly across different blockchains. So if you ever deployed your contract, let's say 100 chains and the bytecode is exactly the same, then you will only be required to verify it once and then it will propagate instantly to the rest of the chains as the bytecodes are the same. So this source code database will be shared. And so as a continuation of this feature that was only present in Bloxcout, we with some other partners representing different block explorers, individual researchers and others came up with this verifier line solution, which is an ecosystem collective that's trying to build this open database that different parties are able to write and read at the same time so that contracts can be submitted, verified as simply as possible, and then be immediately available within different blog explorers connected to this database. So more info on the Verifier alliance is coming this year on the upcoming conferences as well.
05:47:46.720 - 05:48:42.882, Speaker A: So yeah, stay tuned and connect with the verifier alliance in the chats if you wanted to as well. Yeah, I think that was pretty much it. Please get in touch with our team if you are planning to launch your own roll up or have some ideas about what can be improved in the blog scout, what new views might be added, what features are you missing? Yeah, thank you very much. That was very insightful. So we have a few minutes for questions. Yeah, thanks for the presentation. So I'm not sure, is the transient data, is it possible to reflect and display it somehow in the block explorer? And if you guys perhaps addressing that already.
05:48:42.882 - 05:49:31.554, Speaker A: What do you mean transient data? Yeah, yeah, the one in the latest update, the Denkun from the previous talk. Yeah, this transient storage. Yeah, that transient storage. I'm sorry? Yeah, I think it maybe makes sense to add the views at the same time for the regular storage and the transient storage. So there is no many difference between how the infrastructure can index those. So basically for any storage updates, I think the raw traces include accesses and reads and writes to both types of storages. So as long as we'll have some view for the general storage changes, yeah, it should be no big problem to add the transient one as well.
05:49:31.554 - 05:50:26.266, Speaker A: Hello, great presentation, thank you. If I understand correctly. So the main difference between your solution and for example etherscan which is also like blockchain Explorer, you can also explore on different chains like on polygon and also optimism. Am I correct? Yeah. So the main difference is that Bloxcloud is open source and the EZR scan is not. So for any chain you are able yourself without asking any permission, without paying to anyone, just go download the latest docker image for Bloxcode, go through quick start guide and launch within a couple of hours. The explorer, you just need to subsidize the infrastructure request for yourself to run in the database, the API and so on.
05:50:26.266 - 05:51:27.154, Speaker A: But yeah, so you don't have to ask for any permission or pay anyone at some point. Of course, people from the larger chain, they just don't want to host it themselves. And so in this case they probably are going to ask to ask if they can host the explorer for them at our infrastructure for some fee and manage all the updates, all the customizations and so on. Does your project have new different feature like in comparison with Etherscan? Some additional functionality? Yes, I think the biggest, probably additional functionality is the support for the user operation for the account abstraction standards. So that's something that's not present in any other general purpose blockchain explorer. So there are some explorers just for account obstruction, but this information is not present in general purpose explorers. So that's the biggest feature.
05:51:27.154 - 05:52:00.422, Speaker A: We have some others on specific chains that these chains are not supported by userscan because people don't want to pay as much as userscan asks. So we have some customizations depending on the particular chain as well. Yeah. Thank you. Thank you very much. We still have a couple of minutes. Is there any other question from the audience? If not, then kirill.
05:52:00.422 - 05:52:40.784, Speaker A: Thank you very much. It was a pleasure. So we have the last session for today, but I'm sure not less exciting than the previous one. So I'm thrilled to introduce Hodelon. He builds privacy tools as a project coordinator for PSE. In his free time, Hodelon contributes to Daos, produces fully immersive events or gross trees. His topic today is zero knowledge proof of reserve.
05:52:40.784 - 05:53:05.194, Speaker A: Please come on stage. The stage is yours. Hello. Welcome everyone. We've made it through three days. Everyone's doing well. Hope to see you after this for drinks, after party and everything.
05:53:05.194 - 05:54:10.730, Speaker A: I'm here to talk about zero knowledge, proof of reserves and just as a really quickly about me. So I work at PSE building privacy tools. I coordinate projects, help projects. I am on coming from the non technical side of things, so I'm not going to be going into how the proofs work, going into the math and all that, but more so giving a general overview and hopefully helping you understand more about the history of proof of reserves, kind of how we got here, what exactly it is, how it works, and then how the project that one of the projects that I'm working with, the project I'll be speaking about, summa, is aiming to tackle a lot of these problems and what we've accomplished. Okay, so brief history. Some of us, most of us might have heard of Mount Gox. They filed for bankruptcy in 2014.
05:54:10.730 - 05:54:47.994, Speaker A: They were the largest bitcoin, or cryptocurrency exchange. I think it was just bitcoin at the time. They filed bankruptcy for 850,000 bitcoin, which was, like, maybe $4 million or something then. And then after the bankruptcy proceedings, there were, like, 200,000 bitcoin that Mark Capellis just happened to find on an old computer. Whoopsie. People were very upset. A lot of people lost a lot of money for trusting this exchange.
05:54:47.994 - 05:55:42.862, Speaker A: Okay, FTX, we all know about FTX. They essentially pursued aggressive growth over actually doing things by any sort of book. They were using all sorts of accounting wizardry to kind of create value. They were also taking funds off of their main exchange and moving them through backdoors to Alameda to kind of their sister corporation, and essentially misusing customer funds in order to appear solvent, when really they weren't. When FTX went under, it brought down the entire cryptocurrency industry. The prices crashed. Celsius, Voyager, and Blockfi also filed for bankruptcy around this time, and it forced a lot.
05:55:42.862 - 05:57:04.754, Speaker A: It forced us as an industry to kind of look at ourselves and question these institutions that we are trusting. And in both of these cases, not only did customers not know what was happening with the funds on the exchange, but the exchange themselves did not even know what was happening with the funds that they were trusted with. So from that, this concept of proof of reserves has come about, which is essentially, can you prove that the assets you have are greater than the liabilities on your books? Liabilities being customer deposits. That's what proof of reserves means. Also, proof of solvency is another term for it. But in a nutshell, do you have enough funds to cover all of the customer? Do you have the assets to cover all the customer funds if all the customers wanted to withdraw at once? Essentially, funds are seifu. Proof of reserves does not need to be applied solely to an exchange.
05:57:04.754 - 05:58:09.414, Speaker A: You can also consider any custodian. We call them custodians. Any service that takes cryptocurrency takes funds and then holds them for customers is the proof of reserves can apply to. Okay, so there is no. There are no anywhere in the world there are no hard requirements for an exchange or for a custodian to offer these proof of reserves. What we are hoping is that, or kind of what we see is that from both the bottom, the user base users demanding these things from exchanges, and then also kind of the top down approach of anticipating that regulators at some point will require exchanges to be doing these audits and proof of reserves. Okay, so how do proof of reserves work? So you have your assets, you have your liabilities.
05:58:09.414 - 05:59:17.262, Speaker A: It is imperative in order to have a proper proof of reserves that you reveal both your assets and the liabilities. So if you say that you have $1 billion in assets, but you also don't reveal your liabilities in any way, then maybe you have $3 billion in liabilities and you haven't really proven anything. Likewise, if you say you have a billion dollars, billion dollars in liabilities, if you have no assets to cover that, then it doesn't matter. So a proof of reserves audit is a, the way that they are typically run is that they are a snapshot of a point in time. It's not a kind of rolling amount, like a rolling balance. You kind of need to, and most exchanges will do these. Some of them will do them annually, some of them every six months.
05:59:17.262 - 05:59:51.514, Speaker A: I think an exchange does them every month. The longer time in between you have these audits, the more potential you can have. You can imagine like an exchange moves the funds somewhere and is doing something with them, and more of a likelihood that they're not going to come back in there for the next audit. We'll get into that frequency later on. Another component of proof of reserves of how it works. They use merkle trees. This is where the cryptography comes in.
05:59:51.514 - 06:01:03.764, Speaker A: So every user is, every user with a balance is assigned a unique id and then is put into. With their balance is put into a merkle tree. So all the users are leaves. And then the root of that tree can be shared publicly without revealing how many users there are, what their amounts are. This retains the privacy of the users, and it also allows the exchange to reveal this information as well, without revealing more than they might want to. Suma, as we'll get into a little later, is we're experimenting with some alternatives to merkle trees, which is kind of interesting, but most every solution right now just uses merkle trees. Okay, so current solutions also use auditors, third party auditors that essentially come in and look at the books and the merkle tree, the proof that you use as a user in the merkle tree is essentially verifying that the auditor has included your balance in that audit.
06:01:03.764 - 06:02:16.018, Speaker A: So the systems that are being used now, it is still dependent on a third party auditor. You still having to trust a third party auditor to that they are acting in the interest of you, that they're not corrupt. And most of the major auditing firms in the world don't touch crypto. And then the several that have been working with crypto firms just recently, within the last year or so, have stopped working with them. So there are less and less options to actually even use a third party auditor. Okay, so this brings us to Vitalik releasing a post on his blog, as he often does, and kind of outlining everything that we had just talked about, using cryptography to allow exchanges to show that they have the funds. He talks about kind of a world in which we are more accountable.
06:02:16.018 - 06:02:53.726, Speaker A: We're not just relying on these exchanges, but we should actually hold them accountable. And we can use cryptography, we can use these tools to be able to do that. From this paper specifically, is where Suma came from. So, Suma, the name Summa comes from a 15th century paper that was published by a friar. And he and this paper, or this book essentially outlined accounting methods, double entry bookkeeping. It's in Latin. Summa means sum or summary.
06:02:53.726 - 06:03:57.004, Speaker A: So that's where the name Summa comes from. So Summa aims to cut out the need for third party auditors entirely from a proof of reserves, so that we no longer have to rely on these auditors and these trusted third parties, and we can just rely on the math to do it. Sim is also we're looking to optimize for the speed at which the proofs, the commitment proofs and the inclusion proofs are generated. And doing that in a more affordable way, you can imagine it takes a lot of compute resources in order to generate large sets of proofs in the order of millions, hundreds of millions of users. If you're in exchange. Something else that Suma has done is to put the verifier for the proofs on chain. So this leads to increase user experience.
06:03:57.004 - 06:04:41.092, Speaker A: The user doesn't have to download any software and use that to validate their proof independently. And it can also be, we can be assured that everybody's using the same verifier. It's all coming from the same place. Okay, so I mentioned earlier that most solutions use merkle trees. So Suma's. The first version that Suma released was a Merkle tree. And then in the interest of trying to optimize for the speed and the cost used for the second version, and univariate sumcheck protocol, which is kind of a novel use of this technology.
06:04:41.092 - 06:05:15.924, Speaker A: It's typically just used within circuits to prove. To prove things. And in this case, we're kind of pulling it out of that and using it in a more applied way. And then the next version that we're working on now is moving from univariate to multivariate sumcheck protocol, and we are hoping that this also brings further optimization. Okay, so how Sumo works. First, the. The exchange for the custodian needs to prove their address, ownership.
06:05:15.924 - 06:06:09.824, Speaker A: Anybody can point to an account on a blockchain and say, those are my funds. But unless you move a certain amount or you produce a signature from that wallet that's verifiable, anybody can point to any funds on the blockchain and say that it's theirs. So, in order for the custodian, in order for us to believe that the custodians funds are actually theirs, that they are in ownership of them, they need to produce a batch of signatures, and then that goes on chain into the contract from there, and that is done optimistically. Okay. There's no. That those signatures aren't validated or verified by any of the cryptography. That's just for us, the user, users, and the public to look and see and be able to see how many funds the custodian has.
06:06:09.824 - 06:07:30.674, Speaker A: So then a liabilities commitment is made. So, this is essentially a commitment proof that says, these are the amount of funds that we have, and then from there, you create an inclusion proof. So there's the one commitment, and then inclusion proofs are created for every customer. So every leaf of that tree or everybody with a balance gets a proof and can then take that proof and go to the commitment and prove that their funds are in there. In that way, the exchange is much less likely to cheat by saying that they have more liabilities than they actually have. So, ideally, if every person goes to prove that they're in there, and then somebody raises their hand and says, my proof is not actually valid, my funds were not included in here, that might mean that there's something fishy going on with the exchange and the funds that they're using. So, from there, users can verify again that they were included in the liabilities and accounted for in the liabilities, and the loop is closed.
06:07:30.674 - 06:08:32.660, Speaker A: Okay, so some of the challenges that we face with this so far, the solutions that we've come up with are only nominally better than current solutions. However, there are improvements, like putting the validator on chain. The concept of removing a third party auditor completely being taken out. And then again, we're hoping that with the next version that we're working on using the multivariate Semtrac protocol, that we can get even better results. So the solution requires that custodians both publish the funds that they have on chain. So they say, these are our wallets, and sign a transaction with them, or not a transaction, but create a signature with those wallets. And that creates a lot of issues.
06:08:32.660 - 06:09:02.928, Speaker A: If you're an exchange, you might not want to, you might not want people to know which wallets are yours. For security reasons, and also for security reasons, it might be difficult to sign wallets. So this is another. Create signatures with wallets. So this is another challenge that we run into. It also requires the custodians to implement it. Even if a custodian is completely honest and has nothing to hide, so to speak, it still takes a lot of work to implement these things.
06:09:02.928 - 06:09:43.784, Speaker A: You have to dedicate resources to it. You have to push this as a part of your platform and market around it, let people know that it's there. And even then, a lot of exchanges have found that even when they do go through all of the trouble and the work to make this available, people don't always use it. Okay. Not the exchanges fault, but if people aren't using the things, then an exchange is using the tools, then an exchange is less likely to make those tools available. Okay. Also, exchanges use a lot of complex accounting.
06:09:43.784 - 06:11:00.540, Speaker A: There's margin loans, which creates more liabilities and can also create negative numbers if somebody is liquidated. And so the current version of Suma does not account for kind of these advanced accounting practices either. And then the last one is that Suma only accounts for the on chain assets, not fiat that an exchange might have as well. This is actually kind of an interesting problem to solve. There's some other projects at PSE TL's notary ZK email that we're going to be experimenting with in this coming year to try to tackle this specifically to help basically come up with solutions to cryptographically verify not just on chain assets, but other assets as well. It's very interesting. Okay, so in conclusion, we can use cryptography, we can use math, we can use zero knowledge proofs in order to hold exchanges accountable.
06:11:00.540 - 06:11:32.604, Speaker A: These institutions that we rely on that are an integral part of the industry and of crypto in general, being off ramps and on ramps, we don't just need to trust that they're going to act in good faith. They've shown that they have not. We can use cryptography to ensure that they do. You can check out the GitHub. Join our telegram if you have questions. And then I'm odd along on all of the stuff. Thank you very much for coming.
06:11:32.604 - 06:12:27.324, Speaker A: I appreciate it. Thank you very much. We have a few minutes for questions just here. Yeah. Thank you for the presentation. I just curious how many partnerships with exchanges you have and have you have any successful integrations of your protocol into exchange? No. So the kind of the difficulties, the challenges that I was talking about doesn't make Suma as is kind of out of the box integratable into exchanges, but we have been talking to exchanges about different concepts that they can use using zero knowledge proofs and using the things that we're kind of exploring to help them develop that.
06:12:27.324 - 06:13:47.090, Speaker A: So, Suma, to answer your question, Suma's not specifically integrated into any exchanges currently. And in fact, most exchanges either don't have them. There's very few exchanges that actually have a proof of reserves and a lot saying that they have some coming and they're investigating them. So kind of developing along with that. All right, anyone else? Hi. Yeah, thanks. So as far as exchanges, it doesn't only, like, I'm presume that it doesn't only solve, like, the solution, your solution doesn't only solve the problem of, like, displaying that the assets exceed liabilities for the exchanges, but probably like down the road something more where like, if an exchange resides in like, some specific jurisdiction where the authorities demand something from it to report on something, and then instead of like, disclosing all the information and saying, okay, here are all the things, and, you know, KYC, about our customers and all the numbers, but instead wraps those claim into some claims and provides that to authorities saying that, okay, well, we're not going to disclose all the sensitive information, but we're going to prove that these customers are solvent, they have everything else and compliant with everything else that you need.
06:13:47.090 - 06:14:28.654, Speaker A: Am I reading it right? Yeah. So those are some good examples of ways of using zero knowledge proofs, right. To be able to comply with regulation and be able to do what zero knowledge proofs do, which is reveal things without giving away what they actually are. The way Suma is designed right now doesn't allow for that specifically, but that would be kind of an addition or kind of a change that could be made to include those type of things as well. Yeah. Thank you. We still have time for one more question.
06:14:28.654 - 06:14:54.914, Speaker A: Okay. If there are no more questions from the audience. Thank you very much. And put your hands together for Holy Lonnie. So that was the last session of today, but please stay on your seats. The organizer would like to share closing remarks in few minutes. Thank you very much for your attention.
06:14:54.914 - 06:21:07.466, Speaker A: It, it, it, it. We have to talk a little bit about the report actually. Yes, and later I would like to talk a little bit about the report that we discussed on Friday. So thanks everybody for being here also Sunday in the afternoon, and also to have still the willingness to listen to us once more. So I'm really thankful once again to you all and basically to many things, people. First of all, I'm grateful to the people from Pone, the people from duct tape productions, that helped us a lot in the organization. Actually, they drove the organization of this Ethereum survey for a second year in a row.
06:21:07.466 - 06:21:29.454, Speaker A: We're really happy. Also, I'm happier than last year because of the venue, but also because of the interactions. There is other people. I thank the external ones. I also wanted to thank the internal people from our own university. That helped a lot in the organization as well. For several months, they are squeezing into the room now, some of them at least.
06:21:29.454 - 06:22:01.292, Speaker A: Benjamin Kraner. It was driving a lot of these activities here. It was doing a lot of operational effort, trying to get the rooms, etc. Something that's very hard in middle of the semester inside of the University of Zurich. Sue Houston, who is also managing our events and partnership at the university, was very instrumental for this. Niccolo was also heading the academic part, the academic track of this conference, and their work that they did was enormous as well. This is with respect to organization.
06:22:01.292 - 06:23:05.904, Speaker A: I think that one thing that I like very much of this iteration of ethereum Suri is that there was a much more level of activity, much more level of interaction. This is why I'm so thankful to the people that gave life to all the discussions that were happening here, but also to all of those that contributed to the program, to which I am really thankful to. I think that this space is very sentimental in some way, in some periods of time. I think that it is important. One thing in this space is not only continuing with the innovation, like in the language, as we were discussing a few minutes ago with Alex, but trying to see the new things that we can do. In many cases, from a technical point of view, there are a lot of things that have been developed that we saw how they may change processes that we have done in the financial services, in other kinds of digital platforms. But the important thing is trying to get a digital ecosystem in which these decentralized platforms coexist.
06:23:05.904 - 06:23:30.080, Speaker A: And can competitively and cooperatively bring forward this space. So I think that you continue working like you have been doing in this year and we can meet once again in the near future. Thank you. And now the word to yourself, that's going to be fantastic. What else to say? Thank you so much, Claudio. I just want to basically also thank everybody, especially the attendees. Thank you, Claudio.
06:23:30.080 - 06:24:23.434, Speaker A: And the blockchain center of the University of Zurich. Also special thanks to Ben and Sue. I don't see her, but they were heavy lifters here on the side of the university. Yeah, almost honestly, I almost missed the closing. I was just like having interactions out there and I was like, oh, shoot, somebody had to call me because otherwise I wouldn't really be here. I think even though you can say the kind of the merge of universities, the academic ground and technology is quite common, it's actually quite unique in the sense of how, especially you guys. And the blockchain center was basically approachable and super helpful in the entire process.
06:24:23.434 - 06:24:58.996, Speaker A: Just a short anecdote. We also host Eat Prague, to which I'm going to invite you in a bit. But I always dreamt of the local universities, but basically just coming, just showing up and talking about what they do and maybe having booth to just like, let people know what they work on, but it's hard. And I recently had conversations with several universities in Prague to get them to eat Prague. And I couldn't believe it because I was like, but guys, we don't ask you for anything. Just please come. Just please be there.
06:24:58.996 - 06:25:31.266, Speaker A: And we're like, oh, there is this process. We don't really. I was like, how come? How come this is so easy with the guys from, from Zurich and won't happen here. So it's not so natural. So thank you again. So finally, I just want to thank again our sponsors, Dfinity, the Internet, computer, Ackee and their project wake anoma and swarm. Really, this wouldn't happen without you.
06:25:31.266 - 06:26:10.518, Speaker A: This was the, this conference. I think it broke even and wouldn't be possible without these sponsors. Then, of course, asymmetrics protocol code based by avalanche Vault, coin and Webtree Foundation, Ethereum ecosystem support program, argon safe circuit and signum. Thank you again. I have to say it out loud, Signum is the only bank that doesn't hate you. And yeah, I'm really, really grateful to see all of these ecosystem programs, the foundations behind what we were talking about for three days to actually support these efforts. So now, actually, the one last thing, and it's not like an apple keynote type of thing.
06:26:10.518 - 06:26:41.054, Speaker A: It's actually much simpler. And the simpler thing is. Let me just reload this. Did we lose anything? Oh, okay. And think. See, it's just. We're just trying to create a mystery, but we're not really good at this, so we have to wait for it.
06:26:41.054 - 06:27:12.206, Speaker A: Just mirror the screen. So I just want to invite you to our next event, which is happening in Prague. May 31, still June 2. It has a slightly different vibe. It's not about academic research. It's not about talking about regulations. The theme of ETH Prague is Solarpunk.
06:27:12.206 - 06:27:46.168, Speaker A: What do we want to dive into is sustainability and societal issues and how they can be actually solved through the technology that everybody is occupied with. You are all wholeheartedly invited to join us in Prague. And there's also be a bigger hackathon part to this. So if you are interested in coding something and actually getting your hands dirty, this is the opportunity. And with that, this is really it. Thank you so much, and I hope you enjoy the rest of the time here. I hope to also see you next year on one of the occasions.
06:27:46.168 - 06:34:59.964, Speaker A: We still have to figure everything out with Claudio, but I'm quite certain we'll figure it out and let you know hopefully soon. Thank you. It. It.

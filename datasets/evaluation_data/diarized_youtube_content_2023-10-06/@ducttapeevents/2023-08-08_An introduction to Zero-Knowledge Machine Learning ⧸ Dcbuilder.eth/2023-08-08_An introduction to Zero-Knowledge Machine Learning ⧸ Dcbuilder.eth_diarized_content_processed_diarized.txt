00:00:01.520 - 00:00:13.554, Speaker A: Hello. Hello. Let me just grab the clicker real quick. All right, so, hello. Hello. I'm DC builder. I'm a research engineer, and I work at Worldcoin on the protocol team.
00:00:13.554 - 00:01:11.794, Speaker A: So my day to day, I usually spend it working on applied cryptography, some distributed systems engineering, solidity, rust, things around that nature. And recently, or for the past few months, I've been doing some research around the topic called zero knowledge machine learning, ZKML. And so it's a really early stage technology that might have a lot of useful applications in the domain of blockchains. And since it's really early on, I just wanted to give an introductory talk that sort of explains what it is, what you can, what you can do, where the state of the art is what you can, what tools you can use to sort of do a ZKMl. And, yeah, just give a brief introduction into what the topic is all about. The clicker is not working for some reason. So it's the clicker, it's not working.
00:01:11.794 - 00:01:50.376, Speaker A: All right, that's good. Yeah. So first, let me boil down ZKML into its two constituents. So, first we have ZK. As you heard in the previous talk, ZK is sort of this piece of cryptography that allows you to essentially prove that some computation happened correctly, and you can also hide parts of this computation. So the workflow is that you have some computer, they do some computation, they generate a proof that that computation happened, and any verifier can verify the correctness of that computation. So in the context of ML, right, it goes back.
00:01:50.376 - 00:02:14.124, Speaker A: Oh, it works the opposite way. Okay, never mind. Yeah. So in the context of ML. So ML, what is ML? Right. So machine learning is a sort of group of algorithms where you have some form of goal or task you want to solve, and you create a sort of heuristic solution for your task. By heuristic, I mean just a good enough approximation.
00:02:14.124 - 00:03:02.984, Speaker A: The way you achieve these approximations is by using several algorithms that sort of have statistical learning in some way or another. Right. You have these sort of like neural networks. If you've heard of them, they're able to sort of get trained on lots and lots of data, lots and lots of examples, and they're able to sort of learn how to solve a specific task based on, like, either, like reinforcement learning, where they, like, ask a specific rating mechanism to rate their task solution, and they essentially get better over time. So in the context of ML, the problems you're usually solving are like classification regression. You're trying to solve some form of optimization for some sort of problem. And the reason why ZK is useful for this is you essentially able to prove these ML algorithms end to end.
00:03:02.984 - 00:03:35.474, Speaker A: You're essentially able to prove that, hey, if I have some input and I feed it into some model, I can get an output and I can prove that all of this happened correctly. So for example, I can say to my friends, hey, I have computed this model on this specific input, and I have this output. So let's say I have a model that is able to discern between a dog and a cat. So I can just feed it an image of a dog or a cat. It has some output. It tells me, hey, this is a cat. And I can prove to anyone that I did indeed do this computation.
00:03:35.474 - 00:04:30.530, Speaker A: So they don't have to run the model, they can just trust me because they can verify the zero knowledge proof. So why is your knowledge so zero knowledge? The main properties that zero knowledge gives you that's useful in the context of machine learning is verifiability of execution. So usually when you're using any ML algorithms, let's say through an API, through a programming interface, you go to like, let's say the OpenAI website, you go to the OpenAI website and they have a model, for example, Whisper. Whisper is a model that does transcription for audio, but the API is very black boxy. You don't really know whether OpenAI is indeed running whisper on those servers. You're just trusting them as an intermediary that hey, you did indeed run Whisper on my algorithm, and you trust because you're paying for some service and you have some legal agreement and they cannot cheat you out of it. However, there is no mathematical proof that they're actually running whisper.
00:04:30.530 - 00:05:20.480, Speaker A: They might be running a much lower or a worse model on the backend and just tell you that it's whisper on the front end and you would have no way to know it. So for this use case, that's where verifiability comes into play. And verifiability of execution comes from the properties of zero knowledge. Cryptography of completeness and soundness, another part of ZK that's useful as the zero knowledge part. So zero knowledge essentially means that you're able to prove the correctness of a statement without revealing any information besides the statement. A sort of good intuition for this is I can prove to you that I computed some model, but I can hide the weights of that model. So I can tell you, hey, my model has x accuracy on some test data sets.
00:05:20.480 - 00:06:03.104, Speaker A: Like for example, it has more than 99% accuracy without revealing the weights of my model. So that's also useful in some context. And when we're talking about ZKML, we're usually talking about proof of inference, right? You may have heard of model training, like training models. You've heard that companies like Google Meta, all of these companies have huge co located data centers that they train machine learning models for years on end to like, try to get the best performance and have the biggest models and whatnot. So this type of computation is really expensive, and it takes a long time to compute. And zero knowledge cryptography only adds more computation. It has an overhead of about 100 to a million.
00:06:03.104 - 00:06:47.534, Speaker A: X depends on which computations you're trying to prove. By overhead, I mean that it's about, let's say like 1000 to a million times more computationally expensive to compute a proof than just run the computation yourself. However, to verify the proof, it's a lot easier than to actually compute the computation. That's the reason why zero knowledge proofs are useful. For example, in the context of blockchains, you can just run some transactions off chain, you can create a proof, and you can verify the mud chain and update the state of the network without having to, for everyone to re execute those transactions. So since proof of training would be two too computationally intensive, the only thing that's currently feasible, and for the foreseeable future, is proof of inference. Just evaluating a already trained model on some input to get some output.
00:06:47.534 - 00:07:16.074, Speaker A: So this is sort of like a simple Venn diagram to essentially combine. Like, essentially, it combines different primitives and constituents in order to explain sort of how ZKML, or like, what properties ZKML has. So we have three. The top one, the yellow circle, is computational integrity. This is the computational correctness or verifiability. I can verify that some computation happened correctly. The bottom left, the blue one, is privacy.
00:07:16.074 - 00:07:50.314, Speaker A: Privacy, as I said, stems from the property of zero knowledge and heuristic optimization. This is what I just essentially, you can think of it as just ML. Heuristic optimization just means that you're trying to optimize a problem for which there's no perfect solution. You're only giving approximations, an approximation you can think of as a heuristic. And so if you combine all three of those, you get ZKML in the middle. If you only combine computational integrity and privacy, you get traditional ZK. Right? What we use in the context of blockchains to verify transaction execution or do private transactions, let's say zcash.
00:07:50.314 - 00:08:42.668, Speaker A: If you only do computational integrity and heuristic optimization, you get validity ML. This essentially means that you're proving that some machine learning model ran correctly, but you're not hiding any parts of the computation. And the last one that I didn't mention is if you combine privacy and heuristic optimization, or ML, you get this field called fully homomorphic encryption. Machine learning. Fully homomorphic encryption is a different type or a different primitive within cryptography that allows you to do slightly different things. Essentially, the difference is full homomorphic encryption allows you to encrypt some data, perform some computation on that encrypted data, and then decrypt it. So that essentially means that you're able to do computations on private data, and the computer that's performing the computations on the private data never gets to learn what the original input was.
00:08:42.668 - 00:09:50.454, Speaker A: So you can do private computation. However, you don't have the computational integrity from zero knowledge cryptography. So here I just have some simple definitions of what I just talked about and use cases. You might be wondering, ok, this is a cool technology, but what are the actual applications for any of this? So the validity property of zero knowledge, the one that allows you to verify that some computation happened correctly, is, in my opinion, is the most useful property out of Zk that's useful in the context of ML. So the first one that I have listed is machine learning as a service transparency. This is the example I mentioned in the beginning, where instead of you trusting OpenAI to give you some model, you can request the OpenAI team or the API to give you a proof that they're actually running the model that they say they're running. If they give you a proof alongside with the output, you can have cryptographic verifiability that they ran some model that they ran the model that they're claiming they have.
00:09:50.454 - 00:10:23.084, Speaker A: And this can work for any context. Another one is verifiable on chain classifiers or regressors that should just say essentially bring ML on chain. So machine learning is very computationally intensive, and blockchains are very computationally constrained. We have Ethereum with 1530 transactions per second. Each block has about 30 million gas with EAP 1559. And the computations you can put into it is very, very slow. So you cannot really do ML on chain, even on l two s today is really hard.
00:10:23.084 - 00:11:34.130, Speaker A: So where ZK is good is that instead of doing the computation on chain, you can do the ML computation off chain, do a zero knowledge proof and just verify it on chain, and you can bring those results. So you can build applications that use ML, um, without having to actually do the computations on chain, which, which brings a whole set of new possible use cases. Um, sort of. One good example of this that I've heard of in the recent, um, months is that, for example, yearn, uh, who is a, or that is a DeFi protocol that does yield aggregation, right? Essentially trying to find which DeFi protocols can give me the best yield on some sort of assets that I provided. So some of these strategies are fairly complex, but if you want to do a strategy that has or involves some form of ML optimization, then you cannot do it on chain. So how do you prove that you're indeed running some strategy on chain is through essentially doing the proof of the ML algorithm off chain, do a proof, send it to the chain, verify it, and then do some computations with it, like run the strategy that you say that you are running. Another one is anomaly detection or fraud prevention.
00:11:34.130 - 00:12:13.046, Speaker A: So there is a few startups in the blockchain ecosystem that are trying to use ML to detect threats, security threats. In this case, whether you see some malicious transactions or some anomaly, you can train a model to learn what normal is the normal day to day of a protocol. There are some transactions that happen in some DeFi protocol. These are the balances and the reserves of the AMM pool, for example. And there's some weird transaction where somebody exploits the entire thing. So you can essentially do something like that in order to prevent attacks instead of having to be reactive to some exploit. If someone detects an anomaly, the protocol can be instantly frozen.
00:12:13.046 - 00:13:15.674, Speaker A: If you provided a proof that an agreed upon model found something that might be potentially risky in this case in the context of ZK. So now just zero knowledge, you're hiding parts of the ML computation. So one good use case is decentralized Kaggle. Kaggle is this machine learning competition platform where essentially, if you are a company that you want to have a problem solved using ML, you can post a kaggle competition with some price attached to it, and different people will try to compete and gets that price by submitting the winning bid and the winning algorithm. So the way it works is that is, company gives money to kaggle and creates the competition. A user wins that competition, and when they win it, Kaggle essentially exchanges the money from the one that created the competition to the user, and the user gives the algorithm that they created to the company that posted the competition. So this has the trusted intermediary, it being Kaggle itself, the platform.
00:13:15.674 - 00:14:02.664, Speaker A: However, if you use ZKML, what you could do is you can prove that your model has more than x accuracy on some test data, which is how you essentially measure what is the best solution. So if you prove that you have the best solution using ZK, you don't have to reveal your model. You can just hide your model. You can just prove that you have some form of accuracy. Once you prove that, you can claim the price that was associated with the competition, and you automatically reveal the model that you've previously committed to. So you can do essentially these cryptographic games where you can hide something and then show it only if you win some form of prize inference on private and sensitive data. So essentially, there's a lot of different types of sensitive data that you might not want to reveal to some form of verifier.
00:14:02.664 - 00:15:00.274, Speaker A: So you can create a proof that you run some model on some private data, and the verifier does not learn anything about the data you ran it on, but you know that it is some form of data that they wanted to have some evaluation on top of this might have used cases in the medical field. Let's say that you want to classify whether some image of a cancer cell is malignous or not. So you can prove to someone that, hey, this is malignous, without revealing who or which original image it was. Essentially, hide any sensitive data that you might want. So I work at Worldcoin, which is a privacy preserving proof of personhood protocol, or, yeah, that's world id. And so essentially, there's a lot of different challenges that we're facing, one of which is that we are building hardware. And when you're building hardware is sometimes hard to essentially give good user experience for people.
00:15:00.274 - 00:16:07.764, Speaker A: In this context. When you go to our piece of hardware, which is an iris biometric scanner, it essentially generates an encoding of the randomness of the human iris, which is called an iris code. And so if we ever update the model for generating these iris codes, you would essentially have to go to this hardware device again. And these hardware devices are spread out to different countries, and you have to go to the same place, physically get onboarded again, and regenerate a new iris code, because if we update the model, the previous iris code is no longer valid. So a good use case for ZKML in this case is that if the user keeps essentially an image from the orb stored on their local device, on their encrypted storage, let's say on their iPhone, they could regenerate their RS code using ZKML. They just download the new model, they download the prover for that specific model, they compute a new iris code locally on their phone, and they submit a proof to the protocol, which is an on chain smart contract. They submit a proof that hey, I've computed a new iris code, and this is the proof that I computed it correctly with the new model.
00:16:07.764 - 00:16:46.644, Speaker A: So that's one use case, another one is making the orb more trustless or more transparent. So this hardware device, we call it the ORB for context. Essentially, there's a lot of execution that happens on the OrB, a lot of computation. And since it's a piece of hardware, currently the way that we enforce that some computations are happening is through a trusted execution environment, a tee. And currently a tee is not very transparent. It just enforces that some computations that you specify are indeed happening, however, to the outside user or to the outside observer. You don't really know what's actually happening on the hardware.
00:16:46.644 - 00:17:50.344, Speaker A: So for example, we can commit to some form of code that's public and open source, and we'd be able to essentially create a proof that hey, we did indeed like this code that's public and open source did indeed run within the hardware device. Another one is two factor authentication. So for example, let's say that when you get a world id, which is essentially this, without getting into much detail, is this essentially private public key pair that allows you to proof that you're a unique person without revealing who you are using zero knowledge. So you just prove that you have a unique world id, which is this sort of unique identifier or passport that essentially represents uniqueness or can prove uniqueness without revealing who you are. And the cool part of this is that if you, let's say you want to do two fa, you can have an image of yourself stored on your own phone, and you could essentially map that image to that specific iris code. And you could essentially do two factor authentication using ZK. And the way that you do this matching is using ML.
00:17:50.344 - 00:18:39.134, Speaker A: So that's where z camel might be potentially useful. And so all these three use cases are the original reasons why I originally got into ZKML. There's a lot of different projects building on top of it, so I suggest you read up more. So I'm going to be showing you a few links. So there's three links here, the QR codes. The first one is the ZKML community is just a telegram group where a bunch of people that are interested in ZKML can talk about different things around ZKML, whether it's new research papers from the ZK side or ML side, or the combination of both to new code bases, new tools, new use cases, new applications, you might be able to build events that happen where people from the ZKML community are at, where you can discuss it essentially. Like the shelling point for where you can talk and discuss anything about ZKML.
00:18:39.134 - 00:19:16.400, Speaker A: The middle one is awesome, ZKML. It's essentially a GitHub repo with a readme or like a markdown file, a text file with a list of resources that I put together about the different ZkML things. So if you want to learn more in deep dive, this is a very introductory talk. I'm happy to answer questions. Now, essentially, it just combines or aggregates all the resources that I found on the Internet about ZKML, whether it's blog posts, podcasts, whether it's code bases, tools, people that are interested in it. So if you want to reach out to them, you can all these sorts of things. And the third one is.
00:19:16.400 - 00:19:50.044, Speaker A: So every single conference, every single time I give this talk, I usually give a sort of shout out to one of my favorite articles that recently came out. So the latest one that I recently read is from one Kx, and they wrote this really in depth blog post, a lot more in depth than this specific talk. So if you want to jump into what ZKML is all about and learn more than this introductory talk, I recommend you read the article on the right. Ok, so thank you. That's everything from me, and I'm happy to take questions.
00:19:58.604 - 00:19:59.344, Speaker B: No.
00:20:02.324 - 00:20:03.028, Speaker C: Does this work?
00:20:03.076 - 00:20:26.466, Speaker B: Yeah, hello. Hello. Yeah, thank you for the talk. So, quick question. Do you have knowledge of current real implementation of CKML working in the world? And what is the overheads that you have seen that you mentioned like a thousand times slower for training, but I don't know if you talk about overheads on inference.
00:20:26.610 - 00:21:04.254, Speaker A: Yeah, 100%. So the current tooling, at least, there's several companies building different types of tools in terms of just generating a proof of any arbitrary computation. So the way that most companies or most projects are approaching this is that you have some machine learning model in a library, let's say tensorflow, Keras, Pytorch. There's this standardized interpretation of these machine learning models. It's called Onnx. It's a standardized format that any of these essentially frameworks can export to. Onnx stands for open neural network exchange.
00:21:04.254 - 00:22:39.992, Speaker A: Essentially, what these tools to create zero knowledge proofs of these models, what they do is that they take the onnx format or the representation of a model, and they transpile it into a zero knowledge circuit. So they create a circuit representation for every single type of computation that's represented inside of this one x representation and then they generate a proof. So the tools, or currently I think the tool that's most flexible for any given user to use, it's called Ezekiel. I'm happy to share your link, or if you just go back to the maybe the presentation is not there anymore, but if you scan the middle QR code, the awesome zkml one, you just scroll down to code bases EZQl and it essentially is a rust tool that creates a proof of an Unix file using the Halo two proving system, the privacy scaling expirations group fork, the one that scroll is using and the one that many projects are using. So essentially creates a zero knowledge proof using halo two. And in terms of the overhead, it changes every single month because they constantly do changes and prs I think right now I wouldn't want to guess, I think it's still around 1000 x overhead. But things I've heard from Jason, one of the co authors of Ezekiel, is that they are already starting to be able to prove models in the sizes of 100 million plus parameters, and it takes I think five minutes on a really big AWS server with like lots of ram, lots of graphics.
00:22:39.992 - 00:22:40.684, Speaker A: Yeah.
00:22:42.744 - 00:23:14.314, Speaker C: Thanks DC. Just one last question please. So how do you think that ZKML differentiates or is better in terms of privacy as compared to probably ML inside a trusted execution environment? I mean in terms of computation, obviously it requires hardware and Z Camel doesn't. But in terms of privacy, how would you compare it?
00:23:14.974 - 00:23:59.224, Speaker A: Yeah, so running ML inside of a trusted execution environment, it gives you some form of guarantee that it's ran correctly within that specific hardware. But if you want to verify that computation outside of that piece of hardware, it's impossible. So the first thing is just like you cannot do on chain ML, because in order for that to work, you'd have to trust that some node has some trusted execution environment. It just doesn't add up. You don't really have the guarantees. What ZK provides you is the guarantees that some execution happened correctly, which trust execution environments do not. They only guarantee you that some form of computation wasn't tampered with within that specific device.
00:23:59.224 - 00:24:02.504, Speaker A: But outside of that environment you have no guarantees that that is actually what happens.

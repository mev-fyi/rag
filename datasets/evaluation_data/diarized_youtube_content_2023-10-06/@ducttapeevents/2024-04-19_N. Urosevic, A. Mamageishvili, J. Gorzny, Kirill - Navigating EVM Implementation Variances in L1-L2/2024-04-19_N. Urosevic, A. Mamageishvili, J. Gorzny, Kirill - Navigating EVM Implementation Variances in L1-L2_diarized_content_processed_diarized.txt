00:00:00.480 - 00:00:11.150, Speaker A: Hey, everyone, can you hear me? Yes. Cool. Hi, everyone. Thank you all for coming. My name is Nabusha. I'll be moderating this panel. I wasn't supposed to moderate.
00:00:11.150 - 00:00:24.782, Speaker A: I was supposed to be sitting with these guys. But nevertheless, the moderator is missing, so I'll fill in. So what we can do for the beginning is we can do a round of introduction so you can state your name and what do you do.
00:00:24.958 - 00:00:49.114, Speaker B: Yeah. Hi, everyone. My name is Kirill. I'm an engineer at Bloxcud, which is an open source, the largest open source evm explorer in the number of chains we support. So, yeah, I'm an engineer there and the head of protocol research. So we do a lot of stuff in researching and supporting different eaps roll ups and different customizations for each of those chains. So, yeah.
00:00:51.174 - 00:01:03.114, Speaker C: Hello, everyone. Welcome to the panel. My name is Akakimamageshwili. I am research scientist of Chain Labs, which is a company that built arbitrum chain that you may know better.
00:01:04.414 - 00:01:14.114, Speaker D: Great. Hi, everyone. My name is Jan Gorsney. I am a technical lead and co founder at Circuit, which is a zero knowledge roll up. And I'm excited to be here to talk with everyone on the panel. So I guess I'll pat.
00:01:16.054 - 00:01:43.410, Speaker A: And my name is Nabusha. As mentioned, I'm one of the co founders at Tenderly, mainly working on some of the core technology behind Tenderly. And currently I'm leading the R and D department. So to kick things off, let's try and address some of the. What are some of the core differences in the implementation between layer one and layer two technology? Whoever wants to go first?
00:01:43.562 - 00:02:22.730, Speaker D: Okay, yeah, sure. I can start. I don't know about core differences. I mean, the l two s and l one s, obviously will do a lot of different features across the board. So, like Starknet and Ethereum, for example, massively different core differences, right? Different VM, incredibly different architecture and design. But I think if this is a panel on EVM equivalence, I'll sort of disregard Starknet for most of this conversation and say there's definitely some other things that I find really annoying that aren't well advertised. And so some of these are like implementing the sort of EVM opcodes in the way that you would sort of expect from a standpoint of an application developer.
00:02:22.730 - 00:03:03.284, Speaker D: So including them, but not necessarily mimicking the semantics of them. So if you look at the block time number or the. Sorry, the block time or the block number on an l two, it's not the same on every l two. And so if you start to fork your standard solidity contracts and defi that compute interest or yields based off of either of those parameters. They're actually not going to necessarily perform the same out of the box on all of your so called EVM equivalent or EVM compatible chains. So I think that's a pretty big issue. I don't know that it's core, because in principle those DeFi protocols can just change it to their chain.
00:03:03.284 - 00:03:35.706, Speaker D: But we were sold on this notion that EVM compatibility or equivalence means I don't have to do any additional work. I can just take my contracts and it will work exactly the same. And I like these examples because they're actually really subtle, like no one really talks about them. And there's actually, there's good people doing good things to advertise some of them. I'm hugging the mic here, so I'll wrap up in a second. Like l two beat does a lot of things like discusses the security implications of roll ups and things like this. But only recently have we seen websites and other people talk about, oh, these small subtle changes.
00:03:35.706 - 00:03:48.644, Speaker D: So there's a site called roll up codes now that, that changes or discusses the changes of these opcodes. And I think that's pretty important, if not core. And then there's probably other things I can talk about, but I'll pass it.
00:03:50.584 - 00:04:59.344, Speaker C: Yeah, so I was actually searching what is the definition of EVM? And I didn't find the exact formal definition of that, but my understanding is most of it, when people talk about EVM, EVM compatibility refers to execution. And there, I think at least arbitrum tries very hard to be exactly compatible with ethereum on the execution layer. So it has implemented Geth for the state transition function. But there is another big part, which is consensus. And this is, I think, what Jan was referring, how transactions are grouped together in case of arbitrum, this like quarter second blocks block times, which is four times, 1248 times shorter than Ethereum block time. And of course application writers should know about this and they need to adjust their interest rate or whatever this is. But I think, yeah, if this is not talked to the public, this at least should be taken very seriously by applications that execution layer stays the same.
00:04:59.344 - 00:05:33.944, Speaker C: Yes, but consensus layer is very, very different. And I'm absolutely fine that it's different, because that's where rollups gain. So this is their selling point, that they have much faster block times. They have centralized sequencer, which maybe doesn't sound good for decentralized system, but it handles transactions much faster. And if rollups had the same consensus layer as Ethereum does, they would be same slow and same inefficient. And I think rollups need to.
00:05:36.764 - 00:05:37.100, Speaker A: Give.
00:05:37.132 - 00:06:31.810, Speaker C: Some improved experience to users. And yeah, so second difference is pricing. And this also should be taken into account, especially by applications that have some long term contracts deployed and they count on. So it's not users who interact with the chain, but it's some contract that pays in the name of users. So pricing can also not be the same because for example, in case of arbitram that has quarter second blocks and there can be a lot of transactions in the same block, it needs to adjust the fee. It cannot wait like Ethereum waits 12 seconds and adjusts by twelve and a half percent maximum. So it can happen that on the arbitrum, the fee spikes much faster than on Ethereum.
00:06:31.810 - 00:06:58.474, Speaker C: And that is just inevitable by just having such a short block times. And this should again be taken into account. I would not call this is a security issue, but more like economic, which can become security issue if those who designed smart contract counted on twelve second and the price update like it is happening on the ethereum. So it can become security issue, but in principle it's not security issue.
00:07:01.534 - 00:07:52.500, Speaker B: Yeah, I'll probably add that. So with all of these different types of roll ups we have today, probably already so many different implementations that you can almost for sure say that we won't be able to come back to this. The same kind of ideal EVM implementation that's the same across the board, and doesn't have any differences across different l one and l two s. So we'll have to leave on and go forward with this difference in mind. So this basically we see differences across the stack. There are some low level differences on the protocol level, so some l one s and l two s support certain transaction types that others don't. There are differences between the block times, as was already mentioned, in the way how gas prices and gas limits work, how the fees are subtracted from the accounts.
00:07:52.500 - 00:08:39.388, Speaker B: Then there are different implications from the transaction inclusion perspective. Like certain mev kind of stuff can only happen in certain chains and cannot happen in others. So there are different kinds of manipulations that can be done in some places and cannot be done in other roll ups. So that's something that should be accounted for. There are a lot of other security implications, again with some specific opcodes, with some specific pre compiles, which can also be present in one roll ups and missing in the other. And another issue is that the space is constantly changing. So we have hard forks, which are happening with its own timeline on Ethereum mainnet.
00:08:39.388 - 00:09:02.784, Speaker B: But then all the layer tools, they have their own schedule, their own changes. Some of these changes, they kind of rely on the schedule of the ethereum in it, some are not. So they all happen in different times. It also kind of affects how the space is moving forward and how we need to support all of these different implementations and nuances at the same time.
00:09:03.604 - 00:09:28.764, Speaker A: Cool. Nice answers guys. So we mentioned some of the differences occurring on layer one and layer two, and we touched base on the EVM compatibility and equivalence, so maybe we can dig deeper down there. So what are some of the distinguishes between those two? What are some the, what are some of the implications of that and how do developers adapt to that?
00:09:31.264 - 00:10:43.344, Speaker B: Yeah, so I think the first thing we need to do is kind of try to define what's the EVM compatibility and what's the EVM equivalence. The way I understand it is that compatibility is something that just, anything that looks like an EVM is something that's EVM compatible. So if you're running something compiled from solidity or something similar, then your platform is probably vm compatible, but then equivalence is something a bit more narrow. So it probably already includes that you need to support certain opcodes, certain precompiles, and they will need to work in the same way they work like for the Ethereum mainnet. They should have the same gas pricing and so on. So of course the level of this equivalence, it impacts the different security considerations. So the more you are equivalent and the closer you are to the Ethereum mainnet, it's probably the simpler it is to kind of deploy some protocol and copy it from the Ethereum in deploy it without any changes to the layer tools, without thinking of some increased security concerns or whatever.
00:10:43.344 - 00:11:20.814, Speaker B: But in the end of the game, yeah, probably no chain, no roll up will be fully 100% EVM equivalent with the Ethereum mainnet. So basically anytime the developer is launching their protocol in this multi chain space, they need to spend some time to review what changes and what differences are between their roll up of choice and the Ethereum mainnet or whatever the protocol was deployed before, and kind of try to understand what are the security assumptions and how they will be different when this deployment will go live.
00:11:24.034 - 00:12:06.918, Speaker C: Thank you. Actually, I was looking into the distinction between these two concepts and what is my understanding? Understanding, I agree completely with Kirill that there is no clear difference. Like this is the definition of compatible and this is definition of equivalence. And these two definitions are different from my understanding. People use these terms, especially equivalence, for maybe marketing reasons. Let's say many chains roll ups say they are compatible and they are compatible, while some say we are more compatible, but nobody wants to say more compatible. So they say we are equivalent.
00:12:06.918 - 00:12:41.324, Speaker C: But as Kirill also said, there is no hundred percent equivalent in the sense of mathematical definition, because there is different block times, there is different pricing, so nobody is 100% equivalent. But it can be that some chain claims they are compatible, another chain claims they are equivalent, and in reality compatible. One is closer to Ethereum EVM than the one that claims that they are equivalent. So that's my understanding. But maybe Jan is different.
00:12:42.064 - 00:13:38.028, Speaker D: I mean, I'm not trying to contradict, I think that's a good point that, like a lot of it is marketing. But to sort of go back to the initial question and something that you guys haven't touched on yet, this notion of equivalence is sometimes used like, oh, the execution layer is the same, but behind the scenes, we're going to change how we record state, or we'll use a different, more zero knowledge friendly hash function to compute a state root rather than Kessac, because Kessec sucks in zero knowledge proof. And I think that distinguishing thing is really nice when you are engineering that part, but otherwise, the app users don't really care. I think for them, EVM compatible should be good enough. This definition change between compatible and equivalence is technically important, but it is not well defined. So it's important, but also, no one's done it, so how important is it? Or maybe people have done it, we just haven't seen it. But I think compatibility is key.
00:13:38.028 - 00:14:20.086, Speaker D: And to touch on the original question of some of the specific differences, changing these backends so how state is recorded, that is important. It's one of the reasons we sort of had, I think, slow adoption in the zero knowledge space is because Kessac sucked so hard and you had to re engineer these parts of geth, for example, to make it work on an optimistic roll up. They could bypass all of that. Kessac didn't matter. You could keep using it, and it was really nice. So I think the compatibility is very, very key. And as long as that is marketed used in the right marketing sense, no one's lying about that, that you can generally portray solidity, and it works very well, or whatever other language you're using to compile on your EVM, that's good.
00:14:20.086 - 00:15:16.796, Speaker D: But the last thing I want to touch on is I think it's also kind of important to say to which EVM you're compatible, because I would bet there are roll ups out there that still don't support Shanghai or different opcodes. And so what ends up happening is you don't support the newest opcode because ethereum just pushed it out and they had good lots of tests. And then people fill up your discord with like, hey, my code is not compiling. I thought you were EVM compatible. You're like, well yeah, just the older version for now and we're working on the next one. And actually I think one of the big challenges is going to be keeping all of the chains who claim to be compatible up to date with Ethereum and one another, especially when there are changes that happen on the sort of equivalence end. So the backend Shanghai might not be super hard to support, but if it means also changing your Zernoul's proof system because you've done something along the way to make that more convenient for you, it's going to be very difficult.
00:15:16.796 - 00:15:51.244, Speaker D: And actually what I think we'll see for other reasons too, is just people deviating from EVM compatibility. In the next couple of years you'll have that as the marketing thing and you can sort of, I think, see it obviously stark. Now, I already touched on, but I think Taiko is introducing new opcodes. So if they have new opcodes, I can't imagine they can use the phrase equivalent because that opcode doesn't exist in one of the evms. But that doesn't mean it's a bad thing. And I think it's actually really cool that people are trying these new things as long as it remains mostly compatible for now, because that's where the developers are in the space. We still want most of solidity to work.
00:15:51.584 - 00:16:12.604, Speaker A: Cool. And from a developer perspective, and you mentioned some chains for example, not supporting some of the latest hard works. What are the things that I need to worry about when trying to migrate? Some of the contracts that I already have on layer one to layer two, for example. What if some opcodes are not supported on layer two? Still?
00:16:14.624 - 00:16:41.574, Speaker D: Yeah, I don't know. The easy way is to try it. Ideally they have a testnet so you can just try it and it doesn't work. And then you have good tests to check that yields are being computed correctly. Because sometimes, like I said, they will support the code. They don't just change the semantics. Otherwise, ideally they have good documentation and say, look, we're only at Paris, not Shanghai, so don't try solidity 820 or whatever the version is that introduced, push zero or whatever that opcode was yeah, I don't know, maybe some of the other ones have good answers.
00:16:44.594 - 00:16:48.802, Speaker A: Okay. Nothing else that developers need to worry about when migrating, I mean.
00:16:48.818 - 00:17:23.446, Speaker D: Okay, so I think that's a surface level one. I would imagine there's ripple effects that will eventually start to happen, like gas computations of transactions might change. We also see some chains support preip 155 transactions, some don't. There's some things on the tooling side that they will need to change. If they always want to redeploy at a specific contract because they don't support that, or because they want to use that type of transaction which is no longer supported by the VM. I think you need to sort of review everything, but testing will get you 90% of the way. And then talking to the team that you want to deploy on is probably going to get you the last 10%.
00:17:23.446 - 00:17:29.474, Speaker D: You just go, you have a talk and say, hey, I'm doing this. Do you expect anything will break? And the answer should be no.
00:17:31.614 - 00:17:36.954, Speaker A: Okay, yeah, sure, go ahead.
00:17:41.414 - 00:17:42.718, Speaker D: Hold on, hold on 1 second.
00:17:42.806 - 00:18:42.886, Speaker E: Let's get you a mic. So I have a very curious example which I encountered a few years ago when I was working with Polygon. Now, polygon block chains actually basically validate a lot faster than Ethereum chains, but Reox on polygon can happen multiple blocks, even double digit blocks blocks ahead. I think maybe at some point even three digit blocks passed. And so what you have is that there's the risk that when you do actually use on a chain which is faster, you still have to wait the same amount of time to actually get the kind of same finality as you would say. I realized that when I was building on the chain, and this is not an attack on polygon, this is just an example that occurred to me, which is that you still end up waiting the same amount of time. Yes, the fees are cheaper, so that's great.
00:18:42.886 - 00:19:09.788, Speaker E: But even if you look at exchanges today, when you're depositing some of the faster change, the waiting time is still the same. So it's not really about the equivalence on EVM, but it's like something lower that then becomes a problem. Are there other pitfalls like that that we do have to bear in mind? And it's nothing to do with solidity, nothing to do with specifically the EVM, but it's stuff like this that we don't know as people who are working on a dapp, for example.
00:19:09.916 - 00:19:50.704, Speaker D: So yeah, I think we were going to talk about this as a question later, but that's one of the sort of later effects that isn't just like oh my solidity didn't compile on my chain, but you have all these tools and infrastructure that aren't in solidity trying to monitor that chain, which is supposed to be the same as any other chain. But if it's chugging along at 100 more blocks per second than the other one, their analytics engines won't perform the same computations, or they'll expect finality after two blocks or something. That's DVM standard, but not on your chain. So I think that's a big problem. I would imagine people like explorers and dexs and anything that's off chain also need to change their tooling. Admittedly I'm not an expert, so I'll pass it to someone.
00:19:51.744 - 00:20:33.944, Speaker C: Yeah, so I would not say this is a EVM compatibility problem. It's more like centralized exchanges and many other validators that look at the chain. Even if the chain, let's say, has very fast block times, they really wait for Ethereum finality. So they don't necessarily trust sequencer fast feed, which is like less than 1 second, and there is block production also few seconds, but. And they wait for Ethereum finality, which is at least six minutes. But that's application dependent. And I don't think this is a concern from the EVM compatibility side, but I agree that this should be communicated better.
00:20:33.944 - 00:20:37.984, Speaker C: What does EVM compatibility actually mean?
00:20:41.764 - 00:22:00.886, Speaker B: Yeah, like as box clouds, as a basically a part of the infrastructure that monitors all of this chain and connect that this indeed is a big problem that you have so many clients running across these different chains, and basically each implementation has some different aspects on the JSON PC level, and then some assumptions about finality, these reorganizations. So definitely reorgs don't usually happen on layer twos, but then if you have something like polygon or ethereum, you can expect these different levels reworks with different depth. And that's something that for sure impacts any sort of indexers that work off chain and try to get something from the transactions, from the events they need to handle. This kind of reworks differently depending on their depth, then yeah, it also impacts in some way different front ends, I think, because a lot of front ends, they have like this general logic of tracking what happens to your transaction after you send it. And then there is different stuff, like they can happen if you resend it, if it gets reorged. So some stuff may break during that. And yeah, as a part of the bigger problem, if you just take this chess on, RPC compatibility, not just the EVM one.
00:22:00.886 - 00:22:52.864, Speaker B: There is also a lot of differences on this level. So each client have some differences within this certain GSN or PC methods. So the Ethereum foundation pushed a lot for the standardized tests during the preparation for the merge, but that basically only covered the set of like core EVM JSON RPC methods. But yeah, it doesn't cover all of them. And then there are a lot of, it certainly doesn't cover these differences in the roll up, just another pc implementation and node implementation. So yeah, there may be some problems there. Certain fields behave differently, certain formats may get changed, and there is no like standardized test suite that you can just run and make sure that your JSON RPC is also 100% compatible with the rest of the ecosystem.
00:22:53.964 - 00:22:55.584, Speaker A: Does that answer your question?
00:22:56.324 - 00:23:24.484, Speaker E: It does address it, partially in the sense that there's so many pitfalls that even though they are equivalent, it does address it. I guess my main question was, what are the pitfalls that we have to bear in mind too, as developers, because it was something that I wasn't aware of until it affected our dapp. When people talk about equivalence, it probably doesn't just sit on the EVM. So I was just curious what l two issues might be with that.
00:23:24.844 - 00:23:36.224, Speaker D: Thank you. Can I just say one, I think the main takeaway is it's more than just the execution layer, it's a little bit more of the consensus layer, like Kaki was mentioning, and there's a lot.
00:23:37.644 - 00:24:17.914, Speaker A: Are there any other questions at this point? Okay, cool, we can continue. So are there any ongoing efforts in the Ethereum community aiming to standardize some of the EVM stuff on the layer too? Like, I know, for example, that arbitrum prenitro had its own implementation of the EVM, and now after the neutro hard work, you kind of became much closer with the version of get. The same thing was with the optimism pre bedrock. So, like, are there any ongoing efforts there to standardize across all l two s or even should we do it?
00:24:20.014 - 00:24:27.434, Speaker D: So I'm not aware of any. I would love to be involved in those, if they exist. I don't know. I'd like to see more.
00:24:30.094 - 00:25:18.988, Speaker B: I can add a little on this question. So, yeah, there's definitely not enough efforts in this direction, and it's very hard to even find all of these differences and changes because they are documented, like separately for each roll up. So if you want to learn about differences on arbitrum, you go to the arbitrum documentation. If you want to learn about optimism, you go to optimism documentation. So there is no single place where you can find all of this information aggregated in the same format. So one of the interesting direction in this improving this kind of problem was the introduction of the roll up improvement proposals kind of format. So previously we only have like eips and ercs, part of this standard for describing Ethereum improvement proposals during these hard works.
00:25:18.988 - 00:25:49.224, Speaker B: And then someone proposed, yeah, let's use them as well for describing different rollup improvement proposals. And if you have like certain opt in, opt out features in rollups, yeah, let's put them in a single directory and manage them all together. And maybe, yeah, in the end of the game we can have this single place which describes all the differences that different roll ups may have or may not. So yeah, that's probably the good direction to look at.
00:25:51.604 - 00:26:50.824, Speaker C: Yes, I'm also not aware of any efforts, but what I think is l two bit can do that because they are doing very good job with estimating how well the roll up does. So they can also maybe measure how compatible they are and that will push roll ups to standardize more and more. But again, as you said, arbitrum really tries hard to be updating as soon as Ethereum does basically same day or same hour. So we are really trying to be as close as possible. But yeah, that would be nice tool to see on l two bit. And I also want to shout out to them because they introduced now this l one finality, there was this previous question which measures time, how quickly roll ups go to base layer and that should be also helpful for users who rely on decentralized exchanges and their monitoring.
00:26:52.164 - 00:27:10.634, Speaker A: Awesome. And with the dancun hard fork happening some months ago, like what do you expect is going to happen in the near future? Like what are some of the things that you expect layer two solutions will implement? And we can start with you Akaki, since you're with the arbitrary.
00:27:11.134 - 00:28:14.258, Speaker C: I'm really excited about this upgrade and so far we've seen very low flop prices and what I'm expecting is more users. So what we are observing so far is more activity but from the same users. But if transaction fees on roll ups, especially on optimistic roll ups, but also ZK rollups dropped significantly, so if this sustains for some time, then I'm expecting definitely many more users that we are not there in the first place. And then maybe fees will go a bit higher and but never to the same level as it was before. And once we reach the level where we are consuming a lot of blobs, maybe Ethereum foundation will add blob capacity. And so that this is this dynamics that I'm expecting. So we won't stay with these three blobs, but we will have then more blobs target number.
00:28:14.258 - 00:28:24.554, Speaker C: And in the end, we go to this. What's the name? Dunk sharding. Full dunk sharding mode. So that's the best dynamics that I'm expecting.
00:28:27.094 - 00:28:51.874, Speaker D: I think you said it well. I think the expectation, I think, will be cheaper and more users for sure. But also this will mean better scalability on ethereum if they add more blobs, which I think will be absolutely necessary. Right, 30 or 40 roll ups out there right now, plus 20 in development or something, they're going to need to be having a lot more space to post things. But I don't know, I'm just excited. I think you said it all.
00:28:53.134 - 00:28:54.030, Speaker B: Okay.
00:28:54.222 - 00:29:05.274, Speaker A: And how do you see all of these varieties in the EVM affecting the tooling and the infrastructure components that are out there helping developers be more productive and efficient?
00:29:05.934 - 00:30:00.456, Speaker D: So I think this was the question that the audience asked, sort of like, what is this beyond just does my solidity work? And I think that's going to mean a lot of work for a lot of people as they sort of pick and choose their favorite chains. Ideally, everything works the same, but as we've already discussed, some chains operate at different block times and have different behaviors, and Reorg depths can be very different among them. So I think it's going to be a lot of work. I mean, I hope we can at least standardize sort of the API calls you need to make, if not the behavior, because just changing one of those is going to be enough to keep people very busy for a long time. But I think we'll really see maybe an advantageous set of tools come out for chains that do things very differently. Like if they can perform different analyses or can support different ways of integrating on that chain, because that chain behaves slightly differently, I think that would be really cool. I don't know what those look like.
00:30:00.456 - 00:30:35.254, Speaker D: I don't have any ideas for what that would look like. If you start changing the behavior of these roll ups anyways, which I think you'll see people doing, let's do it for the better, and so let's build some better tools. What tools don't we have that we do want? Is doing analytics sort of enough? For example, would there be a better analytics engine? Not that dune is bad, if there were different systems to work with or different support by the roll up itself. And I think seeing those changes will be really cool. But I don't know what those look like or if they're possible. Maybe that's it.
00:30:39.394 - 00:31:21.530, Speaker B: Yeah, another good thing I think makes sense to add it at least. Although we have these hundreds and thousand roll ups already, at least we don't have hundreds and thousand implementations for this roll up. So it's nice that basically everyone is using one of these rop families or stacks, so we have only a few of them. So it makes it easier to support everything. So at least narrows the efforts required to support as many chains as you want. So I think for now we have only like four or five majorly used stacks like optimism stack arbitrum nitro and orbit stack ZK sync and Polygon CDK. Yeah, I think something like that.
00:31:21.530 - 00:31:34.574, Speaker B: So at least people are trying to converge to a single roll up family. There are not too many of them, so that kind of simplifies the life of tooling and infrastructure.
00:31:35.314 - 00:32:02.184, Speaker A: Yeah, I agree with that. And what do you think are some of the security implications of having this many varieties of the EVM implementations? Layer two, like, are we going to need to have security auditors specialized just for some implementation of DVM, and are they going to have to look out for each new hard fork? And what do all of these chains introduce on the EVM level?
00:32:03.324 - 00:33:11.772, Speaker B: Yeah, I think one of the things I noticed recently within like the past year in the security space is that now it became basically a requirement, mandatory requirement for whenever you are ordering an audit from a security firm or starting a security contest, something like that. One of the first question is basically which chains your protocol is supposed to be operating on. And you select if your protocol is supposed to be only working on the Ethereum mainnet, or if it's only supposed to be working out bread room. And then the security researchers use this information to kind of assess your protocol according to the nuances and the security implications for each of those chains. So that's important thing to consider. And then it's also an important point that the original protocol developers, they ordered an audit for some protocol in Ethereum Mainad, but then some guy came in and forked this protocol and launched it on some roll up without changes. So yeah, that kind of shorts the security as well, because this protocol was not originally audited for that type of roll ups.
00:33:11.772 - 00:33:29.984, Speaker B: And so that kind of may be a problem at some point. So yeah, people just need to pay attention when they review the audits. If the protocol was audited for the certain chain, they're planning to use it. Yeah, I think that's it from my side.
00:33:31.684 - 00:34:05.724, Speaker C: Yeah. So I actually think I agree with what Jan said before, that protocols should do, of course, their due diligence and deploy on the testnet, and then they need to talk to rollup team and find out the remaining details they may have missed. I don't think there will be security service that will check all the subsets of rollups where your protocol will be safe. That will be too much to ask to anyone. But yeah. So protocols themselves should go through this process, I think.
00:34:07.104 - 00:34:07.392, Speaker A: Yeah.
00:34:07.408 - 00:34:40.002, Speaker D: So I agree with both of them. I think that first one is really important. If you get an audit, tell them what you're deploying on, because sometimes you might not even think, but if you have any inclination, they're like, oh, you're developing a DAP, and maybe I'll put it on Polygon later. Tell them upfront so that the persons can figure out what that implications are, if there are any. But I also think there'll be new avenues for places like security people in the space. So at Zurkit, one of the things we're doing is sort of sequencer level security where we'll prevent bad transactions from executing on the l two, whatever that means. And I had to talk on that.
00:34:40.002 - 00:35:51.274, Speaker D: But how that could be done could involve other security auditors or could involve, you know, different people taking an active part in the security of the system that isn't just in the state transition function. And I don't know what all those things look like, but you could envision involving them in restaking protocols to somehow do something on the governance of the chain. Or maybe you have a prover market that requires some level of security that can't easily be implemented just on chain using economics or something, or technically. And so I think for now the answer is pretty straightforward, like the other two said, test and talk to auditors and do these things. But I think in the future you're going to see a lot of very different things and you'll obviously see very specialized security risks on very specialized chains, like what is the implication of a new opcode going to do and things like this. And it will be very interesting to be researching in that space because you'll see hacks probably happen on a couple of chains and then probably they won't be as successful on other chains. And not just because the flash loan value wasn't there and liquidity was fragmented, but because some chain actually prevented it in some way, whether that was intentional or whether that was just, oh, they changed the block time parameter in it.
00:35:51.274 - 00:36:14.510, Speaker D: It saved them would be very, very interesting. And I think that has been really under explored. Like, I think there would be really lots of good questions to say what is possible only on some trains, or only if some trains change some property that others which don't have that wouldn't be affected by. So I think it's going to be a very interesting space to be a security person.
00:36:14.582 - 00:36:22.654, Speaker A: Thank you so much. Are there any questions from the audience? Yeah, we have one there.
00:36:28.114 - 00:37:02.886, Speaker D: Thank you. What are the current biggest challenges in the l two evms? Are there any global challenges that needs to be solved? There are definitely challenges. I think the prover times for ZK provers have come down quite a bit. You can probably still do better. A lot of research going into that. I would say that's where I'm focusing a lot of my time because we're in testnet. I'm sure there's others though.
00:37:02.886 - 00:37:43.044, Speaker D: I'm sure there's things like decentralization. We all probably want to be there at some point. And what does it mean to decentralize a sequencer? Is it the same as decentralizing a network? Do we actually add consensus overheads if we do that? And so should we do that? Are there other challenges related to getting other people involved in other parts of the system? For a zero knowledge system, that would be like decentralizing the prover. Is it easy? Is it hard? I don't think there are a lot of chains out there that have a complete picture of what that looks like. I could be wrong. I think some others are definitely attempting it. But I bet the solutions that we have today won't look like the ones that we have in two years or three years, right? So I think there are definitely challenges.
00:37:43.044 - 00:37:45.564, Speaker D: It's a little hard to nail the specifics.
00:37:47.144 - 00:38:13.724, Speaker C: So my top pick was actually what you mentioned, this ZK roll ups proving EVM state. But there is significant progress, as I understand. Another is maybe shared sequencing and interoperability and their EVM real compatibility would be really useful. If all rollups had that, then we could have this glorious shared sequencer.
00:38:16.944 - 00:39:00.844, Speaker B: Yeah. There is also some research going on into adding like a multiprover setup for the rollups so that you can prove the roll up state independently using different engines. So you can have multiple ZK provers developed by different people and using different strategies to prove the same EVM. And then if all of them agree on the same state, then you can be more sure that this state is indeed correct and wasn't manipulated in any way. You can also combine like the ZK and optimistic approach together to also increase security. There is some interesting research going on for the future years for the parallelization of EVM. So if you can parallelize execution of different transactions that don't touch the same set of accounts or whatever, if you can execute them in the same parallel environment.
00:39:00.844 - 00:39:03.644, Speaker B: So that's one of the interesting approaches as well.
00:39:05.784 - 00:39:30.184, Speaker D: I've got one more, I got one more which is probably just like interoperability systems, right? You're going to want to have people move liquidity from arbitrum to somewhere else or vice versa. And I know there's been a ton of bridges, but bridges have been so problematic in the past, there's probably going to be new innovations in this space. And I think it'd be interesting if you could somehow work that in either through shared sequencing or some other way that's unique to sort of a layer two environment.
00:39:33.084 - 00:40:11.014, Speaker C: Yeah, actually I have one more. This is a question I'm very interested personally it's multidimensional pricing of resources. Because what we see now is biggest problem in EVM is state growth and everything follows state growth. So that's the biggest bottleneck. Of course there is parallel execution, but I think before we go there. So if we solve parallel execution that won't save us because the restate growth and that needs to be accounted. But what is happening now we have just one gas unit where all the resources opcodes are translated into and priced in the same way.
00:40:11.014 - 00:40:45.684, Speaker C: While it can be that some transactions don't grow the state at all and they should be priced less. So this is now done manually. So the conversion between different resources into gas. But it would be nice if to have parallel independ maybe not independent but parallel markets for each resource. Of course we cannot have thousands of different opcodes priced differently. But what we see with this EIP 48 44 this is first attempts to go to multi dimensional pricing. So now we are pricing call data separately.
00:40:45.684 - 00:41:41.764, Speaker C: So this is, I think symptom of a bigger problem. So we knew that roll ups are overpaying for cold data because if we can afford now these cheap blobs we could have done it before too. But because everything was connected with state growth and single dimensional pricing there was this problem of rollups paying too high number. And I think this is the same happening now with other resources on Ethereum. And if all rollups are EVM compatible they are inheriting the same problem. So this multidimensional pricing I think needs to be done and will be done in some way. And I think this is where rollups again can, together with Ethereum, collaborate and for example, agree on the new transaction format which specifies their willingness to pay for different resources, for example.
00:41:43.704 - 00:42:00.864, Speaker A: Thank you. Any other questions from the audience? If no, like, guys, if you have any final words to say before we adjourn, no.
00:42:01.024 - 00:42:03.968, Speaker D: Thank you. Thank you. It was fun.
00:42:04.096 - 00:42:06.064, Speaker A: Awesome. Thank you so much. Thank you guys for coming.

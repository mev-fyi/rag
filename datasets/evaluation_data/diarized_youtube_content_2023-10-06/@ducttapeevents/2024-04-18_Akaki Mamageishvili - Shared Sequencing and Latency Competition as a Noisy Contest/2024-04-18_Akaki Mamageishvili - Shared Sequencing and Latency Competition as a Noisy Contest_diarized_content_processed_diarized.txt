00:00:00.400 - 00:00:35.372, Speaker A: Thank you. Thank you for the introduction. Welcome everyone, and thank you for joining this presentation. So I will talk about shared sequencing economics, and we will look at this from the latency competition perspective, which we model as a noisy contest. This is a joint paper together with Christoph Schlegel, who is researcher at Flashbots. First, let me give you some motivation. We all know that Ethereum is very good with decentralization and security, but it has problems with scaling.
00:00:35.372 - 00:01:30.332, Speaker A: And Ethereum decided to go with the paths of rollups, and it created this roll up centric roadmap. And this resulted into, at the moment, at least 50 functioning roll ups and maybe more than hundreds of announcements of rollups that are under development. So far, so good. We can assume that Ethereum is really scaling at least, let's say 50 times. If we assume that all rollups have the same parameters as Ethereum chain does, and most of them do, because they are implementing evms, ethereum virtual machines, and even trying to optimize, for example, arbitrum. That is the roll up that was developed by my company, off chain labs. But it comes at a cost, and the cost is this fragmented liquidity.
00:01:30.332 - 00:02:32.756, Speaker A: So instead of all liquidity being on one chain and move on that chain freely, now you need to move them from one roll up to another roll up. And there are of course no direct channels to move money. Probably first you need to withdraw from a roll up to Ethereum and then move to another roll up. So this creates this fragmented liquidity. And you can also see it on the, for example, defi llama. You can see that it's still the case that Ethereum has most of the liquidity, but already some roll ups have some significant amount of liquidity, at least 50, few of them. But we have arbitrageurs that are trying to adjust the prices of different assets in the exchanges, decentralized exchanges, and they are helping the market to be efficient, so to have equal prices on different roll ups and different domains.
00:02:32.756 - 00:03:10.726, Speaker A: But of course, it comes at a cost to arbitrageurs. Also, as I said, coordinating these arbitrage activities are quite difficult. You cannot withdraw money from one roll up and move it to another roll up through Ethereum because that's too slow. Someone else maybe already has funds on another roll up, and that arbitrage will be faster. So to solve this problem, at least partially, shared sequencing solution was proposed. And there are at least several projects that I'm aware that are solely focused on shear sequencing. These are espresso and Astria.
00:03:10.726 - 00:04:17.090, Speaker A: And I would say that even swab, which is a chain or solution that is proposed by flashbots, can also facilitate some shared sequencing. So I will talk about what are the shared sequencers? Let's for the simplicity for this presentation, look at two domains, for example two roll ups. This is the simplest case, but it can be also one roll up and ethereum main chain. And actually all the shared sequencing solutions that I have seen so far, they are offering the same transaction ordering policy, namely creating blocks from the manpool of transactions that is already live on ethereum. So they don't go with first come, first serve solutions so far. But there are some promises given in that direction as well. Okay, so now we are assuming that shared sequencer can sequence transactions on both domains, both chains.
00:04:17.090 - 00:05:09.854, Speaker A: Okay, that makes life of arbitrageure simpler because now it can submit one bundle of transactions and hope that they will be executed atomically on both chains. Actually, those solutions that offer shared sequencing, they also make promise that they can execute atomically. So both of transactions will be executed. Condition that other transaction on another chain will be executed in the order that is defined by the transaction sender. But for the sake of this paper, we look only at the sequencing so transaction is sequenced and the guarantees that it will be executed. But shared sequencer may not be able to give this guarantee. Okay, then we are analyzing what does it mean for cross domain arbitrage trading.
00:05:09.854 - 00:05:57.328, Speaker A: We look at the arbitrage trading as a contest where if the transaction ordering is designed by shared sequencing, for example, if it's first come, first serve on both chains or one chain, then competition is who is fastest. So competition is about the latency. But if we have ethereum style priority gas auctions, then traders are incentivized or they are competing on higher bids. So whoever has higher bid is included fastest. And we only look at this kind of competition. So you cannot. So we are not looking into cases where you are sandwich attacking some attack some transaction.
00:05:57.328 - 00:07:00.390, Speaker A: But we only look at, let's say back running competition where you just want to be fastest. Once price changes, either outside market or inside the chain exchange, you want to be fastest to take this advantage and get back on the previous transactions. And this way we can see shared sequencer as a tool to reduce noise. So noise is just randomness, because if you try to be fastest on two chains, chances that you will fail on one of them is higher than if you fail on one of them. Okay, only on one of them. Okay, then we are interested what happens with the investment, how it changes the strategies of arbitrageurs and we develop a very simple model that captures shared sequencing versus separate sequences. So we should be able to compare these two solution concepts at least along some dimensions.
00:07:00.390 - 00:07:39.536, Speaker A: And we managed to do it at least for two dimensions. So one is quite trivial. As I said, if you are competing on two chains separately, the chances are that both players or all players lose, because you win some and other players win some others. So it can be that all the players are failing. So nobody wins all the competition competitions, all the contests, all the races. But in case of shared sequencer, it is guaranteed that someone wins. Okay? So at least user experience in this regard is better with shared sequencing.
00:07:39.536 - 00:08:31.584, Speaker A: But now we are also interested in the revenue that the chains extract. Because chains need to join the shared sequencer, they need to allow shared sequencer to run a sequencing rule on them, and therefore they need to get some revenue from that. Okay, so we have very simple model where we have again two players, two domains, and they are trying to be fastest on both domains, both chains. And in case of winning, they are getting, let's say, the same value. Of course, this is not always true, but for the sake of this presentation and this paper, this is the simplest model and it already shows some difference between shared sequencing and separate sequencing. So I think this is fair enough. And again, they need to win both competitions.
00:08:31.584 - 00:09:48.956, Speaker A: Okay, so what do arbitrageurs do? They invest some amount to create their signal. And signal will be defined in some different contexts. And of course, if you want your signal to be better, for example, if you want to be faster, you need to invest more. So we have some cost function that is increasing differentiable that we need for deriving analytic results and convex, this is quite intuitive condition to assume, but there is also random noise. So for example, in case of pure time competition, when you send your transaction to a sequencer, you are not sure how fast it reaches and there are some random factors that may delay it a bit. Okay, so the arbitrageur I wins the race against arbitrageure j. If the signal plus this noise term is larger than signal plus noise term for the other player, and if we have a distribution on the difference this noises, then we can calculate the probability that one arbitrager wins the race.
00:09:48.956 - 00:10:32.524, Speaker A: So this just probability is given. We assume that there is this distribution, then we assume it's normal. Again, we want to have analytic solutions, but we can have arbitrary distribution and give results for that arbitrary distribution as well. Okay, so now some examples. First is first come, first serve, where your signal is, how fast you are and more you invest faster, you are. So that defines basically your timestamp. But there is also, of course, noise parameter, as I said, that you are never sure that you will be reaching the sequencer in exactly the time you have calculated.
00:10:32.524 - 00:11:44.360, Speaker A: So another example is Timeboost, which is a recent proposal by including myself and Christoph and co authors from off Chain Labs and Cornell University at Felton and Mahemna Calcar. So, where any user, and in our case, arbitrageur, invests. So, bids to buy a time boost, which will be subtracted from the timestamp. And timestamp is some random noise, let's say in case of Ethereum type block building, you can imagine that s is how much users invest in searching and epsilon. So the noise parameter is some random factors in the market, for example, if they manage to reach the builder, et cetera. But I want to make a disclaimer, we are not really analyzing this last part very carefully in our model. Okay, so now what is the difference with shared sequencer, there is just one sequencer.
00:11:44.360 - 00:12:32.874, Speaker A: So you aim this sequencer, you have one noise terminal, and you have one signal that you need to generate. For example, you want to relocate close to this sequencer and trace where the sequencer is located at different times. We separate sequencers, you need to target both sequencers, be closer to both sequencers. And there are two noise terms, of course, but of course in the equilibrium, and that's what we are looking into, you may invest slightly less when you have two different separate sequencers. We assume that noises are independently distributed. So sequencers, for example, are not sitting together. And they, so separate sequencers, they move around independently from each other, also not always correct.
00:12:32.874 - 00:13:29.222, Speaker A: But this allows us that instead of distribution function f, we can just take f squared, and that simplifies the analysis considered. Okay, so we have unique symmetric equilibrium of the game and equilibrium. In the equilibrium, we can find signal. So this s prime with a very simple equation. So it's basically first order condition for both separate sequencing sequencers and shared sequencers, or one sequencer. So as simple as that, we can just solve what is the equilibrium signal. Okay, so now the question is, what does it mean? Does shared sequencer bring more revenue? Because that's the first intuition of everyone that now, okay, arbitrageurs really love just one sequencer, so they will invest more to win, because at least one of them is winning.
00:13:29.222 - 00:14:15.178, Speaker A: So don't forget that we show that this is not always true. And it really depends on the shape of this cost function and what is the variance of the noise. So how different the noise can be. So we look at constant elasticity cost functions. So cost is just x to the power beta. And we see that if the value from the winning arbitrage opportunity is large enough, we have this number to be the investment with one sequencer. So shared sequencer and this number.
00:14:15.178 - 00:15:10.414, Speaker A: So I will not read what are these values. But what we obtain is that if beta is larger than one and for convexity we need beta to be larger, the investment in case of one sequencer is always higher than investment with two. And now if you go back and consider that this is just latency competition, it means that players will waste more because that's a waste. It just goes to outsiders not to chain. So waste is more with shared sequencers. Okay, so in case of latency competition, this is a bad news. Okay, in case of time boost, I don't want to, I don't have time to go very slowly here, but so you are generating some signal, which is you are paying for time advantage.
00:15:10.414 - 00:16:00.248, Speaker A: So more you pay, more time advantage you get. And that time advantage is subtracted from your timestamp. So your adjusted time step will be your real time step minus some signal s and you can get at most g advantage. So we are thinking to get, for example, at most half second advantage. And this is the cost function. And we obtain a proposition that revenue that is obtained through this time boost mechanism is higher for separate sequencers as long as this condition holds. So we can look, so do some comparative statics on these parameters.
00:16:00.248 - 00:16:28.420, Speaker A: So you know what is v is value, sigma is variance. Basically, g is the maximum advantage you can buy, sees how much it costs to buy. So this is this parameter. And this constant is something related with two. So two is number of roll ups or number of domains, and square root of two PI. This comes from normal distribution. So this is not just some random constant here, it has some meaning.
00:16:28.420 - 00:17:04.674, Speaker A: So we can go through what does it mean. So if for example, valuation is large enough for the arbitrage, it's actually better to have two separate sequences. You don't need to have shared sequencer because separate sequencers will obtain higher revenue. Also quite unintuitive result. And also then it depends if sigma is small, so there is small noise. In some cases, you can assume that noise is small. So you know how fast you reach the sequencer.
00:17:04.674 - 00:17:28.302, Speaker A: And there is no random, much randomness there. Then you again have that two separate sequencers is actually better. And that makes sense because if there was no noise, there would not be need of shared sequencer in the first place. That's it. Okay, so that's all from my side. Thank you. If you have questions, please ask me now.
00:17:28.302 - 00:18:46.094, Speaker A: I think there's some time or I'll be around here. Thank you. We still have a couple of minutes. You can ask one or two questions, actually, if you have any. Hi, just wanted to know, do you see also, or do you have a feeling or an intuition on how the results generalize to even more roll ups, like three or four? Oh, that's a good question. So if you assume independence again, so that you can still solve the equilibrium condition, so it will be f cubed instead of squared in case of three roll ups. So one thing about more roll ups is I don't believe it will be often the case that you trade on three different roll ups at the same time.
00:18:46.094 - 00:19:37.924, Speaker A: Because if you adjust the price between two roll ups, or centralized exchange and roll up, or layer one exchange and some roll ups, there is no need to do this cyclic adjustment. But it can happen that sometimes arbitrages are careless and leave some opportunity behind. I think all the insights will carry over. So it can still be that shear sequencer for very large valuation, arbitrage still collects less. So we didn't do this for many roll ups in the paper, we did it for many players. And there it really generalized easily, and I believe for rollups will be the case too. So more roll ups.
00:19:37.924 - 00:19:39.624, Speaker A: So thank you.
00:19:54.084 - 00:20:16.964, Speaker B: A very good presentation. Akaki, I have a question, if there are other applications of a shared sequencer than crossrolab arbitrage? And my second question is, I mean will the cross roll up arbitrage be used more often than the arbitrage between rollups and the Ethereum mainnet?
00:20:18.224 - 00:21:08.274, Speaker A: Yeah, so about second question, I believe most of the arbitrage is between centralized exchange and rollup, except for some weird tokens that are only sold on roll ups or the layer one. But there is let's say some 20% or 15% of the arbitrage, which is also significant number about other uses of shared sequencing. I'm pretty sure there are other uses as well, but main demand comes from arbitrageurs and these mev searchers. But I can imagine other uses. Actually that's a good question. We should ask those companies that create such services. But I can imagine like regular retail users also using sometimes this option.
00:21:08.274 - 00:21:10.254, Speaker A: That's a good question.

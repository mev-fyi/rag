00:00:00.410 - 00:00:34.818, Speaker A: Hi everyone, and welcome to this portion of the playlist that accompanies chapter 21 of the book algorithms Illuminated. Part Four algorithms for NP hard Problems Chapter 21 is all about exact inefficient algorithms. So as we've seen, unfortunately, you can't have it all with NP hard problems. And when you're unwilling to compromise on correctness, you have no choice but to compromise on speed. So the goal here is going to be to design exact algorithms. They're always correct. If it's an NP hard problem, we expect it's probably going to run in exponential time, at least in some cases.
00:00:34.818 - 00:01:29.782, Speaker A: So our goal as algorithm designers is to come up with something which is certainly better than naive solutions like exhaustive search by as much as possible, as much of the time as possible. So we'll start in this video with section 21.1. We're going to apply an old friend dynamic programming, and we're going to apply it to the traveling salesman problem. So that'll give us an algorithm which, while exponential, is indeed quite a bit better than exhaustive search. We'll look at a second case study of dynamic programming, this time also involving randomization. It's going to be an algorithm for finding long paths in networks which is of interest in a bioinformatics context. Then we'll turn to tools which are super useful even if they don't have provable running time guarantees, namely state of the art solvers for problems that can be encoded as mixed integer programs and also for problems that can be encoded as satisfiability.
00:01:29.782 - 00:02:12.150, Speaker A: Those, despite the lack of provable guarantees, constitute cutting edge technology for solving empty hard problems in practice. So let's get started and revisit our old friend, the traveling salesman problem. Let me begin just by quickly reminding you about the definition of the traveling salesman problem, plus how long it takes to solve it using exhaustive search. So in the Tsp, the input is a complete graph on some number N of vertices. Each of the n choose two undirected edges is in the graph, and each of them has a real valued cost, denoted c sub e. The goal is to compute a traveling salesman tour. That means it's a cycle that visits each vertex exactly once.
00:02:12.150 - 00:03:01.794, Speaker A: So it starts somewhere, and then an N minus one hops it, visits all the rest of the vertices and then finally comes back to where it began. And among all the tours, you'd like to find the one that minimizes the sum of the edge costs. That's the tsp. So as mentioned, the Tsp is unfortunately an NP hard problem. So if we want an exact algorithm for it, we're going to expect it to have to run an exponential time, at least in some cases. So the question then is can we have some kind of nice algorithmic idea that at least allows us to improve over just naive exhaustive search? So to benchmark ourselves, let's just remember exactly how long Exhaustive Search takes for the Tsp. Well, we had a quiz on this in the very first video about how many traveling salesman tours are there, and it's N minus one factorial.
00:03:01.794 - 00:04:01.930, Speaker A: It's N minus one factorial times a half, but basically N minus one factorial. So if you're going to enumerate each of those tours, and then you're going to compute the cost, and remember the best one, you're going to be spending o of n time for each of the n minus one factorial tours for an overall running time of n factorial. And this is really bad, right? We already are very unhappy with running times of the form two to the n, but N factorial is quite a bit bigger than that, right? So two to the N, that's just a string of N, two S multiplied together n factorial, that's N terms multiplied together, most of which are way bigger than two. So n factorial is clearly a bigger number. To answer the question, how much bigger is the N factorial than two to the N? Let me tell you about a famous approximation result known as sterling's approximation. So sterling's approximation gives us an incredibly accurate estimate of how the factorial function grows. So specifically, n factorial grows as more or less you should think of it as N over e.
00:04:01.930 - 00:04:34.100, Speaker A: Here, e is indeed the constant 2.7 118 over e raised to the n. So there's also a leading term root two pi n that's less important. What's more important to notice is this n over e raised to the n. And notice that as soon as N gets even modestly big, multiplying a bunch of N over e's times each other. That's going to be a much, much bigger exponential than multiplying a bunch of twos together. So that shows that n factorial really is growing much, much faster than two to the N as N grows large.
00:04:34.100 - 00:05:27.954, Speaker A: So, for example, if you had an algorithm with running time scaling like n factorial on modern computers circa 2020, you could probably handle input sizes up to maybe 15 or so. Whereas with an algorithm with running time two to the n, you could handle problem sizes more than twice as large all the way up to maybe around 40, which I know does not sound that impressive. But remember, these are empty, hard problems, and we have to show them some respect. Okay? So two to the N is a lot better than N factorial. So that then is going to be our goal for the Tsp naive, exhaustive search runs in time, n factorial two to the n would be much faster while still being exponential as we expect. So we're going to shoot for a Tsp algorithm running in time ballpark two to the n. All right, so I'm telling you about Stirling's approximation right now because I want you to appreciate how much bigger N factorial is than two to the n as N grows large.
00:05:27.954 - 00:05:57.678, Speaker A: Turns out we're actually going to use this approximation quite directly in our analysis of the next algorithm that we're going to discuss for finding long paths in graphs. I'm not going to prove strilling's approximation to you. Pretty much nobody remembers the proof. The proof is calculus, but nobody remembers it. So it's not important to remember the proof. It's not even really important you remember the statement honestly, it's not even really important you remember the name. But what you really should remember is that there's a super accurate estimate of the factorial function if you ever need it.
00:05:57.678 - 00:06:41.562, Speaker A: Then you'll be able to look it up easily on Google and then on Wikipedia and you'll just be able to get this exact same formula I've written down on this slide. So in the last chapter, we revisited a familiar old algorithm design paradigm, greedy algorithms. We saw their nice application to the design of fast heuristic algorithms for NP hard problems. So in this chapter, we're again going to revisit one of our tools from the old toolbox, but it's going to be a different one. It's going to be dynamic programming. Now, a lot of the killer applications of dynamic programming are to polynomial time solvable problems. As you've seen in previous books of the series, previous videos of this video list, you did actually already see an application of dynamic programming to an NP hard problem because the knapsack problem actually is NP hard.
00:06:41.562 - 00:07:18.214, Speaker A: But that's something we gave a dynamic programming algorithm for, which was nice. And now we're going to see another example to the traveling salesman problem. So before we go into that, let me just quickly jog your memory about how dynamic programming works. So the whole key in coming up with a dynamic programming algorithm is to figure out the right collection of subproblems. What are the properties we want of these subproblems? Well, there should be not too many of them because we're going to wind up solving each of the subproblems. It shouldn't take too long to solve the subproblems, at least given the ones that we've already solved. And then after we've solved all the subproblems, it should be easy to read off what is the actual answer to the original problem that we care about.
00:07:18.214 - 00:07:58.790, Speaker A: So, for example, some algorithms you may remember. So like in the dynamic programming knapsack algorithm, there was one subset for each prefix of the first I out of the n items. That was one dimension of the dynamic programming table, and the other dimension was the residual capacity. So for each possible prefix of items and each possible integer amount of residual knapsack capacity, you had a separate sub problem. Or in the Bellman Ford algorithm for the single source shortest path problem. So there subproblems were parameterized by how many hops you were allowed to have in a path. So a given subproblem would ask you for the length of the shortest path from the starting vertex to some destination vertex v that has at most I edges in the path.
00:07:58.790 - 00:08:46.530, Speaker A: It takes a lot of practice to figure out how to come up with these magical collections of subproblems. But of course, you now being here in part four, have already had quite a bit of practice and we're going to get some more practice in the next couple of videos. Just to remind you, the way you usually come up with the subproblems is you do this thought experiment about what the optimal solution has to look like. So someone hands you an optimal solution on a silver platter and you want to prove that it has to be composed or built up from solutions to smaller subproblems, optimal solutions to smaller subproblems in a limited number of ways. And then you can do exhaustive search over the limited number of things that it might possibly look like. Again, we'll make this concrete starting on the next slide. Point being is once you have a collection of subproblems with all these properties, you're pretty much done the dynamic programming algorithm just writes itself.
00:08:46.530 - 00:09:36.222, Speaker A: You systematically solve all of the subproblems, starting with the easiest ones and ending up with the most difficult ones, and then you just infer the final solution from your subproblem solutions. That last step is usually trivial because usually the original problem is one of your subproblems. In many cases the running time analysis of a dynamic programming algorithm is quite straightforward. So for example, suppose that the number of subproblems you have is F of n, where n here denotes the input size. So this could be linear in n or quadratic in n, or even worse anyways some function of the input size. Suppose you have a running time bound of G of n for solving each of your subproblems, given the solutions to the easier subproblems that you already solved. And suppose it takes you H of n time to extract the final solution from the solutions to all of the subproblems.
00:09:36.222 - 00:10:36.274, Speaker A: Well, then we get a sort of obvious running time bound, which is just the number of subproblems f of N times the time per sub problem g of N, plus the post processing sort of extraction step h of n. So when we apply dynamic programming to an NP hard problem like the TSB, we got to expect at least one of the functions FG or H to be exponential in N. Looking back at some canonical dynamic programming algorithms, for example, for the Napsack problem, for sequence alignment, or for Bellman, Ford and Floyd Warshall algorithms. What you'll notice is that the functions g and h so the time to solve each subproblem and the post processing work, they are never large. They're always either O of one constant or O of n linear, whereas the number of subproblems F of n has been very different in the different dynamic programming algorithms that we've considered. So if we're going to apply dynamic programming to the Tsp, we need to expect one of these functions to be exponential. And thinking about a little bit, it's really f of N we expect to be exponential.
00:10:36.274 - 00:11:15.122, Speaker A: We're going to be looking to see an exponential number of subproblems in our dynamic programming algorithm. So let's now go through this thought experiment to identify the right collection of subproblems. So let's really reason about how optimal traveling salesman tours must be composed of optimal solutions to smaller subproblems. In other words, suppose someone handed you on a silver platter an optimum traveling salesman tour. What must it look like? So this tour, right, it visits all of the vertices, and if we want, we can think of it as starting at the vertex labeled number one. Let's assume the vertices are just numbered from one to N. We can think of this tor as starting at the vertex one and then eventually coming back to it.
00:11:15.122 - 00:12:03.838, Speaker A: And a trick we've seen works really well in these dynamic programming thought experiments is to reason about the very last decision made by an optimal solution. So in this context, right, the edges of the tour, we can think of them as being ordered, and we can look at the last hop. So we can look at the edge that goes from some vertex j back to one at the end of the tour. So now what we imagine we do is we undo that final decision of the optimal solution, we see what we get, and then we try to understand for what subproblem is that optimal. So if we remove this final edge, this edge between one and j from the optimal tour, what do we get? Well, now we have a path. It goes between one and j, and it visits every vertex exactly once. Moreover, there's no cycles in it because we started with a tour.
00:12:03.838 - 00:12:44.878, Speaker A: And the green path between one and j, that's not just any old path between one and j that visits every vertex. If you think about it, it's got to be the minimum cost. Such path, there's no shorter way to get between one and j visiting every vertex exactly once. Because if there were, then we could get a better tour to the original instance just by plugging that edge between one and j back in between the allegedly better path. So this is good news. What this means is that if we only knew the identity of this vertex j, then we would know what the entire tour looks like. It would be the edge between one and j, plus a path between one and j, a path that visits every vertex exactly once.
00:12:44.878 - 00:13:21.722, Speaker A: And subject to that has the minimum possible cost. That's what the optimal tour has to look like. So there's really only n different candidates vying to be an optimal traveling salesman tour, one for each possibility for this penultimate vertex j. Now, of course, we do not priori know what j is, we do not know what is the last vertex visited by an optimal tour. But again, there's only a linear number of possibilities. So we can just do exhaustive search over the N different candidates for that last vertex. So writing that down in math, we can just write down an exhaustive search over the possibilities for j.
00:13:21.722 - 00:14:10.006, Speaker A: So that's what this min over j equal two to N is doing. Okay, I lied a little bit. It's not N candidates, it's N minus one candidates for the optimal tour, because one can't also be the second to last vertex. And then for a given guess of what j is, you just look at the cost of the edge between one and j plus the minimum cost of any cycle free path going between one and j and visiting all of the vertices exactly once. So if you prefer to think about dynamic programming recursively, the approach here would be we try all possibilities for j, and for each choice of j we recursively compute the minimum cost path between one and j, visiting all of the vertices. So that all sounds fine and good. So this tells us how to compute the optimal torque cost using N minus one, recursive calls to a subroutine that can compute these one j cycle free pass that visit all vertices.
00:14:10.006 - 00:14:46.172, Speaker A: And the next question is how do we do that? And here things get a little trickier. Let's think that through in the following quiz. So we're going to ask the same type of question. So suppose we've now fixed j. Suppose someone handed you on a silver platter the minimum cost path from one to j of the type that we want. So cycle free and visiting every vertex. Again, we want to think about the last decision made by this optimal solution.
00:14:46.172 - 00:15:38.058, Speaker A: So that's going to be the final hop, which ends at the vertex j. So there's some penultimate vertex, call it k, so the path ends with the edge k comma j. Now we want to think about plucking off that last edge, seeing the subpath that we have left. We want to ask the question for what subproblem is that subpath an optimal solution? All right, so let's talk through the solution to this quiz. This is an important quiz for understanding the algorithm in this section. So first of all, because we started with this path P, that's cycle free, goes from one to j, visits every vertex and has final hop going from k to j, the subpath P prime. Well, it's certainly still cycle free.
00:15:38.058 - 00:16:36.320, Speaker A: It certainly goes from one to k because we plucked off the last edge that went from k to j, and it visits all the vertices except for j. So every vertex P visited every vertex we plucked off the KJ hop. So the remaining path, P prime, visits everybody in V minus j. Crucially, it is also true that this path, subpath P prime, does not visit j, right, because P visited j only once in its final endpoint, and P prime we've removed that final hop, so it does not visit j. So that means answers A and C are both correct. Answer b, meanwhile, is incorrect. While P prime is indeed some cycle free path from one to K that visits all the vertices in V minus J, it need not be a minimum cost such path, because who's to say that there isn't some other path, also cycle free, also starting at one and ending at K, also visiting all the vertices of E minus J, and also visiting the vertex J.
00:16:36.320 - 00:17:25.726, Speaker A: And to see that I'm not just making up this possibility, consider the following three vertex counterexample, right, so in this example, as you can see, the length of a shortest path between one and k gets smaller if you allow it to use the vertex j as well. If all it can do is use one and k, it has to pick the one hop cost five path. If it's also allowed to use j, then it can do better. It can have the two hop path with overall cost four. So, in other words, P prime being a path that is precluded from using vertex j, it potentially cannot compete with other paths that are allowed to use vertex j. The good news is that P prime still is an optimal solution to a suitable subproblem, namely the type of subproblem mentioned in the second two answers. So, in other words, D is in fact a correct answer.
00:17:25.726 - 00:18:04.746, Speaker A: The way you'd prove this is exactly the same kind of proof by contradiction cut and paste argument that we've seen in many, many other dynamic programming algorithms. So start from an optimal path from one to j cycle free, visiting every vertex once that's this light blue path in the upper left corner. Now we're thinking about plucking off that final hop k comma j. So that leaves us with the residual light blue path from one to k. We want to argue that that's a minimum cost path of the given type. So one that goes from one to K visits every vertex other than j once and does not visit vertex j at all. So suppose for contradiction that wasn't the case.
00:18:04.746 - 00:18:59.754, Speaker A: Suppose there was actually a cheaper path than this prefix that meets the exact same set of constraints. So starts at one, goes to k no cycles, visits exactly the vertices of V minus j and does not visit j. So let's draw that path in magenta. Well, if the cost of the magenta path is less than the cost of the light blue path, then the cost of the magenta path plus that final hop KJ is less than the cost of the light blue path plus that final hop k comma j. In other words, this magenta path together with that final hop k comma j, that's a better path than we started with. Now, it's very important that the magenta path does not use the vertex j that's one of our constraints. If the Magenta path did use the vertex j, then when we put in that final hop k comma j, that would make a cycle, that would be the second visit to j.
00:18:59.754 - 00:19:34.100, Speaker A: So we would not be satisfying the cycle free condition. But because we're assuming the Magenta path is a sort of superior version of the prefix p prime, so it goes from one to K, it's cycle free, visits all the vertices of B minus j does not visit j. That means when we take the Magenta path, plug on that last k comma j hop, we get a cycle free path. Crucially, now it visits every vertex, including j, and its cost is strictly less than that of the light blue path. But that's contradiction, because the light blue path was the minimum such cost. Minimum cost such path and.

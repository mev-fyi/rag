00:00:00.410 - 00:00:36.230, Speaker A: Hi, everyone. My name is Tim Roughgarden. I'm a professor at Columbia University and also the head of research at a 16 Z Crypto. This is sort of a home recorded version of a talk that I gave at the Crypto Economic Security Conference on November 1, 2022. And let me say at the outset, just thanks to both Don Sonne and Arthur Gervais for inviting me to give this talk. And what I wanted to tell you about today, for lack of a better title, is Some Results and Challenges in Crypto Economics. I have to be honest, I don't actually use the word crypto economics all that often.
00:00:36.230 - 00:01:32.090, Speaker A: It just sort of means such different things to different people. But when Don and Arthur asked me to give this talk, I thought I'd use it as an excuse to kind of ruminate for a little while about what are the sort of unique characteristics of the types of problems that come up in this sort of nebulous area of crypto economics. And actually, I'm really glad that I did because it kind of reminded me of just how unique and intellectually fascinating the problems in this area are. I thought it would be useful to start by comparing and contrasting the types of problems that come up in cryptoeconomics with the types of problems that have traditionally come up in mechanism design, which is a subfield of microeconomics. Now, mechanism design, one of the descriptions I like is as inverse game theory. So what do I mean by game theory? Well, in game theory, usually some game falls from the sky and you're just tasked with studying it, right? Maybe it's prisoner's Dilemma. Maybe it's Tragedy of the Commons, rock, paper, scissors, whatever.
00:01:32.090 - 00:02:19.362, Speaker A: And then in game theory, you kind of investigate it from a strategic perspective. You say, do any of the players have, for example, dominant strategies? What are the Nash equilibria of the game that you're looking at? In other words, given a game, you try to identify what are the most plausible outcomes of that game. Meanwhile, in mechanism design, you start not with the game, but with the outcome. And often it's an outcome you want to see happen, like all of your protocol participants sort of following the protocol as you intended them to. And then starting from the outcome, you reverse engineer a game for which that desired outcome is, in fact, an equilibrium. Maybe ideally, an equilibrium of dominant strategies, but if nothing else, a Nash equilibrium. So mechanism design has a strong engineering flavor.
00:02:19.362 - 00:03:02.546, Speaker A: That's probably one of the reasons why it's been one of the strongest points of contact between computer science and economics. There's even kind of a meme originating in a paper of Al Roth about mechanism design. As economist, as engineer. We've already mentioned one example of a sort of desired outcome all protocol participants following the protocol as intended. Another very basic one, also relevant for us will be imagine you just have some scarce resource that you want to allocate in the most efficient possible way. You want to allocate it to those who value it the most. If you've ever heard of like a second price or Vic re auction or the Generalization to the Vicary Clark Groves or VCG mechanism those are all really just games in the sense that they're ways of setting up payments.
00:03:02.546 - 00:03:47.330, Speaker A: They're games in which the desired outcome, welfare maximizing allocation of the scarce resources arises as the dominant strategy equilibrium. So these are all sort of games that incentivize participants to report their true value for what's being allocated. And then with that accurate information, the mechanism is in a position to have an efficient allocation of the scarce resources. Now, in many, not all, but in many applications of mechanism design, including these Vic reaction and VCG mechanism examples, there are payments involved. There will be a sort of transfer of money between the participants of the mechanism and the person running the mechanism. And generally in mechanism design you don't really worry much about what this money is. It's something like US.
00:03:47.330 - 00:04:45.590, Speaker A: Dollars. You don't think much more about it. Now, many of the key problems in cryptoeconomics concern the following question, which is what if when we are designing our mechanism, we have access to a cryptocurrency, to a currency native to a blockchain protocol on which that mechanism is executing? So this is just a really fascinating question. I don't really know of an analog of this in the traditional economics literature from the pre blockchain days. And this question is really interesting for two reasons. The first reason is it just enlarges the design space, right? So I'm just letting you do more things with mechanisms than you could before you could access sort of native cryptocurrency. You might ask what could you do with that power? Well, for example, you might be able to print new money, meaning new coins in the native cryptocurrency or conversely, take those coins permanently out of circulation.
00:04:45.590 - 00:05:34.754, Speaker A: Imagine traditional application of a vikri auction where the mechanism description includes oh, by the way, just print some new US dollars to sort of complete the description. It would look nuts. But this is actually supernatural in the context of blockchain protocols that host cryptocurrencies. The second reason this question is so interesting is because with that power, for example, to mint new coins or burn old coins, with that power comes responsibility in the sense that there are then macroeconomic consequences of your mechanism. It actually affects the supply of the native currency that it's working with. Think about running like a second price auction in the real world, right? You are not thinking about the US money supply, right? It has nothing to do with you. It's totally outside of your mechanism.
00:05:34.754 - 00:06:46.910, Speaker A: Whereas in these types of problems in crypto economics, the microeconomic design aspects of the mechanism are just intrinsically coupled to the macroeconomic consequences of the mechanism which again is something I've really just never seen it before. So let's proceed to two, I think, really good examples of these types of problems in crypto economics, and in particular, this interplay between the micro and the macroeconomics in mechanism design. So let's go back to the beginning. Let's go back to Nakamoto and the Bitcoin protocol and let's examine it through a mechanism design lens. So let's start with the desired outcome. So here we'd just like everybody to follow the protocol as intended, which means every Bitcoin miner, we would like to see them dutifully trying to solve their proof of work crypto puzzles and in doing so, trying to add a block extending the end of the longest chain. The question then is how do we reverse engineer a game like, for example, payoffs to the participants that incentivizes them to act in this way? So the behaving in this way constitutes an equilibrium of that game.
00:06:46.910 - 00:07:36.538, Speaker A: Nakamoto and Bitcoin approach this in what is probably the most natural possible way, which is, you know, whenever a miner gets a block on the longest chain, let's give them a reward. We're not interested in blocks that are off of the longest chain. So blocks off the longest chain will get no reward. And the intuition behind that is then sort of pretty clear, right? So as a miner, your rewards come purely from blocks that get added to the longest chain. So any block that you create, you want to maximize the likelihood that it's going to wind up on the longest chain. And intuitively, like, what could you do that would be better than just appending it to the end of the longest chain, such as it is right now? There's one quick digression, which is that in a famous paper almost a decade ago by AOL and Surrey, they showed that actually this intuition isn't 100% correct. It does incentivize miners to coordinate on the longest chain in certain regimes.
00:07:36.538 - 00:08:52.790, Speaker A: There are other regimes where actually, while it is true nodes are incentivized to some extent to add blocks to the longest chain in an orderly fashion, in some regimes they're incentivized even more to behave in unintended ways, deviating from the longest chain protocol. And this you can interpret as sort of a cautionary tale of just how hard it is to get the game theory right in the design of blockchain protocols. Now, for this idea of rewarding blocks in the longest chain, for that to be meaningful, it must be that those rewards have real economic value. And so the question is, where is that money, where is that value going to be coming from? Who's going to pay for those rewards that are going to Bitcoin miners? So this question would be difficult, if not impossible, to answer without access to some native currency, to some cryptocurrency. But of course, the Bitcoin protocol does have access to its own native currency. And in particular, the protocol is in a position whenever a block is added to the longest chain to simply mint new bitcoins, currently six and a quarter bitcoins. And then that is the reward that gets directed to the creator of that block.
00:08:52.790 - 00:09:37.246, Speaker A: This is, in fact, the only way that bitcoins have ever been brought into circulation. And here already you can start seeing that there are, in fact, macroeconomic consequences of these mechanism design decisions. Right? So printing new money, that's a form of inflation. So when we ask the question if meaningful value is going to sort of creators of these blocks, where is that value coming from? It's basically coming from the holders of that cryptocurrency. So from bitcoin holders in the form of a type of dilution. So from my description so far, it probably just sounds like money is going to be printed in perpetuity, right? Blocks are going to keep getting created. I said with every block, new coins get minted.
00:09:37.246 - 00:10:53.050, Speaker A: So it would seem that the supply of bitcoins is always going to be increasing, but famously, that is not the case. You could imagine a version of bitcoin like that, but Nakamoto famously was very intentional about setting a hard cap on the number of bitcoins that could ever possibly be in circulation, that number being 21 million. And I want to emphasize this design decision in bitcoin is really orthogonal to all of the other stuff you might have heard about, right? Longest chain, consensus, proof of work, civil resistance, UTXOs, the bitcoin scripting language, you could have all of that stuff with a different macroeconomic policy. But in this independent dimension, nakamoto required that there would be this hard cap on the number of bitcoins, perhaps as a reaction to the bank bailouts that were happening at that time during the great recession. So, again, Nakamoto was not like logically forced into this macroeconomic policy, but then after deciding upon this macroeconomic policy, it logically forced other aspects of the design. Right, given that the bitcoin protocol never burns bitcoins, so bitcoins never get deliberately removed from circulation, so the money supply is only increasing. So if you're going to have a hard cap of 21 million, that means at some point the block rewards have to be going to zero.
00:10:53.050 - 00:11:46.240, Speaker A: And that's currently expected to happen in the year, something like 21 40. All right, so at this point, you'd be totally right to circle back to our original question, which is like, okay, well, then what's actually our plan to sort of motivate nodes to carry out the bitcoin protocol if we're not going to use black rewards? The vision has always been since the bitcoin white paper, that, look, if bitcoin protocol is still being used over 100 years from now, presumably it's pretty valuable. And presumably people are going to be paying nontrivial transaction fees for the privilege of their transactions being included. So the hope was always that decreasing block rewards would be supplanted with increasing transaction fees. It's always been obvious that if that didn't happen. If the block rewards went to zero and the transaction fees stayed small, it's always been clear that the bitcoin protocol would cease to be useful, at least for sort of valuable transactions. It would have poor economic security.
00:11:46.240 - 00:12:22.486, Speaker A: There's also a much sort of more subtle issue which was investigated in detail in a paper six or seven years ago by Carlston At All, which is that another difference between block rewards and transaction fees is that block rewards, they're always the same, every single block. So currently it's six and a quarter bitcoins for every block. Doesn't matter if it's today's block or tomorrow's block or whatever. Yes, every four years it changes. But sort of locally, all blocks have exactly the same block reward. Transaction fees, meanwhile, can vary by an order of magnitude or more from block to block. So you have high variance in transaction fees you did not have with block rewards.
00:12:22.486 - 00:13:06.338, Speaker A: And that actually creates some additional game theoretic issues. For example, imagine you're a bitcoin miner, and the last miner that sort of produced a block cleared out the mempool. There's nothing left, and all of the transactions that it included had like tons of transaction fees. So the last bitcoin miner just made a killing and there's literally no transactions for you remaining at all. Well, then you got to start wondering, especially if the block reward is pretty small. Maybe instead of trying to extend that last lucky miner their block, like I'm supposed to do, maybe I'll actually try to fork their block. So basically replay a version of almost the same block, maybe with a few less transactions, but basically stealing most of their transaction fees.
00:13:06.338 - 00:13:45.780, Speaker A: And more generally, when you have very small block rewards and high variance in transaction fees, miners are incentivized to keep undercutting each other as opposed to extending each other's blocks. And that would be a real issue. Now, with transaction fees, you can imagine pretty simple tweaks to bitcoin that would fix this. It would be a hard fork, but it wouldn't be a dramatic hard fork. For example, you can imagine smoothing transaction fees over many blocks. So maybe when you mine a block, you would get 1% of the transaction fees of that block, plus you'd get 1% cut of the transaction fees of each of the next 99 blocks as well. Then it wouldn't be a perfectly constant reward from block to block, but it would presumably be close enough.
00:13:45.780 - 00:14:34.590, Speaker A: So when this Carlston At All paper came out, ethereum had really sort of just started. There certainly wasn't any DeFi or decentralized finance. So pretty much the only things there were to worry about were block rewards and transaction fees. There was not really any other source of minor revenue back then. Now, and this is what so often happens with good research, which is that if you nail the essence of some issue, you just find that it just sort of reoccurs in disguise. In a way you never could have intended many years later. And that's exactly what's happened with that Carl Stunnedall study, because their identification of these undercutting issues that miners are incentivized to carry out if there's high variance revenue coming from blocks, that's now become more relevant than ever with the advent of decentralized finance on Ethereum and other smart contract platforms.
00:14:34.590 - 00:15:18.180, Speaker A: There's something known as mev. I'm not going to even try to define it, but roughly think of it as like miners or block producers kind of siphoning revenue off of the application layer, thereby giving them a third sort of stream of rewards. And even more so than with transaction fees, mev opportunities can vary tremendously, block to block by orders of magnitude. So again, you sort of want to try to think about sort of smoothing them out. Now that's going to be harder with mev than with transaction fees because transaction fees are directly visible to the layer one. So for example, to Ethereum mainnet and it's in a position to just smooth it out itself. Mev lives at the application layer, so it's not directly observable by the underlying consensus protocol by layer one.
00:15:18.180 - 00:16:06.658, Speaker A: So to carry out this smoothing idea, you need to have some other ingredient, like maybe a sort of competitive market for block building, so that the mev value at the application layer winds up getting expressed down at the consensus layer, so that it's in a position to smooth out those payoffs. If you want to see the latest along that, I would just do a search for mev smoothing and in particular, the Ethereum community's latest work on that topic. So let's move on to our second example. We'll be segwaying from bitcoin to Ethereum and from block rewards to transaction fees. And let's look at the market for Ethereum block space through the lens of mechanism design. So Ethereum block space is typically a scarce resource. So one desired outcome we might be interested in is allocating that scarce resource in the most efficient way possible.
00:16:06.658 - 00:16:46.782, Speaker A: That is to the transactions that gain the most value from being executed in the Ethereum virtual machine. One way to suss out the most valuable transactions would be to charge as a transaction fee the market clearing price. Here, by market clearing price, I mean the price at which supply equals demand. So if the supply of Ethereum block space is like 15 million units of gas per block, then I'm talking about the price at which there's precisely 15 million units of gas worth of transactions that are willing to pay that price. That's what I mean by the market clearing price. If the market clearing price just fell from the sky, we'd be good to go. The block space would be fully utilized and by precisely the transactions willing to pay that price.
00:16:46.782 - 00:17:30.678, Speaker A: So precisely the most valuable transactions, of course, market clearing price does not fall from the sky. So we have to address where it might come from in the transaction fee mechanism that's always been used in bitcoin and also was used in Ethereum until a little over a year ago, something known as a first price auction. There, users basically just have to figure it out for themselves. So every user just attaches a bid to its transaction, which it has to pay if that transaction winds up getting included in some block. And with this mechanism, you're kind of hoping that at equilibrium in some sense of the word, users have basically figured out how to bid. Meaning they've basically figured out the market clearing price. That, however, is not so easy to do first price auctions.
00:17:30.678 - 00:18:23.770, Speaker A: It actually can be pretty tricky to figure out what to bid, especially if you have sort of wildly changing demand, as you often do in a blockchain context. So those concerns were the primary motivation behind the design of the mechanism known as EIP 1559. So this is the transaction fee mechanism that Ethereum is using now and has been since August of 2021. And here the idea is rather than foist any work onto the users, the protocol itself, the transaction fee mechanism itself is going to try to keep track of what the current market clearing price is, something known as a base fee, which again is an estimate, the mechanism's current estimate of what the market clearing price is. So, some additional details so first of all, the mechanism is continually adjusting the base fee after all demand. And therefore the market clearing price might be changing over time. So it's continually updating the base fee using a form of local search.
00:18:23.770 - 00:19:02.098, Speaker A: So if recent blocks kind of look too small, smaller than you'd like, that suggests the current base fee is set too aggressively and that you should decrease it. If recent blocks are sort of bigger than you'd like, that suggests that the base fee is too low and that you should increase it. So this mechanism turns out to have some really nice properties from a UX sort of game theoretic perspective. So for example, most of the time it's as easy for users as shopping on Amazon. So it acts as something known as a posted price mechanism. So basically from a user perspective, it just kind of says there's a price posted, hey, $10 to have your transaction included. You can either pay it or not, just as if you were shopping at Amazon.
00:19:02.098 - 00:20:03.626, Speaker A: There is sort of an edge case where if the base fee is way too low, then you kind of gracefully revert back to a first price auction, but you don't have those nice sort of UX properties. The mechanism is also unusually resistant to collusion of various forms. So for example, between a block producer and a bunch of users who'd like to have their transactions included in that block and a twist to this whole analysis is that those collusion resistance properties actually hold only if you do something counterintuitive with the revenue generated by the base fee. The obvious thing to do with the base fee revenue is to pass it on to the producer of the block, right? That's what's always sort of historically been done with transaction fees and bids in these transaction fee mechanisms. But if you do that, then in fact the game theory breaks down. Then in fact a cartel of a block producer and users can collude off chain to circumvent any kind of base fee you might be trying to enforce on chain. However, if you redirect the revenues generated by the base fee literally anywhere else, it doesn't matter as long as it's not to the producer of that block.
00:20:03.626 - 00:21:03.482, Speaker A: If you direct them anywhere else, then actually you do get all of these unusual and very attractive collusion resistance properties. So you could imagine different versions of EIP 1559 that answer the question where to route to the base fee revenues in different ways. Just like you could imagine different versions of Bitcoin with different macroeconomic policies concerning the circulating supply. And again here a specific choice was made in the version of EIP 1559 deployed in Ethereum, which is do maybe the sort of simplest possible thing with the base fee revenues, which is simply to burn them. By which I mean that the currency used to pay transaction, to pay the base fee, those coins are just removed permanently from circulation. And it is in this design decision then within EIP 1559 where it's now crucial that the mechanism has access to a native currency. That's why it's able to burn permanently the coins used to pay those transaction fees.
00:21:03.482 - 00:22:05.486, Speaker A: I should say up till this point, like everything on the last slide, all of that, everything could have been denominated in USDC and it all would have made sort of perfect sense. This step would not make sense if everything was denominated in Know. The Ethereum blockchain of course, isn't a position to burn some digital representation of a US dollar that sits somewhere else. It is not in a position to actually burn that US dollar, whereas it is in a position to burn the native currency, to burn ETH. So the only reason this works, the only reason you can get away with is burning the base fee revenue solution is because you have access to that native cryptocurrency. But as usual, with this power to manipulate the underlying cryptocurrency comes responsibility, meaning macroeconomic implications, right? So the design decisions that have been taken in EIP 1559 all motivated primarily by simplicity. Either simplicity for the user in figuring out how to bid or simplicity just in the protocol and its implementation by doing the simplest possible thing to dispose of base fee revenues.
00:22:05.486 - 00:23:21.830, Speaker A: That combination, it just has macroeconomic consequences, right? It's sort of the opposite of the block rewards that we had in Bitcoin. Rather than a form of inflation, this is a form of deflation. So this is pushing toward decreasing the circulating supply of ETH, there are still sort of inflationary aspects of ethereum, so you get this tug of war between the inflationary parts and the deflationary parts. But long term, I think most of us expect ETH to be a deflationary currency. So we have this nontrivial macroeconomic consequence of design decisions that were really made more for microeconomic reasons. And a question you could ask is like, is this byproduct should we be happy about this? Or is this just sort of a cost we have to pay? How should we feel about this? Now, if you ask anyone who holds a nontrivial amount of ETH of ethereum's cryptocurrency, they're generally going to be you'll find they'll be really big fans of these design decisions and of the deflationary pressure on the currency that's caused by EIP 1559. The reason being is if you sort of posit that the overall value of the ethereum cryptocurrency should be independent of the circulating supply, right? Like if you double the number of coins, well, then each coin should just be worth half as much, sort of and vice versa.
00:23:21.830 - 00:24:11.734, Speaker A: Well, then whenever coins are being taken out of circulation and the overall number of coins is decreasing, that means the per coin price should be going up. So holders of the currency are sort of hoping that this deflationary pressure makes their coins worth more going forward. If, on the other hand, you ask any traditionally trained macroeconomist about this, they're going to tell you, oh my God, what a bad idea. They're going to just have a knee jerk reaction that deflationary currencies are doomed to fail. They'll probably tell you stories about sort of stagnation in Japan back in the 1990s. Now, I got to tell you, I'm not super convinced by this analogy. It's not obvious to me that, I don't know, sort of the currency of a sovereign nation is such a great analogy for sort of a cryptocurrency like ETH.
00:24:11.734 - 00:25:15.890, Speaker A: But I have to concede that the gauntlet has been thrown. I mean, I do think it is up to researchers in the blockchain space to explain why it might be that deflation is not a disaster for a cryptocurrency in the way that it's believed to be for currencies of sovereign nations. All right, so the two examples we've covered so far, I think kind of despite the fact that so many people define crypto economics in so many different ways, I think pretty much everybody would agree that the two problems we just saw are indeed crypto economics. And in particular, both of those illustrate this very sort of unique interplay between the micro and macroeconomics sort of of the mechanism design problem, which again, really does not have analogs in traditional mechanism design. For this third example, I think some people would call this crypto economics and some people wouldn't. I wanted to talk about it anyways, number one, because I wanted to say at least something at the application layer, we've been talking much more about the consensus layer thus far. Plus I just wanted to tell you about sort of some of the work I've been doing most recently in sort of DeFi in decentralized finance.
00:25:15.890 - 00:26:02.158, Speaker A: So specifically I want to talk a bit about automated market makers or AMMS through the lens of mechanism design. Now, my guess is, if you're watching this video, there's a good chance, you know, at least kind of superficially what AMMS are know, but just sort of a quick review to the point of any exchange. And in particular, in AMM is to allow two different assets to be exchanged for each know, maybe ETH for USDC and vice versa. We've of course had exchanges sort of in the traditional markets forever. And there's largely a convergence on a particular design, namely a limit order book. But in blockchains thus far, the dominant paradigm, at least for purely on chain solutions, has been different. And that's because limit order books, they're just sort of a poor match for blockchain protocols, at least the ones that we have right now.
00:26:02.158 - 00:27:04.660, Speaker A: They're primarily just because they're too expensive, they require too much storage and too much computation. For a purely on chain exchange, you really want to do something simpler than a limit order book. Automated market makers or AMMS are then that simpler format. So an AMM is not keeping track of some perhaps long list of sort of outstanding limit orders. It's really just keeping track of generally sort of two numbers, which is how many coins, X and Y, it has of the two different assets that's enabling the exchange of and as a function of those two supplies of X and Y programmatically, there's going to be some spot price which is then quoted at which traders are free to buy or sell. So in an AMM, a little bit of computation is required to determine how much you get back of one asset in exchange for a given amount of the other asset. But it's generally a very lightweight computation, certainly much lighter than trying to do matching of orders in a limit order book.
00:27:04.660 - 00:28:02.322, Speaker A: Interestingly, AMMS, they've risen to prominence kind of in web three in the blockchain world, not so much for for economic reasons, but really just for computational considerations, right? Just for their simplicity. So they're really kind of the product of doing mechanism design under very severe computational constraints, just because the amount of computation available on a blockchain like Ethereum is really quite limited. This echoes sort of the theme in a well known branch of algorithmic game theory called algorithmic mechanism design, which focuses on mechanisms guaranteed to run in polynomial time. But polynomial time is definitely not good enough for something you're going to implement purely on chain. On a blockchain like Ethereum, you really need much tighter control over the computation required. And it's under those severe constraints that AMMS really shine. Unlike the last two examples, AMMS don't really fundamentally.
00:28:02.322 - 00:28:55.474, Speaker A: Rely on the existence or access to cryptocurrencies, right? Back when we talked about Bitcoin, the mechanism needed to sort of print new bitcoins in order to reward producers of new blocks. That obviously is impossible unless you actually can directly control and manipulate the currency. Similarly, in EIP 1559, all of those base fee revenues got burned so that you'd have good game theoretic properties. Again, not clear how you'd pull that off if you couldn't sort of directly work with a native currency. AMMS, they're typically used to trade cryptocurrencies, granted, but there's nothing fundamental about that. You could use an AMM to trade any two assets, right? X and y on the slide could be units of anything. And meanwhile, the actual sort of operation of what an AMM does, I mean, it's basically just some arithmetic, right? It really doesn't need some kind of native token or native currency in order to carry out the operations of an AMM.
00:28:55.474 - 00:29:40.248, Speaker A: Again, unlike bitcoin block rewards, unlike EIP 1559, and indeed, when uniswap, right, the most famous AMM out there, when they launched originally, they did not have any kind of token because they didn't need one. There were other tokens that you could trade in their AMMS. And again, the operation of the AMMS didn't really need that token. So there is a uni token now, but that was added only later. It's really not fundamental to how those uniswap AMMS operate. All right, so I promised to say just 1 minute about the research I've been doing lately concerning automated market makers, which is about a measure known as lever. So that's LVR, which stands for loss versus rebalancing.
00:29:40.248 - 00:30:08.084, Speaker A: Now, we've already talked about benefits of AMMS. So principally they're just computationally very simple, so suitable for on chain implementation in today's blockchain protocols. They also guarantee liquidity even for sort of long tail assets where there's a thin market. So that's another nice property of them. But they do have drawbacks too, inevitably. And so one of the main ones is what's known as adverse selection for the liquidity providers. Remember LPs, they're the ones that actually deposit the coins in the first place.
00:30:08.084 - 00:30:56.580, Speaker A: The traders are then trading back and forth. So by virtue of always being open for business, always being willing to take either side of a trade at the current quoted spot price, basically, liquidity providers can be forced to carry out trades at worse than market prices. So, for example, if the spot price of an AMM ever becomes stale, if it ever sort of drifts away from the price of the asset on the open market, then you can expect some sort of opportunistic arbitrageure to make a trade. That corrects. The spot price of the AMM brings it in line with the rest of the market. Those arbitrage trades, they will yield profit for the arbitrageure, and that profit will come at the expense of the liquidity providers. So that's what I mean by the LP's adverse selection costs being forced to take possibly the wrong side of every single trade.
00:30:56.580 - 00:31:42.032, Speaker A: So the work I've been doing with a number of co authors recently strives to isolate and characterize these adverse selection costs to really just give sort of a formula for exactly what's the cost to an LP for providing liquidity to one of these pools. Now remember, it's not all bad news for the LPs. They're also getting a share of the fee revenue. So if that's high enough, that will outweigh the losses from lever. But lever is sort of isolating the cost part of the cost benefit analysis that liquidity providers should be doing so before our work. So over the last couple of years, adverse selection costs were typically measured by something known as impermanent loss. And I won't define that for you here, but let me just say our critique of that is that it conflates two really fundamentally different things.
00:31:42.032 - 00:32:39.620, Speaker A: It conflates the adverse selection costs that we're trying to isolate with sort of price movements of the underlying assets. So in particular, large adverse selection costs can be occluded by favorable changes in market conditions. So one way to think about our concept lever is as basically taking impermanent loss and modding out by all the parts of it that depend on market movements. So another way to think about it is if you hedge out the hedgeable parts of impermanent loss, you're left with this sort of unhedgible residue which just stems from sort of trades being executed at unfavorable prices. And this unhedgible residue that you're left with is exactly what we're calling lever or loss versus rebalancing. I'm not going to go into technical detail here. Let me just say that if you want to compute historical lever so using past data, that's quite straightforward to do using the typical data you'd have for an AMM's performance if you want to make predictions about the lever going forward.
00:32:39.620 - 00:33:22.880, Speaker A: Like if you're a potential liquidity provider assessing whether to deposit your coins in an AMM or not. You want to know what kind of lever you should expect. It actually turns out for most of the popular AMMS to be surprisingly easy to work with analytically in kind of a standard black Scholes setup. So one example of that would be the sigma squared over eight that's on the bottom of the slide that I'm not going to explain here. But if you want to know more about lever, you can check out YouTube videos by any of the co authors of this paper. So myself, Jason Milionis, who's a PhD student at Columbia, CMC Molemi, who's a professor in the Business School of Columbia, and Anthony Li Zhang, who's a professor in the business school at University of Chicago. So we all have longer form talks on lever, which you can find on YouTube.
00:33:22.880 - 00:34:04.928, Speaker A: All right, so that wraps up the examples I wanted to discuss. Let me just conclude this talk with three slides of kind of grand challenges, let me call them in crypto economics, I've grouped them by theme. So I'll sort of talk about the theme of each and mostly just leave it to you to read sort of the specific example questions that are on the slide. So grand challenge number one, which is maybe the most ambitious of them all, is to make macroeconomics our own. And here, by we, I mean the types of people that I envision probably watching this video. So computer scientists, blockchain researchers, et cetera. And this is something we've seen happen, frankly, with other parts of economics over the past 20 to 25 years.
00:34:04.928 - 00:34:46.716, Speaker A: It started with game theory. So it's been around forever since the in the late 90s, computer scientists got interested in Game Theory because they needed it to reason about the applications that they cared about. And at the same time that they learned how to apply Game Theory in their applications, they also brought sort of unique things to the table. So they also made Game Theory their own, bringing in, for example, a concern for computational complexity, the price of anarchy of Nash Equilibria and so on. It happened next with mechanism design, which, again, has been around forever. It's been around for, I don't know, 60 plus years. And again, computer scientists, we sort of needed to learn mechanism design because, again, it was so relevant for the applications that we wanted to think about.
00:34:46.716 - 00:35:43.352, Speaker A: But over the last 20 years, we've also, in some ways, made it our own, again, with an emphasis on sort of computational and communication constraints, using approximation to overcome problems that are historically sort of dismissed as just unsolvable and weakening informational constraints, which are sort of pretty common historically in the mechanism design literature. And I got to tell you, to date, as far as I know, there's been basically zero conversation between computer scientists and traditionally trained macroeconomists. Like, if you look over the conference proceedings of the EC conference, so EC stands for Economics and Computation. That's the flagship conference in algorithm, the Game Theory. I'll bet over those 25 conference proceedings, the median number of papers in that conference in a given year that touch macroeconomics. I'm guessing the median number is zero. I'm not saying there's never been any in the history of the field, but it's really very rare.
00:35:43.352 - 00:36:06.724, Speaker A: Similarly, I go give seminars at economics departments all the time. I've done it dozens and dozens of times. They always take me out to dinner with a selection of the faculty. I've never met a macroeconomist at one of those dinners ever. So there's definitely like a big gap right now as far as the interaction between the two. Like game theory, like mechanism design. We're going to have to come to macroeconomics because we need it.
00:36:06.724 - 00:36:45.164, Speaker A: We need to understand fundamental questions that come up in the design of blockchain protocols. Nakamoto thought a hard cap was a good idea. Is it a good idea and again, I don't want an answer based on politics or ideology. I want an answer based on technical and economic analysis. Similarly, remember the paradox of the deflationary cryptocurrency, right? You have ETH holders who love it, you have macroeconomists who think it's a disastrous idea. Please give me some technical or economic analysis to help sort of resolve these conflicting opinions. So the second grand challenge is a topic on which I think we've actually made a lot of progress as a community over the last few years.
00:36:45.164 - 00:38:00.568, Speaker A: Though I do think there's still a huge opportunity to take the ideas that we've learned, the lessons we've learned so far, and transform that into really a mature theory at the level of, say, the theory for analyzing classical consensus protocols where people pin down sort of the optimal fault tolerance possible for every imaginable distributed computing model you might ever think of. I think we can get to a similar level with this topic, namely incentives at layer one in the consensus layer already with the bitcoin and ethereum protocols. There are some very nice ideas on this topic. We've discussed some of those previously in this talk and then there's been sort of more breakthroughs since, right? So for example, we've got postmerge ethereum or ETH 2.0, whatever you want to call it, which introduced a number of further ideas in order to incentivize the nodes running the protocol to behave as intended. But while we've definitely had some good ideas thus far, I do think there's a real opportunity to take kind of our, I'd say, fairly ad hoc current understanding and transform it into a really kind of complete and mature theory, right? So just to give one example, so slashing is definitely part of the post merge ethereum vision. So post merge ethereum is a proof of stake blockchain protocol.
00:38:00.568 - 00:38:48.344, Speaker A: Those nodes responsible for carrying out the protocol are forced to put up a stake in the native ethereum cryptocurrency and that stake gets slashed at least partially taken away from them if they misbehave in a detectable way. And I should say it is not at all universally agreed upon that you should do slashing in a proof of stake blockchain. There's plenty of other proof of stake blockchain protocols that do not do slashing. They will still kind of withhold inflationary rewards from nodes if they misbehave, but they won't actually sort of take away any of their stake. Whereas in postmerge ethereum, if you're sort of a validator, you really are at risk of having your funds slashed. So the obvious sort of danger with slashing is you might wind up slashing nodes that were trying to be honest and just there was some kind of mistake. So that might be a little bit of a harsh of a punishment.
00:38:48.344 - 00:39:39.580, Speaker A: And then moreover, you might deter nodes from running the protocol if they're concerned about being slashed despite their best efforts. On the positive side, it seems like slashing enlarges the design space around proof of stake blockchain protocols in a way that seems to let you do things that you couldn't otherwise. But again, we do not have a formal proof of that. So once again we just have these super basic questions which, for example, I get asked all the time in my role running the research team at a 16 Z crypto. And frankly, just the theory is not there. I think it will be there, but we've got a lot of work to do. So the third circle of questions concerns the layers of the blockchain stack and understanding the economics of each layer in isolation and then also the economic interactions between the different layers of that stack.
00:39:39.580 - 00:40:27.336, Speaker A: Thus far, most of the research effort has been focused on layer one, the consensus layer, like we've been discussing, or on the application layer. But there's other layers of the stack and they're actually really important. For example, I have to call out the peer to peer layer or layer zero, right? So when you think about a consensus protocol, you presuppose something underneath it which allows the nodes to communicate with each other. Either maybe they're voting on blocks, maybe they're sort of sharing information about pending transactions. Right? And blockchain protocols usually do not directly incentivize nodes to participate correctly in the underlying sort of peer to peer communication protocol. The status quo may or may not be economically sustainable. It's not obvious.
00:40:27.336 - 00:41:05.572, Speaker A: Perhaps nodes have enough external reasons to participate correctly in the peer to peer network to do it despite the lack of direct incentives. But again, we just don't have a formal analysis of that. We really just don't understand layer zero from an economic perspective and we need to. Then there's also, at least in sort of our present designs, fairly complex interaction between the various layers. Like I think of mev as being maybe sort of exhibit A here. I think of that as an interaction between layer one and the application layer. For example, people like to assert that mev is sort of unavoidable, like you can't get rid of it.
00:41:05.572 - 00:41:50.884, Speaker A: Maybe that's true, I don't know. But certainly no one's ever proved a theorem which says that it's unavoidable. And to make that statement to my taste, I would like to see it backed up with some formal analysis zooming out even more broadly. At the moment we're seeing these very complex interactions between the different layers of the blockchain stack. And what's completely unclear to me is whether there's something about building decentralized systems that makes that inevitable, that you just can't have clean separations between the different layers. But for all I know, that's really just kind of an artifact of how little of the blockchain design space we've studied to date. So I hope that gives you a little bit of a taste of the kinds of questions that are on my mind and the kinds of questions that people ask me all the time.
00:41:50.884 - 00:42:16.990, Speaker A: Both in my role as a Columbia professor and in my role as head of research at a 16 Z crypto. The list of examples in this talk, of course, was not comprehensive. This list of challenge questions, of course, is not comprehensive. It's just merely meant to indicate that while we have a few answers, we have far, far more questions. We have a lot of work to do, but that's also the most exciting time to be in a research area. So that's all I've got. Thanks very much.
